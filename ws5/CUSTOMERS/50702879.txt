8728:US	50702879	R2KVQITKGKW5U0	0375423133	677060758	Meta Math!: The Quest for Omega (Peter N. Nevraumont Books)	Books	4	85	103	N	Y	A real boundary between what one can know of, but not know?	The omega number arises in the context of what is called algorithmic information theory, which the author of this book has been instrumental in developing. It is not a difficult concept to understand at least from the standpoint of where it stands in the deductive ladder of modern mathematics. The goal of algorithmic information theory was to formulate a notion of randomness that was not only rigorous from a mathematical standpoint but was also embedded in the notion of an algorithm. Recognizing that it is impossible to construct and infinite random sequence using a (deterministic) algorithm, the author's main contribution was to define a random infinite (binary) sequence using what he has called the `halting probability.' The omega number, or `halting probability' is defined with respect to a (prefix) machine that halts for some input program. Since the machine can halt, the omega number is positive, but is less than 1 since the machine does not always halt. The omega number is a probabilistic notion since it is the probability that the machine halts if its program is given by a sequence of fair coin tosses. The author shows that the omega number is a random real number, is not computable, and therefore transcendental. All of these notions he discusses in fair detail in the book. The omega number, as he defines and discusses it, is quite an astounding quantity, for he concludes that it measures what can be known by human reason. If the entire edifice of mathematics were compressed to a particular number of bits, then the omega number (for this number of bits) can be used to decide whether every result in this edifice is true or false (or independent).<br /><br />The book is interesting reading, the reader obtaining insight into how the omega number was discovered, its role in the philosophy of mathematics, and its ramifications in the automatic discovery of mathematics. In addition, there are many places in the book where the author gives sound advice on how best to pursue research in science and mathematics, and even philosophy. For example, he encourages the sharing of ideas in order for them to become successful. He also complains of the excessive egotism that permeates the scientific community, and describes this as \\"poisoning\\" science. In this regard, he correctly notes that scientific results are the product of many minds, and that their prioritization to one individual is wrong and instead is diffused over the population of researchers.<br /><br />The author is correct in saying that mathematics is not very different from physics, and that the creation of mathematics involves intuition and guesswork. But he is not convincing in showing that this intuition cannot be emulated in a (calculating) machine, but merely takes it to be an activity that must take place due to the limitations arising from the omega number. It is one thing to prove that the omega number places limits on mathematics. It is quite another to characterize \\"intuition\\" explicitly, freeing it from its current mystical connotations, and showing how it operates to bring about creative ideas in mathematics. And yes, mathematics must be beautiful, as the author states in the book. Aesthetic quality in pure mathematics has driven many of the research programs in mathematics. But mathematical beauty is in the eye of the beholder, and varies radically from one mathematician to another. Each mathematician deploys their own hedonic function when judging the beauty of particular mathematical constructions.<br /><br />The author also mentions AM (Automated Mathematician) in the book, calling it, interestingly, a \\"program.\\" At the time it first appeared, AM was thought of as \\"intelligent\\" and had the capability of creating original concepts in mathematics. After this initial confidence, it was then subjected to intense criticism, and due to this criticism AM was abandoned both by its creator and everyone else in the automated reasoning community of researchers. It has now become merely a \\"program\\", i.e. a collection of statements that cannot possibly be thought of as intelligent or creative.<br /><br />The author though exaggerates the ramifications of the incompleteness theorems of Godel and in the formalist program of Hilbert. The everyday practice and discovery of mathematics is not done formally, and if it were it is doubtful that mathematicians could be as productive as they are.  Mathematical results are reported using a mixture of natural language and mathematical syntax, and in no way are like the formal languages that Godel and Hilbert insist on. So the results of Godel do not cause any trouble for mathematics, since all mathematical research is expressed in informal language. And there are no examples of statements of the Godelian type being derived in the everyday practice of mathematics. Godelian statements must be artificially contrived and even then using a non-constructive diagonalization argument. Therefore it is of no surprise at all to find out that all of mathematics has not been derived from a small collection of mathematics. It is certainly not discovered that way, but rather arises as vague, random mental associations in the mind of the mathematician. Once discovered though, the results are published, using as much rigor as practical, with this rigor being constrained by the use of natural language. It remains to be seen whether the use of natural language can be eliminated ala the strategy of Bourbaki. If it can, maybe using a variant of discourse representation theory or some other strategy, then it is not unreasonable to believe that all mathematical results can be derived from a few axioms. If they cannot, this is no reason for worry, as they are intrinsically beautiful in themselves, and their applications will still go on and on.hers. It has now become merely a \\"program\\", i.e. a collection of statements that cannot possibly be thought of as intelligent or creative.  <br /> <br /> <br />The author though exaggerates the ramifications of the incompleteness theorems of Godel and in the formalist program of Hilbert. The everyday practice and discovery of mathematics is not done formally, and if it were it is doubtful that mathematicians could be as productive as they are.  Mathematical results are reported using a mixture of natural language and mathematical syntax, and in no way are like the formal languages that Godel and Hilbert insist on. So the results of Godel do not cause any trouble for mathematics, since all mathematical research is expressed in informal language. And there are no examples of statements of the Godelian type being derived in the everyday practice of mathematics. Godelian statements must be artificially contrived and even then using a non-constructive diagonalization argument. Therefore it is of no surprise at all to find out that all of mathematics has not been derived from a small collection of mathematics. It is certainly not discovered that way, but rather arises as vague, random mental associations in the mind of the mathematician. Once discovered though, the results are published, using as much rigor as practical, with this rigor being constrained by the use of natural language. It remains to be seen whether the use of natural language can be eliminated ala the strategy of Bourbaki. If it can, maybe using a variant of discourse representation theory or some other strategy, then it is not unreasonable to believe that all mathematical results can be derived from a few axioms. If they cannot, this is no reason for worry, as they are intrinsically beautiful in themselves, and their applications will still go on and on.	2005-10-09
10344:US	50702879	R3445Q114EIRFC	0521821126	41534022	Quantum Theory of the Electron Liquid	Books	5	10	12	N	Y	An outstanding job	Written with the student in mind, this book gives an excellent introduction to density functional theory, many-body quantum theory, and their application to the physical system now known as the electron liquid. Given the current interest in electron liquids, both from an applied and a theoretical standpoint, this book serves a need for those who want to educate themselves on the different techniques and strategies used to study the behavior of electron liquids, and general many-body systems. The authors of the book emphasize modern developments, and give many references for those readers who want to pursue the subject in even more detail. An understanding of both the physical and mathematical ideas in the book require concentrated effort, but anyone who has decided to read such a sizable book realizes that true insight into any subject only comes from such an effort. The authors understand this, and they do not hesitate to elaborate on sophisticated concepts when they arise. But they also interject informal and colloquial language in many places in the text. This serves to set the reader more at ease, and makes for even more enjoyable reading.<br /><br />Readers (such as this reviewer) who have a background in high energy physics or relativistic quantum field theory will find many of the concepts used in these fields find application in the theory of electron liquids. In addition, many of the concepts used in high-energy physics, such as the idea of spontaneously broken symmetries, arose in condensed matter and many-body physics. The symbiosis of ideas between these different fields has been a fruitful one and this will no doubt continue in the years to come. An example of this is the Chern-Simons theory, which arose in the context of quantum chromodynamics as a theory of the strong interaction, and finds its way in this book in the discussion on the Laughlin theory of the fractional quantum Hall liquid. This theory, as the authors point out, is based on a careful choice of wave functions, and therefore cannot be viewed as systematic in its strategy in finding solutions. The Chern-Simons theory is brought in to provide a more systematic approach. It is a fascinating strategy, for using it one maps the problem of the two-dimensional electron liquid into an equivalent many-body problem of interacting composite particles. One can then use a mean-field approximation on the latter system. This approach is somewhat similar to the \\"duality\\" phenomena found in string theories (although the analogy is somewhat loose). The Chern-Simon theory also finds its place in purely mathematical contexts, such as topological quantum field theory and the theory of knots, and readers with a background in this area will see familiar constructions in the author's discussions. The authors derive an expression for the electromagnetic response function for a system of composite particles that satisfies Kohn's theorem, but point out that it does not have the correct scaling properties.<br /><br />The authors give a thorough overview of density functional theory, with emphasis placed not only on the formalism but also on its utility in solving many-body problems. Readers growing up in the usual formalism of Hilbert spaces will need justification as to the power of density functional methods and how one can still calculate quantities of interest without really using the many-body wave function. And, anyone who has tried to perform numerical computations of quantum-mechanical quantities understands the need for algorithms that are manageable, i.e. that allow the computation of physical quantities in a reasonable time scale. The authors point out though that the Kohn-Sham equations, which result after the minimization of the energy as a functional of the electron density, can be solved computationally on a time scale that increases as a power of the number of electrons. This is to be contrasted with the computation of the solution of the N-electron Schrodinger equation, which depends exponentially on N. However, as in all problems in constrained optimization, there is no free lunch (this has been proven rigorously), and so there is always a penalty to be paid in any solution strategy. For the Kohn-Sham equations, one uses the `effective potential' that is local in space, but has a nonlocal dependence on the density, allowing only an approximate description. Another penalty arises from using the determinantal wave function in the solution of the Kohn-Sham equations does not give a robust approximation to the true ground-state wave function. The last penalty arises because of the \\"universal\\" nature of density functional: it has the same form for all physical systems and so does not bring out the physical properties that are unique to a particular one. In addition to these issues, readers who insist on constructive approaches to mathematical proof will reject the proof of the Hohenberg-Kohn theorem, since it relies on proof by contradiction. In physical applications this is a minor issue of course, but in attempts to put density functional theory, indeed all of quantum field theory, on a constructive rigorous mathematical foundation, this issue is of importance. The authors (correctly) have no intention of respecting mathematical rigor, and state so explicitly. Instead they emphasize the physics behind the formalism and discuss the experimental evidence for it. Indeed, the book is full of examples of this evidence, and the appropriate references are given. Most of the discussion on the experimental situation is given in the context of the quantum Hall effect, which seems appropriate given that the authors have made original contributions to the understanding of this effect.<br /><br />[DISCLOSURE: This reviewer knows the second author personally, but did not discuss this review with him. The opinions above are an honest assessment of the content of the book, and were not influenced, at least consciously, by any personal knowledge of the author.]ich depends exponentially on N. However, as in all problems in constrained optimization, there is no free lunch (this has been proven rigorously), and so there is always a penalty to be paid in any solution strategy. For the Kohn-Sham equations, one uses the `effective potential' that is local in space, but has a nonlocal dependence on the density, allowing only an approximate description. Another penalty arises from using the determinantal wave function in the solution of the Kohn-Sham equations does not give a robust approximation to the true ground-state wave function. The last penalty arises because of the \\"universal\\" nature of density functional: it has the same form for all physical systems and so does not bring out the physical properties that are unique to a particular one. In addition to these issues, readers who insist on constructive approaches to mathematical proof will reject the proof of the Hohenberg-Kohn theorem, since it relies on proof by contradiction. In physical applications this is a minor issue of course, but in attempts to put density functional theory, indeed all of quantum field theory, on a constructive rigorous mathematical foundation, this issue is of importance. The authors (correctly) have no intention of respecting mathematical rigor, and state so explicitly. Instead they emphasize the physics behind the formalism and discuss the experimental evidence for it. Indeed, the book is full of examples of this evidence, and the appropriate references are given. Most of the discussion on the experimental situation is given in the context of the quantum Hall effect, which seems appropriate given that the authors have made original contributions to the understanding of this effect.     [DISCLOSURE: This reviewer knows the second author personally, but did not discuss this review with him. The opinions above are an honest assessment of the content of the book, and were not influenced, at least consciously, by any personal knowledge of the author.]	2005-10-08
19609:US	50702879	RJCT7ZQOP2YHV	0521361001	933005053	Modeling Brain Function: The World of Attractor Neural Networks	Books	4	17	17	N	Y	Of historical importance	The study of the physics of the brain from the standpoint of dynamical systems was very popular during the 1980's. The theory of chaotic dynamical systems, and the accompanying concepts of strange attractors, horseshoe maps, and fractal basins of attraction was the subject of intense research at that time. It was inevitable perhaps that these theories would be applied to the understanding of the brain, given the dynamical nature of the neuronal synapse. This book, published in 1989, gives a good overview of what was known at the time. It could be read by anyone with a background in dynamical systems and some elementary knowledge of brain biology. The mathematics is also straightforward in that the author does not bring in any of the heavy tools from differential topology or measure theory, which is normally done in discussions of dynamical systems.<br /><br />There are some points made in the book that must be understood by the reader because the author feels that they are needed to build a successful model of the brain. For example, he discusses the notion of an `input system', which is a system that, for each input, produces and output with the same \\"status.\\" Cognitive discrimination must be used at the input level, if one is to avoid the use of the `homunculus' (the little external observer), for distinguishing between \\"good\\" and \\"bad\\" outputs. The major task in the author's view is to produce \\"exceptional\\" input-output relations, i.e. relations that correspond to intuitions about cognitive processes. A successful brain model, i.e. one that is able to incorporate memory, should be able to distinguish between stimuli that are familiar from those that are to be submitted to the brain for processing or learning. Thus the model must avoid the use of what the author calls `spontaneous computations', which require an external observer (the homunculus again) to interpret the relation between the input and the output. The author gives an example of a system that performs only spontaneous computations early on in the book. Hence the author proposes the use of artificial neural networks (ANNs) to avoid the occurrence of spontaneous computations. An ANN organizes stimuli in association classes represented by an attractor, and all the stimuli in a particular class are associated with the attractor to which they flow. The author feels that ANNs are more adept at respecting the requirement that for mental computations, which are essentially operations on temporal sequences of data, some record of the initial input sequence must be carried along on a parallel channel, in order to provide the outcome with specific \\"meaning\\" and a correspondence to the assigned task.<br /><br />These considerations on the dependence of the processing on the initial input motivate the author to discuss the role of ergodicity in the dynamics of the neural systems of the brain. As the author shows, any generic system subjected to noise will be ergodic, so that eventually the system will access each of its possible states in a manner that is completely independent of the initial state. The author points out two ways in which ergodicity can be avoided: one is to assume that the network is noiseless, and thus only certain moves are allowed from each vertex; the other is to assume that `cooperative phenomena' is present. Since the first possibility is rather exceptional, the author chooses the second, and gives detailed discussion on how cooperative behavior can arise in ANNs. One interesting, and ubiquitous example that he discusses for cooperativity as an emergent property is the Ising model. Mathematically, the breaking of ergodicity involves the taking of the thermodynamic limit, and a necessary condition for emergence is this context is the asymptotic degeneracy of the eigenvalues. To illustrate how this is done, the author uses the solution of a master equation that characterizes the probabilities of making transitions from one state to another in the system.<br /><br />In order to build a credible model of the neuronal processes of the brain, the author is aware that such a model has to be able to deal with input in the form of temporal sequences, and not just single patterns. He devotes an entire chapter to this in the book, motivating his discussion with the notion of a `central pattern generator' (CPG). The simplicity of CPGs is a concern and the author is aware that such simplicity does not exist in models of cognitive processes. Nevertheless the modeling of CPGs using neural networks can add credence to the program to model general brain processes in terms of neural networks, complex as they can be.<br /><br />One of course must be able to deal with both the storage and the retrieval of temporal sequences. After discussing some of the early research dealing with these needs, the author then reviews a strategy for dealing with temporal sequences that involves the notion of a `quasi-attractor', which is a network state that acts like an attractor for a short period of time. Quasi-attractors are used to delay the transfer of information out of the attractor. Thus the transitions are governed by synapses that have a time delay. The influence of a pre-synaptic neuron through these synapses will arrive later than the influence coming through a `stabilizing' synapse. The latter type of synapse arises because of the `stabilizing' term in the network model that ensures that if the network is in a state that is identical to a stored pattern then the network will remain there. The author shows how the network can use these delayed transitions to deal with temporal sequences in a manner that is acceptable, i.e. in a way that the `cognition time' is of the order of magnitude of the delay. The author discusses an example dealing with the counting of chimes, in order to give credence to his constructions.  In this example it is seen that the network resides in each of the quasi-attractors for a long enough time so as to allow the output neurons to identify the cognitive event.system.  <br /> <br />In order to build a credible model of the neuronal processes of the brain, the author is aware that such a model has to be able to deal with input in the form of temporal sequences, and not just single patterns. He devotes an entire chapter to this in the book, motivating his discussion with the notion of a `central pattern generator' (CPG). The simplicity of CPGs is a concern and the author is aware that such simplicity does not exist in models of cognitive processes. Nevertheless the modeling of CPGs using neural networks can add credence to the program to model general brain processes in terms of neural networks, complex as they can be.  <br /> <br />One of course must be able to deal with both the storage and the retrieval of temporal sequences. After discussing some of the early research dealing with these needs, the author then reviews a strategy for dealing with temporal sequences that involves the notion of a `quasi-attractor', which is a network state that acts like an attractor for a short period of time. Quasi-attractors are used to delay the transfer of information out of the attractor. Thus the transitions are governed by synapses that have a time delay. The influence of a pre-synaptic neuron through these synapses will arrive later than the influence coming through a `stabilizing' synapse. The latter type of synapse arises because of the `stabilizing' term in the network model that ensures that if the network is in a state that is identical to a stored pattern then the network will remain there. The author shows how the network can use these delayed transitions to deal with temporal sequences in a manner that is acceptable, i.e. in a way that the `cognition time' is of the order of magnitude of the delay. The author discusses an example dealing with the counting of chimes, in order to give credence to his constructions.  In this example it is seen that the network resides in each of the quasi-attractors for a long enough time so as to allow the output neurons to identify the cognitive event.	2005-10-03
31690:US	50702879	R9G72GEO1TJTQ	3540221395	205308814	Universal Artificial Intelligence: Sequential Decisions Based On Algorithmic Probability	Books	4	21	21	N	Y	Very ambitious project.	This book differs from most books on the theoretical formulations of artificial intelligence in that it attempts to give a more rigorous accounting of machine learning and to rank machines according to their intelligence. To accomplish this ranking, the author introduces a concept called `universal artificial intelligence,' which is constructed in the context of algorithmic information theory. In fact, the book could be considered to be a formulation of artificial intelligence from the standpoint of algorithmic information theory, and is strongly dependent on such notions as Kolmogorov complexity, the Solomonoff universal prior, Martin-Lof random sequences and Occam's razor. These are all straightforward mathematical concepts with which to work with, the only issue for researchers being their efficacy in giving a useful notion of machine intelligence.<br /><br />The author begins the book with a \\"short tour\\" of what will be discussed in the book, and this serves as helpful motivation for the reader. The reader is expected to have a background in algorithmic information theory, but the author does give a brief review of it in chapter two. In addition, a background in sequential decision theory and control theory would allow a deeper appreciation of the author's approach. In chapter four, he even gives a dictionary that maps concepts in artificial intelligence to those in control theory. For example, an `agent' in AI is a `controller' in control theory, a `belief state' in AI is an `information state' in control theory, and `temporal difference learning' in AI is `dynamic programming' or `value/policy iteration' in control theory. Most interestingly, this mapping illustrates the idea that notions of learning, exploration, adaptation, that one views as \\"intelligent\\" can be given interpretations that one does not normally view as intelligent. The re-interpretation of `intelligent' concepts as `unintelligent' ones is typical in the history of AI and is no doubt responsible for the belief that machine intelligence has not yet been achieved.<br /><br />The author's formulations are very dependent on the notion of Occam's razor with its emphasis on simple explanations. The measurement of complexity that is used in algorithmic information theory is that of Kolmogorov complexity, which one can use to measure the a prior plausibility of a particular string of symbols. The author though wants to use the `Solomonoff universal prior', which is defined as the probability that the output of a universal Turing machine starts with the string when presented with fair coin tosses on the input tape. As the author points out, this quantity is however not a probability measure, but only a `semimeasure', since it is not normalized to 1, but he shows how to bound it by expressions involving the Kolmogorov complexity.<br /><br />The author also makes use of the agent model, but where now the agent is assumed to be acting in a probabilistic environment, with which it is undergoing a series of cycles. In the k-th cycle, the agent performs an action, which then results in a perception, and the (k+1)-th cycle then begins. The goal of the agent is to maximize future rewards, which are provided by the environment. The author then studies the case where the probability distribution of the environment is known, in order to motivate the notion of a `universal algorithmic agent (AIXI).' This type of agent does not attempt to learn the true probability distribution of the environment, but instead replaces it by a generalized universal prior that converges to it. This prior is a generalization of the Solomonoff universal prior and involves taking a weighted sum over all environments (programs) that give a certain output given the history of a particular sequence presented to it. The AIXI system is uniquely defined by the universal prior and the relation specifying its outputs. The author is careful to point out that the output relation is dependent on the lifespanor initial horizon of the agent. Other than this dependence the AIXI machine is a system that does not have any adjustable parameters.<br /><br />The author's approach is very ambitious, for he attempts to define when an agent or machine could be considered to be `universally optimal.' Such a machine would be able to find the solution to any problem (with the assumption that it is indeed solvable) and be able to learn any task (with the assumption that it is learnable). The process or program by which the machine does this is `optimal' in the sense that no other program can solve or learn significantly faster than it can. The machine is `universal' in that it is independent of the true environment, and thus can function in any domain. This means that a universal optimal machine could perform financial time series prediction as well as discover and prove new results in mathematics, and do so better than any other machine. The notion of a universally optimal machine is useful in the author's view since it allows the construction of an `intelligence order relation' on the \\"policies\\" of a machine. A policy is thought of as a program that takes information and delivers it to the environment. A policy p is `more intelligent' than a policy p' if p delivers a higher expected reward than p'.<br /><br />The author is aware that his constructions need justification from current practices in AI if they are to be useful. He therefore gives several examples dealing with game playing, sequence prediction, function minimization, and reinforcement and supervised learning as evidence of the power of his approach. These examples are all interesting in the abstract, but if his approach is to be fruitful in practice it is imperative that he give explicit recommendations on how to construct a policy that would allow a machine to be as universal and optimal (realistically) as he defines it (formally) in the book. Even more problematic though would be the awesome task of checking (proving) whether a policy is indeed universally optimal. This might be even more difficult than the actual construction of the policy itself.the agent. Other than this dependence the AIXI machine is a system that does not have any adjustable parameters.     The author's approach is very ambitious, for he attempts to define when an agent or machine could be considered to be `universally optimal.' Such a machine would be able to find the solution to any problem (with the assumption that it is indeed solvable) and be able to learn any task (with the assumption that it is learnable). The process or program by which the machine does this is `optimal' in the sense that no other program can solve or learn significantly faster than it can. The machine is `universal' in that it is independent of the true environment, and thus can function in any domain. This means that a universal optimal machine could perform financial time series prediction as well as discover and prove new results in mathematics, and do so better than any other machine. The notion of a universally optimal machine is useful in the author's view since it allows the construction of an `intelligence order relation' on the \\"policies\\" of a machine. A policy is thought of as a program that takes information and delivers it to the environment. A policy p is `more intelligent' than a policy p' if p delivers a higher expected reward than p'.      The author is aware that his constructions need justification from current practices in AI if they are to be useful. He therefore gives several examples dealing with game playing, sequence prediction, function minimization, and reinforcement and supervised learning as evidence of the power of his approach. These examples are all interesting in the abstract, but if his approach is to be fruitful in practice it is imperative that he give explicit recommendations on how to construct a policy that would allow a machine to be as universal and optimal (realistically) as he defines it (formally) in the book. Even more problematic though would be the awesome task of checking (proving) whether a policy is indeed universally optimal. This might be even more difficult than the actual construction of the policy itself.	2005-09-26
35224:US	50702879	RN8ANMCK754YU	0393977773	103316649	Cognitive Neuroscience: The Biology of the Mind	Books	5	15	20	N	Y	Excellent	Research in cognitive neuroscience has exploded in the last two decades, mostly due to the rise of experimental techniques such as magnetic resonance imaging and positron emission topography, but also due to the ability now to simulate neuronal behavior computationally. This book, written by leading experts in the field is written for the student in mind, so anyone with a strong curiosity about what has been accomplished in cognitive neuroscience up till now will gain a lot from reading the book. The study of the brain is fascinating and there is every indication that a thorough understanding of cognitive processes, including the nature of consciousness, will be achieved in this century.<br /><br />Just a small sample of some of the questions that arise from the reading of the book include:<br /><br />1. What is the cause of akinetopsia, i.e. loss of motion perception?<br /><br />2. What is the relationship between learning and memory?<br /><br />3. How limited is short-term memory and where are sensory memories stored?<br /><br />4. Why were `working memory' models proposed and what evidence is there to support them?<br /><br />5. What is the difference between declarative and nondeclarative memories?<br /><br />6. What is the connection between amnesia and the medial temporal lobe?<br /><br />7. Just how accurate are the experimental techniques of PET and fMRI?<br /><br />8. Is damage to the hippocampus sufficient to block the formation of new long-term memories?<br /><br />9. Does damage to the medial temporal lobe and diencephalic memory systems affect both episodic and semantic memory?<br /><br />10. What brain systems support procedural memory?<br /><br />11. Is there any evidence that brain lesions can affect the perceptual representation system but leaving the declarative memory untouched?<br /><br />12. How much is known about the molecular mechanisms of synaptic strengthening in long-term potentiation?<br /><br />13. Just how much is known about the neural organization of language?<br /><br />14. What evidence is there for domain-specific knowledge systems that are evolutionarily adapted?<br /><br />15. What is the nature of the segmentation problem and what is its relevance in the neuronal modeling of language use and acquisition?<br /><br />16. Is reading represented by a specialized input system?<br /><br />17. What are the differences between the modular and interactive models of language comprehension?<br /><br />18. What evidence is there for the garden-path model of syntactic analysis?<br /><br />19. What is the nature of agrammatic aphasia and what causes it?<br /><br />20. What is semantic paraphasia what causes it?<br /><br />21. What is the nature of Broca's aphasia?<br /><br />22. What connection, if any, is there between the size of the corpus callosum and autism?<br /><br />23. Why, from an evolutionary perspective, is it advantageous to have hemispheric specialization?<br /><br />24. How does the frequency hypothesis explain hemispheric asymmetries in visual perception?<br /><br />25. How effective are the computational models of visual system?<br /><br />26. What experiments indicate that cortical cell number cannot by itself fully explain human intelligence?<br /><br />27. In contrast to nonhuman animals, why do humans try to find patterns in sequences of events, even though they are informed explicitly that the sequences are random?<br /><br />28. What evidence exists for a `generative assembling device' in the left hemisphere?<br /><br />29. How are movement plans represented?<br /><br />30. What is the function of \\"mirror cells?\\"<br /><br />31. To what degree does learning play in producing purposeful actions?<br /><br />32. Do representations within the motor cortex change as a function of practice?<br /><br />33. What is the timing hypothesis of the role of the cerebellum in motor learning?<br /><br />34. What causes Parkinson's disease?<br /><br />35. What are the executive functions?<br /><br/>36. What is the difference between working memory and associative memory?<br /><br />37. How is information activated and maintained in working memory?<br /><br />38. What is the nature of recency memory?<br /><br />39. What is the dynamic filtering mechanism and what experimental evidence is there to support it?<br /><br />40. What are schema control units and what role do they play in response selection?<br /><br />41. How can emotion be defined in order to carry out a neuroscientific science of emotion?<br /><br />42. What role does the amygdala play in the processing of emotional stimuli?<br /><br />43. Are the neural systems of emotion and cognition independent? Interdependent?<br /><br />44. What is a somatic marker and what role does it play in decision-making?<br /><br />45. What neural systems are responsible for controlling facial expressions?<br /><br />46. What is genetic specificity and genetic pleiotropy?<br /><br />47. How can one determine whether a neuronal structure or behavior is functionally significant to the organism in the environment to which is adapted or whether it is an epiphenomenon of evolution?<br /><br />48. What is the role, if any, of subconscious processing?<br /><br />49. What is the nature of access-consciousness?<br /><br />50. How close are neuroscientists to a science of consciousness?/>38. What is the nature of recency memory? <br />39. What is the dynamic filtering mechanism and what experimental evidence is there to support it?  <br />40. What are schema control units and what role do they play in response selection?  <br />41. How can emotion be defined in order to carry out a neuroscientific science of emotion? <br />42. What role does the amygdala play in the processing of emotional stimuli? <br />43. Are the neural systems of emotion and cognition independent? Interdependent?  <br />44. What is a somatic marker and what role does it play in decision-making? <br />45. What neural systems are responsible for controlling facial expressions?  <br />46. What is genetic specificity and genetic pleiotropy? <br />47. How can one determine whether a neuronal structure or behavior is functionally significant to the organism in the environment to which is adapted or whether it is an epiphenomenon of evolution?  <br />48. What is the role, if any, of subconscious processing?  <br />49. What is the nature of access-consciousness? <br />50. How close are neuroscientists to a science of consciousness?	2005-09-25
39439:US	50702879	R12BY4WWFQ0ATI	0670033847	72218650	The Singularity Is Near: When Humans Transcend Biology	Books	5	201	221	N	Y	Technophilic ecstacy	The author is definitely one of the most inspiring of all researchers in the field of applied artificial intelligence. For those, such as this reviewer, who are working \\"in the trenches\\" of applied AI, his website is better than morning coffee. One does not have to agree with all the conclusions reached by the author in order to enjoy this book, but he does make a good case, albeit somewhat qualitative, for the occurrence, in this century, of what he and other futurists have called a `technological singularity.' He defines this as a period in the future where the rate of technological change will be so high that human life will be `irreversibly transformed.' There is much debate about this notion in the popular literature on AI, but in scientific and academic circles it has been greeted with mixed reviews. Such skepticism in the latter is expected and justified, for scientists and academic researchers need more quantitative justification than is usually provided by the enthusiasts of the singularity, which in this book the author calls \\"singularitarians.\\" Even more interesting though is that the notion of rapid technological change seems to be ignored by the business community, who actually stand to gain (or lose) the most by it.<br /><br />Since this book is aimed primarily at a wide audience, and not professional researchers, the author does not include detailed arguments or definitions for the notion of machine intelligence or a list of the hundreds of examples of intelligent machines that are now working in the field. Indeed, if one were to include a discussion of each of these examples, this book would swell to thousands of pages. There are machines right now used in business and industry that can manage, troubleshoot, and analyze networks, diagnose illnesses, compose music definitely worth listening to, choreograph dances, simulate human behavior in computer games, recommend and engage in financial transactions and bargaining, and many, many other tasks, a detailed list of which would, again, entail many thousands of pages.<br /><br />There are various psychological issues that arise when discussing machine intelligence, which if believed might prohibit the acceptance of any kind of notion of a technological singularity. For example, it is one of the historical peculiarities of research in AI that advances in the field are later trivialized, i.e. when a problem in AI becomes solved it no longer holds any mystery and is then considered to be just another part of information processing. It is then no longer regarded as `intelligent' in any sense of the term.  This phenomenon in AI research might be called the \\"Michie-McCorduck-Hofstader effect\\", named after the three individuals, Donald Michie, Barbara McCorduck, and Douglas Hofstader, who discussed it some detail in their writings. If one examines the history of AI, one finds many examples of this effect, such as in knowledge discovery from databases, the use of business rules in database technologies, and the use of ontologies for information systems development. One of the best examples of this effect though is the backgammon player TD-Gammon, a highly sophisticated example of machine intelligence but which is now considered to be merely part of the \\"programmer's toolbox.\\" The Michie-McCorduck-Hofstader effect is important in discussing the notion of a technological singularity since if one does occur this effect would diminish one's ability to recognize it as being real. The author does not name this phenomenon as such in the book, but a reading of it definitely reveals that he is aware of the skepticism expressed by many towards any \\"advances\\" in machine intelligence.<br /><br />Another one of these psychological issues regards the attitude of many philosophers on the notion of machine intelligence. In most cases they are extremely skeptical, and many AI researchers seem to feel the need to \\"refute\\" their opinions on the \\"impossibility\\" of intelligent machines. Unfortunately the author is one of these, and devotes space in the book to counter various philosophical arguments against AI. His arguments, although valid, are really a waste of time though. Such time would be better spent, both for the author and for AI researchers, in the actual development of intelligent machines. A moratorium should be declared among AI researchers on all philosophical speculation. Such musings are best left to professional philosophers, who have the time and the inclination to indulge themselves in them.<br /><br />There are other issues that should have been given more attention in the book, such as more details on the energy requirements needed to bring about such a singularity. In addition, the author needs to sharpen just what he means by intelligence and move away from the Turing test/human brain benchmark that he uses in the book. There are many examples of intelligence in the natural world, and these can and have been emulated in many different types of machines. Interestingly, the fixation on human intelligence and the reverse engineering of the human brain (that is exemplified in this book) has inspired a few research teams to attempt to build a machine of \\"general intelligence\\", i.e. one that can think in many different domains, as clearly humans can. But it is still an open question whether this intelligence is \\"entangled\\" over these domains, i.e. whether or not a decrease in ability in one domain will affect the ability in another. From an evolutionary or efficiency standpoint it would seem that that domain specific intelligence is more optimal.<br /><br />The notion of a technological singularity can be met with both exhilaration and a sense of foreboding, since (radical) change can be embraced with enthusiasm and with some feelings of anxiety. Even the author expresses this when he writes in the book that he is not \\"entirely comfortable\\" with all the consequences of a technological singularity. He has though made a fairly strong case for rapidly accelerating change. If the book concentrated more on the actual examples of intelligent machines and included the enormous amount of data from activities in applied AI that are now going on, an even stronger case could be made.s. Unfortunately the author is one of these, and devotes space in the book to counter various philosophical arguments against AI. His arguments, although valid, are really a waste of time though. Such time would be better spent, both for the author and for AI researchers, in the actual development of intelligent machines. A moratorium should be declared among AI researchers on all philosophical speculation. Such musings are best left to professional philosophers, who have the time and the inclination to indulge themselves in them.  <br /> <br />There are other issues that should have been given more attention in the book, such as more details on the energy requirements needed to bring about such a singularity. In addition, the author needs to sharpen just what he means by intelligence and move away from the Turing test/human brain benchmark that he uses in the book. There are many examples of intelligence in the natural world, and these can and have been emulated in many different types of machines. Interestingly, the fixation on human intelligence and the reverse engineering of the human brain (that is exemplified in this book) has inspired a few research teams to attempt to build a machine of \\"general intelligence\\", i.e. one that can think in many different domains, as clearly humans can. But it is still an open question whether this intelligence is \\"entangled\\" over these domains, i.e. whether or not a decrease in ability in one domain will affect the ability in another. From an evolutionary or efficiency standpoint it would seem that that domain specific intelligence is more optimal.  <br /> <br />The notion of a technological singularity can be met with both exhilaration and a sense of foreboding, since (radical) change can be embraced with enthusiasm and with some feelings of anxiety. Even the author expresses this when he writes in the book that he is not \\"entirely comfortable\\" with all the consequences of a technological singularity. He has though made a fairly strong case for rapidly accelerating change. If the book concentrated more on the actual examples of intelligent machines and included the enormous amount of data from activities in applied AI that are now going on, an even stronger case could be made.  <br /> <br />	2005-09-22
48797:US	50702879	R1R8KCF4X17GZ1	0618405682	769724160	The Singing Life of Birds: The Art and Science of Listening to Birdsong	Books	5	48	64	N	Y	Exceptional	There is not one page in this book that is not interesting, and along with the CD that accompanies the book, the reader will be exposed to an incredible amount of information, resulting from years of fieldwork on the part of the author. Even the reader who is not an active birder will, after finishing the book, be left with a deep appreciation of the singing abilities of songbirds. Many, many questions arise from the reading of the book, some of these being:<br /><br />1. Why do some songbirds, such as the whip-poor-will, the catbird, and thrasher have thousands of songs in their repertoire and sing them almost unceasingly, when such a strategy might result in them not been appreciated by their listeners?<br />2. Is there ample empirical evidence that will support the notion that the speed of singing increases as the number of different songs increases?<br />3. Do birds that sing with a great variety in their songs sing more continuously and vice versa?<br />4. How does one characterize a bird song, i.e. how for example does one define when a song starts and when it ends?<br />5. The male whip-poor-will has been documented by the author as being able to sing as many as 2, 590 songs (all the songs the same) per hour. What kind of food consumption is necessary on the part of this bird to give him the energy needs for this rate of singing? And is this singing rate optimal, i.e. what is the maximum rate of singing that this bird can perform? And is there a genetic advantage in such a high singing rate? Do female whip-poor-wills really listen attentively to the quality of each song, to see how perfectly each one is, as the author speculates in the book?<br />6. It is readily apparent when reading the book that the hours of dawn are the most optimal when listening to bird song. Why do birds choose these hours, instead of for example, the hours of dusk, to sing?<br />7. For a given species of bird, how much variability is there in the selection of songs from morning to morning?<br />8. What is the ratio between birdsongs who learn their songs from their parents and those who have their songs \\"wired into their genes\\"?<br />9. What dependence on age is there in the selection of songs for a given species of songbird?<br />10. For a given species of songbird, how much variability is there in the selection of songs for different phases of the breeding cycle?<br />11. For a given species of songbird, how much variability is there in the selection of songs for different geographical locales that the bird resides in?<br />12. What is the longest recorded song and which bird sings it?<br />13. What is the most complex song ever recorded and which bird sings it?<br />14. For a given species of songbird, how do the songs of the female compare with those of the male? Are they more complex or less? Are they longer or shorter? Are they more delightful to listen to? Why does the female sing? How does the female distinguish a song from a male member of her species if there are many songs being sung simultaneously by other males of many different species?<br />15. How does the songbird vocal anatomy vary among songbirds?<br />16. Mockingbirds can mimic the songs of other birds, as is well documented in this book. Should this mimicry be considered \\"learning\\"?<br />17. If a male songbird is singing to attract mates, is he singing to capture the attention of a particular female or is he engaging in \\"multicasting\\", i.e. seeking to attract the attention of any female in the given locale?<br />18. Do male songbirds try to compete with other male songbirds by singing songs that are qualitatively better, i.e. give more pleasure, to the female songbird who is listening to them?<br />19. The author has reported that the male Carolina wren has large groups of specialized \\"song-learning\\" neurons in its forebrain, resulting in a extremely large repertoire of songs. Is brain size of songbirds correlated positively with the size of the song repertoire?<br />20. What is the difference between \\"singing\\" and \\"calling\\"?<br />21. Do mockingbirds copy songs with high fidelity? How effective is their process of duplication?<br />22. What species of songbirds are able to respond to songs that they do not share among themselves?<br />23. Can any songbirds be made to learn songs that are designed/composed by the human ornithologist?<br />24. Why do some species of songbirds learn their songs while others do not? Is there an evolutionary advantage in learning songs?<br />25. Is there evidence from the fossil record that some species of bird existing today used to be songbirds in the past and vice versa?<br />26. Are there different dialects of song in a particular species of songbird? How do these dialects very with the geographical locales that the songbirds inhabit? If there are different dialects in the species, can a songbird using one dialect learn the dialect of another? Could they learn perhaps a \\"hybrid\\" dialect?<br />27. If male songbirds learn only the songs of their fathers, how would this affect the genetic diversity of these songbirds? Would it increase or decrease it?<br />28. If the song repertoires of a particular species of songbird change in evolutionary time, how fast do they change? Is there a correlation between environmental changes and changes in song repertoires?<br />29. As reported by the author, some species of songbird songs with their neighbors (of the same species). What advantages does this confer on the songbird?<br />30. Can the listening of songbirds shed any light on the status of their health? To what extent do viral infections for example, affect the quality of their songs? Could one diagnose a malady in a songbird by listening to its song?ngbirds copy songs with high fidelity? How effective is their process of duplication?   22. What species of songbirds are able to respond to songs that they do not share among themselves?   23. Can any songbirds be made to learn songs that are designed/composed by the human ornithologist?   24. Why do some species of songbirds learn their songs while others do not? Is there an evolutionary advantage in learning songs?   25. Is there evidence from the fossil record that some species of bird existing today used to be songbirds in the past and vice versa?   26. Are there different dialects of song in a particular species of songbird? How do these dialects very with the geographical locales that the songbirds inhabit? If there are different dialects in the species, can a songbird using one dialect learn the dialect of another? Could they learn perhaps a \\"hybrid\\" dialect?  27. If male songbirds learn only the songs of their fathers, how would this affect the genetic diversity of these songbirds? Would it increase or decrease it?   28. If the song repertoires of a particular species of songbird change in evolutionary time, how fast do they change? Is there a correlation between environmental changes and changes in song repertoires?  29. As reported by the author, some species of songbird songs with their neighbors (of the same species). What advantages does this confer on the songbird?   30. Can the listening of songbirds shed any light on the status of their health? To what extent do viral infections for example, affect the quality of their songs? Could one diagnose a malady in a songbird by listening to its song?	2005-09-17
50307:US	50702879	R3HLC67VRRYEG3	1584885181	146869396	Handbook of Elliptic and Hyperelliptic Curve Cryptography (Discrete Mathematics and Its Applications)	Books	5	8	8	N	N	Very understandable overview of modern developments	Elliptic curve cryptography is now an entrenched field and has been subjected to an enormous amount of research in the last fifteen years. As soon as encryption schemes based on arithmetic in elliptic curves were proposed, it was natural to speculate on whether these schemes could be generalized to hyperelliptic curves or even general abelian varieties. This book gives an overview of what has been done, and even though most of the proofs are omitted, it does serve a need for those interested in the latest developments in the subject. This reviewer did not read the entire book, but concentrated instead on only a few parts that discussed developments in the last few years. Just skimming the book though will reveal that the authors have been very thorough in giving the reader the necessary mathematical background for a study of ECC and HECC cryptography. Readers needing more detailed background can consult the many references.<br /><br />As expected, a substantial portion of the book is devoted to point counting methods. One of the methods discussed is the p-adic approach to counting the number of points on an elliptic curve over a field with a small characteristic, with the three most practical ones given the most attention. One of these, the Satoh algorithm, first computes the p-adic approximation of the canonical lift of an elliptic curve E over a finite field F(q), where q = p^d and p is a small prime. This involves lifting the j-invariants using a multivariate version of Newton's root finding algorithm. The trace of the Frobenius endomorphism must then be recovered, and this is done by using the action of the lift on a holomorphic differential on the lift. The resulting factoring problems are formidable, so instead the q-th Verschiebung, which is the dual isogeny to the Frobenius endomorphism is used. The Verschiebung is a separable morphism and the trace of an endomorphism is the trace of its dual. These facts are used to express the trace of the Frobenius endomorphism as a product (modulo q) of coefficients in Z(q). These coefficients are then calculated using certain polynomials.<br /><br />Another algorithm using the p-adic approach to counting is the Arithmetic-Geometric-Mean (AGM) algorithm, which is discussed for the 2-adic case.  As the name implies, this method is based on the AGM iteration, wherein a sequence of elliptic curves is constructed all of which are 2-isogenous to each other. This sequence is constructed so that it converges to the canonical lift of an ordinary elliptic curve, and then an explicit formula for the trace of the Frobenius map is derived. It is then shown how to extend the AGM algorithm to hyperelliptic curves by interpreting it as a special case of the Riemann duplication formula for theta functions.<br /><br />The third p-adic algorithm discussed is called the Kedlaya algorithm and involves working with the affine curve associated to a hyperelliptic curve of genus g. Associated with this affine curve is its `dagger algebra,' the latter of which is discussed in the book and has its origins in the Monsky-Washnitzer cohomology for nonsingular affine curves over a finite field. This cohomology, which is currently listed under the classification of `rigid cohomology' is a cohomology for algebraic fields over fields of nonzero characteristic and can be considered to be a version of de Rham cohomology (in positive characteristic). In arises when one attempts to lift the Frobenius endomorphism on the coordinate ring of the curve to the coordinate ring of a lift of the curve. Taking the p-adic completion of the coordinate ring of the lift results in a de Rham cohomology which is even larger than the coordinate ring (the limit of exact differentials may not be exact), and so one works with a subring of the completion, which is called the `dagger ring.' The Frobenius endomorphism on the coordinate ring can then be lifted to a (Z(q)) endomorphism on the dagger ring. One can then define differentials ofelements in the dagger ring, yielding a module over the dagger ring. The kernel and cokernel of this differential map can then be used to construct the zeroth and first Monsky-Washnitzer cohomology groups. The lift of the Frobenius endomorphism to the dagger ring induces an endomorphism on the cohomology groups, and this allows a Lefschetz fixed point formula to be proved, thus giving the number of rational points on the curve. The Kedlaya algorithm essentially follows this approach to do the point counting, but outputting the zeta function and working only for p greater than or equal to 3.<br /><br />The book is not just a discussion on theoretical developments and computational algorithms, as an entire part of the book is devoted to applications. One of the applications discussed is that of `smart cards' which to date have been one of most widely used applications of cryptography. An entire chapter is spent on the hardware of smart cards, followed by one on how to attack the implementations of cryptosystems. One particular method for extracting the keys from inside a tamper-proof device involves the use of `power consumption analysis,' which is discussed in some detail in this chapter. The power consumption curve of the device or smart card is analyzed by the attacker, and this, coupled with an understanding of cryptographic algorithms, allows the keys to be compromised. Countermeasures against these attacks are discussed in the next chapter. The discussion is general enough in these chapters to give the motivated reader enough information to experiment with both attacking and with designing and testing effective countermeasures.ntials of elements in the dagger ring, yielding a module over the dagger ring. The kernel and cokernel of this differential map can then be used to construct the zeroth and first Monsky-Washnitzer cohomology groups. The lift of the Frobenius endomorphism to the dagger ring induces an endomorphism on the cohomology groups, and this allows a Lefschetz fixed point formula to be proved, thus giving the number of rational points on the curve. The Kedlaya algorithm essentially follows this approach to do the point counting, but outputting the zeta function and working only for p greater than or equal to 3.  <br /> <br />The book is not just a discussion on theoretical developments and computational algorithms, as an entire part of the book is devoted to applications. One of the applications discussed is that of `smart cards' which to date have been one of most widely used applications of cryptography. An entire chapter is spent on the hardware of smart cards, followed by one on how to attack the implementations of cryptosystems. One particular method for extracting the keys from inside a tamper-proof device involves the use of `power consumption analysis,' which is discussed in some detail in this chapter. The power consumption curve of the device or smart card is analyzed by the attacker, and this, coupled with an understanding of cryptographic algorithms, allows the keys to be compromised. Countermeasures against these attacks are discussed in the next chapter. The discussion is general enough in these chapters to give the motivated reader enough information to experiment with both attacking and with designing and testing effective countermeasures.	2005-09-16
59964:US	50702879	R25MPFA30MFP2J	3540226141	630892778	Complex Manifolds and Deformation of Complex Structures (Classics in Mathematics)	Books	5	14	16	N	N	Superb	Of importance to applications such as superstring theories in high-energy physics, the theory of complex manifolds and the deformation of complex structures are explained in great detail in this book by one of the major contributors to the subject. One of the valuable features of the book that is actually rare in more recent books on mathematics is that the author tries (and succeeds) to give motivation for the subject. This feature is actually quite common in older books on mathematics, for with few exceptions writers at that time believed that a proper understanding of mathematics can only come with explanations that are given outside the deductive structures that are created in the process of doing mathematics. These explanations frequently involve the use of diagrams, pictures, intuitive arguments, and historical analogies, and so are not held to be rigorous from a mathematical standpoint. They are however extremely valuable to students of mathematics and those who are interested in applying it, like physicists and engineers. There seems to be an inverse relationship between rigor and understanding of mathematics, and given the emphasis on the former in modern works of mathematics, one can expect students to have more trouble learning a particular branch of mathematics than those students of a few decades ago.<br /><br />Luckily though the author of this book has given the reader valuable insights into the nature of complex manifolds and what is means to deform a complex structure. Complex manifolds are different from real manifolds due to the notion of holomorphicity, but are similar in the sense that they are constructed from domains that are \\"glued together\\". In complex manifolds, the \\"glue\\" is provided by biholomorphic maps between the domains, the latter of which are open sets called `polydisks'. A `deformation' of the complex manifold is then considered to be a glueing of the same polydisks but via a different identification. For an n-dimensional complex manifold, the maps could thus be dependent on say m parameters, which are labeled as \\"t\\" by the author. This dependence on t would result in a differentiable family of complex manifolds. One thus expects the complex manifold to be dependent on t, but the author discusses a counterexample that indicates that one must not be cavalier about this approach.<br /><br />The definition that is arrived at involves letting t be an element of a domain B in m-dimensional Euclidean space, and considering a collection of compact complex n-dimensional manifolds that depends on t. This collection will be a `differentiable family' if: 1. There exists a differentiable manifold M and a C-infinity map W from M onto B such that the rank of the Jacobian matrix of W is equal to m at every point of M. 2. M(t), the inverse image of t under W is a compact connected subset of M, and in fact is equal to a member of the collection. 3. M has a locally finite open covering along with smooth coordinate functions on the covering that have non-empty intersection with each member of the covering. Beginning with an initial element of B, each member of the inverse image of t under W is viewed as a deformation of the initial member. The crucial point made by the author is that the restricting the domain of the parameter t to a sufficiently small interval allows the representation of the member M(t) as a union of polydisks that are independent of t. Therefore only the coordinate transformations depend on t, and thus only the way of glueing the polydisks depends on t.<br /><br />To show that these constructions are meaningful, namely that the complex structure of M(t) actually depends on t, the author studies the case of m = 1. In the process he constructs the infinitesimal deformation of M(t), and interprets it as the derivative of the complex structure of M(t) with respect to t. He also shows that the infinitesimal deformation does not depend on the choice of systems of local coordinates, and that the infinitesimal deformation vanishes when M(t) does not vary with t. The author then defines, using a notion of equivalence between two differentiable families, a differentiable family (M, B, W) to be `trivial' if it is equivalent to a product (M x B, B, P). Restricting this triviality to a subdomain gives a notion of `local triviality', which implies immediately that each M(t) will be biholomorphically equivalent to a fixed M. He then shows that if the infinitesimal deformation vanishes then the differentiable family is locally trivial. A more substantial statement of this result is encapsulated in the Frolicher-Nijenhuis theorem, which follows from the results that the author proves in the book. These results involve the theory of strongly elliptic differential operators and considerations of the first cohomology group of M(t) with coefficients in the sheaf of germs of holomorphic vector fields over M(t).<br /><br />The case of a complex analytic family of compact complex manifolds entails that B will be domain in complex n-space. The author shows that a complex analytic family will be trivial if it is trivial as a differentiable family. As expected, because of the nature of analyticity learned from the theory of complex variables, the proof of these results involves the theory of harmonic differential forms. The author gives these proofs in detail in the book. He also considers the question whether if given an element b of the first cohomology group of a compact complex manifold Mwith coefficients in the sheaf of germs of holomorphic vector fields over M, one can find a complex analytic family that takes M as its initial element and the derivative equal to b. This question, as expected, involves the use of obstruction theory, which the author develops in great detail. In these considerations, the reader will see the and origin and role of the moduli of complex structures. These are essentially the number of parameters m, as long as the complex analytic family is `complete.'at the infinitesimal deformation vanishes when M(t) does not vary with t. The author then defines, using a notion of equivalence between two differentiable families, a differentiable family (M, B, W) to be `trivial' if it is equivalent to a product (M x B, B, P). Restricting this triviality to a subdomain gives a notion of `local triviality', which implies immediately that each M(t) will be biholomorphically equivalent to a fixed M. He then shows that if the infinitesimal deformation vanishes then the differentiable family is locally trivial. A more substantial statement of this result is encapsulated in the Frolicher-Nijenhuis theorem, which follows from the results that the author proves in the book. These results involve the theory of strongly elliptic differential operators and considerations of the first cohomology group of M(t) with coefficients in the sheaf of germs of holomorphic vector fields over M(t).  <br /> <br />The case of a complex analytic family of compact complex manifolds entails that B will be domain in complex n-space. The author shows that a complex analytic family will be trivial if it is trivial as a differentiable family. As expected, because of the nature of analyticity learned from the theory of complex variables, the proof of these results involves the theory of harmonic differential forms. The author gives these proofs in detail in the book. He also considers the question whether if given an element b of the first cohomology group of a compact complex manifold Mwith coefficients in the sheaf of germs of holomorphic vector fields over M, one can find a complex analytic family that takes M as its initial element and the derivative equal to b. This question, as expected, involves the use of obstruction theory, which the author develops in great detail. In these considerations, the reader will see the and origin and role of the moduli of complex structures. These are essentially the number of parameters m, as long as the complex analytic family is `complete.'	2005-09-12
62665:US	50702879	R3N2OO6RUHAW1F	1560257164	911325333	The Iranian Labyrinth: Journeys Through Theocratic Iran and Its Furies	Books	4	15	15	N	Y	Very helpful	It can now be taken as an axiom that the Western press cannot be trusted to report honestly the events of the Middle East as they are occurring and how they have occurred in the past. Journalism has been morphed into a game of politics and self-aggrandizement on the part of journalists. The study of history has been exposed as a game of promoting a particular worldview, and historians have exhibited an extreme bias that is sometimes admitted but frequently is not. For these reasons the study of historical events has taken on particular importance at the present time. Those who sincerely desire an accounting of history in most cases must undertake the study themselves. In addition, the prevailing political climate dictates that an accurate picture of history be available, in order to not be subjected to the mental tyranny of propaganda. Every citizen must now become a historian, and must practice extreme skepticism towards any assertions that are put into print that claim to be accurate appraisals of past events. Documents and sources must be checked meticulously, and no apologies must be given if research indicates that historical events do not conform to prevailing ideologies.<br /><br />This book, written by one of those who have been \\"on the ground\\" in the Middle East, attempts to give an overview of the history of Iran in the twentieth century. The accounting that he gives sounds plausible, and as a whole the book seems to be free of any extreme bias or hidden political agendas. However, it should be remembered that the author has viewed the Middle East through finite time windows, and therefore his appraisal of the events he has observed may not reflect the true situation. The fact that the book must be kept at a manageable length for publication also dictates that the author must employ selective filters on the history he is attempting to analyze. The author though gives many references for those readers who want to pursue further studies on the history of Iran. In view of the current tensions between Iran and the United States, it is imperative that an understanding of this tension be put into proper historical context. Some in the United States government have called for war against Iran. To find out whether such a war is justified entails that a thorough understanding of Iranian history be obtained.<br /><br />Some of the many historical topics that the author discusses in the book include:<br /><br />1. The reasons for the invasion of Iran by Iraq in September 1980.<br /><br />2. The origin and functioning of the Islamic Majlis.<br /><br />3. The White Revolution, initiated by Shah Pahlavi, in 1963. This consisted of a \\"six-point\\" program involving agrarian reform, the nationalization of the forests, the sale of public factories to compensate landlords, suffrage for women, profit-sharing in industry, and the eradication of illiteracy.<br /><br />4. The overthrow of the Mussadiq government by the CIA in 1953. This was the beginning of the heavy influence and manipulation of the United States into the affairs of Iran. The author reports that U.S. military and economic aid from the years 1953 - 1956 totaled $414, 000, 000. In addition, he reports that thousands of Americans moved to Iran during this time, which caused further alienation of the Iranian populace.<br /><br />5. The life history of Muhammad Mussadiq al Saltane and his rise to the leadership of Iran in 1949.<br /><br />6. The nationalization of the oil industry in 1950. The Anglo-Iranian Oil Company was nationalized, resulting in the CIA-sponsored coup against the Mussadiq government.<br /><br />7. The history of the Reza Shah regime from 1925 - 1941.<br /><br />8. The history of the Muhammad Reza Shah regime from 1941 - 1979. After installed by the CIA in 1953, the author reports that the Shah's persecution against the opposition resulted in the deaths of 5.000 Iranians as well as the exile of 50,000. The author discusses the formation of the Sazman-e Aminyat Va Ettilaat-e Keshavar (Organization of National Security and Intelligence) or Savak. The Savak organization was discussed by some members of the Western press as being one of the reasons for the overthrow of the Shah in 1979, due to its atrocious conduct towards many Iranian citizens. The author reports that Savak maintained strong ties to the CIA as well as to the Israeli foreign intelligence agency. The author also reports that Savak agents engaged in the deliberate attack against religious seminaries, resulting in the deaths of hundreds of people. The Shah also engaged in poll rigging and persecution of political opponents. One of those undergoing persecution and arrest was the Ayatollah Khomeini. The Shah had absolutely no qualms about using the military to suppress uprisings, with as many as ten thousand people reportedly being killed in the Tehran Grand Bazaar in what has been called the Khordad 15 Uprising.<br /><br />9. The life and history of Ayatollah Ruhollah Khomeini. The author gives an interesting and detailed description, and the reader obtains insight into the religious views of Khomeini. Particularly interesting is his belief in an ethics that is not rule-based, i.e. not a prescriptive \\"do and don't\\" ethics for believers. The goal of all believers must instead be to oust corrupt officials and eliminate repressive regimes, and then replace them with ones that are ruled by just Islamic jurists. Once obtaining power in 1979, Khomeini unfortunately did not hesitate to use it to eliminate rivals, thus proving himself to be the moral equivalent of the man he replaced.havar (Organization of National Security and Intelligence) or Savak. The Savak organization was discussed by some members of the Western press as being one of the reasons for the overthrow of the Shah in 1979, due to its atrocious conduct towards many Iranian citizens. The author reports that Savak maintained strong ties to the CIA as well as to the Israeli foreign intelligence agency. The author also reports that Savak agents engaged in the deliberate attack against religious seminaries, resulting in the deaths of hundreds of people. The Shah also engaged in poll rigging and persecution of political opponents. One of those undergoing persecution and arrest was the Ayatollah Khomeini. The Shah had absolutely no qualms about using the military to suppress uprisings, with as many as ten thousand people reportedly being killed in the Tehran Grand Bazaar in what has been called the Khordad 15 Uprising.  <br />9. The life and history of Ayatollah Ruhollah Khomeini. The author gives an interesting and detailed description, and the reader obtains insight into the religious views of Khomeini. Particularly interesting is his belief in an ethics that is not rule-based, i.e. not a prescriptive \\"do and don't\\" ethics for believers. The goal of all believers must instead be to oust corrupt officials and eliminate repressive regimes, and then replace them with ones that are ruled by just Islamic jurists. Once obtaining power in 1979, Khomeini unfortunately did not hesitate to use it to eliminate rivals, thus proving himself to be the moral equivalent of the man he replaced.	2005-09-10
73889:US	50702879	R3VV57HAVYFK04	0674708768	718836998	The Problems of Jurisprudence	Books	5	19	23	N	Y	An excellent overview	For newcomers to the philosophy of law and for anyone interested in legal reasoning and the difficult problems of jurisprudence, this book gives an excellent overview. The author discusses the history of the subject as well as giving a thorough discussion of modern developments. In addition, many references are given for readers who want to investigate the subject in more detail. The philosophy of law has become even more important in recent years due to the social tensions surrounding the Supreme Court of the United States as well as the difficult legal issues involved in nation building.<br /><br />The following questions, among many others, arose for this reviewer when reading the book, with some of them being answered in the book and some not:<br /><br />1. What is the difference, if any, between standards and rules?<br /><br />2. What is the difference, if any, between substantive justice and formal justice?<br /><br />3. Does the granting of broad discretionary powers to legal officials encourage abuse?<br /><br />4. When a legal rule ages, does it become less or more applicable to the activities it is supposed to refer to, i.e. will judges become more tempted to declare exceptions and extensions to it?<br /><br />5. How important is the use of formal logic in legal deliberations?<br /><br />6. Can most, or even all, legal argumentation/deliberation be given an algorithmic or formulaic definition?<br /><br />7. Can statutes or constitutions, being forms of communication, be verified in the same way as scientific hypotheses can?<br /><br />8. Does good legal judgment consist of caution, detachment, imagination, and common sense or must these be supplemented by other activities or modes of cognition?<br /><br />9. Is law an autonomous discipline, with the designation \\"autonomous\\" given its usual intuitive meaning?<br /><br />10. Can the complexity of legal deliberations/reasoning of a judge be modeled successfully using a language or framework that is clearly not being used by that judge?<br /><br />11. Is the \\"test of time\\" a legitimate criterion for accepting certain legal practices?<br /><br />12. What is the role of metaphors in legal reasoning?<br /><br />13. What is the role of defeasible reasoning in legal deliberation/argumentation?<br /><br />14. Are legal deliberations always inconclusive?<br /><br />15. Is there any need, from the standpoint of rational legal deliberations, for the \\"trappings of the judicial process,\\" i.e. the elaborate courtrooms with elevated benches and compelled etiquette on the part of the observers and litigants?<br /><br />16. Is criminal law dependent on the notion of free will?<br /><br />17. Assuming that certainty is unattainable in most legal deliberations, what is the role of probability theory in these deliberations?<br /><br />18. Is the interpretation of legal texts deductive, and if not, what does it mean to interpret a legal text?<br /><br />19. What is the difference between common law and statutory law?<br /><br />20. Does agreement on the meaning of legal texts depend ultimately on the use of force?<br /><br />21. How does one characterize an activist judge from a non-activist one?<br /><br />22. When a legal text or document is examined, is it always important to acknowledged the intent of the individual(s) who wrote it?<br /><br />23. Can interpretations of legal documents ever be politically neutral?<br /><br />24. Can a legal system be constructed that would be free of errors?<br /><br />25. How influential has feminist thought been in the philosophy of law in the last few decades?<br /><br />26. What is the nature of \\"prudentialism\\" that is advocated by the author of the book?/>11. Is the \\"test of time\\" a legitimate criterion for accepting certain legal practices?  <br />12. What is the role of metaphors in legal reasoning?  <br />13. What is the role of defeasible reasoning in legal deliberation/argumentation?  <br />14. Are legal deliberations always inconclusive?  <br />15. Is there any need, from the standpoint of rational legal deliberations, for the \\"trappings of the judicial process,\\" i.e. the elaborate courtrooms with elevated benches and compelled etiquette on the part of the observers and litigants?  <br />16. Is criminal law dependent on the notion of free will?  <br />17. Assuming that certainty is unattainable in most legal deliberations, what is the role of probability theory in these deliberations?  <br />18. Is the interpretation of legal texts deductive, and if not, what does it mean to interpret a legal text?  <br />19. What is the difference between common law and statutory law?  <br />20. Does agreement on the meaning of legal texts depend ultimately on the use of force?  <br />21. How does one characterize an activist judge from a non-activist one?  <br />22. When a legal text or document is examined, is it always important to acknowledged the intent of the individual(s) who wrote it?  <br />23. Can interpretations of legal documents ever be politically neutral?  <br />24. Can a legal system be constructed that would be free of errors?  <br />25. How influential has feminist thought been in the philosophy of law in the last few decades?  <br />26. What is the nature of \\"prudentialism\\" that is advocated by the author of the book?	2005-09-05
74805:US	50702879	R20826VRGUIA6M	0262072203	216526732	The Mind's Arrows: Bayes Nets and Graphical Causal Models in Psychology	Books	4	18	18	N	Y	An interesting and important overview of Bayesian belief networks	This book could be considered to be a non-mathematical introduction to Bayesian networks, as applied to the field of cognitive psychology. It is readily apparent that the author does not believe that traditional statistical methods, such as factor and regression analysis, are unsuitable tools for the study of how the human mind gains an understanding and knowledge of the causal structure of the world. Bayesian networks are thus brought in to replace these methods.<br /><br />The author begins the book by distinguishing between `graphical causal structures,' which include structures with feedback, from `causal Bayes nets', which do not. He concentrates on the latter in the book, believing that they have great utility in psychological theory, namely in studies of adult judgment, psychometrics, cognitive neuropsychology, and in developmental and social psychology. In particular, causal Bayes nets can be used to successfully model the 'theory theory' which was developed to understand how cognition develops in infants and children. Children are of course able to learn the causal structure of the world, and this ability can be captured by the use of causal Bayes nets. In the context of developmental psychology, the emphasis in the book is on how children obtain the ability to predict and control their environment, and not on how they obtain the ability to generate explicit causal explanations.<br /><br />The author gives a brief history of cognitive psychology in order to motivate the ideas in the book. The discussion is intriguing, for it sheds light on the attitudes, biases, and the frequent extreme pessimism of practitioners in the field. Some cognitive psychologists for example held to the belief that humans are unable to conform to moral or rational standards, and that even if they are able to do this in some contexts or circumstances, a change in these circumstances will suppress this conformity. Science, the ultimate in rational endeavor, is in this view an \\"unstable oddity\\" that can only be sustained if sophisticated structures of social interaction are constructed.<br /><br />The author though has a realistic assessment of practice, and points to the \\"child scientist\\" as being one that has a genuine desire for the understanding and control of the environment, is not worried about competition for jobs or tenure, and thus is not unduly biased by the need for them. The \\"child scientist\\" is to be distinguished from the \\"adult scientist,\\" the latter of which is distracted by societal issues that force them out of their rational equilibrium.<br /><br />Most interesting, because the author is a professional philosopher, is his statement that twentieth-century philosophy does not seem to permit any concept of the logic of discovery. Scientific inquiry or investigation, hypothesis testing, etc, cannot be described algorithmically. The author though describes these views as being \\"quaint,\\" and offers as proof the progress that has been made in machine learning. The study of machines or 'computational systems' that can gain knowledge of the world via its sensory inputs and 'primitive abilities' is what the author has designated as 'android epistemology.' The author characterizes 'android epistemology' as being the most ambitious project of all in artificial intelligence. What he does not mention though is that major progress has been made in this project in the last decade. Along these same lines, a newcomer to artificial intelligence will hear mention of the 'frame problem,' which involves the need for the specification of not only what changes but also what does not change under a particular action. The frame problem has been the subject of considerable debate in the artificial intelligence community, and is also an issue in the developmental psychology of infants and children.<br /><br />The construction of a causal Bayes net uses the causal Markov assumption and the notion of an acyclic directed graph. The author views causes, effects, etc. in terms of concepts: The concept of the causes of a feature or collection of features; the concept of the effects of a feature or collection of features, and most importantly causes are to be distinguished from covariates. To reduce computational complexity, edges can be reduced or connections with low probability can be eliminated. Variables with a common effect can be collapsed, as well as causes with distinct effects. Features that are mutually exclusive can be represented by an abstract variable. Variables that are intermediate between other variables can be deleted if adjustments are made, and variables can be refined and coarsened if needed. Prior knowledge can be used or omitted if desired.<br /><br />A sizable portion of the book is devoted to the discussion of the efficacy of human judgment in causation. The author discusses experiments that test this efficacy, and how the data is interpreted with respect to the Rescorla-Wagner model. This model has dominated psychological theories of human and animal learning for many years, but the author discusses an example that indicates problems with this model. This is followed by a discussion of the Cheng model of human judgment of generative causal power. The Cheng model can be expressed as a Bayes net, and the author gives detailed discussion on just how effective this representation can be.<br /><br />The most interesting chapter of the book concerns the use of neural networks to study the effects of brain lesions. A baseline neural network is constructed that is supposed to emulate the normal capacity of the brain. This network is then altered in order to model the functioning of a damaged brain. This strategy is particularly interesting, and very important considering the enormous efforts that are currently being made to connect experimental data to neural network architectures. The author quotes theorems that indicate that the transmission functions of the neural network are really arbitrary as far as the independence properties of the network are concerned. The \\"lesioning\\" of the neural network cannot eliminate any of these independencies. These results, which seem to cast doubt on the strategy of using lesioning, do not negate the use of Bayesian neural networks to study brain lesions. These theorems do not invalidate the use of Bayesian neural networks.ects, etc. in terms of concepts: The concept of the causes of a feature or collection of features; the concept of the effects of a feature or collection of features, and most importantly causes are to be distinguished from covariates. To reduce computational complexity, edges can be reduced or connections with low probability can be eliminated. Variables with a common effect can be collapsed, as well as causes with distinct effects. Features that are mutually exclusive can be represented by an abstract variable. Variables that are intermediate between other variables can be deleted if adjustments are made, and variables can be refined and coarsened if needed. Prior knowledge can be used or omitted if desired.<br /><br />A sizable portion of the book is devoted to the discussion of the efficacy of human judgment in causation. The author discusses experiments that test this efficacy, and how the data is interpreted with respect to the Rescorla-Wagner model. This model has dominated psychological theories of human and animal learning for many years, but the author discusses an example that indicates problems with this model. This is followed by a discussion of the Cheng model of human judgment of generative causal power. The Cheng model can be expressed as a Bayes net, and the author gives detailed discussion on just how effective this representation can be.<br /><br />The most interesting chapter of the book concerns the use of neural networks to study the effects of brain lesions. A baseline neural network is constructed that is supposed to emulate the normal capacity of the brain. This network is then altered in order to model the functioning of a damaged brain. This strategy is particularly interesting, and very important considering the enormous efforts that are currently being made to connect experimental data to neural network architectures. The author quotes theorems that indicate that the transmission functions of the neural network are really arbitrary as faras the independence properties of the network are concerned. The \\"lesioning\\" of the neural network cannot eliminate any of these independencies. These results, which seem to cast doubt on the strategy of using lesioning, do not negate the use of Bayesian neural networks to study brain lesions. These theorems do not invalidate the use of Bayesian neural networks.	2005-09-04
87776:US	50702879	R30I58RAFLOD8C	026253195X	462189787	Foundations in Social Neuroscience (Social Neuroscience)	Books	5	10	11	N	Y	A fascinating collection of articles	Which brain mechanisms are involved in the typical social interactions that humans engage in everyday life? To what extent are these interactions determined by the dynamical processes in the human brain? Are there separate areas or modules in the brain responsible for these interactions, and what happens when these modules become dysfunctional? These questions, along with many more, are addressed in this collection of articles, which are written for experts in cognitive neuroscience. However, non-experts, such as this reviewer, can profit from a perusal of the articles, even if they have only an understanding of the basic rudiments of cognitive neuroscience. Only twenty-six of these articles were read by this reviewer, and for lack of space just a few of these will be reviewed here.<br /><br />The article entitled \\"Neural Correlates of Theory-of-Mind Reasoning: An Event-Related Potential Study\\", is an attempt to find the neural system that is behind reasoning about mental states. Such a finding is deemed important by the authors of this article, since an impairment of this system may result in autism. They quote research that is suggestive of the idea that the ability to think about mental representations of reality, such as beliefs, is not correlated with the ability to think about other kinds of representations of reality, such as photographs. Autistic individuals have trouble with the former but not with the latter. The authors outline experimental tests that illustrate these differences, and also discuss experiments that show that autistic individuals show greater impairment for left-hemispheric tasks. The implications of these studies for a modularized theory of mind is discussed in some detail, and they conclude these studies give evidence for the assertion that neurophysiological abnormalities in autistic individuals is related to deficits in their social cognitive abilities.<br /><br />For this reviewer, the most interesting article in the book is the one entitled \\"Attention, Self-Regulation, and Consciousness\\", which as the name implies, addresses the study of consciousness. The scientific study of consciousness is finally being taken seriously by cognitive neuroscientists, and this article gives a good example of this. The authors concentrate on the voluntary control of the mental processes that are responsible for the regulation of behavior and thought. They clearly have no qualms at being at odds with entrenched philosophical notions of consciousness and voluntary control. The neuronal system that is responsible for the regulation of thought, emotion, and behavior, is, in their view, one that consists of the midfrontal cortical areas and the underlying basal ganglia. This system has been called the `executive network' by cognitive neuroscientists, and is active for tasks involving selection, conflict, and error detection. The authors discuss various experiments that were conducted to investigate the brain mechanisms behind these three tasks.  For selection, the experiment involved the reading of individual words and monitoring (using PET) the brain activity in finding the use of the words. The `scalp signatures' of some of these activations, along with the PET and later fMRI studies, reveal the dynamics involved in the creation of a single thought. The fMRI data revealed even more, namely that different areas are activated when different semantic categories are processed. Most interesting is that these experiments revealed that the neuronal activity in an area that is attended to inhibits items that are far outside of the category attended to. When elements of a task are in conflict, it is expected that executive control will perform the selected function. Experiments involving the Stroop effect revealed that the midline frontal areas are involved in the resolution of conflict between tasks, but that they are not involved in the feelings of conflict and effort. The supervisory attention system is also concerned with error detection, which the authors view as a conscious strategy to adjust the performance speed to a level of accuracy that is deemed adequate. Experiments revealed that error negativity is localized in the anterior cingulate gyrus, but that the areas of activation of the cingulate were different depending on the task demand.<br /><br />Still another highly interesting article is entitled \\"In Search of the Self: A Positron Emission Tomography Study\\" wherein the authors study the assertion that the association of episodic memory retrieval with the activation of right prefrontal cortex can be attributed to the representation of the self in this portion of the brain. In addition, the authors wanted to find out if there was any evidence for the neural correlates of self-referential processing, i.e. does an individual for example remember a word better if it is reference with respect to the self rather than just processed in semantic terms? In the opinion of the authors, if the self is involved in the activation of the right frontal regions in a manner which is independent of the nature of the cognitive operation, then self-referential encoding will also be associated with PET activations that are mainly right lateralized. If the self-referential encoding is associated with activations in the left frontal regions, then it would be similar to other types of (deeper) processing. Experiments were conducted that enabled a comparison between semantic \\"self\\", \\"other\\", and \\"general\\" tasks, and nonsemantic \\"syllable\\" tasks. These experiments revealed that adjectives judged semantically were better recognized in a later test than adjectives judged in terms of the number of syllables. Adjectives in the \\"self\\" condition were better recognized than those in the \\"other\\" and \\"general\\" conditions, thus indicating a self-reference effect in memory. Most interesting is the authors' contention that the similarities in cortical activation patterns between the \\"self\\" condition and the \\"other\\" and \\"general\\" conditions reveal that thoughts of self involve a \\"conceptual self\\", i.e. a representational schema that arises from an abstraction of several personal episodes. Quoting other researchers, they view the self as a \\"highly-organized cognitive structure\\" abstracted from individual instances. Individuals who are brain-damaged and do not possess episodic memory but who can form accurate judgments about their personality characteristics provide further evidence for their assertions.ion, which the authors view as a conscious strategy to adjust the performance speed to a level of accuracy that is deemed adequate. Experiments revealed that error negativity is localized in the anterior cingulate gyrus, but that the areas of activation of the cingulate were different depending on the task demand.     Still another highly interesting article is entitled \\"In Search of the Self: A Positron Emission Tomography Study\\" wherein the authors study the assertion that the association of episodic memory retrieval with the activation of right prefrontal cortex can be attributed to the representation of the self in this portion of the brain. In addition, the authors wanted to find out if there was any evidence for the neural correlates of self-referential processing, i.e. does an individual for example remember a word better if it is reference with respect to the self rather than just processed in semantic terms? In the opinion of the authors, if the self is involved in the activation of the right frontal regions in a manner which is independent of the nature of the cognitive operation, then self-referential encoding will also be associated with PET activations that are mainly right lateralized. If the self-referential encoding is associated with activations in the left frontal regions, then it would be similar to other types of (deeper) processing. Experiments were conducted that enabled a comparison between semantic \\"self\\", \\"other\\", and \\"general\\" tasks, and nonsemantic \\"syllable\\" tasks. These experiments revealed that adjectives judged semantically were better recognized in a later test than adjectives judged in terms of the number of syllables. Adjectives in the \\"self\\" condition were better recognized than those in the \\"other\\" and \\"general\\" conditions, thus indicating a self-reference effect in memory. Most interesting is the authors' contention that the similarities in cortical activation patterns between the \\"self\\" condition and the \\"other\\" and \\"general\\" conditions reveal that thoughts of self involve a \\"conceptual self\\", i.e. a representational schema that arises from an abstraction of several personal episodes. Quoting other researchers, they view the self as a \\"highly-organized cognitive structure\\" abstracted from individual instances. Individuals who are brain-damaged and do not possess episodic memory but who can form accurate judgments about their personality characteristics provide further evidence for their assertions.	2005-08-28
96189:US	50702879	RNEIGGYWSSX7H	0030968356	707594088	Borror and DeLong's Introduction to the Study of Insects	Books	5	19	20	N	Y	Important for both biologists and non-biologists	Everything about insects is fascinating, and this book gives a comprehensive overview of their behavior, anatomy, and classification. For non-experts in entomology, such as this reviewer, the book provides the necessary background for further study. Topics such as the molecular genetics of insects and the genetic engineering of insects are not covered, but there are plenty of other books that treat these topics in detail. Only the first four chapters were read by this reviewer, but only chapter four will be discussed here.<br /><br />Early on in chapter four, the authors dispel the prejudice that since insects have small nervous systems and have short life spans, they are not automatons and can exhibit a remarkable degree of spontaneity. Insects can adjust to the circumstances of their environment and the organization of their activities can be extremely complex. What is most interesting about their discussion of insect behavior is the emphasis on how it depends on the internal state of the insect, and not only its nervous system but also its internal organs.<br /><br />The authors view the basic unit of behavior in an insect as being a `reflex'. A receptor that is stimulated will cause a particular group of insects to contract, which is observed as a body movement of the insect. A `releaser' is the stimulus that actually triggers a specific collection of movements. This results in what is called a `fixed-action pattern', which, as the name implies, occurs the same way every time it occurs. To be contrasted with these are the `modal-action patterns' that adapt to changes in the body position of the insect relative to external objects. A `central pattern generator' the authors write, is responsible for the leg and wing movements of insects, and allows them to navigate in noisy environments. All of these considerations of insect behavior are interesting in themselves, but even more so considering that they are being applied to unexpected fields such as artificial intelligence. Indeed, the learning abilities of insects are being emulated in various machines in the last few years, with good success. And even, a new area of artificial intelligence called `swarm intelligence' has arisen that is based on the behavior of ants.<br /><br />Along these same lines, the authors discuss four categories that he believes are useful in characterizing insect behavior. These categories clarify to a large extent the difference between `preprogrammed' and modified behaviors. The first of these are called `closed instincts', which are fixed programs. The second is more flexible and are called `open instincts', where experience feeds back and changes the program. The third consists of `restricted learning' and is the analog of classical conditioning. The last one is `flexible learning', wherein experience can result in significant changes in the behavior pattern. All of these categories have found expression in machines, as well as the types of learning that the authors believe exists in insects: habituation, and associative, latent, and insight learning. The authors admit though that insight learning, where familiarity with relationships among (neutral) stimuli is obtained, has not been established without controversy in insects. Honey bees though they quote as examples of insects that can engage in insight learning. Very interesting also in this discussion of the behavior of insects is the use of mathematical models. As expected intuitively, these models involve control theory, but even more \\"exotic\\" approaches such as optimality theory and dynamic stochastic modeling. Optimality theory is used with the assumption that insects evaluate their state variables and engage in decision-making that optimizes their gain according to some criterion.<br /><br />Needless to say the learning abilities and behavior of insects is fascinating, and no doubt there are many surprises waiting for future entomologists. Their research efforts will not only assist in the better understanding of the most important representatives of the animal kingdom but they will be immediately used by those who are attempting to emulate this \\"primitive\\" intelligence of insects in machines.assist in the better understanding of the most important representatives of the animal kingdom but they will be immediately used by those who are attempting to emulate this \\"primitive\\" intelligence of insects in machines.	2005-08-23
107098:US	50702879	R2VL7SHRDD8UK6	0895260387	127908019	How The Catholic Church Built Western Civilization	Books	3	57	111	N	Y	Good in some places...	This book is remarkable in its audacity, for it attempts to establish something that would require many volumes with thousands of pages representing years of meticulous research. There are some good points made in the book, but on the whole it does not offer a convincing case for its main thesis. It is readily apparent that the author feels that the Catholic Church has been misrepresented in history. For example, he begins the book with a quote from an historian in saying that anti-Catholicism is the \\"one remaining acceptable prejudice in America.\\" But he does not offer any statistical evidence for this claim, only saying that it is \\"difficult to dispute.\\" Perhaps, but to make it so would require a lot more evidence than the author has provided in this book. To his credit though, the author is unashamed in putting forth his thesis that the Catholic Church has been the major force behind Western civilization. He does not hide his (extreme) bias, unlike many other historians who have a hidden agenda that is carefully hidden from the reader.<br /><br />The author downplays the Inquisition, stating that there was not as many people killed as is commonly accepted (as if the true number made it more acceptable). He bemoans American \\"popular culture\\" in teaching false ideas about the Catholic Church, but no examples of this are given. He complains of the \\"strong prejudice\\" of the \\"public\\" against the Middle Ages, but no examples of this are given (and just who is this public that many authors always blame for so much ignorance?). He also criticizes \\"professional authors\\" for distorting the history of the Catholic church, saying that they are not \\"trained historians.\\" But as to what constitutes a trained historian he does not say. Does he expect every reader of this book to be a \\"trained historian\\"? If not, he still cannot expect readers to take his word for what he asserts in the book, and accept it uncritically.<br /><br />One of the biggest mistakes the author makes in the book is that he takes a confession of the Christian or Catholic faith as a defining characteristic of an individual, as one that outweighs any other attributes of this individual. The people that he discusses in the book, such as Stanley Jaki, Jean Buridan, Thomas Aquinas, Robert Grosseteste, Nicolaus Steno, Giambattista Riccioli, Maria Grimaldi, Roger Boscovich, and Athanasius Kircher certainly made valuable contributions to the body of knowledge, but could we not say that they were scientists, philosophers, astronomers, or historians, and so on, before saying that they were Christians? Did they spend more time doing science, philosophy, and astronomy than they did in carrying out duties for the Catholic Church. Should we not define an individual according to their (real) accomplishments and not to their (ancillary) beliefs, whatever these beliefs might be? If a person spends ninety percent of his (her) time doing scientific research, and ten percent of his (her) time praying or ministering, should we not call that person a scientist and not a religious devotee? If so, then one cannot argue, as the author does, that the Catholic Church is responsible at all for these achievements. They were done in spite of its teachings, not because of it. Further, there are indications from research in cognitive neuroscience that the brain has a modular structure, implying possibly that religious activity is completely uncorrelated with scientific activity. This would mean that religious thought does not assist in scientific theorizing and experimentation, and scientific thought adds nothing to religious practice.<br /><br />There are a few places in the book though that the author is correct in his assertions. One of these concerns the contributions made by the physicists of the Middle Ages. For example, Jean Buridan's ideas on the \\"impetus\\" are discussed in fair detail in the book. When reading about the ideas of Buridan and others in the Middle Ages, it becomes more apparent that their contributions were ignored, at least from the standpoint of the origin of the concept of inertia in physics and also projective motion. [In this regard, this reviewer recommends the book \\"The Science of Mechanics in the Middle Ages\\" by Marshall Clagett for in depth discussion of the contributions of medieval physicists. This book definitely adds more weight to the author's assertions.]<br /><br />The author's contention that the antagonism of the Catholic Church with Galileo was overblown is however not convincing. Yes, one can easily accept that the authorities in the Catholic Church told him to teach the Copernican theory as a \\"hypothesis\\" and not as \\"true\\". The difficulty with this though is that these authorities had absolutely no moral right to do this, and the fact that they did is further evidence that the Catholic church was anti-scientific, or at least felt threatened by the need for freedom of thought in scientific research. Should a scientist seek approval for his (her) hypotheses from the pope every time they are arrived at? Apparently the author accepts this as viable, if one is to accept his thinking on the Galileo affair.<br /><br />In addition to these mistakes, the author shows lack of respect for religious ideas that are not Catholic in origin. For example, the contributions of \\"Muslim\\" scholars to science are reduced to being merely translations of the ancient Greek classics. \\"The contributions of Muslim scientists\\", he says, \\"occurred in spite of Islam rather than because of it\\". He forgets the brilliant contributions of \\"Islamic\\" mathematicians to algebra and geometry, which to this day every school child in the United States and Europe has to learn.<br /><br />With considerable revision, and with the predilection to honor the Catholic Church omitted, this book could be a valuable contribution and a sound apology for the scientific, artistic, and social contributions of the Middle Ages. As it stands though, it alienates the skeptical reader and negates the brilliance of those who lived in those times. Their brilliance was real, whether motivated by religion or otherwise.t that their contributions were ignored, at least from the standpoint of the origin of the concept of inertia in physics and also projective motion. [In this regard, this reviewer recommends the book \\"The Science of Mechanics in the Middle Ages\\" by Marshall Clagett for in depth discussion of the contributions of medieval physicists. This book definitely adds more weight to the author's assertions.]<br /><br />The author's contention that the antagonism of the Catholic Church with Galileo was overblown is however not convincing. Yes, one can easily accept that the authorities in the Catholic Church told him to teach the Copernican theory as a \\"hypothesis\\" and not as \\"true\\". The difficulty with this though is that these authorities had absolutely no moral right to do this, and the fact that they did is further evidence that the Catholic church was anti-scientific, or at least felt threatened by the need for freedom of thought in scientific research. Should a scientist seek approval for his (her) hypotheses from the pope every time they are arrived at? Apparently the author accepts this as viable, if one is to accept his thinking on the Galileo affair.<br /><br />In addition to these mistakes, the author shows lack of respect for religious ideas that are not Catholic in origin. For example, the contributions of \\"Muslim\\" scholars to science are reduced to being merely translations of the ancient Greek classics. \\"The contributions of Muslim scientists\\", he says, \\"occurred in spite of Islam rather than because of it\\". He forgets the brilliant contributions of \\"Islamic\\" mathematicians to algebra and geometry, which to this day every school child in the United States and Europe has to learn.<br /><br />With considerable revision, and with the predilection to honor the Catholic Church omitted, this book could be a valuable contribution and a sound apology for the scientific, artistic, and social contributions of the Middle Ages. As it stands though, it alienates the skeptical reader and negates the brilliance of those who lived in those times. Their brilliance was real, whether motivated by religion or otherwise.	2005-08-17
112708:US	50702879	R2EE65A6O35KYT	1591023025	971777951	Reality Check: What Your Mind Knows, But Isn't Telling You	Books	2	74	106	N	Y	The author needs a reality check	In this book, the author offers what he considers to be a realistic view of modern life and the human condition. He calls this a \\"reality check\\", but the book definitely does not give the reader a comprehensive, coherent, scientific, and realistic view of the state of world today. Too often those who describe themselves as being \\"realistic\\" are highly skeptical of those who have an optimistic view of life, and believe that such people are naive, unintelligent, or ignorant. The \\"realists\\" seem to enjoy rubbing peoples faces in the dirt, with the intent of waking them up from their optimistic delirium and showing them \\"the true nature of things.\\" But cynicism is not equivalent to realism....<br /><br />Many assertions are made in this book without sound scientific or objective evidence. For example, the author speaks of a \\"territorial imperative\\" as if it were a proven and well-substantiated concept in anthropology. The scientific evidence for this concept though is meager, and the author in no way documents any evidence for it anywhere in the book. In relation to this, he speaks in the book of something called the \\"Simmel effect\\", named after the sociologist George Simmel, and which asserts that in social groups that are ordered by rank, individuals imitate symbols that designate the higher hierarchal levels and abandon the symbols that designate the lower level ones. The author does not discuss the evidence for the Simmel effect, but does give one reference on the Web that is currently not available. There has been research into the Simmel effect that does show that successful status symbols begin to diminish as soon as they become dominant, but this research involved the use of simulation studies. It would be very interesting and helpful if more empirical studies could be conducted. The author's support for this effect is mostly anecdotal, quoting for example the \\"tattoo craze\\" and how some people begin with maybe one or two tattoos and wind up covering their entire bodies in order to gain \\"status.\\" He does not however indicate how many people have engaged in this behavior. Has he studied or observed a large collection of individuals who do? No statistical data is offered to the reader in this regard. He also offers as evidence for this effect the corporate executives who update their offices, jets, and living space; academics who need to \\"be first\\" with research data, and managers who search for someone to demean in order to obtain a \\"daily status boost.\\" But who are these people that he is referring to? What are their names? How many of them has he observed in this regard?<br /><br />He also claims that many people have a need for spiritual belief that can \\"shut out\\" their ability to ponder complex or difficult concepts. How does he know this? What evidence is there that would allow him to conclude this? How many people is this true of? This question is not merely an academic or semantic one, for if it were true it says that when the brain is engaging in religious speculation that this will interfere with conceptualization in other domains. No evidence is given for this claim, even though one could easily find it plausible. It also makes assumptions on the ability of the brain to engage in parallel tasking and domain-specificity. Given the intense research that has been done in cognitive neuroscience in the last two decades that has attempted to settle whether the human brain is actually modular in its architecture, the author's claim here is very outlandish.<br /><br />The author's view of history is also unrealistic and cynical. Yes, the twentieth century was unequaled in its unmitigated brutality and the weapons humans used against each other. It would be wrong however to conclude that even though there were over 90,000,000 million deaths in the last century due to war, this number is not comparable to the number of people in that century who did not choose to participate in the killing of others. And if one looks at history, one will notice that the vast majority of people have never taken another life, have never participated in war, and have led lives that are exemplary if judged from true ethical standards. But yet if we are to believe the author, we will hold that humans are a killer species, anxious at all times to due harm to others, and we must engage in focused concentration to avoid our predilection for violence. The author is too focused on the news reports, with their predilection toward bad news, to notice that these reports are anomalous, large deviations from the norm, as compared to the typical events that govern human interactions and human behavior. Indeed the author should himself engage in a \\"reality check\\": he will find that things are nowhere near as bad as he believes.s at history, one will notice that the vast majority of people have never taken another life, have never participated in war, and have led lives that are exemplary if judged from true ethical standards. But yet if we are to believe the author, we will hold that humans are a killer species, anxious at all times to due harm to others, and we must engage in focused concentration to avoid our predilection for violence. The author is too focused on the news reports, with their predilection toward bad news, to notice that these reports are anomalous, large deviations from the norm, as compared to the typical events that govern human interactions and human behavior. Indeed the author should himself engage in a \\"reality check\\": he will find that things are nowhere near as bad as he believes.	2005-08-14
119794:US	50702879	R12KF0G60B2T7L	1578700779	884189837	1: Developing IP Multicast Networks, Volume I	Books	4	2	3	N	N	A good overview	Multicast has for several years been used in LAN environments to easily exchange information among users, especially in educational and academic research environments. The advent of audio and video conferencing has increased its use in these environments, and it is now making its presence known in WAN and Internet environments. This book gives an overview of the how to implement IP multicast on Cisco devices, and does a good job in that regard. Readers with a general knowledge of networks, even those who have not administered Cisco devices explicitly, can gain much from the book. This reviewer was not interested in the actual implementation of Cisco multicast networks, which is covered in Part 3 of the book, and so this review will concentrate on the other three parts of the book. These parts are mostly descriptive, but they do discuss some of the performance issues involved with the deployment of IP multicast, although nowhere in the book are test cases discussed, even though their inclusion would have been extremely helpful. Multicasting by itself is not a complicated phenomena to understand and use, but when it is deployed over Layer 2 or when coupled with QoS some interesting issues can arise. This reviewer was mostly interested in traffic engineering in multicast environments, and the author spends an entire chapter on this topic.<br /><br />The book begins with a history of multicast and the MBone, the latter of which is a collection of Internet routers and hosts that are interconnected and are able to forward IP multicast traffic. IP multicast is of course an unreliable transmission mechanism, based as it is on UDP. Along with stating the assigned scope of the multicast addresses over IP, the author also reviews the scheme for multicast MAC addressing. The MAC address mapping will cause a CPU performance hit though since the CPU will have to be interrupted in order to deal with all 32 of the IP multicast groups. This arises since the IP multicast address information cannot be mapped into the available space of the MAC address space. There is a 32:1 address ambiguity when an IP multicast address is mapped to a MAC address.<br /><br />One can summarize the properties of the multicast routing protocols discussed in the book straightforwardly:<br /><br />PIM (Protocol Independent Multicasting) can run in three different modes, namely Dense (DM), Sparse (SM) and Sparse-Dense. A router will always forward multicast traffic on a dense mode interface unless all the PIM neighbors of the interface prune themselves from the multicast tree. Multicast traffic will be forwarded on a sparse mode interface only if at least one of the PIM neighbors explicitly joins the multicast tree. In sparse-dense mode, the interface can be running in sparse mode for some groups and dense mode for others. There is a \\"hello interval\\" for PIM multicast which is the frequency at which the router will send PIM query messages, the latter of which are used for selecting a PIM designated router. The PIM designated router is responsible for sending IGMP (v1) queries. Bootstrap messages can be forwarded from an interface in PIMv2. This allows all PIM-SM routers in a domain to dynamically learn all Group-to-RP mappings.In PIM-DM, the multicast traffic is periodically forwarded even on pruned interfaces of a source-based distribution tree. This allows the learning of membership changes. This 'state-refresh interval' can be configured on the first-hop routers of the multicast source, allowing the interface to periodically send a state refresh control message down the source-based distribution tree. When doing multicast in an NBMA (NonBroadcast MultiAccess) network, a router will replicate multicast packets for all neighbors configured for broadcast (actually pseudobroadcast to use the author's characterization). To avoid this, one can configure the router in NBMA mode, which will then only allow the replication of packets for PIM neighbors. NBMA mode is only supported by Cisco for SM networks.<br /><br />DVMRP (Distance Vector Multicast Routing Protocol) does neighbor discovery, where network routing information is exchanged between neighbors. This information consists of Route Report messages that advertise a source network and a hop-count. DVMRP generates two routing tables, one is a multicast routing table to the receivers and a unicast routing table to the sources. When forwarding, a DVMRP router will use the unicast table for RPF (Reverse Path Forwarding) checks and the multicast table for forwarding multicast packets. When doing unicast routing, the router will use the unicast table for the RPF check, but will use a different multicast routing protocol for forwarding multicast packets. There is a metric value associated with a DVMRP unicast route, which is the sum of the interface metrics of a route between the router originating the report and the router in the source network.<br /><br />For multicast traffic, one can control bandwidth with: 1. Aggregate rate limiting, which sets an upper bound for all multicast traffic being sent on an interface. 2. Mroute table entries wherein each individual multicast stream is set to a maximum rate. 3. `Scoped zones' and multicast boundaries, which prevent multicast traffic with a high rate from traveling outside the provisioned regions. Doing actual multicast traffic engineering is complicated do to the need for calculating the proper RPF (Reverse Path Forwarding) interface (and not the destination IP address). The author discusses in detail some of the techniques that can be used, such as GRE tunnels and `pseudo load-sharing.' GRE tunnels are used to do load-splitting of multicast traffic, which cannot be done otherwise since multicast is allowed only one incoming interface. He also describes how to do traffic conversion between broadcast and multicast, this being allowed for Cisco IOS 11.1 or later. This is a useful capability for networks where the source or the receivers, or both, do not support IP multicast.e is only supported by Cisco for SM networks.  <br /> <br />DVMRP (Distance Vector Multicast Routing Protocol) does neighbor discovery, where network routing information is exchanged between neighbors. This information consists of Route Report messages that advertise a source network and a hop-count. DVMRP generates two routing tables, one is a multicast routing table to the receivers and a unicast routing table to the sources. When forwarding, a DVMRP router will use the unicast table for RPF (Reverse Path Forwarding) checks and the multicast table for forwarding multicast packets. When doing unicast routing, the router will use the unicast table for the RPF check, but will use a different multicast routing protocol for forwarding multicast packets. There is a metric value associated with a DVMRP unicast route, which is the sum of the interface metrics of a route between the router originating the report and the router in the source network.  <br /> <br />For multicast traffic, one can control bandwidth with: 1. Aggregate rate limiting, which sets an upper bound for all multicast traffic being sent on an interface. 2. Mroute table entries wherein each individual multicast stream is set to a maximum rate. 3. `Scoped zones' and multicast boundaries, which prevent multicast traffic with a high rate from traveling outside the provisioned regions. Doing actual multicast traffic engineering is complicated do to the need for calculating the proper RPF (Reverse Path Forwarding) interface (and not the destination IP address). The author discusses in detail some of the techniques that can be used, such as GRE tunnels and `pseudo load-sharing.' GRE tunnels are used to do load-splitting of multicast traffic, which cannot be done otherwise since multicast is allowed only one incoming interface. He also describes how to do traffic conversion between broadcast and multicast, this being allowed for Cisco IOS 11.1 or later. This is a useful capability for networks where the sourceor the receivers, or both, do not support IP multicast.  <br />	2005-08-10
129806:US	50702879	RG6SI0YR02QZA	0321304543	243113582	The Art of  Computer Virus Research and Defense	Books	3	21	41	N	Y	Disappointing	The book is very disappointing in that the author does not show explicitly how to create and code viruses. The author explains in the preface that he does not include such code because of its obvious dangers. This reviewer believes however that the more understanding we have of viruses the better we can deal with their threats. We need to understand just what is possible, and this can only be done by creating viruses that may or may not be hazardous to computer systems. The more viruses that we create and then study the more we can guard against their infection. This goes for computer viruses as well as biological ones. Yes, there are dangers involved in doing this, but these dangers are nullified by the tools and artificial immune systems that we create in the process of studying viruses.<br /><br />The book of course is not without its merits, one of these being the discussion of the history of computer viruses, which the author includes in the first chapter of the book. The designation \\"computer virus\\" was done in 1984, at which time a formal mathematical model was created for computer viruses. The author defines a computer virus as being a program that can recursively and explicitly copy a possibly evolved version of itself. This definition he says covers the notion of a `companion virus', which does not necessarily modify the code of other programs.<br /><br />The author is also very thorough in his treatment of the different viruses and their association with specific computer platforms. In addition, he gives a detailed treatment of how to analyze a computer virus using disassemblers, debuggers, emulators, virtual machines, virus test networks, and unpackers, along with various other tools. Readers will definitely benefit from knowledge of assembly code.<br /><br />For non-experts in virus research (such as this reviewer) but who have a strong mathematical background, a natural question to ask is whether one could develop a highly sophisticated computer immune system that would be able to detect any kind of computer virus within a reasonable time scale. The author believes that this cannot be accomplished, quoting a result by the mathematician Frederick Cohen (the inventor of the term \\"computer virus\\") indicating that such an immune system is not possible. The Cohen proof is not included in the book unfortunately, but a perusal of the literature will reveal that the proof is based, as expected, on the theory of computability and Turing machines. What Cohen showed was that the detection of generic computer viruses is undecidable by showing that if such a procedure existed, it would solve the halting problem for Turing machines.<br /><br />Given the Cohen result, it is appropriate to ask whether viruses can come in such a wide variety as to make their detection and annihilation unique to the actual virus. In addition, it would appear that after a reasonable amount of time, it would become more difficult for virus writers to come up with `exotic' viruses that elude detection. Have most of the effective or interesting viruses already been invented, and therefore countered, by anti-virus programs? When reading this book one gets the impression that this is the case. However, the author shows that such a judgment would be premature, and he spends a fair amount of time in the book discussing possible future developments in computer viruses, particularly in distributed environments.<br /><br />Even if virus writers are exhausting the possibilities for effective viruses, they can still find ways of evading the detection programs, using encryption for example. The author discusses several different approaches to the encryption of viruses, all of these having varying degrees of success, depending of course on the resources and knowledge base of the virus analyst. An interesting topic discussed in this connection is the origin of `oligomorphic' viruses, which change their decryptors in new generations. The `polymorphic' viruses, which are the next stage in complexity, are also discussed in this context, these allowing the mutation of their decryptors in possibly millions of different forms. When a virus is able to create new generations of itself that look different, it is called a 'metamorphic' virus. The author gives examples of these, how thay are detected, and the possibility of using them to construct a virus generator able to create new virus mutations on the fly without any human intervention. One of the metamorphic viruses, named W95/Zmist, is described by the author as being one the most complex binary viruses ever created. For that reason it is discussed in detail in the book. This discussion is fascinating reading, and one would have hoped that the source code was supplied in the book in order to allow responsible and curious individuals to create the W95/Zmist virus and study its behavior in real systems under controlled laboratory conditions.<br /><br />The author does not distinguish between computer worms and viruses, except to say that the former are sometimes distinguished from the latter in the way they infect networks. A worm does not usually need to infect files but can propagate as a standalone program. However, the author gives examples of worms that do propagate by the infection of files. Illicit information gathering is the purpose of most worms, and the author discusses several different techniques that worms use to obtain this information. Particularly interesting to read about are the different techniques that computer worms are used to propagate themselves. One of these involves instant messaging, which because of its popularity will certainly be one that is given more attention by future attackers.<br /><br />Virus writers will become more creative in the future, and their efforts will no doubt be discussed in future editions of this book. But it is the more subtle approaches that remain undiscovered that are the most devastating to both individuals and businesses. One gets the impression when reading this book that most of the viruses are created by pranksters who gain emotional reinforcement by the success of the exploits. The antivirus defense techniques work in the latter but not the former.ic' viruses, which are the next stage in complexity, are also discussed in this context, these allowing the mutation of their decryptors in possibly millions of different forms. When a virus is able to create new generations of itself that look different, it is called a 'metamorphic' virus. The author gives examples of these, how thay are detected, and the possibility of using them to construct a virus generator able to create new virus mutations on the fly without any human intervention. One of the metamorphic viruses, named W95/Zmist, is described by the author as being one the most complex binary viruses ever created. For that reason it is discussed in detail in the book. This discussion is fascinating reading, and one would have hoped that the source code was supplied in the book in order to allow responsible and curious individuals to create the W95/Zmist virus and study its behavior in real systems under controlled laboratory conditions. <br /> <br />The author does not distinguish between computer worms and viruses, except to say that the former are sometimes distinguished from the latter in the way they infect networks. A worm does not usually need to infect files but can propagate as a standalone program. However, the author gives examples of worms that do propagate by the infection of files. Illicit information gathering is the purpose of most worms, and the author discusses several different techniques that worms use to obtain this information. Particularly interesting to read about are the different techniques that computer worms are used to propagate themselves. One of these involves instant messaging, which because of its popularity will certainly be one that is given more attention by future attackers.  <br /> <br />Virus writers will become more creative in the future, and their efforts will no doubt be discussed in future editions of this book. But it is the more subtle approaches that remain undiscovered that are the most devastating to both individuals and businesses. One gets the impression when reading this book that most of the viruses are created by pranksters who gain emotional reinforcement by the success of the exploits. The antivirus defense techniques work in the latter but not the former.	2005-08-05
138224:US	50702879	RQ0C13S162NQK	0121783561	569669321	Tending Adam's Garden: Evolving the Cognitive Immune Self	Books	5	10	10	N	Y	A fascinating proposal	In this book the author makes a seemingly radical hypothesis, namely that human immune system is in fact a cognitive system. Those who think of a cognitive system as also being one that is conscious will find the author's contention perhaps even more radical. However, the author's notion of a cognitive system is not as elaborate, and such systems are very prevalent in manufacturing and control systems, telecommunication networks, and military systems.<br /><br />The book is targeted toward a wide readership, and therefore the author omits detailed scientific jargon and also omits many references. Readers (such as this reviewer) who are not experts in immunology though can still gain a lot of insight into the workings of the human immune system, and the book could be read as an introduction to this important field. In fact, a non-expert in immunology might gain much more from the book than an expert, for the former has not been biased by the \\"classical\\" clonal selection theory of the immune system, and will therefore be more open to the prospect of a different paradigm. The physicist/mathematician reader will find an interesting use by the author of chaotic dynamical systems and its notion of an attractor. The use of these concepts goes along with the author's notion of evolution and adaptation, which he describes as a radical departure from the standard view. Adaptation, in his view, is defined as an attractor, and is not correlated with improvement of the organism. Evolution does not involve the `improvement of DNA' but rather is the `creation and occupation of attractors.'<br /><br />The main virtue of this book is the author's careful elucidation of the notion of a cognitive system. This is necessary in his view in order to distinguish such a system from one that might qualify as being cognitive, but one would not want to view as being cognitive. As evidence of the latter, he gives the example of the production of urine by the kidneys. Such a system he says exhibits complexity, precision, and regulation that rivals many nervous systems, but one that should not qualify as being cognitive. A cognitive system he argues is able to make decisions, is able to form images of their environments, and is able to learn from experience. This learning ability involves the updating of their internal structures and images, which the author refers to as `self-organization.' Hence `choice,' `internal images,' and `self-organization' allows the cognitive system, and therefore the organism that possesses it, to interact with the world that will give it distinct advantages over what can be obtained from evolutionary genetics.<br /><br />So what is the nature of the `images' of the environment encoded by the immune system? They are merely proteins, some of which are distributed throughout the body and form geometrical shapes as well as `abstract, functional' ones. These images are also of two types, the `innate' images, which are inherited, and `acquired' images, which arise from the cognitive process. Autoimmune diseases, the author argues, involve an image dysfunction in the immune system.<br /><br />A cognitive view of the immune system the author thinks is necessary because of the need for immune receptors to have the ability for specific recognition. However, they are degenerate, `pleiotropic', redundant, and random observes the author, and this means that cognition (as he defines it) is necessary in order that the immune system generate specificity out of the non-specificity of its components. The author outlines in detail how to construct immune cognition, this involving the `geometry' of cognition, the `dynamics' of cognition, and the `images' or `patterns' of cognition.<br /><br />In terms of its ability to engage in cognitive decision-making, the immune system reacts to a pattern of signals that it receives by selecting a particular type of response pattern from its collection of available responses. An `immune language' that combinesgerm-line and somatic `chemical words' is used to make the decisions. These choices, the author emphasizes, are not the result of any `self-reflective consciousness' or `mystical free will' but in fact are deterministic. Choices in the immune system can occur because it can exercise options and because it can learn. From a chemical perspective, the decision-making in the immune system involves associating somatic perceptions of objects with classes of effector responses in the germ-line.<br /><br />These views of immune system decision-making are fascinating, and will certainly invoke strong reactions from the philosophical community. Indeed, what is normally thought of as capabilities only found in a `mind,' namely that of abstraction, semantics, and context, these can also be found in the human immune system. It communicates via molecular interactions; its antigens and cytokines express semantic attributes since they can confirm ligands and their receptors and can arrange the signal molecules in patterns; and can patterns of signals can create a signal context.<br /><br />The immune system can be defective, this resulting among other things in the deadly autoimmune diseases. The author discusses this unfortunate circumstance in detail in the book, but he is also willing to contemplate deliberate intervention into the workings of the immune system in order to circumvent any problems with it. In the last paragraph of the book, noting that \\"two cognitive systems are better than one,\\" the author advocates the deliberate engineering of the immune system, i.e. that of turning \\"on or off the immune response as we see fit.\\" Along with genetic engineering, metabolic engineering, and other endeavors of twenty-first century technology, such a prospect is awesome.' that combines germ-line and somatic `chemical words' is used to make the decisions. These choices, the author emphasizes, are not the result of any `self-reflective consciousness' or `mystical free will' but in fact are deterministic. Choices in the immune system can occur because it can exercise options and because it can learn. From a chemical perspective, the decision-making in the immune system involves associating somatic perceptions of objects with classes of effector responses in the germ-line.  <br /> <br />These views of immune system decision-making are fascinating, and will certainly invoke strong reactions from the philosophical community. Indeed, what is normally thought of as capabilities only found in a `mind,' namely that of abstraction, semantics, and context, these can also be found in the human immune system. It communicates via molecular interactions; its antigens and cytokines express semantic attributes since they can confirm ligands and their receptors and can arrange the signal molecules in patterns; and can patterns of signals can create a signal context.  <br /> <br />The immune system can be defective, this resulting among other things in the deadly autoimmune diseases. The author discusses this unfortunate circumstance in detail in the book, but he is also willing to contemplate deliberate intervention into the workings of the immune system in order to circumvent any problems with it. In the last paragraph of the book, noting that \\"two cognitive systems are better than one,\\" the author advocates the deliberate engineering of the immune system, i.e. that of turning \\"on or off the immune response as we see fit.\\" Along with genetic engineering, metabolic engineering, and other endeavors of twenty-first century technology, such a prospect is awesome.	2005-08-01
141117:US	50702879	R23IGZLY1G8N2I	0465092667	810818791	The Cube and the Cathedral: Europe, America, and Politics Without God	Books	3	17	54	N	Y	The volume of a cube is greater than that of a cathedral	The allegory in this book is quite simple, perhaps too much so: the \\"cathedral\\" contains the people of Catholic Christendom, while the \\"cube\\" consists of the secularists who reject any notion of god or objective moral order. The dwellers of the cathedral are responsible for giving societal arrangements meaning and offer hope and motivation for the future. The cube dwellers on the other hand, are responsible for the current malaise in Europe, offer no timeless solutions to societal problems, and have absolutely no vision for the future.<br /><br />The author's thesis is not only provocative but a grand one, considering how much time it would take to substantiate it with sound research and historical analysis. One will not find such in this small book, for if it were included, the size of the book would increase beyond all measurable bounds. Indeed, there are many statements in the book that are completely unsubstantiated, that cite only anecdotal evidence, or that illustrate that the author does not have a command of basic knowledge of statistical sampling. One of these is the claim that Americans, after 9/11 and the Iraq War, became aware that they have a \\"Europe problem.\\" How many Americans are aware of this? How does the author know that this is the case? What statistical sampling technique has he used? And how does he know that the United States and western Europe have \\"different visions\\" and that the \\"ideological gap\\" between them is based on a collection of experiences in the twentieth century that are different? Has he sampled the citizenry of all the countries involved to see if this is really the case? To what degree are they different? And again: is it statistically significant for his case in the book that one out of five Germans believed that the US was responsible for 9/11? Also, who are the European public intellectuals that are \\"Christophobic\\"? What are their names, and what writings or dialog serves as justification for labeling them as such? The list goes on, and there are also many places in the book where the author takes a swipe at other religions, such as the Islamic faith. In the latter for example, he plays on fears of terrorism in the supposed influx of Muslims into Europe. He forgets, perhaps intentionally, that terrorist Muslims are only a tiny minority of those who refer to themselves as followers of Islam.<br /><br />If the European populace is indeed \\"Christophobic\\" as the author claims (again, without sound statistical evidence), perhaps there is good reason for their anxieties concerning religion. The savagery of the Crusades, the Inquisition, and the Thirty Years War serve as a grim reminder of the destructive power of religion. No, religion is not the cause of all the conflicts that Europeans had to endure over the centuries, but it no doubt gave courage to those who had to fight the battles. Promises of eternal rewards can act as a catharsis to those burdened with the horror of war, and can, perhaps without intending to do so, make it easier for wars to get off the ground. Individuals convinced that they are mortal and that there is no afterlife might perhaps be extremely reluctant to sacrifice themselves, knowing that this life, with both its vicissitudes and its joys, is the only one they have.<br /><br />The author asks the reader to consider which group of people, those in the cathedral or those in the cube, are more able to offer a more stable and contented society, and one that is looks to the future with hope. Which culture, he asks, has a greater likelihood of protecting human rights, of defending \\"legitimate\\" pluralism, and of justifying morally the democratic project? He offers no surprises to the reader that it is the former that are better qualified, and he does not see any reconciliation or intersection morally or ideologically with the latter. Only \\"metaphysical boredom\\" will be result of dwelling in the cube he concludes. Occupiers of the cube will not have any sense of obligation to others, and will not defend their freedoms or meet their spiritual and physical needs.<br /><br />Without a more detailed characterization of what constitutes a cube dweller, since the author did not offer a suitable one in the book, one can only make educated guesses as to their temperament and philosophical outlook. A reading of European literature does offer some evidence of the malaise and \\"metaphysical boredom\\" that the author has put forward as his main thesis. But a cube dweller could also mean a person whose secularism is not the result of cynicism or militant rejection of the religious worldview. It could mean an individual who finds the prospect of eternal life itself extremely boring, even terrifying. Such an individual understands that religion is to be rejected because it is superfluous and no longer needed for life's motivations and joys. Cube dwellers can no longer worship a deity because they can no longer believe that they can offer anything to such a deity. They have rejected the Christian god as they have rejected the gods of the Greeks: they have outgrown such notions and have turned their attention to the celebration of life and all the multiplicities it has to offer. They indulge themselves in the excitement of scientific discovery. They dance with joy in hearing of the latest technological developments, astounding as they are in the twenty-first century. Their enthusiasm for existence spills over in their treatment, tolerance, and deep respect for their fellow human being, knowing that others hold to possibly different worldviews, but who understand that conclusions reached are the result of different histories of neuronal synapses. Most importantly, they are quite willing to share their space in the cube with those who occupy the cathedral, but also the synagogue, the mosque, and the temple. There is ample volume in the cube to accomodate them.obligation to others, and will not defend their freedoms or meet their spiritual and physical needs.  <br /> <br />Without a more detailed characterization of what constitutes a cube dweller, since the author did not offer a suitable one in the book, one can only make educated guesses as to their temperament and philosophical outlook. A reading of European literature does offer some evidence of the malaise and \\"metaphysical boredom\\" that the author has put forward as his main thesis. But a cube dweller could also mean a person whose secularism is not the result of cynicism or militant rejection of the religious worldview. It could mean an individual who finds the prospect of eternal life itself extremely boring, even terrifying. Such an individual understands that religion is to be rejected because it is superfluous and no longer needed for life's motivations and joys. Cube dwellers can no longer worship a deity because they can no longer believe that they can offer anything to such a deity. They have rejected the Christian god as they have rejected the gods of the Greeks: they have outgrown such notions and have turned their attention to the celebration of life and all the multiplicities it has to offer. They indulge themselves in the excitement of scientific discovery. They dance with joy in hearing of the latest technological developments, astounding as they are in the twenty-first century. Their enthusiasm for existence spills over in their treatment, tolerance, and deep respect for their fellow human being, knowing that others hold to possibly different worldviews, but who understand that conclusions reached are the result of different histories of neuronal synapses. Most importantly, they are quite willing to share their space in the cube with those who occupy the cathedral, but also the synagogue, the mosque, and the temple. There is ample volume in the cube to accomodate them.	2005-07-30
149204:US	50702879	R287QQV9N6DBVH	1932594019	655642308	The Ethical Brain	Books	5	47	61	N	Y	A first look at neuroethics	With the rapid demise of the religious worldview and with the deconstruction of the concept of the soul/self in the twenty-first century, it remains to be seen what system of morals and ethics will supplant the traditions and arbitrary legal codes of the past. There are myriads of possible systems that could be constructed, and no doubt many of these will not be scientific in their foundation or pragmatic in their consequences. Many might be terrified by what is ahead for law and morality, just as they were when Friedrich Nietzsche proclaimed the death of God and the consequent \\"eclipse\\" of moral values in the nineteenth century. His pronouncement was prophetic, if delayed somewhat, and definitely not one that was scientific.<br /><br />This book, written by one of the founders of cognitive neuroscience, gives a proposal for one of these systems, and bases it on what is known from research in neuroscience. It is of course this research that has contributed to the dissolution of the concept of the soul referred to above. It has also called into question the sacred axiom without which ethical systems were held to be impossible: free will.<br /><br />The author though exudes a confidence and calmness of spirit in his deliberations. He is cautious without being anxious, and gives the reader information about what is known in neuroscience, omitting speculation but at the same time anticipating future developments. Several highly interesting issues are discussed, including what moral status is to be conferred to the human embryo, the origin (and end) of consciousness, the enhancement of the human brain via genetic engineering and various drugs, the idea of free will and the neuroscience of determinism (and its legal consequences), the concept of personal responsibility (and its correlation, if any, with the brain), the use of brain fingerprinting, and misattribution and its consequences for the justice system.<br /><br />There are several questions that one could ask after reading this book, depending on the background and interests of the reader. For example, are ethical aphasias possible? Does lying result in permanent disruption of cognitive faculties? Can genetic engineering, in the form of real-time gene therapies, be used to enhance the ethical capabilities of the human brain? What advantages does neuroethics have over ethical systems based on religion? Will humans find neuroethics sufficiently motivating to sustain them throughout the generations ahead? At least to this reviewer, the answers to these questions are of great interest. Neuroethics not only sounds sensible, even given the body of evidence now currently available in the field of neuroscience, but also highly motivating.sk after reading this book, depending on the background and interests of the reader. For example, are ethical aphasias possible? Does lying result in permanent disruption of cognitive faculties? Can genetic engineering, in the form of real-time gene therapies, be used to enhance the ethical capabilities of the human brain? What advantages does neuroethics have over ethical systems based on religion? Will humans find neuroethics sufficiently motivating to sustain them throughout the generations ahead? At least to this reviewer, the answers to these questions are of great interest. Neuroethics not only sounds sensible, even given the body of evidence now currently available in the field of neuroscience, but also highly motivating.	2005-07-25
152425:US	50702879	R16ER98AJSNCVV	0786712694	910851835	The Essential Middle East: A Comprehensive Guide	Books	5	9	9	N	Y	Of great assistance in obtaining a more accurate view of the Middle East	If one has a genuine desire to understand the history and events of the Middle East, this desire will only be met by painstaking research, and this research will entail that one seek alternative sources of information. A true and accurate understanding of the Middle East cannot be obtained by consulting the Western press, for the latter has proved itself biased beyond all rational bounds. It cannot be trusted. Indeed, it has become a uncritical sycophant of a yellow, brutal regime, and through its writer's pens has with great zeal assisted in the unleashing of horrible carnage upon a people whose history has been re-written, falsified, and vilified.<br /><br />It becomes imperative therefore that a methodology be developed that will allow an objective study of the history of the Middle East. It is the opinion of this reviewer that such a study should begin with a perusal of the works of those individuals that are \\"on the ground\\": those individuals that live in the regions of interest and who are experiencing the events as they happen.<br /><br />This book therefore is a good start in this regard, for it has been written by someone who has lived in the Middle East, and has compressed his experiences in the written word with concentrated skill. The author of course has his biases, but since they are not hidden from the reader under the cover of tact and prudence, they can be readily be dealt with by a patient reader. Non-experts in the history of the Middle East, such as this reviewer, will gain a lot from the study of this book. There are many surprises of fact for those readers, such as this reviewer, who have been acclimated to the distortions of the Western press.<br /><br />Some of these surprises include: 1. The United Nations partition for Palestine in 1947 gave the Jewish people, who owned 6% of the land at the time, 53.5% of Palestine. 2. Menachem Begin, former prime minister of Isreal from 1977-1983, was the main planner of the attack on Deir Yassin, an Arab village, in 1948, which resulted in the massacre of 254 people. In the author's opinion, this massacre motivated a massive exodus of Arabs from Palestine, but he does not offer (causal) evidence for this. 3. Iraq, under Saddam Hussein, began using chemical weapons, in the form of mustard gas and nerve gas, in October 1983, in its war against Iran (called interestingly, `Gulf War I' by the author). 4. \\"Hamas\\" means \\"zeal\\" in Arabic. 5. The Hanbali code, which is the school of the Sharia founded in the eighth century, is opposed to the legal pronouncements of the Quran and the `sunna', thus shedding light on the tensions between the Sunnis and Shiites in the Middle East. 6. \\"Hizbollah\\" means \\"party of Allah\\" in Arabic. 7. Kuwait actually assisted Iraq, both materially and logistically, in its war against Iran. 8. Reza Shah Pahlavi changed the name of Persia to Iran in 1933. 9. Premier Muhammad Mussadiq nationalized the Anglo-Iranian Oil Company in 1951, perturbing the West, and resulting in the CIA launching a counter-coup in 1953. 10. Bahais, a religious minority in Iran, are considered heretics and are banned in Iran. 11. The Quran forbids usury, and money is to be used only as a means of exchange. However, the need for lending instigated a pronouncement in Islamic doctrine that \\"Necessity makes prohibited things permissible.\\" The author describes other methods of circumventing the doctrine against usury. 12. The Islamic revolution began in 1977 as a demand by Iranian intellectuals to abolish censorship. Nonreligious opposition to the Pahlavi regime was substantial but was not given any power after Khomeini took power. 13. Khomeini was a writer, and was arrested in 1963 but Shah Pahlavi. This caused an uprising argues, the author, which was crushed by Pahlavi, with thousands being killed in the process. After taking power, Khomeini repressed all non-Islamic contributors to the revolution.  14. Nuclear weapons research began in Israel in 1957. According to the author, Israel has the capacity to produce a neutron bomb, and has in its possession 400 thermonuclear and nuclear weapons. 15. Oil was found in Iran in 1908 by a British prospector, whose firm eventually became the Anglo-Persian Oil Company. 16, At current production rates, Iran will run out of oil in 2070, but their natural gas reserves, at current production rates, will last another 450 years. 17. At current production rates, Iraq will be out of oil in 2116. Gas production can continue at current rates until 2096. 18. Saudi Arabia, if current production rates continue, will run out of oil in 2087.<br /><br />There are many other interesting facts in the book, which will need checking if the reader is to be confident in their truth. This will take an enormous amount of resources and time, and will require knowledge of Arabic. However, a more accurate picture of the Middle East is preferable to the loose association of facts delivered by the Western press. It is only by a thorough understanding of the Middle East can one differentiate foes from friends. An honest examination of the evidence will reveal, at least so far, that there are more friends in the Middle East than foes. Whether this will remain true remains to be seen.acity to produce a neutron bomb, and has in its possession 400 thermonuclear and nuclear weapons. 15. Oil was found in Iran in 1908 by a British prospector, whose firm eventually became the Anglo-Persian Oil Company. 16, At current production rates, Iran will run out of oil in 2070, but their natural gas reserves, at current production rates, will last another 450 years. 17. At current production rates, Iraq will be out of oil in 2116. Gas production can continue at current rates until 2096. 18. Saudi Arabia, if current production rates continue, will run out of oil in 2087.     There are many other interesting facts in the book, which will need checking if the reader is to be confident in their truth. This will take an enormous amount of resources and time, and will require knowledge of Arabic. However, a more accurate picture of the Middle East is preferable to the loose association of facts delivered by the Western press. It is only by a thorough understanding of the Middle East can one differentiate foes from friends. An honest examination of the evidence will reveal, at least so far, that there are more friends in the Middle East than foes. Whether this will remain true remains to be seen.	2005-07-23
158872:US	50702879	R2O59WII1A16P9	0262071045	380137959	An Artificial Intelligence Approach to Legal Reasoning (Artificial Intelligence and Legal Reasoning)	Books	4	4	4	N	Y	Of historical importance	To design a machine that can engage in legal reasoning has been of great interest in the field of artificial intelligence and in some schools of jurisprudence. This goal has not been achieved to the satisfaction of all those involved in building legal reasoning machines, but some progress has been made. This book, which is widely cited by those working in legal artificial intelligence, was one of the few at the time of publication that gave a fresh approach to the problem.<br /><br />When reading the book it is apparent that many questions must be answered before a successful legal machine can be constructed. These include: How does one apply a rule to the stated facts of a legal case? Is there a demarcation between the conclusions that can be reached using ordinary logical deduction and those arrived at by the discretion of the judge? Can a machine analyze full and encapsulate in its knowledge base the concepts of wisdom and justice? How does the language of rules connect with the language in which facts are stated? What kinds of predicates are to be used only in the antecedents of rules? If the descriptions and examples are only `usually fairly good,' when can a machine make the conclusion that these examples are good enough for a particular issue at hand? How does one determine that a legal predicate not defined further by rules is clearly satisfied by the facts of a case being analyzed? How are past cases to be represented? How is the legal machine to represent the reason(s) for a decision? Which facts are to be considered relevant in determining the satisfaction of which legal predicate?<br /><br />The author addresses these questions in this book, and even a reader not interested in the applications of artificial intelligence will gain good insights into the processes of legal reasoning. Legal conclusions for example can be divided into two classes, those that are the result of deductive reasoning and those that require the judge to select the `just' conclusion. A `just' conclusion is therefore to be distinguished from those arrived at deductively. This observation, if valid, definitely has ramifications for the building of legal machines, since deductive reasoning patterns are fairly easy to implement in machines. But the concept of a `just' conclusion would be a challenge for a machine implementation.<br /><br />As brought out in the book, any kind of reasoning pattern utilized by a machine must be subject to constraints, these constraints being unique to the domain in which the machine reasons. In legal reasoning, this constraint takes the form of `stare decisis', which means that the machine must be able to make analogies and be aware of cases in the past. In addition, legal reasoning is `rule-guided', rather than rule-governed, and legal rules are heuristic in nature, generally have exceptions, and sometimes may contradict one another. Besides these constraints, the terms in legal discourse are what the author calls `open-textured,' in that the meaning of terms and predicates are inherently indeterminable. Legal questions frequently invite more than one answer, and these answers can change over time. Hence legal reasoning patterns must be able to adapt to a dynamic knowledge base.<br /><br />According to the author, the strategy for a successful legal reasoning machine would involve the ability to distinguish between `hard' versus `easy' questions. The hard questions in legal discourse arise because of the existence of competing rules, unresolved predicates, and competing cases. The machine must be able to detect `hard' cases, and it could do this by using a collection of heuristics. One of these heuristics involves the use of what the author calls `common sense knowledge' (CSK) rules, which are to be distinguished from general human commonsense knowledge. If an answer can be derived using CSK rules and if there does not exist any objection to using this answer, then question is assumed to be `easy.' The second heuristic entails that if no answer about the satisfaction of a legal predicate can be defined using CSK rules, then the machine will search for cases that illustrate that the facts of the case at hand are actually an example of a situation that the legal predicate has covered in the past. The third states that if a tentative answer is derived using non-legal knowledge, then the machine will search for cases that call for the opposite answer.<br /><br />To test and benchmark her strategy, the author works in the field of `offer and acceptance' and `contract law', and deals specifically with the case `Adams vs Lindsell'. To construct the reasoning patterns, she brings in a highly interesting construction that she calls a `augmented transition network' (ATN). An ATN represents the standard states in a contract situation and the interpretations of events are represented as links between the states. The ATN that she constructs has twenty-three sates, twenty legal rules, and one hundred generalized `fact patterns.' The latter are associated with each legal predicate, and can be supported by several cases.<br /><br />The author gives detailed analysis of her approach, and remarks that its use has not produced situations wherein a `tentative' truth value is defeated. Several test problems are analyzed at the end of the book, these dealing mostly with how the reasoning patterns analyze events, and one that deals, interestingly, with legal study aids. From her conclusions it is readily apparent that legal reasoning is very difficult to implement in artificial intelligence, for the primary reason that deduction does not by itself determine the outcome of a case. Another reason is the role of legal precedent, which can give a new interpretation to the language of old rules.<br /><br />The author also makes commentary on the future of legal artificial intelligence. Considering the progress made in this field since this book was published, especially in the use of knowledge engineering in the practice of law, one can be confident that legal machines will make their presence known in the courts, in legal philosophy, and in constitutional interpretation in the years to come.e second heuristic entails that if no answer about the satisfaction of a legal predicate can be defined using CSK rules, then the machine will search for cases that illustrate that the facts of the case at hand are actually an example of a situation that the legal predicate has covered in the past. The third states that if a tentative answer is derived using non-legal knowledge, then the machine will search for cases that call for the opposite answer.  <br /> <br />To test and benchmark her strategy, the author works in the field of `offer and acceptance' and `contract law', and deals specifically with the case `Adams vs Lindsell'. To construct the reasoning patterns, she brings in a highly interesting construction that she calls a `augmented transition network' (ATN). An ATN represents the standard states in a contract situation and the interpretations of events are represented as links between the states. The ATN that she constructs has twenty-three sates, twenty legal rules, and one hundred generalized `fact patterns.' The latter are associated with each legal predicate, and can be supported by several cases.  <br /> <br />The author gives detailed analysis of her approach, and remarks that its use has not produced situations wherein a `tentative' truth value is defeated. Several test problems are analyzed at the end of the book, these dealing mostly with how the reasoning patterns analyze events, and one that deals, interestingly, with legal study aids. From her conclusions it is readily apparent that legal reasoning is very difficult to implement in artificial intelligence, for the primary reason that deduction does not by itself determine the outcome of a case. Another reason is the role of legal precedent, which can give a new interpretation to the language of old rules.  <br /> <br />The author also makes commentary on the future of legal artificial intelligence. Considering the progress made in this field since this book was published, especially in the useof knowledge engineering in the practice of law, one can be confident that legal machines will make their presence known in the courts, in legal philosophy, and in constitutional interpretation in the years to come.	2005-07-19
162159:US	50702879	R22TXS4WYIR11	0821836749	320077209	88: Vertex Algebras and Algebraic Curves (Mathematical Surveys and Monographs) (Mathematical Surveys & Monographs)	Books	5	13	13	N	Y	Very well written and motivates the subject well.	Physicists view vertex algebras in many different ways, depending on their area of research. Some have used them without calling them as such, such as those dealing with the quantum operator equations of motion in the Heisenberg picture for potentials of higher order than quadratic. Researchers in string theory will view them in the context of two-dimensional conformal field theory, and in the use of the ubiquitous Virasoro algebra. Those in quantum field theory/elementary particle physics come across them in the context of the operator product expansion.<br /><br />Mathematicians view them in many different ways also. The exciting results in the construction of the Monster group by Richard Borcherds has an interpretation in the theory of vertex algebras. And, as the authors of this book point out, vertex algebras provide a rigorous formulation of two-dimensional conformal field theories. Most concepts in quantum field theory do not have such a rigorous formulation, and so any results that one can get in this regard are very useful to have.<br /><br />This book gives a highly detailed overview of the theory of vertex algebras, so much so that the book is highly dense and requires long blocks of time for readers (such as this reviewer) who are not experts. However, even though the authors are mathematicians, they motivate the subject very well, instead of presenting a \\"definition-theorem-proof\\" format. Indeed, at the beginning of the book the authors give a very good summary of the theory and at the beginning of every chapter the authors inform the reader just what they are going to do in that chapter.<br /><br />Loosely speaking, vertex operators can be viewed as generalizations of linear operators acting on a vector space, i.e. if V is a vector space, one can construct linear maps from V into the space of Laurent series with coefficients in V and from the space of bi-infinite Fourier series into the space of Laurent series with coefficients in V. One can also construct a bi-infinite formal series with coefficients in End(V) (the collection of endomorphisms of V), where these coefficients when acting on any element of V will vanish for large values of n. These different conceptions of a vertex operator are all equivalent, but the main issue at hand is the multiplication of vertex operators at the same point. The space End(V) is of course an associative algebra, and one can extend the products of elements of End(V) to the space of vertex operators via the \\"Wick product,\\" a construction that is very familiar to those readers working in quantum field theory. All of these considerations are made rigorous in the first chapter of the book, wherein also the axioms for vertex algebras are given explicitly. Noted in these axioms is the presence of a `vacuum vector' in the vector space V, reflecting of course the connection of vertex operators with quantum field theory. The authors also point out that the axioms of a vertex algebra are natural generalizations of the axioms of an associative commutative algebra with a unit. When a vertex algebra happens to be commutative, it is essentially equivalent to a commutative algebra with a unit and a derivation.<br /><br />The physicist reader will probably appreciate this book more than the mathematician reader, since, again, so many of the constructions have their place (albeit with a rigorous foundation) in physics. Indeed, vertex algebras appear as the chiral symmetry algebras of two-dimensional conformal field theories, such as the Heisenberg vertex algebra, which appears as the free bosonic theory; the Kac-Moody algebra, which appears as Wess-Zumino model, and the Virasoro algebra, appearing as the Belavin-Polyakov-Zamolodchikov minimal model. These are all vertex algebras that are associated to (infinite-dimensional) Lie algebras, and which are discussed in great detail in chapter two of the book.<br /><br />The operator product expansion, again a familiar construction in quantum field theory, wherein the product of two fields at nearby points can be expanded in terms of other fields, is studied in chapter three. The most interesting fact that comes out of this chapter is the power of the locality axiom for vertex algebras, which allows the construction of a vertex operator from knowledge on how it acts on the vacuum vector. This is called the Goddard Uniqueness Theorem, and is proved in this chapter. The authors prove the associativity property of vertex algebras and give examples of the operator product expansion: the Heisenberg, Kac-Moody, and conformal vertex algebras.<br /><br />The mathematician reader, especially one that is working the field of algebraic geometry, will not be disappointed in this book, as the authors connect vertex algebras with vector bundles and algebraic curves. In particular the authors show how to give a geometric realization to a vertex operator and consequently give a global geometric meaning to vertex operators on arbitrary algebraic curves. Central to this discussion is the notion of a conformal and more generally a quasi-conformal vertex algebra, and the action of a group of transformations on the vertex algebra that change coordinates by `internal symmetries.' This allows a coordinate-independent description of the vertex operation, and this is used to study spaces of coninvariants and conformal blocks associated with a quasi-conformal vertex algebra and a smooth projective curve. The conformal blocks form a vector space that give information on the algebraic curve, and the vector bundles on it. The authors spend a great deal of time discussing how the spaces of conformal blocks change as the complex structure on the curve changes. The authors do this by considering the space of conformal blocks as a sheaf on the moduli space of smooth pointed curves of some genus. This sheaf allows a kind of uniformization on the moduli space involving the action of the Lie algebra of derivations on this space. This is done both for Virasoro vertex algebras as well as affine Kac-Moody algebras. The book ends with a thorough discussion of chiral algebras, which give a coordinate-free approach to the operator product expansion on algebraic curves.lds at nearby points can be expanded in terms of other fields, is studied in chapter three. The most interesting fact that comes out of this chapter is the power of the locality axiom for vertex algebras, which allows the construction of a vertex operator from knowledge on how it acts on the vacuum vector. This is called the Goddard Uniqueness Theorem, and is proved in this chapter. The authors prove the associativity property of vertex algebras and give examples of the operator product expansion: the Heisenberg, Kac-Moody, and conformal vertex algebras.     The mathematician reader, especially one that is working the field of algebraic geometry, will not be disappointed in this book, as the authors connect vertex algebras with vector bundles and algebraic curves. In particular the authors show how to give a geometric realization to a vertex operator and consequently give a global geometric meaning to vertex operators on arbitrary algebraic curves. Central to this discussion is the notion of a conformal and more generally a quasi-conformal vertex algebra, and the action of a group of transformations on the vertex algebra that change coordinates by `internal symmetries.' This allows a coordinate-independent description of the vertex operation, and this is used to study spaces of coninvariants and conformal blocks associated with a quasi-conformal vertex algebra and a smooth projective curve. The conformal blocks form a vector space that give information on the algebraic curve, and the vector bundles on it. The authors spend a great deal of time discussing how the spaces of conformal blocks change as the complex structure on the curve changes. The authors do this by considering the space of conformal blocks as a sheaf on the moduli space of smooth pointed curves of some genus. This sheaf allows a kind of uniformization on the moduli space involving the action of the Lie algebra of derivations on this space. This is done both for Virasoro vertex algebras as well as affine Kac-Moody algebras. The book ends with a thorough discussion of chiral algebras, which give a coordinate-free approach to the operator product expansion on algebraic curves.	2005-07-17
174301:US	50702879	R1FRHXILPQKUMA	0192804960	800563171	Brainwashing: The Science of Thought Control	Books	5	91	101	N	N	Will strongly influence your ideas on brainwashing	Beginning with the stories of brainwashed American soldiers in the Korean War and ending with positive suggestions on how to avoid brainwashing, the author of this book takes the reader through a fascinating and very informative overview of the subject. Avoiding long-winded philosophical musings on free will and determinism, she instead supports her case on the reality of brainwashing with what is known about the human brain via research in neuroscience. The book is rich in information and gives the reader an understanding of to what degree the human mind can be controlled and manipulated. The author gives several examples of mental manipulation, all of these being quite frightening scenarios. It is the opinion of this reviewer that the election results of last year serve as a good contemporary example of how the press, government, public relations firms, and well-financed private interest groups can exert intense influence on the minds of a large portion of the American public. The outcome of that election serves as a grim reminder of how a passive, uncritical frame of mind can be filled with ideas and impressions that bear no resemblance to reality.<br /><br />When reading the book, it is interesting to learn that the Chinese Communists did not view their methods as being coercive. They however viewed their \\"re-education\\" efforts as being \\"morally uplifting\\", and evidently applied them with the conviction that they were releasing their victims of \\"reactionary\\" or \\"imperialist\\" thoughts. This brings the issue of whether indeed anyone can claim that a certain collection of ideas is \\"bad\\", while another collection is \\"good\\". The author addresses this issue of \\"relativism\\" or \\"moral incommensurability\\" in the book, and acknowledges that there is a temptation to believe that it serves to enhance respect for other opinions. She cautions however that prospective brainwashers take full advantage of moral relativism, as it enables them to practice their mind-numbing indulgences without any outside interference. The author therefore rejects moral relativism, leaving judgments as to what kind of ideas are the most sensible to be those that reflect what the majority of people actually desire. She does not however dismiss the relevance of individual differences, acknowledging that two people may have different `value profiles', and that these may conflict from time to time. In addition, values become more abstract or ethereal as one moves from the individual to the group, the author asserts, and in the process of abstraction individual differences become lost. This has the consequence that the ethereal ideas cannot really be judged as good or bad, and thus their propagation may result in severe harm. This harm can be minimized according to the author by using the methods of politics. Her assertion here has a certain irony to it, given that many (including this reviewer) have believed consistently that those in the political profession are the major proponents and practitioners of brainwashing (with last year's election again giving a powerful example). The author though is pragmatic, and notes that not all ethereal ideas are dangerous. Some can benefit society, and so the goal should be to minimize the harmful consequences and allow the beneficial ideas to flourish. Her strategies for doing this she encapsulates into what she calls `FACET', which stands for Freedom, Agency, Complexity, Ends-not-means, and Thinking. She describes at length what is involved in this approach, emphasizing its pragmatism, but also giving some evidence of its efficacy.<br /><br /> Through her discussion of neuroscience, the author dispels any notion of the Cartesian `diamond minds' metaphor that has plagued Western thought for the last four centuries. Indeed, if the claims of contemporary research in cognitive neuroscience are correct, then the human brain is indeed a very dynamic object, sometimes undergoing radical change. As an example of this, the author quotes the `phantom limb' scenario. Altering personal identity however is impossible if the proponents of the diamond mind are correct. The author again though gives evidence to the contrary, this evidence coming from what is known about the brain. In the process of doing this, she gives an interesting introduction to what she calls the `schematic self'. This concept is motivated by the fact that human beings seem to take on a variety of different `identities' depending on the social situation in which they find themselves. These roles or `schemas' include a collection of behaviors, and the thoughts, attitudes, and emotions that accompany them. These schemas can contain beliefs that are incompatible however, especially if they are correlated with different situations that individuals find themselves in. This incompatibility helps to explain the somewhat perplexing or contradictory behavior that is observed in many people. There is a temptation to label an individual as a `hypocrite' when having observed him acting in one situation, he behaves totally different in another, this behavior being seemingly at odds with the behavior in the first situation. Therefore, the author concludes, it should not surprising that brainwashing can work, given this capacity for variation in the `self.' The reader interested solely in scientific explanations will of course demand that the author justify this schema theory with evidence from neuroscience. She does so, but only briefly, and concludes that the schemas are patterns of connections between neurons, and that the stronger the connections, the more automatically the schemas will be triggered under the activation by certain stimuli. Some of these stimuli might be subtle, such as those arising from advertising. These might strengthen the \\"weak\\" schema, but the individual does not experience it as a change in self. However, stimuli resulting from the use of force act to change the strong schemas. Brainwashing by force thus may radically change the individual's strongest beliefs, and the author again gives evidence from neuroscience that supports the assertion that this can indeed happen. Lacking in this discussion are actual case studies, but the arguments seem plausible. Further research is of course necessary, but overall the author seems to make a convincing case for the reality of brainwashing. It can be countered given the initiative howeverthor quotes the `phantom limb' scenario. Altering personal identity however is impossible if the proponents of the diamond mind are correct. The author again though gives evidence to the contrary, this evidence coming from what is known about the brain. In the process of doing this, she gives an interesting introduction to what she calls the `schematic self'. This concept is motivated by the fact that human beings seem to take on a variety of different `identities' depending on the social situation in which they find themselves. These roles or `schemas' include a collection of behaviors, and the thoughts, attitudes, and emotions that accompany them. These schemas can contain beliefs that are incompatible however, especially if they are correlated with different situations that individuals find themselves in. This incompatibility helps to explain the somewhat perplexing or contradictory behavior that is observed in many people. There is a temptation to label an individual as a `hypocrite' when having observed him acting in one situation, he behaves totally different in another, this behavior being seemingly at odds with the behavior in the first situation. Therefore, the author concludes, it should not surprising that brainwashing can work, given this capacity for variation in the `self.' The reader interested solely in scientific explanations will of course demand that the author justify this schema theory with evidence from neuroscience. She does so, but only briefly, and concludes that the schemas are patterns of connections between neurons, and that the stronger the connections, the more automatically the schemas will be triggered under the activation by certain stimuli. Some of these stimuli might be subtle, such as those arising from advertising. These might strengthen the \\"weak\\" schema, but the individual does not experience it as a change in self. However, stimuli resulting from the use of force act to change the strong schemas. Brainwashing by force thus mayradically change the individual's strongest beliefs, and the author again gives evidence from neuroscience that supports the assertion that this can indeed happen. Lacking in this discussion are actual case studies, but the arguments seem plausible. Further research is of course necessary, but overall the author seems to make a convincing case for the reality of brainwashing. It can be countered given the initiative however	2005-07-08
174515:US	50702879	R331OKBFGP37BR	0387004513	553300370	Monte Carlo Methods in Financial Engineering (Stochastic Modelling and Applied Probability) (v. 53)	Books	5	30	36	N	Y	An excellent overview	Monte Carlo simulations are extensively used not only in finance but also in network modeling, bioinformatics, radiation therapy planning, physics, and meteorology, to name a few. This book gives a good overview of how they are used in financial engineering, with particular emphasis on pricing American options and risk management. Aspiring financial engineers will find much that is helpful in the book, and after reading it should be able to apply the methodologies in the book in whatever financial institution they find themselves employed. The mathematics may be too formidable for a practical trader, but the book is targeted to readers who intend to work as financial engineers in a high-powered financial institution. Due to constraints of space, only the last two chapters will be reviewed here.<br /><br />The next-to-last chapter discusses the difficult problem of pricing American options, which the author introduces as an `embedded optimization problem': the value of an American option is found by finding the optimal expected discounted payoff, in order to find the best time to exercise the option. When applying Monte Carlo simulation, the author restricts himself to options that can only be exercised at a finite, fixed set of opportunities, with a discrete Markov chain used to model the underlying process representing the discounted payoff from the exercise of the option at a particular time. This allows the use of dynamic programming, which the author does throughout the chapter, with the further simplification that the discounting is omitted. The author also shows how to find the optimal value by finding the best value within a parametric class, giving in the process a more tractable problem. This approach considers a parametric class of exercise regions or stopping rules. The author's discussion is somewhat too brief, but he does quote many references that the reader can easily consult.<br /><br />Also discussed are random tree methods, which simulate paths of the underlying Markov chain, and which allow more control on the error as the computational effort increases. The random tree method gives two consistent estimators, one biased high and one biased low, with both converging to the true value, and attempts to find the solution to the full optimal stopping problem and estimate the true value of an American option. The author discusses briefly the numerical tests that support this method. Similar to this method are stochastic mesh methods, the difference being that stochastic mesh methods utilize information coming from all nodes in the next time step. These methods are given detailed treatment in this chapter, along with detailed discussion of their limitations and computational complexity. Regression-based methods, which estimate continuation values from simulated paths, are discussed within the framework of stochastic mesh. These methods allow the estimation of continuation values from simulated paths and consequently to price American options by Monte Carlo simulation.<br /><br />Still another method that is discussed in this chapter is that of state-space partitioning, which, as the name implies, involves the partitioning of the state space of the underlying Markov chain. Monte Carlo simulation then allows the calculation of the transition probabilities and the averaged payoffs, and then these calculations are used to obtain estimates of the approximating value function. The author discusses the problems with this approach, these arising mostly in high-dimensional state spaces, as expected.<br /><br /> The last chapter will be of particular interest to risk managers, wherein the author applies Monte Carlo simulation to portfolio management. The measurement of market risk in his view boils down to finding a statistical model for describing the movements in individual sources of risk and correlations between multiple sources of risk, and in calculating the change in the value of the portfolio as the underlying sources of risk change. Most interesting in the discussion is the use of heavy-tailed probability distributions to model the changes in market prices and risks. A few methods for calculating VAR are discussed, which is then followed by how to use Monte Carlo simulation for estimating VAR. The author reminds the reader of the pitfalls in using probability distributions based on historical data for sampling price changes. A variance reduction technique based on the delta-gamma approximation is used to reduce the number of scenarios needed for portfolio revaluation. The author first treats the case where the risk factors are distributed according to multivariate normal distribution, and then latter the case where the distribution is heavy-tailed. The delta-gamma approximation captures some of the nonlinearity in a portfolio that contains options. This nonlinearity arises because of the dependence of the option on the price of the underlying asset. Keeping the quadratic terms in the Taylor expansion of the portfolio change yields the delta (first derivative) and gamma (second derivative) terms (the sensitivities). One then must find the distribution of a quadratic function of normal random variable, which the author does numerically via transform inversion. Particularly interesting in this discussion is the use of `exponential twisting' to obtain a dramatic reduction in variance. One then samples from the `twisted distribution' provided the `twisting parameter' is chosen intelligently. The author gives references, and discuses in slight detail, results that show the asymptotic optimality for this method.<br /><br />The case for a heavy-tailed distribution if of course much more involved, since there are no moment generating functions for the quantities of interest. The author gets around this by using an `indirect' delta-gamma approximation, which involves expressing the quantities of interest in terms of a new random variable that is more convenient to work with. The author also discusses various methods for doing variance reduction in the heavy-tailed case, one of these methods again involving exponential twisting. The chapter ends with a discussion of credit risk. The main item of interest here is the calculation of the time of default, which the author discusses in terms of the default intensity and intensity-based modeling using a stochastic intensity to model the time to default.s of risk change. Most interesting in the discussion is the use of heavy-tailed probability distributions to model the changes in market prices and risks. A few methods for calculating VAR are discussed, which is then followed by how to use Monte Carlo simulation for estimating VAR. The author reminds the reader of the pitfalls in using probability distributions based on historical data for sampling price changes. A variance reduction technique based on the delta-gamma approximation is used to reduce the number of scenarios needed for portfolio revaluation. The author first treats the case where the risk factors are distributed according to multivariate normal distribution, and then latter the case where the distribution is heavy-tailed. The delta-gamma approximation captures some of the nonlinearity in a portfolio that contains options. This nonlinearity arises because of the dependence of the option on the price of the underlying asset. Keeping the quadratic terms in the Taylor expansion of the portfolio change yields the delta (first derivative) and gamma (second derivative) terms (the sensitivities). One then must find the distribution of a quadratic function of normal random variable, which the author does numerically via transform inversion. Particularly interesting in this discussion is the use of `exponential twisting' to obtain a dramatic reduction in variance. One then samples from the `twisted distribution' provided the `twisting parameter' is chosen intelligently. The author gives references, and discuses in slight detail, results that show the asymptotic optimality for this method.<br /><br />The case for a heavy-tailed distribution if of course much more involved, since there are no moment generating functions for the quantities of interest. The author gets around this by using an `indirect' delta-gamma approximation, which involves expressing the quantities of interest in terms of a new random variable that is more convenient to work with. The authoralso discusses various methods for doing variance reduction in the heavy-tailed case, one of these methods again involving exponential twisting. The chapter ends with a discussion of credit risk. The main item of interest here is the calculation of the time of default, which the author discusses in terms of the default intensity and intensity-based modeling using a stochastic intensity to model the time to default.	2005-07-08
178580:US	50702879	R1BZQQGL07UYPN	0375758259	389338120	When Genius Failed: The Rise and Fall of Long-Term Capital Management	Books	4	15	23	N	Y	Mathematics vs intuition...was there a clear victor?	Were the individuals who initiated and ran Long Term Capital Management geniuses, as the title of this book indicates? When reading the book, the reader is led to believe, via their quoted statements, that they themselves thought they were geniuses. Did the eventual behavior of the markets convince them otherwise? Did the downfall of LTCM inject them with an overwhelming dose of humility? Without knowing them this would be hard to say. But one can say with a large degree of confidence that no amount of intellectual ability will negate the fact that the financial markets are a collective, emergent entity.  The markets do not care about the accolades or credentials of the traders that invest in them. The only reason for displaying these credentials is to convince investors to take part in a financial scheme, whether it is a private investment group, a new business, or some other entity that requires expertise in finance. When reading this book, it is apparent that the prospective investors in LTCM viewed its proprietors with an uncritical adulation, and did not ask the probing questions that they should have before they made the decision to invest. They should have ignored the fact that a few of these proprietors were their former professors or tutors, and concentrated instead on the content of their proposals, for it is only this that is relevant. If indeed the investors were overly impressed by the titles and awards possessed by the members of LTCM, then they clearly made a mistake. They should have only been concerned with the content of the proposals made by LTCM. If they did not have the mathematical knowledge to understand the proposals, they should have either obtained it on their own or have withdrawn their investment.  The list of investors is quite amazing when viewed in retrospect: Sumitomo Bank, Dresdner Bank, Liechtenstein Global Trust, Julius Baer, Republic New York Corporation, Banco Garantia, Michael Ovitz, Phil Knight, Robert Belfer, James Cayne, St. John's University, Yeshiva University, University of Pittsburgh, Paragon Advisors, PaineWebber, Donald Marron, Black & Decker, Continental Insurance of New York, and Presidential Life Corporation are examples. The interest of these institutions and investors is fascinating given that derivatives trading and sophisticated mathematical modeling was relatively new at the time. Their decision to invest therefore had weak historical precedent, and therefore it is easy to believe the author's contention that this decision was based on their uncritical adulation of the LTCM members. The \\"mystique\\" of these members was taken \\"to a very high extreme\\", writes the author.<br /><br />The author attempts to give the reader insight into the personalities of the LTCM members, and his descriptions of them work to a certain degree. Such insight is necessary to gain a proper understanding of their behavior. But a description of their overt behavior and demeanor still leaves the reader wanting as to whether their appearance, i.e. the way they portrayed themselves to others, did reflect what they truly believed inside. Was their behavior part of their salesmanship, a conscious strategy to portray themselves as savvy business people who had great insight into the workings of the financial markets, masking their hidden insecurities on these workings? Or was their behavior reflective of what they truly were, i.e. individuals who through their training in finance and mathematics, were confident in themselves and in the concept of LTCM. For example, was John Meriwether indeed a quiet, private individual with a \\"steel-trapped\\" mind as the author portrays him, or was this merely a facade that Meriwether thought would give him a sphinx-like aura of mystery? And if the latter is true, why did Meriwether think that such behavior was necessary? What historical precedent did he follow in this regard? Does such behavior result in better financial contracts? A better understand of the markets? The markets of course do not care about the personalities of the traders that participate in them. The markets do not hold any special affection for a James McEntee, who \\"traded from his gut.\\" Nor do they care about the commentary of a Seth Klarman, who accused the mathematical models of LTCM as being blind to \\"outlier events.\\" And they certainly do not respect the boasting of a Greg Hawkins, who proclaimed that LTCM made more money because its members \\"were smarter.\\"<br /><br />The book is interesting even from a contemporary perspective, in that it brings out the still ongoing tension between those who prefer a more mathematical/scientific approach to trading and those who \\"trade from the gut.\\" The financial modelers still refer to the latter as \\"uniformed speculators\\", \\"noise traders\\", or \\"nonscientific, old-fashioned gamblers.\\" The gut-traders still scold the modelers as a \\"dressed-up form of gambling\\" or as \\"pure academics\\" and \\"not applicable to the real world.\\" The debate between these two groups though is evolving, due in part to the rapid automation of the financial markets. More trust is being given to machines that can not only crunch the numbers but can also exercise the \\"intuitive judgment\\" that some traders still insist is the way to go in trading. It will be interesting to see if these machines can deal with the markets in a manner that is superior to what humans have done for centuries. Genius arising from silicon will compete with genius arising from carbon. But one thing is certain: if machine trading results in instabilities in the markets, with huge losses to the institutions that own them, there is little doubt that these failures will be protected by the same boards of governance that rescued LTCM. To paraphrase the author, high finance rewards success, but in the twenty-first century, failure will be protected as well.e markets of course do not care about the personalities of the traders that participate in them. The markets do not hold any special affection for a James McEntee, who \\"traded from his gut.\\" Nor do they care about the commentary of a Seth Klarman, who accused the mathematical models of LTCM as being blind to \\"outlier events.\\" And they certainly do not respect the boasting of a Greg Hawkins, who proclaimed that LTCM made more money because its members \\"were smarter.\\" <br /> <br />The book is interesting even from a contemporary perspective, in that it brings out the still ongoing tension between those who prefer a more mathematical/scientific approach to trading and those who \\"trade from the gut.\\" The financial modelers still refer to the latter as \\"uniformed speculators\\", \\"noise traders\\", or \\"nonscientific, old-fashioned gamblers.\\" The gut-traders still scold the modelers as a \\"dressed-up form of gambling\\" or as \\"pure academics\\" and \\"not applicable to the real world.\\" The debate between these two groups though is evolving, due in part to the rapid automation of the financial markets. More trust is being given to machines that can not only crunch the numbers but can also exercise the \\"intuitive judgment\\" that some traders still insist is the way to go in trading. It will be interesting to see if these machines can deal with the markets in a manner that is superior to what humans have done for centuries. Genius arising from silicon will compete with genius arising from carbon. But one thing is certain: if machine trading results in instabilities in the markets, with huge losses to the institutions that own them, there is little doubt that these failures will be protected by the same boards of governance that rescued LTCM. To paraphrase the author, high finance rewards success, but in the twenty-first century, failure will be protected as well.  <br />	2005-07-06
180449:US	50702879	RNOLJMROZ0LB5	006055438X	57180289	State of Fear	Books	2	4	14	N	Y	Unsubstantiated commentary in the appendix of the book	This reviewer did not read the story in this book, but only the \\"author's message\\" and roughly ten percent of the references he includes in the book. Therefore, no commentary will be made on the story, except to say that a story need not be scientifically factual or accurate if it is to be enjoyed. Realism has its place in literature, but given the massive amounts of bias, conspiracy theories, and lies that permeate the press and the Internet at the present time, a story of pure fantasy would be a welcome relief.<br /><br />The author claims to have read environmental texts for three years, and has in his words examined a \\"lot of data.\\" If one examines his conclusions though, it is apparent that he has a somewhat sophomoric view of what constitutes scientific research, what scientific paradigms are currently operative, and the proper mathematical frameworks to use in climate research. In addition, even though there are some references included in the book, he does not correlate them with his list of conclusions. He also speaks very qualitatively at times, which is inappropriate considering the need for meticulous detail and quantitative analysis when doing scientific research, especially in a politically sensitive subject such as global warming. For example, he claims that we know \\"astonishingly little\\" about the environment, and that both sides of the debate overstate the \\"degree of certainty.\\" The author though does not propose any rigorous, quantitative measure of uncertainty. It is one thing to assert the inaccuracy of modeling, it is quite another to propose constructive and useful models for studying climate. The author has done none of this.<br /><br />He claims also that atmospheric carbon dioxide is increasing, and that human activity is the \\"probable cause\\".  Is it really, and what does he mean by \\"probable\\" here? Is it a Bayesian notion of causality, which is frequently used in data analysis, or some other notion? What data is there to support the assertion that carbon dioxide is increasing? He does not cite the research papers that would allow him to conclude this, however plausible it may sound. Even worse, he states that the computer models vary by 400%. How did he arrive at this figure? Which models is he referring to? It is the norm rather than the exception that these models are probabilistic models, and so to compare them one must compare probability distributions. The \\"percentage difference\\" between them must then be defined more carefully than what is so cavalierly used by the author here.<br /><br />And speaking of models, the author asserts that science has undergone a \\"major revolution\\" in the last 35 years. This revolution takes the form of models based on chaotic dynamical systems and catastrophe theory. These developments, he claims, have \\"transformed the way we think about evolution and ecology.\\" This is an exaggeration to say the least, as it is still unclear whether climate dynamics is actually chaotic, and in fact this claim has been hotly debated in the research literature. In addition, catastrophe theory has not made an impact as many decades ago thought it would. The author has not quoted any research papers in relation to this claim. Certainly chaotic dynamical systems have been widely applied to many different fields, such as finance, ecology, and biology, but the validation of these applications is extremely difficult, and this difficulty has thwarted the use of these applications.dioxide is increasing? He does not cite the research papers that would allow him to conclude this, however plausible it may sound. Even worse, he states that the computer models vary by 400%. How did he arrive at this figure? Which models is he referring to? It is the norm rather than the exception that these models are probabilistic models, and so to compare them one must compare probability distributions. The \\"percentage difference\\" between them must then be defined more carefully than what is so cavalierly used by the author here.     And speaking of models, the author asserts that science has undergone a \\"major revolution\\" in the last 35 years. This revolution takes the form of models based on chaotic dynamical systems and catastrophe theory. These developments, he claims, have \\"transformed the way we think about evolution and ecology.\\" This is an exaggeration to say the least, as it is still unclear whether climate dynamics is actually chaotic, and in fact this claim has been hotly debated in the research literature. In addition, catastrophe theory has not made an impact as many decades ago thought it would. The author has not quoted any research papers in relation to this claim. Certainly chaotic dynamical systems have been widely applied to many different fields, such as finance, ecology, and biology, but the validation of these applications is extremely difficult, and this difficulty has thwarted the use of these applications.	2005-07-04
183444:US	50702879	RXZJQCKK6J4Q	0374153892	282518591	Gilead: A Novel	Books	5	14	15	N	Y	A deeply touching story	Deeply touching and powerful in its prose, this story will take the reader to a world where one can almost hear a dandelion seed glance against a tree leaf; a world where children's chores were still required and marriage was viewed as sacred. It is a world that is dying, with its memories passed on only in writing. The gentle brushes of the wind in this world are being replaced by the chaotic vortices of change in the twenty-first century. Its nuances are not to be experienced any more. But a close approximation can be, by the reading of this story.<br /><br />One should not view John Ames in the confines of his Christian beliefs, for these beliefs were only part of who he is. They were his personal schema; sometimes active, sometimes brought into his attentive consciousness, but at times replaced by others. One could easily view his beliefs as flexible, as tolerating different worldviews, or as ones where Christian steps can take different routes. \\"There are many ways to live a good life,\\" he writes in the first paragraph.<br /><br />Being a minister, people insisted that he be a \\"little bit apart.\\" He was not permitted to engage in humor, or appreciate the same. People changed the subject when they saw him coming, but also were able to confide in him things that they would never to anyone else. Religion is frequently a catharsis, but not always. He recognizes also the destructive power of anger, which them must be constrained by an upper bound, both in degree and frequency.<br /><br />And religious beliefs, like all others, find their origin in the surroundings, in the context in which one finds oneself. He was a \\"pious child\\" from a \\"pious household\\" in a \\"pious town\\". Such an environment affected his behavior greatly, he writes.<br /><br />He has read Ludwig Feuerbach as well as Karl Barth, and he holds the optimism of the former to be just as valuable as the wisdom of the latter. The atheism of Feuerbach he tolerates, because Feuerbach \\"loves the world.\\" His optimism is refreshing and realistic. He wakes up every morning and celebrates his existence and the efficacy of his mind. Grief and loneliness are rare in this life; peace and comfort are the norm. And in a moment of exuberance, he tries to dance to a waltz, not having been trained in the steps. No mind as optimistic as his can finish life without a dance. It is impossible.<br /><br />Even his conception of God is interlaced with his optimism; bound tightly by it. It is one where God is not judgmental, but one where God takes pleasure in the viewing of his creatures. We are all \\"actors on a stage, \\" and \\"God is the audience.\\"<br /><br />In the most awesome passage from the book, he declares with humility and with understatement that \\"this is an interesting planet. It deserves all the attention you can give it.\\"<br /><br />He's right.orld.\\" His optimism is refreshing and realistic. He wakes up every morning and celebrates his existence and the efficacy of his mind. Grief and loneliness are rare in this life; peace and comfort are the norm. And in a moment of exuberance, he tries to dance to a waltz, not having been trained in the steps. No mind as optimistic as his can finish life without a dance. It is impossible.  <br /> <br />Even his conception of God is interlaced with his optimism; bound tightly by it. It is one where God is not judgmental, but one where God takes pleasure in the viewing of his creatures. We are all \\"actors on a stage, \\" and \\"God is the audience.\\"  <br /> <br />In the most awesome passage from the book, he declares with humility and with understatement that \\"this is an interesting planet. It deserves all the attention you can give it.\\"  <br /> <br />He's right.  <br />	2005-07-02
191043:US	50702879	R1LP15CLP89NKS	0195178238	521334662	The First Crusade: A New History	Books	4	1	9	N	Y	An engaging account of unmitigated brutality	Following the hype and propaganda of Pope Urban II in 1095, tens of thousands of people began a trek to recapture Jerusalem very shortly thereafter. Their decision to engage in the \\"Crusades\\" is very perplexing if viewed from the standpoint of a strict reading of the New Testament, but no surprise at all if viewed from the standpoint of the present time. Modern events give plenty of hints as to the power of propaganda in influencing human decision-making. The people in 1095 of course did not have the electronic media of today, but they did have individuals like Pope Urban II and Peter the Hermit, who were its medieval equivalents.<br /><br />Containing many references, and also offering insight into medieval attitudes and ethical standards, this book gives a highly interesting account of the First Crusade. The author is not content with a mere listing of facts, but attempts to understand how the First Crusade got started, what military strategies were used, and its political, historical, and moral legacy. He definitely views the First Crusade as a \\"holy war\\" and a war that was whipped up by the propaganda of Pope Urban II. The message of this Pope was that Muslims were brutal oppressors, which according to the author was \\"pure propaganda.\\" Muslims at that time he writes were far more tolerant of other religions than Catholic Christendom.<br /><br />The author paints a bleak picture of France at the time of the First Crusade: a violent feudalistic society polluted with endless strife and conditioned by daily doses of the Christian religion. This was not a time to be envied by anyone, and the people living then had to face difficulties that are totally beyond anything anyone faces today. The hypocrisy and greed of the Catholic church at that time is readily apparent, and it is indeed a wonder that the conduct of the priests and bishops of that institution had the power that they did. The general populace was illiterate however, so this may explain their willingness to subjugate themselves to the petty doctrines and stale platitudes of the Catholic church hierarchy. The author gives detailed discussion of how Pope Urban II justified military action against Jerusalem in the context of Christian dogma, which is very pacifistic in its leanings, at least from a reading of the New Testament scriptures. To hold to the belief that the goal of capturing Jerusalem was to revenge its' taking by Muslims seems ridiculous, given that the Muslims did this 400 years before. The author points this out in the book, and discusses other counterexamples to the notion that there was any real threat to Latin Christendom. In the author's view, the First Crusade was carried out to serve the needs of the papacy and to expand the influence of the Roman church. The author describes the Latin Church as \\"energetically encouraging\\" military conflict and promoting \\"carnage as an expression of pious devotion.\\" He also notes that the writings of St. Augustine, in his concept of a just war, had a great influence in the eleventh century. Indeed, the intervening centuries allowed the \\"concept of sanctified violence\\" to take hold. Of course, Pope Urban II did not participate in the fighting, his cowardice representing a character trait that is shared by most of today's leaders.<br /><br />The only minus to the book is that the siege of Jerusalem is not described in much detail. The reader is left with the impression that the downfall of Jerusalem was not documented with as much detail as the rest of the First Crusade. Considering some of the original descriptions of the siege, with the extreme language that they use, this belief may be somewhat justified. But all of these accounts of the downfall of Jerusalem describe a situation of unmitigated brutality, wherein babies were smashed against the wall, Muslims were beheaded, and even gentiles were massacred. These acts, along with the Catholic church that supported them, deserve eternal condemnation. The pope, the Catholic church, and all who participated in the First Crusade should never be forgiven for these atrocities.holic church, and all who participated in the First Crusade should never be forgiven for these atrocities.	2005-06-26
191901:US	50702879	R2JIBU0XW1KM25	0967504406	282688887	Marell: Eccentric Erotica	Books	5	2	3	N	N	Will "remove the condoms from your mind."	Readers, regardless of their level of experience, will, if they \\"remove any condoms from their mind\\", find themselves opening up to the characters in these stories, and much is to be learned from each of them. Indeed, there are ample lessons in geometry in each one of these stories: there are triangles interacting with cylinders, triangles interacting with triangles, and peas decorating triangles. The cylinders are sometimes real and at other times artificial. Sometimes they find permanent attachment and at other times portable. Some cylinders are wooden, brought into being with the skilled hands of a feminine, lustful artisan, who is tutored brilliantly by an elusive and timid furniture maker. These cylinders do not go to waste though, for their maker indulges in them with a vengeance. This goes for the other cylinders (and triangles): they all find fulfillment in the stories, as will the cylinders or triangles of the reader. The peas too share with the cylinders the ability to reach out into space and make themselves more visible. The peas are of course readily attended to, as will be the peas of some readers. And luckily, at least one of the characters enters through the back door, as they should. Zippers will come down, bras will become unhooked, and shoes will drop to the floor. The sounds of these will accompany the reading; that is assured. For some readers, caution though must be exercised (as something else inevitably will be) if this book is read vertically and on a tiled floor: such readers may slip and fall.	2005-06-25
198616:US	50702879	R3BUBEXUYB4PFS	0307275329	387937921	A Summer of Faulkner: As I Lay Dying/The Sound and the Fury/Light in August (Oprah's Book Club)	Books	5	8	9	N	Y	Hot and humid...indeed sweltering	Review of \\"As I Lay Dying\\":<br /><br />This is a story that should be read on a sweltering hot, humid day in the summer. But even if it isn't, the reader will still imagine such a day, as the words of the story, subtle but powerful, control the neuronal synapses of the reader. They capture the reader's imagination, framing it uniquely, and offering no flexibility in interpretation. And the characters? They are black stick figures, very suitable as participants in a Martha Graham dance: totally alien to experience, but somehow, through their actions, their dialog, and their introspection, instill appreciation in the reader's mind. Indeed, these characters are not \\"introduced\\". What the reader understands of them is to be found in their actions, their dialog, and their introspection.<br /><br />There is Darl, whose mind exhibits at first keen mathematical and geometric precision: he knows that he walks not approximately fifteen meters ahead of Jewel, but exactly fifteen meters ahead of him (the author again reminds the reader of this distance in the next paragraph, and later, when Jewel is ahead, but now by exactly five meters); the path on which Darl walks circles the cottonhouse at \\"four soft right angles\\". Darl is a quasi-Sartrian: experiencing the negation, for \\"sleep is is-not and rain and wind are was, it is not\\".<br /><br />There is the business sense of Cora, ala her optimization of the egg laying habits of her chickens. Her optimism also, and her faith in human nature, makes her overwhelmingly realistic.<br /><br />There are the carpentry skills of Cash, which beg for recognition, and once his carpentry projects are initiated, they are not to be interrupted, even by a torrential downpour, the latter of which is viewed, while Cash is sawing, as an \\"illusion of the mind.\\" Carpentry finds semantic equivalence to poetry: he made the coffin \\"on the bevel\\" (Faulkner inserts a diagram to make the coffin geometry readily apparent...believing written descriptions inadequate?). His exactitude in his profession does not compare with his judgments of normality: \\"But I ain't so sho that ere a man has the right to say what is crazy and what ain't\\".<br /><br />There is the delightful skepticism and nihilism of Jewel, who finds no utility in God. None at all.<br /><br />There is Anse, who worries about the neighbors: he wants to maintain an aura of respectability when transporting the coffin. The selection of the proper horse takes precedence over his grief. Socially conscious but also aware of exploitation: \\"it takes them that runs the stores in the towns, doing no sweating, living off of them that sweats.\\" Religion is his opiate and compensation for this: \\"there is a reward for us above.\\"<br /><br />There is Samson, alienated from his neighbors, and unable to grasp the Bundren grief and their individuality.<br /><br />There is Dewey Dell, self-aware and knowing her place, as not being as \\"good as town people,\\" and who feels like a \\"wet seed wild in the hot blind earth\\" (another Faulkner literary gem here). Dewey recognizes the anxiety of time: It is a \\"womb\\", a \\"hard girdle in which lie the outraged entrails of events.\\" The trip to Jefferson therefore is agonizing in its length, but she relieves her agony in a characteristically standard way: \\"I believe in God, God. God, I believe in God.\\"<br /><br />There is Tull, who is protected from the vicissitudes of the world by not thinking about them. Too much thinking he believes is not the will of God. The brain is like machinery, and it \\"won't stand a whole lot of racking.\\" It is not to be used more than necessary. Tull is to be contrasted with Darl, who \\"thinks by himself too much.\\"<br /><br />There is Vardaman, who cannot deal with tragedy (either successfully or unsuccessfully). His mother \\"is a fish\\": Vardaman conflates images in the world with images in his mind.<br /><br />There is the stark-deafening idealism of Peabody, whose view of death is that it is \\"merely a function of the mind\\", namely in the minds of those who are grieving for the one who is lost.<br /><br />And there is the dying woman, Addie Bundren: the narrative center.it is \\"merely a function of the mind\\", namely in the minds of those who are grieving for the one who is lost.  <br /> <br />And there is the dying woman, Addie Bundren: the narrative center.	2005-06-19
200181:US	50702879	R2VGMKWK6AVTCT	0976443732	420645813	Neocon Middle East Policy: The Clean Break Plan Damage Assessment	Books	4	18	21	N	N	A good start	As the authors of this book remark in their forward, this book studies the consequences of a particular document, called \\"A Clean Break, a New Strategy for Securing the Realm,\\" which was composed in 1996 by the Institute for Strategic and Political Studies. This think tank was located in Jerusalem at the time, and the purpose of the document was to advise the government of Benjamin Netanyahu, who was at that time the newly-elected Prime Minister of Israel. The document is reprinted in an appendix to the book, but can also readily be found on the Internet.<br /><br />Anyone whose is intellectual honest, both with her self and others, will no doubt find the thesis that one document can by itself have wide influence difficult to accept. Such skepticism would be justified, but it should also be remembered that the political concepts and philosophy expoused in \\"A Clean Break\\" is held by many individuals in both the United States and Israeli governments at the present time, and there is every indication that this influence will continue. There is little doubt now of the destructive and destabilizing effects of this philosophy, which has been called `neo-conservatism' both by the authors of this book and many others in the political science community. Indeed, the war in Iraq and the separating wall in Israel are ample evidence of the decadence of this philosophy. The authors show in fair detail some of its consequences, although at times some of their claims are left unjustified. They state explicitly though that they wish to avoid the \\"mono-causal\\" trap of holding to an \\"all-encompassing\\" historical explanation of the policies of the United States in the Middle East.<br /><br />It is not necessary to hold to all of the assertions made by the authors in order to obtain useful information from this book, concise as it is. It is a good start for a more extensive and future study of the influence of neo-conservative thought on the United States government. The book is composed of several different articles written by various individuals of different backgrounds, levels of expertise and religious affiliations, and this serves to give a broader range of opinion than might be found with only a few authors. There a many places in the book where statistical facts are omitted, such as the claim that the Palestinian economy suffers from 70 percent unemployment, and the claim that 70 percent of the Israeli population are willing to give up occupation in order to have peace with the Palestinians. The inclusion of careful statistical evidence would certainly make the authors case more credible and would convince the more scientific and skeptical reader of the truth of their assertions.<br /><br />If one peruses history, it is not surprising at all that a very small group of individuals, via their rhetoric and their hype, would put into play a series of events that stand with only a few others in their deceptive power and brutality. History is replete with examples of how these individuals, through both verbal and written communication, can influence a great majority of people to do things that they would not do under ordinary circumstances, and commit acts that are contrary to their chosen ethical standards. The vast majority of these examples share a common denominator, namely the exploitation of fear to bring to fruition a certain political, religious, or financial goal. The authors of \\"A Clean Break\\" are examples of how this is done. Fortunately their philosophies and their horrific consequences are now being discredited. This book is one of the few available that dares to expose the decadence of these philosophies. Hopefully there will be many more.omposed of several different articles written by various individuals of different backgrounds, levels of expertise and religious affiliations, and this serves to give a broader range of opinion than might be found with only a few authors. There a many places in the book where statistical facts are omitted, such as the claim that the Palestinian economy suffers from 70 percent unemployment, and the claim that 70 percent of the Israeli population are willing to give up occupation in order to have peace with the Palestinians. The inclusion of careful statistical evidence would certainly make the authors case more credible and would convince the more scientific and skeptical reader of the truth of their assertions.  <br /> <br />If one peruses history, it is not surprising at all that a very small group of individuals, via their rhetoric and their hype, would put into play a series of events that stand with only a few others in their deceptive power and brutality. History is replete with examples of how these individuals, through both verbal and written communication, can influence a great majority of people to do things that they would not do under ordinary circumstances, and commit acts that are contrary to their chosen ethical standards. The vast majority of these examples share a common denominator, namely the exploitation of fear to bring to fruition a certain political, religious, or financial goal. The authors of \\"A Clean Break\\" are examples of how this is done. Fortunately their philosophies and their horrific consequences are now being discredited. This book is one of the few available that dares to expose the decadence of these philosophies. Hopefully there will be many more.	2005-06-18
205865:US	50702879	R36FIZIL9RYV05	1893798283	611166122	Booby Trapped: Men Beware! The Dirty Seven Sisters: A Dating Guide for the 21st Century	Books	3	18	20	N	N	Some men like em...some don't	Unless the reader has had experience with the types of women that are described in this book, it might be difficult to believe that such women exist. Certainly there are women in the real world that share some of the characteristics of the \\"Dirty Seven Sisters\\" that are described in gritty and somewhat vituperative detail in the book, but these women can develop relationships with men in a manner which might be loosely described as \\"symbiotic\\". Some men in the upper income bracket for example may find the \\"Material Girl\\" very suitable for a long-term relationship. Such a woman, due to her need for money and material status, will do most anything that these men need, including engaging in the type of sex they desire and in serving as arm-candy for various outings on the town. The money that they spend on the \\"Material Girl\\" is viewed as a mere entertainment expense. Some wealthy men therefore prefer the \\"Material Girl\\" and will not heed any advice to avoid them. The same goes for the rest of the \\"Dirty Seven Sisters\\": some men, because of their tastes and outlooks, however peculiar to external observers, may prefer being subjugated to \\"The Mom\\", or having a temporary fling with \\"Shopaholica.\\"  Personal tastes dictate some strange combinations of partners at times, but these relationships can also evolve in ways that are not predictable, due to the tensions of life and the particular contexts in which they find themselves. In that respect the author finds the personalities and neuronal synapses of the \\"Dirty Seven Sisters\\" fixed in time and unchangeable. But it is rare to find a human being who does not and cannot adapt themselves to new challenges and new outlooks. The author though does not admit the possibility of change in these women, who she views as the most despicable of the female human species. This reviewer agrees somewhat with her assessment, but others may not, and again, may view these women as highly desirable, even knowing in full their \\"wickedness.\\" The author, and the reader, should remember that good character, like beauty, is in the eye of the beholder.<br /><br />In addition to the author's purely subjective biases against the \\"Dirty Seven Sisters\\" there are other problems with the book. One example is her claim that only ten percent of women qualify for admission into the club of the \\"Dirty Seven Sisters.\\" Years of research and observation she says, leads her to this conclusion. The largest contingent of these women exist in the developed countries, with only a small number, if any, residing in the \\"Third World\\". She does not offer any statistical studies substantiating these claims, and no references are given that would shed more light on her claims. The reader should really not expect this however, for this book is really aimed at those who are looking for the type of woman that the author would characterize as \\"good.\\" Those who enjoy the company of the \\"Dirty Seven Sisters\\", whether this is because of sex or some other form of entertainment, would perhaps welcome the presence of a statistical study in the book. This would allow them to estimate their best chances of finding one of these women, or the best places to find them.he author, and the reader, should remember that good character, like beauty, is in the eye of the beholder.       In addition to the author's purely subjective biases against the \\"Dirty Seven Sisters\\" there are other problems with the book. One example is her claim that only ten percent of women qualify for admission into the club of the \\"Dirty Seven Sisters.\\" Years of research and observation she says, leads her to this conclusion. The largest contingent of these women exist in the developed countries, with only a small number, if any, residing in the \\"Third World\\". She does not offer any statistical studies substantiating these claims, and no references are given that would shed more light on her claims. The reader should really not expect this however, for this book is really aimed at those who are looking for the type of woman that the author would characterize as \\"good.\\" Those who enjoy the company of the \\"Dirty Seven Sisters\\", whether this is because of sex or some other form of entertainment, would perhaps welcome the presence of a statistical study in the book. This would allow them to estimate their best chances of finding one of these women, or the best places to find them.	2005-06-13
207252:US	50702879	RL05YXJLN2OH2	0805063323	207010020	Dr. Tatiana's Sex Advice to All Creation: The Definitive Guide to the Evolutionary Biology of Sex	Books	5	2	2	N	Y	A fascinating collection of examples	The enjoyment of this book is, delightfully, inversely proportional to your ignorance of the subject matter. Those readers, like this reviewer, who are new to the subject matter will find example after example and surprise after surprise from the beginning to the end of this book. It is fascinating reading, and will definitely give you a deep appreciation of the human place in the living world. Human sexual practices are definitely somewhat boring if compared to those that occur in insects, fish, worms, and many other species of animals and plants.  The examples in this book are ample evidence of this. Since the power of this book is in the surprises it offers the reader, a review of it should not act as a spoiler by giving away any of the examples in the book. Therefore this reviewer will resist the temptation to discuss any of them. Suffice it to say that the author has written a brilliant book, one that should be perused by everyone. Many references are given at the end of the book for those who want to investigate the science behind the examples in more detail. The author also discusses, albeit briefly, the various theories behind the evolution of sex. The contents of the book are certainly ones that can be discussed in any social context, and this reviewer has found that such discussions are met with intense curiosity and intrigue by all of the participants in them.	2005-06-12
210766:US	50702879	R313W2W33DGOCJ	0195091957	768361367	The Logic of Reliable Inquiry (Logic and Computation in Philosophy)	Books	3	3	8	N	Y	Are the results in this book reliable?	How can a learner, be it a human or otherwise, be guaranteed of arriving at a correct result before it encounters novel situations or acquires new knowledge? How reliable is the learning process at the time it is adopted? The author, in this lengthy and detailed treatise, tries to answer these questions in the framework of what he calls `formal learning theory.' This branch of learning theory is more mathematical than others, and studies to what extent a learning system can be judged as reliable. This book certainly outlines the main results, but it is difficult to see their relevance, as the author does not relate them to practical learning systems. This is not a surprise of course, given the nature of formal learning theory. In addition, there are many places in the book that seem to be a mere relabeling of certain results in set-theoretic topology, thus making them appear vacuous from a mathematical standpoint.<br /><br />The author also agrees to the standard definition of induction (ala Sextus Empiricus), with its goal of establishing a \\"universal\\" in terms of a particular (finite) set of observations. Thus induction will not be a reliable learning strategy, since some of the particulars may be omitted and conflict with the universal. One cannot include all of the particulars, since they form an infinite collection. But there are other views of induction that are being used in contemporary learning theory and artificial intelligence. The author is apparently unaware (or does not consider it relevant) of the research in inductive logic programming that have given a deductive foundation to inductive, scientific reasoning based on `inverse resolution'. In a first order theory, hypotheses can be generated deductively using background knowledge and examples, and by using a particular notion of language bias to constrain the search for the hypotheses. These systems of hypothesis generation even have practical use, and serve as a counterexample to the author's contention that inductive inference is not deductive. Of course, the way he understands it, i.e. taken from the literature on the philosophy of science, it is certainly not deductive. Hence, induction, as viewed by the author, will never yield a certain result, i.e. one obtained by deduction, and so he endeavors to find measures of convergence for inductive systems that will \\"logically guarantee\\" convergence to the \\"truth.\\"<br /><br />The notion of truth as a scientist may hold to it is not really discussed in any detail in the book. Instead, some rather vague notions of truth, such as \\"correctness\\" or \\"predictiveness\\" are used, which are (in a major portion of the book) only supposed to depend on the hypothesis and the data stream. Data streams are taken to sequences of natural numbers that encode discrete \\"observations\\", and the author rather cavalierly allows the existence of infinite data streams, despite his assumption that truth or correctness is to be an \\"empirical' relation. The scientist is also viewed as a passive observer, with the data stream not depending on the actions that the scientist takes. This of course means that data streams coming from quantum systems will not be modeled by this approach. In addition, the difference between closed and open sets cannot be detected in real-world computations, thus casting further doubt on the relevance of the author's results to real scientific practice.<br /><br />Since the author wants to stay in the framework of mathematical logic, and since this is a book on philosophy, no attempt is made to compare the results derived in the book with historical practices in scientific research. Such a comparison would lend more credence to the formal models of hypothesis creation or theory construction that are put forward by the author. The construction of formal models for scientific research or other types of learning is fairly straightforward as this book shows. These models are abstracted from the processes that one observesin science and one can believe that they do represent what scientists actually do. However, if one is to have great confidence that these models are accurate, one must compare them to actual case histories in scientific research. This is not done in this book, and neither in any other one on the same topic that this reviewer is aware of. This aggravates the view held by many professional scientists that philosophers of science are engaging in sheer speculation and fantasies of thought. It is fair to say that such a view is very close to the truth, and unfortunately this book is evidence for that view.observes in science and one can believe that they do represent what scientists actually do. However, if one is to have great confidence that these models are accurate, one must compare them to actual case histories in scientific research. This is not done in this book, and neither in any other one on the same topic that this reviewer is aware of. This aggravates the view held by many professional scientists that philosophers of science are engaging in sheer speculation and fantasies of thought. It is fair to say that such a view is very close to the truth, and unfortunately this book is evidence for that view.	2005-06-09
216316:US	50702879	R2UCLGJD4L05KP	0743466861	40100291	Brown Sugar 3: When Opposites Attract	Books	5	0	1	N	Y	Skillful perturbation of the erotic imagination	The mixing of different shades of brown is always exciting to view or imagine. Indeed, the combination of deep black, sepia, coffee, caramel, or raw sienna is always a distinctly pleasurable experience, whether this combination is done with two colors at a time or even more. And all variations in tone are uniquely qualified to grant this ecstasy of visualization and participation.<br /><br />The intertwining of this part of the spectrum is expressed powerfully in this collection of short stories. It does not exhaust the imagination, as it should not, for readers must not let any book totally eliminate this part of the brain. There must always be a residual amount left after the story is told, for future reference that is, and for future fantasies. Good erotica is characterized by its ability to let readers both identify with the events in the story and to fill it in with private details as they see fit. It is therefore to be distinguished from pornography, which leaves nothing to the imagination, and which is typically a synonym for banality.<br /><br />The story by Lori Bryant-Woolridge stands out in particular in its ability to swindle, delightfully, the reader's imagination. Called \\"Close Encounters,\\" it deceives the reader into thinking that orgasm is near, that the characters identities are fixed, and that their desires are average. The story definitely takes the reader out of sexual equilibrium, and does not disappoint in its ability to deliver what it promises.<br /><br />Reading the book is like building a tent. Each story is like a stake that must be hammered into the ground to make the tent more taut. As these stakes are pounded into the dirt the tent becomes tenser; its surface becomes drum tight. The deeper the stakes go the tighter it gets, finally ripping under the tension. The reader is then left naked with no protection from the elements, but most assuredly satisfied.	2005-06-04
222164:US	50702879	R2UUOHVNJVG9RN	0300107900	359110617	The Spanish Inquisition: A History	Books	5	85	107	N	Y	Terror is frequently correlated with envy and religion	Discussion of the Spanish Inquisition usually invokes emotions of disgust or anger, but also an appreciation of how precious it is to be able to pick up a book or express an opinion without fear of being either tortured or killed by government authorities. Therefore reading a book on the topic can be difficult at times, if one focuses on the brutality of the methods used and the zeal in which they were. This book, by comparison with most others on the Spanish Inquisition, is very short, but it does introduce the reader to the reasons for it and its historical legacy.<br /><br />The author summarizes the Spanish Inquisition as being \\"350 years of terror,\\" which is an accurate description considering the horrific acts that were committed in this time period. These acts are delineated in detail in this book, beginning essentially with the papal bull in 1478 that was targeted towards Jewish converts to Christianity. Those Jews found guilty of \\"reversion\\" were promptly executed. The three dominant religions, Islam, Christianity, and Islam were of course in existence at this time, and were, according to the author, not tolerant of each other and each was convinced that it held the keys to truth. If there was tolerance to any degree, it was a \\"de facto\\" tolerance argues the author, i.e. \\"suffered rather than desired.\\" It is interesting to note that de facto tolerance is also the predominant form for these religions in the world today.<br /><br />The social tensions between Jews and Christians in Spain at this time are brought out in detail in the book. On the surface these tensions even seem comical because of their absurdity. As examples of this idiocy, marriages between Jews and Christians were forbidden; Jews could charge interest on a loan to Christians, and vice versa, but never to members of the same faith; and Jews were blamed for economic recessions, and for spreading the plague. Reading of the persecutions against Jews at this time reinforces the opinion that the more economically industrious a person was the greater his danger.<br /><br />In fact, envy is viewed by the author as a possible cause of the Inquisition, rather than merely from religious zealotry. Fray Luis de Leon of the University of Salamanca, who was denounced to the Inquisition by some of his own (jealous) colleagues, is given as an example of this. Other university professors were subjected to the same treatment, by those who, according to the author, wanted the \\"university chairs\\" of these professors. The author quotes Unamuno as stating that it was the \\"terrible Hispanic envy born of incompetence and pettiness\\" that was responsible for the Inquisition. Considering the typical attitudes of many in the academic community today, an environment that is typically polluted with envy, this assertion by Unamuno does not at all seem farfetched.<br /><br />The author does not want to end the book without a discussion of the consequences of the Inquisition on Spanish society. One might think that such a horrific series of events lasting for as long as it did would have devastating effects on any society. The author argues that the Inquisition was responsible for some of Spain's misfortunes, but not all of them. Its economic impact was minimal he says, with the decline of Spain economically being due essentially to the ability of wages to keep up with prices, thus lowering incentives among investors. The author is aware that this argument deserves more scrutiny however.<br /><br />Science and literature suffered greatly from the Inquisition however, due in large measure to the infamous book burnings and Indexes. All of these are discussed in detail in the book, terrifying as they were. This horrible destruction of knowledge is something that along with the brutality against \\"heretics\\" will be etched in the minds of all those with independent minds and who have deep respect for human life. Those individuals who launched and practiced the Inquisition should never be forgiven for their savagery against Jewish people and others who differed from the entrenched dogma of the Catholic church. The Inquisition served no constructive purpose, had no moral validity, and deserves daily condemnation. Only then can we be more confident that such a series of events does not happen again.uld never be forgiven for their savagery against Jewish people and others who differed from the entrenched dogma of the Catholic church. The Inquisition served no constructive purpose, had no moral validity, and deserves daily condemnation. Only then can we be more confident that such a series of events does not happen again.	2005-05-31
222446:US	50702879	R7ECHTBQWLR8C	1568812116	172176373	Mathematics by Experiment: Plausible Reasoning in the 21st Century	Books	5	12	13	N	Y	Intuitions and experiments come first; rigorous proofs later	If one peruses the mathematical literature for the last one hundred years one will notice that in most cases no diagrams or pictures appear. The level of rigor in all cases is impressive though, but unfortunately this makes the understanding of the results much more difficult. There seems to be an inverse relationship between rigor and understanding in mathematics, at least for those who are new to the subject at hand. In order to gain this understanding, the drawing of pictures and diagrams is useful, along with a certain amount of experimentation with the concepts at hand. Intuition, how mysterious, and however ill defined, plays a role in both the understanding of mathematical results and in their discovery. Many mathematicians do not want to acknowledge this, as a visitation to a typical conference will readily verify. The attitude has been expressed that mathematics has \\"always been abstract\\" and therefore that pictures or diagrams violate its spirit. Even a well-known geometry center whose goal was to use sophisticated computer graphics to visualize complex mathematical objects lost its funding, to the consternation of a few but with glee to most.<br /><br />Thus the way to discovery of mathematics, i.e. the heavy use of intuition, the disorganized shuffling of concepts, and the experimental doodling, has been masked by the final product of this process: a superb example of logical rigor and organization called modern mathematics. The authors of this book however think otherwise, and they give the best apology for the role of experimental mathematics than anyone else in the literature. The book is packed with highly interesting examples and challenging exercises, all of which are ample proof of the need for doing experimentation in mathematics.<br /><br />In addition to these considerations, the book is just plain fun to read, and even though time constraints may prohibit the working out of every exercise, the book could be used profitably in a graduate course in mathematics or even possibly in an undergraduate course at the senior level. Hopefully this approach to scholarship in mathematics will take hold in this century, and mathematicians will not only write down their final results with all their splendid rigor, but also how they got there. This would serve to educate younger generations of mathematicians in just how discovery in mathematics is done and increase their efficacy in the same. The book will also assist those who are trying to build machines capable of discovering novel results in mathematics. Machine proofs of difficult theorems and conjectures are now a reality, and in the twenty-first century we will no doubt see many more of these.<br /><br />This book therefore contains a lot of hints about how to proceed in mathematics. Its acceptance will depend on how well it does its job in the creation of new mathematical results and in the teaching of them. Results in mathematics that seem plausible serve to make conjectures and motivate the construction of rigorous proofs. This book is a first step in a hopefully larger work.course in mathematics or even possibly in an undergraduate course at the senior level. Hopefully this approach to scholarship in mathematics will take hold in this century, and mathematicians will not only write down their final results with all their splendid rigor, but also how they got there. This would serve to educate younger generations of mathematicians in just how discovery in mathematics is done and increase their efficacy in the same. The book will also assist those who are trying to build machines capable of discovering novel results in mathematics. Machine proofs of difficult theorems and conjectures are now a reality, and in the twenty-first century we will no doubt see many more of these.  <br /> <br />This book therefore contains a lot of hints about how to proceed in mathematics. Its acceptance will depend on how well it does its job in the creation of new mathematical results and in the teaching of them. Results in mathematics that seem plausible serve to make conjectures and motivate the construction of rigorous proofs. This book is a first step in a hopefully larger work.	2005-05-30
223623:US	50702879	R2H9EPOIRIOY4C	0262083388	899731367	Brain Fiction: Self-Deception and the Riddle of Confabulation (Philosophical Psychopathology)	Books	5	35	36	N	Y	A fascinating and important study	To anyone interested in modern research in neuroscience, this book will be of great interest. Confabulation, the topic discussed in the book is one that was completely new to this reviewer, but the preface and jacket summary motivated the subject in a way that definitely convinces the reader that it is relevant to both neuroscience and neurophilosophy. It is important to emphasize that both of these fields are used to discuss confabulation in the book. The author is a professional philosopher, but he makes heavy use of the latest research in neuroscience, and this is refreshing, for it makes his conclusions more credible, not being ones that are arrived at solely (and therefore incorrectly), through sophisticated rhetoric and from the safety of the academic armchair.<br /><br />As a phenomenon in the human mind, confabulation is rather disconcerting, and one can only feel extreme empathy for those who are afflicted with it. The author discusses several different cases of confabulation, including Korsakoff's syndrome, anosognosia, Anton's syndrome, and Capgras' syndrome. He also gives an extensive discussion of the different explanations for confabulation by various researchers. Many of these explanations are interesting, such as the one that connects confabulation with the human storytelling. Individuals concoct stories in order to engage in self-protection and self-definition, and consequently define, however inaccurately, their identities. This can be done without conscious deliberation, and its function is to solidify the personal identity of the narrator.<br /><br />Another interesting explanation for confabulation that is discussed in the book considers the time scales needed for individuals to formulate decisions and then act on them. If these time scales are very short, the decision-maker cannot consider all possibilities, and minute concentration to detail is prohibited. Therefore the human mind will omit these details, eliminate any feelings of doubt from the cognitive process, and concentrate on the \\"big picture.\\" Confabulation is then essentially a smoothing function, a large-scale manifestation of this process.<br /><br />For the author though, confabulation is a process that cannot only be studied empirically, but can also be connected with epistemological issues in philosophy. When confabulating, the human brain is unable to check whether an answer is not real. He attempts to justify his theories by using what is known in neuroscience, with the specific goal of showing that the brain's ability to construct an appropriate response is independent of its ability to check that response.<br /><br />Since the author is a professional philosopher, and not a neuroscientist, readers of a more scientific persuasion may be concerned that the discussion on epistemology will degrade into sophistry. Refreshingly though it does not, for the author gives a fascinating discussion of confabulation as an \\"epistemic phenomenon,\\" but integrating it with the neuroscience of confabulation. Two epistemic mistakes are made when confabulation is present argues the author. The first one occurs in a particular knowledge domain in which a process causes a thought to occur that is \\"ill-grounded\\". The second mistake is the result of the failure to self-correct, this process of self-correction occurring in the frontal regions of the brain. All cases of confabulation involve these two mistakes argues the author, and he connects his assertions with the more general field of naturalized epistemology, the latter of which was put on a more rigorous foundation by the philosophers Alvin Goldman and W.V.O. Quine. These philosophical musings are necessary argues the author, for they allow one to distinguish between \\"well-grounded\\" and \\"ill-grounded\\" beliefs, which one must do if a successful explanation of confabulation is to be obtained. The biology of the brain though must enter into any of this theorizing, for as has been shown experimentally, damageto the areas of the brain responsible for the construction of knowledge domains, along with damage to the monitoring processes in the orbitofrontal areas of the brain, can result in confabulation.<br /><br />Most interesting in this discussion on confabulation and knowledge is the author's contention that the construction of effective representations by the human brain takes place in degrees. He then discusses an appropriate consequence of this assertion, which he calls the `degraded representation principle.' This principle asserts that if the capacity to represent events of a certain type is diminished in a particular individual, then the likelihood for this individual to confabulate about these events increases.<br /><br />Self-deception, a \\"lighter\\" manifestation of confabulation is discussed at the end of the book, and is, one could argue, the most prevalent form of confabulation. The author does distinguish it from clinical confabulation, and after reading this chapter this demarcation becomes justified. The person who is engaging in self-deception frequently has a greater ability to access the information that is needed to prove his belief is ill-grounded. A clinical confabulator though does not, as the processes and brain areas needed for this proof have been destroyed. Various degrees of tension also exist in the range from that of the clinical confabulator, who experiences none when making ill-grounded claims, to that of the self-deceiver who may experience a lot.<br /><br />As an example of self-deception, the author offers the educator who describes himself as being better than their colleagues. It is interesting that he chose this example, since it seems that this form of self-deception is the rule rather than the exception in the halls of academia, at least from an anecdotal standpoint. This inflated view though is accompanied by the \\"weakness of the warrant\\", wherein the justification or \\"warrant\\" for the belief is very weak. An individual engaged in self-deception has beliefs that are not constructed from the most reliable collection of beliefs that his brain could deliver if it was not crippled by self-deception. The issue of course here, as it is throughout the book, concerns the human need for belief systems that can be justified or warranted. As the author points out early in the book, the avoidance of confabulation must have an evolutionary importance for the well being of the human species. Time constraints and resources though may prohibit an exhaustive check of all assumptions and beliefs.tally, damage to the areas of the brain responsible for the construction of knowledge domains, along with damage to the monitoring processes in the orbitofrontal areas of the brain, can result in confabulation.  <br /> <br />Most interesting in this discussion on confabulation and knowledge is the author's contention that the construction of effective representations by the human brain takes place in degrees. He then discusses an appropriate consequence of this assertion, which he calls the `degraded representation principle.' This principle asserts that if the capacity to represent events of a certain type is diminished in a particular individual, then the likelihood for this individual to confabulate about these events increases.  <br /> <br />Self-deception, a \\"lighter\\" manifestation of confabulation is discussed at the end of the book, and is, one could argue, the most prevalent form of confabulation. The author does distinguish it from clinical confabulation, and after reading this chapter this demarcation becomes justified. The person who is engaging in self-deception frequently has a greater ability to access the information that is needed to prove his belief is ill-grounded. A clinical confabulator though does not, as the processes and brain areas needed for this proof have been destroyed. Various degrees of tension also exist in the range from that of the clinical confabulator, who experiences none when making ill-grounded claims, to that of the self-deceiver who may experience a lot.  <br /> <br />As an example of self-deception, the author offers the educator who describes himself as being better than their colleagues. It is interesting that he chose this example, since it seems that this form of self-deception is the rule rather than the exception in the halls of academia, at least from an anecdotal standpoint. This inflated view though is accompanied by the \\"weakness of the warrant\\", wherein the justification or \\"warrant\\" for the belief is very weak. Anindividual engaged in self-deception has beliefs that are not constructed from the most reliable collection of beliefs that his brain could deliver if it was not crippled by self-deception. The issue of course here, as it is throughout the book, concerns the human need for belief systems that can be justified or warranted. As the author points out early in the book, the avoidance of confabulation must have an evolutionary importance for the well being of the human species. Time constraints and resources though may prohibit an exhaustive check of all assumptions and beliefs.	2005-05-29
226308:US	50702879	R3KOMZA4FLAK7P	0525947663	942334245	God In the Machine: What Robots Teach Us About Humanity and God	Books	4	11	11	N	Y	An interesting and bold narration	Those readers who have no religious beliefs but yet are interested in or working in the field of artificial intelligence may think that this book would not be very interesting or important, or possibly an apology for a particular religious worldview. When beginning the book this attitude will be reinforced somewhat, since it takes a while for the author to develop her main themes. Once she does however the book is fascinating, and her discussion of some of the issues in artificial intelligence is highly original and insightful. Considering the environment in which she worked it is refreshing to learn that the author was taken seriously, in spite of her overt expression of her religious beliefs. The only minus to the book is that the author concentrates her attention on robotics, which is a very narrow field of artificial intelligence at the present time. Machines can be intelligent to various degrees without looking like humanoids and without interacting with the environment in the manner that the author describes in great detail in the book. Indeed, these machines are more than just the \\"machines that sit on the desk\\" to quote the author. No, they cannot move in the world as humans do, but their abilities to perform tasks in a way that cannot be done by humans attests to their cognitive abilities.<br /><br />Along with those who work in the field, the author has developed a deep appreciation of the magnificence of the human machine. She encapsulates her view of humanity not according to the usual classification, but according to human capabilities. Humans can tell stories (\\"homo narrans\\"), can stand upright (\\"homo erectus\\"), can use technology to change the world (\\"homo faber\\"), can engage in creativity (\\"homo ludens\\"), and can hold to religious beliefs (\\"homo religiosus\\"). There are of course other machines, biological and otherwise, that can do some of these things, but the human machine is unique in being able to do all of them, and then with a relatively low energy requirement. This of course does not make the human machine superior to the others, and in fact humans cannot compete at all with some of the machines of today in certain tasks. Those who build robots though insist on replicating the idiosyncrasies of the human machine, even though these robots may not be useful in any practical sense. The author's goal in the book is to try and understand why the building of these robots has been such an intense activity in the last half-century.<br /><br />It is clear that many do not find the prospect of humanoid robots very pleasant at all. Hollywood movies, with their depiction of machines bent on the annihilation of humankind, are both an expression and cause of this anxiety.  But stories of non-human entities possessing high degrees of intelligence have also pervaded our myths and stories long before the invention of film. As an example she describes the myth of the \\"golem\\" coming from Jewish mysticism. Interestingly, in some stories, golems are made from clay and constructed through words and numbers. Their purpose is to assist in the understanding of the world, a mythos or paradigm that definitely intersects with the one in artificial intelligence.<br /><br />More interesting in her discussion of \\"rebuilding ourselves\\" is the reminder of a peculiar phenomenon that takes place in the artificial intelligence community, indeed in the scientific research community as a whole. This regards the \\"demystification\\" or diminishing of awe when a scientific explanation is found for a particular human capability. Indeed, it seems that every time an advance is made in artificial intelligence, such as a machine beating the best backgammon or chess player in the world, it eventually gets dismissed as being merely the result of a sophisticated program, and not as an example of true intelligence.<br /><br />The author of course is not free of biases, as no one can be, whether they are in the scientific profession or not. Her intellectual honesty though is refreshing, and she is unashamed of her devout religious beliefs. She correctly recognizes that there are many in the scientific community who occupy both laboratories and churches, and make significant contributions to science. Whether they are scientists who sometimes practice religion or religionists who sometimes engage in scientific research is perhaps left to debate. But the author believes that these individuals, along with all the rest of humanity, clearly benefit and learn from social interactions, and that such interactions are even absolutely necessary for true intelligence to arise. Sometimes though these interactions go awry, and result in devastating conflict, this occurring primarily because of a diminution in respect for differences or of parties not being in the same physical space. The acceptance of humanoid robots she argues will therefore depend on whether their differences can be respected and whether they can interact with us in the same physical space. These robots can be viewed therefore as a gauge on how far we have advanced in our acceptance and respect for others. Certainly this is a good reason for the creation of these machines if none other can be found. But many other reasons can be found.....intellectual honesty though is refreshing, and she is unashamed of her devout religious beliefs. She correctly recognizes that there are many in the scientific community who occupy both laboratories and churches, and make significant contributions to science. Whether they are scientists who sometimes practice religion or religionists who sometimes engage in scientific research is perhaps left to debate. But the author believes that these individuals, along with all the rest of humanity, clearly benefit and learn from social interactions, and that such interactions are even absolutely necessary for true intelligence to arise. Sometimes though these interactions go awry, and result in devastating conflict, this occurring primarily because of a diminution in respect for differences or of parties not being in the same physical space. The acceptance of humanoid robots she argues will therefore depend on whether their differences can be respected and whether they can interact with us in the same physical space. These robots can be viewed therefore as a gauge on how far we have advanced in our acceptance and respect for others. Certainly this is a good reason for the creation of these machines if none other can be found. But many other reasons can be found.....	2005-05-27
229581:US	50702879	R2KM0M2MNFFWLE	0679454438	148918425	The Road to Reality : A Complete Guide to the Laws of the Universe	Books	4	13	21	N	Y	Standard material in most places, provocative in others.	The author of this book is well known to those who have studied general relativity and its quantization, his contributions to these areas going back to the 1960's. Indeed, the (black hole) singularity theorems and the invention of twistor theory are both credited to the author. The first of these is straightforward to learn from a mathematical standpoint, while the second can be very difficult to assimilate, as it is typically not motivated very well in the research literature. The author does discuss twistor theory in the book, but the discussion is not well motivated, and will be very disappointing to those readers who were expecting one that would be intuitively clear.<br /><br />However, there are many places in the book where the author gives the reader special insight. Some of the these discussions include: 1. The discussion of the axiom of choice and the Banach-Tarski theorem, revealing the non-constructive nature of the latter, and also revealing the author's Platonism. Clearly the author does not favor a purely constructive approach to mathematics. Such an approach though would not only serve mathematics better but also its physical applications. Bizarre and counterintuitive results such as the Banach-Tarski theorem, incompleteness theorems, and non-computability results that arise from Cantor diagonalization would disappear, as they should, since they have no practical or observable consequences. 2. The treatment of complex numbers is thorough, but unfortunately the author has christened them as \\"magical.\\" This reinforces the view that complex numbers have some of special or mystical status in mathematics, which they do not. In addition, their use in physical applications is not mysterious either in spite of their not being used for such for 350 years after their invention in 1545. 3. The discussion on analytic continuation, which is presented in a way which will make the transition to sheaf theory much more palatable. Indeed the author describes the existence of complex smoothness in an open region in the complex plane as being equivalent to the existence of a power series expansion about any point in this region. Thus a holomorphic function is one which can be analytically continued about a sequence of points. The author refers to this as a `rigidity' of holomorphicity, in that once a holomorphic function is fixed in its original region, and the path is fixed, the function can only be extended in one way. Real-analytic functions do not have this special property. 4. The discussion of quantum entanglement and quantum teleportation is very clear, with the only minus being that the author is too accepting of the reality of entanglement, and does not review critically the experimental evidence for this phenomena. A highly critical analysis of entanglement has not been done in the literature, even though such an analysis is sorely needed, due to the importance of entanglement as a mechanism to make quantum computation a reality. 5. The author mentions briefly an extension of the standard model that involves associating to each non-Abelian symmetry group a dual group, which is the same (abstract) group but will typically be broken. Most interestingly, this procedure results in a theory that only has three adjustable parameters, which definitely makes it reasonable to describe it as a significant advance in mathematical physics. 6. The chapter on the Big Bang and its \\"thermodynamic legacy\\" is the best in the book, for it addresses issues in a way that is both easily understandable and mathematically sound. The author presents the Big Bang as being \\"extraordinarily special\\" due to its low (relatively speaking) entropy. His discussion leads him into considerations of the anthropic principle, and he refreshingly recommends caution in giving this principle a religious interpretation. The author follows this by a fascinating discussion that reveals just how weak the anthropic principle is, and he once again expresses preference for naturalistic explanations on explaining the special nature of the Big Bang.aturalistic explanations on explaining the special nature of the Big Bang.	2005-05-24
232806:US	50702879	R1JXEJ1YUZ6KEV	0802844375	273241205	Reason for the Hope Within	Books	1	8	114	N	Y	Naive and sophomoric	Skimming through this book will reveal a number of articles with interesting titles, but only one of them, entitled \\"A Scientific Argument for the Existence of God\\" was studied by this reviewer, and hence only it will be reviewed here. It regards the notion of the \\"fine-tuning\\" of various physical parameters as being \\"proof\\" for the existence of God. The tone of the article is extremely sophomoric, and it exaggerates what is really known in modern physics.<br /><br />The author gives five examples of what he calls \\"fine-tuning\\", with this \\"fine-tuning\\" supposedly defined with respect to the occurrence of \\"life,\\" the latter of which is left undefined in the article. The reader though can assume an ordinary, common sense view of life, and for the purposes of this review the definition could be very liberal, i.e. merely supposing the existence of carbon molecules, or very stringent, i.e. the existence of a simple living organism, such as a paramecium.<br /><br />The first example regards what the author oddly calls the \\"strength\\" of the big bang. He states that if the \\"strength\\" of the big bang differed by one part in 10^60, then \\"life\\" would be impossible. He quotes a reference that supposedly sheds light on this statement. This reviewer has not examined this reference, but it would seem unlikely that it would be of interest from the standpoint of cosmology. If life is taken to mean carbon molecules, then this would require solving the bound state problem in quantum field theory, which has not been done in physics to this date. If life is taken to mean a paramecium, one needs to start with the big bang, evolve the universe, show the eventual appearance of carbon molecules, and then show how these and other molecules formed the paramecium (and face the formidable protein-folding problem in the process). Then one has to show how a change in the \\"strength\\" of the big bang of one part in 10^60 would not result in the eventual appearance of carbon molecules, but even if they did appear, the paramecium (or any other simple life form) would not be formed. Either way the calculation will be extraordinarily difficult. It has not been performed by the author of this article or in any research article that this reviewer is aware of. It would seem that the author, in his rush to justify his theistic biases, is willing to accept extremely weak evidence, at least from the standpoint of physics. It will do no good to quote \\"eminent\\" physicists in this regard, since they have not done these calculations explicitly, due to their extreme difficulty. Indeed, Freeman Dyson, who the author quotes in the article, has certainly done valuable work in perturbative quantum field theory (quantum electrodynamics to be exact), but he has not even come close to solving the (non-perturbative) bound-state problem in quantum field theory. The author therefore naively gives credit to the well-known physicists he quotes, without understanding the true nature and difficulty of the physical problems that must be solved before he can make the claims that he does in this article. Arguments from authority are worthless in a scientific argument, the latter of which the author has designated his article to be.<br /><br />The same commentary also applies to the author's assertion that \\"life\\" would be impossible if the strong interaction has been stronger or weaker by as little as five percent. As it stands, this is a huge claim, since calculations with the strong interaction are extremely difficult to carry out. The theory of the strong interaction is governed by quantum chromodynamics, and only approximations to this theory, such as lattice calculations, have shown promise for an understanding of the dynamics of strongly interacting particles. Once again, in his hurry to justify his theistic biases, the author uses examples that do not reflect the true status of modern physical theory.<br /><br />In the third example of \\"fine tuning\\", the author quotes work that concludes that if gravity had been stronger or weaker by one part in 10^40, then \\"life\\" would be impossible. One needs a successful theory of quantum gravity to make this claim, and such a theory has not yet reached the level of sophistication that would allow this claim to be made with confidence.<br /><br />Similar objections could be made to the other two examples of \\"fine tuning\\", but will not be done here. But in addition to his naivete about what has really been accomplished in modern physics, the author makes unproven claims about how scientists really operate during their research. The most extreme example of this is in what he calls the `prime principle of confirmation', which is supposed to give criteria for rejecting one scientific hypothesis over another. The author though does not give historical test cases in scientific research that show the viability of this principle. It is certainly not one that scientists are vocal about or self-consciously follow. In fact, the assignment of probabilities to hypotheses is only one of many ways to model the process of scientific research. Each of these has their advantages and disadvantages, and their validation is currently hotly contested, especially in the field of automated scientific discovery.<br /><br />The standard model of elementary particle physics has been fine-tuned to get the right answers, but this fine-tuning is not what the author has in mind. He wants to justify the existence of a theistic designer, but he has not given any sound, scientific arguments in this article. To justify the claims made by the author would take an army of researchers and massive computer calculations. The results would be very important in themselves, as the bound state problem and protein-folding problem are of great interest to physicists and computational biologists. The author's arguments are though extremely weak, and remind one of a piece of bread lying in a bowl full of milk: seemingly solid, but when one lifts it up for examination it falls to pieces.stronger or weaker by one part in 10^40, then \\"life\\" would be impossible. One needs a successful theory of quantum gravity to make this claim, and such a theory has not yet reached the level of sophistication that would allow this claim to be made with confidence.     Similar objections could be made to the other two examples of \\"fine tuning\\", but will not be done here. But in addition to his naivete about what has really been accomplished in modern physics, the author makes unproven claims about how scientists really operate during their research. The most extreme example of this is in what he calls the `prime principle of confirmation', which is supposed to give criteria for rejecting one scientific hypothesis over another. The author though does not give historical test cases in scientific research that show the viability of this principle. It is certainly not one that scientists are vocal about or self-consciously follow. In fact, the assignment of probabilities to hypotheses is only one of many ways to model the process of scientific research. Each of these has their advantages and disadvantages, and their validation is currently hotly contested, especially in the field of automated scientific discovery.     The standard model of elementary particle physics has been fine-tuned to get the right answers, but this fine-tuning is not what the author has in mind. He wants to justify the existence of a theistic designer, but he has not given any sound, scientific arguments in this article. To justify the claims made by the author would take an army of researchers and massive computer calculations. The results would be very important in themselves, as the bound state problem and protein-folding problem are of great interest to physicists and computational biologists. The author's arguments are though extremely weak, and remind one of a piece of bread lying in a bowl full of milk: seemingly solid, but when one lifts it up for examination it falls to pieces.	2005-05-21
240173:US	50702879	R3P1404Q6KLC3U	0821829556	137486294	Mirror Symmetry (Clay Mathematics Monographs, V. 1)	Books	5	7	12	N	N	Detailed overview of the subject	Mirror symmetry has become an established branch of mathematics and mathematical physics, and research in the subject has resulted in brilliant developments. This sizable book contains essentially some (polished) lecture notes of a seminar series in mirror symmetry that was given in the spring of 2000. This reviewer only studied Part 5 of the book, entitled \\"Advanced Topics\\" and so only that part will be reviewed here. In addition, space constraints then dictate only a small portion of this part can be reviewed. Needless to say, any reader who intends to tackle this book will need a substantial background in modern mathematics and advanced physics, and a sizable commitment in time. The time spent is well worth it though, as both the mathematics and physics behind mirror symmetry has to rank as one of the most fascinating research topics in the last two decades.<br /><br />In the chapter entitled \\"Topological Strings\\" the authors consider the functional integration of worldsheet geometries. This project involves essentially the integration over the complex structures of Riemann surfaces. Referring to this procedure as \\"quantum gravity\\", they do not address it in-depth, but instead focus on the coupling of topological sigma models to worldsheet gravity, which is called `topological string theory' in the literature. The authors first consider the case where the target is a Kahler manifold whose first Chern class is zero, since for this case the quantum cohomology ring is less easy to obtain, i.e. it can obtain contributions from holomorphic maps of any degree.  Even for the case where there is no coupling to gravity, the degree 0 contribution is related to the classical intersection number. The contributions from higher degree result in the deformation of the classical cohomology ring into the quantum cohomology ring. The authors then ask whether there are any other correlators that will give nontrivial (non-zero) invariants in genus 0. Posing this question leads to the WDVV equation and the genus 0 topological string partition function. The n-point correlation functions of topological strings can then be defined as the nth partial derivatives of this function. For higher genus cases, the correlators are all zero, but the authors show the connection between the higher genus partition function and holomorphic anomalies. The case of three-dimensional Calabi-Yau manifolds is special, if one concentrates on the integration over the complex structures of the worldsheet. When the complex dimension of this moduli space is 3(g-1) then there are isolated points where holomorphic maps exist. Defining a topological string theory for Calabi-Yau threefolds is straightforward, as the author shows, and proceeds analogously to the case of topological field theory. A measure is defined on the moduli space of Riemann surfaces of genus g that cancels the axial charge anomaly. A genus g (>1) topological string amplitude, which is a section of a bundle over the moduli space of Calabi-Yau manifolds, is then obtained from this procedure. Modulo the presence of holomorphic anomalies, the authors show that the definition of topological string amplitudes is consistent with the topological symmetry. The origin of these holomorphic anomalies is discussed in fair detail by the authors, having their origin in the boundaries of the moduli space.<br /><br />The rigorous mathematical formulation of mirror symmetry is of course of great interest to mathematicians. Because of its origin in string theory and quantum field theory, mirror symmetry has not yet received this kind of rigor. Chapters 37 and 38 of this book discuss some of the approaches that attempt to put mirror symmetry on a more rigorous foundation. One of these involves the use of `derived categories,' an approach that was recommended by the mathematician Maxim Kontsevich. The discussion in these chapters takes place in the context of D-branes, and Kontsevich conjectures that mirror symmetry is the equivalence of two categories: the derived category of coherent sheaves, and the category of Lagrangian submanifolds with flat U(1) connections. Specifically the equivalence entails the equivalence between the bounded derived category of coherent sheaves or `B-cycles' and the category of A-cycles with compositions defined in terms of holomorphic maps from disks. This latter category is derived from the Fukaya A-infinity category, as is shown by the authors. They discuss in detail this category, being essentially a generalization of a differential, graded algebra, especially how to obtain the compositions.  In chapter 37, the authors give an explicit example of the equivalence of these categories for the case of the elliptic curve. The elliptic curve is interesting in this regard in that it is its own mirror, i.e. the complex parameter is mapped to the complexified Kahler parameter by the mirror map.<br /><br />The derived category has sometimes been a stumbling block to those who want to understand the Kontsevich conjecture. The authors do not attempt to give the reader the needed insight into this kind of category, but merely take it to be a collection of all holomorphic bundles and coherent sheaves. Sheaves in this category can be subtracted from each other using a map between them. Physically, this subtraction corresponds to the annihilation of branes and anti-branes via a tachyon. Derived categories though are straightforward to think about if one views them from the standpoint of algebraic topology. Derived categories are rich enough to include notions of localization and triangulated objects (i.e. \\"complexes\\") and maps (i.e. morphisms) between these objects. This is a kind of \\"homology\\" but what is of main interest are homotopies between the morphisms. The class of homotopic morphisms between two complexes forms an abelian group and one can then obtain a category consisting of complexes as objects and classes of homotopic morphisms as morphisms. A cohomology functor can then be defined on this category, along with graded objects and differentials between them. The homotopic category can be given a \\"triangulation\\" and morphisms in this category that give rise to isomorphisms in cohomology are given special status, called `quasimorphisms.' The localization of this category with respect to quasimorphisms is called a derived category.the equivalence of two categories: the derived category of coherent sheaves, and the category of Lagrangian submanifolds with flat U(1) connections. Specifically the equivalence entails the equivalence between the bounded derived category of coherent sheaves or `B-cycles' and the category of A-cycles with compositions defined in terms of holomorphic maps from disks. This latter category is derived from the Fukaya A-infinity category, as is shown by the authors. They discuss in detail this category, being essentially a generalization of a differential, graded algebra, especially how to obtain the compositions.  In chapter 37, the authors give an explicit example of the equivalence of these categories for the case of the elliptic curve. The elliptic curve is interesting in this regard in that it is its own mirror, i.e. the complex parameter is mapped to the complexified Kahler parameter by the mirror map.  <br /> <br />The derived category has sometimes been a stumbling block to those who want to understand the Kontsevich conjecture. The authors do not attempt to give the reader the needed insight into this kind of category, but merely take it to be a collection of all holomorphic bundles and coherent sheaves. Sheaves in this category can be subtracted from each other using a map between them. Physically, this subtraction corresponds to the annihilation of branes and anti-branes via a tachyon. Derived categories though are straightforward to think about if one views them from the standpoint of algebraic topology. Derived categories are rich enough to include notions of localization and triangulated objects (i.e. \\"complexes\\") and maps (i.e. morphisms) between these objects. This is a kind of \\"homology\\" but what is of main interest are homotopies between the morphisms. The class of homotopic morphisms between two complexes forms an abelian group and one can then obtain a category consisting of complexes as objects and classes of homotopic morphisms as morphisms. A cohomology functor can then be defined on this category, along with graded objects and differentials between them. The homotopic category can be given a \\"triangulation\\" and morphisms in this category that give rise to isomorphisms in cohomology are given special status, called `quasimorphisms.' The localization of this category with respect to quasimorphisms is called a derived category.	2005-05-15
240508:US	50702879	R286CCT8W4VG6D	354042363X	904666431	Emergent Neural Computational Architectures Based on Neuroscience: Towards Neuroscience-Inspired Computing (Lecture Notes in Computer Science)	Books	4	2	2	N	Y	Good overview of current research	Considering intense efforts in bio-inspired computing, taking the form of genetic algorithms, swarm intelligence, and artificial life, it is not surprising that the field would also gain inspiration from the workings of the brain, whether the brain comes from a human or some other mammal. This is both an exciting development and a difficult one, not only because a complete working model of the mammalian brain is not available yet, but also because of the sheer computational power needed. With faster machines of course, the second problem will be alleviated, and the first is undergoing rapid development, thanks to the research efforts in neuroscience. This book is a collection of articles that give a review of some of research in neuroscience-inspired computing. Since they are review articles, readers will not find in-depth discussion, but references are given that will assist curious readers who need more information on a particular topic.<br /><br />The editors introduce the subject of neuroscience-inspired computing by pointing out some of the main sources for this inspiration. These sources serve to divide the book into four sections. The first of these concerns the modular organization of the brain. Even though the view of the human brain as being composed as specialized modules is still the subject of intense debate, there is experimental evidence from brain imaging studies that there are regions in the brain that are correlated with cognitive functions. Neural networks are of course used extensively in business and industry, but they are highly task specialized, and it therefore would be interesting, and useful, to entangle these networks together in order to enable the resulting system to solve more general tasks.<br /><br />Another inspiration comes from the amazing robustness of the human brain. Through various recovery mechanisms, a damaged brain still is able to function to a large degree, and it therefore would be useful in emulate these mechanisms in non-biological machines. The editors discuss briefly various approaches that have been taken in the construction of models of both recovery through regeneration and via functional reallocation. Several papers in the book illustrate the construction of these models. One of these stands out with its emphasis on the creation of neural systems that are dynamic and adaptive. Everyone who has designed neural networks for practical use is aware of the fine-tuning needed to create a successful neural architecture. The authors of this particular article use a neuron development simulator along with evolutionary algorithms to evolve various neuron morphologies and architectures.<br /><br />The third source of neuroscience-inspired computing comes from the neurophysiology of the brain. The performance of the brain is dependent on the temporal correlation between collections of neurons and brain regions. In the typical construction of a neural network, time dependences are usually not taken into account. This prohibits the neural network from dealing with data that is temporal in nature. In one of the articles in the book, the author describes the neuroscience behind time-dependent learning and proposes an associative learning rule that respects the potentiation or depression of the neuronal synapse at long time scales. The model of dynamical synapse that he proposes involves the computation of the excitatory post synaptic potential at the synapse and the backpropagating action potential. A learning rule is then constructed which depends on the cross-correlation between these two signals. This model, along with others that are discussed in other articles in the book, illustrate the role of timing and synchronization in neuronal processes. One of the more exotic models discussed in this regard is based on chaotic dynamics. Although the modeling of the brain as a collection of chaotic neural objects is difficult to validate because of the long time scales and large amount of data required, the model is discussed in sufficient detail to make it worth reading.<br /><br />The last source of inspiration concerns the memory storage capabilities of the human brain. One of the articles in the book concerns the construction of artificial neural networks that can deal with sensitive to contexts, is hierarchical and extensible. The article is more ambitious than the others in the book as it discusses many difficult issues in the neuronal modeling. The goal of this modeling is to account for the ability of the human brain to engage in abstract reasoning. The local associationist algorithms that are usually used cannot emulate symbol-like behavior, and so the authors attempt to use recurrent nets and `schemata' to deal with this issue.<br /><br />The articles definitely motivate the reader to investigate further the status of research in neuroscience-inspired computing. Further progress in neuroscience will be needed before machines can be constructed which emulate the brain in more detail. But even without a full understanding of the human brain machines could be constructed that use some approximate features of the human brain. These machines will have capabilities that may be better than those whose functioning or computational abilities are not based on human brain processes or its modular structure. The practical use of these machines will then motivate the construction of even better machines as more knowledge of brain processes becomes available.of data required, the model is discussed in sufficient detail to make it worth reading.  <br /> <br />The last source of inspiration concerns the memory storage capabilities of the human brain. One of the articles in the book concerns the construction of artificial neural networks that can deal with sensitive to contexts, is hierarchical and extensible. The article is more ambitious than the others in the book as it discusses many difficult issues in the neuronal modeling. The goal of this modeling is to account for the ability of the human brain to engage in abstract reasoning. The local associationist algorithms that are usually used cannot emulate symbol-like behavior, and so the authors attempt to use recurrent nets and `schemata' to deal with this issue.  <br /> <br />The articles definitely motivate the reader to investigate further the status of research in neuroscience-inspired computing. Further progress in neuroscience will be needed before machines can be constructed which emulate the brain in more detail. But even without a full understanding of the human brain machines could be constructed that use some approximate features of the human brain. These machines will have capabilities that may be better than those whose functioning or computational abilities are not based on human brain processes or its modular structure. The practical use of these machines will then motivate the construction of even better machines as more knowledge of brain processes becomes available.  <br />	2005-05-15
242955:US	50702879	R1TEV9UH09131Y	0742538222	682056761	The New Concise History of the Crusades	Books	3	45	148	N	Y	Captivating reading....but also an apology for the Crusades	Assuming that the documents on which the book is based are factual, it does contain a lot of interesting information, whose verification of course would take a lifetime of meticulous research and a great deal of financial resources. Not since the historical volumes of Will and Ariel Durant, which covered the Crusades, has there been a work that adds strong personal viewpoints regarding the Christian religion. The commentary of the Durants and that of author of this book are diametrically opposed regarding Christianity, but it definitely distracts readers who are extremely curious about the causes and historical context behind the Crusades. However, since the author has chosen to include opinions on the moral legitimacy of the Crusades, readers are justified in making critical analysis of these opinions.<br /><br />The atrocities of 9/11 are of course mentioned in the preface, and the author's bias against the Islamic faith is expressed early on. Indeed, in the second paragraph of the book the author makes it a point to remind the reader that unlike Christianity the Islamic faith had a notion of holy war before the Middle Ages. It took the Roman Emperor Constantine, in his conversion to Christianity in A.D. 312 to realize that Christians, who endured brutal persecution for two centuries, now had armies and power at their disposal. And, as the author points out, this caused St. Augustine in the fifth century to formulate criteria for a \\"just war.\\" Such a war was not to be one waged for religious conversion or for destroying heresies. The Crusades and the Inquisition are two examples where his formulation was corrupted and abused, and this corruption and abuse has continued to this day. In the intervening centuries intense competition for carnage and horror took place between Islam and Christianity. It is hard to say who won this competition, given the level of brutality exhibited by each. The city of Jerusalem was one of the major sources of contention and \\"moral justification\\" for the Crusades, as is readily apparent when reading this book. Christian pilgrims to Jerusalem filled the coffers of those who ruled the city, but this enrichment still did not suppress its political instability. It is very troubling that one city could be responsible for so much violence, and this violence continues to this day.<br /><br />There are many interesting discussions in this book however, and due to its size the knowledge it contains can be rapidly assimilated. The reader learns for example of the \\"Children's Crusade,\\" which arose, as can be expected, from the incessant preaching for the Crusades that occurred in northern France and various areas in Germany. Fortunately, and the author relieves quickly the readers anxiety, this Crusade was not made up of children, and not really a crusade in comparison to the rest. It was made up of a collection of \\"unknown\\" people, who no doubt really believed in the content of the preaching they listened to. The author describes their march to the Holy Land, which ended in tragedy, some of them being sold as slaves. Their efforts were nullified, no books have been written exclusively about them. Being mere footnotes in history, they did not qualify for the \\"great people of history,\\" and no canonization or glorification was imputed to them.<br /><br />But one crusader stands out in the book as being more heroic and morally sound than the rest, and it is easy to question the author's objectivity in his description of this crusader, due to his academic affiliation. Indeed, the picture painted of St. Louis is one of extreme piety, generosity, and holiness. Being king of the most enriched country in Europe at the time gave him access to resources that enabled him to crusade for the liberation of Jerusalem. But despite the abundance of material wealth, St. Louis of course had to motivate people to follow him into battle. The author describes him as being very \\"inspiring\\" to the troops, and a \\"gifted leader.\\" There is no reason to doubt this, as wars are not fought by one man, but with many who must control their fears and engage in activity that is not directly in their interests. Religion of course always helps in supplying this courage, which St. Louis was eager to supply. The individuals who accompanied St. Louis are of course not remembered; they were not canonized, and no American cities were named after them.  But even though the author chose to characterize St. Louis as one who viewed the conquest of Jerusalem as the \\"greatest act of devotion to Christ,\\" the fact remains that the Crusades he led were inhumane, immoral acts, having absolutely no ethical justification, and a complete waste of time and resources, just like the others.der.\\" There is no reason to doubt this, as wars are not fought by one man, but with many who must control their fears and engage in activity that is not directly in their interests. Religion of course always helps in supplying this courage, which St. Louis was eager to supply. The individuals who accompanied St. Louis are of course not remembered; they were not canonized, and no American cities were named after them.   But even though the author chose to characterize St. Louis as one who viewed the conquest of Jerusalem as the \\"greatest act of devotion to Christ,\\" the fact remains that the Crusades he led were inhumane, immoral acts, having absolutely no ethical justification, and a complete waste of time and resources, just like the others.	2005-05-12
249566:US	50702879	RYUJIWBKR0R7J	006083871X	261484893	God's Politics	Books	4	9	13	N	Y	A breath of fresh air	As the content of this book illustrates, it would be incorrect to assume that all people that profess belief in Christianity or some other religion are enemies of those that don't. For those who think there is no intersection between secularism and religion in terms of values will definitely find counterexamples to that belief in this book. Too much emphasis has been placed in the media on the \\"Religious Right,\\" giving its members an aura of invincibility as well as intolerance. This has seemingly caused many in the secular community to view religion in an even more hostile light than they did before. This is definitely unfair, and does not square with the facts. In the scientific and engineering professions in particular, one observes an interesting statistic, namely that most of the advances in these professions have occurred with the assistance of scientists and engineers who also hold to religious beliefs. Indeed, if the statistical abstracts are correct in stating that ninety-five percent of the world's populations believe in some sort of divine being, then it follows straightforwardly that the other five percent who do not are not responsible for all of the scientific and technological advances. Whether they are scientists who sometimes engage in prayer and supplication or people of faith who sometimes practice science is a matter perhaps for debate, but the fact remains that the current state of technology is due to in large measure to the efforts of people who have spent their time in churches as well as laboratories.<br /><br />But the illegal and immoral war in Iraq, coupled with the strange and hysterical dialog engaged in by many religious \\"leaders\\", is cause for alarm, and those in the \\"secular Left\\" can therefore gain a great deal by recognizing that they have much in common with the author's dialog in this book. A lot of his values are the same, and an alliance, even if not formalized in common institutional action, is warranted with those that the author represents. Genuine concern with what is happening in the world, and an utmost respect for human life, are the values that form a non-empty intersection with the author and the secular community. One might call a common call to action a pragmatic philosophy, but however it is labeled, there should not be anxiety among secularists that the joining of hands with people of faith is a form of compromise or intellectual suicide. Sound judgment, and not arrogance, must be the predominant mental attitude for all who oppose the brutality of the war in Iraq. Standing with those who share the same values can alleviate more suffering than working alone.<br /><br />There is much in this book that is refreshing, and it is certainly one that stands in contraposition to the lunacy proceeding from the current administration and in some extremist religious circles. There are some mistakes in the book, like any other, but there are some gems of thought that deserve careful reflection. For example, some of the wisest advice given in the book is in the last chapter entitled \\"The Critical Choice.\\" The author cautions, rightfully, against the monster of cynicism, realizing fully its potential to cripple the human intellect. The author shows great insight into the reasons why people choose to be cynics (and yes, he thankfully views it as a choice): essentially to protect themselves from disappointment, to find a \\"refuge from commitment.\\" Cynics though, contrary to what the author states, do not really know what is going on in the world. They fancy themselves \\"realistic,\\" but in fact view the world via sweeping generalizations and ignore consciously and deliberately counterexamples to their viewpoints. The author recommends action not optimism as an antidote to cynicism, but both are needed, along with an insatiable curiosity to figure things out, and absolutely, and without any doubt: pure intellectual honesty.<br /><br />In the last chapter, the author also makes some predictions for the \\"new millennium.\\" Some of these are relevant only to those who have some type of religious beliefs. Others are certainly ones that many will hope for, such as the prediction that the \\"Religious Right\\" will lose control of religious discussion. It is doubtful though that Internet pornography will \\"quietly undermine\\" human relationships. On the contrary, people will become jaded to pornography, and due to its lack of imagination and creativity, it will no longer influence anyone to any large degree. Indeed, pornography will decline because of its banality, not because of any restraints placed on it. This goes also for the author's prediction on the \\"moral pollution\\" of Hollywood culture and corporate advertising. Hopefully though prayer and Bible study will not become more important to people than it is now. What we need is more thinking and less prayer; the prayer/thought ratio must be kept as small as possible. The \\"secular Left\\" will not give up its hostility to religion, even though for reasons given above, they should not be hostile to it. But secularism will not die; it will grow without conscious effort. The secularists of the twenty-first century will be busy with technological development and scientific research and will not, and need not, concern themselves with the perusal of ancient religious texts. These developments are rapidly accelerating and will continue to do so, with or without the assistance of people of faith. But if the past is any indication, one can expect their assistance, and it will be extremely efficacious.ctions for the \\"new millennium.\\" Some of these are relevant only to those who have some type of religious beliefs. Others are certainly ones that many will hope for, such as the prediction that the \\"Religious Right\\" will lose control of religious discussion. It is doubtful though that Internet pornography will \\"quietly undermine\\" human relationships. On the contrary, people will become jaded to pornography, and due to its lack of imagination and creativity, it will no longer influence anyone to any large degree. Indeed, pornography will decline because of its banality, not because of any restraints placed on it. This goes also for the author's prediction on the \\"moral pollution\\" of Hollywood culture and corporate advertising. Hopefully though prayer and Bible study will not become more important to people than it is now. What we need is more thinking and less prayer; the prayer/thought ratio must be kept as small as possible. The \\"secular Left\\" will not give up its hostility to religion, even though for reasons given above, they should not be hostile to it. But secularism will not die; it will grow without conscious effort. The secularists of the twenty-first century will be busy with technological development and scientific research and will not, and need not, concern themselves with the perusal of ancient religious texts. These developments are rapidly accelerating and will continue to do so, with or without the assistance of people of faith. But if the past is any indication, one can expect their assistance, and it will be extremely efficacious.	2005-05-07
257196:US	50702879	RXDDYI5XHZCZ1	0387977104	481717507	Sheaves in Geometry and Logic: A First Introduction to Topos Theory (Universitext)	Books	5	35	39	N	Y	Excellent	Topos theory now has applications in fields such as music theory, quantum gravity, artificial intelligence, and computer science. It has been viewed by some as being excessively abstract and difficult to learn, and this is certainly true if one attempts to learn it from the research literature. The use of this book to learn topos theory certainly puts this view to rest, as the authors have given the readers an introduction to topos theory that is crystal clear and nicely motivated from an historical point of view. Indeed the prologue to the book gives the reader a deep appreciation of the origins of the subject, and could even serve as an introduction to a class on algebraic geometry.<br /><br />An understanding of sheaf theory and category theory will definitely help when attempting to learn topos theory, but the book could be read without such a background. Readers who want to read the chapters on logic and geometric morphisms will need a background in mathematical logic and set theory in order to appreciate them. Topos theory has recently been used in research in quantum gravity. A reader interested in understanding how topos theory is used in this research should concentrate on the chapter on properties of elementary topoi, the one on basic categories of topoi, and the chapter on localic topoi.<br /><br />The authors introduce topos theory as a tool for unifying topology with algebraic geometry and as one for unifying logic and set theory. The latter application is interesting, especially for readers (such as this reviewer), who approach the book from the standpoint of the former. Indeed, the authors discuss a fascinating use of topos theory by Paul Cohen in his proof of the independence of the Continuum Hypothesis in Zermelo-Fraenkel set theory.<br /><br />The prologue for this book is excellent, and should be read for the many insights and motivations for the subject of topos theory. The elementary category theory needed is then outlined in the next section. A \\"topos\\" is essentially a category that allows the construction of pullbacks, products, and so on, with the philosophy being that objects are to be viewed not only as things but as also having maps (functors) between them. In the section on categories of functors, this viewpoint becomes very transparent due to the many examples of categories that are also topoi are discussed. These examples are presented first so as to motivate the general definition of topos later on. Some of these categories are very familiar, such as the category of sets, the category of all representations of a fixed group, presheaves, and sheaves. Of particular interest in this section is the discussion of the propositional calculus, and its representation as a Boolean algebra. Replacing the propositional calculus with the (Heyting) intuitionistic propositional calculus results in a different representation by a Heyting algebra. From the standpoint of ordinary topology, the Heyting algebra is significant in that the algebra of open sets is not Boolean, i.e. the complement (or \\"negation\\") of an open set is closed and not open in general Instead it follows the rules of a Heyting algebra. This type of logic appears again when considering the subobjects in the sheaf category, which have a \\"negation\\" which belong to a Heyting algebra. Thus topos theory is one that follows more than not the Brouwer intuitionistic philosophy of mathematics. Recently, research in quantum gravity has indicated the need for this approach, and so readers interested in this research will find the needed background in this part of the book.<br /><br />After a straightforward overview of how sheaf theory fits into the topos-theoretic framework, the authors also discuss the role of the Grothendieck topology in sheaf theory. This involves thinking of an open neighborhood of a point in a space as more than just a monomorphism of that neighborhood into the space (all the open neighborhoods thus furnishing a \\"covering\\" of the space). This need was motivated by certain constructions in algebraic geometry and Galois theory, as the authors explain in fair detail. A covering of a space by open sets is replaced by a new covering by maps that are not monomorphisms. Starting with a category that allows pullbacks, an indexed family of maps to an object of this category is considered. If for each object in this category one uses a rule to select a certain set of such families, called the coverings of the object under this rule, then ordinary sheaf theory can be used on these coverings. If one desires to drop the requirement that the category have pullbacks, this can be done by introducing a category that comes with such \\"covering families.\\" This is the origin of the Grothendieck topologies, wherein the indexed families are replaced by the sieves that they generate. A Grothendieck topology on a category is thus a function that assigns to each object in the category a collection of sieves on the object (this function must have certain properties which are discussed by the authors). Several examples of categories with the Grothendieck topologies are discussed, one of these being a complete Heyting algebra. Another example discussed comes from algebraic topology, via its use of the Zariski topology for algebraic varieties. The discussion of this example is brilliant, and in fact could be viewed as a standalone discussion of algebraic geometry.<br /><br />When considering the notion of the Grothendieck topology, the authors define the notion of a `site', which is essentially a (small) category along with a Grothendieck topology on the category. They then show how to define sheaves on a site, which then form a category. A `Grothendieck topos' is then a category which is equivalent to the category of sheaves on some site. The authors then show, interestingly, that a complete Heyting algebra can be realized as a subobject lattice in a Grothendieck topos.ce). This need was motivated by certain constructions in algebraic geometry and Galois theory, as the authors explain in fair detail. A covering of a space by open sets is replaced by a new covering by maps that are not monomorphisms. Starting with a category that allows pullbacks, an indexed family of maps to an object of this category is considered. If for each object in this category one uses a rule to select a certain set of such families, called the coverings of the object under this rule, then ordinary sheaf theory can be used on these coverings. If one desires to drop the requirement that the category have pullbacks, this can be done by introducing a category that comes with such \\"covering families.\\" This is the origin of the Grothendieck topologies, wherein the indexed families are replaced by the sieves that they generate. A Grothendieck topology on a category is thus a function that assigns to each object in the category a collection of sieves on the object (this function must have certain properties which are discussed by the authors). Several examples of categories with the Grothendieck topologies are discussed, one of these being a complete Heyting algebra. Another example discussed comes from algebraic topology, via its use of the Zariski topology for algebraic varieties. The discussion of this example is brilliant, and in fact could be viewed as a standalone discussion of algebraic geometry.<br /><br />When considering the notion of the Grothendieck topology, the authors define the notion of a `site', which is essentially a (small) category along with a Grothendieck topology on the category. They then show how to define sheaves on a site, which then form a category. A `Grothendieck topos' is then a category which is equivalent to the category of sheaves on some site. The authors then show, interestingly, that a complete Heyting algebra can be realized as a subobject lattice in a Grothendieck topos.	2005-05-01
258200:US	50702879	RVQ9GAXC4LVV5	0802141935	918527495	The Neocon Reader	Books	1	18	62	N	Y	Introduction to the political philosophy of yellow abdomens	\\"The neo-conservatives run the Pentagon\\", so says one commentator recently. From the news reports, no matter how distorted they might be, and from some of the literature that has been pouring forth from those who describe themselves as neo-conservatives, one could believe the commentator's statement. They exude great confidence in their philosophy, provocative as it is, and they are unashamed of presenting it with gusto. But underneath their rhetoric and bombast one observes a conspicuous absence: the absence of the (Sartrian) belief that philosophy and action are one. Indeed, they are comfortable with putting pen to paper, and consequently whipping up hysteria and zeal for armed conflict, but they do not participate in that conflict. Readers will find an excellent compilation of their philosophies in this collection of articles and excellent examples of intellectual and moral cowardice. Space and time prohibit a detailed overview of them, so attention will be drawn to the two worst of them (the weighting scheme used by this reviewer to judge this was very difficult):<br /><br />In his article \\"Beyond the Axis of Evil: Additional Threats from Weapons of Mass Destruction\\", John R. Bolton discusses what he considers to be the greatest threat to national security, namely state sponsorship of terrorists that use weapons of mass destruction. The article states the obvious, and has many unsubstantiated claims. One of these is the assertion that Iraq has developed, produced, and stockpiled biological warfare agents and weapons. In addition, they have developed, produced, and stockpiled chemical weapons. Also, Syria has been known to have a chemical warfare program. And Cuba has a well-developed biomedical industry, and that the US \\"believes\\" that Cuba has a limited biological warfare research and development effort. How does Bolton know all these things? What kinds of biological agents did they develop and how much of them did they have? What kinds of chemical agents? Bolton gives no references and the skepticism of this reviewer regarding these claims increased after completing the article. One fact though is beyond dispute: Bolton has not yet volunteered for military service to help America win \\"the fight to root out and destroy terror.\\" He states in this article that America is leading this fight. Perhaps, but America is doing it without his assistance on the battlefields of Iraq and Afghanistan. Bolton, like so many others of his persuasion, has excused himself from doing the real fighting. His hands are too shaky and his intestinal fortitude too lacking for such an endeavor.<br /><br />But by far the best example of vague and floating abstractions comes in the article by Condoleezza Rice entitled \\"The President's National Security Strategy\\". Rice is a Lieutenant Keefer with XX chromosomes, a person who keeps her skirts nice and starched and clean, even in the Iraq War. One will not find any Iraqi sand embedded into the fibers of her crisp, designer suits. What one will find, and this is exemplified perfectly in this article, is a capacity for stating much but proving little. She speaks of \\"existential threats\\", of the \\"crystallization\\" of our vulnerabilities after 9/11 and of threats being \\"fully materialized.\\" These are certainly colorful metaphors, and an example of a sterile intellect hiding behind tact and prudence. They are never defined or subject to clarification, in spite of her statement in the article that \\"clarity is a virtue.\\" Clarity is not to be found in this article, but what can be found is language that smoothes over the perturbations that real facts can induce when presented to an administration that is unprepared and ill-equipped mentally to deal with them. Rice speaks against the tension between the `realistic' and `idealistic' schools of foreign affairs, and asserts \\"these categories obscure reality.\\" Her grasp of reality and facts though seems shaky at best, totally obscuring historical realities. This is readily apparent when she states that \\"we do not seek to impose democracy on others.\\" Considering the carnage in the illegal and immoral war against Iraq, a war that Rice made happen and steadfastly supports, to make it a \\"stable democracy\\", this is indeed an odd statement to make, and is indicative of how shielded Rice is from the true realities of the world.<br /><br />Indeed, throughout this book you will find a sizable collection of trembling hands, weak intellects, and yellow abdomens. But one thing you will not find in the book is an article that implores those in the neo-conservative camp to sign up for combat duty in the military. Nay, you will not find such an article, nor one that implores the sons and daughters of these individuals to do the same. They leave the horrors of warfare to those that do not think or act like they do.when she states that \\"we do not seek to impose democracy on others.\\" Considering the carnage in the illegal and immoral war against Iraq, a war that Rice made happen and steadfastly supports, to make it a \\"stable democracy\\", this is indeed an odd statement to make, and is indicative of how shielded Rice is from the true realities of the world.     Indeed, throughout this book you will find a sizable collection of trembling hands, weak intellects, and yellow abdomens. But one thing you will not find in the book is an article that implores those in the neo-conservative camp to sign up for combat duty in the military. Nay, you will not find such an article, nor one that implores the sons and daughters of these individuals to do the same. They leave the horrors of warfare to those that do not think or act like they do.	2005-04-30
264948:US	50702879	RZNAAQPCNGS6B	0521837332	918687704	Quantum Gravity (Cambridge Monographs on Mathematical Physics)	Books	5	32	36	N	Y	A useful overview of an alternative theory	This book gives a detailed overview of that \\"other theory\\" of quantum gravity called `loop quantum gravity'. String theory has been viewed by many as a promising theory of quantum gravity and there are many reasons to believe this is the case. String theory though requires a formidable amount of mathematics for its construction, and has yet to have any experimental verification. Therefore, it is not surprising that other alternative theories of quantum gravity would be constructed, these needing a minimal amount of formalism and staying as close as possible to what can be observed. Loop quantum gravity is one of these, and is the most popular alternative to string theory as a theory of quantum gravity.<br /><br />The initial five chapters of the book motivate the need for quantum gravity and also phrase the theories of general relativity and relativistic quantum physics in a language that will be used to formulate the theory of loop quantum gravity. General relativity (GR) is formulated as a dynamical system defined by the Hamilton-Jacobi equation for a functional defined on the space G of three-dimensional SU(2) connections. The equation is invariant under internal gauge transformations and 3D diffeomorphisms.<br /><br />The quantization of GR is obtained in terms of complex-valued Schrodinger wave functionals on G. The derivatives of the Hamilton-Jacobi functional are replaced by derivative operators in order to obtain the quantum dynamics. The Hamilton-Jacobi equation then becomes the Wheeler-DeWitt equation governing the quantum dynamics of spacetime. The quantum (kinematical) state space is defined letting G be the space of smooth 3D real connections defined everywhere on a 3D surface S. The functionals are defined in terms of an ordered collection of smooth oriented paths L (essentially a lattice) on S, and are called \\"cylindrical functions\\" by the author. Scalar products are defined, which when completed gives the (kinematical) Hilbert space K. Lest the reader believe that this is nothing more than a quantum Yang-Mills theory on a lattice, the author is careful to note that a continuous theory over all possible lattices in S is being considered. The space K is nonseparable, but factoring out the diffeomorphisms gives a separable one. It has an orthonormal basis, and contains a subspace K0 of states invariant under local SU(2) gauge transformations. The ubiquitous spin network states form a orthonormal basis for K0. Again the author cautions against viewing this as ordinary lattice gauge theory, since diffeomorphism invariance makes it different from the latter. The spin networks are graphs L with links and nodes. The nodes are joined by links and the curves in L overlap only at the nodes. Each node has a multiplicity that measures the number of links going in and out of it. The author shows explicitly how to construct the spin network states, which are an orthornormal basis for K0.<br /><br />So what about the observables of loop quantum gravity? The connection and its momentum are the field variables in the canonical theory, and are replaced by field operators. The momentum operator has a curious operation in this theory: the author describes it as \\"grasping\\" a path. The momentum operator though is not gauge invariant on K0, and so the author defines a new gauge-invariant (and self-adjoint) operator associated to S and has a straightforward operation on spin network states. This operator represents the physical area of S, and its spectrum, interestingly, can be interpreted as a quantized area. This result is related to the derivation of the entropy of black holes in the book, and is considered to be one of the significant results given by loop quantum gravity. A similar construction is done with the volume, giving a volume operator, which also has a discrete spectrum, but only has contributions from the nodes of a spin network state. Loop quantum gravity therefore truly gives a \\"quantized geometry.\\" Each node of a spinnetwork represents a quantum of volume, giving a collection of \\"chunks\\" separated from each other by surfaces, the areas of which are governed by the area operator. The graph L of the spin network determines the adjacency relation between these chunks, and is interpreted as the graph dual to a cellular decomposition of physical space. Spin network states therefore determine a discrete quantized three-dimensional metric.<br /><br />The dynamics of loop quantum gravity requires the construction of the Hamiltonian operator. As in quantum field theories, this involves regularization, and the author shows how the Hamiltonian operator acts only on the nodes of the spin network, and gives a detailed discussion of the background independence of the theory. The latter is one of the most important features of loop quantum gravity, and is frequently advertised as one of its virtues. The author also discusses the extent to which the Hamiltonian operator is unique, outlining in the process several alternatives. When matter fields are considered, the author shows that the total Hamiltonian is finite, again pointing to the background-independence of loop quantum gravity. Loop quantum gravity reduces to classical general relativity as Planck's constant goes to zero, but the author lists many issues that have not been settled by this theory. One of these of course concerns the observable consequences, the lack of which it shares with string theory. Loop quantum gravity also does not attempt to unify the different interactions in nature in a single theory, as does string theory. But loop quantum gravity does give some interesting predictions, one of these being that the size of the universe is quantized. It also predicts an inflationary phase in the expansion of the early universe, as numerical solutions of the Wheeler-DeWitt equation indicate. By far the most interesting consequence of loop quantum gravity, is that it makes more reasonable the Bekenstein-Hawking interpretation of the entropy of a black hole. In fact the Bekenstein-Hawking entropy can be derived in loop quantum gravity, up to a factor called the Immirzi parameter. These are all impressive achievements, considering the status of quantum gravity now as compared to three decades ago.of a spin network represents a quantum of volume, giving a collection of \\"chunks\\" separated from each other by surfaces, the areas of which are governed by the area operator. The graph L of the spin network determines the adjacency relation between these chunks, and is interpreted as the graph dual to a cellular decomposition of physical space. Spin network states therefore determine a discrete quantized three-dimensional metric.  <br /> <br />The dynamics of loop quantum gravity requires the construction of the Hamiltonian operator. As in quantum field theories, this involves regularization, and the author shows how the Hamiltonian operator acts only on the nodes of the spin network, and gives a detailed discussion of the background independence of the theory. The latter is one of the most important features of loop quantum gravity, and is frequently advertised as one of its virtues. The author also discusses the extent to which the Hamiltonian operator is unique, outlining in the process several alternatives. When matter fields are considered, the author shows that the total Hamiltonian is finite, again pointing to the background-independence of loop quantum gravity. Loop quantum gravity reduces to classical general relativity as Planck's constant goes to zero, but the author lists many issues that have not been settled by this theory. One of these of course concerns the observable consequences, the lack of which it shares with string theory. Loop quantum gravity also does not attempt to unify the different interactions in nature in a single theory, as does string theory. But loop quantum gravity does give some interesting predictions, one of these being that the size of the universe is quantized. It also predicts an inflationary phase in the expansion of the early universe, as numerical solutions of the Wheeler-DeWitt equation indicate. By far the most interesting consequence of loop quantum gravity, is that it makes more reasonable the Bekenstein-Hawking interpretation of the entropy of a black hole. In fact the Bekenstein-Hawking entropy can be derived in loop quantum gravity, up to a factor called the Immirzi parameter. These are all impressive achievements, considering the status of quantum gravity now as compared to three decades ago.	2005-04-25
266878:US	50702879	RTQ8X1KI0U0WD	0195154207	206268025	The Future of the Brain: The Promise and Perils of Tomorrow's Neuroscience	Books	4	25	29	N	Y	Addresses much more than is indicated in the title	Any discussion of mind control or alteration of the brain causes most great anxiety, and justifiably so. We all like to believe we are in total control, whether in fact this is the case. Free will is taken to be an axiom, giving personal comfort and confidence in one's autonomy and freedom, and any perceived threat to personal identity is steadfastly avoided. Philosophical doctrines are developed that hold to a \\"diamond theory\\" of mind and personality: one where the mind cannot be altered and is rigid and inflexible. Contrary to these claims and fantasies of thought, research in neuroscience and neuropharmacology has indicated that the thought patterns of the brain can be altered temporarily by drugs or permanently by lesions or surgery. Pharmaceutical companies, the military, marketing firms, and the educational establishment have expressed a great interest in neuroscience and the products that are based on it. The interest of all these institutions is perhaps disconcerting, so one needs an objective and honest overview of neuroscience in order to check whether this anxiety is indeed justified.<br /><br />The author of this book has given a critical discussion of the technologies of neuroscience, differentiating those that are currently available from those that are projected to arise in upcoming decades. He also gives a thorough overview of brain science and anatomy, geared toward a \\"semi-popular\\" readership, and which allows a deeper appreciation of the technologies used to \\"modulate\\" the brain. The author does not shy away from philosophical musings, but he keeps them at a reasonable abeyance, and does not let thought experiments and armchair speculation get in the way of practical, scientific discussion. His materialistic worldview is refreshing and is resonant with some very new views of consciousness, namely that it evolved and adapted to the needs of human survival.<br /><br /> Sometimes though the author lets his distaste of alternative points of view detract from the rational dialog that he predominantly engages in throughout the book. The field of `evolutionary psychology' for example, is subjected to harsh criticism, which for the uncommitted reader, such as this reviewer, detracts from the quality of the book. He also takes aim at the \\"meme\\" idea of Richard Dawkins, exclaiming that those who hold to the idea \\"should know better.\\" This kind of rhetoric, again, does not serve a useful purpose to anyone who is genuinely interested in the subjects that are discussed in this book.<br /><br />Also criticized in the book is the modular or `architectural' view of mind, which holds that the mind is a collection of modules each one of which has a different function. The proponents of the modular theory of mind assert that these modules have evolved independently (or nearly so) and have remained unchanged for quite some time. The author does not agree at all with this theory, believing that there is more to the mind/brain than mere information processing. The mind/brain is also concerned with \\"giving meaning,\\" he says, but he never really clarifies how it can indeed do this, although emotions are thought to play a key role. The author goes even further in asserting that it is the presence of emotions in the mind/brain that distinguish it from a computer. This may be true, but it has little to do with the main theme of the book. It is another place in the book where the author seems to get distracted from his primary goals. This is not to say that his meanderings are not interesting in and of themselves. In fact, there are many issues raised that are very important from the standpoint of someone interested in such topics as the nature of intelligence and how emotions are used to solve problems. In a footnote for example, the author points to the work of the \\"psychometricians,\\" who assert that intelligence can be reduced to a single factor, which they refer to as `crystallized intelligence.' Thus a modular theory of mind is tobe rejected. At any rate, research in cognitive neuroscience has shed light on the modular view, with the issues thankfully being delegated to laboratory experiments, rather than the sophisticated rhetoric of philosophical speculation.<br /><br />So what of the technologies of neuroscience? Do they hold much promise for the well being of humankind in the next few decades? The author ends the book with what he believes are the most optimal developments in this regard. There is no doubt that changes in biochemistry can affect cognitive processes, but the decisions on which kinds of changes should be done has been and continues to be a contentious issue. The author discusses in detail the different drugs that have been used, such as the SSRIs (selective serotonin reuptake inhibitors). Prozac (fluoxetine) is an example of one of these, and evidence is readily available as to its advantages and dangers. The author cites only one in three patients actually obtained an improvement, and withdrawal from its use can cause severe problems, even though it is not \\"formally\\" addictive. Also discussed is the use of Ritalin (methylphenidate) to treat ADHD (Attention Deficit/Hyperactivity Disorder) and also the propensity in the last decade to define mental disorders or maladies in a way that makes them almost indistinguishable from normal states of the brain. It could be said with fairness that pharmaceutical companies have been responsible for most of this, due to their need to drive and sustain their business, but caution also must be exercised in dismissing too quickly the drugs that do have a substantial benefit.<br /><br />The author also discusses other topics that are moving away from being science fiction, and are approaching practical implementation. These include mind-reading technologies, neurogenetics, psychogenetic engineering, psychotropic drugs, and biocybernetics. All of these are exciting technologies, and show much promise, as well as much peril. The discoveries of neuroscience will enhance dramatically ethical discussion and deliberation, as the last chapter of this book is an example of. This reviewer remains extremely optimistic about future developments, given the brilliance exhibited in our collective human past.nd is to be rejected. At any rate, research in cognitive neuroscience has shed light on the modular view, with the issues thankfully being delegated to laboratory experiments, rather than the sophisticated rhetoric of philosophical speculation.  <br /> <br />So what of the technologies of neuroscience? Do they hold much promise for the well being of humankind in the next few decades? The author ends the book with what he believes are the most optimal developments in this regard. There is no doubt that changes in biochemistry can affect cognitive processes, but the decisions on which kinds of changes should be done has been and continues to be a contentious issue. The author discusses in detail the different drugs that have been used, such as the SSRIs (selective serotonin reuptake inhibitors). Prozac (fluoxetine) is an example of one of these, and evidence is readily available as to its advantages and dangers. The author cites only one in three patients actually obtained an improvement, and withdrawal from its use can cause severe problems, even though it is not \\"formally\\" addictive. Also discussed is the use of Ritalin (methylphenidate) to treat ADHD (Attention Deficit/Hyperactivity Disorder) and also the propensity in the last decade to define mental disorders or maladies in a way that makes them almost indistinguishable from normal states of the brain. It could be said with fairness that pharmaceutical companies have been responsible for most of this, due to their need to drive and sustain their business, but caution also must be exercised in dismissing too quickly the drugs that do have a substantial benefit.  <br /> <br />The author also discusses other topics that are moving away from being science fiction, and are approaching practical implementation. These include mind-reading technologies, neurogenetics, psychogenetic engineering, psychotropic drugs, and biocybernetics. All of these are exciting technologies, and show much promise, as well as much peril. The discoveries of neuroscience will enhance dramatically ethical discussion and deliberation, as the last chapter of this book is an example of. This reviewer remains extremely optimistic about future developments, given the brilliance exhibited in our collective human past.	2005-04-23
269799:US	50702879	R3RGEDSIX9CS2O	0444508120	196995989	002: Handbook of Automated Reasoning, Volume II	Books	5	4	5	N	N	Both interesting and important in applications	This volume would be of interest to anyone who is interested in automated reasoning, both from the standpoint of research and from one of pure curiosity. Only the article entitled \\"Proof-Assistants Using Dependent Type Systems\\" will be reviewed here since it was the only one in the book that was read by this reviewer.<br /><br />The article can be read by anyone with a background in mathematical logic and lambda calculus. The content of this article is very important for those who are interested in proof checking, which has practical applications in circuit design and software development. Most professional mathematicians have yet to have confidence in computer-generated proofs, but thanks to the development of the Coq proof assistant, this is changing. One famous example of this non-confidence was the proof of the Four-Color Theorem in 1976. A substantial portion of this proof involved the use of computer-generated constructions, which were too time-consuming to be checked by hand. Mathematicians were very skeptical that the computer program was generating the correct results, since a verification of the program as being free from errors was missing. This verification was accomplished last year via the Coq proof assistant, which is discussed at some length in this article.<br /><br />The authors though discuss more than just the Coq proof assistant, and take a more general approach to the subject of type theory and its use in proof checking. Recognizing that the vast majority of mathematical proofs reported in mathematical journals is expressed using informal, natural language, they outline how to use type theory to translate informal mathematical statements into a formal language. Mathematical propositions become `types,' and proofs become `terms inhabiting' these types. The proof assistant that is considered is interactive, in that the proof terms are generated interactively between the user and the proof development system. The question that of course immediately rises concerns the reliability of the proof checker. The authors point to the `de Bruijn criterion' for reliability, namely that the proof-objects generated by the proof assistant can be checked by a simple algorithm. Checking a proof is then essentially checking a type, and interactive theorem proving is the interactive construction of a term of a given type.<br /><br />A type theory will also involve the construction of functions between types, which can be done, as the authors explain, via axiomatization, the lambda calculus, and primitive recursion. These functions can compute via reduction rules, and so can be viewed as algorithms. The authors show that functions can also be viewed as graphs in type theory, both in terms of ordinary formal logic and in constructive logics. The distinction between functions as algorithms and functions as graphs is readily brought out.<br /><br />If one is to do computation (and proofs) in type theory confidence must exist in the reduction rules. This is ensured by the `Subject Reduction' property (which gives the familiar cut-elimination property in logic programming) and in the decidability of conversion on the set of well-typed terms.<br /><br />Using (intensional) type theory to formalize mathematics must, if it is to represent mathematics faithfully, involve (extensional) concepts such as quotients and subsets. Issues of decidability have motivated the definition of a `setoid' in the type theory formalization of mathematics. The authors describe a setoid as a pair, consisting of a \\"carrier\\" (the \\"domain\\") and an equivalence relation that gives the notion of equality (sometimes called \\"book equality\\" in the literature on constructive mathematics). The authors give the details on how a quotient and a subset can be represented using setoids.<br /><br />The authors then show how these considerations can be implemented in a particular type theory: that of higher order predicate logic called lambda-HOL. This is followed by a discussion of a more general class of type systems and the need for a successful type-checking algorithm. The authors then discuss how to incorporate inductive types into type theory, which is needed if one is to generate proofs by induction and define functions recursively, as is commonly done in mathematics.<br /><br />The Coq proof assistant is described informally in part 4 of this article, with actual Coq statements included that illustrate how it works. A general `proof assistant' is composed of a `proof checker' and an interactive proof-development system. In the latter one chooses a context and a statement called a `goal' that is to be proved relative to that context. The user then makes use of `tactics' that are used to give hints of the real proof to the machine.<br /><br />The authors define a `proof development' as being a formalization of a context and a statement along with the construction of a `proof-object' for it. Of particular importance in this regard is the notion of a `theory development,' which is a collection of primitive and defined notions and axioms and provable theorems along with a goal to be proved. The authors outline an arithmetic example of a theory development in the Coq system: every natural number has a prime divisor. The computational abilities of Coq are also discussed briefly. The authors end the article with a comparison of several different proof assistants, such as Lego, Agda, Nuprl, HOL, Isabelle, Mizar, ACL2, and PVS, and a brief discussion of the applications of proof-assistants. The authors seem optimistic that mathematicians will eventually make heavy use of proof-assistants, and that this will result in the discovery of new and interesting mathematical results. It might take a new generation of mathematicians and highly sophisticated, intelligent proof assistants in order for this to happen, but the future of automated reasoning is certainly going to be a fascinating one.followed by a discussion of a more general class of type systems and the need for a successful type-checking algorithm. The authors then discuss how to incorporate inductive types into type theory, which is needed if one is to generate proofs by induction and define functions recursively, as is commonly done in mathematics.  <br /> <br />The Coq proof assistant is described informally in part 4 of this article, with actual Coq statements included that illustrate how it works. A general `proof assistant' is composed of a `proof checker' and an interactive proof-development system. In the latter one chooses a context and a statement called a `goal' that is to be proved relative to that context. The user then makes use of `tactics' that are used to give hints of the real proof to the machine.  <br /> <br />The authors define a `proof development' as being a formalization of a context and a statement along with the construction of a `proof-object' for it. Of particular importance in this regard is the notion of a `theory development,' which is a collection of primitive and defined notions and axioms and provable theorems along with a goal to be proved. The authors outline an arithmetic example of a theory development in the Coq system: every natural number has a prime divisor. The computational abilities of Coq are also discussed briefly. The authors end the article with a comparison of several different proof assistants, such as Lego, Agda, Nuprl, HOL, Isabelle, Mizar, ACL2, and PVS, and a brief discussion of the applications of proof-assistants. The authors seem optimistic that mathematicians will eventually make heavy use of proof-assistants, and that this will result in the discovery of new and interesting mathematical results. It might take a new generation of mathematicians and highly sophisticated, intelligent proof assistants in order for this to happen, but the future of automated reasoning is certainly going to be a fascinating one.	2005-04-21
273143:US	50702879	RAJFOT45QCK5B	0312319169	863828045	Company Man	Books	4	2	6	N	N	Good suspense...and a portrait of an atypical CEO	In financial theory there is a principle called \\"no-arbitrage\\" which in a nutshell says there is no free lunch, i.e. there is no collection of investment decisions or portfolio that does not carry risk. This principle is usually taken to be an axiom, and allows the derivation of many results that have practical utility in everyday trading. To hold to a contrary position to the principle of no-arbitrage is to be subjected to simple counterexamples that quickly indicate that such a position is not tenable.<br /><br />The CEOs of today's corporations however are seemingly exempt from this principle. No matter what the financial condition of their company, they are protected. Protected from the volatility and vicissitudes of the marketplace, they gain monetarily no matter what happens to the company. Thus they have no stake in the performance of the company, and therefore do not hold any personal connection with it. Parasitic to the core, they make money even if the company fails. To be a CEO of the corporation of today is to have a free lunch, to indeed have a perfect risk-free arbitrage opportunity.<br /><br />Nick Conover, the main character of this novel, is the CEO of the Stratton Corporation, which designs and manufactures office furniture. Conover though is atypical. He does not have a huge office full of the ego-boosters that decorate the walls of today's CEO. This is also due in large measure to the products that the Stratton Corporation made, emphasizing the \\"open-plan system\\" of the workplace. Conover is also committed to the success of the company, and takes personal interest not only in Stratton but also in the community in which it operates. Such a CEO is a rare species today, whose conduct still appears reprehensible, Sarbanes-Oxley notwithstanding.<br /><br />But Conover is not perfect, nor should he be expected to be. He commits an act in the story that in context would not at all seem unjustified if viewed in the context in which it occurred. But he tries to cover it up, having been convinced to do so by an individual who in no way shares his moral competence and who exaggerates the consequences if Conover admits to the act. Fear always disturbs one's mental equilibrium, but for a CEO it can spell the end of a career, due to a hostile press that seems to take delight in scandal and in hyping up the \\"general public\\", the latter of which it not only patronizes but typically views with disdain. Conover succumbs to this fear-mongoring, against his better judgment, and consequently finds himself in a position that would certainly act as a mind-numbing burden to anyone with a clear moral conscience.<br /><br />Through Conover, the author gives a character that is more fleshed out than the characters of his earlier novels. He captures Conover's introspection very well, along with the lifestyle and family tensions that are naturally expected to occur with anyone as busy as him. The author also teases the reader with issues of current interest, such as globalization and the intense pressure for modern corporations to transfer manufacturing to China.<br /><br />Yes, Conover is atypical. He cares about his community and endeavors to maintain cordial relations with its inhabitants. Like most corporations, Stratton has to engage in layoffs, but Conover tries to soften the blow to the community as best he can. His position as CEO of Stratton does grant him an ultimate perk however, but it does seem justified, given the context. One can be pragmatic in excusing Conover of his conduct, given his sustained use of an accurate moral compass throughout his life.aving been convinced to do so by an individual who in no way shares his moral competence and who exaggerates the consequences if Conover admits to the act. Fear always disturbs one's mental equilibrium, but for a CEO it can spell the end of a career, due to a hostile press that seems to take delight in scandal and in hyping up the \\"general public\\", the latter of which it not only patronizes but typically views with disdain. Conover succumbs to this fear-mongoring, against his better judgment, and consequently finds himself in a position that would certainly act as a mind-numbing burden to anyone with a clear moral conscience.    Through Conover, the author gives a character that is more fleshed out than the characters of his earlier novels. He captures Conover's introspection very well, along with the lifestyle and family tensions that are naturally expected to occur with anyone as busy as him. The author also teases the reader with issues of current interest, such as globalization and the intense pressure for modern corporations to transfer manufacturing to China.     Yes, Conover is atypical. He cares about his community and endeavors to maintain cordial relations with its inhabitants. Like most corporations, Stratton has to engage in layoffs, but Conover tries to soften the blow to the community as best he can. His position as CEO of Stratton does grant him an ultimate perk however, but it does seem justified, given the context. One can be pragmatic in excusing Conover of his conduct, given his sustained use of an accurate moral compass throughout his life.	2005-04-18
278533:US	50702879	R3K2T6XKJK9S5X	0805074562	393014403	On Intelligence	Books	3	12	22	N	Y	A bit too philosophical	In the field of artificial intelligence it seems there are as many definitions of intelligence as there are stars in the heavens. Each of these definitions seems plausible, and interestingly, they seem to get more difficult to satisfy with time. Thus progress in artificial intelligence seems to be non-existent, since the criteria used to designate a machine as being intelligent ten years ago are no longer used today. Researchers in AI used to believe for example that if a machine could beat a human in chess then it should definitely be deemed intelligent. That belief is hardly held by anyone in the AI community at the present time.<br /><br />The author of this book proposes yet another definition of intelligence, and it is one that is inspired by his understanding of how the human brain functions. His justifications are interesting, but they are highly speculative, and border on mere philosophical musings. It would have been a better book if the author refrained from the random walks in conceptual space that are characteristic of philosophy, and justified his conception of intelligence with what is really currently known in neuroscience. He does quote the research of neuroscientists that have produced a detailed map of the monkey cortex, which revealed many different regions connected together in a complex hierarchy. The author then makes the assumption that the human cortex hierarchy has a similar hierarchy. This is not really an unreasonable assumption if viewed from the standpoint of neuroanatomy, but from the standpoint of the cognitive abilities of humans versus those of monkeys, it might indeed be an assumption that deserves intense scrutiny.<br /><br /> The author definitely wants to view intelligence as being one that can function over many different domains, i.e. an intelligent machine will be able to not only play chess for example, but could also analyze stock market data or perform some other function typically thought of as requiring careful thought. He expresses this by saying that the human cortex is \\"universal\\" in that it can be applied to any type of sensory or motor system, and that the \\"algorithm of the cortex\\" can be expressed independently of any particular function or sense. Certainly humans can think in many different domains, but one cannot conclude from this that humans possess the general intelligence that the author believes they do. There is in fact a large body of research that indicates that the human brain has a modular structure (the author discusses this research very briefly), with each module being responsible for functioning in a particular domain. If one of these modules ceases to function, this has no effect on the functioning of the others. This is a view of the brain as having a domain-specific structure. A domain-general notion of intelligence would mean that the brain can deal with several different domains, but that the same reasoning patterns or processes are used to think in these different domains. If one of these reasoning patterns or processes becomes non-functional, the rest of them will suffer. One could still view the brain as consisting of modules expert in different domains, but that these modules are \\"entangled\\" with each other in the sense just specified, i.e. damage in one module will affect the others.<br /><br />In fairness to the author, there is also research in neuroscience that lends support to his notion of general intelligence and a single algorithm that can deal with all of the data presented to the human brain. He gives a few references that discuss this research, and he definitely emphasizes the need for feedback and the related notion of `auto-associative' memories. The brain in his view is a \\"pattern machine\\" and if one is to construct truly intelligent machines one must make use of this pattern manipulating capability of the human cortex. Thus intelligent machines will be a result of this \\"neocortical inspired\\" computing, and the author spends a lot of timeexplaining why these machines will mimic the ability of the brain to solve a problem using memory, and not by computing a solution. The cortex, in his view, creates \\"invariant representations\\" which can handle the intricate variability of the world it is confronted with. He summarizes this viewpoint by saying that the neocortex stores sequences of patterns, recalls patterns auto-associatively, stores invariant patterns, and stores patterns in a hierarchy. His explanations of how it does this are interesting, but again are very speculative, and in the absence of a prototype for a machine that possesses this kind of intelligence, it is difficult to assess the validity of his assertions.<br /><br />This reviewer strongly disagrees with the assertion from the author that there are no machines today that express true intelligence. A strong case can be made for the existence of myriads of intelligent machines in the world today, but this case would again be dependent on a particular definition of intelligence. Machines that have intelligence as the author defines it are nowhere in sight, and this is no doubt due to the lack of commercial value in the domain-general intelligence that the author advocates. The intelligent machines of today can learn, adapt, and manage, and do many other different things, but they only do these things in specific domains. There is absolutely no need for these machines to have expertise in more than one domain, both for the sake of efficiency and also because of economics. In managing a network for example, there is no need for a machine to have expertise in some other area, such as chess playing or backgammon. Business demands thus dictate the kind of domain-specific intelligence that is so prevalent in hundreds of intelligent machines performing many useful functions in business and industry.t of time explaining why these machines will mimic the ability of the brain to solve a problem using memory, and not by computing a solution. The cortex, in his view, creates \\"invariant representations\\" which can handle the intricate variability of the world it is confronted with. He summarizes this viewpoint by saying that the neocortex stores sequences of patterns, recalls patterns auto-associatively, stores invariant patterns, and stores patterns in a hierarchy. His explanations of how it does this are interesting, but again are very speculative, and in the absence of a prototype for a machine that possesses this kind of intelligence, it is difficult to assess the validity of his assertions.  <br /> <br />This reviewer strongly disagrees with the assertion from the author that there are no machines today that express true intelligence. A strong case can be made for the existence of myriads of intelligent machines in the world today, but this case would again be dependent on a particular definition of intelligence. Machines that have intelligence as the author defines it are nowhere in sight, and this is no doubt due to the lack of commercial value in the domain-general intelligence that the author advocates. The intelligent machines of today can learn, adapt, and manage, and do many other different things, but they only do these things in specific domains. There is absolutely no need for these machines to have expertise in more than one domain, both for the sake of efficiency and also because of economics. In managing a network for example, there is no need for a machine to have expertise in some other area, such as chess playing or backgammon. Business demands thus dictate the kind of domain-specific intelligence that is so prevalent in hundreds of intelligent machines performing many useful functions in business and industry.	2005-04-13
280071:US	50702879	R1LTGSHP0E06YP	0786312319	632880425	Energy Risk: Valuing and Managing Energy Derivatives	Books	4	9	12	N	Y	A good general introduction but needs more case studies	It is now a tautology to say that energy derivatives are very important financial instruments. Energizing a market of billions of dollars, they are useful to many different organizations and find their place in myriads of both business and personal portfolios. This book is written for those readers who are just entering the field of energy derivatives, but yet who still have a background in other areas of financial engineering. It emphasizes risk minimization, and also gives some of the author's unique perspective on the subject. Only the first six chapters were read by this reviewer and so only these will be reviewed here.<br /><br />The first chapter of the book discusses the general properties of energy derivatives and the concept of risk management. The author distinguishes between `quantitative' analysis, which emphasizes the construction of models that replicate market behavior, and `fundamental' analysis, which is an attempt to understand and describe market behavior in terms of the economics of supply and demand. The author emphasizes fundamental analysis in the book. She also outlines what makes energy derivatives unique in their analysis, i.e. what makes them different from interest rate and equity markets in terms of these different analysis categories. Energy markets exhibit stronger mean reversion, she argues, and supply constraints can \\"shock\\" the system. These differences motivate the introduction of the topics of `convenience yield' and seasonality that do not have to be used in other types of markets.<br /><br />Chapter 2 gets into the actual construction of financial models, with the author emphasizing the need for effective benchmarking of these models. She constructs some elementary stochastic price models and introduces some of the basic modeling terminology to be used in the book. One of these concepts is the `convenience yield' that represents the benefit that a holder of a commodity receives by holding the commodity, and is a measure of the balance between the available supply and the existing demand. Defining the convenience yield is difficult, but dominates the mathematical modeling of the energy markets. The author spends a fair amount of time discussing the mean-reversion process with more to come in later chapters. She also discusses the difference between yield and forward rate curves, a forward curve geared toward short-term interest rates, while a yield curve is a discount rate curve representing average rates from the present to points along the time axis.<br /><br />In chapter 3 the author discusses some of the mathematical/statistical tools involved in energy derivatives, with the analysis of time series and distribution analysis being the two dominant tools that are examined. Time series are used to monitor day-to-day changes in prices, while distribution analysis deals with price levels over extended intervals of time. The material in the chapter is standard, and should be helpful to readers who need a review of it.<br /><br />Chapter 4 is an introduction to the modeling of spot prices, with the assumption that supply and demand effects converge in the spot market prices. Derivative contracts are bought and sold with the belief that this convergence holds. After a quick look at actual time series of spot prices, the author constructs a lognormal price model and two mean-reverting models. Lognormal price models are of course standard constructions in financial engineering, and are popular for their simplicity and for enforcing positive-definiteness. Negative autocorrelation between spot prices are characteristic of energy markets, and is satisfied in mean-reverting models. The author also introduces one of her models, a two-factor model, with the first factor being the spot price, and the second factor a long-term equilibrium price, which when the latter is zero gives a single-factor model for the energy commodity spot price. Time series analysis is used to obtain the model parameters and distribution analysis is used to test the models over extended time periods. The distribution analysis involves Monte Carlo simulation, and the results showing the differences between actual and sample model simulated distributions.<br /><br />Recognizing the importance of forward prices in derivatives pricing and risk management, the author gives a detailed treatment of them in chapter 5. The author points out, interestingly, that there is no correlation between energy futures prices to interest rates in the energy commodity markets. The futures and forward prices are valued in an identical manner in energy markets, and energy future price and forward price can be used interchangeably. She also uses the no-arbitrage market condition to show that spot and forward prices are different, and derives partial differential equations for the forward price, both with and without dividends.<br /><br />Chapter 6 is extremely important, especially for the development of practical trading strategies, for it concerns measures of volatility for price processes. The volatility of the spot price gives information about the degree of randomness in the returns of the spot price over short intervals of time. Traders are of course very interested in volatilities, since the width of the price distribution is related to the probability of the option expiring in-the-money. This is well-known in financial modeling of derivatives, but there are some peculiarities in energy markets, such as \\"volatility term structure\\", that make the modeling process more difficult. The author discusses how to calculate historical, market-implied, and model-implied volatilities, and introduces the (two-dimensional) `discrete volatility matrix', the latter of which is due to the author. Several justifications are given for using a two-dimensional matrix of volatilities rather than a single-volatility term structure. The author does not however give any practical reasons for using this matrix or case studies that would illustrate its advantages. Reference is given to a commercial product that uses it, but it would have been helpful to the reader if the author had given more details on its use in practical everyday trading.eters and distribution analysis is used to test the models over extended time periods. The distribution analysis involves Monte Carlo simulation, and the results showing the differences between actual and sample model simulated distributions.  <br /> <br />Recognizing the importance of forward prices in derivatives pricing and risk management, the author gives a detailed treatment of them in chapter 5. The author points out, interestingly, that there is no correlation between energy futures prices to interest rates in the energy commodity markets. The futures and forward prices are valued in an identical manner in energy markets, and energy future price and forward price can be used interchangeably. She also uses the no-arbitrage market condition to show that spot and forward prices are different, and derives partial differential equations for the forward price, both with and without dividends.  <br /> <br />Chapter 6 is extremely important, especially for the development of practical trading strategies, for it concerns measures of volatility for price processes. The volatility of the spot price gives information about the degree of randomness in the returns of the spot price over short intervals of time. Traders are of course very interested in volatilities, since the width of the price distribution is related to the probability of the option expiring in-the-money. This is well-known in financial modeling of derivatives, but there are some peculiarities in energy markets, such as \\"volatility term structure\\", that make the modeling process more difficult. The author discusses how to calculate historical, market-implied, and model-implied volatilities, and introduces the (two-dimensional) `discrete volatility matrix', the latter of which is due to the author. Several justifications are given for using a two-dimensional matrix of volatilities rather than a single-volatility term structure. The author does not however give any practical reasons for using this matrix orcase studies that would illustrate its advantages. Reference is given to a commercial product that uses it, but it would have been helpful to the reader if the author had given more details on its use in practical everyday trading.	2005-04-12
283020:US	50702879	R3D5MMQU02UG58	0805069135	219495499	Why We Love: The Nature and Chemistry of Romantic Love	Books	4	39	47	N	Y	A first approximation to a science of love	The one thing one can say with confidence before reading this book is that love is universal: it affects everyone on this planet and everyone that has ever lived. Love can occur spontaneously or it can be chosen, and it can be responsible for much pleasure, as well as much pain. It is so common that its celebration has become the topic of countless novels and platitudes, as well as embedded in a myriad of cliches. But can there be a science of love, i.e. can love be examined for example using the frameworks of cognitive neuroscience or neuropharmacology? Does love lend itself to the modus operandi of reductionism that is so characteristic of scientific research?<br /><br />This book can be considered to be a first approximation to a science of love. Targeted to what has been called the \\"popular audience\\" it nevertheless gives enough references that interested readers can consult for more details. It is an interesting book, and the author has done a fine job in presenting her case for a neuroscientific theory of love. It convinces the reader that such a theory is not only possible, but also does not diminish the importance and mystique of romantic love. If indeed in the future a comprehensive neuroscientific theory of romantic love were finally developed, this would not mean that such an in-depth understanding would alter our personal interest in engaging in romance. Love poems and love stories will still be written, jilted lovers will still feel pain, and people will still seek out and find the person of their dreams.<br /><br />That love is not an isolated process in the human brain is brought out with great clarity in the book. Indeed, love as a neuronal process or emotion is correlated with the emotions of jealousy, anger, and hatred, among others. And since romantic love is such a strong emotion, as are these others, one might be led to believe that it might, as a neuronal process, have a long lifetime. The author sheds some light on this question, quoting research from neuroscience that indicates that romantic love lasts anywhere from twelve to eighteen months. Noting this research, she nevertheless asserts that the actual lifetime of romantic love is highly variable, depending greatly on the individuals that are involved.<br /><br />The most interesting part of the book was chapter 3, which is a discussion on the experimental techniques that were used by the author to study which parts of the brain are activated when a person is strongly in love, and a discussion of the brain chemistry of love. Her discussion summarizes some of her research that she conducted in 1996, with the goal of collecting data on the role of chemicals such as dopamine, norepinephrine, and serotonin. Dopamine in suitable levels can produce a more focused attention and highly motivated goal-directed behavior, all of these being characteristic of romantic love, the author asserts. As for norepinephrine, it can produce high energy, loss of appetite, insomnia, and extremely enhanced memory capabilities, which are again associated with romantic love. Serotonin, which has been used to treat individuals with obsessive-compulsive disorder, is implicated by the author in explaining why people in love seem to think incessantly about the object of their love. The author though cautions the reader that her belief that these chemicals play a role in romantic love must be weighed against the fact that these chemicals can produce different effects depending on their dose. In addition, they perform different functions depending on the region of the brain, and each will interact with the other in different ways depending on the circumstances. The author though takes as a working hypothesis that romantic love is caused by elevated levels of dopamine or norepinephrine, and decreased levels of serotonin.<br /><br />The author reports that her experiments in fMRI scans indicate that there is activity in the part of the brain called the caudate nucleus when a person isstrongly in love. Subjects that were in love were presented a photo of their sweetheart and the scans indicated that the caudate is highly activated when this was done. This apparently was a surprise to the author, for she states that this region was widely known to be responsible for the directing of body movement, and only has recently been shown to be also responsible for sensations of pleasure and for motivation to gain rewards. According to the author, the data indicated that the more passionate the person was about their loved one, the more active the caudate was. As stated this statement is somewhat suspect, since one would need an independent criteria for determining the degree of passion in the subject at hand. In addition to the caudate, the scans revealed that the brain region that becomes active when people eat chocolate also becomes active when people are passionately in love. This result has been widely publicized in the press and Hollywood movies, interestingly.<br /><br />Another result, described as \\"striking\\" by the author, was that the fMRI experiments revealed activity in the ventral tegmental area (VTA) of the brain. The VTA has been revealed to be the center of the reward circuitry of the brain, and is responsible for the creation of dopamine-making cells, thus adding support to her working hypothesis. Because of the association with motivational centers of the brain, the author also claims that these experiments verified that romantic love is a fundamental human mating drive. Thus it can be hard to control, like other drives such as hunger or thirst. The author is careful to note that her experiments did not establish the role of norepinephrine and serotonin in romantic love. In addition, the role of the \\"thinking\\" part of the brain, namely the cerebral cortex, was not revealed in these experiments.a person is strongly in love. Subjects that were in love were presented a photo of their sweetheart and the scans indicated that the caudate is highly activated when this was done. This apparently was a surprise to the author, for she states that this region was widely known to be responsible for the directing of body movement, and only has recently been shown to be also responsible for sensations of pleasure and for motivation to gain rewards. According to the author, the data indicated that the more passionate the person was about their loved one, the more active the caudate was. As stated this statement is somewhat suspect, since one would need an independent criteria for determining the degree of passion in the subject at hand. In addition to the caudate, the scans revealed that the brain region that becomes active when people eat chocolate also becomes active when people are passionately in love. This result has been widely publicized in the press and Hollywood movies, interestingly.  <br /> <br />Another result, described as \\"striking\\" by the author, was that the fMRI experiments revealed activity in the ventral tegmental area (VTA) of the brain. The VTA has been revealed to be the center of the reward circuitry of the brain, and is responsible for the creation of dopamine-making cells, thus adding support to her working hypothesis. Because of the association with motivational centers of the brain, the author also claims that these experiments verified that romantic love is a fundamental human mating drive. Thus it can be hard to control, like other drives such as hunger or thirst. The author is careful to note that her experiments did not establish the role of norepinephrine and serotonin in romantic love. In addition, the role of the \\"thinking\\" part of the brain, namely the cerebral cortex, was not revealed in these experiments.	2005-04-10
283268:US	50702879	R1C3KLXZNQR54U	0452284570	345670700	Entanglement	Books	3	22	35	N	Y	Outlines the history well, but a convincing case is lacking	Currently driven by the intense interest in quantum computation and quantum information theory, the subject of the entanglement of quantum states has been widely discussed in both the research literature and the popular press. Most of this discussion has been uncritically supportive of the reality of entangled states, and any views to the contrary have not made their way into refereed physics journals, but instead have appeared on physics blogs or preprint servers. This book is no different than most of the literature on entanglement, for it approaches the subject from a spirit of uncritical adulation for those who are or have been actively involved in research in entanglement. The book would have been a lot more useful if the author had discussed at least some of the criticism regarding the experimental verification of entangled states.<br /><br />In addition to the omission of critical arguments, there are many conclusions that are made in the book that are contingent on a certain philosophy of mathematical proof. When this philosophy is abandoned, these conclusions do not hold. For example, a reader who is sympathetic with the intuitionistic, constructive philosophy of mathematics will reject proofs by contradiction. This would not be an issue if it were not for the fact that proof by contradiction is used to prove many of the results on entangled states. For example, the GHZ theorem in the context of 3-particle entanglement is proved by contradiction in the book. It would be interesting to see a constructive proof of this result. Lacking such a proof would cause some to question the conclusions of the GHZ theorem that the Einstein \\"local elements of reality\\" and quantum mechanics are incompatible.<br /><br />In the context of the GHZ result, it is interesting to read in the book of the connection between knot theory and quantum mechanics. The author reports work by one physicist who has found a correspondence between the GHZ entangled state of three particles and the Borromean rings of knot theory. The Borromean rings are a three-component link wherein the components are topologically linked but the removal of any single component results in a pair of unlinked rings. The GHZ state can be viewed as an entangled superposition of three particles will all of their spins aligned in the z direction. If one measures the spin of one of the three particles, then the state of the entire system collapses into a tensor product and thus becomes \\"disentangled.\\" The author points out though that this result is dependent on the basis that is chosen. If one writes the state in terms of spin alignment in the x-direction, then the state behaves like the Hopf rings. The author gives a very brief discussion of how to generalize this to the case of N particles. These are intriguing results, especially if one remembers the belief of the famous physicist Lord Kelvin that the periodic table can be derived from considerations of knot theory.<br /><br />The book has much more material, most of it extremely controversial if viewed in a skeptical frame of mind. Entanglement is certainly an interesting phenomenon if it truly exists in the physical world, and is not just a consequence of mathematical musings in the Hilbert space formalism chosen for quantum physics. The author does give a fine account of the history behind the study of entanglement, along with discussion of the Bell inequality and the experiments that were constructed to test it. Unfortunately this book, like all the other books and scientific papers on the subject, failed completely to convince this reviewer of the reality of entanglement. Seeing the raw data of the experiments would alleviate the skepticism perhaps, or maybe witnessing the actual experiments. It is the opinion of this reviewer that there is no convincing evidence of entanglement in any of the research literature, and this book, along with this literature, would have to be radically revised to make the case for entanglement sound and without controversy.r entanglement sound and without controversy.	2005-04-10
283544:US	50702879	R27SXBKQY6TY5K	0767918436	934092098	More Than Human: Embracing the Promise of Biological Enhancement	Books	4	16	18	N	Y	Realistic and optimistic	In the last few years there have been a number of books that have served as excellent apologies for the ongoing and very rapid technological developments. The authors of these books have their own beliefs as to the actual rate of technological progress, but they are uniform in their unrelenting optimism about this progress. This is indeed refreshing, considering that most authors that discuss scientific and technological development seem to have one singular goal: to instill anxiety and foreboding in their readers. The author of this book will have none of that, and has written a book that projects a future that is both believable and scientifically realistic. In addition, the author does not hesitate to speculate, but is always careful to note when his speculations begin and end. He also points out the risks that are involved in human modification, and exhibits caution when it is appropriate.<br /><br />One particular topic that the author addresses early on is gene therapy, and considering the hit that gene therapy has taken in the press recently, this is an appropriate choice of topics. It would be unwise to dismiss the viability of gene therapy so early in the game, and the biotech industry needs to be more aggressive in its development. The author discusses some of the applications of gene therapy, including that of the isolation of the growth hormone erythropoietin (EPO) in order to treat anemia. EPO gene therapy could be used by athletes to boost performance, but the author cautions that EPO is probably responsible for the deaths of several athletes in the early 1990's. He also describes alternative strategies using gene promoters, that will allow the control of the EPO levels, and also \\"hybrid\\" approaches that involve both the taking of pills and gene therapy. Also discussed are gene therapies for cosmetic enhancement, for curing baldness, and for curing Alzheimer's disease. Gene therapy for the latter involves the modification of neurons in order that they have extra copies of the gene responsible for production of NGF (nerve growth factor).<br /><br />Some laboratory evidence involving laboratory mice indicates that NGF gene therapy could improve their learning and memory. The author points out one experiment where extra levels of NGF enabled mice to navigate a maze about 60 percent faster than normal mice. He also discusses research where mice were genetically engineered to have extra copies of the NR2B gene, which produces proteins that are needed for the NMDA receptors in the hippocampus. These mice learned things more quickly at any age than normal mice. The downside of this genetic engineering is that the mice also \\"unlearned\\" more quickly, and seemed to be more susceptible to pain than ordinary mice.<br /><br />Another unique feature of this book that sets it apart from other apologies for enhancement technologies is the inclusion of statistical evidence for many of its assertions. The reader will find bar graphs, references to pertinent statistical studies in the literature, and other graphs as appropriate. Particularly interesting is the graph on worldwide life expectancy, since it indicates that life expectancy at later age has not risen much in the last one hundred years. The author then proceeds to give a fascinating account of the research that has been done in life extension in the last few years. Some of this research involved the changing of a single gene, which for the case of the nematode worm resulted in the tripling of its life span. Even though his discussion is fairly short, the author gives enough to motivate the reader to search for more in-depth discussion of the research in this very exciting area. The possibility of increasing human life spans by decades or more will of course raise the interest of the majority of people. The author believes that therapies that can increase human life span will enter into human trials within the next decade. This is a very optimistic projection considering the current perceptions of the FDA and the pharmaceutical industry as a whole.<br /><br />Readers who are impatient to get on with the genetic engineering of humans will have to wait a little longer. As the author reminds us, the germline genetic engineering of a human embryo has not been attempted as of yet. The gene therapy for Ashanti DeSilva was `somatic' gene therapy, and could not be passed on to her children. The author though mentions a procedure that would blur the distinction between germline genetic engineering and somatic gene therapy. It involves in utero gene therapy, and is done while the fetus is still in the mother's womb. Such a technique was never carried out, due to regulatory restrictions, but the author gives several reasons why it could be viable. Genetic diseases like Tay-Sachs, cystic fibrosis, congenital heart problems could be eliminated he says by this technique. The author points out, interestingly, that 59 percent of the American population approves of the use of genetic engineering to eliminate disease from the unborn. It is actually surprising, at least to this reviewer, that this figure is so high, given the anxiety about genetic engineering in general, even in areas as \\"trivial\\" ethically as genetically modified crops. In addition, and this is most refreshing to read, the number of Americans who approve of genetic engineering to create desired traits in children went from 10 percent in 1994 to 20 percent in 2002, according to a study quoted in the book. This is a promising trend, and gives one hope that the population as a whole will eventually appreciate the ethical soundness of using genetic engineering.<br /><br />The author also addresses the controversy on human reproductive cloning, noting correctly that it is not safe to perform today, but supporting its use when safety concerns have been overcome. Reproductive cloning will hopefully become routine in this century, and human clones will enjoy the rights that all humans have. Banning reproductive cloning is not necessary, the author argues. Clones will be ordinary people, like the rest of us.idering the current perceptions of the FDA and the pharmaceutical industry as a whole.  <br /> <br />Readers who are impatient to get on with the genetic engineering of humans will have to wait a little longer. As the author reminds us, the germline genetic engineering of a human embryo has not been attempted as of yet. The gene therapy for Ashanti DeSilva was `somatic' gene therapy, and could not be passed on to her children. The author though mentions a procedure that would blur the distinction between germline genetic engineering and somatic gene therapy. It involves in utero gene therapy, and is done while the fetus is still in the mother's womb. Such a technique was never carried out, due to regulatory restrictions, but the author gives several reasons why it could be viable. Genetic diseases like Tay-Sachs, cystic fibrosis, congenital heart problems could be eliminated he says by this technique. The author points out, interestingly, that 59 percent of the American population approves of the use of genetic engineering to eliminate disease from the unborn. It is actually surprising, at least to this reviewer, that this figure is so high, given the anxiety about genetic engineering in general, even in areas as \\"trivial\\" ethically as genetically modified crops. In addition, and this is most refreshing to read, the number of Americans who approve of genetic engineering to create desired traits in children went from 10 percent in 1994 to 20 percent in 2002, according to a study quoted in the book. This is a promising trend, and gives one hope that the population as a whole will eventually appreciate the ethical soundness of using genetic engineering.  <br /> <br />The author also addresses the controversy on human reproductive cloning, noting correctly that it is not safe to perform today, but supporting its use when safety concerns have been overcome. Reproductive cloning will hopefully become routine in this century, and human clones will enjoy the rights that allhumans have. Banning reproductive cloning is not necessary, the author argues. Clones will be ordinary people, like the rest of us.  <br /> <br />	2005-04-09
293659:US	50702879	R3UD7LM08GKQFC	0262072548	65017141	The Cognitive Neurosciences III (MIT Press)	Books	5	41	42	N	N	Fascinating	This (sizable) book is the third in a series of updates that are published every five years and whose goal is to delineate in as much detail as possible the status of research in cognitive neuroscience. Cognitive neuroscience has become an exciting field in the last fifteen years, this due in large part to the experimental techniques available to researchers. In addition, researchers in cognitive neuroscience have been more willing in recent years to take on research topics that were viewed as marginal from a scientific viewpoint. One of these concerns the scientific study of consciousness, and a large portion of this book discusses the latest results in this area. The book is definitely directed towards experts, but non-experts (such as this reviewer) with a good general background in brain science can still gain a lot from the perusal of the articles. Due to constraints of space, only a few of the articles (of the fourteen that this reviewer read) will be reviewed here.<br /><br />In their article \\"From Number Neurons to Mental Arithmetic: The Cognitive Neuroscience of Number Sense,\\" the authors investigate how the brain represents and manipulates numbers. Their investigation covers both human and primate abilities in mathematics, and they use both behavioral data and data obtained from functional imaging to make their case that an elementary number system is present very early in the life in both humans and animals. Preverbal human infants in particular are able to discriminate sets on the basis of their cardinality. Using the method of habituation and recovery of looking time, the authors point out that researchers have shown that both newborns and preverbal infants have the ability to discriminate between sets of visual objects, along with tones or words that differ in the number of syllables, on the basis of their numerosity. The authors though point out the difficulties in studying experimentally the performance of humans and nonhumans in number estimation. The accuracy of these experiments decreases as the numbers increase, and the variability increases with the size of the number, following what is called `Weber's law.' The authors include several graphs that illustrate evidence for Weber's law in both animal and human numerical behavior. As to the actual part of the brain where numerical processing takes place, the authors hold that data from neuroimaging points to the horizontal segment of the intraparietal sulcus in the parietal lobes (HIPS). This data shows that the HIPS becomes more active when subjects estimate the approximate result of an addition problem, rather than compute the exact solution. In addition, HIPS is active when a comparative operation that requires access to a numerical scale is needed. The HIPS can also show strong category specificity for numbers when contrasted with different categories of objects of concepts. In addition, the activation of HIPS is not dependent on the modality of the input used to present numbers, and exists even when subjects were unaware of the presence of a numerical symbol. Lastly, the authors quote neuropsychological studies that indicate that HIPS plays a central role in numerical quantity representation.<br /><br />An intense debate that has taken place in both cognitive neuroscience and in philosophical circles concerns the domain specificity of cognitive systems. In the article \\"Domain Specificity in Cognitive Systems,\\" the authors present the electrophysiological, and neuropsychological evidence, as well as evidence from neuroimaging for the thesis of a domain specific organization of the prefrontal cortex. Of particular interest in the discussions in this article is the discovery that neuronal-firing is location-specific and directly associated with accurate recall. In addition, studies of small lesions in the dorsolateral prefrontal cortex have indicated that these lesions have resulted in memory loss for some hemifields or visual field locations. Prefrontal neurons, the authors assert, are adapted to and defined by the type of data they retain. Even more fascinating is the assertion that single neurons store single spatial locations, and that memory operations are performed by a dedicated group of prefrontal neurons. If these assertions are true, they have enormous consequences not only for drug design but also for the field of artificial intelligence.<br /><br />In the article \\"A Framework for Consciousness,\\" the authors discuss their ideas on the problem of consciousness and the experimental techniques that could possibly support these ideas. Being more theoretical than the rest of the articles in the book, this article is one of the many that have only appeared in recent years due to the change in attitude regarding scientific investigations of consciousness. Indeed, such studies have become respectable in many neuroscientific circles, and this is fortunate given that the study of consciousness has been historically delegated mostly to philosophers, with consequently very few results that shed light on the origin and nature of consciousness. The authors define a `framework' as a \\"point of view\\" for approaching a scientific problem, and not a collection of hypotheses as is normally the practice in scientific research. A framework they say is likely to be incorrect in all the details, and holds unstated assumptions, but it is appropriate to use at a time when a field is still in its infancy. The goal of the authors is to explain the problem of qualia, i.e. the connection between subjective sensations and the physical interactions in the brain. They do not attack this problem directly, but instead they use the `neural correlates of consciousness (NCCs)', and outline the framework in which NCC is to be studied. This framework consists of the assumption of a nonconscious homunculus, the existence of \\"zombie\\" modes as nonconscious cortical reflexes, the existence of transient coalitions of neurons, explicit representations, and essential nodes, the `higher levels first' assumption, the existence of driving and modulation connections, the assertion that conscious awareness involves a series of \\"static snapshots\\", the assumption that attention and consciousness are separate processes, the role of \\"synchronized firing\\", and the existence of a \\"penumbra\\" or collection of neurons not part of the NCC, that are responsible for the \\"meaning\\" behind the neuronal firing.al neurons, the authors assert, are adapted to and defined by the type of data they retain. Even more fascinating is the assertion that single neurons store single spatial locations, and that memory operations are performed by a dedicated group of prefrontal neurons. If these assertions are true, they have enormous consequences not only for drug design but also for the field of artificial intelligence.  <br /> <br />In the article \\"A Framework for Consciousness,\\" the authors discuss their ideas on the problem of consciousness and the experimental techniques that could possibly support these ideas. Being more theoretical than the rest of the articles in the book, this article is one of the many that have only appeared in recent years due to the change in attitude regarding scientific investigations of consciousness. Indeed, such studies have become respectable in many neuroscientific circles, and this is fortunate given that the study of consciousness has been historically delegated mostly to philosophers, with consequently very few results that shed light on the origin and nature of consciousness. The authors define a `framework' as a \\"point of view\\" for approaching a scientific problem, and not a collection of hypotheses as is normally the practice in scientific research. A framework they say is likely to be incorrect in all the details, and holds unstated assumptions, but it is appropriate to use at a time when a field is still in its infancy. The goal of the authors is to explain the problem of qualia, i.e. the connection between subjective sensations and the physical interactions in the brain. They do not attack this problem directly, but instead they use the `neural correlates of consciousness (NCCs)', and outline the framework in which NCC is to be studied. This framework consists of the assumption of a nonconscious homunculus, the existence of \\"zombie\\" modes as nonconscious cortical reflexes, the existence of transient coalitions of neurons, explicit representations, and essential nodes, the `higher levels first' assumption, the existence of driving and modulation connections, the assertion that conscious awareness involves a series of \\"static snapshots\\", the assumption that attention and consciousness are separate processes, the role of \\"synchronized firing\\", and the existence of a \\"penumbra\\" or collection of neurons not part of the NCC, that are responsible for the \\"meaning\\" behind the neuronal firing.	2005-04-01
304332:US	50702879	R15TLA0VIRJXPY	9810232802	565145841	Photosynthetic Excitons	Books	5	3	3	N	N	A very detailed treatment of the physics of photosynthesis	As defined in this book, and in other works on condensed matter physics, an exciton is a superposition of localized molecular excitations. The physics of excitons must of course be described by quantum mechanics (or better yet quantum field theory), and this description is given ample detail in this book for the case of excitons in the photosynthetic system of plants and cyanobacteria. It discusses the physics of photosynthetic excitons by breaking it up into two cases. The first of these is where the broadening the absorption and flourescence bands is larger than the coupling strength between pigments, and hence perturbation theory (the Fermi Golden Rule) can be applied. The second case is where the coupling is the same order of magnitude or greater than the amount of broadening. The first case describes the incoherent energy transfer between the donor and acceptor molecules in the photosynthetic apparatus, and is described by the Forster equation, which was derived early on in the study of the physics of photosynthesis. In the second case one must study `coherent' excitons, which are those where the excitations are not localized on individual molecules.<br /><br />The authors give a comprehensive overview of the dynamics of excitons in photosynthetic complexes and their steady-state spectroscopic properties in this book. Readers of the will probably have different interests when approaching the book, some may want a more theoretical emphasis, while others want to understand the experimental or spectroscopic results in photosynthesis. Both sets of readers will find what they are looking for in the book, and also much more detail if needed in the larger number of references given. All readers are expected to have a solid understanding of the photosynthetic system from a biological or descriptive perspective, and a solid background in quantum physics at the advanced graduate level. The book is fascinating reading, and considering the importance of photosynthesis, is one that certainly become a classic in the field. There is serious discussion at the present time in systems of artificial photosynthesis, and in using the photosynthetic apparatus as a method of computation. Whether this research will get off the ground and produce useful technologies remains to be seen, but certainly an understanding of the physics of photosynthesis as given in this book will play a role in attempting to bring these projects to fruition.<br /><br />Such a long and detailed book cannot be reviewed in the space available, but there are many places in the book that stand out in their clarity and the degree of fascination they instill in the reader and deserve mention. One of these concerns the use of the stochastic Liouville equation in describing the depolarization of a dimer in an ultrafast flourescence or transient absorption experiment. The authors use a `delocalized' representation to calculate the density matrix elements, and consequently calculate the intensity of the flourescence, for orientations of the polarizer both parallel and perpendicular to the excitation and detection branch.<br /><br /> Another interesting discussion in the book, because of both its clarity and its conciseness, is one that concerns a kinetic model of a light-harvesting antenna (LHA) complex consisting of several pigments with localized excitons. The LHA is modeled by a homogeneous rectangular or hexagonal lattice. The kinetics within the LHA is then determined by the hopping rate, and the charge separation in the reaction center (RC) is included as a quenching rate on one of the lattice sites. The kinetic model illustrates the role of the LHA, via the dense packing of pigments in it, in enhancing the number of photons that reach the RC. The lifetime of an exciton increases because of this, but only at the expense of the slower decay of excited states. The authors discuss how to determine the relation between the LHA and the RC experimentally by using time-resolved methods to compare the kinetics of the excited states obtained after excitation of the LHA with those obtained by direct excitation of the RC. Particularly interesting in these experiments is the use of genetic mutants lacking LH2 to study the kinetics within the RC.<br /><br /> The authors also spend two entire chapters on the nonlinear annihilation of excitons, both from a theoretical and an experimental point of view. The nonlinear processes which they study come primarily from molecules that are in excited singlet (S) or triplet (T) states, and are referred to as singlet-singlet (S-S) and singlet-triplet (S-T) annihilation. They arise primarily at high excitation densities, are diffusion-limited, and result in excess energy being redistributed among the vibrational modes. The authors derive the kinetic equations for a collection of pigment molecules located on the sites of a regular lattice, where each molecule is characterized by a set of singlet states. They then discuss the case where singlet excited molecules can be converted into triplet states via intersystem crossing. The kinetic equations for the density of the excited states are derived, and the authors show how `anti-Smoluchowski triplet-triplet (T-T) annihilation can arise because of the inhomogeneous distribution of triplets resulting from S-T annihilation.  They also discuss in some detail the local heating that results from the excitation annihilation. This local heating has the effect of modifying the coupling of the molecule to its surroundings, resulting sometimes in the `polaron effect'. The authors use collective coordinates to study the (linear) coupling between an electron and the collective nuclear motion. The dynamics of the collective coordinates are described by a stochastic damped oscillator equation.  For the case where the kinetics of the collective coordinates is fast relative to the changes in temperature and occupation number of the molecule. Thermal fluctuations are thus neglected and the equation can be readily solved. For the case where the collective coordinates change slow with respect to changes in temperature, one again gets a solution, and also a notion of `difference absorption spectrum', which the authors discuss in the context of pump-probe spectroscopy.resolved methods to compare the kinetics of the excited states obtained after excitation of the LHA with those obtained by direct excitation of the RC. Particularly interesting in these experiments is the use of genetic mutants lacking LH2 to study the kinetics within the RC.  <br /> <br /> The authors also spend two entire chapters on the nonlinear annihilation of excitons, both from a theoretical and an experimental point of view. The nonlinear processes which they study come primarily from molecules that are in excited singlet (S) or triplet (T) states, and are referred to as singlet-singlet (S-S) and singlet-triplet (S-T) annihilation. They arise primarily at high excitation densities, are diffusion-limited, and result in excess energy being redistributed among the vibrational modes. The authors derive the kinetic equations for a collection of pigment molecules located on the sites of a regular lattice, where each molecule is characterized by a set of singlet states. They then discuss the case where singlet excited molecules can be converted into triplet states via intersystem crossing. The kinetic equations for the density of the excited states are derived, and the authors show how `anti-Smoluchowski triplet-triplet (T-T) annihilation can arise because of the inhomogeneous distribution of triplets resulting from S-T annihilation.  They also discuss in some detail the local heating that results from the excitation annihilation. This local heating has the effect of modifying the coupling of the molecule to its surroundings, resulting sometimes in the `polaron effect'. The authors use collective coordinates to study the (linear) coupling between an electron and the collective nuclear motion. The dynamics of the collective coordinates are described by a stochastic damped oscillator equation.  For the case where the kinetics of the collective coordinates is fast relative to the changes in temperature and occupation number of the molecule. Thermal fluctuations are thus neglected and the equation can be readily solved. For the case where the collective coordinates change slow with respect to changes in temperature, one again gets a solution, and also a notion of `difference absorption spectrum', which the authors discuss in the context of pump-probe spectroscopy.	2005-03-23
308976:US	50702879	R2LCR0GN6FO7CF	0742534081	301876115	Cloning After Dolly: Who's Still Afraid?	Books	5	10	10	N	Y	Brilliant	Once again this author has given the reading public a book that cuts through the media hype, superstition, and emotionalism that has polluted debate on human cloning and genetic engineering. He discusses the science of cloning in a manner that will be understandable to readers who are not specialists in biotechnology, and counters successfully the moral and ethical arguments against cloning, particularly human reproductive cloning. But the book is not only about finding counterarguments against human cloning. The author understands that in addition to these, one needs to make a positive, constructive case for human cloning. He does so in this book, in fact devotes an entire chapter to it. Most importantly, the author refrains from the vituperation that can frequently accompany discussion on genetic engineering, and has given the reader a book that is both detailed and broad in scope.<br /><br /> Those of us who strongly support research into biotechnology have known for some time that there would be a backlash against it. What we did not know is that this backlash would occur so soon, believing that it would take place maybe a few decades from now. Nevertheless it is upon us, and every effort should be made to fight against the ignorance, disinformation, and false platitudes that are now dominating discussion on cloning and biotechnology, as well as other areas of technology. The inspiration and common sense needed for this fight can be found in this book, and in great abundance.	2005-03-19
309021:US	50702879	R3E87ZQ4HM3EYH	0813339367	683590358	Man the Hunted: Primates, Predators, and Human Evolution	Books	5	47	50	N	Y	Finally	From a mathematical/statistical viewpoint, one of most unjustified beliefs of the modern age is that humans are a killer species. Unfortunately this myth is embedded in both popular and scientific cultures, and has resulted in a completely distorted view of human and primate species. The number of humans throughout history that have actually killed another human being is extremely small, and warfare is actually quite rare between humans. Yet we are told over and over again that humans have an innate propensity for murder or violence. The good news is that such a viewpoint has been challenged recently by some anthropologists and social psychologists, with two of these being the authors of this book. They not only give fossil evidence that supports their assertion that humans and other primates are not violent by nature, but also give constructive arguments as to their actual nature, namely that their behavior is a consequence of their exposure to predation. The book is fascinating reading, and readers who accept the \\"Man the Hunter\\" paradigm in anthropology will find solid challenges to their belief structures. It is indeed refreshing to finally see a book in print that gives serious effort to countering this paradigm.<br /><br />The book begins with the authors asking whether human evolution has been molded by hunting ability or by survival techniques that were developed to avoid being eaten. They then spend much of the book elaborating on the fossil record and contemporary evidence of predation on human and non-human primates. The authors are intellectually honest enough to admit that quantitative data is sparse, and that they use current examples of predation on primates to estimate the rates of predation on ancient hominids. Fossils of the losers in predator-prey encounters are available they say, but there are not enough of them to obtain conclusive figures on the rate of predation or reliable information on successful strategies to outwit predators.<br /><br />As an example of their analysis, the authors point out that in all the research conducted so far, killings among chimpanzees averaged only one every 8.5 - 17 years. So much for the assertion that chimpanzees are natural-born killers. They also point out, but unfortunately do not give any references, that current research into the neurophysiology of aggression between species indicates that this form of aggression is very different from the violence humans sometimes wage against each other. Because of its importance, and because it would enhance the case of the authors, it would have been very helpful if the authors had cited research papers on this topic.<br /><br />Most enlightening is the section of the book entitled \\"The Other 50%\\" the authors illustrate, without appeals to some current notions of \\"masculine\\" versus \\"feminine\\" science, the pitfalls of ignoring how the females are behaving in primate groups. Why is the behavior of females always ignored in anthropological studies? The historical record reveals that women are even less violent than men have been, and most men, in fact the vast majority, have not been violent. In this section the authors also briefly discuss the research of Adrienne Zihlman, a physical anthropologist whose studies revealed that in early hominid societies women conducted most of the socialization of the young and were repositories of group knowledge, among other things. Most interestingly, these studies revealed that females chose sexual partners that were less aggressive than others, completing negating frequent contemporary assertions to the contrary.<br /><br />Other interesting discussions or facts in the book include: 1. The large change (300cc) in cranial capacity that occurred from the time of the first known member of human genus (H. habilis) to H. erectus. The authors quote research that indicates that 20cc of brain tissue is added every 100,000 years. 2. The \\"Man the Dancer\\" hypothesis. The authors admit to sarcasm here, but their discussion serves as an amusing counterexample to the \\"Man the Hunter\\" dogma. Activities such as face-to-face sex, cooperation, language and singing, and bipedalism could be explained by a propensity to dance rather than a desire to hunt, they humorously emphasize. In a light-hearted way they expose the absurdity of the Man the Hunter hypothesis. 3. The detailed discussion of the six different explanations for bipedalism: carrying, vigilance, heat-dissipation, energy-efficiency, display, and foraging. The authors are careful to point out that none of these explanations are causal explanations of bipedalism, but rather our ancestors were `preadapted' for it. They discuss some of the factors that make bipedalism advantageous, such as carrying food and tools, sitting upright while eating, etc. 4. The discussion of the predominant role of intelligence in dealing with predators, by confronting the `predation sequence' at its earliest stages.<br /><br />So why do so many scientists and the \\"general public\\" accept the view that human ancestors were bloodthirsty killers? The authors believe that there are three reasons for this, namely the `perverted' Western views of modern humans, the Christian concept of `original sin', and `sloppy science'. They devote an entire chapter to the elaboration of these reasons, and their arguments are convincing. Whether or not their ideas will replace the current hunter-killer paradigm only time will tell. Hopefully these ideas, or better ones that are formulated when more evidence becomes available, will do just that.asm here, but their discussion serves as an amusing counterexample to the \\"Man the Hunter\\" dogma. Activities such as face-to-face sex, cooperation, language and singing, and bipedalism could be explained by a propensity to dance rather than a desire to hunt, they humorously emphasize. In a light-hearted way they expose the absurdity of the Man the Hunter hypothesis. 3. The detailed discussion of the six different explanations for bipedalism: carrying, vigilance, heat-dissipation, energy-efficiency, display, and foraging. The authors are careful to point out that none of these explanations are causal explanations of bipedalism, but rather our ancestors were `preadapted' for it. They discuss some of the factors that make bipedalism advantageous, such as carrying food and tools, sitting upright while eating, etc. 4. The discussion of the predominant role of intelligence in dealing with predators, by confronting the `predation sequence' at its earliest stages.  <br /> <br />So why do so many scientists and the \\"general public\\" accept the view that human ancestors were bloodthirsty killers? The authors believe that there are three reasons for this, namely the `perverted' Western views of modern humans, the Christian concept of `original sin', and `sloppy science'. They devote an entire chapter to the elaboration of these reasons, and their arguments are convincing. Whether or not their ideas will replace the current hunter-killer paradigm only time will tell. Hopefully these ideas, or better ones that are formulated when more evidence becomes available, will do just that.	2005-03-19
317996:US	50702879	R3Q3BF44R63103	0521853249	450845566	The Torture Papers: The Road to Abu Ghraib	Books	5	36	41	N	Y	A recorded history of sadism, incompetence, and cowardice	The editors of this book have done a fine job, and the publisher should be commended for bringing this sizable collection to print. Due to the size of the book, long periods of time would be required to read all of the memorandums in it. A great deal of information can be gained however from the perusal of even a small number of these memorandums. They give an inside view of the workings of a collection of individuals who are far from the combat sands of Iraq and Afghanistan, and whose goal is to make sure that they will be insulated from any legal consequences of their actions and recommendations. Joshua L. Dratel, one of the editors of the book, states this clearly when he asserts that the implicit message in the memoranda is that the policy makers who wrote them actually detest the American system of justice and find it impractical as a tool for fighting terrorism. This reviewer is in full agreement with Dratel's commentary. Indeed, the memoranda definitely support the notion that its authors consider it axiomatic that the Constitution, the Geneva Convention, and other bodies of law are impotent in the face of international terrorism. They have let the events of 9/11 lower considerably their confidence in rational, legal procedures for the resolution of conflicts. Dratel states it concisely and correctly when he states that the events of 9/11 `cannot serve as a license - for our government in its policies, or for ourselves in our personal approach to grave problems - to suspend our constitutional heritage, our core values as a nation, or the behavioral standards that mark a civilized and humane society.'<br /><br />Some insight, however limited, can be gained from Memo 11, which is one of the memorandums that Bush put forward regarding the treatment of detainees and the prisoner-of-war status of the Taliban and Al Qaeda. After reading Memo 11, the question immediately arises: Why did the memorandums and discussion continue even after Memo 11 (the Bush memorandum to the Vice President, et al)? After all, in this memo, Bush explicitly states that the Geneva provisions do not legally cover Al Qaeda and the Taliban. But Bush emphasizes that even though he accepts the legal conclusions of the Attorney General and the Department of Justice regarding the inapplicability of the Geneva convention to Al Qaeda and the Taliban, and that he therefore has the \\"authority under the Constitution\\" to suspend Geneva, he nevertheless decides to \\"decline to exercise that authority.\\" However, Bush is careful to note that he \\"reserves the right\\" to exercise this authority in future conflicts. In addition, he orders that detainees be treated humanely, according to the principles of Geneva, \\"including those who are not legally entitled to such treatment.\\" Thus it appears that any further legal argumentation by anyone in the administration regarding the use of torture should be viewed as purely academic. But as this book clearly shows, there was still much discussion on these matters after Memo 11 was sent (February 7, 2002). The need for further discussion is not clear even after reading the memorandums that were sent between various individuals after Memo 11.<br /><br />Torture has been practiced by many different individuals, political and religious groups, and regimes throughout history. Whether it is the Catholic Church in the Inquisition, the Chinese government under Mao ZeDong, or American military personnel in Iraq, the practice of torture is not exclusive to \\"leftist\\" or \\"rightist\\" political groups. The use of torture though to gain information is an implicit admission of the inability to collect real intelligence, either because of laziness or incompetence. Those individuals who practice torture for this reason no doubt understand this. They fully understand that torture is useless in gaining helpful information from prisoners. Therefore their decision to engage in the torture of prisoners is no doubt a result of their sadistic nature, which can be brought out not only in the theatre of war but also under the protection of religious and governmental institutions. These institutions, despicable and contemptible as they are, deserve every legal penalty available against them. Of course, legal penalties presuppose the existence of institutions that have the legal authority to carry them out. Considering the status and jurisdiction of international law in the last few years, the number of these institutions is in rapid decline, leaving the practical application of torture open to any country that desires to carry it out.ght out not only in the theatre of war but also under the protection of religious and governmental institutions. These institutions, despicable and contemptible as they are, deserve every legal penalty available against them. Of course, legal penalties presuppose the existence of institutions that have the legal authority to carry them out. Considering the status and jurisdiction of international law in the last few years, the number of these institutions is in rapid decline, leaving the practical application of torture open to any country that desires to carry it out.	2005-03-12
319895:US	50702879	R1XYAF9IJQU4GT	0895260476	989380415	The Politically Incorrect Guide to American History	Books	3	16	29	N	Y	Biased....but	That one can be biased and still tell the truth can be a troubling assertion to many, but it is true nevertheless. For example, a reporter sympathetic with the current administration and assigned to Iraq may decide to report only the \\"good\\" news he encounters there, such as hospitals and schools being built, and so on. The fact that the reporter omitted the news of people dying does not erase these \\"good\\" facts. The reporter is simply not reporting the entire story because of personal bias and political sympathies. The reporter is still telling the truth however, namely that hospitals and schools are indeed being built.<br /><br />The reporting of facts that occurred in long periods of time is what we call history, and like \\"ordinary\\" reporting, it too can be done honestly, even though a great deal of bias exists in the historian's mind as to what is important enough to include in his work. For example, the historian Howard Zinn emphasized what he considered to be the bad events in American history. Many readers of his works are angered by his assertions, and claimed that they are not truly representative of American history.<br /><br />This book, like the one by Zinn, views American history with a large degree of political bias. Its title alone is a good illustration of this, for it immediately alerts the reader that the facts to be reported will be those that the author considers to be \\"politically incorrect.\\" Like the term \\"liberal\\", the designation of some dialog as being \\"politically incorrect\\" has taken on a vague connotation in recent years, but one could perhaps use it in a general sense to be the type of dialog that those with a conservative political philosophy would be sympathetic with.<br /><br />The book is fast reading, and as a scholarly work it needs a lot of fleshing out. There are many places in the book, like other history books, where the author does not justify his assertions. Some of these include:<br /><br />- That charitable giving in the 1980s grew at a 55% percent faster annual rate than the rate it had during the previous 25 years. The author quotes a source for this claim, but does not include the statistics or analysis in the book unfortunately. In addition, the author implicitly assumes that \\"greed\\" is immoral. One could debate this at length, but it reflects the author's bias towards a particular doctrine of morality. But again, the author's claims will motivate inquisitive readers to find out the facts for themselves.<br /><br />- That Ronald Reagan \\"defeated Communism,\\" forgetting the contributions of reformers in the former Soviet Union, such as that of Mikhail Gorbachev. Both Reagan and Gorbachev played a role, and it would have been helpful for the reader if the author had discussed the degree that each contributed to the dissolution of the Soviet regime.<br /><br />- The reference to \\"dishonest reporters and political commentators\\". Who are they? The author should have given examples of their dishonesty and commentary.<br /><br />- That during the Clinton administration, the Pentagon apparently required special permission for promotions of all white men without disabilities. How does he know this? He should have included copies of the relevant documents or gave references supporting this assertion.<br /><br />- That Clinton helped spread Islamic radicalism into Europe because of the Balkan campaign. This is a difficult thing to prove, requiring extensive statistical sampling and research. How much did Islamic radicalism spread and what countries in Europe were most affected? Most importantly, how does one distinguish Islamic radicalism from \\"ordinary\\" Islamic philosophy?<br /><br />- That Clinton bombed the pharmaceutical factories in the Sudan to distract the American public from the Lewinski scandal. This assertion claims to knowledge of Clinton's frame of mind, and can never be proved with certainty. Such speculations should be left to a book on political aesthetics, not a serious book on history.<br /><br />- That the poor in America are better off in actuality than any other people in previous ages. To prove this would be extremely difficult, taking an entire book in itself, and a huge amount of statistical data.<br /><br />- That 1960s liberalism discouraged all the \\"right\\" things and encouraged all the \\"wrong\\" ones. As to what is right or wrong for a human being is a value judgment, and so the author should have spent considerably more time elaborating on just what he meant. Not only that, the word \\"liberalism\\" has been kicked around a lot in the last few decades. The author needs to be more careful in how this word is used and to what group of people the word \\"liberal\\" actually describes. Will the real liberal please stand up?<br /><br />There are many assertions however in the book that are very interesting, and deserve further investigation. Some of these include the assertion that there was a net increase in taxes in the 1980s. Another is the claim that Clinton ordered the military overseas 48 times during his tenure as president.<br /><br />The book therefore is well worth reading, in spite of its inherent bias. It could serve as a counterweight to the book by Zinn and others written on American history. With enough books on American history written by many different authors, each with distinct and various degrees of personal and political bias, one can gain a truly accurate view of the subject. Of course, the reading of these works will require long periods of time, and some amount of filtering or bias will be needed to sift through the enormous number of facts. Thus for both author and reader, bias is a fact of life, occurring in various degrees depending on the person, and determining what information will be held in memory.n history.<br /><br />- That the poor in America are better off in actuality than any other people in previous ages. To prove this would be extremely difficult, taking an entire book in itself, and a huge amount of statistical data.<br /><br />- That 1960s liberalism discouraged all the \\"right\\" things and encouraged all the \\"wrong\\" ones. As to what is right or wrong for a human being is a value judgment, and so the author should have spent considerably more time elaborating on just what he meant. Not only that, the word \\"liberalism\\" has been kicked around a lot in the last few decades. The author needs to be more careful in how this word is used and to what group of people the word \\"liberal\\" actually describes. Will the real liberal please stand up?<br /><br />There are many assertions however in the book that are very interesting, and deserve further investigation. Some of these include the assertion that there was a net increase in taxes in the 1980s. Another is the claim that Clinton ordered the military overseas 48 times during his tenure as president.<br /><br />The book therefore is well worth reading, in spite of its inherent bias. It could serve as a counterweight to the book by Zinn and others written on American history. With enough books on American history written by many different authors, each with distinct and various degrees of personal and political bias, one can gain a truly accurate view of the subject. Of course, the reading of these works will require long periods of time, and some amount of filtering or bias will be needed to sift through the enormous number of facts. Thus for both author and reader, bias is a fact of life, occurring in various degrees depending on the person, and determining what information will be held in memory.	2005-03-10
323972:US	50702879	R2SJT6WAE9V1H3	0262661748	974898584	Complex Worlds from Simpler Nervous Systems (MIT Press)	Books	5	13	13	N	Y	Very interesting and informative	Anyone curious as to extent to which various human cognitive and neural capabilities are can exist in nervous systems that are much smaller and simpler than humans will gain a lot from the perusal of this book. But more importantly, the book also offers a glimpse of how these nervous systems are able to deal with their environment in ways that perpetuate the survival of the organisms that possess them. Their abilities in many ways surpass those of humans, but the comparison with humans should really not be the focus of attention. The most important thing to gain from the reading of this book is that nervous systems have evolved in ways that are advantageous to the organism. As two authors in the book expressed it, \\"the abilities of an animal seem to be governed largely by what it needs to pursue its lifestyle.\\" All of the articles in this book are interesting, but for lack of space only three of them will be reviewed here.<br /><br />The authors of the article \\"Exploration of Cognitive Capability in Honeybees: Higher Functions Emerge from a Small Brain\\", give a brief but fascinating overview of the research that has been performed in the neural and learning capabilities of honeybees. It is incredible fact, as brought out in the article, that the brain of the worker honeybee is only one cubic millimeter in volume, has a mass of only 1 mg, and has less than a million neurons. In spite of these dimensions however, honeybees are still able to process visual and motion information in ways that are very similar to the way that humans do. Indeed the honeybee is able to engage in pattern recognition, perception, and the learning of complex tasks. Honeybees are able to take pattern presented to them, train on these patterns, and use what they have learned to evaluate new patterns presented to them. Most interestingly, the authors describe experiments that show that honeybees are able to perceive some of the illusions that humans do. Other abilities discussed include learning to negotiate complex mazes, and are able to count landmarks as they do. Furthermore, they make use of rules that worked in the past in order to navigate through mazes. Thus bees exhibit a remarkable ability to construct concepts. The authors also mention the exciting prospect of constructing a learning machine that is capable of performing behavior similar to the honeybee. Given the size of the honeybee brain, this certainly seems like a goal that could be readily accomplished.<br /><br /> In the article \\"In the Mind of a Hunter: The Visual World of Praying Mantis\\", the authors present the mantis as being an insect that is very complex from the standpoint of its ability to process information, being manifested in what the authors refer to as \\"plastic behaviors.\\" Anyone who has observed a praying mantis in a garden or other places outdoors cannot help but be fascinated by their behavior. This article puts these behaviors on a neurological foundation, and the picture the authors paint is a very interesting one. The reader learns of the compound eyes of the praying mantis, which allow visualization in every direction. The range of light intensity (four log units) allows the mantis to distinguish between different objects. Amazingly, their eyes have about nine thousand sampling units or `ommatidia' as the authors call them. But it is the \\"prey recognition\\" algorithm used by mantids that is of primary interest to the authors. They have found through their research that this algorithm depends on the simultaneous assessment of a collection of stimulus parameters. From the standpoint of its nervous system, prey recognition is accomplished by a movement-sensitive cell called the lobula giant movement detector (LGMD). The LGMD is presynaptic to the descending contralateral movement detector (DCMD). They mention the construction of an artificial neural network of the LGMD-DCMD systems that learns to respond to the same types of stimuli that mantids recognize as prey, but unfortunately do not discuss it in any detail.<br /><br /> The author of the article \\"Motion Perception Shapes the Visual World of Amphibians\\" discusses how frogs and toads are able to catch their prey, avoid predators, and find mates without the benefit of eye movements. The emphasis in the article is in on how these different entities are classified and discriminated, how retinal images of moving objects are discriminated from self-induced moving images, on whether or not toads employ concepts or engage in learning, and how toads analyze visual stimuli without the benefit of a cerebral neocortex. The distinction between prey and nonprey is correlated with the geometry of the object relative to the direction of movement. In order to justify what is happening at the neuronal level, the author describes the properties of the retinal ganglion cells (which mediate the output of the retinal network) and the neurons of the retinal projection fields in terms of their receptive fields. A table is given along with extension discussion of their properties. Toads also make use of the odor of their prey, and the author discusses, with a detailed diagram, the brain structures involved in visual-olfactory learning. Most interesting is the author's discussion of backpropagation artificial neural networks used to model the feature detection abilities of amphibians. A two-layered artificial neural network is trained to classify and evaluate objects of different lengths moving in prey and nonprey configurations.ut unfortunately do not discuss it in any detail.  <br /> <br /> The author of the article \\"Motion Perception Shapes the Visual World of Amphibians\\" discusses how frogs and toads are able to catch their prey, avoid predators, and find mates without the benefit of eye movements. The emphasis in the article is in on how these different entities are classified and discriminated, how retinal images of moving objects are discriminated from self-induced moving images, on whether or not toads employ concepts or engage in learning, and how toads analyze visual stimuli without the benefit of a cerebral neocortex. The distinction between prey and nonprey is correlated with the geometry of the object relative to the direction of movement. In order to justify what is happening at the neuronal level, the author describes the properties of the retinal ganglion cells (which mediate the output of the retinal network) and the neurons of the retinal projection fields in terms of their receptive fields. A table is given along with extension discussion of their properties. Toads also make use of the odor of their prey, and the author discusses, with a detailed diagram, the brain structures involved in visual-olfactory learning. Most interesting is the author's discussion of backpropagation artificial neural networks used to model the feature detection abilities of amphibians. A two-layered artificial neural network is trained to classify and evaluate objects of different lengths moving in prey and nonprey configurations.  <br />	2005-03-07
327571:US	50702879	R377WN3ZRI2GX	1585422762	756890865	Weapons of Mass Deception: The Uses of Propaganda in Bush's War on Iraq	Books	4	4	5	N	Y	Needs more scientific support but a good start	Deception has become a popular practice in modern society, but it is not all pervasive, since if it were there would be no change and no criticism. Without a doubt there would not be the plethora of ideas that now exists if everyone was convinced that the practice of deception is a moral or practical imperative. However, it is the modus operandi of government officials and advertising executives, who believe that without it no products could be sold and no wars could be fought. Their belief in deception has its roots in their own insecurities: they simply do not believe that they can give convincing arguments or rationales behind the products they manufacture or the ideologies they believe. Government officials have another belief that puts them to some extent in the same camp as academicians and educated intellectuals: they believe that \\"the public is dumb\\" and therefore needs to be deceived. To not deceive the public is to let them lead themselves astray and pursue irrational or destructive tendencies. The belief that \\"the public is dumb\\" is not unique to any political or partisan cause, and it is accepted as \\"commonsense\\" by most individuals in government and those in its supporting infrastructure.<br /><br /> This book discusses the techniques and modern history of propaganda and advertising as it was applied to justify the current conflict in Iraq. It does so however from a general non-scientific viewpoint, and thus does not attempt to give a scientific understanding of why populations are sometimes taken by sloganeering, propaganda, and other forms of media hype. If the book made connections with current research in neuroscience, it would have been a lot more interesting. As it stands it should be thought of as a \\"first approximation\\" to a full understanding of the efficacy of advertising and propaganda techniques. Such an understanding would be very helpful to those who are not only curious about the effects of the media on the human brain, but also want to discover countermeasures to these effects.<br /><br /> Some of the virtues of the book include its description of the extent to which the horror of the 9/11 attacks was exploited by many different groups, and not just those in government. The current administration of course was the worse culprit and took full advantage of the anxiety felt by most everyone after 9/11 in order to launch a brutal, illegal, and immoral war in Iraq. The authors give many more examples of political and interest groups who squeezed every drop they could out of the 9/11 disaster. The tactics of deception used were independent of the beliefs and ideologies of the respective groups. Both Democrats and Republicans had absolutely no qualms about using the 9/11 nightmare to propagate with gusto their political memes.<br /><br />When reading the book, it is amazing to see the amount of money that was spent by public relations and advertising firms hired specifically to take advantage of the fears of the \\"general public.\\" The authors correctly advise against letting fear rule our lives, and this book actually assists in encouraging a strong sense of skepticism toward the media and the government. In every waking hour of our lives we must critically examine all news stories, speeches, and political and commercial advertisements so as not to be inadvertently influenced by their content. Neuroscience teaches us that the human brain is susceptible to deceptive information if conscious effort is not made to examine it carefully and deliberately, but it is also able to differentiate between what is plausible and what is implausible. A focused, skeptical public can definitely serve as countervailing power to the lies and rubbish that proceed from cynical and amoral advertising agencies and government institutions.to discover countermeasures to these effects.  <br /> <br /> Some of the virtues of the book include its description of the extent to which the horror of the 9/11 attacks was exploited by many different groups, and not just those in government. The current administration of course was the worse culprit and took full advantage of the anxiety felt by most everyone after 9/11 in order to launch a brutal, illegal, and immoral war in Iraq. The authors give many more examples of political and interest groups who squeezed every drop they could out of the 9/11 disaster. The tactics of deception used were independent of the beliefs and ideologies of the respective groups. Both Democrats and Republicans had absolutely no qualms about using the 9/11 nightmare to propagate with gusto their political memes.   <br /> <br />When reading the book, it is amazing to see the amount of money that was spent by public relations and advertising firms hired specifically to take advantage of the fears of the \\"general public.\\" The authors correctly advise against letting fear rule our lives, and this book actually assists in encouraging a strong sense of skepticism toward the media and the government. In every waking hour of our lives we must critically examine all news stories, speeches, and political and commercial advertisements so as not to be inadvertently influenced by their content. Neuroscience teaches us that the human brain is susceptible to deceptive information if conscious effort is not made to examine it carefully and deliberately, but it is also able to differentiate between what is plausible and what is implausible. A focused, skeptical public can definitely serve as countervailing power to the lies and rubbish that proceed from cynical and amoral advertising agencies and government institutions.	2005-03-04
334884:US	50702879	R3CRKZEVBA3L1R	1594674574	677463996	Hear Him! the One Hundred Twenty-Five Commands of Jesus	Books	5	2	4	N	N	An interesting approach to Christian ethics	Ethical systems based on rules can be very extensive, due to the need for the rules to cover the most important situations that may be encountered by the agent. But rule-based ethics must be coupled with a system of rewards that will motivate agents to conform to or apply the rules as they set goals. This book delineates a system of ethical rules that are based on the Christian religion, with particular emphasis on the Biblical tradition in the New Testament. Clearly the author has studied ancient Greek, for he has included discussions of Greek syntax and grammar throughout the book. Those readers who have studied classical Greek will no doubt find the book more interesting than those that have not.<br /><br />A system of ethics, if it is to be of assistance to agents in their decision-making and planning, must be one that is practical and is not a burden to them. It must be a suit of clothes that they can wear and not a straight jacket. Passages in the New Testament guarantee that this is not the case, for the author quotes one from the Gospel of John that states \\"his commandments are not burdensome.\\" But are they really? Can one really obey these commandments and have a satisfying and enriched life? Some of them are indeed radical if viewed in a commonsense frame of mind. The author clearly believes they are practical, for he speaks of them as giving preparation for the challenges of everyday life in an \\"increasingly alien world.\\"<br /><br />The \\"rules\\" or \\"commandments\\" listed in the book are meant to delineate the consequences resulting from disobeying them. Some of the commandments have practical, everyday consequences if disobeyed, while the disobeying of others will prohibit entrance into heaven. Space prohibits a detailed commentary on each of them, but a few of the more interesting ones, both because of their consequences if taken literally, and because of their simplicity include:<br /><br />10. [Come to terms quickly with your accuser while you are on the way to court with him, or your accuser may hand you over to the judge....]: This commandment encourages settling out of court, and as written has an intense distrust of the courts. It therefore is not a commandment that will be appreciated by lawyers, since if followed their services will not be needed. This is an excellent example of a commandment that, if followed, will have long-term social consequences (in this case the obliteration of a large portion of the legal profession).<br /><br />11. [You have heard that it was said, to those of ancient times, ... \\"You shall not commit adultery.\\" But I say to you that everyone who looks at a woman with lust already committed adultery with her in his heart]: In this commandment one is not supposed to distinguish between fantasy and reality.<br /><br />14. [You have heard that it was said to those of ancient times....\\"An eye for an eye and a tooth for a tooth.\\" But I say to you, Do not resist an evildoer. But if anyone strikes you on the right cheek, turn the other also...]: Thus any notion of a \\"just war\\" is forbidden by this commandment, as is revenge and other \\"sins of anger\\". This is a commandment that is definitely ignored in the modern world.<br /><br />15. [If anyone wants to sue you and take your coat, give your cloak as well.]: One therefore is not to resist personal lawsuits. This commandment also makes a large portion of the legal profession a white elephant.<br /><br />19. [You may be children of your Father in heaven;...For if you love those who love you, what reward do you have? Do not even the tax collectors do the same? And if you greet only your brothers and sisters, what more are you doing than others? Do not even the Gentiles do the same?]: A \\"war against terror\\" is therefore absolutely prohibited by this commandment.<br /><br />20, 21, 22. [Pray for those who persecute you...Do good to those you hate you...Bless those who curse you]: Again, no \\"war on terror\\" is permitted.<br /><br />23. [Be merciful,just as your Father is merciful]: Does this commandment prohibit the death penalty?<br /><br />26. [Do not condemn and you will not be condemned]: This commandment prohibits antigay rhetoric and condemnation, for starters.<br /><br />33. [Beware of practicing your piety before others in order to be seen by them]: This seems to be the commandment that is disobeyed the most these days.<br /><br /> Eternal life in heaven is the \\"reward\\" for obeying the majority of these commandments. But is eternal life in heaven really a reward that anyone should desire? What will life be like in such a place? The Bible and this book do give some hints on this question, and they do not seem very attractive at all, at least to this reviewer. Existence in heaven is one where goals can be delayed indefinitely, and therefore ambition becomes meaningless. When there is an infinite amount of time to accomplish goals, there is no incentive to bring them to fruition. An existence where there is no struggle to understand, where there is no pain, where slothfulness has the same reward as industriousness, is certainly not one that sounds very interesting at all.<br /><br />There are many no doubt who would prefer this kind of existence, but this reviewer would rather spend a normal lifespan living in the \\"increasingly alien world\\" of the twenty-first century, with its marvels of technology and science, than an eternity in the heaven that is described rather vaguely in the Bible and its traditions. Indeed, this is the best time ever to be alive, and we are the luckiest generation. For this reviewer, the rewards of living in the twenty-first century outweigh considerably the rewards promised by the different religions. Eternal life in heaven cannot compare with the excitement of living in this century.the death penalty?     26. [Do not condemn and you will not be condemned]: This commandment prohibits antigay rhetoric and condemnation, for starters.     33. [Beware of practicing your piety before others in order to be seen by them]: This seems to be the commandment that is disobeyed the most these days.      Eternal life in heaven is the \\"reward\\" for obeying the majority of these commandments. But is eternal life in heaven really a reward that anyone should desire? What will life be like in such a place? The Bible and this book do give some hints on this question, and they do not seem very attractive at all, at least to this reviewer. Existence in heaven is one where goals can be delayed indefinitely, and therefore ambition becomes meaningless. When there is an infinite amount of time to accomplish goals, there is no incentive to bring them to fruition. An existence where there is no struggle to understand, where there is no pain, where slothfulness has the same reward as industriousness, is certainly not one that sounds very interesting at all.     There are many no doubt who would prefer this kind of existence, but this reviewer would rather spend a normal lifespan living in the \\"increasingly alien world\\" of the twenty-first century, with its marvels of technology and science, than an eternity in the heaven that is described rather vaguely in the Bible and its traditions. Indeed, this is the best time ever to be alive, and we are the luckiest generation. For this reviewer, the rewards of living in the twenty-first century outweigh considerably the rewards promised by the different religions. Eternal life in heaven cannot compare with the excitement of living in this century.	2005-02-27
336643:US	50702879	R1VS4DMP1BQYYY	0975410105	18826706	Modifying Africa: How Biotechnology Can Benefit the Poor and Hungry--A Case Study from Kenya	Books	5	2	2	N	Y	Short but a fair and balanced apology for GM crops	Paraphrasing the author's words in this short booklet, those who reject biotechnology do so on full stomachs. Fortunately she is not one of these individuals, but instead has focused much of her energy and intellect on bringing the benefits of agricultural biotechnology to the country of Kenya. She is unashamed in her support of the introduction of genetically modified crops and does not hesitate to state her position clearly and concisely. In a work this short, it is impossible to set down the scientific justifications for genetic engineering, but the author does give the reader a general overview of how it can help alleviate the widespread hunger in Kenya. It is refreshing to know that there are some competent researchers who are ready to stand up and be counted in their defense of genetic engineering. It seems that there are many in the biotech industry reluctant to do the same, unfortunately.<br /><br /> The author is careful to note that biotechnology is not the only answer for all of Kenya's nutritional needs, but she does expose, within the limits of space, the unsubstantiated opinions of some regarding genetically modified crops. Transgenic crops in particular have been viewed by some as being extremely dangerous, due to the suspicion that `horizontal gene transfer' is more likely for such crops. The author believes that the likelihood of such `gene escape' is extremely low, but she does not include detailed evidence to support her view, no doubt because she wanted to make the book accessible to a general readership. The author does however view the phenomenon of herbicide resistance as one that requires further study, quoting a modeling study that indicates that herbicide-tolerant sugar beets for example, would affect the skylark population in the UK. Thus the author seems fair to arguments that both support the incorporation of agricultural biotechnology and those that don't. Readers who require a more comprehensive viewpoint can consult the references that she gives at the end of the book.that she gives at the end of the book.  <br /> <br />	2005-02-25
337811:US	50702879	R2N6QGAQHOTBZQ	0521429935	698805659	Mapping the Mind: Domain Specificity in Cognition and Culture	Books	4	5	5	N	Y	Needs more scientific support but a helpful book	Is the human brain an entity that makes use of a general collection of reasoning processes that can be used to solve problems no matter what domain or context these problems appear? Or does the human brain make use of cognitive processes that work only in specific domains? The latter alternative is called `domain specificity' and is held to be the correct one throughout this book. The articles in the book argue for the hypothesis of domain specificity mostly from a philosophical point of view, and not a scientific one. The articles though do grant a large degree of insight into the current thinking on domain specificity. Via measurements and laboratory experiments, current research in neuroscience is beginning to shed more light on whether the brain is an \\"all-purpose\\" problem solver or a collection of independent modules geared toward specific tasks. All of the articles in the book are interesting, but only a few will be reviewed here due to reasons of space.<br /><br /> The first article of the book, entitled \\"Toward a topography of mind: An introduction to domain specificity,\\" introduces the problem of domain specificity and how it arose historically. It is very tricky to define what a domain actually is, but the authors of this article take it up in some detail. They emphasize the Chomsky theory of natural language grammar as being one of the first most important examples of a domain-specific perspective. If the mind is modular, as Chomsky and the authors in this book assert, then damage to one module should not affect the cognitive abilities of another module. There are indications from experimental neuroscience that this is the case for abilities such as language, music, and mathematics for example. The authors mention some of this evidence in this article. Interestingly though, they believe that theories are domain specific. They argue for example, that a theory of biology cannot be applied to physics. However this is only partly true. For example, molecular biology can be interpreted completely in terms of physics. There are many other examples of theories designed for specific domains that work in others. In addition, the authors assert that theory construction is not necessary for \\"getting around the world.\\" This may be true in a certain weak sense, but finding a cure for cancer or \\"getting around\\" or traveling to other worlds requires highly sophisticated theories. The authors do however distinguish between `scientific' theories and commonsense or `folk' theories, the latter of which are needed in everyday life.  They discuss some examples in the article that emphasize their assertion that \\"theoretical\\" beliefs are important in organizing input data. The authors also address the question of what a domain really is, noting at the same time that an explicit definition does not exist. They therefore rely on examples of domains, and characterize it as a body of knowledge that serves to identify and interpret phenomena sharing certain properties.<br /><br /> In the second article of the book, entitled \\"The modularity of thought and the epidemiology of representations,\\" the author attempts to defend the view that thought processes themselves are also modular, and to explain his ideas on second topic in the title. The author believes that the modularity of thought is in no way incompatible with the diversity of human cultures, and much of the article is devoted to explaining why he thinks this is true. To this end, the author wants to distinguish between the `actual' domain of a conceptual module and the `proper' domain. The actual domain is the totality of information in the environment that satisfies the input conditions of the module. The `proper' domain is the information that it is the module's biological function to process. The module will process information in its actual domain, regardless of whether or not this information is contained in its proper domain. This distinction the author believes will allow him to explain the wide variation in human cultures, for the actual domains have become larger than the proper domains. This allows the organization of vast amounts of information, and allows the distinguishing of what he calls `cultural domains' of modules. For the author, an explanation of culture involves explaining why some representations become more widely distributed than others. This explanation he calls the `epidemiology of representations', wherein information in human communities is thought of as competing for private and public space and time. Interestingly, the transmission of cultural information in his view induces in the actual domain of any module a proliferation of `parasitic' information that acts like the proper domain of this module. He quotes music as being an example of this, but he is careful to point out that he has not supported his case in this regard by rigorous scientific evidence.<br /><br /> In order to fit in to the evolutionary paradigm of modern science, the authors of the fourth article in the book, entitled \\"Origins of domain specificity: The evolution of functional organization\\", attempt to show how modules can be viewed as evolved adaptations. The authors emphasize very strongly the need for natural selection in explaining the existence of complex functional design, and that the evolved design of organisms is the result of events in the past and happened without anticipation of the present. Successful cognitive mechanisms of the present are the result of what has happened in the past. Domain-general mechanisms, the authors argue at length, cannot be reconciled with evolutionary biology. Generality is achieved at the price of effectiveness, and domain-specific mechanisms that are able to utilize the stable features of recurring situations will outperform general mechanisms that don't utilize these features. There are no domain-general criteria for success/failure that correlate with fitness. In addition, domain-general criteria are limited to what can be derived from perceptual information, and are subject to combinatorial explosion.de variation in human cultures, for the actual domains have become larger than the proper domains. This allows the organization of vast amounts of information, and allows the distinguishing of what he calls `cultural domains' of modules. For the author, an explanation of culture involves explaining why some representations become more widely distributed than others. This explanation he calls the `epidemiology of representations', wherein information in human communities is thought of as competing for private and public space and time. Interestingly, the transmission of cultural information in his view induces in the actual domain of any module a proliferation of `parasitic' information that acts like the proper domain of this module. He quotes music as being an example of this, but he is careful to point out that he has not supported his case in this regard by rigorous scientific evidence.      In order to fit in to the evolutionary paradigm of modern science, the authors of the fourth article in the book, entitled \\"Origins of domain specificity: The evolution of functional organization\\", attempt to show how modules can be viewed as evolved adaptations. The authors emphasize very strongly the need for natural selection in explaining the existence of complex functional design, and that the evolved design of organisms is the result of events in the past and happened without anticipation of the present. Successful cognitive mechanisms of the present are the result of what has happened in the past. Domain-general mechanisms, the authors argue at length, cannot be reconciled with evolutionary biology. Generality is achieved at the price of effectiveness, and domain-specific mechanisms that are able to utilize the stable features of recurring situations will outperform general mechanisms that don't utilize these features. There are no domain-general criteria for success/failure that correlate with fitness. In addition, domain-general criteria are limited to what can be derived from perceptual information, and are subject to combinatorial explosion.	2005-02-24
345169:US	50702879	R10L3I29OBT3V6	0595314384	172573265	The New Science of Technical Analysis: Using the Statistical Techniques of Neuroscience to Uncover Order and Chaos in the Markets	Books	4	2	2	N	Y	Suitable for those entering the field	This book does give an overview of some techniques used to analyze financial time series, and some of these techniques are indeed used to analyze neuronal processes in the field of neuroscience, but it might be somewhat of an exaggeration to say that they are inspired by neuroscience, unless you are a neuroscientist who is also involved in financial analysis. The author of this book is an example of the latter, and has written a book that discusses some of the statistical tools he developed for neuronal processes, and how they can be applied to the analysis of price patterns in financial markets. Most of the techniques are well known, and readers with a strong background in probability theory and statistics will find nothing new in the book. However, readers who are in the early stages of educating themselves on the statistical analysis of economic and financial time series should find the book very useful. Most of the page space is devoted to graphs, but the author does give insightful opinions on the use of the statistical tools.<br /><br /> Realizing that a rigorous definition would take sophisticated mathematics, the author gives a nonmathematical definition of the terms `independent' and `random.' An event is `independent' if it is not influenced by the outcome of a previous event in time, and does not influence any events that come after it. Thus the independence of an event must be discussed in relation to other events, i.e. on whether or not past events can influence it, and whether it can influence future events. A `random' event, on the other hand, is one that is determined by chance. The notion of `chance' is related to probability theory by the author, via the law of large numbers. The author also is careful to point out that the techniques he develops in the book can only be applied to `stationary' time series. He again uses a nonmathematical definition, and defines `stationarity' as meaning that the underlying rules that generated the time series do not change with time. If a time series is nonstationary then the rules that generated it change over time. Stationarity, independence, and randomness are the parameters of the time series the author is concerned with in the book, and he emphasizes that these parameters are independent.<br /><br /> The author has developed many of the tools in an earlier book that he has written, and the reader will have to consult this book for more in-depth discussion. He does however include many helpful insights on statistical data analysis. Some of these are: 1. The use of detrending on economic time series that contain a significant trend. What constitutes a \\"significant\\" trend is not discussed. 2. The use of the `differential spectrum' to determine if a time series is independent or not. This method is based on the notion that the distribution of positive and negative price changes will be symmetrical for an independent time series. The bin widths and the number of price changes will determine the sensitivity of this method, as the author illustrates using several examples. He also shows how to use the chi-square statistic to compare the relative distribution of positive and negative price changes. 3. The use of the `relative price change' to determine which kinds of serial dependences are present in a time series and to determine the duration of a `temporal window' during which the price changes are not independent. Readers familiar with n-gram methods in computational linguistics will see them here in another guise.o not change with time. If a time series is nonstationary then the rules that generated it change over time. Stationarity, independence, and randomness are the parameters of the time series the author is concerned with in the book, and he emphasizes that these parameters are independent.  <br /> <br /> The author has developed many of the tools in an earlier book that he has written, and the reader will have to consult this book for more in-depth discussion. He does however include many helpful insights on statistical data analysis. Some of these are: 1. The use of detrending on economic time series that contain a significant trend. What constitutes a \\"significant\\" trend is not discussed. 2. The use of the `differential spectrum' to determine if a time series is independent or not. This method is based on the notion that the distribution of positive and negative price changes will be symmetrical for an independent time series. The bin widths and the number of price changes will determine the sensitivity of this method, as the author illustrates using several examples. He also shows how to use the chi-square statistic to compare the relative distribution of positive and negative price changes. 3. The use of the `relative price change' to determine which kinds of serial dependences are present in a time series and to determine the duration of a `temporal window' during which the price changes are not independent. Readers familiar with n-gram methods in computational linguistics will see them here in another guise.	2005-02-18
348244:US	50702879	R3SYI1PMY4O9S2	1560229993	705216950	Plant Functional Genomics (Crop Sciences)	Books	5	2	2	N	Y	Extremely interesting	As the editor of this book explains in the preface, `functional genomics' is an extension of the term `genomics', with the latter used to designate the mapping and sequencing of genomes. Functional genomics, on the other hand, assumes the existence of a complete genome sequence, and then attempts to elucidate the functional properties of each gene. Motivated by the completion of the sequencing of the genome of Arabidopsis thaliana in 2000, the authors of the articles in this book discuss the more recent developments in plant functional genomics. Even though it is written for experts in the field, with some concentrated effort and a thorough perusal of the references, non-experts (such as this reviewer) who are curious about these developments should find the book worthwhile. Because of the interests of this reviewer, which lie predominantly in the biochemistry and biology of photosynthesis, and the genetic engineering of the chloroplast, the review will be restricted to the two articles that discuss these topics.<br /><br />In the article `Chloroplast Proteomics' by Klaas J. van Wijk, the author believes that the study of the proteome of plastids is advantageous because of the reduced complexity of the problem, if compared to the proteomics of a total cell. The author illustrates this reductionist philosophy in the dividing up of the chloroplast proteome into six different \\"subproteomes\\" so as to make the identification and characterization of proteins more straightforward. These subproteomes are the inner and outer envelope, the soluble stroma, the tight and loose peripheral thylakoids, the soluble lumen, and the integral membrane. This division, the author believes, makes experimental determination of the proteins much more straightforward. He focuses his attention in the article on those experimental techniques that allow large sets of proteins to be predicted. Emphasis is placed on the way in which proteomics has contributed to the understanding of the biology of plastids. The author also takes great care in distinguishing large-scale transcript analysis from proteomic analysis, believing that both approaches are complementary, and gives references to the literature that support this viewpoint.<br /><br />The role of statistical and mathematical techniques in proteomics, such as the use of hidden Markov models, is readily apparent in the article. Noting that the majority of the plastid proteome is encoded by the nuclear genome with the proteins being synthesized as precursor proteins with N-terminal `cleavable transit peptides' (cTPs), the author lists a few Websites for obtaining software, such as TargetP and Predotar, to identify cTPs and also lists other predictors and plastid proteomics databases cited in the chapter.<br /><br />There are many very interesting facts reported in the chapter. One of these concerns the phylogenetic analysis of the proteome of Arabidopsis thaliana, which reveals that it has its origins in bacteria, but during the long process of evolution many other genes that encode for plastid proteins were acquired. Another concerns the use of hidden Markov models as predictors for alpha-helical transmembranes. Still another concerns the experimental techniques used for the identification and characterization of the plastid proteome, such as mass spectrometry, cyclotron resonance, and electrophoresis. Readers with knowledge of physics will certainly appreciate the discussion of these techniques.<br /><br />In the article `Functional Characterization of the Photosynthetic Apparatus in Arabidopsis thaliana' by H. V. Scheller, C. Lunde, A. Haldrup, and P. E. Jensen, the authors emphasize that a substantial number of the genes of a plant, around ten percent, are involved in photosynthesis, and interestingly, have their origins in cyanobacteria. They are careful to point out both the advantages and disadvantages in using Arabidopsis to study photosynthesis, with the main advantage clearly being the availability of its complete genome. The primary focus of the article is on the function of proteins in the thylakoid membrane and the authors do not discuss stromal processes or transport processes in the chloroplast.<br /><br />For the photosystem II (PSII) the authors give a list of the genes making up this system. They include in this list the location of the gene, i.e. whether it is in the nuclear or plastid genome, the protein for which it encodes, its molecular mass, its major function, and the accession number. Those readers interested in studying the effects on photosynthesis due to the switching off of these genes will find ample discussion in this article, with attention given to the nuclear-encoded subunits. The authors emphasize that not much is known about the chloroplast-encoded PSII proteins in Arabidopsis.<br /><br />As an example of the effect of the knockout of genes, the authors discuss how the quantum yield of PSII electron transport and oxygen evolution can be decreased by the knockout in one of the psbO genes. They also discuss the destabilization of PSII dimers due to the reduction of the PsbW protein. This discussion is interesting in that no observable change in the phenotype was observed despite a fifty percent reduction in PSII activity.<br /><br />Still another interesting discussion in this article regards the role of the Lhcb proteins in Arabidopsis, which are involved in light harvesting. For the Lhcb4 and Lhcb5 proteins, the authors describe an experiment in which these two proteins were down-regulated using an antisense approach. It is interesting to note that growth was not affected in the plants lacking Lhcb4 or Lhcb5, but that the PSII content was increased in the antisense plants. The authors conclude from this that the ratio between PSI and PSII is highly optimized in plants. A mutated plant with defects in one photosystem has a large capacity to compensate for the defects. For Lhcb2, the authors discuss an antisense experiment for one of the three lhcb2 genes that resulted in the largest number of gene products being simultaneously suppressed of any other study to date. Interestingly, the thylakoid structure was not affected by these manipulations, only small changes in the antenna size of PSII were observed, and the rate of photosynthesis was only reduced by about fifteen percent. Growth conditions were the same as the wild type in the laboratory, but fitness was considerably decreased under field conditions.the availability of its complete genome. The primary focus of the article is on the function of proteins in the thylakoid membrane and the authors do not discuss stromal processes or transport processes in the chloroplast.  <br /> <br />For the photosystem II (PSII) the authors give a list of the genes making up this system. They include in this list the location of the gene, i.e. whether it is in the nuclear or plastid genome, the protein for which it encodes, its molecular mass, its major function, and the accession number. Those readers interested in studying the effects on photosynthesis due to the switching off of these genes will find ample discussion in this article, with attention given to the nuclear-encoded subunits. The authors emphasize that not much is known about the chloroplast-encoded PSII proteins in Arabidopsis.  <br /> <br />As an example of the effect of the knockout of genes, the authors discuss how the quantum yield of PSII electron transport and oxygen evolution can be decreased by the knockout in one of the psbO genes. They also discuss the destabilization of PSII dimers due to the reduction of the PsbW protein. This discussion is interesting in that no observable change in the phenotype was observed despite a fifty percent reduction in PSII activity.  <br /> <br />Still another interesting discussion in this article regards the role of the Lhcb proteins in Arabidopsis, which are involved in light harvesting. For the Lhcb4 and Lhcb5 proteins, the authors describe an experiment in which these two proteins were down-regulated using an antisense approach. It is interesting to note that growth was not affected in the plants lacking Lhcb4 or Lhcb5, but that the PSII content was increased in the antisense plants. The authors conclude from this that the ratio between PSI and PSII is highly optimized in plants. A mutated plant with defects in one photosystem has a large capacity to compensate for the defects. For Lhcb2, the authors discuss an antisense experiment for one of the three lhcb2 genes that resulted in the largest number of gene products being simultaneously suppressed of any other study to date. Interestingly, the thylakoid structure was not affected by these manipulations, only small changes in the antenna size of PSII were observed, and the rate of photosynthesis was only reduced by about fifteen percent. Growth conditions were the same as the wild type in the laboratory, but fitness was considerably decreased under field conditions.	2005-02-16
352455:US	50702879	RICJ3K031KEW9	0060001496	38141805	Liars, Lovers, and Heroes: What the New Brain Science Reveals About How We Become Who We Are	Books	5	20	20	N	Y	A fascinating and readable discussion of neuroscience	Explaining the field of cultural biology and the evidence from neuroscience that supports it, the authors have written a book that is accessible to all readers, regardless of their background. Every page gives a fascinating look at the causes/motivations behind human behavior and the authors argue convincingly for their thesis that this behavior has both environmental and genetic origins. They also include ample references for the reader who wants to pursue the subject in more detail.<br /><br /> The authors do not hesitate to embed their discussion of cultural biology in the historical backdrop in which it arose. As the authors report, some of the early research in the subject was met with harsh criticism, as for example the reaction against the book on sociobiology by E.O. Wilson. The vituperation leveled against Wilson by prominent intellectuals has no place in scientific debate and should not be engaged in under any circumstances.<br /><br /> The ability to image the brain and to model it with sophisticated computational tools has led to more knowledge about it in the last ten years than all of previous history, the authors argue. Brain imaging techniques such as MRI, PET, and optical topography have given experimental support for theories of the brain, giving much more valuable information that is needed to understand various diseases and abnormalities of the brain. Philosophical speculation and rhetoric have been eliminated in favor of careful scientific analysis and measurements, fortunately.<br /><br /> The book is packed full of interesting examples and surprises, and space does not permit a detailed review of these, but a few of them include: 1. The fact that the brain can detect and respond correctly to regular patterns in the environment without a person's conscious awareness of them. Experiments illustrating this are discussed in the book. 2. Neural network models of the basal ganglia indicate that it learns in essentially the same way as the brain of a bee. 3. The fact that the brain functions at different time scales, depending on the problem that it is presented with, from milliseconds all the way to minutes. This wide gap in processing time no doubt reflects evolutionary pressures that optimized the brain to prioritize some problems relative to others. 4. The suggestion that the anterior cingulate in humans may be the site of free will. 5. The suggestion that the \\"area 10\\" region in the front of the prefrontal cortex is the origin of our sense of self and our self-awareness. 6. The fact that half of the cortex is devoted to visualization. 7. The experimental evidence that indicates that environmental stimulation induces the maturing of brain cells in the hippocampus. 8. The fact that the brain is 90% of its final size at age five, and keeps growing until adolescence. 9. The rise of the \\"neural constructivist\\" view that the brain uses information from the world to build itself. Called \\"self-organization\\" by those who work in the field of dynamical systems, the constructivist point of view holds that the interaction with the world is a special type of learning that changes the brain and assists in building it. The authors refer to the brain/environment interaction as \\"constructive learning\\", and believe that the slow time scales needed for cortical development optimizes the influence of the world on the human brain, and thus make being human possible. The more time the brain has to develop, the likelihood of helpful inputs from the world to guide the construction of highly complex neural circuits increases. The result of this is a mind that can deal efficiently and accurately with the complexities of human existence. 10. The evidence that the development of the brain is non-uniform, but rather occurs hierarchically. The portions of the brain dealing with sensory information develop earlier than those that are responsible for the encoding of more abstract information. 11.  The reason for suicidal behavior lies inthe prefrontal cortex, which is also involved in mental disorders such as schizophrenia and depression. 12. The origin of drug addiction being in the ventral tegmental area of the basal ganglia. 13. The effects of serotonin and its manufacture in the brain by a group of neurons called the dorsal Raphe nucleus. Interestingly, despite being a small cluster of neurons, it is able to influence billions of neurons in the cerebral cortex. 14. The TD-Gammon learning machine and its ability to teach itself backgammon. The authors believe that the TD-Gammon machine exhibits real machine intelligence, and it is the opinion of this reviewer that they are quite correct in asserting this. 15. The origin of human personality as being from the anterior cingulate cortex, which uses previous experiences in order to construct the appropriate cognitive and emotional responses to novel situations. Attention to difficult problems is correlated with high activity in the anterior cingulate. 16. The fact that the male and female brains are the result of hormones, such as testosterone. The male brain becomes \\"masculinized\\" under the influence of testosterone, but only indirectly: the brain converts testosterone into estrogen, interestingly. The authors are careful to point out that testosterone and estrogen do not act at all places in the brain, and that sexual identity has its origin mostly in the hypothalamus. 17. The suggestion that it is the concurrent release of opiates and the oxytocin that produce the sensation of orgasm. 18. The origin of romantic love as being in the various chemical processes of the brain, and the experiments involving transgenic mice that supported this viewpoint. 19. The evidence from neuroscience that supports the \\"Aristotelian\\" conception of human nature, i.e. that family ties, friendship, and trust are more characteristic of humans than antisocial or individualistic behavior. Humans need to identify with something larger than their private existence, the authors argue. 20. The neuroscientific explanations for involvement in cults and for conformity to groups. 21. The authors' view of \\"constructive intelligence\\", and how it is at odds with the modern \\"IQ\\" version of intelligence.or lies in the prefrontal cortex, which is also involved in mental disorders such as schizophrenia and depression. 12. The origin of drug addiction being in the ventral tegmental area of the basal ganglia. 13. The effects of serotonin and its manufacture in the brain by a group of neurons called the dorsal Raphe nucleus. Interestingly, despite being a small cluster of neurons, it is able to influence billions of neurons in the cerebral cortex. 14. The TD-Gammon learning machine and its ability to teach itself backgammon. The authors believe that the TD-Gammon machine exhibits real machine intelligence, and it is the opinion of this reviewer that they are quite correct in asserting this. 15. The origin of human personality as being from the anterior cingulate cortex, which uses previous experiences in order to construct the appropriate cognitive and emotional responses to novel situations. Attention to difficult problems is correlated with high activity in the anterior cingulate. 16. The fact that the male and female brains are the result of hormones, such as testosterone. The male brain becomes \\"masculinized\\" under the influence of testosterone, but only indirectly: the brain converts testosterone into estrogen, interestingly. The authors are careful to point out that testosterone and estrogen do not act at all places in the brain, and that sexual identity has its origin mostly in the hypothalamus. 17. The suggestion that it is the concurrent release of opiates and the oxytocin that produce the sensation of orgasm. 18. The origin of romantic love as being in the various chemical processes of the brain, and the experiments involving transgenic mice that supported this viewpoint. 19. The evidence from neuroscience that supports the \\"Aristotelian\\" conception of human nature, i.e. that family ties, friendship, and trust are more characteristic of humans than antisocial or individualistic behavior. Humans need to identify with something larger than their private existence, the authors argue. 20. The neuroscientific explanations for involvement in cults and for conformity to groups. 21. The authors' view of \\"constructive intelligence\\", and how it is at odds with the modern \\"IQ\\" version of intelligence.	2005-02-12
353364:US	50702879	R16LSCXLCSNQ28	0198525206	500243859	The Cognitive Neuroscience of Music	Books	4	77	80	N	Y	Very interesting overview of current research in the subject	The collection of articles in this book gives a fascinating overview of human musical cognition and how it is modeled computationally. It also addresses the effect of brain lesions or abnormalities on musical competence and abilities, and thus gives the reader a taste of the kind of research that is being done in current research circles in the cognitive neuroscience of music. It is readily apparent after reading the articles that much is known about musical cognition, but there are many questions yet to answer. Because of space constraints, only a few of the articles will be reviewed here.<br /><br />When considering human musical ability and competence it is natural to ask whether it is the result of evolutionary adaptations or whether it is \\"accidental\\" or \\"evolutionary vestige.\\" The article by David Huron discusses these questions in some detail, with emphasis on the ability of evolution to shape not only physiological attributes and functions, but also human attitudes, emotions, cognitive abilities, and so on. The author gives an overview of the `nonadaptive pleasure seeking' (NAPS) view of music, and also the view that music is indeed an evolutionary vestige. He concludes, interestingly, that the truth of NAPS would place music lovers at an evolutionary disadvantage. If music is an evolutionary vestige, it still is important to ask, says the author, what value it had in the past for human survival. He discusses various types of evidence for supporting an evolutionary origin for music, such as genetic, neurological, ethological, and archaeological. Noting that no genes have been discovered which are correlated with musical ability, the other types of evidence do add plausibility to his evolutionary hypothesis, he argues at length in the article. The ability of music to form social bonds he believes shows the greatest promise as a plausible evolutionary origin for music. Most interesting is his discussion of how music brings about social bonding, with the hormone oxytocin playing a major role in this regard.<br /><br /> The article by Stephen McAdams and Daniel Matzkin on the perception of musical similarity is interesting for its own sake but also from the standpoint of artificial intelligence. Measures of similarity and to what extent a given concept can be changed and still be judged or perceived to be in the same category are of great interest in artificial intelligence. The authors of this article argue that the empirical evidence in similarity perception limits the `transformation space' for given music material. In other words, one can only go so far in the transformation of the original musical material before it is judged as completely new. The authors discuss in detail the factors that contribute to these limitations. In this context, the authors discuss a very interesting experiment to test among other things whether professional musicians are able to hear similarity to a greater degree of transformation if the transformations respect certain syntactical rules. The authors conclude, and their conclusions adhere to what is expected based on listening experiences, that the space of possible variations of musical material that is perpetually similar to an original piece of music is very limited.<br /><br /> Neural networks naturally enter into any discussion on human cognition, and they do so here in the article by Barbara Tillman, Jamshed Bharucha, and Emmanuel Bigand, who use them to model music cognition. Simulation of mental processes is of immense importance in brain research and allows one to study the effect of various anatomical and physiological abnormalities on cognition. The authors mention these capabilities in their article, but their emphasis is on explaining how neural networks coupled with unsupervised learning, can be used to model music cognition. They also mention, but do not discuss in any detail, the use of self-organizing maps to simulate the neural plasticity that allows the capacity to extract regularities and to then become sensitive to musical structures and regularities.<br /><br /> The article by John Brust discusses the effect of neurological disorders on musical function. The author discusses `musicogenic seizures', which are triggered by the hearing of music. Interestingly, these seizures can be triggered in some people by merely listening to their own voice. In some individuals, sound can also produce the perception of colors. This is called `synesthesia' by the author, but he does not discuss it in any great length. Apparently synesthesia is poorly understood, but has been noted to happen very frequently in individuals using hallucinogenic drugs. Also discussed is `amusia\\" which is an acquired impairments of musical processing.<br /><br /> The next article by Isabelle Peretz continues the discussion on amusia, but the emphasis is on what it reveals about brain specialization for music. The author holds that music has neuroanatomical specialization, in that there is a collection of neural networks that are dedicated to the processing of music. The author discusses various patients who had accidents causing brain damage in certain areas of the brain but were still able to retain musical skill. This occurred even when the damage occurred in the part of the brain responsible for language abilities. Even more surprising is that the auditory recognition of music is supported by cognitive processes that are not used at all in speech recognition or in environmental sound recognition. The author also discusses musical savants and the phenomenon of tone deafness. In terms of neural networks, the author asserts that brain specialization for music involves the encoding of pitch along musical scales and the ability to impute a regular beat to incoming events. She believes though that further research is needed to show that neural networks that are domain specific for music are the result of evolutionary adaptation.y to extract regularities and to then become sensitive to musical structures and regularities.   <br /> <br /> The article by John Brust discusses the effect of neurological disorders on musical function. The author discusses `musicogenic seizures', which are triggered by the hearing of music. Interestingly, these seizures can be triggered in some people by merely listening to their own voice. In some individuals, sound can also produce the perception of colors. This is called `synesthesia' by the author, but he does not discuss it in any great length. Apparently synesthesia is poorly understood, but has been noted to happen very frequently in individuals using hallucinogenic drugs. Also discussed is `amusia\\" which is an acquired impairments of musical processing.  <br /> <br /> The next article by Isabelle Peretz continues the discussion on amusia, but the emphasis is on what it reveals about brain specialization for music. The author holds that music has neuroanatomical specialization, in that there is a collection of neural networks that are dedicated to the processing of music. The author discusses various patients who had accidents causing brain damage in certain areas of the brain but were still able to retain musical skill. This occurred even when the damage occurred in the part of the brain responsible for language abilities. Even more surprising is that the auditory recognition of music is supported by cognitive processes that are not used at all in speech recognition or in environmental sound recognition. The author also discusses musical savants and the phenomenon of tone deafness. In terms of neural networks, the author asserts that brain specialization for music involves the encoding of pitch along musical scales and the ability to impute a regular beat to incoming events. She believes though that further research is needed to show that neural networks that are domain specific for music are the result of evolutionary adaptation.	2005-02-11
354746:US	50702879	R1ZKRR2M6QE7RZ	0262661160	471554510	Cognitive Modeling (MIT Press)	Books	4	3	4	N	Y	An interesting and helpful collection of articles	This book could be considered to be a collection of articles on the `computational theory of mind.' Although the articles are somewhat out of date, due to the advances in neuroscience and cognitive science that have occurred since the time of publication of the book, it does serve as a good motivation for the understanding of more recent developments. I did not read all of the articles in the book, and so my review will be confined to the ones that I did.<br /><br />The article on ACT in chapter 2 is basically a theory of cognition that is based on recursion. Referring to ACT as a \\"simple theory of complex cognition\\", John Anderson, the author of the article, wants to simulate the manner in which humans develop recursive programs. The machine that is to simulate this makes use of `production rules,' in its knowledge base, which the author claims is exhaustive enough to produce complex cognition. To produce true machine intelligence, all one has to do is to tune these production rules and make use of them as needed. As the author describes it, the original ACT theory was based on human associative memory, but the one described in this article is called ACT-R, and can simulate adaptive behavior in the presence of a noisy environment. The author describes various simulations using ACT-R, and concludes that it is sensitive to prior information and to information about what is appropriate response to the situation it finds itself in. The author stresses more than once the simplicity of the ACT-R system: it is able to encode data from the environment as declarative knowledge, encode the changes in the environment as procedural knowledge, and encode the statistics of this knowledge use in the environment.<br /><br /> Another highly interesting article is the one by Alan Prince and Paul Smolensky on the application of optimization theory to linguistics. Called `optimality theory' by the authors in their extensive research on the topic, in the article they discuss the relations between optimality in grammar and optimization in neural networks. The authors discuss with great clarity the role that constraints play in the construction of linguistic structures, and the fact that these constraints typically conflict with each other. This conflict between grammatical constraints must thus be managed by a successful grammatical architecture. Optimality theory asserts that these constraints are universal in the sense that they are present in every language. The connection of optimality theory with neural networks arises when one is interested in finding out if the properties of optimality theory can be explained in terms of fundamental principles of cognition. The computational theory of neural networks the authors believe holds some clues on these properties. In order to make the connection with grammatical issues, as abstract as they are, and because neural networks are highly nonlinear dynamical systems, one must find a way of encapsulating the complicated behavior of neural networks. The authors accomplish this by the use of Lyapunov functions, which for reasons of consistency of terminology they call `harmony functions.' For those neural networks admitting a harmony function, the initial activation pattern flows through the network to construct a pattern of activity that maximizes \\"harmony.\\" Most interestingly, the harmony function for a neural network performs the same function as does the mechanisms needed for well-formed grammar. The patterns of activation are thus a mathematical analog of the structure of linguistic representations. However, the authors are careful to note that not every weighting scheme for the neural network will give a possible human language. It is here where the constraints play an essential role in limiting the possible linguistic patterns and relations.<br /><br /> The article by Keith Holyoak and Paul Thagard discusses the construction of a correspondence between a source analog and of a target. This is the so-called analogical mapping, which is constructed using a collection of structural, semantic, and pragmatic constraints. In the view of the authors, the concept of analogy can be broken down into four components, namely the selection of a source analog, the actual mapping, an analogical inference (transfer), and the actual learning that takes place. The authors omit discussion of the last component in this article. The finding of the correspondences between the two analogs can result in a combinatorial explosion, and so use is made of appropriate constraints. These constraints consist of those that exemplify structural consistency, those of semantic similarity, and lastly of pragmatic centrality. The theory of analogical mapping that the authors propose is governed by these constraints. They discuss the ACME (Analogical Constraint Mapping Engine) algorithm as one that constructs a network of units representing mapping hypotheses and eventually converges to a state that represents the best mapping. They list several applications of ACME, such as radiation problems, attribute mappings, chemical analogies, and the classical `farmer's dilemma' problem. ACME was also able to simulate a number of empirical results related to human analogical reasoning. The analogical mapping they discuss is most powerful in a specific domain however. This domain-specificity is a typical restriction for most of the efforts in learning theory and artificial intelligence.is the so-called analogical mapping, which is constructed using a collection of structural, semantic, and pragmatic constraints. In the view of the authors, the concept of analogy can be broken down into four components, namely the selection of a source analog, the actual mapping, an analogical inference (transfer), and the actual learning that takes place. The authors omit discussion of the last component in this article. The finding of the correspondences between the two analogs can result in a combinatorial explosion, and so use is made of appropriate constraints. These constraints consist of those that exemplify structural consistency, those of semantic similarity, and lastly of pragmatic centrality. The theory of analogical mapping that the authors propose is governed by these constraints. They discuss the ACME (Analogical Constraint Mapping Engine) algorithm as one that constructs a network of units representing mapping hypotheses and eventually converges to a state that represents the best mapping. They list several applications of ACME, such as radiation problems, attribute mappings, chemical analogies, and the classical `farmer's dilemma' problem. ACME was also able to simulate a number of empirical results related to human analogical reasoning. The analogical mapping they discuss is most powerful in a specific domain however. This domain-specificity is a typical restriction for most of the efforts in learning theory and artificial intelligence.	2005-02-10
356195:US	50702879	R2O7HCF07AOIM4	0070155577	670968658	Knowledge-Based Systems in Artificial Intelligence (McGraw-Hill advanced computer science series)	Books	3	1	1	N	Y	Of historical importance	The AM machine, developed by Doug Lenat in 1976 in his Phd dissertation, was designed to invent mathematical concepts and engage in making mathematical conjectures in elementary set theory and number theory. In the first article of this book, and the only one that will be reviewed here, Lenat summarizes AM in the context of the theme of the book. The AM machine is not viewed anymore as being interesting (no pun intended), but readers who have an interest in automated mathematical discovery should read this article, both for its insights and because of its historical importance. Many of the approaches to automated mathematical discovery that came after AM were very similar to it, both in terms of the form of the reasoning patterns and the use of extensive knowledge bases in mathematics.<br /><br />As Lenat describes it in his article, AM began with 115 elementary concepts such as sets and \\"bags\\", and was able to arrive at concepts such as \\"subset\\" and \\"disjoint set\\". It was also able to formulate concepts in number theory such as prime numbers and highly composite numbers. A concept in AM is given a \\"frame representation\\", where each frame has 25 \\"facets\\" and can have multiple entries for each facet. The facets could be definitions, algorithms, or examples of a concept, or generalizations or specializations of a concept, or conjectures involving a particular concept. A collection of tasks acting on a facet of a concept, and ordered by \\"interestingness,\\" were then processed by AM. A task performs a particular action on the facet by searching through its knowledge base of 242 heuristics. AM then chooses the appropriate heuristic(s) for the task, and then performs any subtasks that are suggested by the heuristic(s).<br /><br />A weighting scheme, consisting of an assignment of a numerical value, is applied to concepts, the individual facets, and the actions on concepts. This scheme is used to judge whether a concept, facet, or action is \\"interesting\\" in some sense. A formula is then used to calculate the \\"worth\\" of a task, this formula being dependent on a weighted sum of these numerical values and the actual number of reasons it counted for the judgment of \\"interestingness\\". The knowledge base of heuristics in AM included a collection of heuristics to be used for deciding the interestingness of a concept. One of these heuristics was that a concept is interesting if there are interesting conjectures about it. A concept is considered uninteresting if no examples or at best only a few examples of it can be found, even after repeated attempts by AM.<br /><br />Several questions arise when considering the discovery process utilized by AM. One obvious one concerns the originality of the discoveries which it made. Were the concepts truly discovered or were they hidden behind the scenes in the elementary concepts? For example, was the idea of a subset already encoded in the elementary concepts? Frequently, a human was called upon to recognize the \\"rediscovery\\" of the concept of subset, but was this really necessary? Would AM have eventually discovered the concept of a subset, if given sufficient time? This brings up the general question as to whether a human could at all times be capable of serving as a tutor or advisor to the machine. What if the concepts are too obscure or complex for human understanding or able to be assimilated by a human on a reasonable time scale?  In addition, a result might be interesting from the viewpoint of the machine, but be vacuous or completely uninteresting from a human standpoint. Should then the machine be thought of as being uncreative when this occurs? In the actual use of AM, the users were able to manipulate AM to make it reason in a particular direction. On the other hand, this issues would not be troubling if viewed from the standpoint of another machine who might be doing the \\"coaching\\". Receiving help from a human or otherwise may be viewed as a bias term for the learning/discovery process. Thisalso would take into account the fact that research in mathematics does not take place in isolation, but instead in a \\"community of mathematicians\\".<br /><br />Another issue concerns the need for doing proofs in mathematics. Typically, a result, in particular an interesting result, would not be judged as such unless there was a proof given for it. This of course excludes conjectures, which are generated quite frequently in the actual practice of mathematical discovery. The making of conjectures is thus certainly thought of as something that a machine purporting to be engaged in mathematical discovery should be able to do. However, it should also be expected to do proofs of some of the discovered concepts. Proofs however were never generated by the AM machine. Does this mean that it was not exhibiting true creativity? From another standpoint, it would be advantageous for AM to be able to engage in the construction of proofs, since, as every human mathematician knows, the actual proof of a mathematical result can frequently inspire more mathematical ideas and conjectures. Thus the construction of proofs would make AM more effective as an automated discovery machine.ess. This also would take into account the fact that research in mathematics does not take place in isolation, but instead in a \\"community of mathematicians\\".  <br /> <br />Another issue concerns the need for doing proofs in mathematics. Typically, a result, in particular an interesting result, would not be judged as such unless there was a proof given for it. This of course excludes conjectures, which are generated quite frequently in the actual practice of mathematical discovery. The making of conjectures is thus certainly thought of as something that a machine purporting to be engaged in mathematical discovery should be able to do. However, it should also be expected to do proofs of some of the discovered concepts. Proofs however were never generated by the AM machine. Does this mean that it was not exhibiting true creativity? From another standpoint, it would be advantageous for AM to be able to engage in the construction of proofs, since, as every human mathematician knows, the actual proof of a mathematical result can frequently inspire more mathematical ideas and conjectures. Thus the construction of proofs would make AM more effective as an automated discovery machine.	2005-02-09
357845:US	50702879	RQN6LI5SU8NX4	0465078362	830433857	Three Roads To Quantum Gravity (Science Masters)	Books	5	11	13	N	Y	A fair summary of the status of research in quantum gravity	Considering the experimental status of theories of quantum gravity, it is remarkable that research in this area has progressed to the level in which it has in the last few decades. If one examines the history of science it is readily apparent that laboratory and observational data drove the most successful scientific theories. By reading this book and by perusing some of the extensive literature on quantum gravity, it seems justified to view research in quantum gravity as being driven more by internal consistency requirements and reasons of aesthetics. The author gives an interesting overview of this research, and targets the \\"popular audience\\" for its readership. The author expresses great optimism that a successful theory of quantum gravity will be attained within the next decade. Considering the current difficulties in this research, this is indeed a refreshing attitude.<br /><br /> All of the approaches to the quantization of gravity rely on mathematical tools that are quite sophisticated, and competence in the use of these tools requires years of study and concentration. Due to the targeted audience, the author does not discuss these in detail, but he does give interesting and intuitive insights into the nature of the mathematical constructions that are used in quantum gravity. One of these, `noncommutative geometry', is quite recent, while the other, `topos theory', has been around for quite some time, albeit in several disguises. If one is to reconcile the two main approaches to quantum gravity, namely the loop approach and string theory, one will need to understand in detail the mathematics behind both of these theories. This will be a formidable undertaking, and it will take disciplined and focused individuals to carry it out. Unfortunately, and the author addresses this in the book, academic and funding pressures discourage such undertakings. This is either an argument for changing the nature of the academy (which will be very difficult) or doing this research outside the academy. But doing research outside the academy runs the risk of it being viewed as low quality, especially by those in the academy, and so this alternative carries high risk also. In either case, research in quantum gravity is difficult not only because of the nature of the subject matter, but also because of the societal and political pressures that make it a very risky endeavor.<br /><br /> The author, and a few others, came to quantum gravity when it was still a relatively young field, and, as he describes in the book, managed to survive in the academic environment. Their zeal is admirable, considering the roller-coast ride of confidence and depression they no doubt felt during their research efforts. There is no doubt now that quantum gravity is considered to be a respectable field of physics, and has attracted some of the best minds that have ever existed on this planet.<br /><br /> The manner in which the author presents the ideas on quantum gravity will no doubt motivate a few bright young people to take up the gauntlet and enter the field. He definitely prefers the loop approach to quantum gravity, being one of the individuals responsible for its development, but he is fair in giving string theory its due. Even professional physicists or mathematicians though who are curious about quantum gravity could gain a lot from a perusal of the book. There are some surprises in store for those who are used to thinking about space and time from a global point of view. This is especially true in the discussion of topos theory and the manner in which it is used in some approaches to quantum gravity. These approaches require that observers always view their place in the world as being one where they must reason using incomplete information. Two or more individuals though who have enough information to decide whether something is true or false will always make the same decision. This `local' view of descriptions, decision-making, and information gatheringwill be immediately appreciated by the mathematician reader who is acquainted with the concept of a `sheaf'.<br /><br /> The only possible irritation in the book (depending on the reader's theological views) is the discussion on the `weak' and `strong' anthropic principle and its play on very large (and very small) numbers. Those readers (such as this reviewer) who are not troubled by the magnitudes of these numbers will find the discussion somewhat superfluous. Some theologians have been delighted with the ramifications of some of the discussion on the anthropic principle and fine-tuning in recent years, particularly in the use of the \\"God of The Gap\\" arguments in cosmology. This will be no doubt continue, due to the need of these theologians to grab at every straw to establish their positions on origins, extremely fragile as they are.<br /><br />Another one of the virtues of the book is the author's willingness to discuss the social and political context in which research in quantum gravity is done. He describes the string and loop-gravity theorists as effectively being at war with other, but that the degree of cooperation between them has (thankfully) increased in recent years. The contention between these two groups is no doubt partly due to financial pressures from funding agencies and also personal insecurities among the researchers themselves, the latter resulting in sometimes maniacal obsessions for recognition among peers as being the first to arrive at a particular result. Some say this contention is healthy for science, while others say it is a complete waste of time and has no constructive purpose. It is the opinion of this reviewer that the second holds.will be immediately appreciated by the mathematician reader who is acquainted with the concept of a `sheaf'.<br /><br /> The only possible irritation in the book (depending on the reader's theological views) is the discussion on the `weak' and `strong' anthropic principle and its play on very large (and very small) numbers. Those readers (such as this reviewer) who are not troubled by the magnitudes of these numbers will find the discussion somewhat superfluous. Some theologians have been delighted with the ramifications of some of the discussion on the anthropic principle and fine-tuning in recent years, particularly in the use of the \\"God of The Gap\\" arguments in cosmology. This will be no doubt continue, due to the need of these theologians to grab at every straw to establish their positions on origins, extremely fragile as they are.<br /><br />Another one of the virtues of the book is the author's willingness to discuss the social and political context in which research in quantum gravity is done. He describes the string and loop-gravity theorists as effectively being at war with other, but that the degree of cooperation between them has (thankfully) increased in recent years. The contention between these two groups is no doubt partly due to financial pressures from funding agencies and also personal insecurities among the researchers themselves, the latter resulting in sometimes maniacal obsessions for recognition among peers as being the first to arrive at a particular result. Some say this contention is healthy for science, while others say it is a complete waste of time and has no constructive purpose. It is the opinion of this reviewer that the second holds.	2005-02-07
360152:US	50702879	R3LIDFFYWV5KS9	1400061946	899669555	An End to Evil: How to Win the War on Terror	Books	1	27	41	N	Y	Sophomoric prattle from two yellow abdomens	This book has to rank as one of the worse of all the political books that appeared in 2004. References are only sparingly given, and therefore a considerable amount of effort would be required to check the author's facts. In fact, if the authors had taken the time to include their references, or elaborated in more detail on the historical background on the myriads of claims that are made, the book would have swelled in size, which no doubt would have prohibited its publication. It is a rush-to-print polemic, and fails miserably in giving the inquisitive reader factual information on world events.<br /><br />Here are just a few of the totally unsubstantiated claims that are made in the book:<br /><br />- The claim that Iran was responsible for the murder of 86 people in Buenos Aires. Was it? Where is the evidence? How do they know this? An inquisitive reader wants to know.<br /><br />- The claim that it is the remnants of the Baath Party that have launched a guerilla war against the Allied forces in Iraq? Where is the evidence? How do they know this? An inquisitive reader wants to know.<br /><br />- The claim that Saddam Hussein harassed and threatened the weapons inspectors in the mid 1990's. Where is the evidence? How do they know this? An inquisitive reader wants to know.<br /><br />- The claim that Saddam Hussein arrested more than 200 hundred senior officers and executed 80 of them in July 1996. Where is the evidence? How do they know this? An inquisitive reader wants to know.<br /><br />- The claim that Saddam Hussein plotted to assassinate G.H.W. Bush during his visit to Kuwait in April 1993. Where is the evidence? How do they know this? An inquisitive reader wants to know.<br /><br />- The claim that Iraq was smuggling billions of dollars' worth of oil through Syria and Iran. Where is the evidence? How do they know this? An inquisitive reader wants to know.<br /><br />- The claim that the UN collected 1.5% commission on all the money in the oil-for-food program. Where is the evidence? How do they know this? An inquisitive reader wants to know.<br /><br />- The claim that the danger from Iraq was underestimated and that it had started work on a nuclear weapons program in the early 1990's. Where is the evidence? How do they know this? An inquisitive reader wants to know.<br /><br />But most troubling, and this goes to the root of any war on terror, nowhere in the book do the authors encourage those that agree with their \\"manual for victory\\" to enlist in the military to fight the \\"war on terror\\" or bring about an \\"end to evil.\\" When viewing the authors on the many television news programs they are invited to, they both appear to be very healthy, indeed, healthy enough to serve in combat duty in Iraq. It is readily apparent they have no intention of serving in combat, and neither do the majority of those that agree with them and the administration of cowards they support. In the book they scold the \\"American political and media elite\\" for \\"losing their nerve for the fight\\", and chide the administration's Democratic opponents for being \\"ready to give up the fight altogether\\", but they let others do the actual dirty work of fighting and killing. There is no sand blowing in their face and no rifles aimed at them when they populate the podiums of their think tanks, and proclaim this book as a \\"manual for victory.\\" But it is a victory that won't be attained with their help in actual battle. \\"We have wanted to fight,\\" they say early on in the book. So why don't they?<br /><br />The authors and the neo-conservative crowd they are a part of can easily be distinguished from others by their unwillingness to put themselves in the line of fire. The authors quote Donald Rumsfeld as saying \\"weakness is provocative\\". Was Rumsfeld showing weakness or strength when he avoided service in Korea or in Vietnam? How about Bush and Cheney when they avoided military service in Vietnam? It seems that weakness and cowardice are the rule rather thanthe exception for the authors and the administration they support. Without doubt they are all yellow, a sickening bright yellow, and their lack of intellect is only matched by their lack of intestinal fortitude.ardice are the rule rather than the exception for the authors and the administration they support. Without doubt they are all yellow, a sickening bright yellow, and their lack of intellect is only matched by their lack of intestinal fortitude.	2005-02-05
367760:US	50702879	R3925VUW4HCCKU	0387942483	718105970	Algebraic K-Theory and Its Applications (Graduate Texts in Mathematics) (v. 147)	Books	5	11	11	N	N	Very effective and understandable overview of K-theory	Speaking somewhat loosely, algebraic K-theory could be viewed as an attempt to generalize the invariants of linear algebra (such as determinants and canonical forms) to the case of projective modules. In modern mathematical classification, it is to be distinguished from topological K-theory, although both have a lot in common in terms of the general mathematical machinery used and were motivated from similar research interests. This book gives a superb overview of algebraic K-theory, and could be read by anyone who has taken a course in commutative algebra or a course in the theory of rings.  The reader will see a common theme throughout algebraic K-theory, namely that of abelianization, which is very prevalent throughout modern mathematics.<br /><br /> In chapter 1, the author begins the construction of K0. After defining projective modules (over a ring R with a unit), and he characterizes finitely generated projective R-modules. The isomorphism classes of finitely generated projective R-modules form an abelian semigroup, the completion of which is the well-known Grothendieck group, and which is defined to be K0(R). The author also develops an alternative approach to K0 using idempotent matrices, thus making a connection with the general linear group. He shows both approaches are essentially equivalent, via the well-known \\"Morita invariance.\\" Several examples of K0 are discussed, such as when R is a principal ideal domain, a local ring, and a Dedekind domain. The author also discusses to what extent K-theory can be viewed as a \\"homology for rings\\". This is relative K-theory, which is defined for two-sided ideals in R. Also, he gives the reader a taste of topological K-theory.<br /><br /> Just as one studies linear transformations of vector spaces and their invariants in linear algebra, the study of automorphisms of free and projective modules is done in K-theory, particularly via the construction of the K1 functor. In chapter 3, the author constructs K1 via the use of matrices, with a more categorical approach delayed until chapter 4. The group of \\"elementary matrices\\" for a ring R is defined, and K1(R) is defined to be GL(R)/E(R). The vanishing of K1(R) is equivalent to saying that every matrix in GL(R) and be row or column reduced to the identity matrix. When R is a field, the calculation of K1(R) reduces to ordinary linear algebra via the use of the determinant, and as a consequence K1(R) becomes trivial. When R is a local ring, then there exists a generalization of the determinant, which induces an isomorphism between K1(R) and the matrix group of its units modulo its commutator. When R is a Euclidean ring, K1(R) is isomorphic to its group of units, but when R is a principal ideal domain or a Dedekind domain, the author shows that K1(R) is not so elementary. He again gives a brief discussion of the application of K-theory, via the K1 functor, to topology. The relative K1 theory is also discussed.<br /><br /> Chapter 4 is an overview of how to construct K-theory for categories, instead of just rings. The categories considered are those that are ones wherein it is sensible to speak of an object as being constructed from more elementary objects, and are \\"abelian\\" categories, i.e. those that allow such homological results as the Five-Lemma. For a ring R, such categories include those of the category of finitely generated R-modules, the category of R-modules with a finite-type projective resolution, as well as of course the category of finitely generated projective R-modules. After discussing the connection between K0(R), K1(R) and K1 of the Laurent polynomial ring in R (the Bass-Heller-Swan theorem), the author introduces the notion of \\"negative K-theory\\", which gives the construction of an exact sequence of an ideal \\"arbitrarily far to the right\\", and thus allows the computation of K0(R/I) given information about R and I.<br /><br /> In chapter 5 the author describes the construction of the K2 functor as accomplished by themathematician John Milnor. This entails a review of the theory of universal central extensions, which the author does in the first section. Following up on the idea that the K-theory of rings measures in some sense the abelian invariants of the non-abelian group GL(R), for a ring R, K2(R) is related to central extensions of E(R) by abelian groups: K2(R) is the kernel of the map of the universal extension of E(R), called the Steinberg group, to E(R). Some examples of the calculation of K2(R) are given, such as for the case where R is a field, wherein K2(R) is generated by the \\"Steinberg symbols.\\" If R is a finite field, then K2(R) is zero. The lengthy concentration on the case where R is a field is done in order to point out the connection of K2 with number theory. When R is a field, the well-known Brauer group relates K2(R) to finite-dimensional non-abelian division algebras over R, and the author discusses this is fair detail.<br /><br /> The construction of the higher algebraic K-functors, i.e. Ki(R) for i greater than or equal to 3, is done in chapter 5 using the +-construction due to Daniel Quillen. It is here that topological considerations are brought to the forefront, since the Quillen approach is to construct the higher K-functors in terms of the homotopy groups of a particular space, called the classifying space. In particular, the (higher) K-theory of a ring R is defined as the product of the group of units of the classifying space of R and K0(R). The author shows that this definition of K-theory does coincide with that of K0 and K1 done earlier in the book. A brief but interesting survey (with proofs omitted) of the applications of the higher K-groups ends the chapter.<br /><br /> I did not read the last chapter on cyclic homology, and so its review will be omitted.This entails a review of the theory of universal central extensions, which the author does in the first section. Following up on the idea that the K-theory of rings measures in some sense the abelian invariants of the non-abelian group GL(R), for a ring R, K2(R) is related to central extensions of E(R) by abelian groups: K2(R) is the kernel of the map of the universal extension of E(R), called the Steinberg group, to E(R). Some examples of the calculation of K2(R) are given, such as for the case where R is a field, wherein K2(R) is generated by the \\"Steinberg symbols.\\" If R is a finite field, then K2(R) is zero. The lengthy concentration on the case where R is a field is done in order to point out the connection of K2 with number theory. When R is a field, the well-known Brauer group relates K2(R) to finite-dimensional non-abelian division algebras over R, and the author discusses this is fair detail.      The construction of the higher algebraic K-functors, i.e. Ki(R) for i greater than or equal to 3, is done in chapter 5 using the +-construction due to Daniel Quillen. It is here that topological considerations are brought to the forefront, since the Quillen approach is to construct the higher K-functors in terms of the homotopy groups of a particular space, called the classifying space. In particular, the (higher) K-theory of a ring R is defined as the product of the group of units of the classifying space of R and K0(R). The author shows that this definition of K-theory does coincide with that of K0 and K1 done earlier in the book. A brief but interesting survey (with proofs omitted) of the applications of the higher K-groups ends the chapter.      I did not read the last chapter on cyclic homology, and so its review will be omitted.	2005-01-30
370013:US	50702879	R30JWF0M3L3CG5	0231120125	390259168	How to Build a Mind: Toward Machines with Imagination	Books	3	8	8	N	Y	Too much philosophy	The author's goal is to answer the question as to whether a (non-human) machine can imagine. Clearly he believes that machines can, and throughout the book he gives his reasons for believing so. Early on, he emphasizes to the reader that he is an engineer, but given the view by most that engineering is a practical profession, he also wants the reader to know that it is philosophy that permits a true understanding of the nature of machine intelligence and forms the proper context for addressing questions regarding the ability of machines to have an imagination. Indeed, research into machine imagination is considered to be a combination of engineering and philosophy. Those readers, including this reviewer, who find philosophical speculation a distraction to the actual construction of intelligent machines might not want to read further. However, there is enough discussion on the history of the author's involvement in the development of intelligent machines to make the book worthwhile to read.  This is especially true for the author's discussion on the MAGNUS machine, which he considers to be a machine \\"driven by inner states.\\" In addition, the author is very aware of the pitfalls of philosophical musings on the nature of consciousness and machine intelligence. One of these concerns the conflict between the use of mathematics and physics to promote true understanding, versus the insistence that such understanding can only be reached from the use of thought experiments and argumentation. Another problem, says the author, is the predilection of philosophers to deny or negate the thoughts of their predecessors, which stymies progress to true understanding and is to be contrasted with the more effective approach in scientific circles, where consensus can be reached based on available evidence. Lastly, the author believes, the drive to understand consciousness has driven philosophers to the embrace of mysticism, with a consequent rejection of quantitative approaches.<br /><br /> The design of non-biological machines with imagination is not only driven by curiosity, but also by the desire to shed light on the nature of consciousness itself, says the author. The actual implementation of conscious imagination in non-biological machines can assist in the understanding of how it is done in biological machines, or at least how they are to be contrasted. The mechanisms giving rise to imaginative consciousness may have common elements in biological and non-biological machines. The author wants to find what aspects of \\"artificial\\" imagination are in fact true for \\"real\\" imagination.<br /><br /> At various places in the book, the author includes hypothetical discussions and debates with various philosophers and notable persons in history. These are interesting for sure, but they distract the reader from the discussion on the actual engineering of conscious and imaginative machines. Philosophers who find machine consciousness an elusive or impossible goal will never be convinced by any arguments supporting this goal. It would be better if researchers in machine intelligence would declare a moratorium on philosophical debate and speculation, and instead get busy with the real goal of designing and constructing intelligent machines.<br /><br /> The author characterizes consciousness in a machine as being the ability to know where it is situated, as being an understanding of its origins, and having its own motivations for the making of decisions. These criteria don't really that seem to difficult to implement in non-biological machines, and as one reads the book it becomes more apparent with each passing page that the author does not consider the implementation of non-biological machine consciousness as being a problem of overwhelming difficulty. His optimism in this regard is very characteristic of those who work in the field of machine intelligence. Their efforts are admirable, and even though the engineering of consciousness in a non-biological machine may remain elusive in years to come, there is no doubt that various types of machine intelligence have been realized in some of the machines of today. We can only expect further advances, and the rise of new types of intelligent machines. Whether these machines meet our expectations is another matter, but they have already exceeded expectations in many cases. Conscious or not, the machines of the future will certainly be fascinating entities with which to interact.iological machine may remain elusive in years to come, there is no doubt that various types of machine intelligence have been realized in some of the machines of today. We can only expect further advances, and the rise of new types of intelligent machines. Whether these machines meet our expectations is another matter, but they have already exceeded expectations in many cases. Conscious or not, the machines of the future will certainly be fascinating entities with which to interact.  <br /> <br />	2005-01-28
380386:US	50702879	R3TGDIVS9H4C4X	0252072235	447596851	March of the Machines: The Breakthrough in Artificial Intelligence	Books	4	15	15	N	Y	Very insightful and historically important	From a perusal of the title, it might appear that this book is one of a few that could be classified as \\"futurism\\" or \\"future-projected technology\\". These books, which have mostly appeared in the last five years or so, have an extremely optimistic view of future developments in artificial intelligence, but most of them do not justify this optimism with rigorous scientific evidence or attempt to quantify what is means for a machine to exhibit intelligence.<br /><br /> This book, first published in 1997, and appearing in paperback last year, is however different in this regard. In the book the author attempts, and in general succeeds, in giving the reader an overview of the status of artificial intelligence as it was in 1997. It does project these developments out to the future, even to the year 2050, but it does so in a way that is free of the overindulgences of media hype and Hollywood exaggerations that frequently accompany \\"semi-popular\\" works on artificial intelligence. Even though it is targeted at readers that are not specialists in artificial intelligence, the book does enable readers with a general education to understand just how advanced machine intelligence was during that time. Most importantly, the author strives to identify what it means for a machine to be intelligent, and his proposals for defining and measuring machine intelligence are quite interesting and show keen insight.<br /><br /> Indeed, the author's views on intelligence, machine or otherwise, are quite refreshing, for he does not make them human-centric. Other species exhibit intelligence in ways that are unique to them and highly suitable for their survival. The author emphasizes that life forms or machines have a degree of intelligence that is appropriate to themselves and the contexts and environments in which they are situated. Humans he says, via technological development, are bringing about machines that may very soon exhibit intelligence that is highly competitive to that of human intelligence, but this is to be measured relative to the needs of each, and these needs may conflict. The author is concerned with this potential conflict, and he devotes a sizable portion of the book in elaborating on just how it may come about.<br /><br /> Throughout the book the author endeavors to contrast the differences between human and machine intelligence. The fact that humans behave and perform differently makes any comparison between machines and humans problematic he believes. The absence of a `typical' human as a standard of comparison for machine intelligence implies that other measures must be devised for estimating this intelligence. And, just as there is high variability among human performance and ability, it is to be expected that this would also be the case for machines. The machines will differ in their respective abilities and with respect to humans. In some instances these machines will \\"outperform\\" humans on various tasks, as they have done in many cases up to the time of publication of this book and at the present time.<br /><br /> Another interesting difference between human and machine intelligence that the author points out concerns what has been called `domain-specificity' by many researchers. In the author's view, machines that are performing \\"intelligent acts\\" do so only in certain domains that are highly specified. A machine adept at chess for example may not be good at doing network management. Humans though can think and accomplish goals in many different domains: they can be good chess players as well as good network managers. However currently there is much debate among cognitive scientists as to whether human expertise is the result of a collection of specialized modules that interact in some way or whether it is the result of a \\"general\\" type of module that can think in many different domains. The author does not indulge himself in this debate, but instead emphasizes that machines and humans in general exhibit different types of intelligence. It is only when their performance on specific tasks is compared can one say whether a machine is \\"smarter\\" than a human, or vice versa.<br /><br /> In the author's view, both humans and machines can learn both in a \\"passive\\" and in an \\"active\\" sense. Passive learning is closer to what one would describe as \\"memorization\\", whereas active learning involves the deliberate initiation of the learning process. Scientific investigation would be an excellent example of active learning, for it involves setting up equipment, taking measurements, etc, in order to test a particular hypothesis or hunch on the part of the investigator. Clearly some machines can do passive learning, via the addition of extra rules or data, but not all can, says the author. Machines can also perform active learning and the author discusses an example of how this is done. While doing this he diverges into a discussion of the `frame problem' in artificial intelligence, which he dismisses as not being a limitation of machine intelligence, giving examples of just why he takes this viewpoint. The frame problem, he concludes, is just as much a problem for humans as well as other life forms.<br /><br /> Particularly insightful is the author's discussion on the advantages of using neural networks for learning rather than depending on expert systems. He is careful to point out that artificial neurons are not exactly the same as human neurons, and therefore that artificial neural network brains will be different from human brains. The performance of these artificial brains will therefore be different, and thus their intelligence will be. The author then asks the reader to consider what goals are to be accomplished using these artificial brains. Since the construction of these brains is done to get something different from human brains, the advantages in using them must be delineated. In the author's view they must go beyond the limitations imposed by the human brain. The author spends over half of the book describing what has been accomplished in the actual construction of artificial brains, with emphasis on the activities of his laboratory at the University of Reading in the UK. All of this discussion is fascinating reading.nt types of intelligence. It is only when their performance on specific tasks is compared can one say whether a machine is \\"smarter\\" than a human, or vice versa.  <br /> In the author's view, both humans and machines can learn both in a \\"passive\\" and in an \\"active\\" sense. Passive learning is closer to what one would describe as \\"memorization\\", whereas active learning involves the deliberate initiation of the learning process. Scientific investigation would be an excellent example of active learning, for it involves setting up equipment, taking measurements, etc, in order to test a particular hypothesis or hunch on the part of the investigator. Clearly some machines can do passive learning, via the addition of extra rules or data, but not all can, says the author. Machines can also perform active learning and the author discusses an example of how this is done. While doing this he diverges into a discussion of the `frame problem' in artificial intelligence, which he dismisses as not being a limitation of machine intelligence, giving examples of just why he takes this viewpoint. The frame problem, he concludes, is just as much a problem for humans as well as other life forms.  <br /> <br /> Particularly insightful is the author's discussion on the advantages of using neural networks for learning rather than depending on expert systems. He is careful to point out that artificial neurons are not exactly the same as human neurons, and therefore that artificial neural network brains will be different from human brains. The performance of these artificial brains will therefore be different, and thus their intelligence will be. The author then asks the reader to consider what goals are to be accomplished using these artificial brains. Since the construction of these brains is done to get something different from human brains, the advantages in using them must be delineated. In the author's view they must go beyond the limitations imposed by the human brain. The author spends over half of the book describing what has been accomplished in the actual construction of artificial brains, with emphasis on the activities of his laboratory at the University of Reading in the UK. All of this discussion is fascinating reading.  <br />	2005-01-20
388416:US	50702879	R3VYU5JEJL0M0W	0470843802	209578173	Analysis of Genes and Genomes	Books	4	5	6	N	Y	Does its job well	The twenty-first century has rightfully been called the \\"age of biology\\", and draws on the laboratory techniques developed in the last half of the twentieth century. The advent of commercial products, medicines, and foodstuffs using the techniques of genetic engineering has resulted in an explosion of books and monographs that attempt, and usually succeed, in explaining these techniques to students and also to those curious about them. Compared to most of these books, this one gives a fairly rapid overview of the subject of genetic analysis and genetic engineering, but one can still gain a deep appreciation of the subject by its study. Many useful diagrams appear in the book, and the author gives useful summaries at the beginning of each chapter. This reviewer only read the last three chapters of the book, so this review will be confined to these.<br /><br />The genetic engineering of plants is covered in chapter 11 of this book. This has become a very contentious topic of late, due to the perceived dangers of genetically modified crops. The author recommends, rightfully, that the potentially adverse side effects of these crops should be studied via careful experimentation. Genetically modified crops have been a contentious issue in the last few years, and the debate concerning their use and consumption has reached a level of vitriol that goes beyond all measurable bounds. This chapter puts the subject on a clear scientific foundation and readers who are interested in genuine scientific understanding of the genetic engineering of plants will benefit greatly from its perusal.<br /><br />Why is it so difficult to get a foreign gene to be expressed in a mammalian cell in which it is inserted? This question is of great interest in biotechnology and is discussed in chapter 12 of the book. Another one of the more interesting topics in this chapter regards the existence of `immortalized' cells, which continue to divide even after being cultured. Two examples are mentioned, the HeLa cells derived from a woman who died of cervical cancer in 1951, and Chinese hamster ovary cells. Programmed cell death or `apoptosis' has been the subject of intense research in recent years, due to its importance in the curing of cancer. The author emphasizes the extreme difficulties involved in obtaining stable transfection in animal cell lines, and discusses several methods to make it more efficient.<br /><br />The author continues the discussion of the genetic engineering of animals in chapter 13, after first reviewing some elementary embryology. This chapter is of particular interest to those readers who are interested in understanding the science behind stem cell research. First discussed is the production of transgenic animals using pronuclear injection. The author points out some of the consequences of this technique brought out by experiments with laboratory mice. One of these is the high concentration of growth hormone mRNA in their livers and growth hormone in their serum, resulting in mice of considerable larger size than their non-transgenic counterparts. The author lists some of the disadvantages in the technique, such as its inability to do gene knock-out, the difficulty in controlling the expression of the transgene, the fact that the expression of the transgene is not strictly inherited, and the occasional creation of a \\"mosaic\\" animal, where the transgene only occurs in certain organs and tissues of the animal. The creation of mosaic animals has resulted in patentable technology in recent years, so this technique, in various guises, does have practical applications.<br /><br />Embryonic stem cells, defined by the author as being undifferentiated cells that are isolated from the inner cell mass of a blastocyst, are discussed next. Interestingly, embryonic stem cells can be maintained in culture indefinitely via cell divisions, and will remain undifferentiated as long as they grown at large distances from each other. The main advantage in using embryonic stem cells, according to the author, lies in their efficiency in homologous recombination. He points out though that non-homologous recombination does still occur, and to distinguish between cells that have integrated the DNA fragment homologously and those that have done so non-homologously, use is made of `ganciclovir', which after phosphorylation will result in inhibition of DNA polymerase activity. Cells that have undergone homologous integration will survive the ganciclovir treatment.<br /><br />The author uses this discussion to motivate the concept of knock out genes, which he considers of extreme importance not only to the understanding of biology but also to the analysis of human disease. There are three classes of knock-outs depending on whether they are lethal to the organism, or either change its phenotype or not. The author also discusses the existence of `conditional' knock-outs, where there is no observable phenotype but arise when genes are acting in parallel pathways and consequently compensate for each other's functions. He also points out that knockout experiments take a considerable amount of time and are very expensive, but this will no doubt change in the upcoming years.<br /><br />Nuclear transfer, certainly the most well known of the techniques in genetic engineering, is also discussed in this chapter. The cloning of mammals, via the transfer of cells from an embryo and fusing them with enucleated eggs, such as was done with sheep, is discussed in fair detail. The author points out the difficulties in producing viable offspring using nuclear transfer from differentiated adult cells. These include the inefficiency of the technique, abnormal offspring, telomere shortening and consequent shortening of life spans. Although cloning of other farm and domestic has been done successfully, the author exhibits justified caution in the cloning of human beings. However, if and when cloning can be shown to be a viable and safe technique for human asexual reproduction, it should definitely be an option for those individuals who have chosen it as their best method for reproduction.. The main advantage in using embryonic stem cells, according to the author, lies in their efficiency in homologous recombination. He points out though that non-homologous recombination does still occur, and to distinguish between cells that have integrated the DNA fragment homologously and those that have done so non-homologously, use is made of `ganciclovir', which after phosphorylation will result in inhibition of DNA polymerase activity. Cells that have undergone homologous integration will survive the ganciclovir treatment.  <br /> <br />The author uses this discussion to motivate the concept of knock out genes, which he considers of extreme importance not only to the understanding of biology but also to the analysis of human disease. There are three classes of knock-outs depending on whether they are lethal to the organism, or either change its phenotype or not. The author also discusses the existence of `conditional' knock-outs, where there is no observable phenotype but arise when genes are acting in parallel pathways and consequently compensate for each other's functions. He also points out that knockout experiments take a considerable amount of time and are very expensive, but this will no doubt change in the upcoming years.  <br /> <br />Nuclear transfer, certainly the most well known of the techniques in genetic engineering, is also discussed in this chapter. The cloning of mammals, via the transfer of cells from an embryo and fusing them with enucleated eggs, such as was done with sheep, is discussed in fair detail. The author points out the difficulties in producing viable offspring using nuclear transfer from differentiated adult cells. These include the inefficiency of the technique, abnormal offspring, telomere shortening and consequent shortening of life spans. Although cloning of other farm and domestic has been done successfully, the author exhibits justified caution in the cloning of human beings. However, if and when cloning can be shown to bea viable and safe technique for human asexual reproduction, it should definitely be an option for those individuals who have chosen it as their best method for reproduction.	2005-01-14
390087:US	50702879	R2ZSXQ9QTY9PHP	0387916075	402310314	Photosynthesis: Molecular, Physiological and Environmental Processes	Books	5	5	5	N	Y	A concentrated overview of photosynthesis	It is perhaps a cliche to say that the process of photosynthesis is the most important one on Earth. Taking advantage of an essentially inexhaustible source of photons, photosynthesis is a highly complex sequence of physical events, with its evolutionary origins only recently explained. This monograph gives a comprehensive overview of photosynthetic system, and is one of the few that includes discussion of its molecular biology. The genetic engineering of the chloroplast is now of great interest, and is being done by many researchers. Readers who want to understand these developments will find a good start in this book. In addition, there has been a growing interest in being able to emulate photosynthesis in non-biological systems. Called `artificial photosynthesis', it would replicate or perhaps improve on the natural photosynthetic system, a prospect that has tremendous technological implications. In addition, the physics behind photosynthesis is discussed at an elementary level in the book, and would be suitable for readers who want to understand the physical processes but without getting into the details. A more detailed discussion would require a discussion of the physics of `excitons', which can involve advanced mathematics, more than this book wants to provide. Unfortunately the book does not discuss how the photosynthetic apparatus evolved, but this is a recent topic that was still pretty much an open question at the time of its publication.<br /><br /> Every topic in the book is fascinating, but for this reviewer the chapter on the molecular biology of the photosynthetic system stood out among the rest. One learns of how the chloroplasts contain DNA that replicates independently of other parts of the genome. This is called `chloroplastic DNA (cpDNA)' and codes for certain proteins, a list of which is given in the chapter. It is interesting to note that chloroplasts supposedly originated as prokaryotic endosymbionts, but as the author explains, many of the original symbiont genes were transferred to the nuclear genome. Their function was then replaced by new mechanisms in the chloroplasts. Chloroplast genes can be activated by light. Called in the book `photogenes', when illuminated they result in increases in transcripts and protein products. A list of light activated genes of the chloroplast and their products are given in this chapter.<br /><br /> In this chapter, the author also points out some open problems that require further research, such as the mechanism behind the proteolysis of the D1 protein in photosystem II. Another open question regards finding the explanation as to why different species of plants have wide variations in their response to light, with genes in some species showing both low and normal response to light, whereas in another showing no low light response. The author's tentative explanation for these differences is that they originate in the context of the ecological behavior of the plants. The sensitivity to light may give an advantage when seedlings are attempting to reach the soil surface or are in deep shade. It would not be advantageous to initiate the photosynthetic reactions fully until sufficient light is available.<br /><br /> That the nuclear and chloroplast genomes are not independent is readily clear from the discussions in this chapter on their interaction. The author gives a detailed diagram illustrating how they interact in terms of their gene products and their incorporation into the chloroplast compartments. The role of phytochrome in the regulation of gene expression is emphasized throughout this discussion. The author also discusses the `chloroplast factor', which is a mechanism for passing information to the nucleus that the chloroplast is ready to receive a protein.<br /><br /> This short review does not even scratch the surface of the many topics that are discussed in this book. Indeed, the apparatus of photosynthesis is extremely complex and one must spend a fair amountof time in attempting to understand it with a reasonable scale of detail. Many references are given for those readers who intend to gain an even more detailed understanding of photosynthesis. The time spend reading and studying this book is well worth it, even if one does not intend to specialize in research in photosynthesis, but rather has an intense curiosity to fathom what is certainly one of the most fascinating of physical systems to evolve on this planet.fair amount of time in attempting to understand it with a reasonable scale of detail. Many references are given for those readers who intend to gain an even more detailed understanding of photosynthesis. The time spend reading and studying this book is well worth it, even if one does not intend to specialize in research in photosynthesis, but rather has an intense curiosity to fathom what is certainly one of the most fascinating of physical systems to evolve on this planet.	2005-01-12
400134:US	50702879	R1SC86U1JP2X8J	0521011493	100105227	An Introduction to the International Criminal Court	Books	4	7	8	N	Y	Very helpful	For this reviewer, who is definitely not a legal expert, this book was read with the goal of understanding to what extent pre-emptive wars can be viewed as `legal', to discover the reasons why the United States chose to withdraw its participation in the International Criminal Court, and to gain basic knowledge on the tenets and origins of international law in order to find out if indeed the current conflict in Iraq could be viewed as a `war crime' or some other severe violation of international law. Before reading this book, this reviewer was very unknowledgeable about legal concepts and reasoning in the context of international law, and had the opinion that international legal agreements were very fragile and tenuous. This view did not really change after reading the book, but its perusal did offer a few surprises and was thought provoking to a large degree. Like most legal treatises, this book suffers from the typical `tyranny of the footnote' that accompanies legal or history books. This minor annoyance that causes the flow of the reading to be disrupted is perhaps compensated by the need for the reader to know that the sources are available and that they can be checked if necessary.<br /><br />Readers who are not legal experts will no doubt think of the Nuremberg trials as being the best representative of what an international court can accomplish given the jurisdiction. Their biases in this regard are in fact true as is brought out many times in the book, particularly in the discussion on genocide and `crimes against humanity', which the Nuremberg trails were set up to deal with after the second world war. The word `genocide' apparently originated with Raphael Lewkin in 1944. Lewkin wanted to make sure that crimes against groups were prosecuted. It was later adopted in 1946 by the Nuremberg prosecutors and declared an `international crime' by the General Assembly of the United Nations. Genocide was to be distinguished from `crimes against humanity' since the latter was only to hold in the context of an international armed conflict. The author argues that the distinction is not really significant today, with `crimes against humanity' now referring to atrocities committed in wartime and in peacetime. However, genocide is to be distinguished from `crimes against humanity' and `war crimes' in that it must be committed with the `intent' of destroying a national, ethnic, racial, or religious group. It is this `special intent' the author argues, that makes genocide different from the other two crimes.<br /><br />According to the author, the designation of an activity as a `war crime' began with the 1907 Hague Convention IV and was refined in the 1919 Commission on Responsibilities. From then on says the author, \\"there is little argument about the existence of war crimes under international law.\\" The Nuremberg charter listed as a war crime the murder or ill treatment of prisoners of war, the killing of hostages, the wanton destruction of cities, villages, or towns, and devastation not justified by military necessity, among other activities. In reference to this, it would seem that the war in Iraq should be labeled as a war crime given that some of the activities to date in this war do satisfy these criteria. In addition, the fire bombing of Tokyo and Dresden, and the atomic bombing of Hiroshima and Nagasaki could be classified as war crimes according to the Nuremberg charter.<br /><br />Of all the characteristics of the International Criminal Court, its jurisdiction is the most problematic. Its creators were very ambitious in their goals, for it was to have the most general scope and application of any international body to date. The author emphasizes that its creation rests on the voluntary participation of countries that decide to be subject to its jurisdiction. The ICC though has a narrower jurisdiction than the individual countries that participate in it. The drafters were careful to grant the individual countries the first crack at the prosecution of certain crimes. If the domestic justice system is `unwilling' or `unable' to prosecute then the ICC can take over. The author refers to this as `admissibility' in the book, which is to be distinguished from jurisdiction. Jurisdiction refers to the `situation' in which a crime has been committed, whereas `admissibility' refers to the proper identification of a `case' that can be taken up by the ICC. The jurisdiction of the ICC though can be prevented by the UN Security Council, this being called `deferral' by the author, and was put in so that the ICC would not be able to act effectively as no veto on issues brought to the Security Council.<br /><br />When reading the book one is struck by the extreme fragility of international law and the difficulties needed to enforce it. The author describes the statutes of the Nuremberg, Tokyo, Yugoslavia, and Rwanda tribunals as being \\"very thin\\" when viewed in the context of criminal law. These tribunals allowed the judges much discretion, but the ICC under the Rome statute attempted to limit judicial discretion to a very large degree. The ICC was to draw on many sources of legal doctrine in order to define the general principles upon which it was to operate. As examples, the author quotes Romano-Germanic and Sharia forms of penal justice, reflecting of course the international character of the ICC, and the diversity of the states that elect to be under its jurisdiction.<br /><br />In the opinion of this reviewer, the best feature of the International Criminal Court is its insistence on trying and punishing individuals, and not states, or other \\"abstract entities\\" like corporations (although corporate liability was debated considerably by the delegates according to the author). Commanders who order their subordinates to carry out war crimes or do not act to prevent them are particularly culpable. Without such an international legal body, disputes or grievances between states will be settled by the use of military power. The victor will have no one to answer to, regardless of the heinous acts it committed to win.he first crack at the prosecution of certain crimes. If the domestic justice system is `unwilling' or `unable' to prosecute then the ICC can take over. The author refers to this as `admissibility' in the book, which is to be distinguished from jurisdiction. Jurisdiction refers to the `situation' in which a crime has been committed, whereas `admissibility' refers to the proper identification of a `case' that can be taken up by the ICC. The jurisdiction of the ICC though can be prevented by the UN Security Council, this being called `deferral' by the author, and was put in so that the ICC would not be able to act effectively as no veto on issues brought to the Security Council.  <br /> <br />When reading the book one is struck by the extreme fragility of international law and the difficulties needed to enforce it. The author describes the statutes of the Nuremberg, Tokyo, Yugoslavia, and Rwanda tribunals as being \\"very thin\\" when viewed in the context of criminal law. These tribunals allowed the judges much discretion, but the ICC under the Rome statute attempted to limit judicial discretion to a very large degree. The ICC was to draw on many sources of legal doctrine in order to define the general principles upon which it was to operate. As examples, the author quotes Romano-Germanic and Sharia forms of penal justice, reflecting of course the international character of the ICC, and the diversity of the states that elect to be under its jurisdiction.  <br /> <br />In the opinion of this reviewer, the best feature of the International Criminal Court is its insistence on trying and punishing individuals, and not states, or other \\"abstract entities\\" like corporations (although corporate liability was debated considerably by the delegates according to the author). Commanders who order their subordinates to carry out war crimes or do not act to prevent them are particularly culpable. Without such an international legal body, disputes or grievances between states will be settled by the use of military power. The victor will have no one to answer to, regardless of the heinous acts it committed to win.	2005-01-05
414535:US	50702879	RZD5C3JQXSC3	0262220555	312843045	Automated Reasoning and Its Applications: Essays in Honor of Larry Wos	Books	4	0	0	N	Y	Of historical interest	This book overviews the status of research in automated reasoning as it stood in 1997, but with emphasis on the work of Larry Wos, and one year after the announcement of the proof of the Robbins conjecture by the EQP reasoning machine. The book is still worth perusing, even though it is seven years out of date, and there has been a considerable amount of work done in the field of automated reasoning since 1997. Much of this work has involved dealing with the informal nature of mathematical proofs as they are currently done in most of the mathematical research literature, and thus involves research both in natural language processing and in automated reasoning. The applications of automated reasoning have to this date involved deductive databases and formal checking of computer systems and circuit designs. The field of automated reasoning is of course of great importance to those involved in the construction of intelligent machines. Throughout this book proof systems such as OTTER (for Organized Techniques for Theorem proving and Effective Research) are referred to quite frequently. OTTER is now one of the most popular systems for the exploration of automated reasoning, and is publicly available. Due to constraints of space, only selected articles of the book will be reviewed here.<br /><br /> The notion of linked resolution is discussed in the second article of the book, which is a strategy used to deal with \\"uninteresting\\" clauses in resolution-based provers. Linked resolution will perform proof steps until an \\"interesting\\" clause is derived, which it will retain and then eliminate the intermediate results. It does this by identifying a collection of clauses called `linking clauses', which are used as a nucleus only in certain steps, like a hyperresolution clash. The author of the article proves a completeness theorem for predicate logic without equality that incorporates linked resolution, and considers this result a generalization of the completeness of hyperresolution. He emphasizes though that adding equality and paramodulation will eliminate the completeness result.<br /><br /> The third article in the book discusses Isabelle, which is a theorem prover that is based upon resolution, and searches for proofs using a tableau approach. It is, according to the author of the article, a `generic' reasoner, in that it can work in a variety of domains without reducing them to first-order logic. Isabelle is also `interactive' meaning that its user can direct each step of the proof. Interactive provers are to be distinguished from the `resolution' systems such as OTTER, but Isabelle is also based upon a form of resolution, and therefore represents a \\"synthesis\\" between the these two traditions in automated reasoning. The author thus describes Isabelle as an interactive prover based on the typed lambda-calculus, and uses as its primary inference rule a generalization of Horn clause resolution. The author outlines in detail the tableau approach, and uses Isabelle to prove classical results in set theory and first-order logic and proves the Church-Rosser theorem for combinators. When reading the article one sees immediately the connection of Isabelle with higher-order logic, it being a `meta-logic' that supports `object-logics' (the meta-logic supporting connectives, implication, and equality), making use of functions called `tacticals' that operate on proof states called `tactics', with concepts from logic programming used to support automation on the tactics and tacticals.<br /><br /> The fifth article in the book, written by William McCune, who is responsible for the use of EQP and its consequent proof of the Robbins conjecture, is an overview of how to evaluate the `paramodulation' strategies using EQP. A test collection of 33 equational theorems is used for this evaluation, and the performance of OTTER and EQP are compared on this collection. The proof of the Robbins conjecture, because of the timing in publishing this book, is not included, as it was solved by EQP, as the author indicates, after this article was finished. The author though describes in some detail the Robbins algebra, and in a footnote briefly discusses how the Robbins conjecture was proven.<br /><br /> The most interesting of the articles in the book is the last one, which concerns what the author of article calls \\"metalevel reasoning\\", and its role in controlling automated reasoning programs. He defines metalevel reasoning as being the reasoning with facts and knowledge beyond the symbols of the formula given to the basic reasoning system. This notion encapsulates perfectly the process by which human mathematicians have generated proofs for the last few centuries. Unlike the case of the formal and automated reasoning systems that have been developed over the last five decades, human mathematicians use ordinary language and extraneous knowledge that is typically outside of the scope or domain of the problem they are analyzing. Automated reasoning systems developed up until now do not do this, says the author, but instead manipulate the symbols of formulas according to a collection of inference rules. A reasoning system that incorporates metareasoning would be an enormous benefit argues the author, and could provide the \\"proving\\" expertise that is now introduced by fiat by the developer or user of the reasoning system. He gives a few examples of metalevel reasoning, and gives an overview of just how a reasoning system that incorporated it would behave. The author also discusses how metalevel control has been studied in the context of general research in artificial intelligence. The research that he describes in this article is now occupying the time of many researchers in automated reasoning and automated theorem proving, and if it comes to fruition will represent a major advance in machine intelligence. For a machine to be able to generate and prove theorems in the manner that human mathematicians are able to, would be an example of machine creativity and has enormous potential in real-world applications such as bioinformatics, automated scientific discovery, network management, and financial engineering. It is for this reason that this reviewer regards this type of research into automated reasoning as being the most important of all activities to date.book, is not included, as it was solved by EQP, as the author indicates, after this article was finished. The author though describes in some detail the Robbins algebra, and in a footnote briefly discusses how the Robbins conjecture was proven.  <br /> <br /> The most interesting of the articles in the book is the last one, which concerns what the author of article calls \\"metalevel reasoning\\", and its role in controlling automated reasoning programs. He defines metalevel reasoning as being the reasoning with facts and knowledge beyond the symbols of the formula given to the basic reasoning system. This notion encapsulates perfectly the process by which human mathematicians have generated proofs for the last few centuries. Unlike the case of the formal and automated reasoning systems that have been developed over the last five decades, human mathematicians use ordinary language and extraneous knowledge that is typically outside of the scope or domain of the problem they are analyzing. Automated reasoning systems developed up until now do not do this, says the author, but instead manipulate the symbols of formulas according to a collection of inference rules. A reasoning system that incorporates metareasoning would be an enormous benefit argues the author, and could provide the \\"proving\\" expertise that is now introduced by fiat by the developer or user of the reasoning system. He gives a few examples of metalevel reasoning, and gives an overview of just how a reasoning system that incorporated it would behave. The author also discusses how metalevel control has been studied in the context of general research in artificial intelligence. The research that he describes in this article is now occupying the time of many researchers in automated reasoning and automated theorem proving, and if it comes to fruition will represent a major advance in machine intelligence. For a machine to be able to generate and prove theorems in the manner that human mathematicians are able to, would be an example of machine creativity and has enormous potential in real-world applications such as bioinformatics, automated scientific discovery, network management, and financial engineering. It is for this reason that this reviewer regards this type of research into automated reasoning as being the most important of all activities to date.	2004-12-23
415824:US	50702879	RVE7I5ZC6FMJW	9812387129	393229265	Quantitative Finance and Risk Management: A Physicist's Approach	Books	4	33	35	N	Y	Very effective overview	This book gives a good general overview of financial engineering but only for those who have had a lot of prior exposure to the subject, at least from a theoretical or academic point of view, but have yet to get their feet wet in actual practice. For physicists with a background in quantum field theory, stochastic dynamical systems, or statistical mechanics, the mathematics in this book will be straightforward, and physicists will be intrigued that some of their ideas are being applied to finance. It is not a book for beginners though, as it will demand a lot of attention to details, as well as a considerable amount of outside reading. Space does not permit a detailed review of such a large book, and so only selected chapters will be reviewed.<br /><br />In chapter 4, the author analyzes plain-vanilla equity options and discusses in particular the case of American options. The calculation of the probabilities of exercise at different future times involves the determination of the critical path followed by a Monte Carlo simulation to determine to the fraction of paths crossing the critical path in each interval of time. The hedges are then distributed in time as the delta times these probabilities of exercise. The author unfortunately does not give the details of how to obtain the critical path in this chapter, but these details can be found in later chapters on path integrals.<br /><br />In chapter 5, foreign exchange options are discussed including how to hedge with the Greeks. The author shows how to price FX forwards and FX European options. He mentions that the Garman-Kohlhagen model is used to price the FX options, but he does not elaborate in any detail on the model. This model, which is the standard pricing convention in the FX market, is the analog of the Black-Scholes model, but where a foreign riskless interest rate is used as the payout on the underlying asset. Particularly interesting in this chapter is the author's discussion on the \\"two-country paradox\\". This paradox arises because the change of variables in foreign exchange instruments forces one to do a separate normalization of the drift of each variable, and does not arise for ordinary options. The drift after the change of variable is not consistent with interest-rate parity. Also discussed are the `volatility smiles' that are empirically observed in FX. As the author illustrates in a diagram, the smile corresponds to an upward-facing parabola, and he explains its occurrence by a \\"fear factor\\" (sometimes called \\"crash-o-phobia\\" in the equity option literature), which causes the implied volatilities of OTM puts to be bid up, thus putting a premium on this volatility relative to the ATM volume.<br /><br />There are five chapters in the book that discuss the use of path integrals in finance, and these chapters include the formalism and how to calculate them numerically. The writing in these chapters is very lucid, and this no doubt reflects the author's background in physics and his consequent bias toward the use of functional integration in financial modeling. The discussion of the Black-Scholes in the context of functional integration is good motivation for later developments, and should convince readers as to the viability of this approach in finance. In addition, the author gives examples where the path integral approach does not merely reproduce the standard results in finance, one of these examples being the inclusion of dividends in options valuation. Including dividends can be done via the use of an \\"effective drift function\\", as the author shows in detail. He also shows that jumps in stock price can be studied in the same way as dividends in the context of path integration. Discrete-schedule Bermuda options are also tackled using path integral methods, as well as American options, and the author shows the reader how to calculate the critical path for these scenarios, following up on a promise in an earlier chapter. The chapter on numerical methods forthe calculation of path integrals is interesting because it introduces some techniques and concepts that are no doubt new to many readers, such as \\"geometric volatility\\", which corresponds to an approximate volatility that would lead to a particular set of paths.<br /><br />Perhaps the most interesting and \\"exotic\\" of the discussions in the book is included in chapter 46, and regards the application of `Reggeon field theory' (RFT) to financial engineering. Even for physicists working in quantum field theory, this type of field theory may be unknown to them, but the author does give a very brief review. He assumes background in scattering theory, the renormalization group, dimensional regularization, and other topics in field theory and high-energy physics, in order to read this chapter. RFT is presented as a theory to describe high-energy diffractive scattering, as a field theory for a particle called the `Pomeron'. The author's interest for the application of RFT to finance concern its ability to model nonlinearities and non-linear diffusion. He writes down the Lagrangian for RFT, which involves the nonlinear product of three fields, and when the interaction is switched off reduces to an ordinary diffusive model in imaginary time. One could apply ordinary perturbation theory to the case of weak interactions, but the author instead is interested in the non-perturbative region for the theory. This he tackles with the renormalization group, the object of which is to find the critical dimension, in order to test for the occurrence of a phase transition. Therefore the Gell-Mann Low beta function is to be calculated (using perturbation theory) and its zeros found. The author summarizes what is known for RFT from the research in the literature. The applications to finance consist of the ability of the RFT model to describe deviations from \\"square-root time\\", the latter of which arises from the standard Brownian motion assumption in financial theory. The RFT model reduces to the standard financial model when the interactions vanish. The nonlinear interactions are expected to produce interesting \\"fat-tail\\" jump events, but the author does not elaborate on this in any detail.hods for the calculation of path integrals is interesting because it introduces some techniques and concepts that are no doubt new to many readers, such as \\"geometric volatility\\", which corresponds to an approximate volatility that would lead to a particular set of paths.  <br /> <br />Perhaps the most interesting and \\"exotic\\" of the discussions in the book is included in chapter 46, and regards the application of `Reggeon field theory' (RFT) to financial engineering. Even for physicists working in quantum field theory, this type of field theory may be unknown to them, but the author does give a very brief review. He assumes background in scattering theory, the renormalization group, dimensional regularization, and other topics in field theory and high-energy physics, in order to read this chapter. RFT is presented as a theory to describe high-energy diffractive scattering, as a field theory for a particle called the `Pomeron'. The author's interest for the application of RFT to finance concern its ability to model nonlinearities and non-linear diffusion. He writes down the Lagrangian for RFT, which involves the nonlinear product of three fields, and when the interaction is switched off reduces to an ordinary diffusive model in imaginary time. One could apply ordinary perturbation theory to the case of weak interactions, but the author instead is interested in the non-perturbative region for the theory. This he tackles with the renormalization group, the object of which is to find the critical dimension, in order to test for the occurrence of a phase transition. Therefore the Gell-Mann Low beta function is to be calculated (using perturbation theory) and its zeros found. The author summarizes what is known for RFT from the research in the literature. The applications to finance consist of the ability of the RFT model to describe deviations from \\"square-root time\\", the latter of which arises from the standard Brownian motion assumption in financial theory. The RFT model reduces to the standard financial model when the interactions vanish. The nonlinear interactions are expected to produce interesting \\"fat-tail\\" jump events, but the author does not elaborate on this in any detail.	2004-12-22
415841:US	50702879	RAF8UX3IBO802	9812388974	263496969	Beautiful Models: 70 Years of Exactly Solved Quantum Many-Body Problems	Books	5	26	26	N	Y	Gives good insights into quantum integrable models	The main virtue of this book is that it clears up any confusion regarding the notion of integrability in a quantum system. After an historical overview of the theory of exactly solvable systems in chapter 1, the author recalls the notion of integrability in classical mechanics, restricting his discussion to systems that are governed by a Hamiltonian. Using the standard action-angle canonical transformation he shows that the integrability of a Hamiltonian system is, as is well known, indicated by the presence of a finite set of quantities that are in `involution', i.e. they are constants of motion.<br /><br /> This notion of integrability will not work for finite-dimensional quantum systems, as the author shows by using a system that hypothetically has a set L of mutually commuting operators, this set also including the Hamiltonian. He shows that no two commuting operators are algebraically independent, and at most D commuting operators are linearly independent, where D is the dimension of the eigenspace of one of the operators. The author then presents a notion of integrability that is less trivial, in that it will give information on the dynamics of the quantum system.<br /><br /> Since quantum systems are typically systems of particles that are interacting with each other, the dynamical events of interest are the scattering events. Indeed, the scattering theory of quantum systems is highly developed, and has inspired an enormous amount of research in both physics and mathematics. The author justifies the viability of this notion of integrability by considering several elementary systems, starting in one dimension and considering one and then two particles, he shows that energy and momentum conservation are strong enough to force the momenta of the scattered particles to be merely rearrangements of the incoming momenta (the particles essentially \\"pass through one another\\").<br /><br /> Things are more complicated when three particles are considered. Energy and momentum conservation can no longer insure that the asymptotic momenta are merely rearrangements of the incoming momenta. The famous `Bethe ansatz' though allows the determination of ratios of amplitudes for scattering in terms of two-body collisions. Genuine 3-body scattering is to be included in the total asymptotic wavefunction, which will deviate from a plane wave as it emerges from a 3-body overlap region. The author call this `diffractive' scattering, and he notes that it will not occur for exactly solvable systems. For generic one-dimensional systems it will occur however, and this prohibits the use of Bethe ansatz. The presence of diffractive scattering will prohibit the occurrence of a third independent conserved quantity, and this gives the author a criterion for defining `non-integrability.' The quantum systems considered in the book are `integrable' and thus do not support diffractive scattering. The consequences of diffractionless scattering in quantum systems are for the author just as interesting as what happens in classical integrable system, and he has written this book to elucidate the properties of these \\"beautiful\\" systems.<br /><br /> Early on in the book the author discusses various techniques that will be used in analyzing the systems throughout the book. These techniques arise in the analysis of systems that are in the ground state and just above the ground state, and when they are at finite temperature. The systems that are studies are all integrable and nondiffractive, and thus obey what the author calls the `fundamental equations', which are coupled equations for the momenta of the system. Systems governed by the delta-function, inverse-square, and hyperbolic potentials are a few those considered when discussing these techniques.<br /><br /> An entire chapter of the book is devoted to the Heisenberg-Ising model, which was the first one that was tackled using the Bethe ansatz and is a model for a magnetic chain and a quantum lattice gas. This model is integrable, or \\"diffractionless\\" as an application of the Bethe ansatz proves, and the author shows how to obtain a complete set of equations for the spectrum using this ansatz. The ground state energy in zero flux and zero field is calculated, and this calculation is then generalized to the case of non-zero field and flux.<br /><br /> Also considered in the book are exchange models, which are quantum systems that have potentials that allow the exchange of quantum numbers between two particles. The author shows how to take some of the potentials that are considered in the book, such as the hyperbolic potential, and modify them to obtain exchange potentials. The hyperbolic potential in particular is strongly repulsive at the origin, and so the wavefunction of two particles will vanish when they meet, prohibiting mixing of different types of particles. This can be alleviated by the incorporation of permutation operator that exchanges the two particles.<br /><br /> The author also discusses the famous Hubbard model in the last chapter of the book. This model, used in condensed matter physics for modeling systems of strongly interacting electrons, is integrable in one dimension, as the author shows using again the Bethe ansatz.<br /><br /> The best chapter of the book is chapter 7, for therein the author addresses in detail more general questions on the property of integrability and how to prove when a system is integrable and when it is not. Noting that there is no optimal way to show that a system is integrable, he discusses various approaches to showing integrability of systems that support scattering. The discussion in this chapter is very lucid, and consequently readers will gain a lot of insight into the properties of integrable systems, particularly in the role of the Yang-Baxter equations and the subsequent notion of a `transfer operator'. The author's explanation of a transfer operator as corresponding to the scattering of test particle with all the other particles is one that clarifies its role and is an explanation that is not found in the literature on exactly solvable systems. He also gives a very interesting discussion of the physics behind non-integrability, using as examples scattering of light rays off wedges of mirrors. These examples serve to shed more light on the behavior of nonintegrable systems, which is more helpful than mere mathematical calculations.tice gas. This model is integrable, or \\"diffractionless\\" as an application of the Bethe ansatz proves, and the author shows how to obtain a complete set of equations for the spectrum using this ansatz. The ground state energy in zero flux and zero field is calculated, and this calculation is then generalized to the case of non-zero field and flux.  <br /> <br /> Also considered in the book are exchange models, which are quantum systems that have potentials that allow the exchange of quantum numbers between two particles. The author shows how to take some of the potentials that are considered in the book, such as the hyperbolic potential, and modify them to obtain exchange potentials. The hyperbolic potential in particular is strongly repulsive at the origin, and so the wavefunction of two particles will vanish when they meet, prohibiting mixing of different types of particles. This can be alleviated by the incorporation of permutation operator that exchanges the two particles.  <br /> <br /> The author also discusses the famous Hubbard model in the last chapter of the book. This model, used in condensed matter physics for modeling systems of strongly interacting electrons, is integrable in one dimension, as the author shows using again the Bethe ansatz.  <br /> <br /> The best chapter of the book is chapter 7, for therein the author addresses in detail more general questions on the property of integrability and how to prove when a system is integrable and when it is not. Noting that there is no optimal way to show that a system is integrable, he discusses various approaches to showing integrability of systems that support scattering. The discussion in this chapter is very lucid, and consequently readers will gain a lot of insight into the properties of integrable systems, particularly in the role of the Yang-Baxter equations and the subsequent notion of a `transfer operator'. The author's explanation of a transfer operator as corresponding to the scattering of testparticle with all the other particles is one that clarifies its role and is an explanation that is not found in the literature on exactly solvable systems. He also gives a very interesting discussion of the physics behind non-integrability, using as examples scattering of light rays off wedges of mirrors. These examples serve to shed more light on the behavior of nonintegrable systems, which is more helpful than mere mathematical calculations.	2004-12-22
418308:US	50702879	R3A619XRJ63TM1	0262201267	251285130	Learnability in Optimality Theory (MIT Press)	Books	4	5	5	N	Y	An interesting overview	A given language learner will choose a grammar based on how she interprets the forms she has heard. The particular grammar she chooses will determine which analysis she chooses for a form. This issue of language learning is the central one that the authors attempt to address in this book, and they do so using `optimality theory', which was developed by one of them. The authors present an approach to language learning that they call `robust interpretive parsing/constraint demotion', that they claim addresses this issue by using a form of successive iteration. The language learner will initially make a guess at a grammar in order to estimate the structural analysis of the data, and then consequently use this analysis to improve the grammar. She will then used the improved grammar to further improve the analysis, and so on. She learns the correct interpretation of the data and the correct grammar at the same time by deploying this iterative scheme, which, according to the authors, makes heavy use of optimality theory in order to characterize the knowledge of the language that she acquires.<br /><br /> The data that is presented to a language learner is very sparse, and this makes the learning of the grammar difficult. According to the authors, a theory of universal grammar must therefore be able to restrict the space of grammars that the learner must consider. Being able to restrict this space is typically taken to mean that only a finite set of grammars need be considered, with each member of the set distinguished via the values of a finite number of parameters. This collection may indeed be very large, and so the goal is place structure on this collection that the language learners can use effectively. The authors discuss briefly a few of these in the first chapter of the book, these being examples of `principles-and-parameters universal grammar', but they conclude that they do not offer enough structure for a language learner to use over and above that of simple search. Optimality theory they say provides the needed structure, and provides learning algorithms that are independent of grammatical assumptions. The authors do not spend a lot of time in the book developing optimality theory, that being done in another book of which one of the authors (Smolensky) was author, but they do devote chapter 2 to its review.<br /><br /> In addressing the language learning problem, the authors want to distinguish three different types of linguistic structure. In order of appearance these are the overt part of the grammatical forms which are directly accessible to the learner, followed by the full structural descriptions, which combine overt and hidden structure, and finally the actual grammar itself, which determines the structural descriptions that are well formed. Using these structures they decompose the language learning problem into `robust interpretive parsing', which maps the overt part of a form into a full structural description, and that of `learning the grammar' using a \\"robust\\" parser.  That these two activities can in fact be \\"decoupled\\" and still result in powerful learning algorithms is one that the authors attempt to justify in the book.<br /><br /> The authors classify these algorithms in the context of hidden Markov models and expectation maximization, which they call `iterative model-based learning algorithms.' These learning algorithms have been around for quite sometime, and have had successful applicability in other contexts. It is not surprising at all that the authors would want to base their approach to language learning on them. They connect iterative model-based learning with optimality theory via the use of `harmony theory', which comes from the theory of neural networks, wherein a representation is deemed more \\"probable\\" the greater the value of its \\"harmony\\".<br /><br /> Harmony theory applied to language learning is appropriately called `harmonic grammar', and the learning procedure follows the parsing/learning procedure discussed above. In the author's theory though the parsing step is `robust interpretive parsing', which gives the most harmonic structural description consistent with the overt data, given the current grammar, which is then followed by `constraint demotion' which gives a grammar that optimizes the structural description in the parsing step. For constraint demotion, the authors prove that for N constraints, no more than N(N-1) informative examples will be needed in order to determine the correct grammar.<br /><br /> In constraint demotion, the learner determines the grammaticality of a structural description with respect to competing candidates, which the authors believe is an advantage, in that these candidates must be dealt with. Positive evidence in the form of a grammatical structural description brings with it negative evidence of competing descriptions. A competing candidate and the grammatical structure will assist in the determination of the correct ranking, as the latter will make the grammatical structure more harmonic than the ungrammatical competitor. Given a collection of loser/winner pairs, the constraint demotion algorithm discovers a ranking that makes each winner more harmonic than its corresponding loser. The algorithm demotes the constraints violated by the winner down in the hierarchy so as make them dominated by the constraints violated by the loser.<br /><br />The authors justify their approach using simulation studies. They do this by applying the iterative learning algorithm to a system of metrical stress grammars. In the system they consider, the underlying form for an utterance can be inferred correctly from the overt form, and consists of the syllables of the latter without the stresses. The authors also include a discussion on the shortcomings of RIP/CD. They discuss three ways in which it can fail to converge to the correct ranking for a language. One of these involves selecting an interpretation that has no chance of being optimal under any total constraint ranking. Another considers a case where the optimal interpretation is harmonically bound by the currently optimal description. The constraint demotion can identify constraints but cannot determine what to demote them below. The last involves endless alternation between different overt forms. A grammar selected for one overt form always fails for some other overt form, and vice versa.sing/learning procedure discussed above. In the author's theory though the parsing step is `robust interpretive parsing', which gives the most harmonic structural description consistent with the overt data, given the current grammar, which is then followed by `constraint demotion' which gives a grammar that optimizes the structural description in the parsing step. For constraint demotion, the authors prove that for N constraints, no more than N(N-1) informative examples will be needed in order to determine the correct grammar.  <br /> <br /> In constraint demotion, the learner determines the grammaticality of a structural description with respect to competing candidates, which the authors believe is an advantage, in that these candidates must be dealt with. Positive evidence in the form of a grammatical structural description brings with it negative evidence of competing descriptions. A competing candidate and the grammatical structure will assist in the determination of the correct ranking, as the latter will make the grammatical structure more harmonic than the ungrammatical competitor. Given a collection of loser/winner pairs, the constraint demotion algorithm discovers a ranking that makes each winner more harmonic than its corresponding loser. The algorithm demotes the constraints violated by the winner down in the hierarchy so as make them dominated by the constraints violated by the loser.  <br /> <br />The authors justify their approach using simulation studies. They do this by applying the iterative learning algorithm to a system of metrical stress grammars. In the system they consider, the underlying form for an utterance can be inferred correctly from the overt form, and consists of the syllables of the latter without the stresses. The authors also include a discussion on the shortcomings of RIP/CD. They discuss three ways in which it can fail to converge to the correct ranking for a language. One of these involves selecting an interpretation that has nochance of being optimal under any total constraint ranking. Another considers a case where the optimal interpretation is harmonically bound by the currently optimal description. The constraint demotion can identify constraints but cannot determine what to demote them below. The last involves endless alternation between different overt forms. A grammar selected for one overt form always fails for some other overt form, and vice versa.	2004-12-20
422127:US	50702879	R3RN9RZBDCKNXW	0262692937	454680997	The Turing Test: Verbal Behavior as the Hallmark of Intelligence (MIT Press)	Books	3	8	18	N	Y	Pure philosophy	The Turing test is one of the most popular tests for judging whether a machine is intelligent, and is one that for many years was accepted uncritically. This has had both good and bad consequences for the field of artificial intelligence, but has certainly been good for the philosophical community. Debates on the Turing test have filled the philosophical literature, and continue to this day. Fortunately, many researchers in artificial intelligence have moved away from the assumption that the Turing test is a useful guideline for assessing machine intelligence. In the years ahead it may become merely an historical curiosity, possibly fading into insignificance because of the presence of (non-human) thinking machines brought about the very people who chose to ignore its validity or utility and got on with the actual construction of these kinds of machines.<br /><br /> This book gives a good overview of the history of the Turing test, includes three of the original papers of Turing, and also gives what the editor of the book calls \\"precursors\\" to the subject. As examples of the latter, he includes some writings of the philosopher Rene Descartes and Julien Mettrie. Many other papers are included, some of these written by well-known philosophers and researchers in artificial intelligence, and the editor includes commentary on some of these papers at various places in the book. Most, if not all, of the discussion in this book is purely philosophical, and therefore does not assist those who are genuinely interested in building intelligent machines. The book therefore will be useless to the collection of researchers engaged in the design and construction of intelligent machines. It will however be very interesting to philosophers, who are not troubled by the gigantic conceptual spaces that are constructed by the deliberations over the Turing test, and they will be able to find ample opportunity to indulge themselves in the proliferation of thought experiments and \\"impossibility proofs\\" that always accompany philosophical discussion of machine intelligence.sibility proofs\\" that always accompany philosophical discussion of machine intelligence.	2004-12-16
424052:US	50702879	R3GI3GREXPFQU2	1584502762	276464365	Grid Computing: Practical Guide To Technology & Applications (Programming Series)	Books	3	15	16	N	Y	Fairly good overview	The interest in grid computing has increased dramatically in scientific circles in the last decade, due in part to the need for high performance scientific computing and the availability of operating systems that make the deployment of distributed computing more painless for the scientific investigator. With the exception of financial firms, grid computing has not made inroads into the business community. Private industry has expressed concerns about the security of grid computing and various psychological barriers have prohibited it from being incorporated even in business LAN environments. This book gives a fairly comprehensive overview of grid computing for those interested in obtaining knowledge as to its efficacy in high performance computing or for those who are investigating whether it can indeed be practical for business. It is readily apparent that the author wants private industry to take grid computing more seriously, and he gives ample discussion of just how this could be done.<br /><br />Part of this discussion involves the relation between Web services and grid computing. Those readers who deal with Web services would expect a connection between grid computing and Web services, and the `Open Grid Services Architecture', spearheaded by IBM and the Globus team, is an attempt to unify the two. The author points out the main difference between the two architectures, namely that Web services support \\"persistent\\" services while grid architectures must also support \\"transient\\" services, such as video conferencing. Web services is in place in many different industries at the present time, but it remains to be seen whether it will remain so in years to come, due in part to the conflicts between the different standardization efforts.<br /><br />The different types of grids that can be configured are also discussed in the book. These include departmental grids, designed for a group of people within an enterprise, enterprise grids which cover all users within an enterprise, and extraprise grids, which can be established within companies. Grid computing has had some reported successes, particular the SETI grid project and the FOLD grid project for calculating protein folding. Both are popular with the public and have GUI interfaces that are very pleasing from an aesthetic point of view.<br /><br />One of the biggest reasons for not being able to do grid computing in a business environment is the reluctance of management to allow many or all of the machines in the organization to be dedicated to the grid, even if done when the machines are offline. This is true even for the `desktop' grids that are discussed in this book. Subjective factors, such as privacy issues (even if they are not valid) and imagined interference come into play when approaching grid computing in a professional business environment. The presence of distributed software on the various machines in the organization may cause many to believe it is the cause of an outage or other problems when they occur. Trust in grid computing has to develop before it will be used routinely in a business environment. The author does address these concerns in the book.<br /><br />He also discusses the need for an easier transition to grid computing in a business context, if the decision to deploy it has been made. The time taken to make grid computing a reality in this context must be minimal, considering the great amount of investment that has already been made in designing, implementing, and maintaining existing applications. Such a transition can be handled by using the approach of Web services, or what he calls Grid services. He outlines a few different ways in which the existing code can be wrapped. If the source code is not available, one can wrap the executables for example. If it is, it can wrapped and additional code overlaid on it in order to interface properly with any existing applications. A WSDL (Web Service Description Document) is then generated and placed in aregistry service, in order that other applications can make use of the service. The Universal Description, Discovery and Integration (UDDI) registry is the one that is advocated by the author.<br /><br />Several applications of grid computing are discussed in the book, each having various degrees of ease in actual deployment. Numerical applications using Monte Carlo are viewed as the easiest ones to be \\"grid-enabled\\", and this is born out in experience. Financial and biotechnology firms in particular are heavy users of grid-enabled applications that utilize Monte Carlo simulations. The author discusses a rudimentary test, called the `compute intensity ratio' to check whether an application is suitable for deploying on a grid. If this ratio is greater than one, then the application is deemed to be well suited for distributed processing on a grid. Applications in desktop grid computing such as risk management and financial derivatives, molecular docking for drug discovery, and architectural rendering are briefly discussed.<br /><br />As an example of a cluster grid, the famous Beowulf cluster, which is heavily used in scientific computing, is discussed in the book. Scientific computing is the major driver behind grid computing, as is readily apparent throughout the book. Discussion of high performance grid computing occupies an entire chapter of the book in fact. Production High Performance Computing via the use of the Message Passing Interface (MPI) has allowed scientists to develop grid applications more effectively, without having to worry too much about architectural issues.<br /><br />The author has included several examples of how grid computing is used in the business community, such as in telecommunications and bioinformatics. There are more examples than he discusses, but they are usually not made public because of considerations of propriety. Businesses that have used grid computing to further their success are usually not vocal in their approaches. The book would have been better if the author had included actual benchmarking studies of how businesses have improved their financial positions by using grid computing, with in-depth figures that illustrate quantitatively the power of grid computing. The inclusion of such studies would definitely assist those who are seriously considering grid computing.placed in a registry service, in order that other applications can make use of the service. The Universal Description, Discovery and Integration (UDDI) registry is the one that is advocated by the author.  <br /> <br />Several applications of grid computing are discussed in the book, each having various degrees of ease in actual deployment. Numerical applications using Monte Carlo are viewed as the easiest ones to be \\"grid-enabled\\", and this is born out in experience. Financial and biotechnology firms in particular are heavy users of grid-enabled applications that utilize Monte Carlo simulations. The author discusses a rudimentary test, called the `compute intensity ratio' to check whether an application is suitable for deploying on a grid. If this ratio is greater than one, then the application is deemed to be well suited for distributed processing on a grid. Applications in desktop grid computing such as risk management and financial derivatives, molecular docking for drug discovery, and architectural rendering are briefly discussed.  <br /> <br />As an example of a cluster grid, the famous Beowulf cluster, which is heavily used in scientific computing, is discussed in the book. Scientific computing is the major driver behind grid computing, as is readily apparent throughout the book. Discussion of high performance grid computing occupies an entire chapter of the book in fact. Production High Performance Computing via the use of the Message Passing Interface (MPI) has allowed scientists to develop grid applications more effectively, without having to worry too much about architectural issues.  <br /> <br />The author has included several examples of how grid computing is used in the business community, such as in telecommunications and bioinformatics. There are more examples than he discusses, but they are usually not made public because of considerations of propriety. Businesses that have used grid computing to further their success are usually not vocal in theirapproaches. The book would have been better if the author had included actual benchmarking studies of how businesses have improved their financial positions by using grid computing, with in-depth figures that illustrate quantitatively the power of grid computing. The inclusion of such studies would definitely assist those who are seriously considering grid computing.	2004-12-14
433222:US	50702879	R1MGU8VFJPWBH7	0060732466	553143722	The Surrender: An Erotic Memoir	Books	5	25	39	N	Y	A real jeans-stretcher.	Reading like a torrential sexual downpour, this book demands the reader's attention. It does not waste time in its major theme, that of the joys of anal sex from a woman's perspective. The language is both raw and poetic, but rarely shocking. Anal sex is not a rare activity with women anymore, even though most men have believed otherwise. Women are not always vocal about their needs and past sexual conquests.<br /><br /> The choreography of anal sex though is very limited, with possibly large deviations in time and positioning. The author made it happen 298 times with her illustrious phantom lover. Her keeping of statistics is admirable. The details of each encounter are with a few exceptions, omitted. It is the pain of the entry, the filling of her butt that gave her pleasure. Her excitement was localized in her anus, and not in her entire body. Not so with her former profession. Ballet requires every body part to be in play, and permits no departure from predefined configurations. But for the author, ballet prepared her for sodomy. For her, anal sex recreated the \\"physical extremism of dancing.\\" To follow the dictates of the choreographer served as preparation, as maybe lubrication for her eventual acceptance of the male tool in her anus. Ballet training requires that one ignore physical discomfort she says. One could say that she believes that it prepares a woman for the lifting of the derriere and the spreading of the legs.<br /><br /> The author's machinations in the book read more like modern dance, rather than ballet. Rebelling against ballet was its goal. Fatigued and irritated by the structure of classical ballet, the choreographers of modern dance negated its demands, and took full advantage of gravity. The writhing and wincing resulting from anal sex, because of its taboo, its rarity, and its ensuing pain, fits the need exactly for the out-of-equilibrium ethos of modern dance. One can defy convention with anal penetration. It is the realm of the daring, of those who with their backs towards the ceiling, turn their back on the past. New experiences though require frequent indulgences. Some call this addiction. Others call it learning. No propagation of the species results from anal copulation. This gives it further justification in the eyes of the sexual rebel. It is always fun to cheat nature.<br /><br /> For the heterosexual male, this book is to be read in a house with wide corridors. It might be difficult to turn corners after its perusal. The writing is terse but effective. When reading the book, beware of Levis and wear pajamas instead. This reviewer thought of only one thing after finishing the book: how nice it would be hear the thuds of the author's shoes hitting the floor beside his bed.ring, of those who with their backs towards the ceiling, turn their back on the past. New experiences though require frequent indulgences. Some call this addiction. Others call it learning. No propagation of the species results from anal copulation. This gives it further justification in the eyes of the sexual rebel. It is always fun to cheat nature.  <br /> <br /> For the heterosexual male, this book is to be read in a house with wide corridors. It might be difficult to turn corners after its perusal. The writing is terse but effective. When reading the book, beware of Levis and wear pajamas instead. This reviewer thought of only one thing after finishing the book: how nice it would be hear the thuds of the author's shoes hitting the floor beside his bed.	2004-12-06
441757:US	50702879	R3PV7NUTJC4DEF	1565848403	209925989	Dick: The Man Who Is President	Books	5	18	25	N	Y	A tale of a yellow abdomen: Part II	That the bumper stickers were configured improperly in election/2004 is the subject of this book. Indeed, \\"Cheney/Bush 2004\\", instead of \\"Bush/Cheney 2004\\", seems appropriate if one is to believe the words of its author. With many references and very well written, it is nevertheless a very painful book to read, for it is a story of how a \\"quiet American\\" manipulated his way to the top of the current administration, and now acts as its leader. It is a story of how a man (if one is to call him that) can avoid the draft and still become head of the most powerful military organization in the history of the world. It is a story of cowardice and betrayal, of immorality and power lust. It is a demonstration that a constitutional title is completely irrelevant in the real management of the American government.<br /><br /> But it could be said that the book is also a story of the millions of people who supported the Cheney/Bush ticket. They have much in common with Cheney, very much indeed. These sycophants for the current administration will absolutely hate this book. It does not reinforce their prejudices and will without doubt cause pronounced cognitive dissonance in their belief structures. By elementary logic, it follows that those who support the administration also support the war. But most of these individuals have never participated in one, and so their support is done from a position of comfort. Their living rooms and sofas are to be contrasted with the horror of conflict, which they have never experienced and will never experience.<br /><br />The vast majority of those that supported this administration in the recent election are indeed true followers of the Cheney/Bush ticket. It should not be believed that they are hypocrites. They are not deviating from their positions and are holding true to them:<br /><br />1. Like Bush and his boss Cheney (in the Vietnam debacle), they are refusing to put on a military uniform and participate in the current conflict in Iraq.<br /><br />2. Like Bush and his boss Cheney, they cheer on the troops, and engage in the same drum beating and jingoism, creating a facade of patriotism, but they have no intention of signing up for duty in Iraq.<br /><br />3. Like Bush and Cheney, their sons and daughters are not signing up for duty in Iraq, and they will not be feeling the pain of having lost loved ones in the current horror.<br /><br />Like Cheney, they have \\"other priorities.\\"in Iraq.  <br /> <br />2. Like Bush and his boss Cheney, they cheer on the troops, and engage in the same drum beating and jingoism, creating a facade of patriotism, but they have no intention of signing up for duty in Iraq.   <br /> <br />3. Like Bush and Cheney, their sons and daughters are not signing up for duty in Iraq, and they will not be feeling the pain of having lost loved ones in the current horror.  <br /> <br />Like Cheney, they have \\"other priorities.\\"	2004-11-29
445935:US	50702879	R1XVQ9WJJYPOYH	1555582826	692806760	Web Services: Theory and Practice	Books	3	4	5	N	Y	Fairly informative	This book is presented as a comprehensive guide to all aspects of Web services, and one that emphasizes the practical issues involved in its use. It is written for a reader who is relatively new to the subject, and therefore does not go into the minute details of it. The author expresses extreme confidence that Web services will continue to rise in importance and will even rescue the IT industry from its current slump. It certainly has had an impact in business applications, but only time will tell whether it will dominate this environment in years to come. Web services has certainly had its critics, who frequently accuse it of being overly hyped and for falsely raising expectations, as well as needing further developments in standardization before being deployed at a large scale. Indeed, the Web services standards process itself has shown signs of fragmentation, with organizations such as Liberty Alliance, Oasis, W3C, and WS-I all competing for the honor of presiding over the standardization process. In addition, vendors of Web services are already at odds with each other, some of these involving licensing and usage restrictions. This has taken place even though Web services are supposed to be a technology that is free to anyone.<br /><br /> Web services are defined in the book as `modular, self-contained application logic' that is developed according to a set of open standards, which the author takes to be the W3C (World Web Consortium). The other standardization efforts mentioned in the last paragraph are not therefore considered in this book. Extensible Markup Language (XML) is of course presented as the underlying basis for Web services. Web services are thus described as a `remote invocation mechanism' that is always realized using XML documents. The protocol for realizing this remote procedure call is called Simple Object Access Protocol (SOAP) and is basically an XML-based messaging system. The author describes how Web services began as a `program-to-program' solution rather than a `human-to-program' one, thus vitiating the need for it to be integrated into a GUI environment. This was changed just a few years ago, he explains, by the advent of Web Services for Remote Portals (WSRP), and a related specification called Web Services for Interactive Applications (WSIA), which expressed the need for a GUI environment in order to make the deployment of services within portals much easier.<br /><br /> After an overview of XML and WSDL in chapter 2, the author discusses Microsoft Web services in chapter 3. After a brief discussion of the history behind Microsoft's involvement in Web services, and the tension between IBM (Java) Web services and that of the .NET approach of Microsoft, the author moves on to a general discussion of the latter. Although there are more thorough treatments of .NET in the literature, the discussion is fairly informative. Performance issues are also briefly discussed in the context of Web services deployed on Windows servers.<br /><br /> The author spends an entire chapter on UDDI and one on SOAP, which give the reader ample information on these two `building blocks' for Web services. Also included is a chapter on Java and Web services, which because of the nature of Java to be `cross platform' seems like a natural language to use. The author though points out the difference in platform independence in Web services, namely that different Web services can run on different platforms, and platform independence with Java, which means that the same Web service can be ported to different platforms.<br /><br /> One area that could be very important in the future use and development of Web services, but is not mentioned in this book,  is artificial intelligence, such as current research efforts in the Semantic Web and research in intelligent agents in networks. The goal of the latter is to manage networks without the need of humans, or at least to make their use minimal. Researchers who work in this area haveexpressed skepticism as to the ability of WSDL, SOAP, and UDDI (Universal Description, Discovery, and Integration) to achieve complete automation and interoperability. These would have to be altered in order to support automated reasoning. The integration of intelligent agents with Web services is will allow the agents to reason about and coordinate services over the Web. Since this will typically involve working over domains or environments that are not known a priori by the agent. This will either entail that the agents adapt to these novel environments or that the Web services themselves change so as to not be as immutable as they currently are. Whatever the case may be, the connection of artificial intelligence with Web services is one that is being currently explored and may prove to be very fruitful for both fields.is area have expressed skepticism as to the ability of WSDL, SOAP, and UDDI (Universal Description, Discovery, and Integration) to achieve complete automation and interoperability. These would have to be altered in order to support automated reasoning. The integration of intelligent agents with Web services is will allow the agents to reason about and coordinate services over the Web. Since this will typically involve working over domains or environments that are not known a priori by the agent. This will either entail that the agents adapt to these novel environments or that the Web services themselves change so as to not be as immutable as they currently are. Whatever the case may be, the connection of artificial intelligence with Web services is one that is being currently explored and may prove to be very fruitful for both fields.	2004-11-24
449505:US	50702879	R1MELLEACNIC1B	0684862697	215865364	The FUTURE AND ITS ENEMIES: The Growing Conflict Over Creativity, Enterprise, and Progress	Books	5	4	10	N	Y	A brilliant apology	Change causes anxiety in some, and so rapid change is for them absolutely terrifying. The author though is a self-professed \\"dynamist\\", and embraces change with a passion. Dynamism, as she defines it, is a world of constant creation, discovery, and competition. It shuns stability and control in favor of evolution and learning. With this book she has written a brilliant polemic that tackles the opponents of change straight on, but she does so with a spirit of calmness and rationality that is quite uncommon in many books of late. Her optimism and keen intelligence are quite refreshing, and much can be learned from a perusal of this book. \\"Life is full of surprises\\", she says, and this motivates her to argue for and embrace the future, a future that will be brought about by inquisitive individuals who are confident of their abilities and not afraid to experiment. For these individuals, to be still is an anathema, but to be out of equilibrium is sheer delight. Change for them is a breath of fresh air and stasis is always stale. To hold to the past is an abomination, to sprint into the future is pure exhilaration. To create new ideas, to build new inventions, to put into concrete form the abstractions of the mind, these signify the creed of the dynamists. Anchorites for science and technology, they are constantly looking forward, never back.	2004-11-21
452955:US	50702879	RAG6X9EQ5TM8J	0521644976	482051825	Photosynthesis (Studies in Biology)	Books	5	5	5	N	Y	Excellent	Of extreme importance for all life on this planet, photosynthesis is one of the most widely studied topics in the physiology of plants. This book gives a fine overview of the subject and is suitable for readers who have some background in botany. It could though be read profitably by anyone, from those students intending to specialize in botany, as well as those who are curious as to the workings of photosynthesis. With serious discussion and research now being done in bringing about \\"artificial\\" photosynthesis, anyone interested in these kinds of developments will need to first have a solid grounding in the mechanisms behind photosynthesis in plants.<br /><br /> The authors are selective in what topics are covered in detail, but by far the most interesting part of the book is chapter 8, which overviews some of the latest research in photosynthesis (they don't discuss any of the research in artificial synthesis though). One of the first topics discussed is the research that indicates that PSII might alone be able to initiate electron transfer from water to NADP and carbon dioxide fixation, this taking place in a mutant version of the green alga Chlamydomonas reinhardtii. The authors are careful to point out that the complete absence of PSI in this system has not been established.<br /><br /> Still another interesting topic in this chapter concerns the determination of how chloroplasts develop via colorless organelles called `etioplasts'. The authors unfortunately do not spend too much time on this topic, but it is an excellent example of light-induced control of the transcription of genes, these genes encoding the proteins that control the transition from etioplast to chloroplast. This is followed by a somewhat more detailed discussion of chloroplast genetics, with the genetic map of the rice chloroplast given as an example. Mentioned also is the work currently done in the genetic engineering of the chloroplast, with the example of the green alga, which has been engineered to be deficient in PSII, PSI, ATP synthase, etc. The genetic engineering of the chloroplast shows some promise in alleviating the concerns of some who point to dangers in the development of transgenic plants, the latter topic of which is also discussed in this chapter. Instead of inserting transgenes into a plant genome, they are inserted into the genome of the chloroplast. Some researchers have claimed that such an approach will not be subject to the `gene silencing' problem that would make the resulting transgene expression unstable. Other researchers though have remained skeptical, and have pointed to other gene silencing mechanisms that might in be even more prevalent in the genetic engineering of the chloroplast. Either way these issues need more investigation, both from the standpoint of scientific curiosity and from an environmental one.een engineered to be deficient in PSII, PSI, ATP synthase, etc. The genetic engineering of the chloroplast shows some promise in alleviating the concerns of some who point to dangers in the development of transgenic plants, the latter topic of which is also discussed in this chapter. Instead of inserting transgenes into a plant genome, they are inserted into the genome of the chloroplast. Some researchers have claimed that such an approach will not be subject to the `gene silencing' problem that would make the resulting transgene expression unstable. Other researchers though have remained skeptical, and have pointed to other gene silencing mechanisms that might in be even more prevalent in the genetic engineering of the chloroplast. Either way these issues need more investigation, both from the standpoint of scientific curiosity and from an environmental one.	2004-11-17
458309:US	50702879	RRFQYRSHIKKVO	0670894737	141542110	The Great Influenza: The Epic Story of the Deadliest Plague in History	Books	5	6	6	N	Y	Fascinating and inspirational	The virus: it is always a source of amazement that an entity so small and so simple could wreck such havoc to human populations. This book details the history of the deadliest viral outbreak in recorded human history. Contributing to the deaths of probably as many as 100, 000, 000 people worldwide, and just over the span of a couple of years, this story of the 1918 influenza virus is a chilling one, but also a story of human and scientific triumph. Reading the pages of this book instills fear as well as inspiration, and it serves as a good apology for current efforts to understand and engineer viruses, in order to soften or even eliminate their threat to all life forms on this planet.<br /><br />This book does not merely discuss the calamity caused by the influenza virus. It also gives an overview of the state of medical science as it was before the virus struck. For anyone (such as this reviewer) not familiar with the history of academic institutions in the United States, especially medical institutions, the author offers a view of it that is actually quite surprising when judged from contemporary standards. The United States currently has the best medical institutions in the world, but as the author shows, this was not the case one hundred years ago. Indeed, the picture of the U.S. university towards the end of the nineteenth is one that was oriented to liberal arts and religious/theological studies. Medicine and science in general were not very well represented in the university, but a perusal of the universities of Europe motivated some to replicate their success in America, with Johns Hopkins being the ultimate example. Even Harvard University, the author points out, would grant a medical degree to anyone who could pass five out of nine courses. He quotes an American student, who, like most others of the time had to go to Europe to get a quality education in medicine, described the state of medical education in the United States as \\"simply horrible.\\"<br /><br /> The contributions and life of William Henry Welch, one of the major players of medical science at the time, founder of the Johns Hopkins medical school, and one of the first proponents in the United States of the germ theory of disease, are discussed in great detail in the book. One can only view his life with admiration, not only for instigating the correct path for medical research in the United States, but also for his dedication to his goal, which early on, required him to live a somewhat Spartan existence. The lives and contributions of other members in the great cadre of medical science of the time, such as Simon Flexner, Oswald T. Avery, William Park, Anna Wessel Williams, Rufus Cole, Paul A. Lewis, and Richard Shope, are given ample treatment in the book, stirring the reader to a quiet envy of their dedication and accomplishments. Their impact to medical science and molecular biology is still being felt, both in terms of their strategies in tackling scientific problems and the restlessness they exhibited in finding the answer.<br /><br /> With the tools of molecular biology and powerful computing machines, knowledge of viruses has swelled dramatically from what it was in 1918. Interest in the 1918 influenza virus has not subsided, and in fact just in the past few weeks there have been efforts by some researchers to study the virus by taking fragments from the (exhumed) victims of the pandemic. Five of the eight genes of the virus have been sequenced, and some researchers have added some of these genes to modern flu viruses, in order to recreate the 1918 virus. Naturally issues of containment have arisen, and they should be, but a study of the 1918 virus is necessary in order to find ways to combat possibly even more virulent viruses. The genetic engineering of viruses, both dangerous and benign is important work that should be done by those individuals who have proven themselves responsible in carrying it out. This book gives ample evidence that an understanding of viruses is of extreme importance to the future of humankind.an understanding of viruses is of extreme importance to the future of humankind.  <br /> <br />	2004-11-12
465809:US	50702879	R1RE3FEZH1LU56	0262193981	686996455	Reinforcement Learning: An Introduction (Adaptive Computation and Machine Learning)	Books	5	19	23	N	Y	An excellent introduction	As a subfield of artificial intelligence, reinforcement learning has shown great success from both a theoretical and practical viewpoint. Taking the form of numerous applications in finance, network engineering, robot toys, and games, it is clear that his learning paradigm shows even greater promise for future developments. The authors summarize the foundations of reinforcement learning, some of this coming from their own work over the last decade.<br /><br />The authors define reinforcement learning as learning how to map situations to actions so as to maximize a numerical reward. The machine that is indulging in reinforcement learning discovers on its own which actions will optimize the reward by trying out these actions. It is the ability of such a machine to learn from experience that distinguishes it from one that is indulging in supervised learning, for in the latter examples are needed to guide the machine to the proper concept or knowledge. The authors emphasize the \\"exploration-exploitation\\" tradeoffs that reinforcement-learning machines have to deal with as they interact with the environment.<br /><br />For the authors, a reinforcement learning system consists of a `policy', a `reward function', a `value function', and a `model' of the environment. A policy is a mapping from the states of the environment that are perceived by the machine to the actions that are to be taken by the machine when in those states. The reward function maps each perceived state of the environment to a number (the reward). A value function specifies what is the good for the machine over the long run. A model, as the name implies, is a representation of the behavior of the environment. The authors emphasize that all of the reinforcement learning methods that are discussed in the book are concerned with the estimation of value functions, but they point out that other techniques are available for solving reinforcement learning problems, such as genetic algorithms and simulated annealing.<br /><br />The authors use dynamic programming, Monte Carlo simulation, and temporal-difference learning to solve the reinforcement learning problem, but they emphasize that each of these methods will not give a free-lunch. An entire chapter is devoted to each of these methods however, giving the reader a good overview of the weaknesses and strengths of each of these approaches. The differences between them usual boil down to issues of performance rather than accuracy in the generated solutions. Temporal difference learning in fact is viewed in the book as a combination of Monte Carlo and dynamic programming techniques, and in the opinion of this reviewer, has resulted in some of the most impressive successes for applications based on reinforcement learning. One of these is TD-Gammon, developed to play backgammon, and which is also discussed in the book.<br /><br />The authors emphasize that these three main strategies for solving reinforcement learning problems are not mutually exclusive. Instead each of them could be used simultaneously with the others, and they devote a few chapters in the book illustrating how this \\"unified\\" approach can be advantageous for reinforcement learning problems. They do this by using explicit algorithms and not just philosophical discussion. These discussions are very interesting and illustrate beautifully the idea that there is no \\"free lunch\\" in any of the different algorithms involved in reinforcement learning.<br /><br />In the last chapter of the book the authors overview some of the more successful applications of reinforcement learning, one of them already mentioned. Another one discussed is the `acrobot', which is a two-link, underactuated robot, which models to some extent the motion of a gymnast on a high bar. The motion of the acrobot is to be controlled by swinging its tip above the first joint, with appropriate rewards given until this goal is reached. The authors use the `Sarsa' learning algorithm, developed earlierin the book, for solving this reinforcement learning problem. The acrobot is an example of the current intense interest in machine learning of physical motion and intelligent control theory.<br /><br />Another example discussed in this chapter deals with the problem of elevator dispatching, which the authors include as an example of a problem that cannot be dealt with efficiently by dynamic programming. This problem is studied with Q-learning and via the use of a neural network trained by back propagation.<br /><br />The authors also treat a problem of great importance in the cellular phone industry, namely that of dynamic channel allocation. This problem is formulated as a semi-Markov decision problem, and reinforcement learning techniques were used to minimize the probability of blocking a call. Reinforcement learning has become very important in the communications industry of late, as well as in queuing networks.ithm, developed earlier in the book, for solving this reinforcement learning problem. The acrobot is an example of the current intense interest in machine learning of physical motion and intelligent control theory.  <br /> <br />Another example discussed in this chapter deals with the problem of elevator dispatching, which the authors include as an example of a problem that cannot be dealt with efficiently by dynamic programming. This problem is studied with Q-learning and via the use of a neural network trained by back propagation.  <br /> <br />The authors also treat a problem of great importance in the cellular phone industry, namely that of dynamic channel allocation. This problem is formulated as a semi-Markov decision problem, and reinforcement learning techniques were used to minimize the probability of blocking a call. Reinforcement learning has become very important in the communications industry of late, as well as in queuing networks.	2004-11-05
472703:US	50702879	R2XLZF4ZPZI4Y0	1932594043	332719909	Neuroscience and the Law	Books	5	19	20	N	Y	Fascinating discussions	The twenty-first century will see breathtaking advances in genetics, artificial intelligence, physics, mathematics, and neuroscience. In fact, there is not one field of science or technology that will not significant strides in this century, this being due not only to the increasing number of scientists but also to the amount of cross-fertilization between fields. Contemplating and witnessing these developments is exhilarating, and being alive in this century is every technophile's dream. All change however brings dangers as well as delights, and it always has legal and political ramifications.<br /><br /> Genetic engineering in particular has caused a lot of concern in the world citizenry, and has even become a major issue in the current presidential campaign. Many are terrified by the prospects of genetic engineering to be sure, but others believe that its dangers pale in comparison to those arising from current developments in neuroscience. A recent article in a major business journal spoke of neuroscience as being a field that will threaten privacy, end autonomy and the concept of human nature, and result in the homogenization of society. The article further asserts that neuroscientists will soon be able to screen an individual's brain in order to assess mental health, or be able to repair faulty personality traits using drugs or microchip implants.<br /><br /> If these developments reach fruition, the legal profession will find itself having to deal with them, like it has with genetics and other scientific developments in the last one hundred years. This book gives an excellent introduction to how the legal community is confronting them, and can be read by anyone curious about the issues at stake, as a background in neuroscience or law is not necessary for its perusal. The book is a collection of articles written by experts in law and neuroscience, but the authors of these articles keep the terminology and concepts at a reasonable level. In addition, philosophical speculation is kept at a manageable level.<br /><br /> In Part 1 of the book, Brent Garland gives a general overview of the main legal issues that have already arisen due to the advances in neuroscience. Garland's first goal is to answer to what extent neuroscience will actually impact the law. He expresses confidence that legal institutions will be able to handle any kind of scientific developments, without any major disruptions to its fundamental structure. In addition, he points to the need for a framework for addressing issues in neuroscience in relation to the law. He settles on one that separates the experimental techniques for monitoring and imaging the brain from its actual manipulations and the modalities for its enhancement. Many interesting issues are discussed by Garland, particularly on the concept of free will, which some believe will be obliterated by neuroscience. Garland however believes this will not be the case, and he offers reasons for holding to this opinion.<br /><br /> The issue of free will in twenty-first century neuroscience is brought up again in Part 2, which is a collection of commissioned articles for the book. The first article by Michael Gazzaniga and Megan Steven addresses briefly the philosophical arguments for free will and then moves on to the fascinating experiments of Benjamin Liber, which shed light on the extent to which brain activity precedes conscious experience. If these experiments indeed show that that brain is able to make decisions before we are aware of them, then this has ramifications to the culpability of criminals when carrying out heinous acts. Gazzaniga and Steven however present arguments that hold that this is not the case, that indeed it is possible to have free will in a deterministic system. Their arguments are more philosophical than scientific, and they conclude that neuroscience can say little about human responsibility. For them, the concept of responsibility is one that arises only as a rule in human society. It does not exist, they say, in the neuronal structure of the brain.<br /><br /> The article by Laurence Tancredi is more pro-scientific than the others in the book. He asserts, rightfully so, that imaging technologies such as PET, SPECT, and fMRI have laid to rest the mind-body problem that has occupied the time of many philosophers for centuries now. He is more pessimistic on the ability of the legal community to keep up with the advances in neuroscience however. He addresses four issues that he believes will challenge legal institutions in the upcoming years: brain death; cognition as it applies to competency in civil matters; cognitive enhancement, and neuroscientific measures for personal veracity. The advent of brain/machine interfaces and the possibility of downloading a person's thoughts into a machine will entail a new definition of brain death, he asserts. Although such a scenario seems implausible at present, so was the idea of brain/machine interfaces not too long ago. Tancredi's discussion of cognitive enhancement is fascinating since he addresses what is currently possible and what might soon be possible in this area (and many references are given).<br /><br /> Henry Greeley's article addresses the legal ramifications of advances in neuroscience in the areas of prediction, litigation, confidentiality and privacy, and patents. He is careful to point out that he believes that the technologies of neuroscience will have more benefit than harm, but that predicting their influence is done only with great difficulty. The author is very thorough in his discussion, and brings up many examples of compelling interest, such as statutory authorization of \\"mental searches\\", legalized or enforced \\"mental intrusions\\", and most interestingly, the possibility of owning a patent on thought patterns.<br /><br /> The article by Stephen Morse discusses the legal concepts that will need to be constructed due to the advances in neuroscience, which he believes has not been done yet. The discussion is therefore more philosophical in nature, and emphasizes the legal concept of personhood. The possibility of free will again takes center stage in this discussion, and Morse clearly believes that only future developments in neuroscience may offer a direct challenge to personhood and responsibility. No threat arises to our social and legal institutions at the present time.a rule in human society. It does not exist, they say, in the neuronal structure of the brain.  <br /> <br /> The article by Laurence Tancredi is more pro-scientific than the others in the book. He asserts, rightfully so, that imaging technologies such as PET, SPECT, and fMRI have laid to rest the mind-body problem that has occupied the time of many philosophers for centuries now. He is more pessimistic on the ability of the legal community to keep up with the advances in neuroscience however. He addresses four issues that he believes will challenge legal institutions in the upcoming years: brain death; cognition as it applies to competency in civil matters; cognitive enhancement, and neuroscientific measures for personal veracity. The advent of brain/machine interfaces and the possibility of downloading a person's thoughts into a machine will entail a new definition of brain death, he asserts. Although such a scenario seems implausible at present, so was the idea of brain/machine interfaces not too long ago. Tancredi's discussion of cognitive enhancement is fascinating since he addresses what is currently possible and what might soon be possible in this area (and many references are given).  <br /> <br /> Henry Greeley's article addresses the legal ramifications of advances in neuroscience in the areas of prediction, litigation, confidentiality and privacy, and patents. He is careful to point out that he believes that the technologies of neuroscience will have more benefit than harm, but that predicting their influence is done only with great difficulty. The author is very thorough in his discussion, and brings up many examples of compelling interest, such as statutory authorization of \\"mental searches\\", legalized or enforced \\"mental intrusions\\", and most interestingly, the possibility of owning a patent on thought patterns.  <br /> <br /> The article by Stephen Morse discusses the legal concepts that will need to be constructed due to the advances in neuroscience,which he believes has not been done yet. The discussion is therefore more philosophical in nature, and emphasizes the legal concept of personhood. The possibility of free will again takes center stage in this discussion, and Morse clearly believes that only future developments in neuroscience may offer a direct challenge to personhood and responsibility. No threat arises to our social and legal institutions at the present time.  <br />	2004-10-30
480823:US	50702879	RHLW0IGYI92H8	1565849205	347310569	With God On Their Side: How Christian Fundamentalists Trampled Science, Policy, And Democracy In George W. Bush's White House	Books	3	11	31	N	Y	Adequate as a warning against dangerous influences	Is the Bush administration packed with \\"fundamentalist\\" Christians whose goal is to bring the United States closer to a theocracy, or is it instead packed with Christian reactionaries who are fed up with \\"liberal\\" points of view, the latter of which have been well-funded by the United States government for the last four decades? If the former is true, this is a very dangerous development that must be countered by anyone interested in freedom of thought and inquiry. But if the latter holds, then the complaints of these reactionaries justify some legitimate sympathy. After all, their tax dollars are spent funding abortion and other activities or concepts that they do not agree with, such as the theory of evolution. Their presence in government is more to counter the trend, as they see it, to use government funding that is opposed to their chosen moral concepts. Therefore, they are deliberately seeking federal funds to enhance what they understand to be activities or doctrines that would enhance the well-being of society.<br /><br /> Since the intentions of these individuals are unknown, it remains an open question as to whether the above alternatives, or others, are really true of them. From the reading of this book, it is fair to say that the author of this book is arguing, using mostly anecdotal evidence, that the first alternative holds. She gives many examples that seem to support this position, but she frequently is unable to refrain from the vituperation that is characteristic of political pamphlets and books of late. Contentious issues like religion and its relation to government frequently generate dialog that would be totally unacceptable in rigorous, scientific discussion. Unfortunately the author has chosen to depart from sound analysis at various places in the book.<br /><br /> The book though is interesting to read, and will provoke readers to investigate the claims further. It would take many weeks, even months, to verify the assertions made in the book, but she does give many references for the dedicated reader who desires to dig deeper. Again, an organized movement to morph America into an oppressive theocracy must be countered very aggressively. One can therefore view the book as a warning, as a book that projects a possible future that is extremely dangerous. The examples, events, and pronouncements from public figures that the author includes serve as siren calls, however loosely the correlation between these events may be.<br /><br />But again, one can bring oneself to have some empathy with the Christian fundamentalists. With their worldview challenged by science, with the concept of the soul being superseded by results from neuroscience, with the age of the Earth being overwhelmingly at odds with their claims, they are struggling to keep their heads above the waters of knowledge. It is no surprise that they are acting as they do, with their zealous attempts to prove `intelligent design' and with their peculiar views of medical science, they are attempting to be scientific, forgetting that the methodologies of science do not permit the leaps of faith that they profess. You cannot go halfway with scientific research. Their attempts to do so are immediately exposed. The science of the twenty-first century will end whatever remnants of the Christian worldview are left as of now. The fundamentalist Christians no doubt see this, even though many do not want to admit it to themselves, and are making one desperate last stand.give many references for the dedicated reader who desires to dig deeper. Again, an organized movement to morph America into an oppressive theocracy must be countered very aggressively. One can therefore view the book as a warning, as a book that projects a possible future that is extremely dangerous. The examples, events, and pronouncements from public figures that the author includes serve as siren calls, however loosely the correlation between these events may be.     But again, one can bring oneself to have some empathy with the Christian fundamentalists. With their worldview challenged by science, with the concept of the soul being superseded by results from neuroscience, with the age of the Earth being overwhelmingly at odds with their claims, they are struggling to keep their heads above the waters of knowledge. It is no surprise that they are acting as they do, with their zealous attempts to prove `intelligent design' and with their peculiar views of medical science, they are attempting to be scientific, forgetting that the methodologies of science do not permit the leaps of faith that they profess. You cannot go halfway with scientific research. Their attempts to do so are immediately exposed. The science of the twenty-first century will end whatever remnants of the Christian worldview are left as of now. The fundamentalist Christians no doubt see this, even though many do not want to admit it to themselves, and are making one desperate last stand.	2004-10-23
482271:US	50702879	R1ZBBKEYZAY083	1590593227	567349076	The Definitive Guide to Linux Network Programming (Expert's Voice)	Books	3	6	11	N	N	An adequate introduction to the subject	This book gives a good general overview of network programming for the Linux operating system along with the C source code used for the implementation. Therefore, individuals who prefer to do network programming in PERL will have to find another book. It is written for the beginner to network programming, but could serve as a general reference for more seasoned network programmers. Due to the straightforward way in which the authors explain the ideas, the book can be rapidly assimilated by those readers who are pressed for time and need to get to the frontiers of the subject with little delay. I only read the first 7 chapters of the book, and so this review will be confined to these.<br /><br />In chapter 1, the authors give an elementary and general overview of networks. All of the discussion is very easy to understand, and should be helpful for newcomers. In particular, the idea of a port is sometimes a source of confusion for those who are new to networking, sometimes viewing them as being hardware interfaces on network devices. They are rather virtual destinations, and allow a standardization of just what kind of network traffic can be passed to and from a node.<br /><br /> Chapter 2 is an introduction to socket functions, a `socket' being explained as an abstraction for network communication. The Linux operating system uses the Berkeley socket interface (over TCP/IP), and the basic network I/O functions and the notion of a `socket descriptor' are explained in detail. A client/server configuration is used to illustrate the function calls utilized in sockets. Address data structures, such as `sockaddr_in', `linger', and `servent', are discussed. The authors also address the need for specifying the network byte order, so as not have to deal with issues of just how numbers are represented on a particular machine. Code is given for a simple application consisting of a string transfer from server to client.<br /><br /> In chapter 3, the authors concentrate on how to transfer files between a client and server but over the (connectionless) UDP protocol using `datagram sockets.' The discussion clearly points out the differences between TCP/IP and UDP in client/server network communications when doing file transfer. A very brief discussion is given for error handling.<br /><br /> The authors go into more of the details of protocol architectures and methods. An important part of this discussion is the difference between `stateful' servers, which maintain information about the current connections with its clients, and `stateless' servers that do not. A fairly thorough discussion is given on the different methods for maintaining state in a server, using the concept of `sessions'. The role of the HTTP protocol in maintaining a session in a stateless server is outlined, along with the role of `session IDs' for this purpose. The authors also discuss how to maintain state on the client side, using cookies, hidden form variables, and URL parameters.<br /><br /> The next part of the book deals with design issues and decisions and how to develop network programs that function in the client-server environment. Explicit programs are given that illustrate multiplexing, forking, and preforking, the latter of which will alleviate somewhat the costs associated with creating child processes during the initialization of the application. The authors also discuss multithreading, and its advantages in performance versus its disadvantages in stability (due to its use of shared memory). They also give the usual cautions in the use of multithreading, such as the need for mutexes when using global variables shared among threads, and when dealing with servers that must maintain a large number of persistent connections. For readers in the scientific community, a very useful section on how to deal with large amounts of data using nonblocking sockets is given.<br /><br /> Only a cursory discussion is given of \\"thick\\" and \\"thin\\" clients in this part, probably since the book is about Linux-based network programming. In non-Linux environments, thin-client architectures have become very important in recent years. The authors do discuss issues from both the client-side and the server-side, such as the differences between `monolithic' and `modular' clients, and the use of daemons on network servers. The advantages for using `privilege dropping\\" are also outlined, this being used in Web server programming for binding ports, and in giving an application superuser status.his part, probably since the book is about Linux-based network programming. In non-Linux environments, thin-client architectures have become very important in recent years. The authors do discuss issues from both the client-side and the server-side, such as the differences between `monolithic' and `modular' clients, and the use of daemons on network servers. The advantages for using `privilege dropping\\" are also outlined, this being used in Web server programming for binding ports, and in giving an application superuser status.	2004-10-21
483662:US	50702879	R1K7QQUQR5O6P1	B0000DK3W8	681039726	Taliban: Militant Islam, Oil and Fundamentalism in Central Asia	Books	5	2	3	N	Y	A tragic story of failed leadership	Since the 9/11 terrorist attacks, a new field of study, which jokingly could be called \\"Talibanology\\" has arisen. The events of 9/11 evidently made many wonder as to the nature of the individuals behind such incredibly evil acts. From the sales figures, books on Islamic history and the Koran apparently skyrocketed after 9/11, due to the need for such understanding. This book however was published before 9/11 (in 2000 to be exact), and therefore gives a perspective on the Taliban that omits the hyperbolae that frequently accompanies more recent studies. There are many surprises in the book for those readers, such as this reviewer, who are not acquainted with the history and beliefs of the Taliban, and who need a study that is unfiltered by the biases of the Western press.<br /><br />As the author explains, the word \\"talib\\" stands for \\"student of Islam\\", with \\"taliban\\" being the plural. A talib is one who is seeking knowledge, and is to be distinguished from a \\"mullah\\" who is a teacher. Apparently the Taliban chose to call themselves by that name in order to separate themselves from the Mujaheddin, and who wanted to \\"cleanse society\\" instead of engaging in a power struggle. Their ideal society was to be modeled after that of the Prophet Mohammed, and this was to be done using strict adherence to Islamic guidelines as put forth in the Koran. One can't help but ponder the fate of the Taliban if they would have relaxed their standards and attempted to have some intersection with other belief systems. Perhaps such pragmatism would have won them greater respect from the international community and prevented their antagonism with the United States.<br /><br />The reader learns of Pakistan and Saudi Arabia being the principal suppliers of funding, weapons, and fuel to the Taliban in the 1990's. Considering they are now American \\"allies\\", this is interesting, and it shows just how fast governments can turn on each other. One also learns that the Taliban were Sunni Muslims, instead of Shia Muslims, the latter identification being incorrectly reported by the Western press. The Sunni Muslims despise the Shias, and vice versa, but it seems that the objects of hatred by the Taliban went beyond factional differences in the Islamic religion, for the Taliban, as one also learns in the book, forced Hindus residing in Afghanistan to wear yellow badges for purposes of identification.<br /><br />The suffering of the people of Afghanistan in the last twenty-five years was not due solely to the Soviet invasion but also to other foreign meddling in its affairs. It was the demand by the international community to end the cultivation of poppy that exacerbated the economic crisis during the civil wars in Afghanistan. The opium trade apparently is going on full steam currently though, annoying many in the American government but apparently encouraged by the CIA in the early years of the Taliban government.<br /><br />Western and non-Western interest in Afghanistan did not just happen after 9/11 however. As the author documents with crystal clarity, energy interests were the primary motivation for so many countries having their eyes fixated on Afghanistan for so many years. The author discusses the competition between Unocal, an American energy conglomerate, and Bridas, an oil company based in Argentina, to build a gas pipeline across Afghanistan. He is very candid in his discussion of how economic interests were behind most of the major conflicts in this region, which is refreshing considering that such interests are usually masked under the guise of some moral or higher purpose. This is especially true for the current war in Iraq waged by the United States and Great Britain, and to a lesser extent Italy and Australia, which is being sold as part of a general \\"war on terror\\".<br /><br />The story of the Taliban is of course a tragic one, since in retrospect they could have been more constructive in their dealings with the international community. They were certainly a tenacious group though, and the reader learns from the author that the Taliban leadership, due to the many conflicts they engaged in, were the \\"most disabled\\" in the world. With justification, one can easily blame religion for their demise, as it has caused more suffering throughout human history than any other system of beliefs. Hopefully the Afghan people, with their new government, however illegitimate it might be, will see the errors of the Taliban and approach life with a more reasoned and healthy attitude; one that is free of religious dogmatism and open to alternative ideas and viewpoints.unity. They were certainly a tenacious group though, and the reader learns from the author that the Taliban leadership, due to the many conflicts they engaged in, were the \\"most disabled\\" in the world. With justification, one can easily blame religion for their demise, as it has caused more suffering throughout human history than any other system of beliefs. Hopefully the Afghan people, with their new government, however illegitimate it might be, will see the errors of the Taliban and approach life with a more reasoned and healthy attitude; one that is free of religious dogmatism and open to alternative ideas and viewpoints.	2004-10-20
487630:US	50702879	R3DAM2KPZQE8UO	0123392519	324397425	Invitation to the Mathematics of Fermat-Wiles	Books	5	21	23	N	Y	An excellent introduction	Modulo some sections that require more mathematical maturity, this book gives a straightforward introduction to the mathematics behind Fermat's Last Theorem that is accessible to the first or second year graduate student in mathematics. This is due not only to the excellence of the presentation, but also the many problems at the end of each chapter, making this book qualify more as a textbook than a monograph. Its perusal will give the reader an appreciation of the role of elliptic curves in the proof of Fermat's Last Theorem. Readers familiar with the applications of elliptic curves will find another impressive one in this context. It is a sizeable book filled with many definitions and theorems, so only a few features that make the book stand out will be mentioned.<br /><br /> The first of these is the chapter on elliptic curves, which the author keeps at a level that does not presuppose a heavy background in algebraic geometry. Instead, he develops them using an approach that one might find in elementary analytic or projective geometry. Mathematical rigor however is not sacrificed, and the author does not hesitate to use diagrams when appropriate. Readers therefore will find the presentation fairly easy to follow, and will not be stymied by the complicated constructions that can easily accompany discussions on elliptic curves in the context of Fermat's Last Theorem. The necessary algebra, such as Galois theory, is given in another chapter.<br /><br />There are two \\"million-dollar\\" problems mentioned in this book, such as the Riemann hypothesis and the Birch-Swinnerton-Dyer conjecture. The Riemann hypothesis arises in the discussion of zeta functions for elliptic curves. In this context, the author characterizes the zeta function in a way that makes its role in number theory very transparent, namely in the role it plays for expressing an integer as a product of primes, and the fact that it can be associated with the valuations of non-zero ideals in the integers. Groups that are \\"simpler\\" than the integers, such as the p-adic integers, also have zeta functions and similar product representations. The need for zeta functions in the book comes in the context of elliptic curves E over the rational numbers Q. The fields \\"simpler\\" than Q are the finite fields F[p] modulo a prime p also result in a representation of the zeta functions as a product, but now the product is taken over the prime ideals of quadratic extensions of the polynomial ring F[p;X] generated by an elliptic curve over F[p]. By quoting, but not proving the Artin representation of the zeta function for E, the author uses this to motivate the `L-function' for E. The Birch-Swinnerton-Dyer conjecture comes in when considering the Mordell-Weil group of E, and asserts that the rank of this group is equal to the order of the zero of the L-function at 1.<br /><br />In the very last section of the book, the author discusses some new areas and concepts in mathematics that were generated by the solution of Fermat's last theorem. One of these concerns a new definition of the ring of p-adic integers, and arises when considering the reduction of an elliptic curve modulo a prime number. For p = 3 or 5, showing that the impossibility of the case of Fermat's theorem for these values of the exponent must be done by the considering, not the congruence modulo p, but the congruence module p^2. The same holds for p = 7, where no h-th power of p will give the result modulo p^h. The author therefore considers infinite powers of p, which brings in the notion of a `projective limit.' Infinite products of the integers modulo prime powers, taken with the Tychonoff topology, gives a local ring on which one can define a p-adic valuation. The author then considers the fraction field of this ring, which is locally compact under the p-adic distance, is the completion of the rational numbers under the p-adic distance, and is isomorphic to the field of p-adic numbers.<br /><br />The author then generalizes this construction by starting with an elliptic curve E over a field K, and for a prime number not equal to the characteristic L of K, he shows how to construct the `Tate module' T(E;L) of E at L. Taking projective limits in this case shows that T(E; L) is a free Z(L)-module of rank 2. For the Galois group G of the algebraic closure of K, the Tate module is also shown to be a G-module over Z(L). Given a prime number p, the Tate module T(E; L) allows one to do arithmetic just as easily, or just as hard, as one does arithmetic in a finite field F[L], if one views the arithmetic in the context of an elliptic curve over Q (one is thus justified in setting L = p). The elliptic curve and the Tate module allow one to know just how many points are in the reduced elliptic curve E in F[p], this following from an understanding of the representations of the Galois group for a fixed L (these representations are related to each other, and thus serves to make the prime arithmetic more manageable). This line of thought is continued by putting the loxodromic parametrization of elliptic curves into this context, resulting in \\"Tate curves\\" E[q] for a p-adic number q.  The author ends this section by discussing briefly some conjectures that he feels will be major unsolved problems in the years. One of these, called `Szpiro's Conjecture', postulates that the minimal discriminant of an elliptic curve over Q is bounded by its conductor. The other, called the `abc Conjecture' conjectures that the maximum of the valuations of three relatively prime integers is bounded by the radical of the product of these integers. Consequences of these conjectures are briefly discussed, including an interesting generalization of Fermat's equation.<br /><br />A very helpful historical summary of the \\"elliptic curve approach\\" to Fermat's Last Theorem is given in the appendix.by starting with an elliptic curve E over a field K, and for a prime number not equal to the characteristic L of K, he shows how to construct the `Tate module' T(E;L) of E at L. Taking projective limits in this case shows that T(E; L) is a free Z(L)-module of rank 2. For the Galois group G of the algebraic closure of K, the Tate module is also shown to be a G-module over Z(L). Given a prime number p, the Tate module T(E; L) allows one to do arithmetic just as easily, or just as hard, as one does arithmetic in a finite field F[L], if one views the arithmetic in the context of an elliptic curve over Q (one is thus justified in setting L = p). The elliptic curve and the Tate module allow one to know just how many points are in the reduced elliptic curve E in F[p], this following from an understanding of the representations of the Galois group for a fixed L (these representations are related to each other, and thus serves to make the prime arithmetic more manageable). This line of thought is continued by putting the loxodromic parametrization of elliptic curves into this context, resulting in \\"Tate curves\\" E[q] for a p-adic number q.  The author ends this section by discussing briefly some conjectures that he feels will be major unsolved problems in the years. One of these, called `Szpiro's Conjecture', postulates that the minimal discriminant of an elliptic curve over Q is bounded by its conductor. The other, called the `abc Conjecture' conjectures that the maximum of the valuations of three relatively prime integers is bounded by the radical of the product of these integers. Consequences of these conjectures are briefly discussed, including an interesting generalization of Fermat's equation.     A very helpful historical summary of the \\"elliptic curve approach\\" to Fermat's Last Theorem is given in the appendix.	2004-10-16
490691:US	50702879	RYOG8C3BYM28M	0781718333	504207898	Fundamental Virology	Books	5	4	4	N	Y	Superb	For non-experts in the subject (such as this reviewer), this book gives a fascinating overview of organisms that have challenged humankind's domination of this planet. Although the book is targeted toward students and biologists, anyone who has a keen interest in virology will gain much from its perusal. Packed with diagrams, and containing hundreds of references, readers should have no problems in assimilating the information in the book, even though it is quite sizable.  I only read chapters 1, 2, 5, 6, and 13 (due only to time constraints and not because the other chapters were deemed unimportant) so my review will be confined to listing some of the interesting facts and helpful features of the book.<br /><br />These include: 1. The discussion on the history of virology, especially the discussion on D'Herelle's dream and Koch's postulates. The early years of virology are impressive given that viruses could not be seen at the time due to the lack of suitable microscopes. 2. The actual number of species of viruses is 1550, with 2404 tentative species. 3. The methods by which the different viruses were identified experimentally, such as cell cultures and recombinant DNA technology. 4. The methods for measuring the infectivity of viruses. 5. The method of fluctuation analysis for measuring spontaneous mutation rates in viruses. The difference in spontaneous mutation rates between DNA and RNA viruses is astonishing. The authors point out the ability of RNA viruses to exist as \\"quasi-species\\", being capable of very rapid adaptation because of the high spontaneous mutation rate.  6. The simple replication abilities of RNA viruses, which although very error prone, results in very rapid evolutionary response. 7. In plant viruses, the existence of genome segments that are frequently packaged in distinct virions, which results in the need for several viruses to co-infect in order to transmit infectivity. 8. Viral RNA genomes are very rich and contain nearly every structural variation possible. 9. The role of horizontal gene transfer in producing the antigenic shifts that produce new pandemic strains of influenza. 10. The ability of cells to counteract virus infections by using gene silencing or the interferon system. Some viruses have evolved mechanisms for evading these defenses. 11. The replication strategies for DNA viruses, and the mechanisms that have evolved to evade host defenses. 12. Viral DNA replication is initiated by using proteins as primers. 13. The ability of viruses to evade host defenses by withdrawing into a latent state. Only a few proteins are expressed when the virus is in this latent state. The authors encourage the reader to pursue research into the mechanisms that are behind the initiation and release from latency, since at the time of writing these mechanisms are not well understood. 14. Gene therapy, certainly the most fascinating of all topics in virology and genetic engineering. 15. The role of self-inactivating (SIN) vectors in enhancing the safety of viral vectors.ral variation possible. 9. The role of horizontal gene transfer in producing the antigenic shifts that produce new pandemic strains of influenza. 10. The ability of cells to counteract virus infections by using gene silencing or the interferon system. Some viruses have evolved mechanisms for evading these defenses. 11. The replication strategies for DNA viruses, and the mechanisms that have evolved to evade host defenses. 12. Viral DNA replication is initiated by using proteins as primers. 13. The ability of viruses to evade host defenses by withdrawing into a latent state. Only a few proteins are expressed when the virus is in this latent state. The authors encourage the reader to pursue research into the mechanisms that are behind the initiation and release from latency, since at the time of writing these mechanisms are not well understood. 14. Gene therapy, certainly the most fascinating of all topics in virology and genetic engineering. 15. The role of self-inactivating (SIN) vectors in enhancing the safety of viral vectors.	2004-10-13
494554:US	50702879	RITORQFSF460S	0393059170	168441340	Cruel and Unusual: Bush/Cheney's New World Order	Books	3	52	70	N	N	Acceptable	Offering at minimum a catharsis for those who dislike Bush intensely, this book is interesting reading and has some interesting surprises. Without a doubt much of it is merely the author's opinions, and his anger and frustration clearly shows through. Anger and hate both require frequent inputs to sustain themselves, and so vituperation is apparent throughout the book. In comparison to most political books of late however, it is kept at a manageable level.<br /><br />Assuming that it can be cross-checked, and this might be very difficult in some cases, the information in this book is educational and sheds light on many current events and on constitutional law. One example is the discussion of the U.S. Northern Command, or NORTHCOM, which was set up to provide military assistance to civilian authorities. This will weaken, the author argues, the Posse Comitatus Act of 1878, which forbids the use of federal soldiers to police American civilians (the phrase itself refers to the power of a sheriff to call upon the male population for assistance in enforcing the laws). Unfortunately, the author does not discuss just what exceptions Congress made to the Posse Comitatus Act, and what limitations, if any, exists for the military's involvement in civilian law enforcement. Another example is the discussion of the Council for National Policy (CNP) and its connection with the \\"Christian Reconstructionists\\". The author claims that individuals such as Trent Lott, Tom Delay, Dan Burton, Ernest Istook, and Don Nickles are members of the CNP, but this might take some time for a typical reader to verify. It is also claimed by the author that Bush made what he calls a \\"pilgrimage\\" to the CNP during his run for the presidency in 1999. This may also be difficult for a reader to verify. The philosophical and political stance of the Christian Reconstructionists is quite troubling on the surface, but it should be remembered that whatever their numbers there are plenty of people who disagree with them and will oppose them vociferously if any attempt is made to morph the United States into an oppressive theocracy.<br /><br />These \\"facts\\" and many more are included in the book, and can be subjected to critical review by the reader. Other areas in the book read more like opinions, but do carry weight if one views them from a particular vantage point or context. These typically involve subjective judgments that may not survive careful scrutiny and vary widely between individuals. It is the opinion of this reviewer that the author is correct in his general assessment of Bush's character and motivations, such as when he states that Bush is unable, despite his best efforts to do so, to pretend a stance against war. Indeed, with his arms poised outward away from his armpits and bent at the elbow, his demeanor is rather of a man who is itching for a fight. Talking like a tough guy is natural to him though, and he relishes it more than ever: \\"bring `em on\\" will be one of his most remembered phrases. Donning a pilot's uniform and parading on a flight deck, Bush is good at pretending to be a soldier, but his history of avoidance of real conflict betrays him. Both Bush and Cheney have distinguished themselves in the having both yellow and red stains on their records. The yellow of their cowardice and the red of the blood of American soldiers and Iraqi civilians gives their resumes a sickening orange color, to be viewed only from a distance and then only with an empty stomach.<br /><br />But Bush would not be bothered by any negative assessment of his presidency, for after all, he, does not \\"feel like he owes anybody an explanation\\", the latter phrase being taken from one of his speeches and included in the book. Taking advantage of the fears and concerns of the populace after the horrific attack of 9/11, and duped by the followers of Leo Strauss, he found the perfect excuse to play warrior, which from a perusal of his demeanor and from listening to his Freudian slips, he thoroughly enjoyed. Thousands of miles away from real conflict, he finds no conflict with himself about sending others to fight, the latter of which both him and his boss Cheney steadfastly and cunningly avoided themselves.joyed. Thousands of miles away from real conflict, he finds no conflict with himself about sending others to fight, the latter of which both him and his boss Cheney steadfastly and cunningly avoided themselves.	2004-10-10
501643:US	50702879	RZ41FHJHQPMYJ	0521297761	221070016	Reason, Truth and History (Philosophical Papers (Cambridge))	Books	3	10	34	N	N	An overindulgence of thought experiments	In this book, the goal of the author is to dissolve a few of the dichotomies that he thinks have existed in the philosophical community for most of the twentieth century. The major dichotomy he believes is the one between the `objective' and `subjective' views of truth and reason. The author asserts that once this dichotomy is accepted, philosophers begin to view the terms of the dichotomy as `ideological labels'. Most philosophers he believes subscribe to the `copy' or `correspondence' theory of truth, which asserts the truth of a statement as a correspondence with mind-independent facts. The author does not cite any statistical evidence for his assertion that most philosophers hold to this view of truth however. By `most' does he mean that over fifty percent of the philosophical community subscribe to the correspondence theory of truth?<br /><br /> Philosophers of course usually do not back up their claims with empirical evidence or statistical sampling. Instead they frequently construct huge systems of thought that they think will settle the issues at hand. Even though the book is much shorter than some of the system-building efforts currently in progress, the argumentation put forward by the author in this book is no different. In fact, by asserting without any statistical evidence that the philosophical community is divided between those who believe in the copy conception of truth and those who hold to relativistic or subjective theories of truth, the author already sets up an artificial problem that may not reflect the true state of affairs in the philosophical community. In addition, by attempting to reconcile these views in the book, he implicitly assumes that they are different, i.e. that the clauses or language that represents each of these views are mutually exclusive. These systems of thought may already share many common conceptions, and their differences and similarities, if any, are dependent on the metric one uses to measure these differences or similarities. The author does not make any proposals for such a metric in the book, but instead puts forward a theory of truth that could be labeled as `rational acceptability'. In his view a statement can be `rationally acceptable at a time' but not `true', and the relation between rational acceptability and truth is a relation between two distinct notions (but again, no metric is proposed to quantify the what he means by `distinct'). His opinions though are similar to the ones that are currently being developed in the artificial intelligence community under the heading of `defeasible reasoning.'<br /><br /> The author therefore spends much time outlining what he considers to be a reconciliation of the objectivist and subjectivist views of truth. He clearly rejects the notion that rationality is restricted to laboratory science, this being what he calls a `hangover from positivism.' However, he also asserts that his conception is not one that has the mind making up the world. His (reluctant) and psuedo-Hegelian metaphor is that the mind and the world together make up the mind and the world.<br /><br /> The rejection of empiricism and scientism is not surprising, given the angst towards science exhibited by many philosophers in the twentieth century. Experimental or `sense data', as the author likes to call it, does not hold any special role in his system, nor does the belief that the evolutionary process has `pressured' our conceptions so that they correspond to external things. He does give an interesting discussion of the \\"evolutionary theory of truth\\", primarily because (in the Appendix) he brings in some formal notions of model theory. He proves that in a given language with a finite number of predicates, for an interpretation I that assigns an intension to every predicate of the language, and which has the property that at least one predicate has an extension which is neither empty nor universal in at least one possible world, there exists another interpretation Jthat disagrees with I but that makes the same sentences true in every possible world that I does. This is the only place in the book though that the author attempts to be quantitative in any general sense.<br /><br /> Indeed, most of the book is arm-chair speculation, and its clauses and derivations could be rejected without disturbing the belief in empiricism or the correspondence theory of truth. The author rejects scientific, `sense-data' experimentation, and believes that part of the problem with modern philosophy is a `scientism' that it has \\"inherited\\" from the nineteenth century. However, the author has absolutely no problem with `thought-experiments', such as the illustrious `brain-in-a-vat' that begins the book. Thought experiments are not subjected to the same criticism as \\"real\\" ones, but instead are inadvertently edified throughout the book, as they are throughout contemporary philosophy.<br /><br />Although the book is interesting reading, and suitable for the private indulging of fantasies of thought, there is no penalty in rejecting the author's assertions, nor in the accepting of them. For all its rhetorical brilliance, there is nothing in the book that is of assistance in the building of a constructive theory of truth and reality.etation J that disagrees with I but that makes the same sentences true in every possible world that I does. This is the only place in the book though that the author attempts to be quantitative in any general sense.  <br /> <br /> Indeed, most of the book is arm-chair speculation, and its clauses and derivations could be rejected without disturbing the belief in empiricism or the correspondence theory of truth. The author rejects scientific, `sense-data' experimentation, and believes that part of the problem with modern philosophy is a `scientism' that it has \\"inherited\\" from the nineteenth century. However, the author has absolutely no problem with `thought-experiments', such as the illustrious `brain-in-a-vat' that begins the book. Thought experiments are not subjected to the same criticism as \\"real\\" ones, but instead are inadvertently edified throughout the book, as they are throughout contemporary philosophy. <br /> <br />Although the book is interesting reading, and suitable for the private indulging of fantasies of thought, there is no penalty in rejecting the author's assertions, nor in the accepting of them. For all its rhetorical brilliance, there is nothing in the book that is of assistance in the building of a constructive theory of truth and reality.	2004-10-03
502416:US	50702879	RITB9UTGE1COO	0060736798	882691706	Secret History of the Iraq War	Books	3	13	25	N	Y	Where is the evidence? Where are the sources?	As a book on history, this one is atypical, for the reason that no references are given nor are any sources quoted. The author believes that revealing his sources will put them in grave danger, and so he refrains from doing it. Readers will therefore have to take his word on the accuracy of the content of the book, which may be difficult to do given the extreme (and justified) skepticism that accompanies any discussion of the war in Iraq. The author has written an interesting and engaging book, but one must leave to future analysis whether what he puts down in print is accurate.<br /><br />There are many surprises in the book if a reader compares its contents with what is being reported in the American news media. Some of these include: 1. The plan by Iraq and Syria to proactively thwart the war on terrorism. 2. The move by Syria to expand military assistance to Iraq by creating a network of fictitious companies. 3. The visit to Syria of Kim Yong-Nam to forge an alliance with Syria, Iraq, and Iran. 4. The pre-war strike (by many months) on Iraqi air defense installations. 5. The pre-war arrival of 150 al-Qaeda terrorists in northern Iraq as preparation for operations in Western Europe. 6. The plan by Hussein for a counterattack across the whole Middle East, involving ballistic missiles that had chemical and biological warheads (this is one place where the reader is dying to know what the author's proof of this is). 7. The plans by Moscow to launch a preemptive coup against Hussein, and its consequent rejection by the American government. The author describes the administration as being \\"horrified\\" by these plans, who would have to face the political consequences of \\"somebody else taking credit for toppling Hussein's regime.\\" The author claims that Washington deliberately tried to foil the Russian plan via a leak to Egyptian intelligence, and the Russians retaliated by refusing to give Washington any intelligence on Iraqi opposition. The author believes that this \\"hands-off\\" stance was a clear detriment to the United States.<br /><br />The author lays the blame of the debacle in Iraq on the intelligence community. If by `intelligence' he means a reasoned measure of the attitudes of the Iraqi people as well as an awareness of the military capabilities of Iraq, then he is correct. The current administration had the capability of finding out just what kind of weapons the Iraq regime possessed, but they chose unfortunately to not been exhaustive in their search. They completely ignored, or perhaps did not even think to consider, the thoughts of the Iraqi people on the conflict they were to face. It is becoming more apparent as time goes on that the Iraqi people view the war as an invasion and occupation, that the Americans are invaders and not liberators. They are rejecting completely the notion of a pro-American Iraq.<br /><br />The author does not discuss any alternative reasons the war in Iraq, no doubt because he is a historian and wants to concentrate on the actual historical events in the war. It would seem though that he would believe that the war was justified if only the intelligence were valid. When reading the book, it would be difficult to view the action in Iraq as one that was driven by the energy needs of the United States. The author does not outline any evidence that might support this view. One should not conclude however that the lack of evidence in this book for this view supports the position that this war was not a \\"war for oil\\". It is very difficult for some, possibly this author, to believe that the United States would engage in such a brutal attack for this reason. For others though, including this reviewer, the belief that Iraq was a war for oil, but masked cleverly behind \\"national security\\" needs, is one that sounds highly credible and possesses a large amount of evidence.\\"hands-off\\" stance was a clear detriment to the United States.  <br /> <br />The author lays the blame of the debacle in Iraq on the intelligence community. If by `intelligence' he means a reasoned measure of the attitudes of the Iraqi people as well as an awareness of the military capabilities of Iraq, then he is correct. The current administration had the capability of finding out just what kind of weapons the Iraq regime possessed, but they chose unfortunately to not been exhaustive in their search. They completely ignored, or perhaps did not even think to consider, the thoughts of the Iraqi people on the conflict they were to face. It is becoming more apparent as time goes on that the Iraqi people view the war as an invasion and occupation, that the Americans are invaders and not liberators. They are rejecting completely the notion of a pro-American Iraq.    <br /> <br />The author does not discuss any alternative reasons the war in Iraq, no doubt because he is a historian and wants to concentrate on the actual historical events in the war. It would seem though that he would believe that the war was justified if only the intelligence were valid. When reading the book, it would be difficult to view the action in Iraq as one that was driven by the energy needs of the United States. The author does not outline any evidence that might support this view. One should not conclude however that the lack of evidence in this book for this view supports the position that this war was not a \\"war for oil\\". It is very difficult for some, possibly this author, to believe that the United States would engage in such a brutal attack for this reason. For others though, including this reviewer, the belief that Iraq was a war for oil, but masked cleverly behind \\"national security\\" needs, is one that sounds highly credible and possesses a large amount of evidence.	2004-10-03
503601:US	50702879	R2I0AURN4KT7FN	0521585295	321933454	Mathematical Methods and Models for Economists	Books	4	25	29	N	Y	A good overview	Mathematical economics has been around for about 175 years, although as a discipline it has only been recognized for about five decades. Professional economists have had various levels of confidence in its validity and applicability, and mathematical economists have been criticized for the esoteric nature of the mathematics they deploy and some have been ostracized from academic departments for this very reason. This book emphasizes the mathematical tools, these being primarily the theory of optimization and dynamical systems, but the author does find time to discuss applications. Some of these could be classified as \\"classical\\" applications, but some are very contemporary in their scope and intersect the work done in financial engineering.<br /><br /> Part 1 of the book introduces the reader to the necessary background in real analysis, topology, differential calculus, and linear algebra. All of this mathematics is straightforward and can be found in many books.<br /><br />In chapter 5, the author considers static economic models, which are described by collections of parametrized systems of equations. The equations are dependent on parameters describing the environment and `endogenous' variables. The goal is to find the values of the endogenous variables at equilibrium, and to find out if the equilibrium solutions are unique. In addition, it is interest to find out how the solution set changes when the parameters are changed. This is what the author calls `comparative statics'. Linear models are considered first, their analysis being amenable to the techniques of linear and multilinear algebra. The comparative statics for linear models is straightforward, with the shift in equilibrium as a parameter is change readily calculated. The comparative statics of nonlinear models involves the use of the implicit function theorem, and the author derives a formula for doing comparative statics in differentiable models. The discussion here, involving concepts such as transversality, critical points, regular values, and genericity, should be viewed as a warm-up to a more advanced treatment using differential topology.<br /><br /> The author studies static optimization in chapter 7, with the postulate of rationality assumed throughout. This allows the study of the behavior of economic agents to be reduced to a constrained optimization problem. The techniques of nonlinear programming are used to find solutions to the constrained optimization problem. Throughout this chapter one sees discussion of the ubiquitous `agent' who is embedded in a collection of possible environments, and is able to carry out a certain collection of actions.<br /><br /> The author finally gets to economic applications in chapter 8, wherein the author studies the behavior of a single agent under a set of restrictions imposed on it by its environment. This rather simplistic study is then generalized to the case of many interacting agents who are taken to be rational. The concept of `equilibrium', so entrenched in economic theory and economic modeling, makes its appearance here. In a condition of equilibrium, no agent has an incentive to change its behavior, and the actions of each individual are mutually compatible. Some of the usual concepts of equilibrium are discussed in the chapter, such as Walrasian equilibrium in exchange economies, and Nash equilibrium in game theory. The (subjective) preferences of consumers are modeled by binary relations and differentiable utility functions. The differentiability allows the techniques of chapter 7 to be used. The author asks the reader to work through some examples of `imperfect' competition at the end of the chapter.<br /><br /> After a straightforward review of dynamical systems in chapters 9 and 10, the author discusses applications of dynamical systems in chapter 11. He begins with a discussion of a dynamic IS-LM model, using assumptions on the evolution of the money supply, the formation of expectations, and price dynamics. This model consists of two first-order ordinary differential equations, and the author studies its fixed-point structure via a standard phase-space analysis. This analysis allows the author to study the effect of a change in parameters, such as change in the rate of money creation, i.e. the effects of a certain monetary policy. Also discussed are `perfect-foresight models', which address the difficult issue of boundary conditions in economic models based on dynamical systems. Two of these models are discussed, one is a stock price model based on the no-arbitrage principle from finance, and the other is a model of exchange-rate determination. The stock price model is the most interesting discussion in the book. It requires one to specify how expectations are formed, and, depending on how this is done, some very unexpected results occur. For example, if the agents have adaptive expectations, the author shows that the forecast error is predictable, and that agents who understand the structure of the model will have an incentive to deviate from the predicted behavior. This behavior on the part of the agents will invalidate the theory since the agents will have an incentive to compute the trajectory of prices, contrary to the assumption of the model. The author concludes that this is in direct conflict with the assumption that individuals are rational and maximize utility, i.e. that in a world without uncertainty, adaptive expectations are inconsistent with the assumption of rationality. The author avoids this problem by assuming that `perfect foresight' holds for the agents, i.e. the agents form expectations that are consistent with the structure of the model. He shows that the assumption of perfect foresight eliminates the inconsistency that was found in the adaptive expectations model. In the perfect foresight model, every agent uses the correct model to predict prices, and no agent has any incentive to act differently. The author then uses this model to study the response of share prices to a change in the tax rate on dividends. The rest of the chapter discusses neoclassical growth models and the software language Mathematica is introduced as a tool for solving nonlinear differential equations.<br /><br /> I did not read the last two chapters of the book, which cover dynamic optimization and its applications, and so I will omit their review.ns, and price dynamics. This model consists of two first-order ordinary differential equations, and the author studies its fixed-point structure via a standard phase-space analysis. This analysis allows the author to study the effect of a change in parameters, such as change in the rate of money creation, i.e. the effects of a certain monetary policy. Also discussed are `perfect-foresight models', which address the difficult issue of boundary conditions in economic models based on dynamical systems. Two of these models are discussed, one is a stock price model based on the no-arbitrage principle from finance, and the other is a model of exchange-rate determination. The stock price model is the most interesting discussion in the book. It requires one to specify how expectations are formed, and, depending on how this is done, some very unexpected results occur. For example, if the agents have adaptive expectations, the author shows that the forecast error is predictable, and that agents who understand the structure of the model will have an incentive to deviate from the predicted behavior. This behavior on the part of the agents will invalidate the theory since the agents will have an incentive to compute the trajectory of prices, contrary to the assumption of the model. The author concludes that this is in direct conflict with the assumption that individuals are rational and maximize utility, i.e. that in a world without uncertainty, adaptive expectations are inconsistent with the assumption of rationality. The author avoids this problem by assuming that `perfect foresight' holds for the agents, i.e. the agents form expectations that are consistent with the structure of the model. He shows that the assumption of perfect foresight eliminates the inconsistency that was found in the adaptive expectations model. In the perfect foresight model, every agent uses the correct model to predict prices, and no agent has any incentive to act differently. The author then uses this model to study the response of share prices to a change in the tax rate on dividends. The rest of the chapter discusses neoclassical growth models and the software language Mathematica is introduced as a tool for solving nonlinear differential equations.  <br /> <br /> I did not read the last two chapters of the book, which cover dynamic optimization and its applications, and so I will omit their review.	2004-10-01
516308:US	50702879	RHKBNEJE15232	0521532159	420798675	Higher Operads, Higher Categories (London Mathematical Society Lecture Note Series)	Books	5	13	15	N	Y	A very interesting overview	Structures such as braided monoidal categories, operads, and Hopf algebras are familiar to those who have studied topological quantum field theory, knot theory, string theory, and the renormalization procedure in quantum field theory. This book attempts, and succeeds, in presenting to the interested reader an overview of higher category theory, which subsumes the aforementioned topics. It is not however a book on applications, but instead details the purely mathematical aspects of higher category, clarifying for example the difference between `weak' n-categories and `strict' n-categories. The author though has not written a book in the typical \\"definition-theorem-proof\\" style, as he motivates the subject very well, and does not hesitate to use diagrams to get his point across. Indeed, he is careful to point out that the subject is inherently topological in its nature, and that diagrams used to illustrate higher-dimensional structures can be viewed as topological structures. The braided monoidal category that arises in knot theory is a perfect example of this.<br /><br /> The author introduces higher-dimensional category theory as one that uses \\"higher-dimensional arrows\\", in analogy to ordinary category as one that uses 1-dimensional arrows. Higher-dimensional category theory or `n-category theory,' is viewed as a generalization of the notion of category. To motivate the concept of a weak n-category, the author reminds the reader of the attempt to prove to what extent the loop group in differential topology is in fact a topological group. The composition of paths in the loop groups is not associative, but rather associative up to homotopy. Associativity does hold in strict n-categories but not in weak n-categories. As another example of non-associativity, the author discusses the fundamental omega-groupoid, which is the higher-dimensional category arising from a topological space. Several examples of weak n-categories are given in the motivating chapter of the book.<br /><br /> The first chapter is an overview of classical category theory, most of which may be review for readers familiar with it. Of particular importance is the notion of a monoidal category, which for the case of a strict monoidal category, generalizes the familiar tensor product operation. The tensor operation is generalized to that of a functor on a category that obeys strict associativity and unit laws. Weak monoidal categories are also defined, where the functor now obeys associativity and unit laws only up to isomorphism. These are the `coherence isomorphisms', and these satisfy the `pentagon' and `triangle axioms.' Modules over commuative rings with the usual tensor product are monoidal categories.<br /><br /> The author introduces operads in chapter two, concentrating first on multicategories, which are collections of objects on which are defined maps or \\"arrows\\", and compositions that satisfy associativity and unit properties. Operads are multicategories with only one object, and can be viewed as an abstraction of a set of composable functions of several variables where the variables can be permuted. Several examples are given of multicategories with many objects, including how a monoidal category can give rise to a multicategory. Operads appear in physical applications, such as string field theory and conformal field theory, which are not discussed in the book, but the author gives many examples of operads that make their properties readily apparent. One of these involves iterated loop spaces, where operads arose historically.<br /><br /> After a further discussion of monoidal categories in chapter 3, the author spends part two of the book solely on operads. One of the first goals of the author is formalize the notion of an input type, so as to allow more than just finite sequences of objects. For each input type he defines a theory of operads and multicategories, which yields the \\"plain\\" operad when the inputs are finite sequences. The author also discusses how to start with a monad T on any category and construct `T-multicategories'. T-operads are then T-multicategories with one object, and algebras can be associated to T-multicategories. These algebras are an analog of the \\"representation\\" or \\"model\\" for the T-multicategory. The author's work on \\"free category\\" or `fc-multicategories', which are 2-dimensional examples of these generalized multicategories. Fc-multicategories are T-multicategories on the free category (fc) monad on the category of directed graphs. As a very interesting example of an fc-multicategory, the author discusses one which encapsulates (in a single structure) rings, homomorphisms of rings, modules over rings, homomorphisms of modules, and tensor products of modules.<br /><br />Also discussed in this part is the notion of an `opetope' (for \\"operation polytope\\"), which are a kind of generalization of the simplices of simplicial geometry. The opetopes are thus the \\"polytopes\\" of higher-dimensional category theory, and are defined by first taking for every natural number and defining a category and monad inductively. The zeroth category is Set and the zeroth monad is the identity. This gives rise to an infinite sequence of opetopes, with the zeroth opetope being 1. The nth category is then canonically isomorphic to Set modulo the nth opetope. A 2-opetope is the natural numbers, while a 3-opetope is the collection of trees. The author shows how to construct a category of n-dimensional pasting diagrams for each natural number n, where for n = 1 is the category of finite totally ordered sets, and for n = 2, the category of trees. The geometric connotations of the pasting diagrams are obvious, as well as their analogy to simplicial objects. An opetopic n-pasting diagram is defined as an (n+1)-opetope for each natural number n. 2-pasting diagrams correspond to trees, and the author shows how to construct `stable trees', i.e. those trees whose vertices have at least two branches coming out of them. The relation of stable trees to the constructions of Stasheff are discussed, along with the connection of opetopes to the construction of weak n-categories.uthor also discusses how to start with a monad T on any category and construct `T-multicategories'. T-operads are then T-multicategories with one object, and algebras can be associated to T-multicategories. These algebras are an analog of the \\"representation\\" or \\"model\\" for the T-multicategory. The author's work on \\"free category\\" or `fc-multicategories', which are 2-dimensional examples of these generalized multicategories. Fc-multicategories are T-multicategories on the free category (fc) monad on the category of directed graphs. As a very interesting example of an fc-multicategory, the author discusses one which encapsulates (in a single structure) rings, homomorphisms of rings, modules over rings, homomorphisms of modules, and tensor products of modules.  <br /> <br />Also discussed in this part is the notion of an `opetope' (for \\"operation polytope\\"), which are a kind of generalization of the simplices of simplicial geometry. The opetopes are thus the \\"polytopes\\" of higher-dimensional category theory, and are defined by first taking for every natural number and defining a category and monad inductively. The zeroth category is Set and the zeroth monad is the identity. This gives rise to an infinite sequence of opetopes, with the zeroth opetope being 1. The nth category is then canonically isomorphic to Set modulo the nth opetope. A 2-opetope is the natural numbers, while a 3-opetope is the collection of trees. The author shows how to construct a category of n-dimensional pasting diagrams for each natural number n, where for n = 1 is the category of finite totally ordered sets, and for n = 2, the category of trees. The geometric connotations of the pasting diagrams are obvious, as well as their analogy to simplicial objects. An opetopic n-pasting diagram is defined as an (n+1)-opetope for each natural number n. 2-pasting diagrams correspond to trees, and the author shows how to construct `stable trees', i.e. those trees whose vertices have at least two branches coming out of them. The relation of stable trees to the constructions of Stasheff are discussed, along with the connection of opetopes to the construction of weak n-categories.	2004-09-19
523586:US	50702879	R1AXOAHK8HA72N	0521567599	705003945	A User's Guide to Spectral Sequences (Cambridge Studies in Advanced Mathematics)	Books	5	15	17	N	Y	A superb overview	Spectral sequences have generally been thought of as being complicated, esoteric constructions, due mainly to the way they are presented in the mathematical literature. This book is very unusual, in that it attempts to explain the need for spectral sequences and give insight into how they arise and in what contexts. Anyone who is curious about spectral sequences will find an exceptionally well-written book here. This goes especially for the physicist reader, who if involved in fields such as string theory or quantum field theory, is faced with a daunting task of learning both the physics and mathematics behind these theories, formidable as both of these are. Chapter one, entitled `An Informal Introduction', is one of the best introductions to spectral sequences in print, in both books and research papers. The intuition gained by the reading of this chapter is invaluable for the chapters that follow, since the author motivates the construction of spectral sequences exceedingly well, with many examples given.<br /><br />The author introduces spectral sequences as a tool for computing the homology or cohomology (which he labels as H*) of a space or an algebraic invariant assigned to a space or algebraic object. In order to obtain a more tractable problem and to motivate the calculation of H* using spectral sequences, the author assumes at first that H* is `filtered', in particular that H* is a graded vector space. As a first approximation to H*, one uses the associated graded vector space to some filtration of H*, which is the \\"target\\" of the spectral sequence. The \\"two-index\\" property of spectral sequences in this case arises from the fact that the associated graded vector space to the filtered graded vector space is in fact `bigraded'. One of the indices is called the `complementary degree' while the other is called the `filtration degree.' More formally, the spectral sequence is a sequence of differential bigraded vector spaces, where each bigraded vector space in the sequence is equipped with a linear mapping that is also a differential.  The goal is then to find the conditions under which the spectral sequence will `converge' to H*. In the introductory chapter, the author outlines various situations that allow one to compute with a spectral sequence. Some familiar constructions appear, such as the Gysin sequence, known from homological algebra and differential geometry, and the exterior algebra, also from differential geometry.<br /><br />With the motivation for spectral sequences established in the introduction, the author proceeds to more formal constructions in the next chapter. Spectral sequences arise as a collection of differential bigraded R-modules between which are defined differentials. The author shows in detail how to build spectral sequences using a filtered differential module and using an exact couple. As per the historical development, he also constructs spectral sequences of algebras using tensor products of differential graded modules. After these constructions are made, the author turns his attention to how well the spectral sequence can approximate its target. This entails, as expected, a rigorous notion of limits. The author in fact defines limits and colimits of modules and the notion of a morphism between spectral sequences. For filtered differential graded modules, he shows how conditions on the filtration will ensure the associated spectral sequence converges uniquely to its target. For exact couples, the convergence can be shown but certain properties such as the Hausdorff property for the filtration must be satisfied.<br /><br />The book covers four main spectral sequences that arise in algebraic topology: the Leray-Serre, Eilenberg-Moore, Adams, and Bockstein spectral sequences. The Leray-Serre spectral sequence arises when studying the homology (and cohomology) of fibrations with path-connected base spaces and connected fibers. The Leray-Serre spectral sequence allows one to compute the cohomology of the total space from knowledge of the cohomology of the base space and the fiber. The author discusses applications in the computation of cohomology of Lie groups. This is accomplished by constructing the fibration resulting from taking quotients by subgroups. Rigorous proofs of all the constructions are given for the interested reader, including a full proof of the theorem that the fourth homotopy group of the two-sphere is the integers modulo two, and the connections with characteristic classes and the Steenrod algebra.<br /><br />The Eilenberg-Moore spectral sequence also arises in the study of fibrations, when the cohomology of the base space and the cohomology of the total space are known and one wants to compute the cohomology of the fiber. The author studies this case and the dual case of the Eilenberg-Moore spectral sequence for homology. Heavy use is made of differential homological algebra in this study. The reader can see with great clarity the role of torsion in the applications of the Eilenberg-Moore spectral sequences.<br /><br />The Adams spectral sequence arises in the context of computing the homotopy groups of a nontrivial finite CW-complex. An approximation to the homotopy groups is given by the `stable homotopy groups', and Adams analysis of these groups and his proof that there are no elements of Hopf invariant one led him to construct the spectral sequence that bears his name. The author gives a detailed overview of this spectral sequence, its applications, and its connection with cobordism theory.<br /><br />The Bockstein spectral sequence arose in the study of Lie groups, and the author gives the details of the construction of this spectral sequence and its application to H-spaces. Bockstein spectral sequences arise from exact couples, the first differential being the Bockstein homomorphism (in the case of homology). The Bockstein spectral sequence can also be constructed for the case of cohomology, wherein the Bockstein homomorphism becomes the stable cohomology operation in the Steenrod algebra. The resulting spectral sequence is in fact a spectral sequence of algebras with the stable cohomology operation being a derivation with respect to the cup product.cohomology of the total space from knowledge of the cohomology of the base space and the fiber. The author discusses applications in the computation of cohomology of Lie groups. This is accomplished by constructing the fibration resulting from taking quotients by subgroups. Rigorous proofs of all the constructions are given for the interested reader, including a full proof of the theorem that the fourth homotopy group of the two-sphere is the integers modulo two, and the connections with characteristic classes and the Steenrod algebra.  <br /> <br />The Eilenberg-Moore spectral sequence also arises in the study of fibrations, when the cohomology of the base space and the cohomology of the total space are known and one wants to compute the cohomology of the fiber. The author studies this case and the dual case of the Eilenberg-Moore spectral sequence for homology. Heavy use is made of differential homological algebra in this study. The reader can see with great clarity the role of torsion in the applications of the Eilenberg-Moore spectral sequences.  <br /> <br />The Adams spectral sequence arises in the context of computing the homotopy groups of a nontrivial finite CW-complex. An approximation to the homotopy groups is given by the `stable homotopy groups', and Adams analysis of these groups and his proof that there are no elements of Hopf invariant one led him to construct the spectral sequence that bears his name. The author gives a detailed overview of this spectral sequence, its applications, and its connection with cobordism theory.  <br /> <br />The Bockstein spectral sequence arose in the study of Lie groups, and the author gives the details of the construction of this spectral sequence and its application to H-spaces. Bockstein spectral sequences arise from exact couples, the first differential being the Bockstein homomorphism (in the case of homology). The Bockstein spectral sequence can also be constructed for the case of cohomology, wherein the Bockstein homomorphism becomes the stable cohomology operation in the Steenrod algebra. The resulting spectral sequence is in fact a spectral sequence of algebras with the stable cohomology operation being a derivation with respect to the cup product.	2004-09-13
524866:US	50702879	R1680TWG7BHSQE	0521831431	593107737	A First Course in String Theory	Books	5	215	220	N	Y	Didactic perfection	This book indeed does the impossible, for it introduces, at a level accessible to undergraduate physics and mathematics students, a subject that ranks as the most formidable construction ever attempted in mathematical physics. Using highly esoteric mathematical concepts, string theory, and its modern metamorphosis, M-theory, requires a high concentration of mental effort and long periods of time to assimilate. It has been difficult for students and those who are curious about string theory to find books or papers that are effective in explaining it from a perspective that gives insight into its many intricacies. This book is one of the few that does that, and it deserves the highest ranking of any of the books in mathematical physics that are currently in print. The author, a noted contributor to the field, has produced a book that will certainly motivate many to take up the subject of string theory, and these individuals can be introduced to it early in their education, instead of having to wait for the second or third year of graduate school. In addition, professional mathematicians can gain the needed physical insight from the perusal of the book, and then apply their unique talents and perspectives to extending the frontiers of string theory, which, to emphasize again, is a subject that requires a tremendous amount of mathematical knowledge and skill. Hopefully this book will be used in the university so as to give students an appreciation of the most complex and fascinating theories ever constructed in the history of physics.<br /><br /> The author's strategy is to introduce the reader to string theory by studying physics in high dimensions. This is done early on, by studying Lorentz invariance in more than three spatial dimensions, and by discussing the notion of `compact' dimensions. In addition, the author studies the quantum-mechanical square well problem with an extra (compact) dimension. This example gives the reader some insight into what can happen to the quantum-mechanical spectrum when a compact dimension is present. Throughout the book, the author makes use of light-cone coordinates, which masks to a large extent the relativistic covariance of the theory, but does have the advantage of making the quantization of the string straightforward. The peculiarities of light-cone coordinates are discussed in some detail, but the author explains them in a way that alleviates any doubt as to their use and physical meaning. The author does devote an entire chapter to the treatment of covariant quantization however. In this discussion the reader will get a first look on how difficult it is to quantize a system with constraints, this giving rise to the famous Virasoro operators. The covariant quantization of strings treats of course all coordinates the same, and this introduces the reader to another surprise from the standpoint of the traditional formalism of quantum mechanics, namely that the usual Hilbert space constructions are not valid, since the states that are constructed can have negative norm. In addition, the author is not able to derive the critical dimension in his treatment of covariant quantization since he wants the book to be accessible to undergraduates.<br /><br /> Another virtue of this book is that the author does not expect the reader to remain passive when reading the book. Short exercises and \\"quick calculations\\" are dispersed throughout the chapters so as to reinforce the reader's understanding of the topics. In addition, there are good problem sets at the end of each chapter. The \\"quick calculations\\" are fun to work out and also serve to slow the overly eager reader from rushing ahead before some of the more fundamental concepts are mastered.<br /><br /> The discussion on D-branes makes the reading of the book especially worthwhile, due to its clarity and the insights it grants on the physics. The role of Neumann and Dirichlet boundary conditions is readily apparent throughout. Due to the use of light-cone coordinates, the author is not able to treat the quantization of strings attached to D0-branes. The appearance of gauge fields (in this case Maxwell fields) when quantizing open strings on Dp-branes is brought out in detail. In his treatment of the quantization of open stretched strings between parallel Dp-branes, the author points out the need for using noncommutative geometry. Noncommutative geometry has received a lot of attention in recent years due to this connection with string theory. The author of course cannot bring in this kind of mathematics without departing from the level of the book. The origin of the Chan-Paton factors as being labels of D-branes, and not merely a computational strategy for obtaining Yang-Mills theories from open strings, is discussed briefly.<br /><br /> The author is quite aware of the skepticism expressed by newcomers to string theory on its physical relevance and experimental realization, for he makes a concerted effort to deal with the extent to which string theories can at least give the results of the Standard Model. He discusses the various approaches to string phenomenology, such as compactification via Calabi-Yau spaces and models based on M-theory. The author recognizes that there is much to be done in string phenomenology, but that significant progress has been made. His remarks should motivate many to enter the field with the goal of showing the derivation of the Standard model from string theory.<br /><br /> T-duality, certainly one of the most fascinating subjects in string theory, is given ample treatment in this book, and its physical interpretation made crystal clear. The presence of T-duality has been of great interest to mathematicians, because it is an example of what has been called `mirror symmetry', a topic that readers will encounter later on if they decide to pursue more advanced treatments of string theory.<br /><br /> Those readers who have encountered Born-Infeld electrodynamics in their travels through physics might be surprised to learn of its applicability in string theory. Being a nonlinear theory of electrodynamics, the Born-Infeld theory is usually thought of as being an historical curiosity. The author shows in detail, using T-duality, how Born-Infeld electrodynamics governs the electromagnetic fields on the world-volumes of D-branes.t-cone coordinates, the author is not able to treat the quantization of strings attached to D0-branes. The appearance of gauge fields (in this case Maxwell fields) when quantizing open strings on Dp-branes is brought out in detail. In his treatment of the quantization of open stretched strings between parallel Dp-branes, the author points out the need for using noncommutative geometry. Noncommutative geometry has received a lot of attention in recent years due to this connection with string theory. The author of course cannot bring in this kind of mathematics without departing from the level of the book. The origin of the Chan-Paton factors as being labels of D-branes, and not merely a computational strategy for obtaining Yang-Mills theories from open strings, is discussed briefly.<br /><br /> The author is quite aware of the skepticism expressed by newcomers to string theory on its physical relevance and experimental realization, for he makes a concerted effort to deal with the extent to which string theories can at least give the results of the Standard Model. He discusses the various approaches to string phenomenology, such as compactification via Calabi-Yau spaces and models based on M-theory. The author recognizes that there is much to be done in string phenomenology, but that significant progress has been made. His remarks should motivate many to enter the field with the goal of showing the derivation of the Standard model from string theory.<br /><br /> T-duality, certainly one of the most fascinating subjects in string theory, is given ample treatment in this book, and its physical interpretation made crystal clear. The presence of T-duality has been of great interest to mathematicians, because it is an example of what has been called `mirror symmetry', a topic that readers will encounter later on if they decide to pursue more advanced treatments of string theory.<br /><br /> Those readers who have encountered Born-Infeld electrodynamics in their travels through physics might be surprised to learn of its applicability in string theory. Being a nonlinear theory of electrodynamics, the Born-Infeld theory is usually thought of as being an historical curiosity. The author shows in detail, using T-duality, how Born-Infeld electrodynamics governs the electromagnetic fields on the world-volumes of D-branes.	2004-09-11
530696:US	50702879	R24M4L1OG0U02P	0596000502	700206176	Server Load Balancing	Books	3	2	3	N	Y	Needs more examples	This book gives an organized but purely descriptive overview of server load balancing and should be helpful to anyone who is approaching the subject for the first time but does not require quantitative assessments of the different methods for doing server load balancing. It is written for the network administrator, but anyone, including network managers should find it helpful. Network engineers may find the treatment too qualitative, but it could be supplemented by more rigorous material if needed.<br /><br /> Chapter 1 is a brief overview of the history of load balancing and why it is needed in Internet environments. DNS-based, firewall, and global server load balancing are briefly discussed, along with clustering. This is followed in chapter 2 by a brief review of the OSI model and the different components involved in server load balancing. The author cautions that the use of VRRP (Virtual Router Redundancy Protocol) may cause problems if the load balancers become isolated from each other, but does not give any historical or test examples of this. The same holds true for his caution on the use of fail-over cables.<br /><br /> The discussion becomes a little more detailed in chapter 3, wherein the author discusses the actual functioning of a server load balancer. Direct server return is discussed, with its use of MAC address translation and loopback interfaces. Both server-based and switch-based load balancers are briefly discussed, but the author does not want to commit to which is the better architecture. The inclusion of some benchmarking studies would be helpful here.<br /><br /> Performance metrics, such as connections per second, total concurrent connections, and throughput are discussed in chapter 4. Although the discussion is purely descriptive, the author does give a \\"metrics matrix\\" that outlines what metrics are important for different types of traffic.<br /><br /> The author gets down to describing the network infrastructure needed to do server load balancing in chapter 5. The different possibilities for network infrastructure are classified according to the IP configuration (flat-based or NAT-based), the return path (bridge path, route path, or DSR), and physical connectivity (one-armed or two-armed). The advantages of the different types of SLB architectures are discussed briefly, but no real test cases or benchmarking studies are included.<br /><br /> The details of flat-based SLB network architectures are discussed in chapter 6. The simplicity of this architecture is emphasized, along with its ability to pass FTP and stream traffic more readily (no real examples given however).<br /><br /> I did not read the rest of the book which covers administrative matters, and so its review will be omitted.erver load balancing in chapter 5. The different possibilities for network infrastructure are classified according to the IP configuration (flat-based or NAT-based), the return path (bridge path, route path, or DSR), and physical connectivity (one-armed or two-armed). The advantages of the different types of SLB architectures are discussed briefly, but no real test cases or benchmarking studies are included.  <br /> <br /> The details of flat-based SLB network architectures are discussed in chapter 6. The simplicity of this architecture is emphasized, along with its ability to pass FTP and stream traffic more readily (no real examples given however).   <br /> <br /> I did not read the rest of the book which covers administrative matters, and so its review will be omitted.	2004-09-06
530909:US	50702879	R31R3AP5BGCY2N	0312341156	246588173	Where the Right Went Wrong: How Neoconservatives Subverted the Reagan Revolution and Hijacked the Bush Presidency	Books	4	30	35	N	N	The author is more right than wrong.	Always pugnacious, but always with a command of historical facts, the author unashamedly puts them down in print with gusto in this book. One does not have to agree with the author on every issue he discusses in the book in order to enjoy its perusal. There are a few places in the book where the author is out of line, such as his statement on the sexual orientation of John Maynard Keynes, a fact that is totally irrelevant to a discussion on the content and consequences of Keynesian economics, but in general the author stays away from ad hominem attacks and does not engage in any kind of vituperation, contrary to what is done in many political books this year. Also, in his discussions on economics, the author makes claims that are unsubstantiated from a scientific point of view. Making economic predictions is a difficult business, requiring careful analysis and a hefty amount of empirical data. None of this is done by the author in this book.<br /><br />The authors' views on terrorism will no doubt create controversy but they are nevertheless accurate. Even though it is very disconcerting to acknowledge it, it is an historical fact that the United States has engaged in terrorism on a massive scale. The fire bombing of Tokyo and Dresden was a terrorist act since it targeted civilians in order to break the will of the German and Japanese people. The exploding of atomic bombs over Hiroshima and Nagasaski were terrorist acts since they targeted civilians in order to break the will of the enemy. And yes, Israel too has engaged in terrorism in their efforts to defeat the British in the 1940's. Their terrorist strategies says the author, were then emulated by the Arabs and Berbers in their efforts to drive out the French in Algeria. As far as a tactical strategy goes, terrorism can bring about change, although sustaining it for long periods of time can be exhausting for those who are engaging in it. The author quotes Sir Peter Ustinov appropriately, who states that \\"terrorism is the war of the poor, and War is the terrorism of the rich.\\"<br /><br />The author is right on target here and he has the courage to actually put this in print. There are no doubt many that have the same convictions as the author in regards to these American acts of terrorism (as this reviewer does). However, it is frequently difficult to express these convictions publicly for fear of reprisals by employers or business associates. The author can though, because of his name recognition, put these kinds of assertions in print. It is indeed quite uncomfortable for many (including this reviewer) to view the United States as having committed massive terrorist acts, but these acts are recorded history, and therefore cannot be denied.<br /><br />The author is quite correct in his view that Congress has abdicated its responsibility and power in \\"granting\\" the current President a \\"blank check\\" to engage in war. Congress he asserts, correctly, has backed away from its sole responsibility to declare war, raise revenue, coin money, and regulate foreign trade. Bush 41, Clinton, and Bush 43 have illegally waged war he asserts, with the current conflict in Iraq being encouraged and planned for many years by the \\"neoconservatives\\", who are unconstrained in their zeal to pick a fight with other countries they deem to be a threat.<br /><br />Much space in the book is devoted to this group of individuals, who are quite content it seems to allow others to do the fighting, but steadfastly avoid it themselves (they seem quite healthy in mind and body, and there is no reason why they should not put on a uniform and join the others currently deployed in Iraq). The author gives the reader great insight on just what motivates these individuals, with a few of them being unknown to this reviewer. One would have liked more discussion on their connection with foreign governments, especially Israel, if this information is available.<br /><br />Paul Wolfowitz, Richard Perle, Douglas Feith, David Wurmser, David Frum, William Kristol, and John Bolton, along with Donald Rumsfeld, Richard Cheney and George W. Bush are all the perfect clones of the fabled Lieutenant Keefer of the Woukian war novel. Keefer encourages acts of courage and daring, but manages to keep his shirts starched and cleaned while others do the dirty work. Each of them no doubt will make a million dollars writing their memoirs when this whole Iraq mess is over, and then live with their consciences, if they have any. They should all have at least a cocktail splashed in their faces, with a challenge to meet them outside if they want to do anything about it.<br /><br />One would have to be a lot drunker than they though, so it would be a fair fight.glas Feith, David Wurmser, David Frum, William Kristol, and John Bolton, along with Donald Rumsfeld, Richard Cheney and George W. Bush are all the perfect clones of the fabled Lieutenant Keefer of the Woukian war novel. Keefer encourages acts of courage and daring, but manages to keep his shirts starched and cleaned while others do the dirty work. Each of them no doubt will make a million dollars writing their memoirs when this whole Iraq mess is over, and then live with their consciences, if they have any. They should all have at least a cocktail splashed in their faces, with a challenge to meet them outside if they want to do anything about it.  <br /> <br />One would have to be a lot drunker than they though, so it would be a fair fight.	2004-09-06
537976:US	50702879	R2AHLE4ZJRCLRI	0262100770	153526032	Systems That Learn - 2nd Edition: An Introduction to Learning Theory (Learning, Development, and Conceptual Change)	Books	4	2	3	N	Y	Insightful introduction to computational learning theory	Concentrating on the mathematical and formal underpinnings of learning theory, this book gives a very interesting and general overview of the subject. Basing their discussion on the learning of \\"texts\\" and the learning of \\"functions\\", the authors address the main issues in the formal modeling of empirical inquiry. The models or \\"paradigms\\" they construct are based on five concepts, which they consider of central importance in empirical inquiry. These concepts are: (1) A reality that is theoretically possible; (2) hypotheses that are intelligible; (3) the data that is available about a given reality; (4) a model of a scientist; (5) the successful behavior of the scientist who is investigating a possible reality. The scientist is thought of as playing a game with Nature, with the class of possible realities being known to each of them initially. Nature selects a member from this class, initially unknown to the scientist. After providing a series of clues (data) to the scientist, the scientist forms hypotheses based on these clues. The scientist wins the game if the hypotheses become stable and accurate. The game is easier to win the more constrained Nature's choice of actual world is.<br /><br /> After a brief philosophical discussion of the paradigms and a review of the theory of computation, the authors begin their study by concentrating on identification of languages and identification of functions. Both of these are considered to be `theoretically possible realities', and in the case of languages, it is \\"texts\\" that are to be identified by scientists. Those texts that can are called `identifiable' and the authors prove a theorem that characterizes how scientists identify languages in terms of finite strings of text. Success in function identification is cast as a generalization of that of text. In this case the class of possible realities are the collection of total recursive functions, and hypotheses are programs that compute these functions. The authors show however that a scientist who identifies the entire class of recursive functions cannot be computable. Very interesting in this discussion is the treatment of `parametrized scientists', i.e. those scientists who can incorporate background knowledge from other scientists.<br /><br /> These considerations involve the view of a scientist as being a certain fixed entity. The authors also consider cases where alternative notions of scientist occur, but the other paradigms are held fixed. The abilities of computable scientists who deploy different inductive `strategies' are studied, with the goal of finding out if a member of a particular strategy can effectively identify languages or functions. Recognizing that the conjectures proposed successively by a particular scientist may not be related to one another, the authors then discuss strategies that result from imposing relations between the conjectures. One of these, called `conservative', insists that a conjecture that generates all the data observed to date should never be abandoned. Also discussed are `generalization strategies' that require scientists to improve upon their successive conjectures. One example of these strategies is called `strong-monotonic', which forbids the revision of a hypothesis if it made a mistake in identification. Another example is called `weak monotonic', which allows the rejection of parts of a hypothesis if it encounters data that cannot be accounted for by this hypothesis. Still another is `monotonic', which allows the correction of mistaken hypotheses, but does not allow hypotheses that will contradict correct classifications. The authors show that monotonicity does not imply weak-monotonicity, and vice versa. Also discussed are `specialization' strategies, which are \\"dual\\" to the three generalization strategies, and which involve the pruning of hypotheses in order to obtain convergence.<br /><br /> The authors also address the case where the conception of a scientist is held fixed, but thecriteria for scientific success are varied. This study, in the opinion of this reviewer, more accurately reflects the real behavior of scientists, who typically use very liberal notions of accuracy. For example, anomalies in data could be tolerated, pending alteration of the hypotheses in the future. These anomalies in fact serve to drive further research, with the goal of finding hypotheses or theories that resolve them. It is typically the case, if not always, that the hypotheses are considered approximate explanations, and so one would expect that the authors' discussion would revolve around the consideration of inference of approximations. The authors though do give an interesting twist to this discussion, namely, they attempt to find criteria for success that actually permit an infinite number of anomalies in the final explanations. This serves to better characterize explanations, they argue. A series of identification criteria are outlined each of which involves measure-theoretic notions of `asymptotic agreement.' A scientist presented with a function must arrive at an explanation that agrees asymptotically with the function up to a prespecified amount.<br /><br /> Also more realistic, due to its emphasis on what happens in actual scientific investigation, is the authors' discussion on alternative conceptions of available data. Noting that data can be missing or have errors, and is presented in a definite order to a scientist, the authors study how to deal with error in the finding of intelligible hypotheses. Their results delineate the extent to which inaccurate data can impede the learning process, with three kinds of \\"inaccurate\\" data considered: \\"incomplete\\", \\"noisy\\", and \\"imperfect.\\"<br /><br /> Other topics discussed include the modeling of empirical inquiry when many scientists are collaborating with each other, and that of probabilistic learning. For team identification of functions, several interesting results are proven, but the authors admit that their results do not apply to the (more realistic) scenario where the hypotheses of each individual scientist influence each other. Also discussed are \\"oracle\\" scientists, who use information of a noncomputable nature, or \\"information oracles\\", in order to perform identifications. When judged by how much information can be given to the scientist, oracles can be \\"omniscient\\" or \\"trivial\\", and it is thus of interest to determine how much oracles can supply scientists in their identification of functions. The authors discuss various results on this topic, showing how much is to be gained by allowing oracle scientists to make additional queries.but the criteria for scientific success are varied. This study, in the opinion of this reviewer, more accurately reflects the real behavior of scientists, who typically use very liberal notions of accuracy. For example, anomalies in data could be tolerated, pending alteration of the hypotheses in the future. These anomalies in fact serve to drive further research, with the goal of finding hypotheses or theories that resolve them. It is typically the case, if not always, that the hypotheses are considered approximate explanations, and so one would expect that the authors' discussion would revolve around the consideration of inference of approximations. The authors though do give an interesting twist to this discussion, namely, they attempt to find criteria for success that actually permit an infinite number of anomalies in the final explanations. This serves to better characterize explanations, they argue. A series of identification criteria are outlined each of which involves measure-theoretic notions of `asymptotic agreement.' A scientist presented with a function must arrive at an explanation that agrees asymptotically with the function up to a prespecified amount.  <br /> <br /> Also more realistic, due to its emphasis on what happens in actual scientific investigation, is the authors' discussion on alternative conceptions of available data. Noting that data can be missing or have errors, and is presented in a definite order to a scientist, the authors study how to deal with error in the finding of intelligible hypotheses. Their results delineate the extent to which inaccurate data can impede the learning process, with three kinds of \\"inaccurate\\" data considered: \\"incomplete\\", \\"noisy\\", and \\"imperfect.\\" <br /> <br /> Other topics discussed include the modeling of empirical inquiry when many scientists are collaborating with each other, and that of probabilistic learning. For team identification of functions, several interesting results are proven, but the authorsadmit that their results do not apply to the (more realistic) scenario where the hypotheses of each individual scientist influence each other. Also discussed are \\"oracle\\" scientists, who use information of a noncomputable nature, or \\"information oracles\\", in order to perform identifications. When judged by how much information can be given to the scientist, oracles can be \\"omniscient\\" or \\"trivial\\", and it is thus of interest to determine how much oracles can supply scientists in their identification of functions. The authors discuss various results on this topic, showing how much is to be gained by allowing oracle scientists to make additional queries.  <br />	2004-08-31
543490:US	50702879	RNNCPRFERV0KM	0471438545	611547151	Engineering of Mind: An Introduction to the Science of Intelligent Systems	Books	4	1	1	N	Y	Some interesting proposals for building intelligent machines	The authors of this book are very ambitious in their goals, for in the book they attempt to outline in some detail how to design a machine that is not only intelligent but can function in more than one domain. A machine that could not only beat the world champion at chess but could also create food recipes would be an example of a machine that can think in more than one domain. Certainly one would view such a machine as intelligent, at least from a qualitative standpoint, without having an explicit way of measuring intelligence.<br /><br /> The authors actually define intelligence as an ability to behave appropriately in an uncertain environment, i.e. an entity that is intelligent will engage in behavior that maximizes the likelihood of success in the achievement of its goals. With this definition, they hope to capture the intelligence of many different entities, both biological and otherwise. Intelligence is not to be defined as an either/or proposition, but instead is graded, and there are many examples of it in systems in the real world, both natural and man-made. Intelligence can therefore exist in degrees, these being determined by the computational power and memory capacity of the brain of the machine, the processes the machine uses for obtaining data from the environment, and the quality of the data stored in memory. Different levels of intelligence, the authors believe, produce different probabilities of success in achieving goals. They do not give explicit examples of how these probabilities vary with the levels however. It would be very interesting to see these examples worked out in detail, for it would give the reader a more quantitative (and useful) notion of \\"machine IQ.\\"<br /><br /> One area of discussion that particularly stands out in the book deals with knowledge representation. Instead of representing everything symbolically via logical theorems, expert system rules, or linguistic grammars, the authors explicitly reject the symbol manipulation systems and instead want to represent knowledge using images or maps. This is interesting because of the high computational demands placed on a machine in performing image processing. The authors are aware of this, and so propose using parallel computation in the image and map domains combined with doing analysis in time and frequency space. This is to be done in a \\"multilevel architecture of dynamic recursive loops.\\" Most of the book is devoted to explaining how to engineer this architecture. Heavy use is made of control theory to do this.<br /><br /> The authors recognize that much remains unknown about the nature of intelligent behavior, but that the concept of a \\"goal\\" is central to ascribing intelligence to an entity. The greater the intelligence of an entity the more ingenious the entity is in dealing with unexpected events or challenges, and predicting the future is an ability possessed by the most intelligent entities. The rather extreme view of intelligence as expressed in this last statement is of course a logical consequence of the author's assertions. Needless to say, no example of an entity that can predict the future is given in the book.<br /><br /> Since goal seeking is an essential characteristic of an intelligent machine, then the machine has to be able to make plans in order to reach its goals. The authors outline discuss two approaches to implementing a planning architecture. One of these is computationally expensive and involves frequently replanning, in order to deal with unpredictability of the environment. The other approach is to use feedback from sensors in order that the planned actions can be modified as needed. The authors outline several different heuristics that could be used to search for plans, and settle on a notion of `hierarchical multiresolutional planning'. This type of planning involves partitioning the planning process into hierarchical layers so that the search space is effectively reduced at each level of the planning hierarchy.<br /><br /> In order for the authors to convince the reader that their efforts will be fruitful in designing an intelligent machine, they devote over two-thirds of the book to the real-world construction of such a machine. This is done by first discussing a reference model architecture, called RCS (for Real-Time Control System), that expresses their computational model of intelligence. The believe that the RCS architecture will allow the eventual design of intelligent machines that can meet specified requirements. Again, their project is very ambitious, due to the many capabilities that the RCS architecture must have. Without observing the machine actually working it would be difficult to verify whether or not they authors have succeeded in their goals. They do however give detailed explanations of the architecture, including line drawings and relevant mathematics, making their approach seem highly plausible. In addition, they give examples involving unmanned military ground vehicles that illustrate the principles they have outlined.<br /><br /> The last chapter of the book is a look toward the future, and the authors, like all others who work in artificial intelligence, feel obligated to address the anxiety felt by some regarding the development of intelligent machines. Hollywood and popular literature is replete with examples of malevolent machines bent on the destruction of humankind or at least taking employment opportunities away from humans. The authors though remain refreshingly optimistic and rightfully dismiss these Hollywood/literary fantasies. They argue well for the productivity gains and positive social impact of intelligent machines. One can confidently look forward to the presence of millions of artificial intelligent machines in the twenty-first century, some of the architectures of which may be similar to the ones that are delineated in this book.ng hierarchy.  <br /> <br /> In order for the authors to convince the reader that their efforts will be fruitful in designing an intelligent machine, they devote over two-thirds of the book to the real-world construction of such a machine. This is done by first discussing a reference model architecture, called RCS (for Real-Time Control System), that expresses their computational model of intelligence. The believe that the RCS architecture will allow the eventual design of intelligent machines that can meet specified requirements. Again, their project is very ambitious, due to the many capabilities that the RCS architecture must have. Without observing the machine actually working it would be difficult to verify whether or not they authors have succeeded in their goals. They do however give detailed explanations of the architecture, including line drawings and relevant mathematics, making their approach seem highly plausible. In addition, they give examples involving unmanned military ground vehicles that illustrate the principles they have outlined.  <br /> <br /> The last chapter of the book is a look toward the future, and the authors, like all others who work in artificial intelligence, feel obligated to address the anxiety felt by some regarding the development of intelligent machines. Hollywood and popular literature is replete with examples of malevolent machines bent on the destruction of humankind or at least taking employment opportunities away from humans. The authors though remain refreshingly optimistic and rightfully dismiss these Hollywood/literary fantasies. They argue well for the productivity gains and positive social impact of intelligent machines. One can confidently look forward to the presence of millions of artificial intelligent machines in the twenty-first century, some of the architectures of which may be similar to the ones that are delineated in this book.	2004-08-25
548346:US	50702879	R3HLZSW1VHYMS4	0060736704	717178025	Bush on the Couch: Inside the Mind of the President	Books	3	16	45	N	Y	Interesting reading....but mere opinions	The author begins this book by wondering why Bush tolerates increased arsenic in the public water supply, while promising to protect the environment. The author though does not give any evidence as to what levels of arsenic really are a serious threat to human health. The author wonders why Bush wants to lift logging restrictions but still wants to call it the \\"Healthy Forest\\" initiative. The author though does not quote any scientific studies that quantify how many trees can be felled before the forest is considered \\"unhealthy\\". Will cutting down one tree threaten the forest? Two? Ten thousand? The author considers these inconsistencies relevant to understanding Bush's mental health, but they seem more like disagreements as to what constitutes sound policy.  Both Bush and the author are guilty of not providing scientific evidence for their assertions. They are not alone in this regard, as many in both government and the private sector typically make claims that are totally unjustified from a scientific viewpoint. The author calls Bush a \\"case study in contradiction\\", but contradictions and inconsistencies in public pronouncements are very common in many individuals, and so accepting these contradictions as signs of mental disturbance would seem unjustified.<br /><br /> But psychoanalysts seem to have rigid criteria for judging what is normal. As one peruses the literature on psychoanalysis, especially the works of Freud and his followers, it becomes readily apparent that what is considered normal would result in most of the people in the world being judged as \\"abnormal.\\" Indeed, Freud expressed this by saying that everyone is \\"slightly neurotic.\\" On the surface, Bush certainly has some odd personal quirks that might cause one to question his stability. It would be difficult though to judge his behavior as \\"unstable\\" without putting many others in the population in this same category. How much different is Bush from the \\"normal\\" population that would justify labeling him as mentally unstable? In the first paragraph in the book, the author is troubled by what he thinks is an \\"oversimplified\\" distinction between right and wrong, good and evil, and allies an enemies, in the mind of Bush. But there perhaps millions of people, typically very religious people, that have the same opinions as does Bush on the nature of good and evil, and do not bother to analyze their beliefs on these matters. Would we want to consider all of these people unstable?<br /><br />The author offers personal opinions on the mental soundness of Bush, based on his experience with his own patients. However he does not back up his assertions with statistical sampling or other types of quantitative analysis. The psychoanalytic school typically does not make use of these techniques, unfortunately. One should consider this book as a collection of educated guesses, requiring a lot of insight possibly, but not delivering a rational, coherent, and sound picture of the mind of George W. Bush.him as mentally unstable? In the first paragraph in the book, the author is troubled by what he thinks is an \\"oversimplified\\" distinction between right and wrong, good and evil, and allies an enemies, in the mind of Bush. But there perhaps millions of people, typically very religious people, that have the same opinions as does Bush on the nature of good and evil, and do not bother to analyze their beliefs on these matters. Would we want to consider all of these people unstable?     The author offers personal opinions on the mental soundness of Bush, based on his experience with his own patients. However he does not back up his assertions with statistical sampling or other types of quantitative analysis. The psychoanalytic school typically does not make use of these techniques, unfortunately. One should consider this book as a collection of educated guesses, requiring a lot of insight possibly, but not delivering a rational, coherent, and sound picture of the mind of George W. Bush.	2004-08-21
558170:US	50702879	R1VSVJSUHK0NJ	0471193747	325010586	Intelligent Systems: Architecture, Design, and Control	Books	4	6	6	N	Y	Clarifies many of the issues	If a machine can act appropriately in an \\"uncertain\\" environment, i.e. if the machine is able to increase its probability of success via the execution of this action, then the machine should be designated as intelligent according to the authors of this book. The success of an action is defined as the achieving of subgoals that allow the machine to achieve its ultimate goal. The criteria for success and the ultimate goal are however defined by an observer or entity that is external to the machine. Thus an intelligent machine requires assessment from this observer in order to judge whether its actions are indeed successful. It is unable to make that assessment itself.<br /><br />The authors spend a great deal of time elaborating on this notion of intelligence and how to actually incorporate it in real machines. Central to the authors' notion of intelligence is the ability of a machine to do searching and to engage in the formation of combinations, as well as the ability to group, cluster, or lump entities together into sets and to focus attention on the details of data or perceptions while ignoring the rest. The authors also assert that there are degrees or levels of intelligence that are determined by the computational power of the \\"brain\\" of the machine, the algorithms that are used by the machine, the information stored in its memory, and the sophistication of the processes that run the machine.<br /><br />The authors also believe that the intelligence of a machine can also increase and evolve, due to increases in computational power and knowledge. A machine can become more intelligent only through learning through experiences. The authors are careful to note that learning is not required for a machine to be intelligent, but is required if the machine is to become more intelligent. They do not quantify though how much more intelligent a given machine can be as a result of learning. Can a machine become twice as intelligent after the process of learning? How about three times as intelligent? How exactly does the intelligence scale as the learning process is active?<br /><br />An entire chapter of the book is spent on what actually constitutes learning in machines. The authors distinguish between `quantitative' or `parametrical' learning, and `cognitive' learning. The former is associated with adaptive systems where these systems can adjust to a changing environment. The latter is associated with a situation where the machine hesitates to make further generalizations or continue to \\"tune\\" itself. The authors list several axioms that they believe every learning system must satisfy. These axioms go by the names of representation, control, plant, goal, observables, and system. In a nutshell, they assert that any reality can be modeled, that a control system exists, that a system exists that is controlled, that a goal set and output specifications exists, that a set of observables can be measured or recorded, and that there is a basic \\"system level\\" description of the intelligent machine. In addition, a `learning control system' is introduced that is basically a control system that generates input according to a control law that is constantly redefined and recomputed.<br /><br />To build an intelligent machine that will rival the performance of natural intelligences, the authors attempt to build a computational model of intelligence that consists of a closed loop of four fundamental processes. These processes are `behavior generation', `world modeling', `sensory processing', and `value judgment', and they work together so as to process sensory information, use and maintain knowledge bases, and to engage in goal-directed behavior. These processes are quite sophisticated and any intelligent machine must be capable of engaging in all of them, according to the authors. Indeed, their sensory processing function does not merely gather sensory information, but also detects and groups features, engages in object recognition, and compares observations with expectations. World modeling involves the construction of representations of various entities, events, and situations and also makes predictions, generates beliefs, and formulates estimates of the probable results of future actions. Value judgment computes the costs and benefits of various plans, along with performing risk analysis and calculating expected payoffs for these plans.<br /><br />Their construction of intelligent systems is based on an architecture that organizes the joint functioning of devices that are not intelligent themselves. The architecture involves something called `functional closure', the construction of representations of the environment, learning via generalization, and algorithms that `self-reference.' An `elementary loop of functioning' (ELF) is used to organize a simple loop of activities involving the sensory processing (SP), the world model (WM), and behavior generation (BG) capabilities of the machine. This architecture is considered to be able to \\"perpetuate its own existence\\" and is therefore called a `generalized subsistence machine' by the authors. The fundamental property of an ELF is to exist as a goal-seeking machine, and ELFs can be part of other ELFs. Each ELF consists of a part that handles goal-directed functioning and a part that handles the regular subsistence functioning. The authors give a real-world example of this architecture, the NIST-RCS architecture, the name of which reflects the authors' host institution.<br /><br />Particularly interesting is the authors' discussion of value judgments. Value judgments, according to the authors, provide criteria for making intelligent choices. This includes the cost and risk analysis of plans and actions, and the desirability of various objects. It is the view of the authors that machine intelligence cannot be achieved if the machine is unable to perform value judgments. This leads them into making definitions of emotions, priorities, and drives, and then to a notion of a `value state-variable', examples of which include goodness, pleasure, pain, hope, frustration, hate, fear, and confidence. The values for the state-variables are determined by the `value judgment functions' that reside in `value judgment modules' of the machine. A value judgment function takes an input state vector which describes the conditions in the world model and produces an output vector consisting of value state-variables.d compares observations with expectations. World modeling involves the construction of representations of various entities, events, and situations and also makes predictions, generates beliefs, and formulates estimates of the probable results of future actions. Value judgment computes the costs and benefits of various plans, along with performing risk analysis and calculating expected payoffs for these plans. <br /> <br />Their construction of intelligent systems is based on an architecture that organizes the joint functioning of devices that are not intelligent themselves. The architecture involves something called `functional closure', the construction of representations of the environment, learning via generalization, and algorithms that `self-reference.' An `elementary loop of functioning' (ELF) is used to organize a simple loop of activities involving the sensory processing (SP), the world model (WM), and behavior generation (BG) capabilities of the machine. This architecture is considered to be able to \\"perpetuate its own existence\\" and is therefore called a `generalized subsistence machine' by the authors. The fundamental property of an ELF is to exist as a goal-seeking machine, and ELFs can be part of other ELFs. Each ELF consists of a part that handles goal-directed functioning and a part that handles the regular subsistence functioning. The authors give a real-world example of this architecture, the NIST-RCS architecture, the name of which reflects the authors' host institution.  <br /> <br />Particularly interesting is the authors' discussion of value judgments. Value judgments, according to the authors, provide criteria for making intelligent choices. This includes the cost and risk analysis of plans and actions, and the desirability of various objects. It is the view of the authors that machine intelligence cannot be achieved if the machine is unable to perform value judgments. This leads them into making definitions of emotions, priorities, and drives,and then to a notion of a `value state-variable', examples of which include goodness, pleasure, pain, hope, frustration, hate, fear, and confidence. The values for the state-variables are determined by the `value judgment functions' that reside in `value judgment modules' of the machine. A value judgment function takes an input state vector which describes the conditions in the world model and produces an output vector consisting of value state-variables.	2004-08-12
561423:US	50702879	R3R5A0W3Y97M12	039915258X	346813546	Bushworld	Books	5	202	274	N	Y	Powerful words from the auburn Cobra.	Sassy, witty, and possessing saliva that is definitely acidic, this author, via the acerbic commentary in her columns, gives the reader a delightful overview of three administrations that have zero intersection in their ideologies, but almost total agreement in their practices, hypocrisies, and brutalities. The worrywort Bush 41, the over-active-libido Clinton, and the verbally stymied Bush 43 get accurate representation in this book, as do some of their cohorts in political manipulation and distortion. The author though clearly defines current political reality in terms of the mentally challenged young boy who currently lives in the White House. This boy has created a world that is unequaled in the sheer audacity of its actions and brutality. It is a world populated by cheaters, manipulators, and yellow bellies. It is a world where cowardice is hidden behind tact and prudence, and where bravado masquerades as courage. It is a world where wars are waged under the guise of national security, and a world whose leaders are dumbfounded about the nature of cause and effect.<br /><br /> The author gives clever names to the individuals who have contributed their (extremely limited) talents to the creation of Bushworld. The \\"quiet American\\" Dick Cheney, who dares not speak up lest his real nature and many personal insecurities be revealed, has most fittingly been given the name \\"Uncle Dick of the Underworld.\\" A true villain, and the most evil of all those who have created Bushworld, Uncle Dick is afraid of letting others know exactly who he is: a weak and cowardly individual who is perfectly content with sending others to war, but has steadfastly avoided it himself. Uncle Dick is a pseudo-intellectual who confuses the creation of wealth with its plundering, and is the perfect Lieutenant Keefer, most assuredly deserving a cocktail be splashed in his face, and one that any person of integrity would like to challenge to a boxing match (one would have to be very drunk though, so as to make it a fair fight).<br /><br /> It is definitely a catharsis to read the author's columns over the last few years. They relieve some of the mental tension that builds up after hearing about another American and Iraqi death. Political commentary, like literature and dance, can give momentary solace. But thankfully it does not tranquilize: it does not impede one from taking appropriate action. Like a good mystery or difficult mathematics, it stimulates the brain into finding an algorithm to alleviate the suffering caused by the creators of Bushworld.<br /><br /> There is nothing surreal about Bushworld, despite the comical flavor that is sometimes imputed to it in this book. We can chuckle at the Dowd characterization of Bushworld as well as mourn for those whose lives have been terminated in it. We can get angry at Bushworld for its flippant disregard for history, and raise our fists in defiance at its stupidity, sadism and arrogance. But, we don't have to live and die in Bushworld: we can pull down the autumn lever and dissolve it entirely.h, so as to make it a fair fight).  <br /> <br /> It is definitely a catharsis to read the author's columns over the last few years. They relieve some of the mental tension that builds up after hearing about another American and Iraqi death. Political commentary, like literature and dance, can give momentary solace. But thankfully it does not tranquilize: it does not impede one from taking appropriate action. Like a good mystery or difficult mathematics, it stimulates the brain into finding an algorithm to alleviate the suffering caused by the creators of Bushworld.  <br /> <br /> There is nothing surreal about Bushworld, despite the comical flavor that is sometimes imputed to it in this book. We can chuckle at the Dowd characterization of Bushworld as well as mourn for those whose lives have been terminated in it. We can get angry at Bushworld for its flippant disregard for history, and raise our fists in defiance at its stupidity, sadism and arrogance. But, we don't have to live and die in Bushworld: we can pull down the autumn lever and dissolve it entirely.	2004-08-09
569928:US	50702879	R1OGWEI3MXTVG2	1860944272	330867044	An Introduction to String Theory and D-Brane Dynamics	Books	4	51	53	N	Y	A little short but does its job.	From a mathematical perspective, string theory, and its modern metamorphosis, M-theory, is the most complex physical theory ever constructed. From a physical and experimental perspective, these theories completely lack any support. Mathematical elegance and the need for a consistent physical theory have driven the research in string theory, and to this day it remains one of the hottest, if not the most esoteric, topics in theoretical physics. Those physicists with a penchant towards mathematics have joined the ranks of those doing research in string theory. Mathematicians are also benefiting immensely from the insights that string theory offers to myriads of concepts and results in mathematics.<br /><br /> This book gives a very quick overview of the main results in string and M-theory, and would be suitable only for those readers who have had a lot of prior exposure to the subject. There are no in-depth explanations given for the physical and mathematical concepts needed in string and M-theories in the book, and therefore it might be difficult for the newcomer curious about these theories to gain an appreciation of them. The mathematics behind these theories is formidable, requiring years of study to digest, and the insight and motivation behind this mathematics is usually not given in the literature, unfortunately.<br /><br /> After a brief discussion of the history of string theory in chapter 1, and also a very brief discussion of the classical dynamics of strings in chapter 2, the author begins a study of how to quantize the bosonic string in chapter 3. This is done using the familiar canonical quantization of quantum field theory but here applied to the (1+1)-dimensional worldsheet field theory. The mass-shell constraints of classical string dynamics appearing as Virasoro operators are subjected to normal ordering in the quantization procedure. The origin of the bosonic critical dimension of spacetime as 26 is not explained in enough detail that will allow the reader to appreciate it. Also discussed, but only briefly, are the `vertex operators', which have become very important recently, especially in mathematics. In this book vertex operators are introduced as an analogy to the operator-state correspondence that is found in ordinary quantum field theory.<br /><br /> Superstring theory is studied in chapter 4, motivated by the need for eliminating tachyonic states and for including fermions in the spectrum. The Ramond-Neveu-Schwarz (RNS) and light-cone Green-Schwarz formalisms are mentioned as two techniques for dealing with superstrings, but the author only uses the RNS formalism in the book. The role of boundary conditions as the origin of the Ramond (R) and Neveu-Schwartz (NS) sectors is explained very well, but the author leaves to the reader (as an exercise) the canonical quantization of the superstring. The origin of the superstring critical dimension as 10 is thus delegated to the reader. The ubiquitous `GSO projection' is introduced as a device for making the theory of interacting strings consistent, one example being the elimination of tachyonic states. The GSO projection is discussed in both the NS and R sectors. The modular invariance of the bosonic string partition function is left as an exercise for the reader. The author does explain well the origin of `spin structures', i.e. their connection with the introduction of fermions, and the consequent use in the superstring theory to get rid of the tachyonic instability. He gives brief discussions of the five different types of string theories, but restricts himself to only Type II superstrings in the remainder of the book. The origin of the famous `T-duality' for closed strings and its relation to the existence of D-branes in superstring theory is explained very well. The author assigns a very interesting exercise for the reader on showing that T-duality interchanges the definition of normal and tangential derivatives, and therefore exchanges Neumann and Dirichlet boundary conditions. This exercise, in this reviewer's opinion, should eliminate sometimes held view of T-duality as being somewhat mysterious. D-branes are explained as being essential for superstring theory, in that there are missing R-R charges in the perturbative string states, i.e. the vertex operators for the R-R states only involve the fields. The D-branes are thus nonperturbative states that carry the R-R charges.<br /><br /> D-branes and their (fascinating) relation to gauge theory are discussed in detail in chapter 6, their dynamics in chapter 7, and their R-R couplings in the last chapter. D-branes are described nonperturbatively, with the massless modes of open strings equated to the fluctuations of D-branes. Massless fields are interpreted as a 10-dimensional gauge theory on the D-brane worldvolume. The guage fields have components as U(1) gauge fields on the D-brane as well as scalar field components that describe the fluctuations of the D-brane. The gauge theory is actually, and most interestingly, a dimensional reduction to the D-brane of supersymmetric Yang-Mills theory. Via a consideration of Wilson lines of the gauge fields, the author shows how T-duality maps gauge fields in open string theory to positions on the D-branes. The dynamics of D-branes is further described in terms of (supersymmetric Yang-Mills) gauge theory, giving the famous AdS/CFT correspondence. This correspondence is quite exciting if one views it from the standpoint of how difficult it is to do nonperturbative calculations in gauge theories. Interactions between D-branes are studied, and the author describes the coincidence (resulting from spacetime supersymmetry) between the D-brane tension and the R-R charge, i.e. that the R-R repulsion between parallel D-branes cancels their gravitational and dilaton attraction. A brief discussion is given of `BPS states' and their relation to D-branes, i.e. that a D-brane is a state that preserves only half of the spacetime supersymmetries. In addition, and similar to the case in gauge field theories where chirality is present, anomalies can arise in D-branes. These arise, as the author shows, on the chiral worldvolume field theory on the intersection of two or more D-branes. Requiring anomaly cancellation will determine completely the coupling between the D-brane and the fields of the R-R sector.d Dirichlet boundary conditions. This exercise, in this reviewer's opinion, should eliminate sometimes held view of T-duality as being somewhat mysterious. D-branes are explained as being essential for superstring theory, in that there are missing R-R charges in the perturbative string states, i.e. the vertex operators for the R-R states only involve the fields. The D-branes are thus nonperturbative states that carry the R-R charges.  <br /> <br /> D-branes and their (fascinating) relation to gauge theory are discussed in detail in chapter 6, their dynamics in chapter 7, and their R-R couplings in the last chapter. D-branes are described nonperturbatively, with the massless modes of open strings equated to the fluctuations of D-branes. Massless fields are interpreted as a 10-dimensional gauge theory on the D-brane worldvolume. The guage fields have components as U(1) gauge fields on the D-brane as well as scalar field components that describe the fluctuations of the D-brane. The gauge theory is actually, and most interestingly, a dimensional reduction to the D-brane of supersymmetric Yang-Mills theory. Via a consideration of Wilson lines of the gauge fields, the author shows how T-duality maps gauge fields in open string theory to positions on the D-branes. The dynamics of D-branes is further described in terms of (supersymmetric Yang-Mills) gauge theory, giving the famous AdS/CFT correspondence. This correspondence is quite exciting if one views it from the standpoint of how difficult it is to do nonperturbative calculations in gauge theories. Interactions between D-branes are studied, and the author describes the coincidence (resulting from spacetime supersymmetry) between the D-brane tension and the R-R charge, i.e. that the R-R repulsion between parallel D-branes cancels their gravitational and dilaton attraction. A brief discussion is given of `BPS states' and their relation to D-branes, i.e. that a D-brane is a state that preserves only half of the spacetime supersymmetries. In addition, and similar to the case in gauge field theories where chirality is present, anomalies can arise in D-branes. These arise, as the author shows, on the chiral worldvolume field theory on the intersection of two or more D-branes. Requiring anomaly cancellation will determine completely the coupling between the D-brane and the fields of the R-R sector.	2004-08-01
575471:US	50702879	R2U3JGJLTIRZP4	0415314534	1289731	The Creative Mind: Myths and Mechanisms	Books	5	14	15	N	N	Superb	The nature and origins of creativity is of great interest in the field of human psychology, and research on creativity has occupied the time of many individuals. This book, written by an individual well recognized in the field, gives a fascinating account of her ideas on creativity, and has been a major influence for those attempting to realize creativity in non-human machines. Throughout its pages, the author attempts not only to define creativity, but also to give criteria for distinguishing new ideas that are creative from simply new ideas. The most important goal of the book though is to frame the nature of creativity in a computational paradigm.<br /><br /> Philosophers, writers, artists, musicians, and others in the humanities will perhaps frown on the author's project to use computational concepts to assist in the understanding of human creativity. Many of those who work in these professions will point to \\"intuition\\" as being the source of creative ideas and works, regardless of their vague understanding of this term. The author demands, rightfully, a clarification of the notion of intuition, but she does not seek to do this herself in the book, but instead looks to the computational paradigm to settle the issue of human and machine creativity. She argues at length throughout the book that not only can this paradigm assist in the understanding of human creativity, but that non-human machines can appear to be creative and can also recognize creativity. The question as to whether non-human machines really are creative is also addressed towards the end of book.<br /><br /> Having a computational model of creativity would allow the design of machines that could produce novel scientific theories, musical compositions, architectural designs, and works of art. It would also give those working in the cognitive sciences greater insight into the understanding of the mechanisms involved in human creative thinking, such as the ability to make analogies, formulate complicated mathematical ideas, or classify patterns. In addition, having a generic computational model of creativity would give insight on how to create novel ideas in a manner that is independent of the domain or context in which one is working. Machines could thus be built that would be able to generate creative ideas in many different domains. For example, a machine that generates new mathematical ideas would also be able to create interesting works of art. This would be a major advance in machine intelligence if such machines could be built.<br /><br /> In the book, the author introduces two notions of creativity that she feels is necessary for her study. One of these is called 'P-creativity', and is a personal and psychological notion. The other is called 'H-creativity' and is a historical notion. Given an idea that arises in a particular person, this idea would be called P-creative if the person could not have had it before. It is irrelevant how many other people already have the same idea. An idea is called H-creative if it is P-creative and no one in human history has ever had it before. As can be seen from the definition, it would be difficult to check whether an idea is really H-creative, since it would require quite an extensive statistical survey. But such a survey would be unnecessary, for the author contends that there is no theory that can explain solely H-creative ideas, but that since H-creative ideas are also P-creative, an explanation of P-creative ideas would also apply to H-creative ideas.<br /><br /> According to the author, the ability to distinguish first-time novelty from genuine originality involves an understanding of what generative processes were involved in the production of the idea. A \\"novel\\" idea is one that can be described or produced by the same set of generative rules as other familiar ideas, whereas a genuinely original idea is one that cannot. Therefore, the designation of ideas as \\"genuinely creative\\" is always done relative to a specific generative system.<br /><br /> Conceptual spaces, in the author's view, are styles of thinking, and creativity must be thought of in terms of the mapping, exploration, and transformation of conceptual spaces. Conceptual spaces are used to organize and give structure to a particular domain of interest, such as checkers game or a Bach concerto. The structure of a conceptual space can be mapped by forming mental representations of it, and these maps can be use to explore them and to change them if necessary. As one example of this, the author quotes the investigations of tonal harmony in post-Renaissance Western music. The dropping of the home-key constraint in tonal music transformed the conceptual space of tonal music to create the conceptual space of atonal music. The deliberate dropping of a constraint is one method by which conceptual spaces can be generated. Another method is to negate a constraint. The author illustrates this method with a discussion of the discovery of the benzene ring due to Friederich Kekule.<br /><br /> A highly interesting and totally unexpected discussion in the book involves the connection of unpredictability with creativity. Since H-creative ideas are ones that have not appeared before in human history, they are unpredicted. The author emphasizes though that this does not mean that H-creative ideas are unpredictable. The role of serendipity, chance, and coincidences in creative thinking are discussed in terms of the computational paradigm. The author concludes from this discussion that creativity cannot be due to chance alone, but that chance with judgment can. The author also discusses three different notions of randomness, with the intent of shedding light on the belief that determinism is incompatible with creativity. These three notions are labeled 'absolute', 'explanatory', and 'relative'.  The first is total absence of any order or structure within the domain; the second the lack of any explanation or cause, and the third lack of any order relevant to some specific consideration. Human creativity is relatively unpredictable the author asserts, and it is easy to believe this considering our folklore understanding of it. The computational paradigm of the author has assisted our understanding of it, but more research is needed.ative to a specific generative system.  <br /> <br /> Conceptual spaces, in the author's view, are styles of thinking, and creativity must be thought of in terms of the mapping, exploration, and transformation of conceptual spaces. Conceptual spaces are used to organize and give structure to a particular domain of interest, such as checkers game or a Bach concerto. The structure of a conceptual space can be mapped by forming mental representations of it, and these maps can be use to explore them and to change them if necessary. As one example of this, the author quotes the investigations of tonal harmony in post-Renaissance Western music. The dropping of the home-key constraint in tonal music transformed the conceptual space of tonal music to create the conceptual space of atonal music. The deliberate dropping of a constraint is one method by which conceptual spaces can be generated. Another method is to negate a constraint. The author illustrates this method with a discussion of the discovery of the benzene ring due to Friederich Kekule.  <br /> <br /> A highly interesting and totally unexpected discussion in the book involves the connection of unpredictability with creativity. Since H-creative ideas are ones that have not appeared before in human history, they are unpredicted. The author emphasizes though that this does not mean that H-creative ideas are unpredictable. The role of serendipity, chance, and coincidences in creative thinking are discussed in terms of the computational paradigm. The author concludes from this discussion that creativity cannot be due to chance alone, but that chance with judgment can. The author also discusses three different notions of randomness, with the intent of shedding light on the belief that determinism is incompatible with creativity. These three notions are labeled 'absolute', 'explanatory', and 'relative'.  The first is total absence of any order or structure within the domain; the second the lack of any explanation or cause, and the third lack of any order relevant to some specific consideration. Human creativity is relatively unpredictable the author asserts, and it is easy to believe this considering our folklore understanding of it. The computational paradigm of the author has assisted our understanding of it, but more research is needed.  <br /> <br />	2004-07-27
577170:US	50702879	RAT3BIOJQVZ3S	1558605959	433055289	Swarm Intelligence (The Morgan Kaufmann Series in Evolutionary Computation)	Books	4	10	11	N	Y	Needs more details, but a good introduction.	The authors of this book state therein that \\"mind is not found in covert, private chambers hidden away inside the individual, but exists out in the open; it is a public phenomenon.\\" This would be a very difficult claim to prove from a scientific standpoint, requiring an understanding of neuroscience, consciousness, and psychology that is not yet available. The author's intent though is more modest: they want to use this statement, which they encapsulate as \\"swarm intelligence\\", as a guide to finding successful optimization algorithms. They spend many pages discussing the foundations and background behind their approach, perhaps in too much detail given the usual pragmatism exhibited by many who study algorithms. Swarm intelligence is a relatively new paradigm in the field of optimization, but its justification should come from the results it gives in practical optimization problems, not in the broad philosophical language that predominates the first part of the book.<br /><br /> Particle swarm optimization is introduced in the book in both 'binary' and 'real-valued' form. The authors identify three principles behind the workings of particle swarms, namely the tendency to \\"evaluate\\"; the use of comparisons to others as a way of measuring individual status or progress; and the use of imitation. These three principles they say allow individuals to adapt to highly complex environments and solve very difficult problems. A binary decision model is used to introduce binary swarm algorithm, which is given in pseudocode, and is tested using a binary-coded version of the De Jong suite of test problems for optimization algorithms. A particle swarm model over the real numbers is then discussed, along with pseudocode, Both the binary and real models of particle swarms illustrate the fact that particle swarm optimization is a consequence of social interaction. The particles or \\"individuals\\" in the swarm learn from each other, and move to become more similar to their neighbors based on the knowledge obtained. Particle swarm optimization is dependent on the existence of social structure, the latter of which is determined by the formation of neighborhoods. These neighborhoods can have a different topology, determined solely by the numerical indices assigned to each individual.<br /><br /> The pseudocode given for particle swarm optimization illustrates well the basic workings of the algorithm in terms of the \\"local\\" and \\"global\\" viewpoint of the particles in the swarm. First the swarm is initialized and the performance of each particle is evaluated using its current position. The performance of each individual is then compared to its best performance so far, and the velocity for each particle changed according to a formula dependent on a system parameter. Each particle is then moved to a new position and the entire process repeated until convergence is attained. When a particle is very far from its best solution previously found, the change in velocity will be greater in order to return the particle toward its best solution. The system parameter will govern how much the particle trajectories oscillate, with smaller values of this parameter ensuring smoother trajectories. The authors give examples with graphs to illustrate this behavior and the influence of the system parameter.<br /><br /> Being aware that particle swarm optimization is typically viewed as a kind of evolutionary algorithm, the author address in some detail the reasons for this classification and its justification. Acknowledging that particle swarm algorithms have been influenced by evolutionary computation, they discuss some of the differences between the two approaches. In evolutionary algorithms individuals survive according to their fitness, whereas in particle swarms every individual will survive. In addition, in particle swarms, it is the velocities that are adjusted, whereas in evolutionary computing it is the positions that are state. The authors express this by sayingthat it is the \\"fate\\" rather than the \\"state\\" that is altered in particle swarm optimization.<br /><br /> The authors include an entire chapter on applications in the book, one of them being the use of particle swarms to evolve neural networks. Evolved neural networks have been shown to perform better in some cases than ones designed from scratch. After discussing some of the approaches to evolving neural networks, the authors point out, correctly, that hardly any of the studies in evolving neural networks are quantitative studies of how well they perform relative to other approaches Performance metrics are hardly ever given, which would allow interested parties to make objective and intelligent decisions on which approach is the most viable. The author's approach of using particle swarms to evolve neural networks also, interestingly, involves evolving the transfer functions of the neural networks, and they test their approach by using the Iris Data Set, a frequent benchmark for classification algorithms. Preliminary results indicate that their approach is a viable one and that it shows promise, but they admit that further experiments are needed in order to form valid conclusions.<br /><br /> So are the optimization algorithms based on swarm intelligence better than those that are based on, for example, on evolutionary algorithms? Are they better than those that are purely randomized algorithms? The authors are not shy about discussing how swarm intelligence optimization algorithms compare with other optimization algorithms, particularly randomized algorithms and the now famous \\"free-lunch\\" theorems of David Wolpert and William Macready. They discuss the free-lunch theorems via a very interesting example dealing with finding one's way out of a room. Using this example, they are convincing in their claim that even though no algorithm can be said to be better than any other when averaged over all cost functions, this averaging is done over processes or tasks that might be deemed absurd in the context of many problems of practical interest. Thus for \\"real\\" problems, one algorithm might indeed be \\"better\\" than another.by saying that it is the \\"fate\\" rather than the \\"state\\" that is altered in particle swarm optimization.  <br /> <br /> The authors include an entire chapter on applications in the book, one of them being the use of particle swarms to evolve neural networks. Evolved neural networks have been shown to perform better in some cases than ones designed from scratch. After discussing some of the approaches to evolving neural networks, the authors point out, correctly, that hardly any of the studies in evolving neural networks are quantitative studies of how well they perform relative to other approaches Performance metrics are hardly ever given, which would allow interested parties to make objective and intelligent decisions on which approach is the most viable. The author's approach of using particle swarms to evolve neural networks also, interestingly, involves evolving the transfer functions of the neural networks, and they test their approach by using the Iris Data Set, a frequent benchmark for classification algorithms. Preliminary results indicate that their approach is a viable one and that it shows promise, but they admit that further experiments are needed in order to form valid conclusions.   <br /> <br /> So are the optimization algorithms based on swarm intelligence better than those that are based on, for example, on evolutionary algorithms? Are they better than those that are purely randomized algorithms? The authors are not shy about discussing how swarm intelligence optimization algorithms compare with other optimization algorithms, particularly randomized algorithms and the now famous \\"free-lunch\\" theorems of David Wolpert and William Macready. They discuss the free-lunch theorems via a very interesting example dealing with finding one's way out of a room. Using this example, they are convincing in their claim that even though no algorithm can be said to be better than any other when averaged over all cost functions, this averaging is done over processes or tasks that might be deemed absurd in the context of many problems of practical interest. Thus for \\"real\\" problems, one algorithm might indeed be \\"better\\" than another.	2004-07-25
580261:US	50702879	R22VXN0MCBDSBW	0471030031	557575269	Statistical Learning Theory	Books	5	49	53	N	Y	An excellent overview	The field of statistical learning theory has not only seen considerable advances in the last fifteen years, it has also found many applications, some of these appearing in commercial packages. It is now classified as a subfield of artificial intelligence, and as such gives an alternative, and frequently more general viewpoint on such topics as pattern recognition, regression estimation, and signal processing. The author of this book is one of the originators of statistical learning theory, and has written a book that will give the mathematically sophisticated reader a rigorous account of the subject. Most of the main results are proven in detail, but the author does find time to include insightful discussion on the origins and intuition behind the concepts involved in statistical learning theory.<br /><br /> Along with a brief introduction, the book consists of three parts, the first being an overview of the statistical theory of learning, the second giving the details of the now widely used support vector machines, and the last one (the most sophisticated mathematically) giving the statistical foundations of learning theory. In writing the book, the author wants to put forward a new approach to dependency estimation problems having their origin in learning theory, and being able to deal with the ?curse of dimensionality?. The origins of the subject lie in the pattern recognition problem and the Glivenko-Cantelli problem in statistics. Both of these problems were discovered to be essentially the same, and the author?s task is to use their similarities to construct a general theory of statistical inference and (inductive) learning. Indeed, a new induction principle, called ?structural risk minimization? (SRM) is paradigmatic in the book, along with the now ubiquitous VC dimension, the latter of which originates in the author?s early research. Both the SRM and the VC dimension illustrate the tension between the need for high accuracy and the need for the minimization of error in data sets.<br /><br /> The learning problem, as the author sees it, is the problem of selecting the correct dependence on the basis of empirical data. Two approaches to this problem are discussed, the first using a ?risk functional?, and the second involving the estimation of stochastic dependencies and the consequent solution of integral solutions. Both of these approaches are modeled in terms of a general model of learning from examples, which consists of a data generator, a supervisor, and a learning machine. The learning machine can either imitate the supervisor or identify how the supervisor operates. These two methods are different, the author says, in that the first one searches for the best prediction based on the data, while the second one attempts to approximate the operator representing the supervisor. Both approaches are studied in the book, with the first one being the easier of the two, while the second involving the solution of ill-posed problems. The author views the learning process in terms of choosing the right function from a given function collection.<br /><br /> Both perceptrons and their generalizations, neural networks, are briefly discussed in the book, along with the back-propagation method. The author gives reasons why he does not think neural networks are well-controlled learning machines, such as the existence of local minima, the slow convergence of the gradient method, and the choice of scaling factors. These problems serve as motivation for the introduction of support vector machines, which are introduced as optimal separating hyperplanes. Support vector machines take input vectors into a high-dimensional feature space via a nonlinear mapping, and an optimal separating hyperplane is then constructed in this feature space.<br /><br /> Similar to the need for neural networks to generalize well, separating hyperplanes must do the same, and due to the large dimensionality of the feature space, a hyperplane that separates the training data may not generalize well. In addition, the large dimensionality of the feature space makes the construction of the hyperplane computationally demanding. The author shows that optimal hyperplanes, found using various mathematical techniques such as quadratic optimization, do generalize well. Also, as the author points out, the explicit form of the feature space need not be known, since only the inner products between the ?support vectors? and the vectors of the feature space need to be calculated. The calculation of the inner product is done with the insight gained from Mercer?s theorem, which gives the existence of a kernel function such that there exists a feature space where this function generates the inner product. This inner product in feature space allows the construction of a decision function that is nonlinear in the input space but that is equivalent to a linear function in the feature space. Different choices of the kernel function give different types of learning machines. The author discusses three examples of support vector machines for pattern recognition: polynomial, radial basis function, and two-layer neural network support vector machines. An entire chapter is spent on the problem of digit recognition using support vector machines.parates the training data may not generalize well. In addition, the large dimensionality of the feature space makes the construction of the hyperplane computationally demanding. The author shows that optimal hyperplanes, found using various mathematical techniques such as quadratic optimization, do generalize well. Also, as the author points out, the explicit form of the feature space need not be known, since only the inner products between the ?support vectors? and the vectors of the feature space need to be calculated. The calculation of the inner product is done with the insight gained from Mercer?s theorem, which gives the existence of a kernel function such that there exists a feature space where this function generates the inner product. This inner product in feature space allows the construction of a decision function that is nonlinear in the input space but that is equivalent to a linear function in the feature space. Different choices of the kernel function give different types of learning machines. The author discusses three examples of support vector machines for pattern recognition: polynomial, radial basis function, and two-layer neural network support vector machines. An entire chapter is spent on the problem of digit recognition using support vector machines.  <br />	2004-07-22
584095:US	50702879	R3N8H44PBGYPO4	026203283X	963917292	Virtual Music: Computer Synthesis of Musical Style	Books	5	19	19	N	Y	A fascinating overview of machine musicanship	This book gives a fascinating overview of machine music as seen through the eyes of the author, who has been actively involved in this field for many years. The reading of this book is recommended for anyone who is interested in the extent of machine musicianship and musical creativity. Not being an expert in music theory should not dissuade one from its perusal. In fact, not possessing extensive knowledge of musical theory may be an advantage, in that one can read the passages and listen to the musical compositions on the accompanying CD with minimal bias as to what constitutes enjoyable or \\"good\\" music. Indeed, if one were to approach musical listening, musical composition, and music theory from the standpoint of being exposed only to `virtual music', what would one then think of music composed solely by humans? Would one then judge \\"machine music\\" to be better than \\"human music\\"? As virtual music becomes more integrated into entire knowledge base of music, as it will in this century, there will be many who will be exposed to it more often than human-composed music. It will come to be accepted as beautiful music to listen to, and debates as to its \\"authenticity\\" will disappear. Even more interesting is the question as to what musical preferences the machines themselves will have. Will they debate among themselves about music theory and what constitutes compositional excellence? It will be interesting to see what kinds of music theory are generated (or preferred) by these machines, and if they are as biased to certain forms of music as their human musician counterparts frequently are.<br />The author characterizes `virtual music' as being a category of machine-created composition that attempts to replicate the style of existing music. He points out that virtual music has predated the advent of computing machines, but that these machines have allowed, at a much larger scale, the composition of music in a pre-selected style. Early instances of virtual music discussed in the book include the `figured bass' of the Baroque period, wherein composers could produce music that adhered to a particular composer style but would still be original. Another (fascinating) example is the `Musikalisches Wurfelspiel', or \\"musical dice game\\" of the eighteenth-century. To obtain a composition, one constructs a matrix, with rows representing the results of the throw of dice, and the columns representing successive measures of music. To get a measure of music, the dice are tossed, and from the result in the correct row the measure is obtained from the column. Also mentioned is the work of Iannis Xenadis, which uses mathematical models to compose music, and the work of Kemal Ebcioglu, which uses first-order predicate calculus to create chorales in the style of J.S. Bach. In addition, the author mentions the work of Dominik Hornel and Wolfram Menzel, who make use of neural networks to create music with stylistic similarities to composers of the Renaissance and Baroque periods.<br />Early in the book, the author introduces what he calls \\"The Game\\" in order to warm the reader up to his study of virtual music. This game requires the reader to identify styles and composers of various examples of music, the notations of which are included in the book, and the actual music on the accompanying book. One of the objects of \\"The Game\\" is to be able to distinguish human-composed music from machine-composed music. Another goal of \\"The Game\\" is to determine not only which works are human-composed but also which ones (they are chorales) best follow the style of J.S. Bach. The third goal is to see whether four mazurkas are really in the style of Frederic Chopin. Players are scored according to their answers, and the author quotes a statistic with large groups of listeners between 40 and 60 percent on the average. The author notes that experts in musicology have failed to recognize many of the machine music examples.<br />For the philosophy-oriented reader, a debatebetween Douglas Hofstadter and the author is included in the book. It is the opinion of this reviewer that such debates do not add too much to the field of artificial intelligence, and that those who are involved in this field should declare a moratorium on philosophical debate, and instead spend their time on creating better thinking machines. Philosophical debate is best left to those who like to indulge in it: the philosophers. There are many like Hofstadter who do not want to accept the musical creativity and abilities of the machines. Convincing these individuals of these abilities is typically difficult, and requires large expenditures of time. This time is better spent on the development of more sophisticated musical machines.<br />There are many interesting discussions in this book, too many to be reviewed here in the space allotted. One of the most fascinating of all the topics is the author's discussion on musical patterns. He believes these patterns are critical to the recognition of musical style, and therefore designates these patterns as \\"signatures\\". These signatures are contiguous note patterns that recur in at least two works of the works of a composer, and are found by using pattern-matching algorithms from artificial intelligence. Interesting in this context is the use of what the author calls \\"controllers\\", which allow variations of patterns to count as matches. As the name implies, these controllers may be set by users or by the machine itself.<br />Besides signatures, \\"earmarks\\" are another device used by the author to do pattern-matching in musical compositions. Earmarks are a kind of measure of the \\"inevitability\\" in some musical works. The machines analyze the music in their databases for earmarks and then make sure that these are not placed in inappropriate locations in the scores or omitted entirely. The author views them as \\"principles rather than data\\", and so a pattern-matching algorithm that finds them must return an \\"abstraction\\" representing the type of material used rather than actual musical events. Detecting earmarks can be very difficult says the author. More research is needed.ate between Douglas Hofstadter and the author is included in the book. It is the opinion of this reviewer that such debates do not add too much to the field of artificial intelligence, and that those who are involved in this field should declare a moratorium on philosophical debate, and instead spend their time on creating better thinking machines. Philosophical debate is best left to those who like to indulge in it: the philosophers. There are many like Hofstadter who do not want to accept the musical creativity and abilities of the machines. Convincing these individuals of these abilities is typically difficult, and requires large expenditures of time. This time is better spent on the development of more sophisticated musical machines. <br />There are many interesting discussions in this book, too many to be reviewed here in the space allotted. One of the most fascinating of all the topics is the author's discussion on musical patterns. He believes these patterns are critical to the recognition of musical style, and therefore designates these patterns as \\"signatures\\". These signatures are contiguous note patterns that recur in at least two works of the works of a composer, and are found by using pattern-matching algorithms from artificial intelligence. Interesting in this context is the use of what the author calls \\"controllers\\", which allow variations of patterns to count as matches. As the name implies, these controllers may be set by users or by the machine itself. <br />Besides signatures, \\"earmarks\\" are another device used by the author to do pattern-matching in musical compositions. Earmarks are a kind of measure of the \\"inevitability\\" in some musical works. The machines analyze the music in their databases for earmarks and then make sure that these are not placed in inappropriate locations in the scores or omitted entirely. The author views them as \\"principles rather than data\\", and so a pattern-matching algorithm that finds them must return an \\"abstraction\\" representing the type of material used rather than actual musical events. Detecting earmarks can be very difficult says the author. More research is needed.	2004-07-19
585357:US	50702879	R2LCWZ2GTDBY0V	0131014684	142908462	Optimizing Network Performance with Content Switching: Server, Firewall and Cache Load Balancing	Books	3	9	9	N	Y	Needs more real case studies....many more.	The concept of content switching is relatively new, but for those engineers who work with content switches in real networks, their behavior can be very unpredictable and can conflict with existing hardware and applications. Indeed, there are a few instances where content switch server load balancing competes with the load balancing done in some multi-tier environments running certain types of protocols, such as T3, coupled with the use of WebLogic activated over an application cluster.<br /> These issues are not discussed in the book, but instead the authors give a purely descriptive and qualitative overview of the history, functioning, and use of content switches. However, from the title, a reader might expect that the book is a rigorous, mathematical study of how the use of content switching can enhance network performance. Such a study is not done in this book, but there is a great need for it for anyone who is considering the use of content switching.<br /> As the authors explain it, content switching has its origins in the rise of the Internet and involves using a single point by which a session can be established. A virtual IP address (VIP) is configured on the content switch, which allows a user to connect to the single point, leaving the content switch to set up a dialog with the server or do appropriate load balancing over a collection of servers.<br /> After a review of the OSI model, the authors begin a discussion of switching at different layers. The claim that the information in the different layers can be used to perform traffic forwarding decisions which are \\"intelligent.\\" Their use of the term \\"intelligent\\" here may be inappropriate though, as there is nothing about content switching that can be deemed intelligent, at least from the standpoint of this reviewer. Certainly a content switch is doing something a lot more involved than an ordinary \\"switch\\", but to be deemed intelligent it must learn from its past, or learn from its mistakes, or take action that it deems necessary for improving the user's experience.<br /> The Virtual Router Redundancy Protocol (VRRP) is discussed in the book, due to its importance in content switching. This discussion is helpful, especially for those who do not have knowledge of this protocol, and how it is used to eliminate single points of failure within content switching topologies. VRRP allows the elimination of single points of failure within content switching topologies and allows the grouping of two or more IP addresses so that they appear to surrounding devices as a single logical IP address.<br /> The difference between virtual services and application redirection is fundamental to content switching according to the authors. Server load balancing and Web cache redirection are examples illustrating this difference. In server load balancing, the content switch has a virtual IP address to which a client will attach. This is the origin of the designation as a \\"virtual service\\", in that the destination address of the client's requests is owned by the content switch. Web cache redirection involves manipulation of the client traffic as it passes through the content switch on its way to its destination. Server load balancing is commonly (and incorrectly) equated to content switching in some organizations.<br /> The authors give a fairly detailed and descriptive overview of layer 3 server load balancing, giving conservation of address space and simplicity as the two primary reasons for deploying it. They also mention, but do not discuss in any great detail, the use of dynamic routing protocols, such as OSPF, RIP, and BGP, in content switching. A more detailed discussion, coupled with performance data, would be very helpful to those readers who are considering using content switching in conjunction with these protocols. They do discuss how to implement high availability in server load balancing using multiple content switches and routers, and using multihoming. The different load balancing metrics, such as least connections, round robin, IP address hashing, response time, bandwidth, and server weighting, are also discussed. Unfortunately, the authors do not include any real test cases or benchmarking studies that illustrate more quantitatively the differences between these metrics. They do however point out the use of server agents to gain information on CPU and disk utilization, and memory performance so as to allow the content switch to better influence traffic flow and session distribution. The use of server agents is growing, and represents the bulk of future development, so it would have been helpful if the authors had included a study of the tradeoffs in using these agents in real networks and servers that are deploying content switching.<br /> Criteria to designate a server as being \\"healthy\\" is also important in server load balancing, and the authors discuss some common approaches to checking server health at layers 2 through 7. These include link-based, ARP, ICMP, TCP, and application health checks. The authors are very aware of the care needed to designate a server as being healthy, but they do not site and case studies that illustrate the real-world behavior of \\"unhealthy\\" versus \\"healthy\\" servers. Claims are made that the deployment of layer 4 load balancing does increase user response time in a hypothetical \\"test case\\" that the authors include in the book, but no explicit data is given that illustrates the situation before and after the load balancing is used.<br /> Layer 7 or \\"content aware\\" server load balancing is usually what is thought of when content switching is mentioned. The authors devote and entire chapter to it, and claim many advantages for its use. Applications of it include HTTP URL parsing, cookies, and header inspection, FTP and DNS parsing, and RTSP stream parsing, all of which the authors discuss in some detail. The `delayed binding' by the content switch makes the decision-making more complicated than layer 4 load balancing, and the authors discuss in detail the differences between immediate versus delayed binding of sessions. Once again though, no real-world examples are given that would illustrate the issues that arise in layer 7 server load balancing.oad balancing metrics, such as least connections, round robin, IP address hashing, response time, bandwidth, and server weighting, are also discussed. Unfortunately, the authors do not include any real test cases or benchmarking studies that illustrate more quantitatively the differences between these metrics. They do however point out the use of server agents to gain information on CPU and disk utilization, and memory performance so as to allow the content switch to better influence traffic flow and session distribution. The use of server agents is growing, and represents the bulk of future development, so it would have been helpful if the authors had included a study of the tradeoffs in using these agents in real networks and servers that are deploying content switching. <br /> Criteria to designate a server as being \\"healthy\\" is also important in server load balancing, and the authors discuss some common approaches to checking server health at layers 2 through 7. These include link-based, ARP, ICMP, TCP, and application health checks. The authors are very aware of the care needed to designate a server as being healthy, but they do not site and case studies that illustrate the real-world behavior of \\"unhealthy\\" versus \\"healthy\\" servers. Claims are made that the deployment of layer 4 load balancing does increase user response time in a hypothetical \\"test case\\" that the authors include in the book, but no explicit data is given that illustrates the situation before and after the load balancing is used. <br /> Layer 7 or \\"content aware\\" server load balancing is usually what is thought of when content switching is mentioned. The authors devote and entire chapter to it, and claim many advantages for its use. Applications of it include HTTP URL parsing, cookies, and header inspection, FTP and DNS parsing, and RTSP stream parsing, all of which the authors discuss in some detail. The `delayed binding' by the content switch makes the decision-making more complicated than layer 4 load balancing, and the authors discuss in detail the differences between immediate versus delayed binding of sessions. Once again though, no real-world examples are given that would illustrate the issues that arise in layer 7 server load balancing.	2004-07-17
586345:US	50702879	RNLIEL2HP3RSV	013144025X	261321356	Autonomic Computing	Books	3	4	4	N	Y	Interesting overview	Optimistic in its projections, and sometimes exaggerating what is currently possible, this book gives an interesting overview of the status of the `autonomic computing' project of IBM. Targeted to the network manager reader, the book views autonomic computing as a new approach to computer and systems management. Reducing costs are its goal, as well as increasing the quality of the service. An autonomic system must, according to the author, have knowledge of itself, have the ability to configure and reconfigure itself, as well as self-optimize itself. It must also have the capability to self-heal, to protect itself, and the ability to discover knowledge of its environment and context, and then adapt itself if needed. Most importantly, the system must be able to deal with any type of environment, and be able to anticipate and adapt to the user needs. The complexity of computing systems though is what is considered to be the real driving force behind research into autonomic computing.<br /> These requirements can be met, says the author, by the use of intelligent hardware and software. Just what constitutes intelligence is not really discussed by the author, and hence readers will have to impute their own notions of intelligence when reading the book. The notion of complexity is also not quantified explicitly, although the author does give a few criteria that signify it, such as the size and cost of a system, and the shortage of skilled labor. This last criterion though is somewhat troubling from the standpoint of the labor markets of today. There is definitely not a shortage of skilled IT labor; in fact, there is an overabundance of highly skilled IT workers, definitely more than the current market can absorb.<br /> This reviewer does not know of a machine or system that has all the requirements that the author lists as necessary in order to be considered as a fully autonomous system. The author claims though that such systems are available, in that IBM customers are using it at the present time. He gives a few examples of firms that are using autonomous systems, but does not give the (quantitative) details of how these firms are using it, nor does he discuss just how much these systems improved the overall functioning and management of the systems deployed by these firms. There is ample evidence from the literature on artificial intelligence that will back up some of the author's conclusions however. Indeed, there are myriads of examples that will substantiate the claims attributed to IBM's Alan Ganek that the efficiency of a business increases as more human error is taken out of the loop. But again, there are no systems being used now that satisfy all eight of the criteria for autonomy.<br /> Part 3 is the most interesting part of the book, for it goes into more of the details behind autonomic computing, including how to build these kinds of systems, and even how to implement it in personal computing systems. The author considers `control loops' as the basic management elements in autonomic computing architectures. Control loops will hide complexity from end-users are able to communicate and negotiate with each other and with resources within and outside of the autonomic computing architecture. A hint of what the author considers as intelligent behavior arises in the discussion on control loops: they are able to request additional processing cycles when needed, can install software and upgrades, can restart a system after failure (but can they restart the systems that they are part of?), can initiate backups after daily processing, and can shut down systems are an intruder has been detected (but can they shut down the systems that they are part of if an intruder is detected in these systems?). Certainly if control loops are able to do all of these things they are emulating functions and tasks normally done by human engineers. The author considers the ability to do these things as a definite sign of intelligence.<br /> The author considers open standards as essential for autonomic computing, and he devotes an entire chapter to explaining his reasons for this. Open standards give more agility and flexibility to users, he says, and he compares proprietary and open models in terms of reliability, interoperability, risk, speed of updates, quality, and cost. The Web Services interoperability standards play an essential role in the open source movement and the author believes, in autonomic computing.<br /> Very helpful is the author's discussion in chapter 10 on how to implement autonomic computing. It is helpful because it does address the attitudes about autonomic computing among users and IT managers. From personal experience, this reviewer has encountered a lot of anxiety and caution in the use of this technology. The author is aware of this however, and therefore he defines the notion of different levels of autonomic computing, that will allow IT managers to incorporate autonomic computing in phases. There are five levels in all, labeled as `basic', `managed', `predictive', `adaptive', and `autonomic'. The tools, processes, and skills become increasingly sophisticated as businesses progress through the levels. At the basic level, IT workers set up, monitor, and manage all systems. At the managed level, management technologies are deployed to allow administrators to collect and synthesize information using fewer consoles. Technologies able to pattern match, perform optimization, and give expert advice are deployed at the predictive level. At the adaptive level, systems can automatically take action based on information available to them. Then at the autonomic level, the systems satisfy all eight of the requirements for autonomy, and the IT infrastructure is governed solely by the policies and objectives of the business.<br /> Autonomic computing is definitely an exciting and profitable development in information technology. It remains to be seen just how fast the business community will integrate it into their operations. With hardware and bandwidth costs dropping, and with software development and engineering becoming more automated with each passing day, autonomic computing seems to be the soundest and most reliable approach to IT systems management.uthor considers open standards as essential for autonomic computing, and he devotes an entire chapter to explaining his reasons for this. Open standards give more agility and flexibility to users, he says, and he compares proprietary and open models in terms of reliability, interoperability, risk, speed of updates, quality, and cost. The Web Services interoperability standards play an essential role in the open source movement and the author believes, in autonomic computing. <br /> Very helpful is the author's discussion in chapter 10 on how to implement autonomic computing. It is helpful because it does address the attitudes about autonomic computing among users and IT managers. From personal experience, this reviewer has encountered a lot of anxiety and caution in the use of this technology. The author is aware of this however, and therefore he defines the notion of different levels of autonomic computing, that will allow IT managers to incorporate autonomic computing in phases. There are five levels in all, labeled as `basic', `managed', `predictive', `adaptive', and `autonomic'. The tools, processes, and skills become increasingly sophisticated as businesses progress through the levels. At the basic level, IT workers set up, monitor, and manage all systems. At the managed level, management technologies are deployed to allow administrators to collect and synthesize information using fewer consoles. Technologies able to pattern match, perform optimization, and give expert advice are deployed at the predictive level. At the adaptive level, systems can automatically take action based on information available to them. Then at the autonomic level, the systems satisfy all eight of the requirements for autonomy, and the IT infrastructure is governed solely by the policies and objectives of the business. <br /> Autonomic computing is definitely an exciting and profitable development in information technology. It remains to be seen just how fast the business community will integrate it into their operations. With hardware and bandwidth costs dropping, and with software development and engineering becoming more automated with each passing day, autonomic computing seems to be the soundest and most reliable approach to IT systems management.	2004-07-16
595484:US	50702879	R30KXENKOP20VV	0262071991	450913145	Conceptual Spaces: The Geometry of Thought	Books	3	33	40	N	Y	A little disappointing	If one is to design a machine that can formulate concepts and engage in such things as inductive inference and its corollary scientific discovery, then one must be able to quantify the notion of a concept in such a way that it can be implemented into the cognitive structure of the machine. One must be able to distinguish one concept from another, be able to tell when one concept is similar to another, and understand in detail how concepts are related across domains. It would not be enough to have qualitative notions of these distinctions or similarities, since they must be able to be formatted in such a way, either via coding, language, or electronically, so as to be used by the machine.<br /> This book gives an interesting approach to the problem of concept classification, but it does so only from a qualitative point of view. It is a good start in this regard, and readers will gain a lot of insight into the problems that it addresses. It does not however give any advice on how to implement its ideas into a real thinking machine. Mathematical concepts are brought in order to talk more meaningfully about spaces of concepts, but they are really restricted to metric spaces and not general enough to deal with the plethora of concepts that could present themselves in typical environments. The book should be considered more as a work in philosophy, so those interested in this field might enjoy the book more than those who were expecting a book more geared towards artificial intelligence and computer science. Those readers interested in automated theorem proving or automated mathematical discovery might find the discussion on geometric categorization models of interest, and will find an interesting application of Voronoi tessellations, namely that of accounting for the varying sizes of concepts in a categorization.<br />By far the most interesting chapter in the book is chapter 6, wherein the author gives a highly original discussion of inductive inference. The ability of human cognition to generalize from a limited number of observations is viewed (correctly) by the author as very impressive, but he is careful to note that inductive inference cannot be done free of side constraints. Quoting the philosopher J.S. Peirce and his evolutionary explanation of why induction is so effective, the author uses his theory of conceptual spaces to develop a theory of constraints for inductive inferences. The main notion in this theory is that of \\"projectability\\", which attempts to delineate the properties and concepts that are may be used in inductive inference. The author wants to arrive at a computational model of induction, and he offers interesting proposals for doing so, even if they lack immediate empirical justification.<br /> Central to the problem of induction the author argues is how observations are to be represented. This has been neglected in the history of philosophy he says, and so he then proceeds to outline his ideas on how to represent observations, distinguishing three levels, namely the `symbolic', the `conceptual', and the `subconceptual.' At the symbolic level, observations are represented by describing them in a specified language. At the conceptual level, observations are characterized relative to a conceptual space. At this level induction is viewed as concept formation. At the subconceptual level observations are characterized by inputs from sensory receptors. Induction is then viewed as the attaining of connections between various inputs. The author views the processing taking place in artificial neural networks as an example of modeling at the subconceptual level.<br /> The problem of induction is more complicated than is typically presented in the literature, the author argues. Inductive inference will look different depending on which approach to observations is taken. In his elaborations on the processes of induction, one of the key issues that arises is the how discovery takes place across different domains. The process of conceptualizing across different domains takes place, as expected, at the subconceptual and conceptual levels. The symbolic level is delegated to formulating laws.e process of conceptualizing across different domains takes place, as expected, at the subconceptual and conceptual levels. The symbolic level is delegated to formulating laws.	2004-07-10
602317:US	50702879	R35L0BWFMV4INJ	1558604677	360733309	Artificial Intelligence: A New Synthesis	Books	4	6	7	N	Y	Good general overview	The field of artificial intelligence has an interesting history, both in terms of its content and the philosophical debate it has provoked. The field could also be loosely described as divided into two camps, those who view it as a collection of highly sophisticated algorithms, and those who view it as an attempt to create machines that exhibit human-level intelligence. Ironically, in the latter camp, it is difficult to assess the progress that has been made, since criteria for measuring machine intelligence are never explicitly given. Instead, dependence has been made on the \\"Turing test\\" for intelligence, a test that is difficult to apply, and in fact can be said to be too vague for a practical, objective assessment of machine intelligence.<br /> This book is written more in the context of the latter camp, than in the former. However, in-depth discussion of the Turing test is not given, and this actually is one of the main virtues of the book, although the author clearly believes that the purpose of doing research in artificial intelligence is to achieve human-level intelligence. As he remarks in the last paragraph in the book, it was written to overview the techniques that he believes are required to achieve human-level intelligence. Although he does not explicitly give the reader tests for machine intelligence that will allow progress to be measured, he devotes a small portion of the book to various ideas on just what constitutes intelligence.<br /> The book also gives a general (and sometimes very brief) overview of the algorithms used in artificial intelligence.  Search heuristics, neural networks, and genetic programming are some of the topics that are covered. The influence of the \\"intelligent agent\\" paradigm, that is now taking the AI community by storm, is very apparent throughout the book. The author though does not neglect some of the topics in \\"good-ole-fashioned\\" artificial intelligence that arose decades ago and is still applicable today, especially in the field of logic programming. These topics include resolution in both the propositional and predicate calculus, and in expert systems. By far the best discussion in the book is on knowledge-based systems and evolving knowledge bases. This topic has taken on considerable importance in recent years due to the importance of data mining and business intelligence.<br /> Readers who are considering artificial intelligence as a career choice will find good motivation by reading this book. The field also is quite different than most others in that it respects a high degree of individual creativity and ingenuity, and has a high bandwidth for new ideas. Beginning with its origins in the 1950s, the field has grown by leaps and bounds, but its applications have exploded in the last five years, fueled mainly by business and financial applications. Concerned not only with achieving human-level capabilities, but also with other forms of intelligence and how they can be useful, artificial intelligence has become one of the predominant forces in the twenty-first century. One can only be excited and optimistic about its further advances.in the field of logic programming. These topics include resolution in both the propositional and predicate calculus, and in expert systems. By far the best discussion in the book is on knowledge-based systems and evolving knowledge bases. This topic has taken on considerable importance in recent years due to the importance of data mining and business intelligence. <br /> Readers who are considering artificial intelligence as a career choice will find good motivation by reading this book. The field also is quite different than most others in that it respects a high degree of individual creativity and ingenuity, and has a high bandwidth for new ideas. Beginning with its origins in the 1950s, the field has grown by leaps and bounds, but its applications have exploded in the last five years, fueled mainly by business and financial applications. Concerned not only with achieving human-level capabilities, but also with other forms of intelligence and how they can be useful, artificial intelligence has become one of the predominant forces in the twenty-first century. One can only be excited and optimistic about its further advances.	2004-07-05
604569:US	50702879	R89L18YKKWLMA	0226468011	583365534	Metaphors We Live By	Books	5	21	24	N	Y	Excellent	This book could be considered to be one of the most intellectually honest of any book in print, for it unashamedly deals with commonsense notions of how the human mind deals with the world. One sometimes gets the impression that some works, especially on the philosophy of mind, tend to mystify or glamorize the workings of the mind. This book gives much weight to the use of metaphors for this purpose, and in doing so is faced with just how efficacious these metaphors are. The ordinary human conceptual system is fundamentally metaphorical it argues, and that metaphors are the predominant mode of cognition. The evidence for their assertion comes primarily from linguistics, and they give numerous examples of the metaphors that are employed by humans in everyday discussion and interactions with others. The authors emphasize though that metaphor is not just a linguistic notion, but that human thought processes themselves are largely metaphorical. So how do we study the metaphorical nature of thought? The author's answer is simple: we use metaphorical linguistic expressions to study the nature of metaphorical concepts. This will allow an understanding of the metaphorical nature of our activities.<br /> The authors are careful to point out that the use of metaphors does, possess a notion of entailment, and that metaphorical entailments are able to characterize a coherent system of metaphorical concepts. Thus this system is not loose and unstructured, but rather similar in fact to the many systems of logic that one finds in computer science and in research in artificial intelligence. However, being able to view one aspect of a concept in terms of another will mask other aspects of this concept, and the authors give several interesting examples of this. When a concept is structured by a metaphor it is always partially structured, for otherwise the metaphor and the concept it is trying to understand would be identical. The metaphorical concepts can be extended however, and be deployed in a way of thinking traditionally called \\"figurative.\\"<br /> Along with these structural metaphors, the authors discuss `orientational metaphors', that serve to organize an entire system of concepts with respect to one another. As their name implies, these metaphors usually involve spatial orientation, and originate in human cultural and physical experience. Several examples of orientational metaphors are given, and they give what they consider to be plausible explanations of how they arise in experience. They remind the reader though that these explanations are not set in stone. However they clearly believe, and they emphasize this in the book, that metaphors cannot be understood or represented independently of its experiential basis. A metaphor is inseparable from its experiential basis.<br /> The philosophical reader will probably want to know how the metaphorical nature of thought connects with a \\"theory of truth\\". The authors don't resist flirting with the boundaries of philosophy, and give a rather lengthy discussion of metaphors and \\"truth.\\" The authors clearly do not believe in the traditional Western notion of objective, absolute, and unconditional truth. They do however vigorously put forward a notion of truth which they believe meshes with their paradigm of metaphor.<br /> Truth, the authors believe, depends on \\"categorization\\", which means that statements are only true relative to some understanding of them, that understanding always involves human categorization arising from experience and not from inherent properties, that statements are true only relative to the properties emphasized by the categories used in the statement, and that categories are not fixed and not constant.<br /> The authors then put forward an explanation of how a sentence can be understood as true, before tackling the general case of metaphors. To understand a sentence as being true in a particular situation involves both having an understanding of the sentence and of thesituation. But to understand a sentence as being true it suffices to understand only approximately how it fits the understanding of the situation. Thus the authors introduce a metric, i.e. a notion of closeness between the situation and the sentence that fits this situation. Obtaining this fit may require several things to happen, such as \\"projecting\\" an orientation onto something that has no inherent orientation, or providing a background for the sentence to make sense.<br /> Having detailed what is involved in understanding a simple sentence as being true, the authors then state that including conventional metaphors does not change anything. The understanding of truth for conventional metaphors can be done in terms of metaphorical \\"projection\\" and in terms of nonmetaphorical \\"projection\\". In metaphorical projection understanding of one thing is done in terms of another kind of thing, whereas in nonmetaphorical projection only one kind of thing is involved. The case of new metaphors does not involve essentially anything more than the case of conventional metaphors.<br /> The authors summarize their \\"experientalist\\" theory of truth as the understanding of a statement as being true in a given situation when the understanding of the statement fits the understanding of the situation closely enough for the purposes at hand. This theory, they say, does mesh with some aspects of the correspondence theory of truth but rejects the notion of a \\"correspondence\\" between a statement and some state of affairs in the world. The correspondence between a statement and that state of affairs is mediated they say by the understanding of that statement and the state of affairs. In addition, truth is always relative to the conceptual system used to understand situations and statements. Further, the understanding of something involves putting it into a coherent scheme relative to a conceptual system. The author's theory of truth is thus reminiscent of the familiar coherence theories of truth. In addition, understanding is always grounded in experience, with the conceptual systems arising from interaction with the environment. Their theory of truth does not require a notion of \\"absolute\\" truth, and most interestingly, and most provocatively, individuals with different conceptual systems may understand the world differently, and have different criteria for truth and reality.<br /> The key word is \\"different\\": an interesting project would be to quantify this.situation. But to understand a sentence as being true it suffices to understand only approximately how it fits the understanding of the situation. Thus the authors introduce a metric, i.e. a notion of closeness between the situation and the sentence that fits this situation. Obtaining this fit may require several things to happen, such as \\"projecting\\" an orientation onto something that has no inherent orientation, or providing a background for the sentence to make sense.<br /> Having detailed what is involved in understanding a simple sentence as being true, the authors then state that including conventional metaphors does not change anything. The understanding of truth for conventional metaphors can be done in terms of metaphorical \\"projection\\" and in terms of nonmetaphorical \\"projection\\". In metaphorical projection understanding of one thing is done in terms of another kind of thing, whereas in nonmetaphorical projection only one kind of thing is involved. The case of new metaphors does not involve essentially anything more than the case of conventional metaphors.<br /> The authors summarize their \\"experientalist\\" theory of truth as the understanding of a statement as being true in a given situation when the understanding of the statement fits the understanding of the situation closely enough for the purposes at hand. This theory, they say, does mesh with some aspects of the correspondence theory of truth but rejects the notion of a \\"correspondence\\" between a statement and some state of affairs in the world. The correspondence between a statement and that state of affairs is mediated they say by the understanding of that statement and the state of affairs. In addition, truth is always relative to the conceptual system used to understand situations and statements. Further, the understanding of something involves putting it into a coherent scheme relative to a conceptual system. The author's theory of truth is thus reminiscent of the familiar coherence theories oftruth. In addition, understanding is always grounded in experience, with the conceptual systems arising from interaction with the environment. Their theory of truth does not require a notion of \\"absolute\\" truth, and most interestingly, and most provocatively, individuals with different conceptual systems may understand the world differently, and have different criteria for truth and reality.<br /> The key word is \\"different\\": an interesting project would be to quantify this.	2004-07-03
605609:US	50702879	R3BAFQXXHESODB	0471162698	4939199	High-Performance Client/Server	Books	3	6	8	N	Y	Very out of date.	The authors introduce this book as one that is different than most of the others on client/server technology that are on the market. They wanted to write a book that addresses the practical issues that arise in the effective use of client/server technology in a business environment. Certainly such a book is needed, especially for understanding the behavior and performance of applications in client/server or in more complicated multi-tiered environments. The need for understanding application performance in multi-tiered environments is now more important than in ordinary client/server environments. Thus this book, published in 1998, is to a large degree outdated. The client/server paradigm has been replaced in the last five years with the multi-tiered paradigm, consisting typically of Web, application, and database servers, all with a lot of redundancy put in, and typically being load-balanced with content switching. There is a chapter on &quot;middleware&quot; in the book, but this is very distant from the complexity of the &quot;back-end&quot; now used by most enterprise applications.<br />For a reader who is a newcomer to application performance issues, this book might be a good start in allowing the reader to get comfortable with some of the terminology that is used in performance studies. However, its approach is very qualitative, and therefore does not give any sound advice, supported by empirical data and mathematics, for addressing the real performance issues involved in application deployment. In addition, the performance monitoring tools recommended are very out of date. Current technology makes heavy use of intelligent agents, which are a lot more resilient and sophisticated than they were at the time of publication of this book. These agents are more than just the rule-based systems that the authors mention and downplay in the book. Intelligent agents are now able to engage in system tuning and performance management at a level of expertise that is approaching, if not exceeding in many cases, the human expertise and ingenuity that the authors extol in the book.ching, if not exceeding in many cases, the human expertise and ingenuity that the authors extol in the book.	2004-07-02
612603:US	50702879	R1COS6QCUMB0HW	0262521709	371293729	Understanding Music with AI: Perspectives on Music Cognition	Books	4	5	5	N	Y	Preliminary to subsequent research in machine music	Art and music used to be thought of as two fields of human endeavor that could never be realized by artificial intelligence. That belief is still held by many, but in the past few decades painstaking and dedicated research in artificial intelligence has shown beyond doubt that not only can non-human machines compose music that is beautiful to listen to, but one can use these machines essentially as tutors, giving keen insight into musical composition and music theory. The musical expertise non-human machines allows a deeper and richer appreciation of music, and the music they produce will continue to stir the senses and interrupt, or perhaps dominate, the normal course of cognition.<br /> Via a collection of research articles, this book gives a splendid representation of what was done in using the field of artificial intelligence to understand music theory and composition up until the year 1992. The last twelve years of course, thanks mostly to faster and more powerful hardware, has seen considerable advances in musical artificial intelligence. The quality of music composed by the machines is astounding, and considering that hardware is continuing to get more powerful (and cheaper), it will be interesting to see what the musical abilities of the machines will be a decade from now.<br /> The book essentially defines itself as an overview of `cognitive musicology', which as Otto E. Laske asserts, is a field that began in the 1970s, and has as its goal the understanding of both musical thought and `musicological' thought, and their links to `musical action.' It has its origins in many different fields, such as cognitive psychology, neuroscience, artificial intelligence, and semiotics, and attempts to model musical knowledge, but does so in a way that does not separate knowledge from action. Laske wants to move away from the Cartesian paradigm, believing that it is inadequate for music research. He also believes, interestingly, that there is a `musical intelligence' that is distinct from various other types of \\"intelligences\\" that can exist in humans. Thus cognitive musicology should be viewed as a field that studies this musical cognitive system, and this study can be done independently of the research into other forms of intelligences, such as linguistic or mathematical.<br />Laske breaks up the field of cognitive musicology into: `local knowledge', which is knowledge about the tools and materials needed; `competence', which is knowledge about the domain; and `performance,' which is knowledge of how to perform under real-time constraints. The integration of work in cognitive musicology with computing machines is essential according to Laske, for this will allow the view of music and musicology as essentially knowledge engineering.  Artificial intelligence is and essential part of cognitive musicology he argues, since it introduces a task-oriented perspective on music, which had not been done in music theory at that time.<br />  The article by Peter Kugel follows the one by Laske, wherein Kugel argues that the strict computational framework of Laske may be inadequate for some forms of musical thought. To make his case on the limitations of computation, he introduces what he calls an `announcement condition.' This is a method by which one can tell with certainty whether a procedure has finished doing its job. This motivates the idea of a `limiting computation', which is one that allows a solution to a problem that a \\"regular\\" computation can't. Musical thinking, Kugel asserts, requires limiting computations, and he discusses various methods for finding examples of musical thinking that require more than regular computations. Interestingly, Kugel uses Cantor diagonal arguments to find, or at least indicate how to find, examples of new styles of composition. There are problems he says that can be found by \\"technique\\", but others require \\"insight\\", and the difference between these does involve the level of knowledge of the problem solver. One can turn some problems requiring insight into ones that do not, but there are some problems, such as those involving musical creation, that cannot be. No explicit examples are given however.<br />  Many other very interesting articles follow, all discussing various aspects of how to model musical activity, connections with artificial intelligence, automated musical composition, etc. One particularly interesting article is the one by Kemal Ebcioglu on designing an expert system for harmonizing chorales in the style of Bach using first-order predicate logic. Written first in PROLOG on a VAX 11 architecture (which shows the age of the article), Ebcioglu describes how a language called BSL (for Backtracking Specification Language) was designed for the purposes at hand. The language was constructed so as to permit the coding of universal and existential quantifiers, be efficient for producing high-quality music, and yet be tractable and easy to use. An illustration of the syntax of the language is given using the 8-queens problem and an informal description is given of the semantics of the language. The search technique of backtracking plays, as the name of the language implies, a central role, but it is implemented in a manner that makes it less inefficient than the usual backtracking techniques that are implemented in LISP and PROLOG. The author then describes the CHORAL system, which allows the representation of Bach chorales and their harmonization.lem solver. One can turn some problems requiring insight into ones that do not, but there are some problems, such as those involving musical creation, that cannot be. No explicit examples are given however. <br />       Many other very interesting articles follow, all discussing various aspects of how to model musical activity, connections with artificial intelligence, automated musical composition, etc. One particularly interesting article is the one by Kemal Ebcioglu on designing an expert system for harmonizing chorales in the style of Bach using first-order predicate logic. Written first in PROLOG on a VAX 11 architecture (which shows the age of the article), Ebcioglu describes how a language called BSL (for Backtracking Specification Language) was designed for the purposes at hand. The language was constructed so as to permit the coding of universal and existential quantifiers, be efficient for producing high-quality music, and yet be tractable and easy to use. An illustration of the syntax of the language is given using the 8-queens problem and an informal description is given of the semantics of the language. The search technique of backtracking plays, as the name of the language implies, a central role, but it is implemented in a manner that makes it less inefficient than the usual backtracking techniques that are implemented in LISP and PROLOG. The author then describes the CHORAL system, which allows the representation of Bach chorales and their harmonization.	2004-06-28
623385:US	50702879	R2CLJC19PJGWSS	159059181X	122186246	J2ee Performance Testing	Books	4	12	12	N	Y	A good introduction	In the last decade, the performance of J2EE applications has become of monumental importance in enterprise industries that use these applications. With the complexity of J2EE applications increasing every year, it is crucial that users of these applications be presented with a level of performance that is acceptable to them, this performance usually codified in the ubiquitous \\"response time.\\" The authors of this book have given a good introduction of how to deal with performance issues in WebLogic applications and have discussed a freely available tool, called Grinder, which allows load-generating and data collection. The book though can be read with respect to any load-generating tool, such as Mercury LoadRunner, etc. Even though Grinder is free, it may take time for enterprise users to trust it in testing and modeling.<br /> After a brief introduction to what the book is all about, the authors begin in chapter 1 with discussion on a testing methodology for doing performance studies of J2EE applications, which they hope will be generic enough for all readers. Their methodology boils down to first defining the performance metrics for the application, and then setting a target for the metrics. Test scripts that accurately simulate the application usage must then be obtained, and the statistical sampling method and metrics must then be defined. The authors emphasize the need for a realistic `usage profile' for the application, and they recommend strongly a fixed number of users per test run, with subsequent runs changing the number of users. They do not give quantitative reasons for not varying the number of users, but merely say that such an approach is \\"statistically incorrect.\\"<br />They also point out the need for including \\"think times\\" between the executions of each request in a script, asserting that the think times will have a very dramatic effect on the observed response times and throughput for a given user load. They are correct in this claim, as testing and modeling studies will show, and they give examples of this in chapter 4 of the book. In addition, they remark that the attempt to simulate more users by decreasing the think time, with the assumption that the resulting data can be then extrapolated to obtain the performance at real think times. They point out, correctly, that applications do not scale linearly over different time scales, and that the application and Web servers, the database server, and the operating system do not interact the same way with different user loads. Performance testers and modelers have verified them time and time again, and so it is beneficial for a reader who might be new to the field to see the case studies illustrating this included in the book.<br />The authors discuss two sampling methods in the book, namely the `cycle' method, and the `snapshot' method. Defining a cycle as a complete execution of a test script by a simulated user, each user will thus execute every request in the script once. Increasing the number of cycles will result in more meaningful statistics, but the time to run a large number of cycles might be too prohibitive. The snapshot method involves capturing the data for a specified period of time.<br />It is rare to see in books at this level a statement that acknowledges the difficulty in the mathematical or simulation modeling of Internet traffic. The authors though are cognizant of this difficulty, and give some brief suggestions on how to simulate the Internet in a test environment.<br />The authors also devote a fair amount of time discussing how to assess the accuracy of the test results. The authors report that variability of up to 50% on the performance testing of applications has been observed, and so they propose a measurement of \\"quality\\" for the sample data. This is defined as the standard deviation divided by the arithmetic mean, and when close to zero indicates high quality in the sample data. A value above 0.25 for the quality they take as a signthat the tests are not reproducible, and they therefore encourage the running of more cycles of the test in order to pin down the origins of this non-reproducibility. They define a \\"load factor\\" to better quantify this, which they define in terms of an \\"aggregate\\" average response time. Plotting this quantity versus the number of cycles gives some information on a bad quality indicator.<br />Frequently, application development using J2EE requires that the impact of design changes or proposals on application performance must be understood. The authors address how performance can be impacted in the context of building servlet applications. The dynamic nature of servlet applications entails that special measures be taken to maximize the performance of the application. The authors discuss how to choose a session mechanism that will preserve the session in user requests, and how to manage the servlet thread pool. Other helpful hints are given on how to increase performance, such as making sure that the auto-reload feature of servlets is disabled in a production environment. In testing the servlet API, the authors choose the snapshot method of data collection, and used zero think times as a baseline, since the real think times are unknown. They use WebLogic Server 6.1 in this discussion however, which makes their presentation somewhat dated, since WebLogic is now in version 8.1. The authors also test the performance when the WebLogic performance pack is activated, for both the average response time and the transactional rate. Also studied is the cost of maintaining HTTP logs, an issue that is very important for those businesses who must keep these logs, either for advertising purposes or other reasons. By running tests, the authors conclude, as expected for those readers who have managed Web servers, that the keeping of log files can have a considerable impact on performance, for a high number of users. The effects of the size of the response generated by the test servlet is also studied, along with the effects of using HTTP 1.0 versus HTTP 1.1.sign that the tests are not reproducible, and they therefore encourage the running of more cycles of the test in order to pin down the origins of this non-reproducibility. They define a \\"load factor\\" to better quantify this, which they define in terms of an \\"aggregate\\" average response time. Plotting this quantity versus the number of cycles gives some information on a bad quality indicator. <br />Frequently, application development using J2EE requires that the impact of design changes or proposals on application performance must be understood. The authors address how performance can be impacted in the context of building servlet applications. The dynamic nature of servlet applications entails that special measures be taken to maximize the performance of the application. The authors discuss how to choose a session mechanism that will preserve the session in user requests, and how to manage the servlet thread pool. Other helpful hints are given on how to increase performance, such as making sure that the auto-reload feature of servlets is disabled in a production environment. In testing the servlet API, the authors choose the snapshot method of data collection, and used zero think times as a baseline, since the real think times are unknown. They use WebLogic Server 6.1 in this discussion however, which makes their presentation somewhat dated, since WebLogic is now in version 8.1. The authors also test the performance when the WebLogic performance pack is activated, for both the average response time and the transactional rate. Also studied is the cost of maintaining HTTP logs, an issue that is very important for those businesses who must keep these logs, either for advertising purposes or other reasons. By running tests, the authors conclude, as expected for those readers who have managed Web servers, that the keeping of log files can have a considerable impact on performance, for a high number of users. The effects of the size of the response generated by the test servlet is also studied, along with the effects of using HTTP 1.0 versus HTTP 1.1.	2004-06-19
631453:US	50702879	R1DHOZ1S2E3HKW	0262025485	149737887	What Is Thought? (Bradford Books)	Books	3	15	25	N	Y	Some interesting ideas here...but speculative at many places	Rapid progress is now being made in the field of neuroscience, and this progress is not merely in theory, but also in laboratory measurements, thanks to the advances in magnetic resonance imaging. Also, advanced and practical applications in artificial intelligence are now a reality. Indeed, applications of artificial intelligence in the business environment are skyrocketing, and there is every indication that this will continue. Still though, the nature of human thought remains somewhat of a mystery, which is a kind of irony, given that intelligence is imputed to humans even without understanding fully what is really going on in the human mind when it is engaged in problem solving, reasoning, planning, or myriads of other activities. We do have non-human intelligent machines, but they are not considered to be by most, with the sole reason being that we can understand the nature of their problem-solving abilities. Will we then continue to view the human mind as exhibiting intelligence once we have deciphered its workings?<br />This book gives many different insights into the problem of human thinking and just what are its origins. Although written for the \\"popular\\" audience, much can be gained from reading it regardless of the reader's background. It does indulge in speculation frequently and reasoning by analogy, and it skirts at the ill-defined boundaries of philosophy, but it is worth taking the time to read in detail.<br />The author has a very specific view of intelligence as is readily apparent when he remarks that human intelligence has the ability to \\"understand\\" in many domains. Machines in his view though do not have this ability, but are \\"brittle\\", and cannot tackle different problems on the fly the way humans can. But does \\"understanding\\", as we frequently impute it to humans, have to accompany successful problem solving? Why is it that we are prejudiced in the requirement of \\"understanding\\" when we characterize an entity as intelligent? And is the ability to answer questions from many domains or contexts, however vaguely they are presented, really indicative of intelligence or understanding? The author wants to clarify the notion of \\"understanding\\", this to be one of the goals in the book. He asks whether there is some \\"quantity called understanding\\" that will serve to distinguish mechanical computation from thought. The author is expressing great insight in bringing this question to light, as it has long been a prejudice that machines are merely engaging in syntactical manipulation, and unable to deal with the \\"semantics\\" or understanding of the \\"meaning\\" behind the symbols.<br />The thesis of the author is very straightforward, namely that Occam's razor, as he defines it, serves as the foundation for human reasoning and the mind. The criterion of simplicity is formulated using Kolmogorov complexity, which is currently the most popular one, at least in the computer science community. Most interesting though is the author's view on compression, in that the human mind functions by using essentially compressed programs. Compression to him is the key to understanding, in fact is equal to it. Compressed descriptions are the origin of understanding, and the human brain has, through evolution and reinforcement learning, acquired very adept programs for a myriad of tasks relevant for human survival.<br />The author's arguments are interesting, but he frequently uses arguments by analogy rather than backing them up with empirical research. More use must be made of the research in neuroscience and psychology before claims can be made on the functioning of the human brain. Too much philosophical discussion has invaded the author's arguments, and this weakens his case in many places in the book. It is the opinion of this reviewer that those engaged in research into artificial intelligence, neuroscience, and closely related fields should declare a moratorium on philosophical speculation and argumentation. The conceptual spaces generated by philosophical speculation are too large to be practical, as they contain too much information, which is constantly expanding with time because of the lack of side constraints, or \\"inductive bias.\\"<br /> Since the efficacy of the human brain is the result of evolutionary pressures, one would naturally ask what role the genetic code would play. The author answers this question in very simple terms, namely that the generation of mind was due to the training of a compact program. This compact program was encoded as DNA, and evolution was a training process for this program. It took four billion years of this training to be compactified into an expression residing in the DNA. This viewpoint is an interesting one, and it sounds very plausible, but again, it still needs to be supported with empirical evidence.<br /> Much use in the book is made of results from computational learning theory because of the author's belief that inductive bias is the crucial to learning in complex environments. `Inductive bias', as he views it, and how it is viewed by researchers in computational learning theory, is a certain preference in learning one concept rather than another. Certainly it is true, and it has been shown by research in computational learning theory, that inductive bias is useful in pruning the search space and can assist in omitting useless information that is not pertinent to the problem at hand. However, the author's view is much stronger regarding the role of inductive bias: he is claiming that it is absolutely essential for learning in complex environments and therefore that other approaches to learning in such environments will not be as efficacious. His views are thus at odds with certain results in computational learning theory regarding the absence of a \\"free lunch\\" in randomized algorithms (as reinforcement learning is). The author is claiming, perhaps without meaning to, that learning algorithms that incorporate inductive bias will give essentially a free lunch. The only way out of this difficulty might be to acknowledge that the learning processes used by the brain are still being subjected to evolutionary pressure and hence that the learning processes now being used are not optimized, and are undergoing modification (however slowly).paces generated by philosophical speculation are too large to be practical, as they contain too much information, which is constantly expanding with time because of the lack of side constraints, or \\"inductive bias.\\"<br /> Since the efficacy of the human brain is the result of evolutionary pressures, one would naturally ask what role the genetic code would play. The author answers this question in very simple terms, namely that the generation of mind was due to the training of a compact program. This compact program was encoded as DNA, and evolution was a training process for this program. It took four billion years of this training to be compactified into an expression residing in the DNA. This viewpoint is an interesting one, and it sounds very plausible, but again, it still needs to be supported with empirical evidence. <br /> Much use in the book is made of results from computational learning theory because of the author's belief that inductive bias is the crucial to learning in complex environments. `Inductive bias', as he views it, and how it is viewed by researchers in computational learning theory, is a certain preference in learning one concept rather than another. Certainly it is true, and it has been shown by research in computational learning theory, that inductive bias is useful in pruning the search space and can assist in omitting useless information that is not pertinent to the problem at hand. However, the author's view is much stronger regarding the role of inductive bias: he is claiming that it is absolutely essential for learning in complex environments and therefore that other approaches to learning in such environments will not be as efficacious. His views are thus at odds with certain results in computational learning theory regarding the absence of a \\"free lunch\\" in randomized algorithms (as reinforcement learning is). The author is claiming, perhaps without meaning to, that learning algorithms that incorporate inductive bias will give essentially a free lunch. The only way out of this difficulty might be to acknowledge that the learning processes used by the brain are still being subjected to evolutionary pressure and hence that the learning processes now being used are not optimized, and are undergoing modification (however slowly).	2004-06-13
638722:US	50702879	R14SLHW1OHQHRF	059600432X	944716083	WebLogic: The Definitive Guide	Books	4	3	5	N	Y	A comprehensive and useful overview of WebLogic	WebLogic has become a very popular tool for integrating and managing applications in multi-tier environments. Implemented as an application server, it remains one of the leaders in J2EE compliance. There is a lot to WebLogic, and so it is unlikely that any one person would need to be in a situation where expertise in all of its properties and capabilities would be required. Because of its popularity though, for those who must confront it via Web applications, a good general familiarity with it is essential. This book gives a comprehensive overview of WebLogic, and readers who need a particular set of questions answered or need an in-depth review will find it useful. The interest of this reviewer was in performance issues in WebLogic, and so the review will be confined to these issues as they are discussed in the book, as space permits. The book devotes an entire chapter to the performance tuning of WebLogic applications, but some of the other performance issues discussed in the book outside of this chapter include:<br /><br /> 1. The Enterprise Java Bean (EJB) container supports checking on value changes so that only persistent fields that have been modified are written to the database. This results in enhanced performance for the EJB.<br /><br />2. WebLogic provides flow control mechanisms that allow the suppression of messages during times of peak messaging. This ensures that the performance of other WebLogic services will not be affected adversely.<br /><br />3. The use of cache filters, which enhance application performance by caching various portions of the application without needing code changes.<br /><br />4. Client-server interactions are optimized when the client is operating within the same virtual machine (VM) as the Remote Method Invocation (RMI) object. Java pass-by-reference semantics when the client and the server object are collocated.<br /><br />5. The Java Database Connectivity (JDBC) connection pools enhance the performance and scalability of an application by allowing the same physical connection to be shared by multiple applications. Connection testing however can cause delays, since WebLogic will execute the test whenever the connection pool receives a connection request from a client.<br /><br />6. Although by default WebLogic allows one to retrieve the physical connection associated with a logical connection, it cannot reuse a physical connection, but will instead discard it and replace it with a new connection in the pool. The performance of an application will be degraded if it depends on the physical connections, since any statement cache might not be valid for the new connection in the pool. One can change this default however to allow physical connections to be returned to the pool when they are closed, if one really desires to do so.<br /><br />7. The performance of JDBC applications can be improved by configuring WebLogic so that it maintains a statement cache for each connection in a connection pool. When a callable statement is created using a connection obtained from the pool, it will be cached so as to avoid recompiling when using it again.<br /><br />8. The performance of a Java Messaging Service (JMS) server can be adjusted using WebLogic by setting up quotas that restrict the number of messages held in server memory, or by enabling paging so that messages held in memory can be swapped out to a persistent store under threshold conditions. The JMS server can also suppress the rate at which JMS clients produce messages when the server attains threshold conditions. WebLogic uses `flow control\\" to do this, which delays the time it takes for calls to produce a message to return. The rate of flow of the messages is thus controlled based on a minimum and maximum range. Any degradation in the conditions will cause the flow rate from senders to approach the minimum range. When the conditions improve, the rate will approach the maximum range. The WebLogic flow control mechanism is given detailed discussion in the book.<br /><br />9. Two types of JMS file stores are possible under WebLogic, namely file-based stores and JDBC-accessible database stores. File stores are faster than JDBC stores, and they do not generate network traffic, whereas JDBC stores will if the database is on a different machine. JMS stores for persistent messages will also degrade application performance. In addition, enabling message paging to a JMS store is more expensive than disabling paging altogether.<br /><br />10. Message delivery and can be controlled and handled in WebLogic by using either `delayed' or `scheduled' message delivery, time-to-live settings, and redelivery mechanisms. Messaging can affect performance depending on the type of messages exchanged. Server memory, message payloads, network resources, and server support for paging and persistent messaging will all have to be optimized in order to get maximum performance from the JMS server. Message selectors also affect performance, and several mechanisms that are used are discussed in the book.<br /><br />11. JMS clients can use WebLogic to dynamically create a permanent destination on the JMS server using methods that are asynchronous, and so there may be a large delay between when a request for a new destination is submitted and when the new destination is bound to the Java Naming and Directory Interface (JNDI) tree of the server. Polling will then have to be done by the client regularly in order to find out if the destination has been created.<br /><br />12. JMS servers can of course be clustered, and JMS clients use connection factories to obtain connections to a JMS server, wherein a load balancing strategy is used to decide which server in the cluster should host the JMS connection. Connection routing can be used to improve scalability, even though it increases network traffic, but network traffic can be minimized for server-side applications. 13. WebLogic uses transaction collocation to reduce network traffic by collocating objects on the server on which the transaction was initiated. If multiple objects are cluster-aware and are engaged in a distributed transaction, WebLogic will collocate the objects on the server on which the transaction had started.are possible under WebLogic, namely file-based stores and JDBC-accessible database stores. File stores are faster than JDBC stores, and they do not generate network traffic, whereas JDBC stores will if the database is on a different machine. JMS stores for persistent messages will also degrade application performance. In addition, enabling message paging to a JMS store is more expensive than disabling paging altogether.     10. Message delivery and can be controlled and handled in WebLogic by using either `delayed' or `scheduled' message delivery, time-to-live settings, and redelivery mechanisms. Messaging can affect performance depending on the type of messages exchanged. Server memory, message payloads, network resources, and server support for paging and persistent messaging will all have to be optimized in order to get maximum performance from the JMS server. Message selectors also affect performance, and several mechanisms that are used are discussed in the book.     11. JMS clients can use WebLogic to dynamically create a permanent destination on the JMS server using methods that are asynchronous, and so there may be a large delay between when a request for a new destination is submitted and when the new destination is bound to the Java Naming and Directory Interface (JNDI) tree of the server. Polling will then have to be done by the client regularly in order to find out if the destination has been created.     12. JMS servers can of course be clustered, and JMS clients use connection factories to obtain connections to a JMS server, wherein a load balancing strategy is used to decide which server in the cluster should host the JMS connection. Connection routing can be used to improve scalability, even though it increases network traffic, but network traffic can be minimized for server-side applications. 13. WebLogic uses transaction collocation to reduce network traffic by collocating objects on the server on which the transaction was initiated. If multiple objects are cluster-aware and are engaged in a distributed transaction, WebLogic will collocate the objects on the server on which the transaction had started.	2004-06-07
639296:US	50702879	R3IDCB5JWKSEL	0471104000	282688294	Energy and Power Risk Management: New Developments in Modeling, Pricing, and Hedging	Books	4	22	23	N	Y	Good overview	The management of risk in the context of energy or weather is quite different than in other contexts, due to the peculiarities of the data that occurs in energy prices. The high volatility of energy prices can range, as the authors of this book point out, between 50-100% for gas, to 100-500% for electricity. No doubt this kind of volatility, and other properties such as correlations and mean reversion, entails that some different mathematical strategies for modeling energy derivatives be devised. The authors give a good tour of some of these strategies, and anyone interested in energy derivatives will gain a lot of insight into their modeling when reading this book. Due to space constraints, only chapters 5 and 7, which this reviewer considered the most important of the book, will be reviewed here.<br />In chapter 5 the author presents techniques for energy modeling that go beyond the used of the convenience yield by using forward pricing techniques. The goal is to describe the dynamics of future contract prices that takes into account the correlations with other futures, and not on the price evolution of a single contract. Thus it is the `forward curve' that is relevant for obtaining a useable model for derivative cash flow. The HJM model is presented as one of these, with changes in the forward curve over a particular time interval represented as a linear combination of random perturbations. For energy markets, each perturbation is specified by a deterministic shape function multiplied by a Gaussian factor. The unobservability of the factors determining the forward curve evolution makes the use of historical data mandatory if the parameters are to be estimated. But lack of sufficient historical data and its nonstationarity complicate this estimation. The authors discuss the Schwartz-Smith multi-factor model as an example of a forward curve dynamics model and give some solutions. They then move on to a model that specifies the dynamics for only the contracts that are actually traded, which in the literature are called `market models.' The model they actually discuss is a multivariate geometric Brownian motion representation of the forward curve dynamics, where the volatility and drift functions are linear functions of the forward prices. The authors then derive the `discrete string models', where it is assumed that the number of factors is equal to the number of contracts, and the random factors are governed by ordinary Brownian motion. String models are represented as having the advantage of being able to directly observe the factors in the historical data. The authors apply string models to multi-commodity cases, and discuss an example for monthly forward prices. They show how to match the current forward curve, the option prices, and the correlation structure for this model.<br />The discussion in chapter 7 revolves around finding better models for the dynamics of power prices that capture the special properties of energy prices, such as mean reversion and seasonality, and the need for stable models. They therefore introduce `hybrid models', which they claim give a more natural representation of the dynamics of power prices, make use of nonprice forward-looking information, and can take the historical data on power prices and then extend it to information on fuel prices, outages, etc. The construction of these models is based on the use of nonlinear transformations on a collection of random variables. The random variables are essentially the system demand, natural gas and oil price, outages, emission prices, and weather at a particular time. The power price then can be written as a function of the dynamics of these factors, the latter written by the authors in terms of the corresponding tradables. Recognizing that hedging cannot be done on some of these factors, they adjust the power price formula so that the power tradables, i.e. the forwards and option prices, are exactly matched. This matching transformation is chosen so that if the forward contracts and options are priced using the adjusted formula, one recovers the exact current prices. The model, as the authors summarize it, is an attempt to explain the behavior of the tradables in terms of the evolution of the underlying factors and static adjustments to the terminal probability distribution. Historical information on the tradables and spot products is not used to calibrate the model, but it is used to validate the model. The authors distinguish between `reduced-form' hybrid models, where the transformation is calibrated from the historical prices, and `fundamental' hybrid models, where the transformation is calibrated from the market structure and is only tested on the historical prices. The authors discuss an example of a reduced-form hybrid model that is heavily parametrized, but has the advantage of using price data more efficiently. The rest of the chapter concentrates on fundamental hybrid models, with the author first discussing how power prices are formed in competitive markets. They consider a typical pool market, with the price determined via auction mechanisms. The authors then try to identify and characterize the underlying random variables that actually affect power prices. The time series for the price of power is written in terms of the demand using a `bid stack' function. The bid stack function is approximated by a `generation stack' that is found for a given time by sorting generation units by their generation costs. This approximation is checked by comparing the marginal generation costs generated by the generation stack with the distribution of power prices determined by the time series via the bid stack. There should be agreement in both approaches between the higher order moments. This comparison forms the basis of the authors' hybrid approach to modeling power prices. A transformation is found which relates the marginal generation costs to the distribution of power prices with the requirement that the prices of market instruments used for calibration are matched, and the higher moments are (approximately) preserved. The transformation is not unique, and in fact a family of transformations induced by the multiplication and stack scaling operators can be found.so that if the forward contracts and options are priced using the adjusted formula, one recovers the exact current prices. The model, as the authors summarize it, is an attempt to explain the behavior of the tradables in terms of the evolution of the underlying factors and static adjustments to the terminal probability distribution. Historical information on the tradables and spot products is not used to calibrate the model, but it is used to validate the model. The authors distinguish between `reduced-form' hybrid models, where the transformation is calibrated from the historical prices, and `fundamental' hybrid models, where the transformation is calibrated from the market structure and is only tested on the historical prices. The authors discuss an example of a reduced-form hybrid model that is heavily parametrized, but has the advantage of using price data more efficiently. The rest of the chapter concentrates on fundamental hybrid models, with the author first discussing how power prices are formed in competitive markets. They consider a typical pool market, with the price determined via auction mechanisms. The authors then try to identify and characterize the underlying random variables that actually affect power prices. The time series for the price of power is written in terms of the demand using a `bid stack' function. The bid stack function is approximated by a `generation stack' that is found for a given time by sorting generation units by their generation costs. This approximation is checked by comparing the marginal generation costs generated by the generation stack with the distribution of power prices determined by the time series via the bid stack. There should be agreement in both approaches between the higher order moments. This comparison forms the basis of the authors' hybrid approach to modeling power prices. A transformation is found which relates the marginal generation costs to the distribution of power prices with the requirement that the prices of market instruments used for calibration are matched, and the higher moments are (approximately) preserved. The transformation is not unique, and in fact a family of transformations induced by the multiplication and stack scaling operators can be found.	2004-06-07
648020:US	50702879	R24R1PZRTD7ZLS	0060958332	568183119	The Language Instinct: How the Mind Creates Language (Perennial Classics)	Books	4	7	9	N	Y	Insightful and packed full of very interesting examples.	For a non-technical and non-orthodox introduction to the origins and characteristics of language this book is excellent. It could be read by anyone who is curious about linguistics as understood by an expert, but whose ideas on the subject are considered somewhat unconventional from the standpoint of modern research in linguistics. Indeed, the very title of this book may raise many an eyebrow from some entrenched schools of modern linguistics. The author though has written a highly interested book here, and after reading it one carries away a deep appreciation of the complexities of language.<br /> Some of more interesting and surprising facts that are discussed in the book include: 1. There has never been a tribe or group discovered that does not use language, and there is no evidence that a particular geographical region has acted as source of language that is spread to groups that previously did not use language. These facts do lend credence to the author's thesis that language is instinctual. 2. The level of industrialization or technology of a society apparently is not correlated with the complexity of the language used by that society. Examples of this are given, such as the Bantu language in Tanzania, whose resemblance to English is compared to the difference between chess and checkers. In addition, the author dispels the myth that individuals in the \\"lower classes\\" of society do not speak as eloquently or with as much sophistication as the \\"middle classes\\". The Black English Vernacular or BEV is cited as an example, and the author quotes studies that indicate higher frequency of grammatical sentences in working-class speech than in middle-class speech. 3. As further evidence to support his thesis that language is instinctual, the author points to the universality of language and language development in children (the latter being his specialty). Interestingly, he states that children reinvent language not because they are \\"smart\\" but because \\"they can't help it.\\" In more than one place in the book he expresses his belief that intelligence is not needed for the acquisition of language. If it indeed it is not, this gives an interesting twist to the current efforts in artificial intelligence to produce machines that are capable of ordinary language. A machine therefore may be designated as \\"intelligent\\" even though it does not have ordinary language capabilities. An immediate consequence of this is that one cannot take the absence of the language ability in machines as evidence that they are not intelligent, as is done many times in the literature that is critical of AI. 4. The discussion of `pidgins' and the `creole' that results when children make them their native tongue. The author cites the construction of these creoles as further evidence of his thesis, for children can take the simple pidgin word strings and without any coaching develop a highly sophisticated, very expressive language. Another example of a pidgin, also discussed by the author, is the independent development of sign language by deaf Nicaraguan children after the failure of teaching them speech reading. This eventually resulted in the Lenguaje de Signos Nicaraguense or LSN that is used to this day.<br /> It remains to be seen whether the author's thesis will eventually be accepted by future linguists. Further research in neuroscience will no doubt shed light on the real origins of language, and once understood natural language capabilities will no doubt be implemented very straightforwardly in the machines, whether or not it is advantageous or not to have machines with these capabilities.it.\\" In more than one place in the book he expresses his belief that intelligence is not needed for the acquisition of language. If it indeed it is not, this gives an interesting twist to the current efforts in artificial intelligence to produce machines that are capable of ordinary language. A machine therefore may be designated as \\"intelligent\\" even though it does not have ordinary language capabilities. An immediate consequence of this is that one cannot take the absence of the language ability in machines as evidence that they are not intelligent, as is done many times in the literature that is critical of AI. 4. The discussion of `pidgins' and the `creole' that results when children make them their native tongue. The author cites the construction of these creoles as further evidence of his thesis, for children can take the simple pidgin word strings and without any coaching develop a highly sophisticated, very expressive language. Another example of a pidgin, also discussed by the author, is the independent development of sign language by deaf Nicaraguan children after the failure of teaching them speech reading. This eventually resulted in the Lenguaje de Signos Nicaraguense or LSN that is used to this day. <br /> It remains to be seen whether the author's thesis will eventually be accepted by future linguists. Further research in neuroscience will no doubt shed light on the real origins of language, and once understood natural language capabilities will no doubt be implemented very straightforwardly in the machines, whether or not it is advantageous or not to have machines with these capabilities.	2004-05-31
649247:US	50702879	R160GE42QH8NEO	0764549758	941053521	Malicious Cryptography: Exposing Cryptovirology	Books	5	24	26	N	Y	Excellent	Bypassing computer security systems has sometimes been called an art rather than a science by those who typically do not interact with computing machines at a level that would allow them to appreciate the science behind security attacks. This book does not address the strategies of how to bypass security systems, but instead concentrates on how to use cryptographic methods to corrupt the machines once access has been acquired. Clearly the authors are very excited about the developments in cryptovirology, a relatively young field, that have taken place in the last five years. Their goal though is not to train hackers to break into systems, but rather to coach the reader on how to find vulnerabilities in these systems and then repair them. The subject of cryptovirology is fascinating, especially in the mathematics that is uses, and a thorough knowledge of its power will be required for meeting the challenges of twenty-first century network computing.<br /> After a \\"motivational chapter\\" that it meant to shed insight on what it is like to be a hacker, this being done through a collection of short stories, the authors move on to giving a general overview of the field of cryptovirology in chapter 2. The reader gets his first dose of zero-knowledge interactive proofs (ZKIPs), which allow a prover to convince a verifier of a fact without revealing to it why the fact is true. The authors point out that viruses are vulnerable once found, since their rudimentary programming can be then studied and understood. This motivates the introduction of public key cryptography into the payload of the virus, and it is at this point that the field of cryptovirology is born.<br /> Chapter 3 is more of a review of modular arithmetic, entropy generators, and pseudorandom number generators and can be skipped for those readers familiar with these. The authors emphasize the need for effective random number generators and in using multiple sources for entropy generation. They also introduce the very interesting concept of a `mix network', which allows two mutually distrusting parties to communicate securely and anonymously over a network. `Onion routing' is discussed as a method for implementing asynchronous mix networks. Mix networks can be used to hide the propagation history of a worm or virus.<br /> In chapter 4, the authors discuss how to implement anonymous communication and how to launch a cryptotrojan attack that utilizes an anonymous communication channel. There are many applications of anonymous communication, one being E-money, and also, unfortunately, money laundering. The authors describe in fair detail how to conduct criminal operations with mix networks and anonymous money. This same technology though allows freedom of speech in geographical areas that are not sympathetic to it. Electronic voting, so controversial at the present time, is discussed as an activity that is very susceptible to the threat of stegotrojans or government violation of anonymity. Techniques for doing deniable password snatching using cryptovirology, and for countering it using zero-knowledge proofs, are also discussed.<br /> Chapter 5 introduces techniques for preventing the reading of counters when a virus is propagating from one machine to another. Known as `cryptocounters', the authors discuss various techniques for constructing them, such as the ElGamal and Paillier public key cryptosystems.<br /> Private information retrieval (PIR), which allows the secure and private theft of information, is discussed in chapter 6, wherein the authors present a few schemes for performing PIR. These schemes, unfortunately, allow the theft of information without revealing anything about the information sought and without revealing anything about what is taken. The authors also introduce a concept that they call `questionable encryptions', which are algorithms to produce valid encryptions or fake encryptions depending on the inputs. Related to question encryption, and also discussed in this chapter, are `deniable encryptions', which allow the sender to produce fake random choices that result in the true plaintext to be kept secret. Also discussed is the topic of `cryptographic computing', which allows computations with encrypted data without first having to decrypt it. The modular arithmetic used in this chapter is fascinating and well worth the read.<br /> Chapter 7 is by far the most interesting of the entire book, and also the most disconcerting if its strategies are ever realized. The goal of the chapter is to find out to what extent a virus can be constructed whose removal will damage the host machine. This, in the author's opinion, would be a genuine `digital disease', and they discuss various scenarios for bringing it about, which are at present not realized, but could be in the near future. The approach discussed involves game theory, and the authors show how the payload of a virus can survive even after discovery of the virus. They give a very detailed algorithm on how to attack a brokerage firm, including the assumptions that must be satisfied by such an attack. The attack is mounted by deploying a distributed cryptovirus that tries to find three suitable host machines, and the attack consists of three phases, the first involving replication leading to the infection of the three machines, the second involving preparation for the attack, and third involving playing the two-player game. The host machines, to be acceptable for launching the attack, must either be \\"brokerage\\" machines, which have sensitive information available to the virus, or \\"reclusive\\" machines, which are machines that are not subjected to much scrutiny.  The goal of the virus, according to the authors, is to give the malware purchasing power, and not direct monetary gain. The virus may then evolve over time to become a portfolio manager, and may even act as a surrogate for purchasing shares on behalf of the firm or client. Other possibilities for the virus are discussed, and the authors overview the security of the attack and its utility.<br /> I did not read the rest of the chapters in the book, so I will omit their review.scussed in this chapter, are `deniable encryptions', which allow the sender to produce fake random choices that result in the true plaintext to be kept secret. Also discussed is the topic of `cryptographic computing', which allows computations with encrypted data without first having to decrypt it. The modular arithmetic used in this chapter is fascinating and well worth the read. <br /> Chapter 7 is by far the most interesting of the entire book, and also the most disconcerting if its strategies are ever realized. The goal of the chapter is to find out to what extent a virus can be constructed whose removal will damage the host machine. This, in the author's opinion, would be a genuine `digital disease', and they discuss various scenarios for bringing it about, which are at present not realized, but could be in the near future. The approach discussed involves game theory, and the authors show how the payload of a virus can survive even after discovery of the virus. They give a very detailed algorithm on how to attack a brokerage firm, including the assumptions that must be satisfied by such an attack. The attack is mounted by deploying a distributed cryptovirus that tries to find three suitable host machines, and the attack consists of three phases, the first involving replication leading to the infection of the three machines, the second involving preparation for the attack, and third involving playing the two-player game. The host machines, to be acceptable for launching the attack, must either be \\"brokerage\\" machines, which have sensitive information available to the virus, or \\"reclusive\\" machines, which are machines that are not subjected to much scrutiny.  The goal of the virus, according to the authors, is to give the malware purchasing power, and not direct monetary gain. The virus may then evolve over time to become a portfolio manager, and may even act as a surrogate for purchasing shares on behalf of the firm or client. Other possibilities for the virus are discussed, and the authors overview the security of the attack and its utility. <br /> I did not read the rest of the chapters in the book, so I will omit their review.	2004-05-30
654912:US	50702879	R1ATQ9OD3N22XM	0595307337	737690839	THE SCYLLA HEXAGRAM: KYM A-1	Books	3	2	3	N	N	Farfetched from a financial point of view...but kinda fun.	As novels go, this one is short (defined as a \\"speednovel\\" in a press release for the book), but that should not dissuade one from reading it. Its plot structure is based on an interesting field, namely financial engineering, a field that has taken a lot of heat lately, thanks to several financial debacles widely reported in the press. A few of these scandals involved financial manipulations that resulted in hundreds of billions of dollars. The demise of these scams is illustrative of the difficulty in keeping financial manipulations secret. The complexity of the financial networks precludes any group of individuals from their manipulation and control. Such manipulations are eventually detected, due in part to the astuteness of investors and in highly sophisticated machines used to predict and monitor financial data from markets all over the world.<br /> Thus the financial manipulation of Obermeyer, one of the characters in the book, and a `star trader' who attempts to achieve global financial control in the guise of the `Scylla hexagram,' is farfetched. The story is full of references to financial terminology, no doubt to make the less knowledgeable reader be able to follow the story. To the more sophisticated reader with a financial background though, they are somewhat of a distraction. The story would have been much more interesting (and credible) if the author had wrote it for a more restricted readership instead of trying to reach a the general reader not schooled in the details of finance. There are many methods of hiding and controlling financial data maliciously, such as using viruses and intelligent agents. Such viruses and agents are studied under the growing field of cryptovirology, and would have made a superb plot device in this story. To make use of the strategies of cryptovirology would have made the story much more interesting, and would even serve as a warning siren to the possible dangers of using these strategies maliciously for financial manipulation and control.<br /> The book though does have some interesting characters, even though the velocity of the book suppresses their development in any great detail. Indeed, Kym Blaze keeps the reader on edge as to the cause of her nervousness and frequently timidity. Her attitude about money is interesting in the way it was described by the author, namely that \\"it has many flavors\\" in that people have different attitudes about how to earn money and live or live without it. Kym was fascinated about the laws governing the flow of money, and had a strong desire to understand these laws. Kym was also described as having a photographic memory, which made her a strong candidate for an intelligence agent. Obermeyer is an interesting character also, but he could more effectively be morphed into a network virus or intelligent agent that moves from one machine to another, leaving no traces by encrypting its presence, and fooling investors into making financial decisions based on its manipulations. Humans do not have the speed and skill to make financial decisions at the enormous scale needed for global control of the financial markets. Obermeyer as human is farfetched, but Obermeyer as a network cryptovirus would be formidable.ation and control. <br /> The book though does have some interesting characters, even though the velocity of the book suppresses their development in any great detail. Indeed, Kym Blaze keeps the reader on edge as to the cause of her nervousness and frequently timidity. Her attitude about money is interesting in the way it was described by the author, namely that \\"it has many flavors\\" in that people have different attitudes about how to earn money and live or live without it. Kym was fascinated about the laws governing the flow of money, and had a strong desire to understand these laws. Kym was also described as having a photographic memory, which made her a strong candidate for an intelligence agent. Obermeyer is an interesting character also, but he could more effectively be morphed into a network virus or intelligent agent that moves from one machine to another, leaving no traces by encrypting its presence, and fooling investors into making financial decisions based on its manipulations. Humans do not have the speed and skill to make financial decisions at the enormous scale needed for global control of the financial markets. Obermeyer as human is farfetched, but Obermeyer as a network cryptovirus would be formidable.	2004-05-25
657477:US	50702879	R1C0SSI9KZN4FR	3540629270	408749143	Foundations of Inductive Logic Programming (Lecture Notes in Computer Science)	Books	4	4	4	N	Y	A prelude to automated scientific discovery	Inductive logic programming (ILP) has come a long way since the early work of the 1970's. The last decade saw the field explode due to practical inductive programming languages being developed. The ability of machines to engage not only in experimentation but also in scientific hypothesis generation that is competitive with human scientists has recently been reported in the literature. It remains to be seen how efficacious these machines are in producing useful scientific hypothesis, but the fact remains that inductive logic programming has played a major role in these developments, and this will no doubt continue in the years to come. This book gives a good overview of ILP from a foundational and theoretical viewpoint. Due to lack of space only selected chapters will be reviewed here.<br />After a thorough overview of logic programming in the first part of the book, the discussion of inductive logic programming begins in part 2, namely in chapter 9, wherein the authors begin by defining induction as learning a general theory from specific examples. Inductive logic programming is characterized as the `intersection of machine learning and logic programming', whose goal is to learn from examples within the framework of clausal logic. The examples and the `background knowledge' are clauses, and the theory derived from them will also consist of clauses. The examples consist of `positive', which are true, and `negative' examples, which are false. The examples are usually ground atoms or ground clauses, depending on the approach used for generalization. In order for the eventual theory to be meaningful, it must, along with the background knowledge, be `complete' (imply the positive examples), and `consistent' (not contradict the negative examples). A theory that is both complete and consistent is said to be `correct'. It is not assumed that the correct theory will be unique. In fact, the authors assume that there may be many \\"hidden\\" theories that could be extracted from the examples and background knowledge. The discovery of a satisfactory theory thus implies that a search be made in the search space of permissible clauses.<br />The authors distinguish between `batch learning', wherein all the examples are given right away, and `incremental learning', where the learning takes place on examples one at a time. Also addressed is the need for bias in the search for theories, and the resulting trade-off in efficiency and the quality of the resulting theory. `Predicate invention' is described as something that might be needed for successful theory construction. The authors stress that the results of the book can be applicable to a nonmonotonic setting.<br />A more formal discussion of ILP is given in chapter 10. A clausal language consisting of the `observational language' that includes the positive and negative examples, and the `hypothetical language' that is used to formulate the theory, is considered. An oracle is used to obtain the truth-values of the examples. The authors discuss how to weaken a theory by using backtracking, and how to strengthen a theory using refinement operators.<br />Chapter 11 discusses `inverse resolution' which is the tour de force of inductive theory discovery. Although not required for understanding the rest of the book, this chapter does introduce the reader to a very important strategy for bottom-up approaches to ILP.<br />In chapter 12, `unfolding' is introduced as a specialization technique that is dual to inverse resolution, and consists of constructing resolvents from given parent clauses. It is used to correct a theory that is overly general. UDS specialization is discussed as a specialization technique that performs a finite number of applications of unfolding, clause deletion, and subsumption on a definite program, and is shown to be complete.<br />Using the results on lattices in chapter 13, namely the lattice of atoms quasi-ordered by subsumption, the authors show that clausal languages and Hornclauses are lattices under subsumption in chapter 14. This means that every finite collection of clauses has a least generalization and a greatest specialization under subsumption. They also show that one cannot generalize this to arbitrary clauses, in that there exists clauses that do not have finite complete sets of downward or upward covers. All of these results depend on defining a strict order on clauses, which is called the `atomic order'. Particularly interesting in this discussion is the complexity measure that the authors introduce on the set of clauses. This measure is not based on size, but instead is a pair of coordinates, where the first coordinate is the size of the largest literal in the clause, and the second coordinate is the number of literals in the clause.<br />The authors take up the difficulties of doing implication between clauses in chapter 15. Subsumption is prevalent in ILP because it is decidable, whereas implication is not. The authors give examples illustrating that subsumption is weaker than implication, and that subsumption is not sufficient for the construction of least generalizations. Recognizing that Horn clauses do not have a least generalization under implication, the authors give criteria for when a finite set of clauses does have a least generalization, namely that set must contain at least one function-free non-tautologous clause. For the case of greatest specialization, they show that every finite set of clauses has a greatest specialization under implication.<br />The role that background knowledge plays in subsumption and implication is the subject of chapter 16. This brings up the topic of `relative subsumption', which goes way back to the beginnings of inductive logic programming. The authors address the existence of least generalizations under relative subsumption by first giving a counterexample showing that in general they do not. They then give criteria that guarantee the existence of least generalization under relative subsumption. The authors then discuss relative implication, showing that relative subsumption does not imply relative implication, and then give criteria for the existence of least generalizations under relative implication. Also studied is a notion of generalized subsumption which applies only to definite program clauses. The relation of this notion to implication and subsumption is discussed in detail.Horn clauses are lattices under subsumption in chapter 14. This means that every finite collection of clauses has a least generalization and a greatest specialization under subsumption. They also show that one cannot generalize this to arbitrary clauses, in that there exists clauses that do not have finite complete sets of downward or upward covers. All of these results depend on defining a strict order on clauses, which is called the `atomic order'. Particularly interesting in this discussion is the complexity measure that the authors introduce on the set of clauses. This measure is not based on size, but instead is a pair of coordinates, where the first coordinate is the size of the largest literal in the clause, and the second coordinate is the number of literals in the clause. <br />The authors take up the difficulties of doing implication between clauses in chapter 15. Subsumption is prevalent in ILP because it is decidable, whereas implication is not. The authors give examples illustrating that subsumption is weaker than implication, and that subsumption is not sufficient for the construction of least generalizations. Recognizing that Horn clauses do not have a least generalization under implication, the authors give criteria for when a finite set of clauses does have a least generalization, namely that set must contain at least one function-free non-tautologous clause. For the case of greatest specialization, they show that every finite set of clauses has a greatest specialization under implication. <br />The role that background knowledge plays in subsumption and implication is the subject of chapter 16. This brings up the topic of `relative subsumption', which goes way back to the beginnings of inductive logic programming. The authors address the existence of least generalizations under relative subsumption by first giving a counterexample showing that in general they do not. They then give criteria that guarantee the existence of least generalization under relative subsumption. The authors then discuss relative implication, showing that relative subsumption does not imply relative implication, and then give criteria for the existence of least generalizations under relative implication. Also studied is a notion of generalized subsumption which applies only to definite program clauses. The relation of this notion to implication and subsumption is discussed in detail.	2004-05-23
664866:US	50702879	R3LIIG99DKCQBV	0130125342	886789933	Learning Bayesian Networks	Books	5	66	74	N	Y	An excellent overview	In just a decade, Bayesian networks have went from being a mere academic curiosity to a highly useful field with myriads of applications. Indeed, the applications of Bayesian networks are wide-ranging and include disparate fields such as network engineering, bioinformatics, medical diagnostics, and intelligent troubleshooting. This book gives a fine overview of the subject, and after reading it one will have an in-depth understanding of both the underlying foundations and the algorithms involved in using Bayesian networks. The reader will have to look elsewhere for applications of Bayesian networks, since they are only discussed briefly in the book. Due to space constraints, only the first four chapters will be reviewed here.<br />The author defines a Bayesian network as a graphical structure for representing the probabilistic relationship among a large number of variables and for performing probabilistic inference with these variables. Before the advent of Bayesian networks, probabilistic inference depended on the use of Bayes' theorem, which entailed that the problems examined be relatively simple, due to the exponential space and time complexity that can arise in the application of this theorem.<br />After a short review of probability theory in chapter 1, a discussion of the \\"philosophical\\" foundations of probability, and a discussion of the difficulties inherent in representing large instances and in performing inference over a large number of variables, the author introduces Bayesian networks as directed acyclic graphs satisfying the Markov condition. A brief discussion of NasoNet, which is a large-scale Bayesian network used in the diagnosis and prognosis of nasopharyngeal cancer, is given. The author then shows in detail how to create Bayesian networks using causal edges, introducing in the process the notion of manipulating variables and the notion of a causation between two variables. An interesting example of manipulation is given in the context of pharmaceuticals, and an example of bad manipulation is given.<br />Chapter 2 addresses the nature of dependencies in DAGs via the concept of `faithfulness' and entailed conditional independencies. Very important in this chapter is the notion of `d-separation', which identifies all and only those conditional independencies entailed by the Markov condition for G. An explicit algorithm is given for finding d-separations. D-separation is used to define a notion of Markov equivalence between DAGs containing the same set of nodes. Also discussed is the minimality condition, wherein a DAG will not satisfy the Markov condition with respect to a probability distribution if an edge is removed from it. The author shows every probability distribution satisfies the minimality condition with some DAG. The notion of a `Markov blanket' is introduced, which measures the extent to which the instantiation of a set of nodes close to a particular node can shield the node from the effect of all other nodes. A Markov boundary of a random variable is then defined as a Markov blanket such that none of its proper subsets is a Markov blanket of the random variable. The utility of these concepts lies in the fact that the set of all parents of each variable X, children of X, and parents of children of X are the unique Markov boundary of X, if the DAG satisfies the faithfulness condition.<br />Inference in Bayesian networks is the topic of chapter 3, with Pearl's message-passing algorithm starting off the discussion for the case of discrete random variables. This algorithm, which applies for Bayesian networks whose DAGs are trees, is based on a theorem, whose statement takes well over a page, and whose proof covers five pages. The author gives detailed examples though, and these are very helpful in understanding the algorithm. The Pearl algorithm is then generalized to singly and multiply connected networks. After a discussion of the computational complexity of the algorithm, the author then overviewsthe `noisy OR-gate model', which is a model whose complexity is manageable, since each variable in the model has only two values. The author then moves on to doing inference using an approach, called `symbolic probabilistic inference' that approximates finding the optimal way to compute marginal distributions of interest from the joint probability distribution. This algorithm involves a number of multiplications in order to compute the marginal probability. To minimize the computational effort, it would be advantageous to minimize the number of these multiplications, and so the author discusses the `optimal factoring problem', which, once solved for a given factoring instance, will give a factorization that requires a minimal number of multiplications. What follows after this is a very interesting discussion of the relationship of human reasoning to Bayesian networks. This is done via the introduction of the `causal network model', and the author then, quite unexpectedly, overviews the research on the testing of human subjects so as to test the accuracy of the model. These testing studies included those that involve inference based on `discounting', which measures to what degree an individual becomes less confident in the cause when told that a different cause of the effect was present. Another discussed is one that involves larger networks in the context of traffic congestion. This is followed by a discussion of a study of causal reasoning in the context of the debugging of programs.<br />Inference algorithms are studied for the case of continuous variables in chapter four. After a review of the normal probability distribution, the author discusses an inference algorithm for the case of Gaussian Bayesian networks. An algorithm for doing inference with continuous variables for singly connected Bayesian networks is given, that allows the determination of expected value and variance of each node conditioned on specified values of nodes in some subset. This is followed by several detailed and helpful examples of inference in continuous variables. As expected, issues with computational complexity arise, and so the author discusses approximate inference, via the method of stochastic simulation, which involves a classical sampling method called `logic sampling.' This is then followed by a discussion of likelihood weighting, which cures some of the problems involved with logic sampling. Abductive inference, so important in contemporary applications, is then discussed in detail.iews the `noisy OR-gate model', which is a model whose complexity is manageable, since each variable in the model has only two values. The author then moves on to doing inference using an approach, called `symbolic probabilistic inference' that approximates finding the optimal way to compute marginal distributions of interest from the joint probability distribution. This algorithm involves a number of multiplications in order to compute the marginal probability. To minimize the computational effort, it would be advantageous to minimize the number of these multiplications, and so the author discusses the `optimal factoring problem', which, once solved for a given factoring instance, will give a factorization that requires a minimal number of multiplications. What follows after this is a very interesting discussion of the relationship of human reasoning to Bayesian networks. This is done via the introduction of the `causal network model', and the author then, quite unexpectedly, overviews the research on the testing of human subjects so as to test the accuracy of the model. These testing studies included those that involve inference based on `discounting', which measures to what degree an individual becomes less confident in the cause when told that a different cause of the effect was present. Another discussed is one that involves larger networks in the context of traffic congestion. This is followed by a discussion of a study of causal reasoning in the context of the debugging of programs. <br />Inference algorithms are studied for the case of continuous variables in chapter four. After a review of the normal probability distribution, the author discusses an inference algorithm for the case of Gaussian Bayesian networks. An algorithm for doing inference with continuous variables for singly connected Bayesian networks is given, that allows the determination of expected value and variance of each node conditioned on specified values of nodes in some subset. This is followed by several detailed and helpful examples of inference in continuous variables. As expected, issues with computational complexity arise, and so the author discusses approximate inference, via the method of stochastic simulation, which involves a classical sampling method called `logic sampling.' This is then followed by a discussion of likelihood weighting, which cures some of the problems involved with logic sampling. Abductive inference, so important in contemporary applications, is then discussed in detail.	2004-05-17
672780:US	50702879	R3I5ZBMWNDYWTH	0670881465	184172254	The 48 Laws of Power	Books	1	47	87	N	N	Advice for the insecure, the incompetent, and the coward.	This is a remarkably silly book, both in terms of its actual content and in its claim of generality. The author offers only anecdotal and meager historical evidence for his claims, never any scientific analysis supported by careful statistical sampling. Does the author seriously believe that if the advice in this book is followed that any individual will be able to become a \\"powerful\\" person? Has he studied the histories of individuals who have decided to follow his advice, in order to judge their \\"success\\" as compared to those who did not follow such advice?<br /> I ran across this book in the psychology section of a local bookstore, and believed it to be a psychological study of \\"power-seekers\\". Curious as to answering the question as to whether the attainment of power is an objective requirement for the human psyche, or whether the lust for it is a symptom of a dysfunctional, maladjusted individual, I believed that a psychological study done with rigorous, painstaking scientific methods would shed light on this question. After a brief perusal of the book however, I concluded that the book must be a parody of the power-seeker, not to be taken seriously, serving only to amuse or poke fun of those whom are easily suckered by the ill-defined and transitory rewards of \\"power\\".<br /> But if the book is read in its entirety, which I did, it seems as though the author really believes what he is putting in print. This is unfortunate, since better use could be made of time and resources. It takes energy to move a pen or move fingers on a keyboard, to produce the paper for this book, and to manufacture its ink. All of this energy is totally wasted on this book, including the energy needed to read it.<br />Only a fool, a coward, or the weak-minded would follow the advice in this book. It is written for the uncreative, the yellow-belly, the psychologically insecure. Individuals with these traits are always in a perpetual state of fear, for they know that their mind is impotent, that the slightest perturbation will knock them out of their unstable equilibrium of imagined security. Such people are easy to spot, for they never say anything of any consequence. If their mental competence is challenged, they will come apart at the seams. Then watch them flee, and laugh out loud when these petty scoundrels scurry away like scared ants. Any revenge they take is to be scoffed at, for when one stands up to them with the sword of mental competence, their schemes will dissolve into nothingness. Chuckle at their obsequious flatteries, and be entertained with the observations of their stupidity, as they try and pass themselves off as \\"powerful\\" people. They are better to watch than circus clowns, and their make-up is always smeared. The self-confident, mentally astute individual is their anathema, but their dependence on such an individual is overwhelming. They need the competent, but never the other way around. Such is the nature of their \\"power\\": it is in reality pure weakness and has enormous fragility.<br />The book has to rank as one of the worst ever written, for it is serious in its petty doctrines. It encourages the practice of evasion and theft. It attempts to circumvent the practical and the competent, not knowing that such an attempt is doomed to failure. It confuses realism with cynicism, and it equates the acquisition of wealth with its plundering. Wallowing in a vague cesspool of self-satisfaction, it peddles power as if it were a commodity, forgetting that its reality is tenuous, and its lifetime is fleeting.ent, that the slightest perturbation will knock them out of their unstable equilibrium of imagined security. Such people are easy to spot, for they never say anything of any consequence. If their mental competence is challenged, they will come apart at the seams. Then watch them flee, and laugh out loud when these petty scoundrels scurry away like scared ants. Any revenge they take is to be scoffed at, for when one stands up to them with the sword of mental competence, their schemes will dissolve into nothingness. Chuckle at their obsequious flatteries, and be entertained with the observations of their stupidity, as they try and pass themselves off as \\"powerful\\" people. They are better to watch than circus clowns, and their make-up is always smeared. The self-confident, mentally astute individual is their anathema, but their dependence on such an individual is overwhelming. They need the competent, but never the other way around. Such is the nature of their \\"power\\": it is in reality pure weakness and has enormous fragility. <br />The book has to rank as one of the worst ever written, for it is serious in its petty doctrines. It encourages the practice of evasion and theft. It attempts to circumvent the practical and the competent, not knowing that such an attempt is doomed to failure. It confuses realism with cynicism, and it equates the acquisition of wealth with its plundering. Wallowing in a vague cesspool of self-satisfaction, it peddles power as if it were a commodity, forgetting that its reality is tenuous, and its lifetime is fleeting.	2004-05-11
675103:US	50702879	R39W8WHAC641WB	0465037712	688146771	Where Mathematics Come From: How The Embodied Mind Brings Mathematics Into Being	Books	4	17	20	N	Y	An interesting view of the nature of mathematics	For as long as Western mathematics has been around, it has generally been viewed as having an existence independent of human experience, as belonging to a Platonic realm of forms and ideas. To make it embodied in the human psyche, as the authors attempt to do in this book, would be a sacrilege to many mathematicians. Such a move would deny the `eternal truth' of mathematics some would argue.<br /> But the last few decades have seen the rise of cognitive science, and this field has led to many interesting insights into the operation of mind and has demystified its status in the world. The authors though see cognitive science as being deficient in one respect: it has omitted the study of mathematical ideas from a cognitive perspective. There is no cognitive science of mathematics, they say, and hence they endeavor in the book to correct this deficiency. Such a project is definitely worth the effort, for mathematics has to be interpreted in the light of what is known about the mind, or as the authors put it, \\"it should study precise nature of clear mathematical intuitions\\".<br /> The book is very interesting to read, and the justifications for the assertions put forward by the authors are certainly the most optimal if viewed in the context of what is currently known in cognitive science. Further work must be done however, particularly in tying their ideas to the very intensive research in neuroscience that is being done at the present time. The prospect of having a science of mathematical thought is an exciting one. This book is the best that is currently available.<br /> The attitude of the authors is most refreshing, in that they not only show great enthusiasm throughout the book, but they are not nervous about discarding what they view as the \\"romance\\" of mathematics. They list several statements illustrating this \\"beautiful romance\\", such as the view that mathematics has an objective existence, which transcends the existence of human beings; or that human mathematics is merely a part of abstract, transcendent mathematics, and that reason is a form of mathematics. These romantic beliefs appear to be false, the authors say. Instead, they argue, the nature of mathematical ideas is that they are inherently metaphorical in nature. They give several examples of this in the first few pages of the book, with the rest of the book elaborating in great detail their reasons for asserting this.<br /> This is certainly an exciting time to be involved in mathematics, and assuming more evidence is accumulated that supports the authors opinions on the embodied nature of mathematics, it will be even more interesting to be engaged in mathematical research and in the teaching of mathematics. Mathematical thinking will then viewed as part of us, not some abstract collection of statements existing in some vaguely defined realm. Viewing mathematics as purely embodied may also give much more insight into teaching non-human machines how to do mathematics. This is the most exciting prospect of all.atics is merely a part of abstract, transcendent mathematics, and that reason is a form of mathematics. These romantic beliefs appear to be false, the authors say. Instead, they argue, the nature of mathematical ideas is that they are inherently metaphorical in nature. They give several examples of this in the first few pages of the book, with the rest of the book elaborating in great detail their reasons for asserting this. <br /> This is certainly an exciting time to be involved in mathematics, and assuming more evidence is accumulated that supports the authors opinions on the embodied nature of mathematics, it will be even more interesting to be engaged in mathematical research and in the teaching of mathematics. Mathematical thinking will then viewed as part of us, not some abstract collection of statements existing in some vaguely defined realm. Viewing mathematics as purely embodied may also give much more insight into teaching non-human machines how to do mathematics. This is the most exciting prospect of all.	2004-05-09
683880:US	50702879	RAX6PLM4UJGZB	0849320283	344470790	Insect Transgenesis: Methods and Applications	Books	5	2	2	N	N	A detailed overview of transgenic strategies in insects.	This book gives a useful and fascinating overview of the status of transgenic strategies in insects as it was known in the year 2000. Written by experts in the field, it will introduce both biologists and non-biologists to many of the techniques used for the introduction of transgenes in insects. Readers are expected to have a fairly strong background in molecular genetics, but it could still be profitably read by anyone who is curious about this exciting technology. Due to space constraints, only a few of the articles will be reviewed here.<br />The first article gives a historical introduction to gene transfer in insects. The P-Element transformation was the first transposon-based system for transforming the germline in D. melanogaster efficiently and stably. This transposon is an example of the Class II short inverted terminal repeat transposons, and its high mobility made it a successful for Drosophila transformation. The P vector however was not successful in non-drosophilid insects, and therefore other choices for vector-mediated transfer were researched. Some of these are discussed in this article, such as the hobo transposon, Hermes, Minos (first to successfully transform a non-drosophilid, the medfly), piggyBac (second successful transformation agent in medflies), and the mariner element. Approaches to creating transient systems, employing viral and symbiont vectors, are also discussed.<br />In article 7, pantropic retroviral vectors for gene transfer in insects are discussed. These arose from the genetic modification of the Moloney murine leukemia virus in order that it contain the G envelope protein from the vesicular stomatitis virus (VSV-G). These vectors are considered to be stable once inserted into the genome and are incapable of self-propagation. Most importantly, these vectors are now extensively used for human gene therapy protocols. The somatic infection of larvae using these vectors has been accomplished in D. melanogaster, Aedes triseriatus, Culex tarsalis (the western encephalitis mosquito), Anopholes gambiae (the malaria mosquito), and Manduca sexta (the tobacco hawkmoth).<br />Article 8 overviews densonucleosis viruses as transducing systems for insects. These viruses are linear single-stranded DNA molecules between 4000 and 6000 nucleotides in length that it seems are restricted to arthropods. The primary application of these vectors has been to deliver genes into mosquitoes for the laboratory study of gene expression. It is hoped that they will be instrumental in control programs against mosquitoes. These viruses have a limited host range however, being restricted to the Aedes, Culex, and Culiseta mosquitoes. They are also considered to be limited in scope as gene-transfer vectors due to their small genome size and due to their (icosahedral) shape.<br />In the ninth article, RNA virus expression systems based on the Sindbis virus for efficiently transducing mosquito cells and allowing stable gene expression in various species of mosquitos, such as the yellow fever mosquito (Aedes aegypti), the eastern treehole mosquito (Aedes triseriatus), the northern house mosquito (Culex pipiens), and Anopholes gambiae, are discsussed. The Sindbis virus is an alphavirus, with a single-stranded RNA genome. The article discusses the protein expression in the saliva of Culex pipiens, in the midgut of Aedes aegypti, and the expression of antiviral RNAs in Aedes aegypti and Aedes triseriatus.<br />In article 11, the role of polydnaviruses in insect transgenic strategies is discussed. These viruses are multisegmented DNA viruses that are found exclusively in the female reproductive tracts of some wasps. Segmentation in the polydnavirus genomes is thought to have evolved in order to increase the copy number of essential viral genes. They are known to integrate stably into the chromosomal DNA of the cell line of a gypsy moth, and to infect and integrate in lepidopteran and coleopteran cell cultures. They are apparently difficult to engineer however, and but the author of the article believes that their impact may lie in pointing the way to other methods for performing transgenesis.<br />Article 12 discusses the Hermes vector for transforming insects other than D. melanogaster. First discovered in M. domestica (the common housefly), cell lines of Anopheles gambiae were stably transformed by Hermes, and Hermes has been transposed in the embryos of Aedes aegypti. It is described in the article as having a wide host range, with accurate transposition occurring in twelve species of insects.<br />In article 13, the genetic engineering of insects with mariner transposons is discussed, The mariner element was first isolated from Drosophila mauritiana, and the mariner family of transposons is known to be widespread in animal genomes. This has caused some to be concerned about the risks involved for active mariners released in insect control programs could invade other genomes, such as human genomes. The article describes the evidence of recent and ancient horizontal gene transfers between animal hosts as being \\"overwhelming.\\" The authors of the article though believe that one should not be concerned about releasing transgenic insects created with mariners into the environment. They give several reasons for not being concerned, one being that when nonautonomous mariners are used using a transient transposase, the resultant transformants are stable. In addition, the timescales involved are too long for horizontal gene transfer to be a significant risk, with over 100, 000 years being quoted as the most recent event for its occurrence. Only two mariner elements have invaded the human genome in the last 100 million years.<br />In the fourteenth article, the tagalong (TFP3) and piggyBac elements, both transposable elements of the TTAA-specific family, are reviewed in regards to their utility in the transformation of insects. The piggyBac element was first isolated from a nucleopolyhedrosis virus which infects cell cultures of the cabbage looper moth (Trichoplusia ni). The authors discusses several successful piggyBac transformations, such as in D. melanogaster, Aedes aegypti, Anopholes Gambiae, Bombyx mori (the domestic silk moth), Pectinophora gossypiella (the pink bollworm), and Tribolium castaneum (the red flour beetle). The horizontal transmission of piggyBac among species is considered to be a viable possibility for the authors, and they therefore devote a section to the safety concerns involved with the release of transgenic insects.ly difficult to engineer however, and but the author of the article believes that their impact may lie in pointing the way to other methods for performing transgenesis. <br />Article 12 discusses the Hermes vector for transforming insects other than D. melanogaster. First discovered in M. domestica (the common housefly), cell lines of Anopheles gambiae were stably transformed by Hermes, and Hermes has been transposed in the embryos of Aedes aegypti. It is described in the article as having a wide host range, with accurate transposition occurring in twelve species of insects. <br />In article 13, the genetic engineering of insects with mariner transposons is discussed, The mariner element was first isolated from Drosophila mauritiana, and the mariner family of transposons is known to be widespread in animal genomes. This has caused some to be concerned about the risks involved for active mariners released in insect control programs could invade other genomes, such as human genomes. The article describes the evidence of recent and ancient horizontal gene transfers between animal hosts as being \\"overwhelming.\\" The authors of the article though believe that one should not be concerned about releasing transgenic insects created with mariners into the environment. They give several reasons for not being concerned, one being that when nonautonomous mariners are used using a transient transposase, the resultant transformants are stable. In addition, the timescales involved are too long for horizontal gene transfer to be a significant risk, with over 100, 000 years being quoted as the most recent event for its occurrence. Only two mariner elements have invaded the human genome in the last 100 million years. <br />In the fourteenth article, the tagalong (TFP3) and piggyBac elements, both transposable elements of the TTAA-specific family, are reviewed in regards to their utility in the transformation of insects. The piggyBac element was first isolated from a nucleopolyhedrosisvirus which infects cell cultures of the cabbage looper moth (Trichoplusia ni). The authors discusses several successful piggyBac transformations, such as in D. melanogaster, Aedes aegypti, Anopholes Gambiae, Bombyx mori (the domestic silk moth), Pectinophora gossypiella (the pink bollworm), and Tribolium castaneum (the red flour beetle). The horizontal transmission of piggyBac among species is considered to be a viable possibility for the authors, and they therefore devote a section to the safety concerns involved with the release of transgenic insects.	2004-05-02
685055:US	50702879	RLV6KIX6WWGTI	012357031X	682186829	Insect Molecular Genetics, Second Edition: An Introduction to Principles and Applications	Books	5	3	3	N	Y	A fascinating overview	The genetic engineering of insects is now commonplace, and for those who want to understand the details behind this exciting and practical technology, this book gives an excellent overview. The goal of this reviewer, who is not a professional biologist, was primarily to understand the efficacy of transgenic strategies in the genetic manipulation of insects. For those with similar interests and backgrounds, the book fills the need, and after reading it, such readers will have a better understanding of just what is possible in the technology of genetic transformation of insects, along with obtaining a stronger background in genetics. This technology is improving and getting more powerful as this book went into print, and no doubt many more fascinating discoveries will take place in the near future. The genetic manipulation of insects shows much promise in not only reducing the threat of malaria but also in controlling unwanted insect populations. The risks involved in this technology are thankfully also addressed in the book.<br /> A thorough review of a book of this size and detail would take many thousands of words, and so attention here will be concentrated on the things that this reviewer found particularly interesting and the surprises in the book. One of these involved the discussion of the RNA era and its role in the early evolution of life. The author views this time as one where RNA organisms, which had multiple-copy double-stranded RNA genomes, these genomes later fragmenting into chromosomes. The interactions between the RNA and amino acids evolved into the present DNA world. Another interesting fact brought out is that DNA can form more than twenty different variations of right-handed helices, and can form left-handed helices in some regions.<br /> The author also discusses the role of exons and introns in molecular genetics, and the `introns-early' and `introns-late' hypotheses. Their role is still not completely understood, and there are many open questions in their study, as is brought out in the discussion.<br /> Still another interesting discussion concerns the role of telomeres in preventing the loss of DNA during replication and their role in ensuring the stability of linear chromosomes. It turns out that telomerase, an enzyme that is responsible for adding these telomeres to the ends, is, interestingly, a reverse transcriptase, meaning that it can transcribe DNA from an RNA template.<br /> The `C value paradox' is also discussed by the author, which she describes as a situation where there is more DNA then is needed by the organism. Surprisingly, the genome size is not correlated with the complexity of the organism or the number of genes encoded. The insect genome size varies widely among the insect species, with 250-fold differences in C values being common. The composition of insect DNA is apparently very different for insects than for vertebrates, with the author quoting the guanine and cytosine bases making up only 32-42% of the DNA, as compared to 45% for vertebrates.<br /> The many roles of heterochromatin is discussed in detail by the author, such as in chromosome mechanics, centromere function, and position effect variegation in Drosophila melanogaster. In the latter, this silences the euchromatic genes that have been moved to regions adjacent to heterochromatin by chromosomal rearrangements. This change in the location of the gene within the nucleus modifies significantly the amount of `gene silencing'. In the context of transgenic strategies, the transgenes inserted into the insect genome can be silenced because they become heterochromatized.<br /> A particularly fascinating discussion is given of the role of transposable elements in the insect genome. These can alter the gene structure and function, and can transfer horizontally between species. The microbial symbiont Wolbachia's role in insect evolution is discussed, and the amazing fact that insects contain three or four genomes, namely the nuclear, mitochondrial, gut symbionts, and Wolbachia, raising the question of just what constitutes a biological individual. Some species of insects can have diploid males and females, or haploid males and diploid females, or only females. In addition, diploid males may undergo chromosome heterochromatimization and loss during development and become haploid.<br />A very detailed overview of transgenic strategies and their role in pest management is given at the end of the book. Giving examples of what has been accomplished in traditional breeding for beneficial insects and in sterilization techniques for pest insects, the author discusses the justifications for using transgenic methods. Mention is made of using green fluorescent protein as a molecular marker to track sterile insects. The author argues that fluorescent dusts currently used are not satisfactory since they can reduce the fitness of the insects and do not always adhere to the insects, biasing the results of the sterilization program. The author is clearly supportive of transgenic strategies to perform pest management, but she gives many references that take more cautionary stances on this technology.  The author also makes the point that insect transgenesis is most appropriate for traits that are determined primarily by a single gene. The manipulation of traits determined by more complex genetic mechanisms are not yet feasible using transgenic strategies. Briefly discussed, but with many references given, are the different methods for transforming the insect germ-line, such as P-element vectors, Hermes, hobo, mariner, Minos, piggyBac, baculoviruses, densonucleosis viruses, pantropic retroviral vectors, polydnaviruses, retrotransposons, and sindbis viruses. Also discussed are paratransgenesis, which involves the genetic transformation of insect symbionts, and FLP-mediated recombination, which involves the introduction of cloned genes into the germ line at a predictable chromosomal site. This latter technique, the author argues, is very desirable for the reason that the likelihood of position effects on gene expression is considerably reduced.<br />Gene silencing, an evolved mechanism to prevent high-level expression of transposable elements, presents a challenge to transgenic strategies. The author discusses briefly some examples of transgene silencing in D. melanogaster. She points out that gene silencing might however be exploited positively by turning off specific genes in insects. References are given that discuss gene silencing in D. melanogaster. Horizontal gene transfer, hotly debated in the press these days, is discussed briefly.nuclear, mitochondrial, gut symbionts, and Wolbachia, raising the question of just what constitutes a biological individual. Some species of insects can have diploid males and females, or haploid males and diploid females, or only females. In addition, diploid males may undergo chromosome heterochromatimization and loss during development and become haploid. <br />A very detailed overview of transgenic strategies and their role in pest management is given at the end of the book. Giving examples of what has been accomplished in traditional breeding for beneficial insects and in sterilization techniques for pest insects, the author discusses the justifications for using transgenic methods. Mention is made of using green fluorescent protein as a molecular marker to track sterile insects. The author argues that fluorescent dusts currently used are not satisfactory since they can reduce the fitness of the insects and do not always adhere to the insects, biasing the results of the sterilization program. The author is clearly supportive of transgenic strategies to perform pest management, but she gives many references that take more cautionary stances on this technology.  The author also makes the point that insect transgenesis is most appropriate for traits that are determined primarily by a single gene. The manipulation of traits determined by more complex genetic mechanisms are not yet feasible using transgenic strategies. Briefly discussed, but with many references given, are the different methods for transforming the insect germ-line, such as P-element vectors, Hermes, hobo, mariner, Minos, piggyBac, baculoviruses, densonucleosis viruses, pantropic retroviral vectors, polydnaviruses, retrotransposons, and sindbis viruses. Also discussed are paratransgenesis, which involves the genetic transformation of insect symbionts, and FLP-mediated recombination, which involves the introduction of cloned genes into the germ line at a predictable chromosomal site. This latter technique, the author argues, is very desirable for the reason that the likelihood of position effects on gene expression is considerably reduced. <br />Gene silencing, an evolved mechanism to prevent high-level expression of transposable elements, presents a challenge to transgenic strategies. The author discusses briefly some examples of transgene silencing in D. melanogaster. She points out that gene silencing might however be exploited positively by turning off specific genes in insects. References are given that discuss gene silencing in D. melanogaster. Horizontal gene transfer, hotly debated in the press these days, is discussed briefly.	2004-05-01
692572:US	50702879	R2YUJ199J4HJMR	0804738513	80846635	1: Foundations of Cognitive Grammar: Volume I: Theoretical Prerequisites	Books	3	27	29	N	Y	Difficult reading but gives a different perspective.	Cognitive grammar is presented in this book as a theory that is \\"fundamentally at odds with the dominant trends in current linguistic theory\\", especially the generative tradition of grammar. The author's main thesis is the inseparability of syntax and semantics, and he attempts to present an account of linguistic structure that is independent of the any particular domain. The formalism of accepted linguistic theory is to be rejected, in favor of what the author calls a \\"conceptual clarification\\" of the fundamental issues in linguistics. Figurative language, with its idioms, metaphors, and \\"semantic extensions\\" is to be given central status, the author argues.<br />For this reviewer, the book was difficult reading, this no doubt due to its departure from the standard formal constructions of linguistics. The author recognizes the difficulty he faces in presenting his theory, he cautions the reader that the theory is not complete, but he asserts that the basic elements of the theory are \\"stable\\" enough to allow presentation in a work such as this. These basic elements are summarized as saying that semantic structure is not universal, but specific to a certain language; grammar is symbolic in nature and consists of the symbolization of semantic structure; and that grammar and lexicon cannot be distinguished.<br />Readers with a background in cognitive science or neuroscience may be taken aback by the author's carefree talk of the functioning of the human brain and mental events, which is frequently done with no empirical evidence to substantiate it. The author though is aware of the lack of evidence, for he says early on that some of the book could be regarded as an exercise in what he calls \\"speculative psychology.\\" He recognizes that his discussion of the cognitive workings of the human mind may not be accurate, but he believes that they are plausible and that the overall system he presents has enough coherence to be valid in many respects.<br />The \\"general assumptions\\" of cognitive grammar are that of \\"symbolization\\", namely that language is symbolic in nature and consists of an open-ended set of linguistic expressions. These expressions associate a semantic representation of some kind with a phonological representation, but this association is not entirely arbitrary. Grammar is the process of grouping morphemes into progressively larger configurations and is inherently symbolic. Grammatical and semantic components are not to be separated, for grammar is the structuring and symbolization of semantic content. The second assumption is that language is an essential part of human cognition, and that if one is to understand linguistic structure one needs to understand cognitive processing. There is no well-defined separation between linguistic ability and other forms of cognitive processing, and therefore cognitive psychology and linguistics must be integrated. The third assumption is that of `naturalness': descriptions must be `natural' in that they must deal with data in all its complexity and subtlety. Natural descriptions are to be contrasted with `artifactual' ones, which destroy the intrinsic organization of the data. Linguistic data is rarely discrete and linguistic categories are not always well defined. A linguistic theory must be `substantive', i.e. such a theory must possess conceptual clarity, and it must also correspond to something real.<br />For the author a `grammar' is a comprehensive description of its structure, with one class of grammars being those that can be written, and another being those that are envisioned by linguists. The latter do not exist he says, since they must satisfy requirements that cannot be met, such as being exhaustive in their coverage and psychologically accurate. The author though views cognitive grammar as a body of knowledge that can be constructed, that being done in terms of what he calls a `structured inventory of conventional linguistic units.' These units are the structures that have been mastered by the speaker to such an extent that they are habitual, and even though may have a large degree of `internal complexity', they are `effectively simple' in that they do not require constructive effort for their use.<br />Linguistic structures are organized on a continuous scale of what the author calls `entrenchment'. The regular use of a structure moves up its level of entrenchment, but long periods of disuse move it down. A novel structure can become so entrenched that it finally becomes a unit. Each unit has different degrees of entrenchment depending on its frequency of occurrence. The author asserts therefore that the greater the entrenchment the greater the linguistic significance.<br />The system of cognitive grammar is summarized as saying that semantic units are defined relative to cognitive `domains'. A concept or a knowledge base can function as one of these domains. In addition, linguistic semantics is asserted to be `encyclopedic', in that the meaning of an expression is usually dependent on specifications in many domains. Some of these domains play a more central role than others in giving this meaning. However, the role of expression in various domains can frequently be a peripheral aspect of its semantic value. The author encapsulates this by saying that language can `self-reference'. Lastly, the units are acquired through `decontextualization'. This means that through a process of abstraction, the extent of which is determined by the varieties of settings of the units and how consistently the units appear in these settings. The grammar of a language is to be viewed as an `inventory of linguistic units' and not a \\"generative description\\" that proceeds by formally constructing the well-formed sentences of the language. It is also not a set of operations what output the well-formed sentences. Language is not an autonomous formal system, but rather can only be understood and characterized in the context of a theory of human cognition. A complete description of human cognition would be needed to give an exhaustive description of language.t have been mastered by the speaker to such an extent that they are habitual, and even though may have a large degree of `internal complexity', they are `effectively simple' in that they do not require constructive effort for their use. <br />Linguistic structures are organized on a continuous scale of what the author calls `entrenchment'. The regular use of a structure moves up its level of entrenchment, but long periods of disuse move it down. A novel structure can become so entrenched that it finally becomes a unit. Each unit has different degrees of entrenchment depending on its frequency of occurrence. The author asserts therefore that the greater the entrenchment the greater the linguistic significance. <br />The system of cognitive grammar is summarized as saying that semantic units are defined relative to cognitive `domains'. A concept or a knowledge base can function as one of these domains. In addition, linguistic semantics is asserted to be `encyclopedic', in that the meaning of an expression is usually dependent on specifications in many domains. Some of these domains play a more central role than others in giving this meaning. However, the role of expression in various domains can frequently be a peripheral aspect of its semantic value. The author encapsulates this by saying that language can `self-reference'. Lastly, the units are acquired through `decontextualization'. This means that through a process of abstraction, the extent of which is determined by the varieties of settings of the units and how consistently the units appear in these settings. The grammar of a language is to be viewed as an `inventory of linguistic units' and not a \\"generative description\\" that proceeds by formally constructing the well-formed sentences of the language. It is also not a set of operations what output the well-formed sentences. Language is not an autonomous formal system, but rather can only be understood and characterized in the context of a theory of human cognition. A complete description of human cognition would be needed to give an exhaustive description of language.	2004-04-25
700044:US	50702879	R13ZQXBS4IPSK7	0262561093	541589652	Artificial Minds (MIT Press)	Books	5	6	6	N	N	Good book for the time of publication	This book brings some refreshing new ideas and perspectives to the field of artificial intelligence. Although qualitative in his approach, and written for a \\"general audience\\", the author offers many insights into a field whose view of intelligence has been interpreted solely in terms of human capabilities. The author offers several alternatives for defining and measuring machine intelligence, all of them interesting, but needing more integration into practical applications in order to test their efficacy. His ideas though serve as strong perturbations that lift the field out of the local equilibrium it frequently finds itself in. He does occasionally wade into the muddy waters of speculative philosophy in the guise of the \\"mind-body problem\\", but the time spent in doing this is more than made up for by his efforts to define and give advice on how to build an artificial mind.<br /> The author is fully aware of the roller-coast ride of confidence and false optimism that the field of machine intelligence has taken in the last five decades. He describes the \\"brittleness\\" of AI systems that are usually confined to a specific domain, such as chess or natural language processing, but cannot be used with drastic modification in other domains. It is the opinion of this reviewer that such domain-specific systems are intelligent, but should be classified as a form of \\"low-level intelligence\\". Systems that can cross learn across domains have a higher level of intelligence. The author could easily incorporate such a classification since his view of the mind is that it is \\"continuous\\" rather than a \\"Boolean\\" notion. He wants the reader to consider the proposition that there are \\"degrees of mind\\" rather than a discrete, discontinuous jump from not having a mind to having one. Mind can be implemented in machines he says, how much depends on several factors, with the most question to answer is how it can be done, not that it can be done.<br /> Readers who do not want to engage in philosophical speculation may be tempted to skip the reading of chapter 2, which discusses the \\"mind-body problem\\". However, there are many interesting discussions in this chapter, and in omitting its perusal such a reader would miss in particular the highly insightful overview of the ideas of Aaron Sloman on free will. Sloman has some interesting things to say about free will, and his ideas are pertinent in an engineering setting, as the reader will discover when reading the author's summarization. The notion of free will as a \\"Boolean\\" is dismissed by Sloman, and the author shows how Sloman's view of free will is directly applicable to the design of (intelligent) agents. The view of Sloman, who is a philosopher, is a good example of the trend of many philosophers to move into the field of artificial intelligence. There are many examples of this trend, and this century will no doubt see the rise of many more of what may be called \\"industrial philosophers.\\"<br /> One of the more refreshing ideas in the book is the author's view that human intelligence should not be viewed as the sole one in existence. Quoting the commandment from ethology that \\"thou shalt not anthropomorphize\\" in his discussion of \\"animal minds\\" the author then makes a good case for the existence of different types of intelligences. The most interesting consequence of his discussion is the difficulty of defining and measuring intelligence in any kind of organism, entity, or system. Before progress can be gauged in artificial intelligence, it is important that there be tools developed that measure the intelligence gains involved in this progress. So far, these tools have been conspicuously absent.<br /> It is clear that the author has a strong background in dynamical systems, since throughout the book one can see ideas from this field appear again and again. For example, in his discussion on `symbolic AI', the author defines a `production system' as a discrete dynamical system that consists of three components: a database, the set of production rules, and the control structure which directs the production rules. Dynamical systems also appear in the `connectionist' paradigm in AI and thus their use may bring together two proposals for machine intelligence that have traditionally been at conflict with each other.<br /> Along with what the author would call real examples of artificial minds, such as the SOAR project, he discusses other interesting proposals for their construction. One of these is the `pandemonium model of mind', which makes use of an `association engine' and `concept demons'. Such terminology may seem alien to the reader, but the author puts any objections as to its impracticality by pointing out the computational interpretation of this model and its actual implementation in Pascal code. Still another project for creating an artificial mind that he visits is the work of Jose Brustoloni on a formal theory of agents. The author describes his work as one of the first that attempts to give a classification of autonomous agents. Interestingly, Brustoloni believes that one type of agent, namely the problem-solving agent, should not be viewed as intelligent, due to its need for maintaining a world model and the subsequent issues of the frame problem and non-monotonic logics. Also interesting is Brustolini's views on a `hierarchy of behaviors', beginning with `instinctive behaviors', and ending with `theory making'. The author states that he knows of no artificial agent that has shown signs of theory making. As of the time of publication, this was an accurate statement, but since then the artificial intelligence community has seen the rise of intelligent machines that can engage in the construction of scientific theories. Based on inductive logic programming, these machines have indicated abilities that are competitive with human scientists.<br /> The author ends the book with optimistic notes of encouragement for the reader. Considering the content of the book and the developments that have taken place since its publication, there is every reason to be very optimistic about the continued development of artificial minds.e components: a database, the set of production rules, and the control structure which directs the production rules. Dynamical systems also appear in the `connectionist' paradigm in AI and thus their use may bring together two proposals for machine intelligence that have traditionally been at conflict with each other. <br /> Along with what the author would call real examples of artificial minds, such as the SOAR project, he discusses other interesting proposals for their construction. One of these is the `pandemonium model of mind', which makes use of an `association engine' and `concept demons'. Such terminology may seem alien to the reader, but the author puts any objections as to its impracticality by pointing out the computational interpretation of this model and its actual implementation in Pascal code. Still another project for creating an artificial mind that he visits is the work of Jose Brustoloni on a formal theory of agents. The author describes his work as one of the first that attempts to give a classification of autonomous agents. Interestingly, Brustoloni believes that one type of agent, namely the problem-solving agent, should not be viewed as intelligent, due to its need for maintaining a world model and the subsequent issues of the frame problem and non-monotonic logics. Also interesting is Brustolini's views on a `hierarchy of behaviors', beginning with `instinctive behaviors', and ending with `theory making'. The author states that he knows of no artificial agent that has shown signs of theory making. As of the time of publication, this was an accurate statement, but since then the artificial intelligence community has seen the rise of intelligent machines that can engage in the construction of scientific theories. Based on inductive logic programming, these machines have indicated abilities that are competitive with human scientists. <br /> The author ends the book with optimistic notes of encouragement for the reader. Considering the content of the book and the developments that have taken place since its publication, there is every reason to be very optimistic about the continued development of artificial minds.	2004-04-19
702070:US	50702879	R2454BK2M8YJ3B	0521775264	45807726	Machine Dreams: Economics Becomes a Cyborg Science	Books	3	2	23	N	Y	A weak case	Recognizing apprehension about current developments in technology and the \\"closed worlds\\" of the \\"brave new world of electronic surveillance and control centers\\", and the presence of anti-cheerleader/antagonists towards artificial intelligence and its supposed tendency to reduce the complexity of humanity to \\"a very small part\\", the author of this book attempts to step beyond this and give an historical overview of the influence of what might be called (and these are words of this reviewer), a \\"cyborg epistemology\\" in the field of economics. The evidence cited is on the whole anecdotal, and what results is a view of economics that could more properly be called \\"deterministic\\". If economics is to be labeled \\"cyborg science\\", then this labeling might have many different meanings depending on the attitudes and background of the reader. For this reviewer, the decision to read this book was based on the belief that it might shed some light on how intelligent machines are being used either to develop new economic theories or to understand the vast amounts of empirical economic data currently available.<br /> Luckily though the author does not intend to give the reader another neo-Luddite treatise on the perils of technology. He lets the reader know early on in the book that this is not his intent, in spite of the first few pages of the book, which might lead a reader to think otherwise. The author describes \\"cyborg science\\" as a description, taken by historians and sociologists of science, of the manner in which science has been transformed as an institution since World War II.  According to the author, this designation is due to Donna Haraway, a contemporary sociologist of science, and applied by many other researchers whom he lists. In order to be fair to the author's use of the term as delineated by these researchers, one would need to study their works. This reviewer has not read any of these, but concentrated instead on the arguments put forward by the author himself, independent of any prior analysis or works of others he depends on. And it is the opinion of this reviewer that although the author might have respected the goals and opinions of all of these researchers in their concept of \\"cyborg science\\", it does not conform to the concept of \\"cyborg\\" as viewed (in general) in artificial intelligence. The concept of cyborg as an \\"automaton\\" is one that the author had in mind, but thinking of machines as automatons takes place in only a few small circles in the field of artificial intelligence. Further, the \\"attack of the cyborgs\\", which labels one section of the book, is a theme of many Hollywood movies, but it is an exaggerated and even comical view of artificial intelligence, and does not deserve inclusion in any serious study of the history of the influence of artificial intelligence on economic theory.<br /> The author begins his \\"cyborg genealogy\\" with Charles Babbage and quickly moves on to von Neumann, Claude Shannon and Norbert Wiener, Alan Turing, the main instigators (consciously or not) to the \\"cyborg science\\" of post-war economics. Throughout the book one can see clearly how the field of operations research was influenced by these individuals, and how ideas from physics, in particular from thermodynamics and statistical physics, found their way into economics. Babbage is described as someone who saw no reason why the human mental faculties could not be \\"economized\\" with the assistance of machinery. His portent of the future is certainly remarkable, given the trend in the last decade of low-level machine intelligence replacing hundreds of tasks typically done by humans.  The \\"Second Industrial Revolution\\" spoken of by Norbert Wiener, and currently advertised with gusto by the new technophilic generation of inventor/visionary Ray Kurzweil, is fully in place, and shows every indication of having extreme social consequences.<br /> One must not however exaggerate the influence of well-known individuals in science and technology in bringing out true changes in society. The ideas of these individuals are widely quoted, but their efficacy is usually tested by many unknown individuals, whose sole interest is in the applicability and marketability of these ideas. The author spends too much time elaborating on the contributions of a small collection of people, ignoring those who were (causally) responsible for the rise of the information age and machine intelligence. In addition, the anecdotal comments attributed to Babbage, von Neumann, Shannon, Turing, and Weiner, that the author believes proves their view of economics as a \\"cyborg science\\" does not mean it has actually become one. The author does not propose any criteria, independent of these anecdotes, for establishing his case that post-war economic theory should be characterized as such. These criteria would have to involve the use of statistical sampling and tests, which is completely absent in this book. A much stronger, and more interesting case could be made if the author did not shy away from these techniques.<br /> So no, this book is not one of the reactionary anti-technology polemics that are beginning to proliferate the bookstores. But it is clear when reading the book that the author is expressing anxiety about the current state of technology and he makes a deliberate attempt in the last pages of the book to engage in philosophical value judgments. The \\"raw emotions\\" he says he felt in the development of his ideas compel him to make moral commentary on the state of economic theory. He does not see sinister plots behind military funding of economics, but he does hold the researchers obtaining this funding accountable for their results, and we should not believe them when they say they were working independently and without outside interference or pressure. The author though does show some traces of the post-hermeneutic criticism that has in large measure dominated the humanities. His worries of viewing markets as machines are in the opinion of this reviewer unjustified if one is to go solely by the content of the book.<br />The (thinking) machines of today are making markets, but not controlling them.logy in bringing out true changes in society. The ideas of these individuals are widely quoted, but their efficacy is usually tested by many unknown individuals, whose sole interest is in the applicability and marketability of these ideas. The author spends too much time elaborating on the contributions of a small collection of people, ignoring those who were (causally) responsible for the rise of the information age and machine intelligence. In addition, the anecdotal comments attributed to Babbage, von Neumann, Shannon, Turing, and Weiner, that the author believes proves their view of economics as a \\"cyborg science\\" does not mean it has actually become one. The author does not propose any criteria, independent of these anecdotes, for establishing his case that post-war economic theory should be characterized as such. These criteria would have to involve the use of statistical sampling and tests, which is completely absent in this book. A much stronger, and more interesting case could be made if the author did not shy away from these techniques. <BR> So no, this book is not one of the reactionary anti-technology polemics that are beginning to proliferate the bookstores. But it is clear when reading the book that the author is expressing anxiety about the current state of technology and he makes a deliberate attempt in the last pages of the book to engage in philosophical value judgments. The \\"raw emotions\\" he says he felt in the development of his ideas compel him to make moral commentary on the state of economic theory. He does not see sinister plots behind military funding of economics, but he does hold the researchers obtaining this funding accountable for their results, and we should not believe them when they say they were working independently and without outside interference or pressure. The author though does show some traces of the post-hermeneutic criticism that has in large measure dominated the humanities. His worries of viewing markets as machines arein the opinion of this reviewer unjustified if one is to go solely by the content of the book. <BR>The (thinking) machines of today are making markets, but not controlling them.	2004-04-18
711261:US	50702879	R7FGSWHC6Q3W8	1568812051	532416031	Machines Who Think: A Personal Inquiry into the History and Prospects of Artificial Intelligence	Books	4	13	16	N	Y	An insightful view of AI from an insider in the field.	The field of artificial intelligence, in terms of its research content, and the confidence it expresses in the results of this research, has executed a roller coaster ride in the last five decades. There have been many proposals, many leads not going anywhere, but just as many leads showing great promise but were abandoned. The reasons why they were abandoned are unclear, but many researchers in artificial intelligence have let them themselves be persuaded that their results do not reflect real intelligence. This has thwarted the development of many promising areas in artificial intelligence, which could have been highly developed by now.<br />The author, in this new edition of her book, has given the reader her opinions of the status of artificial intelligence in the twenty-five years after the first edition of the book. Her assessment of the last twenty-five years is in general optimistic, but her review concentrates mostly on research in the academic setting. There have also been dramatic advances in artificial intelligence in the commercial sector in the last twenty-five years, but many of these are difficult to document, since issues of propriety arise in the business environment. The many applications that are used by business and industry are practical proof of the rise of machine intelligence in the last twenty-five years, and many of these make use of the academic developments that the author discusses in this book.<br />The self-doubts and concentrated attention expressed by various researchers are well documented by the author, and some interesting historical anecdotes are included. The author describes the \\"odd paradox\\" in artificial intelligence as one where the its practical successes are absorbed into the domains in which they found application. Once assimilated, they become \\"silent partners\\" alongside other (non-intelligent) approaches. This reinforces the belief that the intelligent applications were not intelligent in the first place, and are then viewed merely as \\"valuable automatic helpers\\". This scenario has been played out many times in the history of artificial intelligence, and, even worse, the fact that the workings of these applications were understood made many assert that this was proof of their non-intelligence. If a process or algorithm is understood, it cannot be intelligent. This bias, the author correctly observes, continues to this day. Regardless of these beliefs or prejudices, the fact remains though that many of today's computers and machines are packed full of intelligence, albeit in different levels, and these levels will dramatically increase in the next twenty-five years.<br />Researchers in artificial intelligence have been accused of exaggerating the status of machine intelligence, and similar to the same exaggerations that occur in other fields, which arise many times from pressures to obtain funding, these accusations do have some truth to them. But the author points out a case where the funding was cancelled due to the project not being \\"extravagant enough.\\" This is an interesting historical fact, and one that illustrates the large swings in confidence that have plagued AI research from the beginning.<br />The strong emphasis on emulating human intelligence has been dampened in recent years, with researchers realizing, refreshingly, that human intelligence is not the only kind in nature. It is in retrospect quite surprising that silicon-based machines were thought to be able to mimic the processes and powers of biological systems. The author quotes one researcher as saying that \\"Silicon intelligence would surely be different from human intelligence\\". This is indeed correct, and one can expect many different types of intelligence to reside in future machines, each of these types emphasizing particular tasks, but being general enough to think in many domains. Maybe a better word for describing the field would be to call it `Alien Intelligence', so as to emphasize the (non-human) idiosyncrasies of these different intelligences.<br />With very exceptions, the philosophical community has been against the possibility of artificial intelligence. This continues to this day, and the author discusses some of the philosophical tirades leveled against artificial intelligence since the first edition of the book. Researchers in AI have taken the time (unfortunately) to answer some of these criticisms, but there is also a trend, which hopefully will continue, to ignore them and instead spend time on what is important, namely the design and construction of intelligent machines. There is no penalty in ignoring philosophical criticism; it lends no constructive insight into artificial intelligence. However there is a great penalty taken in the form of wasted hours in attempting to answer the vague and impractical claims of philosophers. Ironically, there have been a few renowned philosophers that have left the practice of philosophy and have entered into research into artificial intelligence (and have done a fine job in this regard).<br />The author also shares with the reader her personal insights into artificial intelligence, and these are interesting considering her involvement with some of the major academic experts in AI. She describes her bias in thinking of (mobile) robots as the sole representative of artificial intelligence. This bias has been alleviated to a large degree in the last decade, but many still equate artificial intelligence to the presence of bipedal robots wandering around performing useful tasks or possibly acting as adversaries to human beings. The latter view of course is very popular in Hollywood interpretations of artificial intelligence. The real truth though is that (immobile) machines, be they servers in networks, laptop computers, or other types of machines, can exhibit high levels of intelligence, depending on what kind of \\"software\\" or \\"mind\\" is overlaid on them.<br />The most important thing to be settled for the field of artificial intelligence, and this is brought out also in many of the author's remarks, is a general methodology for gauging machine intelligence. The Turing test is too subjective and tied too much to measures of human intelligence. The AI community definitely needs to arrive at quantitative measures of machine intelligence in order to assess progress and allow the business community to judge more accurately whether a certain level of machine intelligence is needed for their organizations.idiosyncrasies of these different intelligences. <br />With very exceptions, the philosophical community has been against the possibility of artificial intelligence. This continues to this day, and the author discusses some of the philosophical tirades leveled against artificial intelligence since the first edition of the book. Researchers in AI have taken the time (unfortunately) to answer some of these criticisms, but there is also a trend, which hopefully will continue, to ignore them and instead spend time on what is important, namely the design and construction of intelligent machines. There is no penalty in ignoring philosophical criticism; it lends no constructive insight into artificial intelligence. However there is a great penalty taken in the form of wasted hours in attempting to answer the vague and impractical claims of philosophers. Ironically, there have been a few renowned philosophers that have left the practice of philosophy and have entered into research into artificial intelligence (and have done a fine job in this regard). <br />The author also shares with the reader her personal insights into artificial intelligence, and these are interesting considering her involvement with some of the major academic experts in AI. She describes her bias in thinking of (mobile) robots as the sole representative of artificial intelligence. This bias has been alleviated to a large degree in the last decade, but many still equate artificial intelligence to the presence of bipedal robots wandering around performing useful tasks or possibly acting as adversaries to human beings. The latter view of course is very popular in Hollywood interpretations of artificial intelligence. The real truth though is that (immobile) machines, be they servers in networks, laptop computers, or other types of machines, can exhibit high levels of intelligence, depending on what kind of \\"software\\" or \\"mind\\" is overlaid on them. <br />The most important thing to be settled for the fieldof artificial intelligence, and this is brought out also in many of the author's remarks, is a general methodology for gauging machine intelligence. The Turing test is too subjective and tied too much to measures of human intelligence. The AI community definitely needs to arrive at quantitative measures of machine intelligence in order to assess progress and allow the business community to judge more accurately whether a certain level of machine intelligence is needed for their organizations.	2004-04-11
716655:US	50702879	R1Y93BJBVJ9C6P	0201440997	639714535	Computer Security: Art and Science	Books	5	11	12	N	N	Superb	This book gives an excellent introduction to the subject of computer security, both from a practical and theoretical point of view. Computer scientists and not security professionals will probably gain the most from the reading of the book, but there is enough practical discussion to allow the latter to gain more insight into various aspects of computer security, particularly in the mathematics of encryption. The book is designed for use in academic classroom settings, and the author gives two different outlines for use in both undergraduate and graduate level courses. The book is divided up into 9 parts, only parts 2 and 3 of which I read in any detail, with the rest only briefly perused. For this reason only these two parts will be reviewed here.<br /> Part 2 of the book is a view of security from the standpoint of theoretical computer science. The author discusses models for the decidability of security systems, i.e. is there a generic algorithm that will determine whether a computer system is secure? As expected, this question is addressed in the context of Turing machines, and the author shows that it is undecidable whether a given state of a given protection system is safe for a given generic right. However the proof proceeds by contradiction, and those of us who insist on constructive proofs in all of mathematics will not accept this one. It would be interesting to find a constructive proof of this result.<br /> If the protection system is restricted in some way then they safety question is decidable. The author discusses such a system, the &quot;Take-Grant Protection Model&quot; in terms of directed graphs, and he shows that this model is decidable in linear time with respect to the size of the graph. He then explains the reasons why a safety model can be decidable versus one that cannot be, via a highly technical discussion of the &quot;Schematic Protection Model&quot; (SPM). This section is very interesting due to the nature of the mathematical constructions that are used. These constructions make it readily apparent why the (undecidable) Harrison-Ruzzo-Ullman (HRU) model is more expressive than the SPM. The expressive power of the different models derives from the notion of a `type', and this motivates the author to consider the `typed access matrix model' and its utility in detailing a system's safety properties.<br /> In Part 3, the author gets down to more practical matters, and discusses the implementation of security policies. Taking a computer system to be a finite-state automaton with transition functions that change state, a security policy is defined as a statement that partitions these states into `secure' and `nonsecure' states. Secure systems are defined as those that cannot enter a nonsecure state if they are in a secure state. All throughout this part the author emphasizes that fact that all security policies are based on assumptions that would lead to the destruction of these policies if they are false. The author discusses a practical example of a security policy in this part. Also discussed is the relation between security and precision, with the idea of a covert channel arising in this context. The author proves that there is no general procedure for constructing a system that conforms exactly to a specific security policy but that allows all actions that the policy allows.<br /> The Bell-LaPadula confidentiality model, which has its origins in military applications, is also discussed in Part 3. The author explains a confidentiality policy as being a `information flow policy', which prevents the unauthorized disclosure of information, with unauthorized alteration of information being secondary. An explicit example of this security involving a UNIX operating system is discussed. A formal model is then proposed, and the author then uses the accompanying formalism to prove the `basic security theorem'. The formal model constructed by the author is interesting in that it can be viewed as a (discrete) dynamical system, with transitions governed by decisions that are responding to requests for access. A system is called secure if it satisfies three conditions, namely the `simple security condition', the `*-property', and the `discretionary security property'. The first condition states that a subject that can read or write to an object must dominate it. The *-property states that if a subject can write to an object, the classification of the object must dominate the subject's clearance; if the subject can also read the object, the subject's clearance must be the same as the object's classification. The discretionary security property relates the authority of the access control matrix to allow the controller of an object to condition access based on identity. The author also discusses in detail the objections to the Bell-LaPadula model of computer security.<br /> The author then directs his attention to integrity policies, wherein the emphasis is on ensuring data integrity, and he discusses various integrity security policies in this regard. One of these is the Biba integrity model, which as it turns out is the mathematical dual of the Bell-Lapadula model, wherein a system is now composed of a set of subjects, objects, and integrity levels. The higher the \\"integrity level\\", the more confidence there is that a program will execute correctly. This model is then generalized to the Lipner integrity matrix model, which is a hybrid of Biba and Bell-Lapadula, this being done to obtain a model more suitable for commercial needs. The author then considers the Clark-Wilson integrity model, which uses transactions as the basic operation, and wherein data subjected to integrity controls becomes `constrained data items.' Various certification and enforcement rules are imposed that give this model more commercial applicability than the others, even though the certification process can be very complex and the prone to error. The author compares the Clark-Wilson model with the Biba model and is clearly on the side of the former in terms of practicality, although in the exercises he asks the reader to construct an emulation of the Biba model using Clark-Wilson.e) dynamical system, with transitions governed by decisions that are responding to requests for access. A system is called secure if it satisfies three conditions, namely the `simple security condition', the `*-property', and the `discretionary security property'. The first condition states that a subject that can read or write to an object must dominate it. The *-property states that if a subject can write to an object, the classification of the object must dominate the subject's clearance; if the subject can also read the object, the subject's clearance must be the same as the object's classification. The discretionary security property relates the authority of the access control matrix to allow the controller of an object to condition access based on identity. The author also discusses in detail the objections to the Bell-LaPadula model of computer security. <br /> The author then directs his attention to integrity policies, wherein the emphasis is on ensuring data integrity, and he discusses various integrity security policies in this regard. One of these is the Biba integrity model, which as it turns out is the mathematical dual of the Bell-Lapadula model, wherein a system is now composed of a set of subjects, objects, and integrity levels. The higher the \\"integrity level\\", the more confidence there is that a program will execute correctly. This model is then generalized to the Lipner integrity matrix model, which is a hybrid of Biba and Bell-Lapadula, this being done to obtain a model more suitable for commercial needs. The author then considers the Clark-Wilson integrity model, which uses transactions as the basic operation, and wherein data subjected to integrity controls becomes `constrained data items.' Various certification and enforcement rules are imposed that give this model more commercial applicability than the others, even though the certification process can be very complex and the prone to error. The author compares the Clark-Wilson model with theBiba model and is clearly on the side of the former in terms of practicality, although in the exercises he asks the reader to construct an emulation of the Biba model using Clark-Wilson.	2004-04-07
718958:US	50702879	RZ2SRN9I2IB3N	1560255560	282559023	Secrets and Lies: Operation Iraqi Freedom and After: A Prelude to the Fall of U.S. Power in the Middle East?	Books	3	8	16	N	Y	So who has the real facts?	Events of course can be observed and documented, but the inner moods and intentions of humans cannot. This fact is forgotten by historians, political commentators, journalists, pundits, writers, and government officials unfortunately. Instead of documenting the events as they occur, and as can be perceived by everyone, the main goal instead is to impute certain frames of mind in the individuals who are involved in these events. The author of this book is no exception to this trend, and the title of the book is a dead giveaway to this fact. It may be true that George Bush knew that the reasons he spoke of for invading Iraq were false; it is just as plausible to believe that he really believed in the reasons he gave. No matter how \\"reasonable\\" it seems to believe that Bush was lying, the fact remains that one cannot look inside his mind to determine if he really was. There is a large uncertainty involved in any conclusion reached regarding the intents and motivations of human beings. Science is just not sophisticated enough to judge by external behavior whether a person is lying, and until it is it must remain an open question as to whether that person is or not.<br /> The author does document the pain and horror felt by the citizens of Iraq when exposed to the horrific act of terror brought onto them by U.S. and coalition forces. He does this by interjecting certain journal entries kept by a few Iraqis during the illegal and immoral invasion of their country. One can only hope in their authenticity, and such skepticism or doubt regarding their authenticity raises other issues involving the claims of certain individuals to have access to information that others do not. In this regard, is the author of this book privy to information that the rest of us do not have? And if the president can engage in such blatant twisting of the facts, why should the reader not believe that the author has also done the same?<br /> A closely related issue is one that also plagues modern journalism and political commentary, namely that the intent of a writer or government official often gets confused with the truth of their claims. It does not matter if the author of this book wrote the book with the intent of financial gain. All that matters is whether the content of the book is true. Many commentators constantly commit this error: the intent of the person for producing a given work is thought to negate the conclusions of the work. The author may have an axe to grind against the current administration, or he may be trying to propagate certain political beliefs or doctrines, or he may be interested in filling his bank account. None of this is relevant regarding the truth of what appears in his book.<br /> But then, how would one verify that what the author is claiming as historical fact is really the way it happened? Should we trust him in this regard? No, we shouldn't. What we should do is engage in the research ourselves in an attempt to verify his assertions. This will be difficult and time-consuming, but such is the nature of seeking the truth. It is easy to form opinions. It is quite another matter to find and verify genuine knowledge.<br /> The book opens with a statement by Bush that he supposedly spoke to (the now former) Palestinian Prime Minister Mahmoud Abbas: \\"God told me to strike at Al Qaida and I struck them, and then He instructed me to strike at Saddam, which I did.\\" I did not hear this statement directly from Bush on television or radio. Did Bush say it? Maybe. Does he believe it? If he does, then Bush is a very disturbed individual. Is it relevant to the author's case in the book, to the historical facts which he takes aim to delineate? No, it is not. It could be omitted without affecting the author's case. It serves no scholarly purpose at all.rn journalism and political commentary, namely that the intent of a writer or government official often gets confused with the truth of their claims. It does not matter if the author of this book wrote the book with the intent of financial gain. All that matters is whether the content of the book is true. Many commentators constantly commit this error: the intent of the person for producing a given work is thought to negate the conclusions of the work. The author may have an axe to grind against the current administration, or he may be trying to propagate certain political beliefs or doctrines, or he may be interested in filling his bank account. None of this is relevant regarding the truth of what appears in his book. <br /> But then, how would one verify that what the author is claiming as historical fact is really the way it happened? Should we trust him in this regard? No, we shouldn't. What we should do is engage in the research ourselves in an attempt to verify his assertions. This will be difficult and time-consuming, but such is the nature of seeking the truth. It is easy to form opinions. It is quite another matter to find and verify genuine knowledge. <br /> The book opens with a statement by Bush that he supposedly spoke to (the now former) Palestinian Prime Minister Mahmoud Abbas: \\"God told me to strike at Al Qaida and I struck them, and then He instructed me to strike at Saddam, which I did.\\" I did not hear this statement directly from Bush on television or radio. Did Bush say it? Maybe. Does he believe it? If he does, then Bush is a very disturbed individual. Is it relevant to the author's case in the book, to the historical facts which he takes aim to delineate? No, it is not. It could be omitted without affecting the author's case. It serves no scholarly purpose at all.	2004-04-05
719547:US	50702879	RV0Q71CILLM8U	0387954902	461929969	Elliptic Curves (Graduate Texts in Mathematics)	Books	5	14	16	N	Y	An excellent update to the first edition.	Anyone who has studied elliptic curves appreciates their beauty and the richness of the mathematics that arises from such a study. This book, first published in 1987, has three additional chapters that reflect some major applications of elliptic curves since then. Indeed, the resolution of Fermat's Last Theorem due to Andrew Wiles and the use of a generalization of elliptic curves, called Calabi-Yau manifolds, in string theory have all taken place since the time of publication. The review here will be confined to these chapters.<br /> Chapter 18 is a brief summary of the modular elliptic curves conjecture and Fermat's Last Theorem from mostly an historical perspective. The author reviews the material from prior chapters that relate to the modular curve conjecture. The Tate module of an elliptic curve plays a central role, with its structure as an l-adic Galois module allowing the author to formulate an alternative version of the modular curve conjecture. The author shows that the modular elliptic curve conjecture is equivalent to the assertion that every l-adic representation arising from a Tate module of an elliptic curve over the rational numbers Q comes from a modular form of weight 2, which is a Hecke eigenfunction.<br /> It is fascinating that the connection between elliptic curves and Fermat's Last Theorem was only pointed out as late as 1986 by the mathematician Gerhard Frey. The relation of the `Frey curve', as it is now called, to Fermat's Last Theorem is discussed by the author, and he shows how it is reduced to the modular elliptic curve conjecture for semistable curves.<br /> In chapter 19, the author introduces the reader to Calabi-Yau varieties, which are higher dimensional analogs of elliptic curves, and which have become very important in high-energy physics. The reader will have to have some background in the theory of complex manifolds to appreciate this chapter, but the author does a quick survey of the relevant topics. Of particular importance in this discussion are the Kahler manifolds, which can be thought of as complex manifolds with a metric that is an analog of the Euclidean metric in the real case, i.e. the metric is Hermitian and is closed.<br /> After a further review of characteristic classes the author gives several equivalent definitions of Calabi-Yau manifolds, and several examples in (complex) dimension one, two, and three. He also gives examples of Calabi-Yau manifolds that arise from projective and weighted projective spaces, and their generalizations, the toric varieties. A brief remark is made concerning the existence of `mirror' Calabi-Yau manifolds, these latter objects currently the subject of intense research. Just as in the case of real manifolds, it is of interest to find invariants for Calabi-Yau manifolds that will assist in their classification. The author does this for the case of surfaces that are Calabi-Yau, and this naturally leads to the analog of the Euler characteristic in the guise of the famous Riemann-Roch theorem. The Riemann-Roch theorem though is not proven, but the author does show explicitly how to obtain the formula for the genus for the structure sheaf on the scheme defined by the ideal sheaf. A brief introduction to K3 surfaces is given. These surfaces are very important in physical applications and in four-dimensional topology.<br /> Finally, in the last chapter of the book, the author studies families of elliptic curves. This is done in the context of the theory of schemes, and the author makes some connections with physics. The author gives a very brief review of scheme theory, starting with the notion of a `local ringed space', which is a topological space with a sheaf of rings defined on it such that the stalks are local rings for every point in the space. Local ringed spaces include smooth and complex analytic manifolds as special cases, and codify both the algebraic and analytic properties of the objects studied. An affine scheme is then defined as a locally ringed space isomorphic to the spectrum of a ring. A scheme is a locally ringed space locally isomorphic at each point to an affine scheme. The isomorphism classes of elliptic curves have the structure of a scheme.<br /> Elliptic fibrations of surfaces over curves are studied in terms of their effective divisors, which are analogs of the canonical divisors used in the Enriques classification of surfaces. The Euler characteristic is then computed in terms of the effective divisor. The author then shows that a K3 surface with a Picard number at least 5 has an elliptic fibration. This is generalized to the case of Calabi-Yau varieties using the concept of a `numerically effective' divisor. Some explicit examples of Calabi-Yau hypersurfaces in four-dimensional weighted projective are then given. These examples were found by string theorists, and the author therefore devotes an appendix that describes how Calabi-Yau manifolds are used in high energy physics. The appendix is very short, and a perusal of the literature of string theory will reveal the overwhelming importance of Calabi-Yau manifolds. String theory has evolved into M-theories and membrane theories, but both of these involve heavy use of algebraic geometry, and many of the constructions are generalizations of what is known for the case of elliptic curves.ocally ringed space isomorphic to the spectrum of a ring. A scheme is a locally ringed space locally isomorphic at each point to an affine scheme. The isomorphism classes of elliptic curves have the structure of a scheme. <br /> Elliptic fibrations of surfaces over curves are studied in terms of their effective divisors, which are analogs of the canonical divisors used in the Enriques classification of surfaces. The Euler characteristic is then computed in terms of the effective divisor. The author then shows that a K3 surface with a Picard number at least 5 has an elliptic fibration. This is generalized to the case of Calabi-Yau varieties using the concept of a `numerically effective' divisor. Some explicit examples of Calabi-Yau hypersurfaces in four-dimensional weighted projective are then given. These examples were found by string theorists, and the author therefore devotes an appendix that describes how Calabi-Yau manifolds are used in high energy physics. The appendix is very short, and a perusal of the literature of string theory will reveal the overwhelming importance of Calabi-Yau manifolds. String theory has evolved into M-theories and membrane theories, but both of these involve heavy use of algebraic geometry, and many of the constructions are generalizations of what is known for the case of elliptic curves.	2004-04-04
720407:US	50702879	R2K6NCJ7DK264G	0765301113	67693328	Slatewiper	Books	3	5	9	N	Y	Some interesting points made....some unjustified worry too.	Genetic engineering has served as a source of many storyline plots in the last twenty-five years. Many of these stories want to play on the fears of those who feel anxiety by the current technologies in this field. It is difficult to say whether they succeed in their goals, but it is fair to say though that genetic engineering is getting some bad press, in spite of its tremendous potential in medicine and agriculture.<br />Slatewiper can be classified as one of these books, but it also qualifies as a fairly good action story. It is fast moving, with few resting places, and it keeps the reader on edge. One does not have time to collect one's thoughts while reading it. This was no doubt the purpose of the author, as careful consideration of the real issues in genetic engineering and its future possibilities might nullify the message of fear that proliferates through its pages. From a scientific viewpoint it is weak, but this is not a detriment to the book since it is fiction, and any scientific misrepresentations or inaccuracies can thus be forgiven. If the book does in fact cause myriads of readers to have distorted views on genetic engineering, it is up to the scientific community to counter these views.<br />The characters in the story are well defined as is to be expected in a story of this kind. The intent of the story is to instill particular attitudes and anxieties about genetic engineering, and so taking the time to develop the characters would detract from this purpose.  The main character and heroine Lara Blackwood, the founder and GEO of a biotechnology firm called GenIntron, with her dual athletic and intellectual capabilities, and her steadfast integrity, stands well above the others in the book. Totally self-reliant, and with personal achievement her only source of self-esteem, Lara represents the best (and very common) qualities in human beings. Her antagonists in the story consider these qualities as weakness however, and misjudge her ability to fight back when she is removed as CEO from her company and her research corrupted to make `Slatewiper', a kind of `genome bomb' that has the ability to wipe out certain groups of people with particular types of genes. In the story these are the Korean people.<br />There are some familiar (and somewhat comical) personalities expressed by some other characters in the story, one of these being Jason Woodruff, banker and board member of GenIntron. Woodruff is described as someone who found Lara's \\"ambiguity subversive and spontaneity unsettling\\". Lara made him feel uncomfortable since \\"women shouldn't be like that.\\" Woodruff is a good representative of the conservative businessman, who has an anathema to change and whose neuronal processes are overtrained. Woodruff has found conceptual equilibrium and is resistant to any external perturbations, such as the dialog of the free-thinking, highly creative Lara Blackwood. Another character that briefly appeared is the parasitic Elliot Sporkin, who organizes an anti-biotech rally against GenIntron, and is described in the book as someone who has made a \\"profitable career off the fears of a scientifically illiterate populace.\\" There are many who follow Sporkin today unfortunately. Some of them populate the highest levels of government, but luckily for every Sporkin there is one highly competent individual who counters his shallow and unsubstantiated opinions.<br />In her morally justified war against the vile Edward Rycroft, the new heads of GenIntron, and Rycroft's partner in crime Tokutaro Kurata, head of the Daiwa Ichiban Corporation, Lara fortunately has the help of Akira Sugawara, nephew of Kurata, and one whose self-esteem was not dependent on the actions of his ancestors. Ismail Brahimi, Lara's cofounder of GenIntron, was not up to the task, for he believed it was the \\"will of God\\" for Rycroft to be head of the company. Beliefs in determinism always dissuade appropriate moral action. Sugawara was a most effective ally, for hismannerisms and respect for Japanese culture did not negate his belief that it was the path of one's own life that determined self-worth. The present needed fixing, and Sugawara acted with resolve, ignoring the natural feelings of guilt that accompany a conscious rift from the culture one is embedded in.<br />Along with the chain-smoking, narcissistic hit-woman Sheila Gaillard, Kurata is a caricature of evil in the book. Believing in the superiority of the Japanese, in both culture and genes, and xenophobic to the core, he felt the need to counter the \\"cultural erosion\\" coming from the outside. The genetic purity of the true Japanese, along with the \\"code of Nihonjinron\\" is to be preserved. The Slatewiper was to be the ultimate ethic cleanser. Since Sugawara was educated in the West, Kurata distrusted him intensely. But Sugawara was not to fall to the perverted thinking of Kurata, who admonished him for not being true to \\"racial purity\\". In the best line of the book, Sugawara countered by saying `I am not a machine rented by my genes; I am not a passive urn made to carry the ashes of the past into the future. I control my destiny; I refuse to have my life dictated by dead men.'<br />In an afterward to the book, the author makes supplication to God that the book is not prophetic. But prayer will not suffice to nullify any threat from bioterrorism. To make sure weapons such as Slatewiper are inert, we need to build the BSL 4 labs of the book. We need to find out what is possible with genetic engineering, what can help us and what can hurt us. We need to find out what is effective and what is not. We must understand how to engineer dangerous organisms so they can be countered. We need to find out how genetic engineering can optimize our health and comfort. This research must be done, and this does not mean years down the road. It must be done right now. Today.for his mannerisms and respect for Japanese culture did not negate his belief that it was the path of one's own life that determined self-worth. The present needed fixing, and Sugawara acted with resolve, ignoring the natural feelings of guilt that accompany a conscious rift from the culture one is embedded in.  <br />Along with the chain-smoking, narcissistic hit-woman Sheila Gaillard, Kurata is a caricature of evil in the book. Believing in the superiority of the Japanese, in both culture and genes, and xenophobic to the core, he felt the need to counter the \\"cultural erosion\\" coming from the outside. The genetic purity of the true Japanese, along with the \\"code of Nihonjinron\\" is to be preserved. The Slatewiper was to be the ultimate ethic cleanser. Since Sugawara was educated in the West, Kurata distrusted him intensely. But Sugawara was not to fall to the perverted thinking of Kurata, who admonished him for not being true to \\"racial purity\\". In the best line of the book, Sugawara countered by saying `I am not a machine rented by my genes; I am not a passive urn made to carry the ashes of the past into the future. I control my destiny; I refuse to have my life dictated by dead men.'<br />In an afterward to the book, the author makes supplication to God that the book is not prophetic. But prayer will not suffice to nullify any threat from bioterrorism. To make sure weapons such as Slatewiper are inert, we need to build the BSL 4 labs of the book. We need to find out what is possible with genetic engineering, what can help us and what can hurt us. We need to find out what is effective and what is not. We must understand how to engineer dangerous organisms so they can be countered. We need to find out how genetic engineering can optimize our health and comfort. This research must be done, and this does not mean years down the road. It must be done right now. Today.	2004-04-03
722817:US	50702879	R4397M8WNX7FB	0387953698	960392031	Computational Cell Biology (Interdisciplinary Applied Mathematics) (v. 20)	Books	5	25	25	N	N	An excellent overview	As a field of applied mathematics, computational biology has exploded in the last decade, and shows every sign of increasing in the next. This book overviews a few of the topics in the computational modeling of cells. I only read chapters 12 and 13 on molecular motors, and so my review will be confined to these.<br /> Nanotechnology could be described as an up-and-coming field, but in the natural world one can find examples of this technology that surpass greatly what has been accomplished by human engineers. The authors begin their articles with a few examples of natural molecular machines, including the \\"rotary motors\\" DNA helicase and bacteriophage, and the \\"linear motor\\" kinesin, the latter they refer to as a \\"walking enzyme\\". Important in the modeling of all these is the theory of stochastic processes in the guise of Brownian motion, which the authors hold is the key to understanding the mechanics of proteins. In chapter 12 they give a detailed overview of the mathematical modeling of protein dynamics, followed in chapter 13 by an illustration of the mathematical formalism in the bacterial flagellar motor, a polymerization ratchet, and a motor governing ATP synthase.<br /> To the authors a molecular motor is an entity that converts chemical energy into mechanical force. The production of mechanical force though may involve intermediate steps of energy transduction, all these involving the release of free energy during binding events. But due to their size, molecular motors are subjected to thermal fluctuations, and thus to model their motion accurately requires the theory of stochastic processes. Thus the authors begin a study of stochastic processes, restricting their attention to ones that satisfy the Markov property. Starting with a discrete model of protein motion as a simple random walk, the authors show that the variance of the motion grows linearly with time, which is a sign of diffusive motion. The partial differential equation satisfied by the probability distribution function, in the continuous limit where the space and time scales are large enough, is left to the reader to derive as an exercise.<br /> The authors then consider polymer growth as another example of a stochastic process, a kind of hybrid one in that it involves both discrete and continuous random variables, the position of the polymer being continuous, while the number of monomers in the polymer is discrete. The authors derive an ordinary differential equation for the probability of there being exactly n polymers at a particular time. From this they show how to obtain sample paths for polymer growth and give a brief discussion on the statistics of polymer growth.<br /> Attention is then turned to the modeling of molecular motions, with the first example being the Brownian motion of proteins in aqueous solutions. The (stochastic) Langevin equation is given for the motion of the protein, both with and without an external force acting on the protein. To find a numerical solution of this equation is straightforward, as the authors show. But they caution however that simulation of this solution on a computer is liable to introduce spurious results, and so they derive the Smoluchowski model, a somewhat different way of looking at random motion via the evolution of ensembles of paths. In this formulation the Brownian force is replaced by a diffusion term, and the external force is modeled by a drift term.<br /> The authors then consider the modeling of chemical reactions, which supply the energy to the molecular motors. Because of the time scales involved in these reactions, a correct treatment of them would involve quantum mechanics, but the authors use the Smoluchowski model. The simple reaction model they consider involves a positive ion binding to negatively charged amino acid, and using as reaction coordinate the distance between the ion and the amino acid, study the free energy change as a function of the reaction coordinate.<br /> The numerical simulation of the protein motion is then considered in much greater detail, using an algorithm that preserves detailed balance. This involves converting the problem to a Markov chain and a consideration of the boundary conditions, which the authors do for the case of periodic, reflecting, and absorbing. Euler's method is used to solve the resulting equations for the Markov chain, and after dealing with issues of stability and accuracy, the Crank-Nicolson method is used. The last few sections of the chapter are devoted to the physics of these solutions and the authors give some intuitive feel for the entropic factors and energy balance on a protein motor.<br /> In the last chapter of the book, the considerations in chapter 12 are applied to concrete molecular motors. The first one examined is a model for switching in a bacterial flagellar motor, which involves the protein CheY as a signaling pathway. The binding of CheY to the motor is modeled as a two-state process, with the binding site being either empty or occupied. The resulting set of coupled differential equations for the probabilities is solved for when the concentration of CheY is constant. An expression for the change in free energy is obtained, and the authors give a discussion of the physics in the light of what was done in the last chapter. The switching rate is computed, along with the mean first passage time.<br /> Some other examples of molecular motors are also discussed, including the flashing racket, the polymerization ratchet, and a simplified model of the ion-driven F0 motor of ATP synthase. This latter motor is fascinating, since it describes the electrochemical energy involved in mitochondria for the production of ATP. The authors do a nice job of showing how the techniques of chapter 12 are used to solve this model, and also give an analytical solution for a certain limiting case.cal simulation of the protein motion is then considered in much greater detail, using an algorithm that preserves detailed balance. This involves converting the problem to a Markov chain and a consideration of the boundary conditions, which the authors do for the case of periodic, reflecting, and absorbing. Euler's method is used to solve the resulting equations for the Markov chain, and after dealing with issues of stability and accuracy, the Crank-Nicolson method is used. The last few sections of the chapter are devoted to the physics of these solutions and the authors give some intuitive feel for the entropic factors and energy balance on a protein motor. <br /> In the last chapter of the book, the considerations in chapter 12 are applied to concrete molecular motors. The first one examined is a model for switching in a bacterial flagellar motor, which involves the protein CheY as a signaling pathway. The binding of CheY to the motor is modeled as a two-state process, with the binding site being either empty or occupied. The resulting set of coupled differential equations for the probabilities is solved for when the concentration of CheY is constant. An expression for the change in free energy is obtained, and the authors give a discussion of the physics in the light of what was done in the last chapter. The switching rate is computed, along with the mean first passage time. <br /> Some other examples of molecular motors are also discussed, including the flashing racket, the polymerization ratchet, and a simplified model of the ion-driven F0 motor of ATP synthase. This latter motor is fascinating, since it describes the electrochemical energy involved in mitochondria for the production of ATP. The authors do a nice job of showing how the techniques of chapter 12 are used to solve this model, and also give an analytical solution for a certain limiting case.	2004-04-01
726721:US	50702879	R1VRCMV4UXKR59	0387550070	421515296	Higher Algebraic K-Theory: An Overview (Lecture Notes in Mathematics)	Books	4	3	3	N	Y	A quick overview of a highly developed branch of mathematics	Algebraic K-theory may be viewed loosely as a theory of large matrices and how to define invariants for them. In ordinary linear algebra, the trace and determinant are elementary examples of these invariants and are straightforward to calculate. And in that same context, if one has M equations in N unknowns over some field K, then the solutions of this system of equations form a vector space S over K. If R is the subspace spanned by column vectors of length M, then Dim S + Dim R = N. As H. Gillet explains in one of the articles in the book, this result can be cast into the language of short exact sequences, and attempts to generalize this for the case when K is a ring is one of the tasks of algebraic K-theory. In this connection algebraic K-theory is useful in the following way: If K is either the integers or a finite field over an indeterminate, then for a polynomial ring A with D -1 variables over K, the group GL(n, A) is finitely generated when N is greater than equal to D + 2. This is an example where things look more stable when the dimension is high, a theme that occurs over and over again in K-theory. Indeed, when A is a finitely generated commutative regular ring, the question as to whether GL(n, A) is finitely generated for all sufficiently large n is equivalent to the question as to whether the K-group K1(A) is finitely generated.<br /> This book goes considerably further then these relatively elementary considerations, in that it treats the higher K-groups and the connection with topological K-theory. Readers will need an extensive background in algebra and topology to appreciate the constructions in this book, which are mostly formal and thus there is the canonical inverse relationship between rigor and understanding. There are many places in the book though where readers can gain useful insights into a mature and highly developed branch of mathematics.<br /> As was hinted above, for a ring R, K0 gives a measure of the failure of finitely generated projective R-modules from having a dimension theory like that of vector spaces.  The first algebraic K-group K1 of a ring R is the quotient group of the infinite general linear group GL(R) modulo the infinite elementary group E(R) (the infinite elementary group comes from considering those matrices which differ from the identity only by an off diagonal element). Whitehead's Lemma shows that E(R) is a normal subgroup of GL(R). One can show that K1 of the integers is just {-1, 1}, and, for more general commutative rings R, that the determinant on GL(R) to the units R* of R induces a universal homomorphism and K1(R) is equal to these units. Thus the determinant gives in this case a universal invariant as was noted above. The second algebraic K-group of a ring R is then defined by generalizing the elementary group to the `Steinberg group' and then taking limits. There is an epimorphism from the Steinberg group to the elementary group and after passing to the infinite limit, the kernel of this epimorphism is defined as the second algebraic K-group of the ring R. K2(R) measures to what extent the Steinberg relations do not define the relations for the elementary group. One can show that K2 of the integers Z is Z/2, and that K2 of the direct product of two rings is the direct sum of their K2 groups.<br /> Topological K-theory, also discussed in detail throughout the book, has its origins in the theory of vector bundles. Two vector bundles are called `stably-equivalent' if they are isomorphic after taking their direct sum with trivial bundles. Stable equivalence forms an equivalence relation and the stable classes form a ring under direct sum and tensor product. This ring is called the K-ring K(X) of the space X on which the vector bundles are defined. If X is compact and E is a vector bundle over X, then the sheaf of sections of this vector bundle is a finitely generated projective module over the ring C(X) of continuous functions on X. This result is known as the Serre-Swan theorem and allows one to discuss the K-theory of the space X in terms of the K-theory of C(X). The properties of this K-theory satisfy those needed to make it a cohomology theory, except for the dimension axiom. Topological K-theory also has the property of Bott periodicity, wherein the K-groups at one dimension are isomorphic to those of two dimensions less.<br /> The higher topological K-theory groups have a counterpart in algebraic K-theory. This can be shown in several different ways, but this book discusses the Quillen or `Q-construction' of higher algebraic K-theory. Dependent on the notion of a `nerve' of a category and its classifying space, the Q-construction involves starting with an exact category M and defining a new category QM with the same objects but with morphisms satisfying certain properties of admissibility and composition. For a small exact category M, the ith higher algebraic K-group of this category is defined as the (i+1)-th homotopy group of the classifying space of M. The book also discusses, for a ring R, the `+-construction' of Quillen, which was the first definition of higher algebraic K-theory, and is considerably less esoteric than the Q-construction since it involves the well-known result that GL(R) is the first homotopy group of the classifying space of GL(R) and the intuitive geometric construction of adding cells to the classifying space to form a new space that has certain useful properties. The ith-higher algebraic K-group is then defined as the ith-homotopy group of this space. Although it is not done in this book, this definition coincides with the Q-construction when the latter is applied to the category of finitely generated projective R-modules.theorem and allows one to discuss the K-theory of the space X in terms of the K-theory of C(X). The properties of this K-theory satisfy those needed to make it a cohomology theory, except for the dimension axiom. Topological K-theory also has the property of Bott periodicity, wherein the K-groups at one dimension are isomorphic to those of two dimensions less. <br /> The higher topological K-theory groups have a counterpart in algebraic K-theory. This can be shown in several different ways, but this book discusses the Quillen or `Q-construction' of higher algebraic K-theory. Dependent on the notion of a `nerve' of a category and its classifying space, the Q-construction involves starting with an exact category M and defining a new category QM with the same objects but with morphisms satisfying certain properties of admissibility and composition. For a small exact category M, the ith higher algebraic K-group of this category is defined as the (i+1)-th homotopy group of the classifying space of M. The book also discusses, for a ring R, the `+-construction' of Quillen, which was the first definition of higher algebraic K-theory, and is considerably less esoteric than the Q-construction since it involves the well-known result that GL(R) is the first homotopy group of the classifying space of GL(R) and the intuitive geometric construction of adding cells to the classifying space to form a new space that has certain useful properties. The ith-higher algebraic K-group is then defined as the ith-homotopy group of this space. Although it is not done in this book, this definition coincides with the Q-construction when the latter is applied to the category of finitely generated projective R-modules.	2004-03-29
729556:US	50702879	R3DT43KRANZLMK	1586481762	970287620	Human Cloning and Human Dignity: The Report of the President's Council On Bioethics	Books	3	5	7	N	Y	A collection of opinions with no firm ethical foundation.	The subject of human cloning has gained considerable press recently, due mainly to claims made by various individuals in successfully producing a human clone. These claims have remained unjustified, due to the refusal of these individuals to permit their scientific verification. The successful birth of a healthy human clone would be a major achievement, both from a scientific standpoint, and from an ethical one. It would give humans yet another option of how they are to reproduce themselves, and far from demeaning or devaluing human life, would actually celebrate it. There is no question that the first human clones will be viewed as somewhat of a novelty by many, but like all other humans born as the result of advances in technology, such as in vitro fertilization, they will be accepted as another unique and valuable addition to the human species, deserving of every legal right and every measure of respect.<br />Having unique fingerprints does not distinguish us as individuals, only our achievements do. It is the total contributions we have made in the entire span of our lives that distinguishes us as individuals.  But Leon Kass, the main author of this book, and the chairman of the President's Council on Bioethics, has chosen the fingerprint as its focal point. Indeed, in the first sentence in the forward, he states that \\"the fingerprint has rich biological and moral significance\\", and that it \\"signifies our unique personal identity.\\" It is ironic perhaps that he has chosen to address the issue of human cloning by beginning with a purely physical characterization of human individuality. Why worry about how different we are from others anyway? If a handful of clones, all with the same fingerprints, make brilliant contributions to humanity, should we not celebrate this? And if a physical attribute is needed to differentiate us as individuals, then should not human clones be regarded as unique by reference to the way they came into this world, i.e. by asexual reproduction?<br />The main virtue of this book is that it omits the vituperation that frequently accompanies discussion of genetic engineering and human cloning. It addresses the main issues calmly, without hype and without personal attacks against those who advocate the genetic engineering of or cloning of human beings. It does however present a very narrow view of the ethical philosophy behind the technology of genetic engineering. The authors cannot seem to find a sound ethical framework in which to speak. Utilitarian considerations behind reproductive cloning for example are abandoned, and are to be replaced with a \\"different frame of reference\\". The Council Members (interesting use of capital letters here) though never articulate in detail just what this ethical \\"frame of reference\\" is, but only seek a \\"deeper meaning\\" in that act of human procreation, which in their view will then give meaning to the raising of children.<br />The reproductive cloning of humans has, interestingly, a certain shock value for the council members (no caps are needed). It, to them, is the \\"most unusual, consequential, and most morally important\\" of the ways of bringing children into the world. Why indeed is this so? If the council members were suddenly to find several children in the world that were brought into the world as a result of cloning, would they find these children that much different than any other children born as the result of \\"ordinary\\" reproduction? The actions taken to produce cloned children are certainly different than taken to produce \\"ordinary\\" children, but will the children themselves be any different in terms of their humanity? Cloned children will play in the sand box, get into fights with each other, face the same struggles, and require the same kind of nurturing as any other children. The moral significance of the actions taken to voluntarily produce children shrink in comparison to their value as humans.<br />It is perhaps ironic that the council members believethat sexual procreation gives each human being a \\"sense of individual identity\\". They inadvertently express a belief that genetic structure is primarily responsible for making humans unique as individuals. Genes and not life experiences and the accumulated wisdom obtained from these experiences are believed by the council members to have great weight in determining our uniqueness as individuals. They don't believe in total genetic determinism though, as further analysis of the book reveals, but their emphasis on the genetic makeup is actually quite surprising given their anti-cloning stance. It is usually the technophilic pro-cloning groups who over-emphasize the role of genetics. One can safely bet though that both the council members and these groups would forget their differences if they saw a lovely cloned human child in a crib, one that is deserving of all the warmth and care that should be given to any other human on this planet.<br />Stem cell research has complicated the cloning debate, and with the announcement last month of promising work involving pluripotent human embryonic stem cell cells derived from a cloned blastocyst, and with the reorganization of the President's Council of Bioethics to make it more anti-cloning and anti-stem cell in its beliefs, one can certainly expect much more contention in the near future. Scientists, geneticists, and genetic engineers must make sure their work and its ethical justification are not left to the sometimes myopic and unjustified opinions such as can be found in this book. The members of the Council of Bioethics do not speak for everyone, and any authority regarding scientific or ethical matters imputed to them is incorrect. Any advice they give is purely their own personal opinion, a result of their own biases and personal history. As such it does not have moral or legal binding for anyone.ieve that sexual procreation gives each human being a \\"sense of individual identity\\". They inadvertently express a belief that genetic structure is primarily responsible for making humans unique as individuals. Genes and not life experiences and the accumulated wisdom obtained from these experiences are believed by the council members to have great weight in determining our uniqueness as individuals. They don't believe in total genetic determinism though, as further analysis of the book reveals, but their emphasis on the genetic makeup is actually quite surprising given their anti-cloning stance. It is usually the technophilic pro-cloning groups who over-emphasize the role of genetics. One can safely bet though that both the council members and these groups would forget their differences if they saw a lovely cloned human child in a crib, one that is deserving of all the warmth and care that should be given to any other human on this planet. <br />Stem cell research has complicated the cloning debate, and with the announcement last month of promising work involving pluripotent human embryonic stem cell cells derived from a cloned blastocyst, and with the reorganization of the President's Council of Bioethics to make it more anti-cloning and anti-stem cell in its beliefs, one can certainly expect much more contention in the near future. Scientists, geneticists, and genetic engineers must make sure their work and its ethical justification are not left to the sometimes myopic and unjustified opinions such as can be found in this book. The members of the Council of Bioethics do not speak for everyone, and any authority regarding scientific or ethical matters imputed to them is incorrect. Any advice they give is purely their own personal opinion, a result of their own biases and personal history. As such it does not have moral or legal binding for anyone.	2004-03-27
730159:US	50702879	R2G8GQH3HAZBQX	0201704552	56055366	High Availability Networking with Cisco	Books	4	3	3	N	Y	A detailed and very useful overview.	This book gives a well-written introduction to how to optimize the availability of networks, restricted of course to Cisco equipment. The author both argues from a theoretical standpoint, but also gives example implementations in order to connect with the real world. Those readers interested purely in the modeling of high availability networks will probably never have to actually engage in the administration of network devices, but the author encourages the perusal of the example implementations in order to gain insight into the workings of high-availability networks. I did not read chapters 4, 5, 10, 11 and 12 so I will omit their review.<br /> The first chapter defines the concept of network availability and introduces some of the elementary mathematical tools needed to characterize it. The author stresses the need for performing a 'availability management analysis' to measure the current availability of a network and study the causes of past failures. He also points out the &quot;catch-22s&quot; in the naive application of availability analysis, such as the need for insuring no common failure modes when employing parallel redundancy.<br /> Chapter two discusses bridging and routing, with careful attention given to the designations of &quot;switch&quot; and &quot;hub&quot;, and to the choice of network topology. The routing protocols RIPv2, OSPF, EIGRP, integrated IS-IS, and BGP are discussed in terms of their stability, performance and availability. Explicit calculations for the metric in EIGRP are given, to illustrate the difference between it and OSPF when redundancy is present.<br /> In chapter 3, the author considers various approaches that allow the network engineer to extend the multiply-connected design of the HA network to the network end systems. This will have the effect of eliminating all single points of failure associated with network access. He first considers the incorporation of a second network interface with independent addresses and the problems that could arise in this approach, these having to do with the network protocol architecture used, the routing protocols in place on the two interfaces, and the application recovery requirements.<br /> The use of redundant routers to ensure network availability is discussed in Chapter 6. Although it is simple to implement this redundancy, the author cautions the reader that it is the other components in the network that cause problems when using redundant routers. Crucial in these considerations is the providing of router independence for the end systems, and the author reviews several protocols for doing this, including passive RIP, proxy ARP, IRDP, DHCP, VRRP, and of course Cisco HSRP. The latter has proved its mettle in allowing transparency to the end systems, load balancing, and the prevention of routing black holes, but the author also stresses that care must be taken to ensure that efficiency is preserved and awareness must be made of the hardware limitations of the routers using HSRP. A very detailed discussion is given on how to protect against LAN segmentation. A real-world example is given that illustrates all of the concepts that the author discusses in this chapter.<br /> Networks built on the hub-and-spoke topology are discussed in chapter 7. Such topologies are usually the result of legacy designs in enterprise businesses and evolve into more hierarchical tree topologies as the business grows. The author's goal in this chapter is to study to what extent the connectivity and fault tolerance of these kinds of network architectures can be improved. The proper routing protocols to use for these kind of topologies are discussed first, and, because of the HA requirement, must be chosen to be dynamic, despite the belief to the contrary that static routes would be sufficient for such simple network topologies. EIGRP is considered to be the routing protocol of choice in these kinds of topologies, and the author discusses in detail why this is the case.<br />The author directs his attention to the issues involved in HA when using Internet Service Providers with the discussion limited to the TCP/IP protocol. BGP is the protocol of choice here, due to the proliferation of routing domains in the Internet, and security issues are much more sensitive in such environments, as the author shows in great detail.  In particular, an example is given of using network address translation to route return traffic. The author also discusses the case where there is a connection to two independent ISPs, providing redundancy to the system on the other side of the Internet. Although total Internet failures are relatively rare, their duration is usually long enough to entail a serious loss of revenue to businesses that depend on the Internet predominantly for this revenue. The author discusses several issues that arise in connecting through multiple ISPs, such as address space, since there are three different classes of public Internet addresses. The interdomain routing with Border Gateway Protocol entails the participation in routing over the Internet as an independent Autonomous System. This guarantees reachability from any other end system that has a path to any of the ISPs used.<br /> In chapter 9, the author addresses availability issues when connecting through firewalls. The security reasons for the deployment of firewalls do not totally dominate the chapter. The author also discusses how the properties of firewalls affect the network design. He emphasizes that the goal in using firewalls is to ensure that the path through them is state sensitive and it must be known as to when they will appear to a router as an end-system or simply as another router. He explains using examples how these distinctions impact network design, and cautions that considerations of router mode versus end-system mode should not be confused with proxy-mode versus pass-through mode considerations. Also discussed are firewalls in a fully redundant network, and the high availability requirements dictate that even greater attention be paid to security issues, since breaches of security may prevent the availability goals. Examples of redundant firewalls with hot standby failover and with load sharing failover are also discussed in detail. The conflict between the needs of routing and the security requirements of firewalls is readily apparent throughout this chapter.<br /> The author directs his attention to the issues involved in HA when using Internet Service Providers with the discussion limited to the TCP/IP protocol. BGP is the protocol of choice here, due to the proliferation of routing domains in the Internet, and security issues are much more sensitive in such environments, as the author shows in great detail.  In particular, an example is given of using network address translation to route return traffic. The author also discusses the case where there is a connection to two independent ISPs, providing redundancy to the system on the other side of the Internet. Although total Internet failures are relatively rare, their duration is usually long enough to entail a serious loss of revenue to businesses that depend on the Internet predominantly for this revenue. The author discusses several issues that arise in connecting through multiple ISPs, such as address space, since there are three different classes of public Internet addresses. The interdomain routing with Border Gateway Protocol entails the participation in routing over the Internet as an independent Autonomous System. This guarantees reachability from any other end system that has a path to any of the ISPs used.  <br /> In chapter 9, the author addresses availability issues when connecting through firewalls. The security reasons for the deployment of firewalls do not totally dominate the chapter. The author also discusses how the properties of firewalls affect the network design. He emphasizes that the goal in using firewalls is to ensure that the path through them is state sensitive and it must be known as to when they will appear to a router as an end-system or simply as another router. He explains using examples how these distinctions impact network design, and cautions that considerations of router mode versus end-system mode should not be confused with proxy-mode versus pass-through mode considerations. Also discussed are firewalls in a fully redundant network, and the high availability requirements dictate that even greater attention be paid to security issues, since breaches of security may prevent the availability goals. Examples of redundant firewalls with hot standby failover and with load sharing failover are also discussed in detail. The conflict between the needs of routing and the security requirements of firewalls is readily apparent throughout this chapter.	2004-03-27
732267:US	50702879	R3FV4UQS58MS3E	1578700949	714913920	Cisco LAN Switching (CCIE Professional Development series)	Books	4	2	2	N	N	A very detailed and very useful overview.	Although this book is designed for readers whose goal is to become CISCO CCIE certified, it could still be read profitably by anyone who needs to understand in detail the design and operation of LANs using CISCO technology. It could even serve as an introduction to general LAN networking technology, even though the book is dedicated to CISCO equipment. As someone involved in the mathematical modeling and simulation of networks, my interest in the book was to obtain knowledge of LAN network configurations and behavior in order to gain insight into performance issues that arise in these types of networks. The book is very detailed, and has exercises at the end of every chapter with answers given to all of these in the Appendix to the book. The emphasis of the book is on both the theory and practical issues that arise in CISCO LANs and how to administer them properly. Since the interest of this reviewer was in performance issues, I only skimmed briefly the discussions on LAN administration.<br />Performance issues are addressed in the book, such as those that arise in Ethernet. The authors show how to calculate the theoretical frame rates for Ethernet, and also give advice on when to judge whether or not an Ethernet network is functioning well. That judgment will be dependent on subjective factors such as user perceptions, as well as quantitative measurements taken from the network. The authors also stress the need for being aware of the hardware limitations of the client when increasing the network bandwidth. Clients could handle a Fast Ethernet for example, and there are times when such bandwidth is needed. However a Gigabit Ethernet connection could actually slow down a typical client workstation due to software interrupts. They elaborate on the Fiber Channel technology when addressing these issues also. Also discussed are the differences between copper and fiber optic media and what kinds of configurations they are best suited for.<br />The authors give the reader insight into the need for LAN segmentation, and compare collision and broadcast domains. They are careful to point out the need for actually measuring the average and peak bandwidth consumed by the applications, rather than just relying on the quoted theoretical bandwidth. All of the network configurations that the authors discuss can be modeled by commercial simulation software available on the market today.  This software can complement the book in that the reader can see just what can happen when making network design changes as specified in the book.<br />Large enterprise businesses frequently need to make use of VLANs and the authors discuss in detail the justifications for using them. These include network security and privacy, broadcast distribution, bandwidth utilization, network latency from routers, and complicated access lists. The authors though emphasize that VLANs may not be as simple to manage as some network administrators believe. The complexity of the network may in fact increase with the use of VLANs, due to the nature of the Spanning Tree algorithm and the dispersive characteristic of broadcast domains. The desire to have a \\"flat\\" network via \\"end-to-end\\" VLANs ran into issues with scalability, due mostly to the Spanning Tree algorithm.<br />Due to its importance, the Spanning Tree protocol is discussed in great detail in this book, with two chapters spanning 136 pages devoted to its elucidation. It is introduced as a loop-prevention protocol that allows bridges to communicate with each other with the goal of discovering physical loops in the network. An example is given of a feedback loop that resulted in 2.4Gbps of traffic in 45 minutes, in order to convince the reader of the severity of feedback loops. All of the examples discussed in these two chapters illustrate the need for great care when implementing the Spanning Tree protocol in LANs. Also discussed is the tricky task of doing Spanning Tree load balancing, which must be done if one is interested in creating a network with optimal performance. Root bridge placement, port and bridge priority, and port cost are the techniques discussed for doing Spanning Tree Load Balancing. The role of VLANs in the creation of multiple Spanning Tree domains over a single physical infrastructure is readily seen in all of these techniques. The advantages and disadvantages of each technique are summarized in detail by the authors.<br />Networks rarely exist in isolation, with connections between them being the norm rather than the exception. The authors therefore discuss different methods of doing the interconnection, via AIM, FDDI, or Ethernet. This is called \\"trunking\\" and is discussed in great detail in the book. As pointed out by the authors, trunking has more scalability then access links since a network administrator can distribute the VLAN connectivity without the need to use a large number of cables and interfaces. One of the most useful of trunking technologies, at least to this reviewer, is EtherChannel, which can give trunk speeds on the order of FastEthernet and Gigabit Ethernet without the need to use another technology. The authors discuss the advantages of using EtherChannel, its ability to function as both an access or a trunk link, and its ability to bundle segments so as to offer more effective bandwidth than any one of the individual links. The authors also discuss the proprietary CISCO link negotiation protocol called Dynamic Trunk Protocol, which reduces the possibility of incompatibility when links are being configured. The trunking capabilities of ATM technologies are also discussed in the context of their long-distance capabilities and their ability to carry different types of traffic, such as voice and video. For readers not familiar with ATM, the authors give a fairly detailed review of it, and an overview of Emulated LAN (ELAN), the latter of which is a special type of VLAN, namely a LAN emulated over ATM. This motivates a treatment of LANE, and then a discussion of trunking in a Catalyst environment, with Multiprotocol over ATM (MPOA).s interested in creating a network with optimal performance. Root bridge placement, port and bridge priority, and port cost are the techniques discussed for doing Spanning Tree Load Balancing. The role of VLANs in the creation of multiple Spanning Tree domains over a single physical infrastructure is readily seen in all of these techniques. The advantages and disadvantages of each technique are summarized in detail by the authors. <br />Networks rarely exist in isolation, with connections between them being the norm rather than the exception. The authors therefore discuss different methods of doing the interconnection, via AIM, FDDI, or Ethernet. This is called \\"trunking\\" and is discussed in great detail in the book. As pointed out by the authors, trunking has more scalability then access links since a network administrator can distribute the VLAN connectivity without the need to use a large number of cables and interfaces. One of the most useful of trunking technologies, at least to this reviewer, is EtherChannel, which can give trunk speeds on the order of FastEthernet and Gigabit Ethernet without the need to use another technology. The authors discuss the advantages of using EtherChannel, its ability to function as both an access or a trunk link, and its ability to bundle segments so as to offer more effective bandwidth than any one of the individual links. The authors also discuss the proprietary CISCO link negotiation protocol called Dynamic Trunk Protocol, which reduces the possibility of incompatibility when links are being configured. The trunking capabilities of ATM technologies are also discussed in the context of their long-distance capabilities and their ability to carry different types of traffic, such as voice and video. For readers not familiar with ATM, the authors give a fairly detailed review of it, and an overview of Emulated LAN (ELAN), the latter of which is a special type of VLAN, namely a LAN emulated over ATM. This motivates a treatment of LANE, and then a discussion of trunking in a Catalyst environment, with Multiprotocol over ATM (MPOA).	2004-03-25
745321:US	50702879	R3W2NZ4JT3D2BB	0691087717	453854261	Lectures on the Arithmetic Riemann-Roch Theorem. (AM-127) (Annals of Mathematics Studies)	Books	4	3	3	N	Y	Deep but important	The Riemann-Roch theorem has come a long way since its origins in the work of Bernhard Riemann 154 years ago. Riemann was attempting to establish the existence of complex functions on multiply-connected surfaces with no boundary. A surface that is (2p + 1)-connected for a positive integer p can be represented as a 4p-sided polygon after making 2p cuts. Riemann showed using the Dirichlet principle that there are p linearly-independent functions defined inside this polygon that are everywhere holomorphic. The differentials of these functions are also holomorphic integrands. By specifying D points at which a function can have simple poles, and by constraining the functions to change only by a constant amount at the cuts, then Riemann showed that one can obtain functions with only simple poles and constant \\"jumps\\" by taking a sum of p linearly independent functions with no poles with functions of the form 1/z at one of the specified points and a constant term. Non-constant meromorphic functions thus exist when p + D + 1 - 2p >= 2, or D > p, which is now called the Riemann inequality. Hence there is a linear space of complex functions of dimension >= D + 1 - p, which contains non-constant functions when D + 1 - p > 1. Roch was Riemann's student and interpreted the quantity D + 1 - p as the dimension of the space of holomorphic integrands. If a function has D simple poles, and if there are Q linearly independent integrands that vanish at these poles, then the function depends on D - p + q + 1 arbitrary constants.<br /> The work of Riemann and Roch is readily seen to be related to the genus of the surface, if viewed in the light of the polygon of 4p sides. The modern view of the Riemann-Roch theorem in fact is naturally viewed as a generalization of a formula for the Euler characteristic, the latter of which involves the genus of a Riemann surface. The \\"classical\\" Riemann-Roch theorem is stated in terms of divisors on a Riemann surface X of genus g and reads as r(-D) - i(D) = d(D) - g + 1, where D is a fixed divisor on the surface, r(-D) is the dimension of meromorphic functions of divisors >= -D on X, and i(D) is the dimension of the space of meromorphic 1-forms of divisors >= D on X. Many other statements have been given, one being in terms of holomorphic bundles defined by D over X, where one computes the Euler characteristic of the sheaf of germs of holomorphic sections of the bundle. Another is in the context of holomorphic bundles over nonsingular complex projective varieties, where the Euler characteristic of the sheaf of holomorphic sections of the bundle is given in terms of a formula involving the first Chern class of the variety. The Euler characteristic has of course also been computed in terms of the index of Dirac operators, and so it is not surprising to find that the Riemann-Roch theorem has an analytical formulation also.<br /><br /> This book proves a Riemann-Roch theorem for arithmetic varieties, and the author does so via the formalism of Dirac operators and consequently that of heat kernels. In the first lecture the reader will see the \\"classical\\" Riemann-Roch theorem in an even more general context then that mentioned above: that of smooth morphisms of regular schemes. Using familiar constructions involving the K-groups and Chow groups to make the calculations more manageable, the author proves the Riemann-Roch theorem for regular schemes by reducing it to the case for projective bundles. Flag schemes are used in the proof, and the strategy used here repeats itself in the proof of the arithmetic Riemann-Roch theorem. Throughout the book the author outlines the necessary background for the eventual proof of the arithmetic Riemann-Roch theorem. This includes a discussion of how to define Chern classes for arithmetic vector bundles, as well as the background in analysis via a discussion of heat kernels and Laplacians on Riemannian manifolds. The detailed discussion of analysis was done, according to the author, soas to avoid the methods of stochastic integration, which he felt might not be familiar to the average reader with a background in algebraic geometry.s to avoid the methods of stochastic integration, which he felt might not be familiar to the average reader with a background in algebraic geometry.	2004-03-15
753853:US	50702879	R2MI29JZYTH9B0	0387954457	683819313	Stochastic Petri Nets: Modelling, Stability, Simulation (Springer Series in Operations Research and Financial Engineering)	Books	5	6	6	N	Y	Very detailed overview of SPNs	Petri nets have been used in operations research and the mathematical modeling of discrete-event systems ever since they were invented in the early 1960s. The applications of Petri nets are immense, having permeated many different fields, some of these being network engineering, queueing theory, and automated manufacturing. This book gives a very clear introduction to the mathematical theory of stochastic Petri nets (SPNs), which were invented in the 1980s, and which are used to model discrete-event systems which undergo stochastic state transitions occur only at an increasing sequence of random times. The book should be viewed as a monograph rather than a textbook since there are no exercises (unfortunately), but readers could still gain a good understanding of stochastic Petri nets by its perusal. One could make up for the lack of exercises by perhaps thinking of new applications of SPNs. My interest in the book was motivated by my wish to use SPNs to model network and application servers, poker games, and machine curiosity and decision-making in artificial intelligence. I only read chapters 1-5 and chapter 9, and so my review will be confined to these.<br />The author defines an SPN as a graph composed of a finite set of `places' and a finite set of `transitions'. A subset of these transitions are taken to be `immediate' transitions, and the set of places consists of normal input places, inhibitor input places, and output places, given a particular transition. A (countable) set of markings denoting the number of `tokens' in a place is also defined. In chapter 2, the author gives several examples of SPNs, such as a producer-consumer system, a queue with batch arrivals, a token ring network, a flexible manufacturing system, a particle counter, and a slotted ring network. Some of these examples illustrate the use of marking-dependent transitions, and the fact that SPN representations of discrete-event systems are not unique. The author also briefly discusses the SPSIM simulation language for SPNs. Also discussed briefly are restricted SPNs, wherein the marking set is not specified explicitly, and an accompanying notion of reachability.<br />The marking process of an SPN is described in terms of an underlying general state-space Markov chain in chapter 3. This allows sample paths to be generated, and one can utilize the results from the theory of Markov chains to study the long-time behavior of SPNs and define performance measures for them. The author gives an explicit algorithm for generating sample paths for the underlying chain and using this, for the marking process itself. This is followed by a discussion of sufficient conditions needed to guarantee infinite lifetimes for the marking process, thus avoiding \\"explosions\\", wherein an infinite number of marking changes occur in a finite time interval with probability 1. The author also gives criteria for showing when the marking process is a time-homogeneous continuous-time Markov chain.<br />In chapter 4, the author discusses to what extent discrete-event systems can be modeled within the SPN framework. He does not answer this in general, claiming that it cannot be, but instead compares the modeling power of SPNs to that of generalized semi-Markov processes (GSMPs). These systems differ, he says, in their event-scheduling and state-transition mechanisms, and the form of the state-space. GSMPs are more general than SPNs, but the author shows that SPNs have at least the modeling power of GSMPs, in that for any GSMP there exists an SPN that `strongly mimics' it: there is a marking process such that both of the processes have the same finite-dimensional distributions using an appropriate mapping between the underlying state spaces. Conversely, for any SNP with both timed and immediate transitions, the author shows that there exists a GSMP that strongly mimics the marking process of the SPN. A very brief but interesting discussion on the ability of Petri nets to mimic a Turing machine is given in the notes to the chapter.<br />The author turns his attention to stability issues in chapter 5. This attention is dictated by the fact the in order for SPNs to be practical for simulation purposes, their marking processes must have well-defined time-average limits. The stability of an SPN is shown, as expected, with reference to the underlying state-space Markov chain used to define the marking process. In this context, the author uses the notion of \\"Harris recurrence\\", wherein Markov chains that have this property repeatedly return to a dense, compact set of states. Criteria for establishing Harris recurrence are given throughout the chapter. Readers will have to know some amount of measure theory in order to read this chapter. The author gives a brief review of it in one of the appendices.<br />Chapter 9 covers colored stochastic Petri nets (CSPNs), which have myriads of applications and so a thorough reading of it is essential for those involved in those applications. As the author explains, associating colors with tokens and transitions will allow the simplification of Petri nets that have large numbers of places and transitions. The tokens are removed and deposited deterministically, and so CSPNs have less modeling power than SPNs. The tradeoff though is the conciseness of the CSPNs. Noted in the definition of CSPNs is the presence of input and output incidence functions, which determine when a transition is enabled in a color and the number of tokens removed and deposited when a transition fires in a color. Several examples of CSPNs are discussed, including machine repair, a token ring network, a system of cyclic queues with feedback, and one dealing with customer complaint processing. As was the case for SPNs, the marking process of a CSPN is defined in terms of a general state-space Markov chain that describes the CSPN at successive marking changes. The author studies the stability of CSPNs , and considers what are called \\"symmetric\\" CSPNs, which are those that remain the same under permutations of its set of colors. The mathematical analysis of symmetric CSPNs is, as expected, simpler than non-symmetric CSPNs.hine is given in the notes to the chapter.<br />The author turns his attention to stability issues in chapter 5. This attention is dictated by the fact the in order for SPNs to be practical for simulation purposes, their marking processes must have well-defined time-average limits. The stability of an SPN is shown, as expected, with reference to the underlying state-space Markov chain used to define the marking process. In this context, the author uses the notion of \\"Harris recurrence\\", wherein Markov chains that have this property repeatedly return to a dense, compact set of states. Criteria for establishing Harris recurrence are given throughout the chapter. Readers will have to know some amount of measure theory in order to read this chapter. The author gives a brief review of it in one of the appendices.<br />Chapter 9 covers colored stochastic Petri nets (CSPNs), which have myriads of applications and so a thorough reading of it is essential for those involved in those applications. As the author explains, associating colors with tokens and transitions will allow the simplification of Petri nets that have large numbers of places and transitions. The tokens are removed and deposited deterministically, and so CSPNs have less modeling power than SPNs. The tradeoff though is the conciseness of the CSPNs. Noted in the definition of CSPNs is the presence of input and output incidence functions, which determine when a transition is enabled in a color and the number of tokens removed and deposited when a transition fires in a color. Several examples of CSPNs are discussed, including machine repair, a token ring network, a system of cyclic queues with feedback, and one dealing with customer complaint processing. As was the case for SPNs, the marking process of a CSPN is defined in terms of a general state-space Markov chain that describes the CSPN at successive marking changes. The author studies the stability of CSPNs , and considers what are called \\"symmetric\\" CSPNs,which are those that remain the same under permutations of its set of colors. The mathematical analysis of symmetric CSPNs is, as expected, simpler than non-symmetric CSPNs.	2004-03-08
755268:US	50702879	R2PDZZLNBRNQHD	080581986X	346723047	Artificial Intelligence and Literary Creativity: Inside the Mind of Brutus, A Storytelling Machine	Books	5	1	1	N	Y	A prelude to automated novel writing.	Machines that can summarize documents are commonplace, as well as machines that can extract words and lines from paragraphs and rearrange them to possibly form something useful or interesting. But can a machine write a short story, or even a full-fledged novel with complex characters and themes? That such ability is not only possible for machines but is actually present in some of them is the subject of this book, and if one ignores the philosophical rhetoric on the \\"strong AI\\" problem, the authors give a fine overview of their project to create a \\"story-telling machine\\", which they have designated as BRUTUS.<br />The authors claim that their book \\"marks the marriage of logic and creativity\\", a claim that will raise the eyebrows of many a philosopher, literary critic, or novelist. But the intuitive dissonance that many in these professions may have regarding the reduction of the free-play of the imagination to the rigors and organization of logic should not dissuade others from believing that such a reduction is not only possible, but has actually been accomplished. Ironically, the authors early in the book assert that there are no examples of machine creativity in the world. Of course, this assertion depends on one's notion of what creativity is, and to what degree this creativity may have depended on the assistance of machines. Machines that create new mathematics, scientific theories, music, or novels do not yet exist, the authors claim, but they do take pains to express their optimism regarding future developments in \\"machine creativity\\".<br />The authors are incorrect in their belief that there are no machines now that can currently develop new and interesting results in a wide variety of different domains. In addition, their notion of intelligence is too anthropomorphic, too tied to what human intelligence is, or is not (and one could argue that machine intelligence is even better understood than human intelligence). The authors though have written a book that gives the reader much insight into what is involved in building creative, thinking machines. Most refreshingly, the authors do not want to settle the question of machine creativity from the comfort of their armchairs, but instead from the laboratory by actually building artificial authors. Philosophical speculation is for the most part eschewed, and is replaced by the rigors and sometimes frustrations of laboratory experiments.<br />According to the authors, BRUTUS exhibits \\"weak\\" creativity rather than \\"strong\\", with the latter being compared to the creation ex nihilo, examples of this being non-Euclidean geometry and the Cantor diagonalization method from mathematics. Weak creativity on the other hand, is a more practical notion, and according to the authors is rooted in the \\"operational\\" one developed by psychologists. In the development of BRUTUS, the authors wanted to create an automated story generator that satisfied seven requirements: 1. The machine must be competitive with the requirements of strong creativity. 2. The machine must be able to generate imagery in the mind of the reader. 3. The machine must produce stories in a \\"landscape of consciousness.\\" 4. The machine must be capable of formalizing the concepts at the core of \\"belletristic\\" fiction, with the example of \\"betrayal\\" being emphasized the most by the authors. 5. The machine must be able to generate stories that a human would find interesting. 6. The machine must be in command of story structures that will give it \\"immediate standing\\" in the human audience. 7. The prose developed by the machine must be rich and compelling, not \\"mechanical\\". BRUTUS they say meets all of these requirements, but no doubt some critics will think otherwise. The authors do make a sound case for their assertions that it does, and it is the belief of this reviewer that they have, and that BRUTUS is one of first automated story generators. With optimism toward the future developments of BRUTUS and artificial intelligence in general, they state that \\"a machine able to write a full, formidable novel, or compose a feature-length film, or create and manage the unfolding story in an online game, would be, we suspect, pure gold. \\"<br />They are right.ence in general, they state that \\"a machine able to write a full, formidable novel, or compose a feature-length film, or create and manage the unfolding story in an online game, would be, we suspect, pure gold. \\"<br />They are right.	2004-03-07
765039:US	50702879	RHKD35ZU0KSBD	0521576253	13393506	Ends of Complexes (Cambridge Tracts in Mathematics)	Books	5	1	1	N	Y	An introduction to topology of CW complexes at infinity.	Compact spaces have been the most desired category to work in both in topology and analysis. This is mainly due to the control that one has over the topology of the space or over the functions defined on it. Dealing with non-compact spaces requires new tools and analysis that are more difficult to use than in the compact case. This book is one of the few that specialize in the study of non-compact spaces via the `ends' of such spaces. Loosely speaking, the `ends' of a topological space are the directions where the space becomes non-compact: they are the complements of arbitrarily large compact subspaces of the space. The authors use tools from both algebra and homotopy theory to deal with the `tame' ends of manifolds and CW-complexes. The treatment is well-organized and well-motivated, and anyone interested in the role that non-compact spaces play in topology, particularly in the classification of high-dimensional compact spaces, can benefit from its study.<br />The book is divided into three parts, the first dealing with the `topology at infinity' using homotopy theory; the second with `topology over the real line' for tame ends; while the third deals with the algebraic theory of ends, and the connection with algebraic K- and L-theory. The main results of the book, dealing with CW complex bands and ribbons, appear in the last three chapters of part 2, but because of space limitations, only the first part will be reviewed here.<br />After an introduction and chapter summary in the first sections of the book, the authors begin a rigorous study of end spaces in chapter 1. The end space e(W) of a space W is studied in terms of its homotopy type, with its path components related to the number of ends of W, and its fundamental group related to the fundamental group at infinity of W. As expected, the end space of a compact space is empty. e(W) can be simple, such as the real line, which has two ends, while the dyadic tree has uncountably many ends.<br />In chapter 2 the authors use direct and inverse systems of groups to study e(W), showing the connection between its weak homotopy type and an inverse system of subspaces of W, and how its homotopy groups fit into a short exact sequence involving the derived limit. Particularly interesting is their discussion on the how the homology of non-compact spaces is related to the localization and completion of rings.<br />The `homology at infinity' of a compact space is studied in chapter 3, with the authors giving detailed constructions of `locally finite' homology. The extent to which the homology at infinity is nonzero gives a measure of the non-compactness of W. The authors relate the homology groups of the end space to the homology at infinity of W, and show that it is an isomorphism if W is `forward tame'. This is followed in chapter 4 by a discussion of cellular homology, the authors relating the singular locally finite homology groups of a certain CW complex to the cellular locally finite homology groups, generalizing the classical result.<br />The homology of covering spaces of W is studied in chapter 5, the authors relating locally finite homology isomorphisms of universal covers to proper homotopy equivalences, generalizing the classical Whitehead theorem. The ordinary and locally finite homology, and the homology at infinity are related to the Wall finiteness obstruction and Whitehead torsion in chapter 6. Algebraic K-theory makes its first appearance here, along with the (locally-finite) projective class, which becomes the Euler characteristic for some CW-complexes. This is followed by discussions of forward and backward tameness in chapters 7 and 8. These notions rely on the behavior of proper maps and homotopies on certain subspaces of W. In chapter 9 the authors give criteria for when a space (an absolute neighborhood retract) is forward and reverse tame, namely it must be bounded homotopy equivalent at infinity to a product with [0, infinity). Then in chapter 10, the projective class at infinity is used as an obstruction to the reverse collaring of W, and the authors prove that for the case of a manifold, the end is forward tame if and only if it is reverse tame, for certain conditions on the fundamental group. The Wall finiteness obstruction makes its appearance here, in that the projective class at infinity is its image under certain conditions on W. The case of infinite torsion in a proper homotopy equivalence of locally finite CW complexes is defined as an element of the infinite Whitehead group in chapter 11. The author uses this notion to prove an analog of the classical Siebenmann result on tame ends and collaring, namely that ends are collared if and only if they are tame and the K0 obstruction vanishes. The authors prove in partcicular that for a (strongly) locally finite CW complex W that is forward tame, the product of W with the unit circle is (infinite) simple homotopy equivalent to a forward collared CW complex (same holds true for reverse tame). That forward tameness is a `homotopy pushout' is proven in chapter 12, at least for metric spaces that are sigma-compact. Used in the proof of this is a special notion of a mapping cylinder called a `teardrop' mapping cylinder.ojective class at infinity is used as an obstruction to the reverse collaring of W, and the authors prove that for the case of a manifold, the end is forward tame if and only if it is reverse tame, for certain conditions on the fundamental group. The Wall finiteness obstruction makes its appearance here, in that the projective class at infinity is its image under certain conditions on W. The case of infinite torsion in a proper homotopy equivalence of locally finite CW complexes is defined as an element of the infinite Whitehead group in chapter 11. The author uses this notion to prove an analog of the classical Siebenmann result on tame ends and collaring, namely that ends are collared if and only if they are tame and the K0 obstruction vanishes. The authors prove in partcicular that for a (strongly) locally finite CW complex W that is forward tame, the product of W with the unit circle is (infinite) simple homotopy equivalent to a forward collared CW complex (same holds true for reverse tame). That forward tameness is a `homotopy pushout' is proven in chapter 12, at least for metric spaces that are sigma-compact. Used in the proof of this is a special notion of a mapping cylinder called a `teardrop' mapping cylinder.	2004-02-29
766737:US	50702879	R33CCBDFPS1THZ	0262523027	219615714	Essential Sources in the Scientific Study of Consciousness (MIT Press)	Books	5	33	34	N	Y	A fascinating collection of articles	If thought about in retrospect, it is perhaps flabbergasting that the study of consciousness was not considered, and could not be considered, part of science. The impact of the behavioral school of psychology was no doubt both a symptom and a cause of this exclusion. The reasons though for excluding the study of consciousness from science are now properly given to historians, for, as this book is an indication of, extensive scientific research is now being done in this area, and this research is a fascinating story. Once thought to be the domain of mysticism and philosophy, research into consciousness has, finally, entered the domain of the laboratory. The arm-chair speculations of Edmund Husserll are now replaced by the fMRI scan and careful observations. In the words of Francis Crick and Christof Koch, who have written an article for this book, &quot;the time to start the scientific attack is now.&quot;<br />  The book is a collection of articles written by active researchers in the field. The preface and the introductory article are excellent and not only introduce the reasons for the book but also put the articles in historical perspective. The author addresses the skepticism of some scientists on whether there is any evidence of conscious experience as such. The articles in the book were selected according to their approach as treating \\"consciousness as a variable\\", similar to any other topic of scientific inquiry. He is aware of the problems associated with such a view though, since consciousness, he says, cannot be varied \\"from the inside\\". Decreasing it will cause us to lose the ability to observe anything, and the consciousness of others is not accessible directly. The author stresses though that contrary to the assertions of some philosophers, consciousness is not beyond scientific study. We need not depend on \\"plausible intuitions, thought experiments, or rhetorical brilliance\\", but can instead rely on experiments and testable hypotheses. He calls this a \\"verifiable phenomenology\\" in contrast with the philosophical movement of the last century.<br /> The article by George Mandler also expresses this attitude, asserting that the study of consciousness has been plagued with \\"philosophical, theological, and pedestrian semantic debris\\". For Mandler, the \\"mind\\" refers to the \\"totality of theoretical processes ascribed to the individual\\", and this viewpoint, he believes, will avoid the collapse into solipsism and sophistry that so often accompanies the philosophical view of the mind. Mandler gives an excellent overview of some of the approaches taken in the scientific study of consciousness. He also outlines his personal views on the subject, asserting that for him, consciousness is tied to a system of limited capacity, this limitation referring to the number of \\"functional units\\" that can be kept in consciousness at a particular point in time. Mandler does believe though that psychologists and philosophers are correct in their assertion that the content of consciousness is not directly available, and so other strategies must be invented to deal with this content. Most interesting though is that the author does not view consciousness as primary, but instead views it merely as one particular mode of processing. Conscious processing of information cannot therefore be said to have more status than processing that does not.<br /> There are many interesting articles in this book, and space constraints do not permit a detailed review here. Some of articles that this reviewer found interesting or exceptionally well written are: 1. \\"Consciousness and Isomorphism\\" by Stephen E. Palmer, which addresses the \\"inverted spectrum argument\\". This has been a source of philosophical argumentation ever since John Locke first proposed it in 1690, and asks for a demonstration that the visual experience of colors between two individuals are the same, or whether they are spectrally inverted. The author discusses his reasons for rejecting Locke's assertion that there is no way to tell whether the spectrums are indeed inverted without the two persons \\"getting into each others heads.\\" 2. \\"Strategies and Models of Selective Attention\\" by Anne M. Treisman. The author outlines her strategies for classifying attention tasks and experimental procedures to study them. She restricts herself to tasks that require immediate perception and response, wherein the experimental subjects are subjected to information overload. Her goal is to find out to what extent the mechanisms of selective attention can be encapsulated into a single mechanism. 3. \\"Aspects of the Theory of Comprehension, Memory, and Attention\\" by Donald G. MacKay, which attempts to provide evidence for a \\"modern\\" version of Wundt's theory, the latter of which asserted that the processing of sentences takes place at two distinct levels, one involving preattentive processes and the other attentive ones. The \\"modern\\" version asserts that the perceptual mechanism consists of two distinct and interrelated levels of components, with the first involving limited capacity short-term memory, and the second a large long-term memory. 4. The article \\"Conscioussness and Complexity\\" by Giulio Tononi and Gerald M. Edelman. This article, like all the rest in the last part of the book, called \\"Theory\\" is fascinating, again because of its attempt to respect the role of experiments. The authors attempt to identify the types of neural processes that account for the key properties of conscious experience, emphasizing that conscious experience is integrated but simultaneously also highly differentiated in that one can experience a large number of different conscious states within a short time. The authors discuss tools for measuring integration, which they call `functional clustering' and for measuring differentiation, which they call `neural complexity'. Then they give criteria for determining whether in fact a group of active neurons can contribute to conscious experience. These criteria are encapsulated into the `dynamic core hypothesis', which they claim is a testable hypothesis on neural contributions to conscious experience. Recent experimental findings are discussed that, in the author's view, show that this hypothesis is viable. These measurements of neural activity shed light on what kind of neural circuits are needed to perform different types of tasks, these tasks sometimes needing conscious control, and sometimes not.ke's assertion that there is no way to tell whether the spectrums are indeed inverted without the two persons \\"getting into each others heads.\\" 2. \\"Strategies and Models of Selective Attention\\" by Anne M. Treisman. The author outlines her strategies for classifying attention tasks and experimental procedures to study them. She restricts herself to tasks that require immediate perception and response, wherein the experimental subjects are subjected to information overload. Her goal is to find out to what extent the mechanisms of selective attention can be encapsulated into a single mechanism. 3. \\"Aspects of the Theory of Comprehension, Memory, and Attention\\" by Donald G. MacKay, which attempts to provide evidence for a \\"modern\\" version of Wundt's theory, the latter of which asserted that the processing of sentences takes place at two distinct levels, one involving preattentive processes and the other attentive ones. The \\"modern\\" version asserts that the perceptual mechanism consists of two distinct and interrelated levels of components, with the first involving limited capacity short-term memory, and the second a large long-term memory. 4. The article \\"Conscioussness and Complexity\\" by Giulio Tononi and Gerald M. Edelman. This article, like all the rest in the last part of the book, called \\"Theory\\" is fascinating, again because of its attempt to respect the role of experiments. The authors attempt to identify the types of neural processes that account for the key properties of conscious experience, emphasizing that conscious experience is integrated but simultaneously also highly differentiated in that one can experience a large number of different conscious states within a short time. The authors discuss tools for measuring integration, which they call `functional clustering' and for measuring differentiation, which they call `neural complexity'. Then they give criteria for determining whether in fact a group of active neurons can contribute to conscious experience.These criteria are encapsulated into the `dynamic core hypothesis', which they claim is a testable hypothesis on neural contributions to conscious experience. Recent experimental findings are discussed that, in the author's view, show that this hypothesis is viable. These measurements of neural activity shed light on what kind of neural circuits are needed to perform different types of tasks, these tasks sometimes needing conscious control, and sometimes not.	2004-02-28
774970:US	50702879	R2UQ8KBG4RDXA1	0121619648	7517000	Artificial Intelligence (Handbook Of Perception And Cognition)	Books	4	3	3	N	N	Things have changed a lot since this book appeared.	This book is a collection of articles that give a fair representation of the status of artificial intelligence in the mid 1990's. In only a decade since those times, the field has expanded considerably, mostly due to applications and the rise of the Internet. Controversy as to the nature and characterization of machine intelligence continues of course, and one finds both intense criticism and uncritical optimism of the nature and future of artificial intelligence. Most of this takes place in the philosophical literature, but there are also places in mainstream AI circles where predictions of future developments are overly optimistic. This optimism is refreshing but it can be a distraction for those that are seriously working to develop useful applications of artificial intelligence. But also, cynicism and negativism have also thwarted research in AI, there having been a few cases that showed much promise, but were abandoned because the researchers were convinced by others that their ideas were unsound. The AM and EURISKO efforts in automated mathematics, which are discussed briefly in this book, are good examples of this.<br />All of the articles in this book are interesting, but there are a few that stand out due to their penetrating insight on matters that are still of great interest in artificial intelligence. One of these is the article entitled \\"Creativity\\" by Margaret A. Boden, who is the editor of the book, and who has done some outstanding work in the elucidation of what it means for a machine (human or otherwise) to be creative. Her insights on this subject are many, and in the opinion of this reviewer her works should be required reading for all those interested in the origins of creativity and attempts to implement it in non-human machines.<br />Boden asserts that every case of creativity cannot be explained by a single scientific theory, one reason for this being that an AI model must be evaluated, and such an evaluation is outside the realm of science. In addition, there is a high variability in creative psychological processes, which preclude a general understanding of them. Lastly, creativity is very idiosyncratic but Boden is careful to point out that it is not random, but instead subject to constraints in `conceptual space'. Boden does not define conceptual spaces from a mathematical standpoint in her article, but she does discuss their utility in modeling creativity in AI, and the role of AI models in making more rigorous the conceptual spaces employed by musicologists, literary critics, etc. Boden's ideas in this article on the mapping, exploring, and transforming conceptual spaces can be viewed in the context of dynamical systems, and such a view allows them to be more easily coded into a machine language. Boden discusses several examples of AI models of the arts, such as connectionist models of music, the AARON program for generating line drawings, and the Letter Spirit project, which tries to model the perception of alphabetic style. She points out the pluses and minuses in each of these examples, such as the limited compositional ability of connectionist models, the limited evaluative and self-correcting powers of AARON, and the lack of Letter Spirit in being able to justify its own decisions. AI models of science are also discussed, and Boden concludes that most of these are `data driven' and cannot identify relevance for themselves. She believes that they can learn, but their discoveries are `exploratory', and do not succeed in changing their own conceptual spaces.<br />The status of machine intelligence for scientific discovery has changed quite a bit since this article was written. Techniques from inductive logic programming coupled with faster hardware are making the reality of automated scientific discovery closer with every passing year in the twenty-first century. With more powerful hardware on the horizon, these developments give evidence of a time when drawing on the efforts of their human tutors, machines will be able to think across scientific domains and formulate hypotheses and creative ideas that may far surpass anything that has been done by human scientists. The time scales needed for this scientific discovery to take place may be so short that it might be difficult for human observers to assimilate these new results in order to evaluate their efficacy and applicability. The machines though may have their own opinions on the utility of the ideas and theories they derive.utors, machines will be able to think across scientific domains and formulate hypotheses and creative ideas that may far surpass anything that has been done by human scientists. The time scales needed for this scientific discovery to take place may be so short that it might be difficult for human observers to assimilate these new results in order to evaluate their efficacy and applicability. The machines though may have their own opinions on the utility of the ideas and theories they derive.	2004-02-22
782926:US	50702879	R10RMRXZQFAMT8	0198751591	323193243	Artificial Intelligence and Scientific Method	Books	4	8	8	N	Y	A prelude to fully automated scientific discovery	This book is interesting in that it attempts to cast questions of the scientific method into the language and concepts of artificial intelligence (AI), instead of in terms of philosophy, as is usually done. The two main camps of philosophy of science, namely inductivism, represented by Sir Francis Bacon, and that of falsificationism, represented by Sir Karl Popper are both discussed in the context of AI. Two examples, one dealing with the discovery of the laws of planetary motion due to Johannes Kepler, and the discovery of sulphonamide drugs, are chosen to illustrate the author's ideas. The author asserts that these examples do not entirely agree with either Bacon or Popper. Kepler used an \\"intuitive induction\\" which involved human insight and creativity, which is quite different from the \\"mechanical induction\\" of Bacon. The discovery of sulphonamide drugs was a more \\"mechanized\\" process, but the author believes it was more of a \\"mechanical falsification\\" rather than Baconian induction. In addition, this discovery, he asserts, has introduced the concept of heuristics, which of course is ubiquitous in artificial intelligence.<br />The author is certainly correct in his belief that Baconian induction, as outlined in the Novum Organum of 1620, has been applied only sparingly in the development of science. He believes that this is changing though thanks to the advent of machine intelligence. Indeed, the existence of machines able to recommend and design experiments, analyze the data from these experiments, and then formulate hypotheses to explain the data was reported just weeks ago in a major scientific journal. These machines were based on inductive logic programming in the guise of a language called PROGOL, which performs relational learning and was just getting started as this book went to press. The author does discuss relational learning in this book, and details algorithms for machine learning that are based on inductive rules of inference and background knowledge and data in these rules. He also discusses the role of testing and falsification in the actual process of using inductive rules of inference in order to produce the final result.<br />The specific machine learning algorithms that the author does discuss are ID3 and GOLEM, with ID3 being a \\"top-down\\" and attribute-based learning algorithm, and GOLEM a \\"bottom-up\\" and relational learning algorithm. ID3 makes use of rules that take the from of decision trees, begins with simple and general rules, and these are then modified or refuted to produce more specific generalizations. The author discusses the role that these programs have in negating the Popperian assertion that induction \\"is a myth\\". Even more interesting is the author's belief that these programs in fact illustrate the \\"mechanical\\" principles of induction that Bacon laid down in 1620. In fact, he states that he has been unable to find an example of the use of Baconian \\"mechanical\\" induction in the history of science before the advent of these languages.<br />Naturally logic programming and its main example PROLOG will arise in any discussion of machine intelligence, and it does so here. PROLOG as a language based on nonmonotonic logic is discussed in detail along with the \\"closed world assumption\\", this being done in order to construct a \\"new framework for logic\\". This framework involves viewing logic as made up not only of inferences but also a \\"control component\\", the latter of which follows either its own autonomous control decisions, or those provided by the programmer. PROLOG is viewed as a language that introduces control into deductive logic, and its development an example of a process that replaced \\"craft skill by mechanization\\". Generation (and checking) of proofs in mathematics is given as an example of this craft skill, having been done to date by trained mathematicians who have the `craft skills' to carry this out. PROLOG is able to construct proofs via its control mechanism and has both a declarative and procedural interpretation. The author shows in what sense PROLOG can lead to what he calls a `new framework for logic', and consequently as evidence that logic is really empirical, and not `a priori' as is typically assumed. The empiricism of logic was argued in another context, namely that of quantum mechanics, but the author believes that `quantum logic' has failed to support the empiricism of logic. PROLOG, he asserts, is a better example of the empirical nature of logic.<br />The author also addresses the possibility of constructing a detailed example of inductive logic, which he believes was not done in traditional circles of logic, these being concerned mostly with deductive inference. After discussing the history of the divergence between the schools of deductive and inductive logic, he expands further on his paradigm of logic as being `inference + control' in showing how ideas from conformation theory can be used as a control mechanism in deductive logic. To illustrate just how this could be done, the author draws on the work of J. Cussens, A. Hunter, and A. Srinivasan in a class of nonmonotonic logics called `prioritized' logics. These authors show that a prioritized logic will allow the inference of formulas that are `most preferred\\", with preferences being accomplished relative to some preference criterion. The author shows how to use relative-frequencies to estimate conformation values. What is most interesting about the work of these three authors, and the author points this out emphatically, is that it may permit the differentiating of one system of logic from another using experimental criteria in the context of a particular application. The author discusses how these authors were able to carry out the empirical testing of different systems of logic using the GOLEM programming language. An explicit example in bioinformatics is discussed, and the author concludes from this example that the choice of logic will depend on the interests of a particular user. Empirical evidence can thus decide on the logic used in a domain, and this choice may also depend on the requirements of the user.<br />I did not read the last chapter of the book, so its review will be omitted.eclarative and procedural interpretation. The author shows in what sense PROLOG can lead to what he calls a `new framework for logic', and consequently as evidence that logic is really empirical, and not `a priori' as is typically assumed. The empiricism of logic was argued in another context, namely that of quantum mechanics, but the author believes that `quantum logic' has failed to support the empiricism of logic. PROLOG, he asserts, is a better example of the empirical nature of logic. <br />The author also addresses the possibility of constructing a detailed example of inductive logic, which he believes was not done in traditional circles of logic, these being concerned mostly with deductive inference. After discussing the history of the divergence between the schools of deductive and inductive logic, he expands further on his paradigm of logic as being `inference + control' in showing how ideas from conformation theory can be used as a control mechanism in deductive logic. To illustrate just how this could be done, the author draws on the work of J. Cussens, A. Hunter, and A. Srinivasan in a class of nonmonotonic logics called `prioritized' logics. These authors show that a prioritized logic will allow the inference of formulas that are `most preferred\\", with preferences being accomplished relative to some preference criterion. The author shows how to use relative-frequencies to estimate conformation values. What is most interesting about the work of these three authors, and the author points this out emphatically, is that it may permit the differentiating of one system of logic from another using experimental criteria in the context of a particular application. The author discusses how these authors were able to carry out the empirical testing of different systems of logic using the GOLEM programming language. An explicit example in bioinformatics is discussed, and the author concludes from this example that the choice of logic will depend on the interests ofa particular user. Empirical evidence can thus decide on the logic used in a domain, and this choice may also depend on the requirements of the user. <br />I did not read the last chapter of the book, so its review will be omitted.	2004-02-16
794166:US	50702879	R17FY8UUDKDWXE	1559634197	247607787	Living with the Genie: Essays on Technology and the Quest for Human Mastery	Books	3	4	9	N	Y	A collection of nervous viewpoints.	Commentary on the future of science and technology is now very popular, and there have been dozens of books in recent years that are very supportive of it, and in fact engage in uncritical examination of its consequences. There are also those that criticize it vociferously, engaging in dialog and vituperation that go far beyond any standards of rational conduct. One could argue that both of these extreme views \\"balance each other out\\", but what is really needed in these books is a rational, critical view of science and technology that is supported by hard evidence, or when that is lacking, by appropriate models that shed more light on what might be coming in the future.<br />The articles in this book are not quite as extreme as the usual ones that you find in the literature today, but all of them express varying degrees of anxiety about the future of technology that they do not really justify with any evidence or sound argumentation. In reading them one must of course not confuse the intent that the authors had for writing the articles with their content. Too often the knowledge (which is usually imputed) of the author's motivations gets in the way of an objective analysis of their works. It does not matter if the author's reasons for writing the article were to market their company, expand their careers, or to draw attention to themselves. All that matters is whether their ideas are substantiated by sound evidence or not.<br />Space does not permit a detailed review of all the articles in the book, and so only two articles that this reviewer found most provocative will be discussed. One of them is the article \\"Promise and Peril\\" by Ray Kurzweil, who is certainly one of the most optimistic of all futurists. His ideas have been given ample discussion on his website, which many of us go to daily, and find it to be more uplifting than morning coffee. However optimistic his ideas, they need to eventually find more justification from a rigorous scientific point of view. Indeed, his claims on the feasibility of intelligent, self-replicating nanobot technology are completely unsubstantiated. He does quote some papers that are written by researchers that might on the surface offer some support to his assertions, but more is needed if decision-makers are going to input the financing to make this technology a reality. One method that Kurzweil could use is modeling, for when a field is in its youth, it is frequently advantageous to engage in modeling in order to assist one's intuition about what is possible. Physical and mathematical models could be constructed of the nanobot technology that would give more confidence in its feasibility. An example of this is given by the theory of molecular motors, wherein many models have been developed that illustrate their behavior, their thermodynamics, and other properties of interest. Such an approach would work well for the nanobot technology that Kurzweil insists will become a reality. Their use would certainly help his case for nanotechnology. In addition, Kurzweil claims that the hundreds of predictions he made in one of his early books have held up well, but a detailed listing of these is not given, unfortunately. Further, his prediction of the rise of machines that greatly exceed the intelligence of humans in the next few decades in unjustified. Indeed, in none of his works does he quantify his notion of intelligence, which would be needed in order to judge whether machine intelligence has indeed surpassed human intelligence. Is machine intelligence really increasing exponentially?  If so, where is the data that shows this explicitly? What intelligence tests exist that will provide a quantitative measure of machine intelligence?<br />Another interesting article is the one entitled \\"The World Is Too Much With Me\\" by Alan Lightman, which could be summarized as a polemic on everyday life in the twenty-first century. Lightman's viewpoint is purely anecdotal, and he admits this, but he also claims that despite the fact that he \\"cannot document any general conclusions,\\" he asserts that his personal experiences are common to everyone. Life is too fast he complains, and people are feeling a \\"vague fear of not being plugged in\\". People are suffering from an information overload, are too obsessed with material wealth, and transforming themselves into false identities on the Internet, in order to escape an overbearing sense of loneliness. Lightman has lost touch with his \\"inner self\\", by which he means the part of him that imagines and dreams, and is the source of \\"true freedom\\". Lightman wants the human being to always come first, and his nostalgia for the past takes him to the New Atlantis of Bacon, and to the quaintness of Benjamin Franklin.<br />But Lightman does not discuss any alternative views, and does not acknowledge the existence of any who do not think like him. He does not notice the many who feel a sense of exhilaration in the motion of the twenty-first century. The new technologies, the new scientific discoveries, the new tools, the new machines, the new entertainment, the new architecture, and the overabundance of information and knowledge: all of these put these individuals into intellectual and personal hyperdrive. Confident and proud of their humanity, their inner selves are in delightful symbiosis with the moods of the twenty-first century. They welcome change with eager anticipation, and their fingers are crossed that the world of Kurzweil will indeed be realized: a world of machines with IQs measured in the millions; a world full of hundreds of new transgenic animals and plants; a world whose tools, vehicles, and buildings arise from automated molecular manufacturing....and best of all, a world populated by confident, rational human beings (as they always have been).aims that despite the fact that he \\"cannot document any general conclusions,\\" he asserts that his personal experiences are common to everyone. Life is too fast he complains, and people are feeling a \\"vague fear of not being plugged in\\". People are suffering from an information overload, are too obsessed with material wealth, and transforming themselves into false identities on the Internet, in order to escape an overbearing sense of loneliness. Lightman has lost touch with his \\"inner self\\", by which he means the part of him that imagines and dreams, and is the source of \\"true freedom\\". Lightman wants the human being to always come first, and his nostalgia for the past takes him to the New Atlantis of Bacon, and to the quaintness of Benjamin Franklin. <br />But Lightman does not discuss any alternative views, and does not acknowledge the existence of any who do not think like him. He does not notice the many who feel a sense of exhilaration in the motion of the twenty-first century. The new technologies, the new scientific discoveries, the new tools, the new machines, the new entertainment, the new architecture, and the overabundance of information and knowledge: all of these put these individuals into intellectual and personal hyperdrive. Confident and proud of their humanity, their inner selves are in delightful symbiosis with the moods of the twenty-first century. They welcome change with eager anticipation, and their fingers are crossed that the world of Kurzweil will indeed be realized: a world of machines with IQs measured in the millions; a world full of hundreds of new transgenic animals and plants; a world whose tools, vehicles, and buildings arise from automated molecular manufacturing....and best of all, a world populated by confident, rational human beings (as they always have been).	2004-02-08
798467:US	50702879	R1LAKKYFQ72TSS	0262182068	678632050	Machine Musicianship	Books	5	21	23	N	Y	The beginnings of the machine musicians.	The author introduces this book as \\"exploration of the theoretical foundations of analyzing, performing, and composing music with computers\\". The book is exceptional in quality of writing and is fascinating to read. The fact that machines are actually composing music that is enjoyable to listen to as well as non-trivial from the judgment of professional musicians has to rank as one of the most fascinating achievements in music theory and artificial intelligence. Readers of this book will require a fair amount of background in music theory, some knowledge of mathematics (the fast Fourier transform is used in some parts of the book), some knowledge of various algorithms in artificial intelligence, such as neural networks and genetic algorithms, and knowledge of the C++ programming language. There is a CD-ROM that accompanies the book, and which contains a library of C++ objects that can be used to build interactive programs. The author emphasizes though the reader does not have to become a C++ programmer in order to follow the text. In addition, he is concerned with the ability and occurrence of machine musicians, and not in the question as to whether or not the methods they use can emulate human music cognition.<br /> In chapter 1 the author introduces techniques necessary for the analysis of algorithms and composition, and for studying pitch-specific processes such as chord classification and key induction. The author restricts himself to what he calls \\"symbolic processes\\" in this chapter, and these he defines as those that are best characterized as a system of representations and rules. The symbols are taken to represent features of the musical context and their relationships are inferred by algorithms based on the knowledge of the objects they represent in real music. A context-independent chord classifier is first developed and then the author gradually introduces elements of context dependence with the goal of showing how these elements improve performance. The author also addresses issues with music representation, such as MIDI, and some possible successors to it. A key induction algorithm based on parallel processing is discussed in some detail. This algorithm takes knowledge about scales and chord functions and then updates saliency ratings for major and minor tonalities.<br />  In chapter 2, the author deals with \\"sub-symbolic\\" processes, which he characterizes as processes that utilize the regularities learned from prior inputs in order to characterize and predict future inputs. He could have designated these as \\"connectionist\\" algorithms, since they learn their behavior from being exposed to material, do not depend on fixed rules, and are usually implemented using neural networks. Neural networks are used to do key induction, and the author discusses a connectionist approach to perform quantization, and a modification of it for use in real time. He also discusses various techniques for doing \\"beat tracking\\", i.e. the process of finding a regular pulse in a sequence of events, remarking that such an ability is very difficult to accomplish in a machine. Also discussed are some algorithms for performing meter induction.<br />  The author turns his attention to pattern recognition and segmentation of music in chapter 4. The discussion of grouping preference rules leads the author to a real-time segmenter, whose rules are grouped according to the quantity of information that is required to apply them. The author discusses the problems with doing real-time segmentation. A dynamic programming approach to pattern matching is outlined, one using a \\"rating matrix\\", and the author points out that the difficulty in doing pattern matching does not lie in the matching algorithm, but rather in the preparation of the patterns needed by the algorithm. The \\"absolute\\" representation of the pitch used in this algorithm is then replaced by the \\"intervallic\\" representation in order to adhere to what is known from human music cognition. The author then compares his pattern matching algorithms with what has been done in the literature. All of this discussion is fascinating, particularly the discussion of Kohonen self-organizing neural nets that learn to cluster inputs into categories via competitive learning.<br />  Then, in chapter 5, the author begins a discussion of the techniques that machines use to do musical composition. All of the algorithms used by these machines are interactive, in that they change their behavior in response to external inputs. Many different techniques are overviewed, such as generation techniques, which the author is well known for, Also discussed are score following, a pattern matching technique that can trace the progress of live performers through their compositions they are playing, and algorithmic signal processing. Detailed diagrams are given for illustrating the different algorithms.<br /><br />  This is followed in chapter 6 by a review of proposals for algorithmic performance and expression, emphasizing the role in particular of research done in music cognition. The author is careful in pointing out that he remains neutral concerning the question of whether a program is capable of musical cognition similar to what humans do. In addition, he gives two reasons why the experimental data from music cognition is not the standard of verification for the algorithms given in the book. Clearly the author is leaning towards the view, and I believe correctly so, that machine intelligence, even in contexts outside of music, may be in many ways very different from human intelligence. Machines will compose and produce music using techniques that may be very different from what humans use, just as machines play chess in ways that are very different from what humans do. Expert systems are discussed as a tool for algorithmic composition, and the author addresses issues of knowledge representation, with detailed emphasis on schemata for this purpose. Particularly interesting is the fact, as the author points out, that most interactive music systems do not learn, but the author discusses various methodologies that are attempting to incorporate learning into machine musicianship, such as neural networks and genetic algorithms. The GenJam machine of John Biles for doing jazz improvisation is a very interesting example of the latter.<br />  I did not read chapters 7 or 8 so I will omit their review.cognition. The author then compares his pattern matching algorithms with what has been done in the literature. All of this discussion is fascinating, particularly the discussion of Kohonen self-organizing neural nets that learn to cluster inputs into categories via competitive learning. <br />         Then, in chapter 5, the author begins a discussion of the techniques that machines use to do musical composition. All of the algorithms used by these machines are interactive, in that they change their behavior in response to external inputs. Many different techniques are overviewed, such as generation techniques, which the author is well known for, Also discussed are score following, a pattern matching technique that can trace the progress of live performers through their compositions they are playing, and algorithmic signal processing. Detailed diagrams are given for illustrating the different algorithms. <BR> <BR>       This is followed in chapter 6 by a review of proposals for algorithmic performance and expression, emphasizing the role in particular of research done in music cognition. The author is careful in pointing out that he remains neutral concerning the question of whether a program is capable of musical cognition similar to what humans do. In addition, he gives two reasons why the experimental data from music cognition is not the standard of verification for the algorithms given in the book. Clearly the author is leaning towards the view, and I believe correctly so, that machine intelligence, even in contexts outside of music, may be in many ways very different from human intelligence. Machines will compose and produce music using techniques that may be very different from what humans use, just as machines play chess in ways that are very different from what humans do. Expert systems are discussed as a tool for algorithmic composition, and the author addresses issues of knowledge representation, with detailed emphasis on schemata for this purpose. Particularly interesting is the fact, as the author points out, that most interactive music systems do not learn, but the author discusses various methodologies that are attempting to incorporate learning into machine musicianship, such as neural networks and genetic algorithms. The GenJam machine of John Biles for doing jazz improvisation is a very interesting example of the latter.<br />        I did not read chapters 7 or 8 so I will omit their review.	2004-02-04
801892:US	50702879	RY5PBN2TVK2IG	1589490045	794916265	Automated Reasoning With Otter	Books	4	0	0	N	Y	A prelude to fully automated mathematics.	Can one take any theorem or conjecture in mathematics and translate it into the language of OTTER in order to either prove the theorem or verify or disprove the conjecture? Unfortunately, the answer is no, as the translation of most of the statements of mathematics into the clause form required by OTTER will take a lot more research to bring it into fruition. The success of such research would be signal a major breakthrough in automated reasoning or automated theorem proving, as one could engage machines in the generation of new mathematical results and the settling of outstanding conjectures.<br /> A variant of OTTER, called EQP, resolved the &quot;Robbins conjecture&quot; in 1997, via the efforst of the mathematician/computer scientist William McCune. First studied in 1933 by Herbert Robbins, the conjecture asserts that every Robbins algebra is Boolean. The proof took 8 days to complete and made international headlines. The success of this proof motivated many to look more deeply into OTTER, and since it is in the public domain, anyone curious about it can obtain it and use it. This book gives a comprehensive and very understandable overview of OTTER, and can be read by anyone with a background in mathematical logic. Some knowledge of logic and functional programming will help too. In relation to OTTER, one goal worth pursuing is to find out to what extent various fields of mathematics can be translated into the (clausal) language of OTTER. Point-set, geometric, and algebraic topology come to mind, as well as algebraic geometry in the guise of schemes and functors of points. Some automated proofs have been found in topology and algebraic geometry. It remains to be seen whether most, if not all the concepts in these fields can be expressed in a language that will enable automated proofs to be given.<br /> OTTER is an ancronym for Organized Techniques for Theorem Proving and Effective Research&quot;, and after a forward to the book by Larry Wos, the author gives an introduction to the language in chapter 1. His concern is with applied logic and not theoretical developments, so the presentation is informal, and therefore useful to those who are anxious to learn OTTER and apply it. Theoretical developments are not completely ignored though, and throughout the book one can see to what extent expressions can be regarded as clauses and then translated into the language of OTTER.n introduction to the language in chapter 1. His concern is with applied logic and not theoretical developments, so the presentation is informal, and therefore useful to those who are anxious to learn OTTER and apply it. Theoretical developments are not completely ignored though, and throughout the book one can see to what extent expressions can be regarded as clauses and then translated into the language of OTTER.	2004-02-02
803872:US	50702879	R69HTVG2WGJ5R	1840464631	477764901	Introducing Artificial Intelligence	Books	5	17	18	N	Y	An excellent introduction.	This book would be an excellent choice for anyone who has no background in artificial intelligence (AI) and wants to understand what the subject is all about. In particular, the book would be ideal for a high school senior who is college bound and is considering computer science as a possible major. But anyone who has an interest in artificial intelligence can gain much from a perusal of this book. Research and applications of artificial intelligence are skyrocketing, and there are many areas in the subject that were unheard of ten years ago. The book discusses some of these new developments, and also the philosophical argumentation that usually accompanies discussion of AI. If the book makes a young person decide to go into the field of artificial intelligence, it has done its job, and this person will join an army of individuals who are deeply passionate about their profession and are very optimistic about its future.	2004-01-31
809622:US	50702879	RJDVIWMHBFZ72	0262112647	539325715	Strategic Negotiation in Multiagent Environments (Intelligent Robotics and Autonomous Agents)	Books	4	2	2	N	Y	A prelude to automated negotiation	The automation of trading and negotiation is becoming more important with each passing year in the twenty-first century. The New York Stock Exchange, the Chicago Board of Trade, NASDAQ, and Web-based businesses like Amazon and Ebay are facing pressure to automate not only their purchasing, but also their abilities to negotiate business deals on part of their customers. In addition, recently issues with electricity and bandwidth marketing will entail a reliable and efficient method of automated bargaining in order to ensure reliable electrical grids and efficient bandwidth allocations. The automation in all of these areas will need to be trustworthy, efficient, and profitable for both the customer and the company if it is to be a viable part of business life.<br /> This book outlines a mathematical theory of negotiation, and combines concepts from game theory, mathematical economics, and artificial intelligence in order to build strategic negotiation models, and discusses their empirical validation. The author bases her model on the Rubenstein model of alternating offers, wherein intelligent agents exchange offers until they reach an agreement or until one of them opts out of the negotiations. She concentrates specifically on the abilities of intelligent agents to coordinate their activities with other agents and to cooperate with them. These agents are assumed to be self-interested, rational, and autonomous. They do not share a common goal and each has its own set of preferences and acts according to them. Because of space constraints, only the first four chapters will be reviewed here.<br /> In the introduction to the book, the author reviews some of the basic concepts from game theory, such as the extensive and strategic representations of a game. The coalitional representation is left to the references. Then, in chapter 2, she discusses in some detail the Rubenstein model of alternating offers, wherein there are N agents the need to reach an agreement on a particular issue, and the agents can only take actions at certain times determined in advance and known to the agents. There is no decision-regret, and the agents are provided with utility functions. The goal is then to find simple strategies that could be recommended to all agents so that no agent could benefit by an alternate strategy.<br /> The author turns to negotiations about data allocation in chapter 3, where servers are autonomous and self-interested, can share documents, and need to make decisions where to locate data available to them. She assumes that the agents prefer any agreement in a given time period over the continuation of the negotiation process indefinitely, assumes losses of unused information, and only considers utility functions with fixed losses per unit time and a discount rate constant in time. The negotiation process is considered in cases of complete information, in which the servers know the expected usage of each dataset, but not the future usage, and in cases of incomplete information, where the expected usage is not, but only the past usage. Recognizing that the allocation problem is NP-complete in these cases, she brings in various techniques from optimization theory and artificial intelligence to deal with it. Simulations using hill-climbing, are shown to give better results than backtracking or genetic algorithms. She also gives a literature survey on distributed file allocation and with various other techniques for the incomplete information case.<br /> In chapter 4, the author discusses bilateral negotiations for resources. In this scenario, one agent has access to a resource and is using it during the negotiation process, while another agent is waiting to use the resource. Cases of both complete and incomplete information are treated, along with cases of multiple encounters. The case of resource allocation is different than that of data allocation in that in resource allocation each agent always prefers a larger portion of the resource. Also, one of the agents loses over time while the other gains in resource allocation. The author discusses an interesting example dealing with the sharing of resources between NASA and ESA, and which illustrates the theorem that an agreement will be reached in the first or second period. This result is also different from the data allocation case, where in the latter, agreement is always reached in the first time period. The case of incomplete information is studied using the notion of \\"sequential equilibrium.\\" This requires that an agent's strategy in each time period will be optimal given its opponents' strategies and its beliefs, and the history up the given time period. Three conditions are imposed on the sequence of strategies and the agent's system of beliefs that serve to characterize sequential equilibrium. The author again compares this with the data allocation, and concludes that for resource allocation with incomplete information, there is less incentive for telling the truth. The author then addresses the situation where the agents can meet several times in order to carry out the negotiation. She points out the use of \\"pooling\\" and \\"separating\\" equilibria in analyzing the situations of multiple encounters. An agent can have different utility functions, giving the agents different \\"types\\". If all these types select the same strategy in all states, this is a pooling equilibrium. If it is not, it is a separating equilibrium, and then it is possible to identify the agent's type from its actions. It is shown, as expected, that the negotiations in the multiple encounter case end no later than the second time period. Here again, the author uses the NASA and ESA robot examples to illustrate the results she derives for multiple encounters. She also shows the results of simulations to validate the agent's performance in situations of multiple encounters. Brief discussion is devoted to extensions of this model, including two agents with more than two encounters, multiple resources, and cases where there are more than two types of agents. For the case of many resources, the author concludes that the agent holding the resource will not stop negotiating with one agent and initiate a new negotiation process with another agent for a different resource. Other approaches to the resource allocation problem follow.source. Also, one of the agents loses over time while the other gains in resource allocation. The author discusses an interesting example dealing with the sharing of resources between NASA and ESA, and which illustrates the theorem that an agreement will be reached in the first or second period. This result is also different from the data allocation case, where in the latter, agreement is always reached in the first time period. The case of incomplete information is studied using the notion of \\"sequential equilibrium.\\" This requires that an agent's strategy in each time period will be optimal given its opponents' strategies and its beliefs, and the history up the given time period. Three conditions are imposed on the sequence of strategies and the agent's system of beliefs that serve to characterize sequential equilibrium. The author again compares this with the data allocation, and concludes that for resource allocation with incomplete information, there is less incentive for telling the truth. The author then addresses the situation where the agents can meet several times in order to carry out the negotiation. She points out the use of \\"pooling\\" and \\"separating\\" equilibria in analyzing the situations of multiple encounters. An agent can have different utility functions, giving the agents different \\"types\\". If all these types select the same strategy in all states, this is a pooling equilibrium. If it is not, it is a separating equilibrium, and then it is possible to identify the agent's type from its actions. It is shown, as expected, that the negotiations in the multiple encounter case end no later than the second time period. Here again, the author uses the NASA and ESA robot examples to illustrate the results she derives for multiple encounters. She also shows the results of simulations to validate the agent's performance in situations of multiple encounters. Brief discussion is devoted to extensions of this model, including two agents with more than two encounters, multiple resources, and cases where there are more than two types of agents. For the case of many resources, the author concludes that the agent holding the resource will not stop negotiating with one agent and initiate a new negotiation process with another agent for a different resource. Other approaches to the resource allocation problem follow.	2004-01-27
812956:US	50702879	R2RTZ1PUNB40WE	3540443843	211675775	Web Intelligence	Books	4	5	6	N	Y	An introduction to the rise of the smart Web.	Consisting of 19 survey papers by various authors, this book attempts to overview research into what the editors have called &quot;Web Intelligence&quot;. All of the topics included in the book are interesting, and very important in both academia and industry as the World Wide Web continues to evolve into a more powerful research tool and Ecommerce engine. Due to space constraints, only the first eight articles will be reviewed here.<br /> After an introductory article on what will be emphasized in the book, the next article deals with how to interpret strong regularities in Web data in terms of user decision-making patterns, and then to describe an agent-based approach to the characterization of user behavior. This article stands out from the others in that it endeavors to be quantitative. For example, heavy-tailed probability distributions are used to model regularities in Web data, and the authors construct an artificial Web space that includes information foraging agents living in it. The authors then compare their model with real-world data, obtaining fairly good agreement.<br /> In the third article, the authors overview the work on DAML-S,  a version of the DARPA Agent Markup Language, and which is one of the attempts to create a &quot;semantic Web&quot;. The goal of the semantic Web is in their view is to construct reusable, high-level, generic procedures that can be customized for individual use, and also, and most importantly to be able to reason about the content that is the result of Web queries. The authors describe the 3 different conceptual areas of DAML-S, and the 3 different processes making it up. They also discuss the advantages in using agent-oriented software engineering in Web services. The emphasize strongly that the semantic Web should not be merely a knowledge repository, but should exhibit behavorial intelligence.<br /> The authors of the fourth article discuss the design and use of social agents in Web applications. Using Scheme, they have developed a language they call Q, to develop interaction scenarios between agents and users. I cannot speak to the efficacy of Q in building avatars and other agents since I have never used it, but the authors assert that it can execute hundreds of scenarios simultaneously, and allows for autonomous agents.<br /> Web-based education was one of the first uses of the Web, and in chapter 5 the authors show it can be improved via the use of agent technology. Their emphasis is on guidebots, which are animated agents or avatars that interact with learners via a combination of speech and gestures. They also describe the Advanced Distance Education (ADE) architecture for Web-based instruction, and discuss a medical application. Most interesting is their use of Bayesian networks in their construction of guidebots.<br /> The acquisition of business intelligence is discussed in chapter 6. The very difficult notion of &quot;interestingness&quot; whose definition plagues most research in artificial intelligence, is addressed in the context of relevant business information on the WWW. The authors discuss a system, coded in C++ and  based on vector space representations and association rule mining, that will gather information on companies for eventual comparisons to be made between them. Five methods are used to compare a user site to a competitor site, and the time complexity of each is discussed.<br /> Chapter 7 overviews a technique for mining (negative) association patterns in Web usage data, called &quot;indirect association&quot;.  In this technique, one finds pairs of pages negatively correlated with each other, but that are accessed together via a common set of pages called the &quot;mediator&quot;. Indirect association is supposed to give information on the interests of Web users who share common traversal paths, in order for example to target users for marketing. Crucial in the definition of indirect association is a measure for dependence between itemsets, and the authors discuss a few of these measures. Sequential indirect associations are defined, and the authors discuss three types of these: Convergence, which represents the different ways of entering a frequent sequence; Divergence, which illustrates how the interest of Web users being to diverge from the frequent sequence; and Transitivity, which illustrates how users can enter the frequent sequence through a particular page rarely go to another. The psuedocode for the \\"INDIRECT\\" algorithm is given, and the authors describe two methods to reduce the number of discovered patterns by combining indirect associations. The authors then describe how they validated their algorithm by testing it on Web server logs from a university site and an online Web store. They conclude from these tests that indirect associations are helpful in the identification of different groups of Web users who share a similar traversal path.<br /> The next chapter deals with some of the issues that are involved in the extraction of information from the Web, with emphasis on automatic extraction methods that use wrapper induction. A wrapper is a procedure that understands information taken from a source and translates it into a form that is then used to extract particular \\"features\\". The trick is to design a wrapper that is intelligent enough to work for many different sources made up of different presentation formats. The authors classify wrappers into manual, heuristic wrapper induction, and knowledge-based wrapper induction. After arguing that manual and heuristic wrapper induction are unsuitable for efficient and intelligent information extraction, they then concentrate attention on a knowledge-based wrapper induction, wherein wrappers are built automatically. Their implementation is called XTROS, written in Java, which does wrapper generation by first converting HTML sources into logical lines, then determining the meaning of logical lines, and then finding the most frequent pattern. The wrapper is then formatted in XML, and the information is then extracted by the interpreter of XTROS, which parses the XML wrapper to build extraction rules and then applies these rules to the search results. The authors describe their performance evaluation of XTROS using a precision and recall measure. The authors remark that XTROS is limited in that it only works for labeled documents, and point to the need for constructing a wrapper learning agent for multidomain environments.he authors discuss a few of these measures. Sequential indirect associations are defined, and the authors discuss three types of these: Convergence, which represents the different ways of entering a frequent sequence; Divergence, which illustrates how the interest of Web users being to diverge from the frequent sequence; and Transitivity, which illustrates how users can enter the frequent sequence through a particular page rarely go to another. The psuedocode for the \\"INDIRECT\\" algorithm is given, and the authors describe two methods to reduce the number of discovered patterns by combining indirect associations. The authors then describe how they validated their algorithm by testing it on Web server logs from a university site and an online Web store. They conclude from these tests that indirect associations are helpful in the identification of different groups of Web users who share a similar traversal path. <br /> The next chapter deals with some of the issues that are involved in the extraction of information from the Web, with emphasis on automatic extraction methods that use wrapper induction. A wrapper is a procedure that understands information taken from a source and translates it into a form that is then used to extract particular \\"features\\". The trick is to design a wrapper that is intelligent enough to work for many different sources made up of different presentation formats. The authors classify wrappers into manual, heuristic wrapper induction, and knowledge-based wrapper induction. After arguing that manual and heuristic wrapper induction are unsuitable for efficient and intelligent information extraction, they then concentrate attention on a knowledge-based wrapper induction, wherein wrappers are built automatically. Their implementation is called XTROS, written in Java, which does wrapper generation by first converting HTML sources into logical lines, then determining the meaning of logical lines, and then finding the most frequent pattern. The wrapper is then formatted in XML, and the information is then extracted by the interpreter of XTROS, which parses the XML wrapper to build extraction rules and then applies these rules to the search results. The authors describe their performance evaluation of XTROS using a precision and recall measure. The authors remark that XTROS is limited in that it only works for labeled documents, and point to the need for constructing a wrapper learning agent for multidomain environments.	2004-01-24
813711:US	50702879	R1FDZNQDCMX37V	1587991101	933193235	Digital Dealing: How E-markets are Transforming the Economy	Books	4	2	2	N	Y	A prelude to online, automated, intelligent eCommerce.	In spite of predictions of doom by some, eCommerce is here to stay, and in fact will evolve into something that might be called &quot;eDealing&quot; or &quot;eNegotiation&quot;. Whatever it is called, the ability to negotiate deals real-time on the Web is something that is coming fast, and will be driven by the need for transparency and efficiency in this kind of deal-making. The author has given an interesting but elementary account of what he has named \\"digital dealing\\", which could be read by anyone who is interested in this type of technology. All of the current financial institutions will eventually have to face up to the presence of e-markets in the months and years ahead. Due to space constraints, only the first four chapters will be reviewed here.<br /> In chapter 1 of the book the author gives an overview of the nature of e-markets, and the phenomenon of &quot;dickering&quot; (bargaining or haggling) for the best price. Successful e-markets in his view must support automated versions of dickering, and engage in deal-making despite the desire to hide the 'best price'. The author gives four steps that he believes will ensure a successful e-commerce system: the identification of potential trading partners, followed by the transmission and reception of trading interest and dickering with potential partners, the actual carrying out the deal, and lastly the providing of the information about the deal to other traders. He also lists, and then discusses what he believes are the most effective e-market models: eBay, OffRoad, FreeMarkets, Nasdaq, Priceline, and Grainger. The author also discusses the need for transparency in terms of three categories, namely the identity of traders, the terms of the bids, and the terms of the deal. The author does not overemphasize the role of e-markets, and clearly many firms still using traditional business practices are feeling threatened by them. No doubt they will have to adapt to the organized, efficient, and rational nature of e-markets.<br /> Chapter 2 overviews the &quot;deal engines&quot; that can do auctions, with the first example the author studying being the English auction, which is deployed by sites such as eBay, and which the author claims is the predominant form of auctioneering on the Internet. What is interesting about the eBay auction process, as pointed out by the author, is that it uses &quot;proxy bidding&quot;, which does not require a bidder to be logged on in the bidding process. This automation of the bidding process will be even more powerful when it is extended to more elaborate financial transactions. The author also discusses the trade-offs involved in transparency during the bidding process. First-price and second-price sealed-bid auctions are also discussed, and the author compares these three different types of auctions according to their advantages for bidder and seller. The author also explains the use of the activity rule in making auctions more transparent. Even more importantly, the author discusses two-sided auctions, which are used in electricity auctions for example, and the various auction abuses that can occur.<br /> In chapter 3, the author discusses various auction mechanisms that are in place for stocks and bonds. Treasury auctions are discussed first, the author pointing out the reason for such a thin tick in such auctions, namely that there is not a wide variation in the estimation of the price of Treasury bills by investors. The author discusses municipal bonds next, emphasizing the advantages of getting into the auction in the last minute. Due to their relatively new arrival in e-auctions, corporate bond auctions are discussed only briefly via the OpenBook auction house of W.R. Hambrecht, which the reader can get more information on if needed on the Web. This is followed by a very interesting discussion on auctions for private equity, with OffRoad Capital furnishing an example of selling private equity via a semi-open-book single-price auction. The author points out the similarity with mutual funds when investing in OffRoad, and discusses the three phases that OffRoad uses for selling a new issue of private equity. The author ends the chapter with discussions of the W.R. Hambrecht IPO auction and auctions for traded stock.<br /> The author overviews, in chapter 4, the role of B-to-B procurement auctions in eMarkets, asserting that automated dickering is a playing a larger role in a business that is now at $100, 000, 000, 000, 000 worldwide. One of the downsides though for e-markets he says is that cooperation between buyer and seller will be difficult because of the standardization in the bid process. The negotiation that must occur when custom-made capital equipment is involved cannot be done easily in e-markets he claims. He is certainly correct if gauged by current standards, but online negotiation is now an intense area of research, and there are many new approaches that allow real-time negotiation online that will fill the requirements that the author discusses. FreeMarkets.com is discussed at the most successful of the online industrial procurement engines. The global supply management function of FreeMarkets has been profitable so far, the author argues, but its biggest problem is that one could use its platform to seek bids to replace its services. These services, according to the author, could become a commodity, with its price set to low levels via the capabilities that FreeMarkets has allowed the clients to use. The author contrasts FreeMarkets with Perfect.com, the latter of which provides software, called PerfectMarket, to actually serve as consultants for online virtual auctions. Suppliers are asked to formulate bidding strategies illustrating how they would respond to what is occurring during an auction. This procurement strategy can be refined by running auctions several times, and the bidding rules are kept secret by Perfect Market, which then effectively acts like a trusted third party. The author remarks that Perfect Market is the only auction system to use the second-price Vickrey principle where bids include more than one price. It is the opinion of this reviewer that online auctioneering will become even more sophisticated in the years ahead, due mainly to advances in machine intelligence.on. The author points out the similarity with mutual funds when investing in OffRoad, and discusses the three phases that OffRoad uses for selling a new issue of private equity. The author ends the chapter with discussions of the W.R. Hambrecht IPO auction and auctions for traded stock. <br /> The author overviews, in chapter 4, the role of B-to-B procurement auctions in eMarkets, asserting that automated dickering is a playing a larger role in a business that is now at $100, 000, 000, 000, 000 worldwide. One of the downsides though for e-markets he says is that cooperation between buyer and seller will be difficult because of the standardization in the bid process. The negotiation that must occur when custom-made capital equipment is involved cannot be done easily in e-markets he claims. He is certainly correct if gauged by current standards, but online negotiation is now an intense area of research, and there are many new approaches that allow real-time negotiation online that will fill the requirements that the author discusses. FreeMarkets.com is discussed at the most successful of the online industrial procurement engines. The global supply management function of FreeMarkets has been profitable so far, the author argues, but its biggest problem is that one could use its platform to seek bids to replace its services. These services, according to the author, could become a commodity, with its price set to low levels via the capabilities that FreeMarkets has allowed the clients to use. The author contrasts FreeMarkets with Perfect.com, the latter of which provides software, called PerfectMarket, to actually serve as consultants for online virtual auctions. Suppliers are asked to formulate bidding strategies illustrating how they would respond to what is occurring during an auction. This procurement strategy can be refined by running auctions several times, and the bidding rules are kept secret by Perfect Market, which then effectively acts like a trusted third party. The author remarks that Perfect Market is the only auction system to use the second-price Vickrey principle where bids include more than one price. It is the opinion of this reviewer that online auctioneering will become even more sophisticated in the years ahead, due mainly to advances in machine intelligence.	2004-01-24
820782:US	50702879	R10AS6U9Y27CGG	0521575451	821205754	Abductive Inference: Computation, Philosophy, Technology	Books	4	15	15	N	Y	Very useful.	Abductive reasoning is no longer just a curious branch of mathematical logic that is of interest only in the academic environment. It now has applications in medical diagnostics, network event correlation, and legal reasoning.  All of these applications are considered to be part of the rapidly growing trend to incorporate artificial intelligence into the business, medical, and legal environments. Defined as inference to the best explanation, abduction is discussed in detail in this book via a collection of articles written by different specialists in the field. It should serve well those readers who are approaching the subject for the first time, or those familiar with it but want to gain more insight into it for possible application. All readers should be aware though of the qualitative approach taken in the book, i.e. the formal development of abductive reasoning in the context of mathematical logic is not present. All of the articles in this book are interesting, but due to space constraints, only the first two articles in the book will be reviewed here.<br /><br /> In the first article, abduction is defined as a form of inference that starts with data that describes something and formulates a hypothesis that gives the best explanation of the data. The term abduction is credited to the philosopher/logician Charles Sanders Peirce, and has been described by the author \\"modus ponens\\" turned backward. The author gives examples of abductive reasoning from everyday life and science, and he is careful to note that problems with combinatorial explosion that results from generating all possible explanations, and so he takes abduction to include generation, criticism, and possible acceptance of explanatory hypotheses. Abductions are described as \\"ampliative\\" inferences, in that there is an increase in information after accepting a best explanation, i.e. successful abductions are \\"truth producing\\". This is actually a very controversial claim, since it is claiming that the abductive process is creative. This is not surprising from a human reasoning point of view, since humans clearly exhibit creativity. But from the standpoint of artificial intelligence, this would mean that an implementation of abductive reasoning in a machine would automatically entail an implementation of creativity, and this claim is currently hotly debated.<br /><br /> The next article discusses abductive reasoning in the context of the most popular knowledge-based systems. The authors address the current status of AI as being one that is fragmented into several competing paradigms, and point to the strong disagreements on how to quantify progress in AI. They argue for the need for AI to continue as a pluralistic enterprise with opposing viewpoints and ideas, and list four different ways in which AI has viewed the idea of a program. One of these views is the \\"strong AI\\" viewpoint, which has sometimes dominated the popular view of AI, and the authors argue correctly that whether or not machines can have humanlike cognitive states is completely irrelevant to the use of AI technology. This they call \\"AI as design science\\" which attempts to view intelligent agents in the abstract, with humans being one set, and silicon-based machines another. This view of AI is the one that is the most effective from the standpoint of business and industrial applications, and this is due to its insistence on practical application and the consequent minimization of philosophical debate, the latter of which one can argue has crippled progress in AI, or at least delayed it considerably. The goal of the design paradigm for AI, as they authors explain it, is to find the general principles of computation and information processing that subsume the human case. After all, they argue, human thinking is of a \\"black box\\" nature, as we currently understand it (our understanding though increasing dramatically with every passing day). The reasoning systems used by machines can be studied, understood, and altered as we please, and in fact could teach humans how to reason better.<br /><br />They also discuss the differences between the symbolic and connectionist approaches to AI, arguing that both of these should be subsumed into a more abstract level of description, called the \\"information-processing\\" level. The input, output, and types of information processing are viewed as the \\"top-level\\" content for constructing theories of AI, two of these being the symbolic and connectionist viewpoints. The authors clearly believe that the logical tradition in AI has caused difficulties, in that it has separated knowledge from its functions, and this leads to the omission of important aspects in knowledge representation. This motivated the \\"frame approach\\" to knowledge representation, and the authors discuss three different reasons for using this representation: 1. Its utility and efficiency in organizing knowledge about classes of objects. 2. The ability to create type-subtype hierarchies. 3. The possibility of embedding procedures in frames to allow inferencing. Object-oriented programming is mentioned as sharing much in common with the frame approach. The authors then finally discuss applications, such as diagnostic reasoning, which from a commercial standpoint has proven to be a very useful application of abductive reasoning. The computational complexity of the diagnostic problem is pointed out, illustrating the need for heuristics in the obtaining of a solution in a reasonable time frame.<br /><br />Most interesting in this discussion is that the authors ask what kind of intelligence is needed to perform diagnostic reasoning. They make a connection here with some current research that attempts to define intelligence independent of what is done in the human case. The answer of how diagnosis is to be done needs to be answered in the context of \\"generic mental structures.\\" A different mental structure will give a different answer, they argue. In the authors view, diagnostic reasoning may involve \\"malfunction hierarchies\\", \\"rule-out\\" strategies, etc, and so one needs approaches that directly address the higher level issues of knowledge-based reasoning. As a science of intelligence therefore, the task of artificial intelligence should be to identify concretely the strategies for processing information and their coherence.as we please, and in fact could teach humans how to reason better.     They also discuss the differences between the symbolic and connectionist approaches to AI, arguing that both of these should be subsumed into a more abstract level of description, called the \\"information-processing\\" level. The input, output, and types of information processing are viewed as the \\"top-level\\" content for constructing theories of AI, two of these being the symbolic and connectionist viewpoints. The authors clearly believe that the logical tradition in AI has caused difficulties, in that it has separated knowledge from its functions, and this leads to the omission of important aspects in knowledge representation. This motivated the \\"frame approach\\" to knowledge representation, and the authors discuss three different reasons for using this representation: 1. Its utility and efficiency in organizing knowledge about classes of objects. 2. The ability to create type-subtype hierarchies. 3. The possibility of embedding procedures in frames to allow inferencing. Object-oriented programming is mentioned as sharing much in common with the frame approach. The authors then finally discuss applications, such as diagnostic reasoning, which from a commercial standpoint has proven to be a very useful application of abductive reasoning. The computational complexity of the diagnostic problem is pointed out, illustrating the need for heuristics in the obtaining of a solution in a reasonable time frame.     Most interesting in this discussion is that the authors ask what kind of intelligence is needed to perform diagnostic reasoning. They make a connection here with some current research that attempts to define intelligence independent of what is done in the human case. The answer of how diagnosis is to be done needs to be answered in the context of \\"generic mental structures.\\" A different mental structure will give a different answer, they argue. In the authors view, diagnostic reasoning may involve\\"malfunction hierarchies\\", \\"rule-out\\" strategies, etc, and so one needs approaches that directly address the higher level issues of knowledge-based reasoning. As a science of intelligence therefore, the task of artificial intelligence should be to identify concretely the strategies for processing information and their coherence.	2004-01-19
822081:US	50702879	RM03OR4GYSJ8Q	0883851059	625050501	Studies in Modern Topology	Books	4	3	3	N	N	Very out of date, but still a good source of intuition.	One of the things that stands out the most with older books in mathematics is that they emphasize the underlying ideas behind the concepts. They do this via pictures and lots of explanation using ordinary language, but they do eventually make their arguments mathematically rigorous. This is to be contrasted with modern texts, which usually approach a subject from a strictly formal point of view. This is fine from the standpoint of mathematical rigor, but students entering the field may have difficulty absorbing the underlying ideas behind the proofs and definitions. This is especially true for the physics community which must quickly master highly abstract ideas in order to use them in applications.<br /> This book was published in 1968, and therefore is out of date considering the developments that have taken place in the areas discussed in the book since then. But the authors of the articles in the book explain things in a way that could be helpful to those who want a more in-depth understanding of various concepts in topology. The editor of the book gives an overview of the status of topology at that time and the articles that appear in the book. Much of the discussion revolves around geometric and algebraic topology, especially work that resulted from attempts to resolve the 3-dimensional Poincare conjecture. This conjecture in 5 dimensions or above, called the generalized Poincare conjecture, was solved by Stephen Smale some years earlier. The 3- and 4-dimensional Poincare conjecture was still open at the time of publication, but he latter was resolved by Michael Freedman just a few years later.<br /> The 1960's was an exciting decade for topology, due not only to Smale's proof but also to many of the other fascinating results that were taking place at the time. Milnors work on exotic spheres stands out in particular, and even more so due to the later work of Simon Donaldson on exotic differentiable structures in 4-dimensional Euclidean space. Differential topology, which started in the 1950's with the cobordism theory of Rene Thom, was a relatively new branch of topology, but is now very important not only in mathematics but in physical applications. Cobordism theory is discussed in the book in the article by Valentin Poenaru, wherein he brings in the notion of a Thom space of a vector bundle, which can be thought of as a generalization of the one-point compactification of a non-compact topological space (and indeed is just that when the base space of the vector bundle is compact).<br /> The 3-dimensional Poincare conjecture, which drove much of the research discussed in this book, is still open as of the date of this review. Three-dimensional topology is still a very active subject, and many fascinating tools, some of them finding inspiration from physics, such as gauge theories, have been applied to studying it. It is this opinion of this reviewer that the resolution of the 3-dimensional Poincare conjecture lies in these tools from physics, the biggest challenge being to make them mathematically rigorous.pology, which started in the 1950's with the cobordism theory of Rene Thom, was a relatively new branch of topology, but is now very important not only in mathematics but in physical applications. Cobordism theory is discussed in the book in the article by Valentin Poenaru, wherein he brings in the notion of a Thom space of a vector bundle, which can be thought of as a generalization of the one-point compactification of a non-compact topological space (and indeed is just that when the base space of the vector bundle is compact). <br /> The 3-dimensional Poincare conjecture, which drove much of the research discussed in this book, is still open as of the date of this review. Three-dimensional topology is still a very active subject, and many fascinating tools, some of them finding inspiration from physics, such as gauge theories, have been applied to studying it. It is this opinion of this reviewer that the resolution of the 3-dimensional Poincare conjecture lies in these tools from physics, the biggest challenge being to make them mathematically rigorous.	2004-01-18
823101:US	50702879	R2W8SBGJ6BX0HJ	052122523X	876120960	The Forces of Nature	Books	4	5	5	N	N	Good source of intuition	For someone interested in the fundamental physics of the different interactions in nature, but has yet learned the necessary mathematics needed to obtain a complete understanding of it, this book could be a good start. I read it when it first appeared in 1979, and it was a good source of intuition then as it is now. I had just finished taking BS degree in mathematics, and was very interested in becoming more familiar with the quantum field theories of elementary particle physics. A few years later in 1983, while waiting for a class on quantum field theory, the instructor, Ervin Fenyves, arrived to class and with great excitement announced the discovery of the intermediate vector bosons by the CERN team in Geneva. The syllabus for the class was of course not followed that day, but instead Dr. Fenyves explained just what decay signatures indicated the presence of the vector bosons.<br /> It must be remembered that this book was published before the discoveries of the intermediate vector bosons, and therefore it is in this sense out of date. These discoveries, and others after them, such as the discovery of flavor-changing neutrinos, give solid support to current physical theories of the fundamental interactions which the author introduces in this book. Readers needing a more in-depth understanding of fundamental physics will need to learn a lot more physics and mathematics then what can be found in this book. This will take a lot of time and effort, but it is well worth it, since the picture of reality that physics now gives us is fascinating, and guarantees to be even more so in the decade ahead, as experiments are conducted at even higher energies. There are of course many excellent books that are more up-to-date, and readers should consult these as their main source of information, but this one could still be used as an historical introduction and overview of what was known before the intermediate vector boson era.	2004-01-17
826862:US	50702879	R3S7S4XTE8SC8W	0312319142	298733702	Paranoia	Books	4	3	7	N	N	Captures the moods of high-tech corporate America.	The high-tech corporate workplace is now more diverse and competitive than ever, and this is due not only to globalization and outsourcing but to the effects of automation. In addition, memories of the \\"employees market\\" of the 1990's and its demise as the new century began are still very much intact. The wild frontier of the nineties employment situation allowed many, if unsatisfied in their current position, to move  \\"out West\\" to another one in a matter of days. The covered wagons of the 1880's though are replaced by the Accord's, Infiniti's, and BMW's of the 1990's. The sense of independence and confidence felt during this time was probably unequaled in the economic history of the United States.<br /> This all changed of course in the collapse of the tech sector, and with jobs getting more scarce all the time, and layoffs increasing dramatically, companies reminded employees, sometimes very untactfully, that they should be \\"thankful to have a job\\", and that the raises will be \\"significantly less\\" than in preceeding years. Such morale-busting, blunt rhetoric would have never been possible in the roaring 1990's. In addition, for the last fifteen years, due mostly to legal pressures, corporate America has been obliged to integrate (no pun here) \\"diversity\\" into the workplace. Fearing lawsuits, and losing some in a few instances, has caused some human resources departments to take measures that would seem drastic if compared with the preceeding decades. Indeed, some have deployed employees, called \\"change agents\\" , whose function is to monitor behavior and language that some might find offensive. All of this results in a jittery, timid, and paranoid workforce, composed of individuals frightened of losing their jobs, offending their minority co-workers, or afraid of not being able to justify, from a cost-effective point of view, their place in the organization.<br /> It is within this context that this novel definitely qualifies as being literary realism, for the author has captured very accurately the moods of the post-1990's workplace, from the employee cubicle all the way to the CEO's office. The dialog and introspection of Adam Cassidy, the main character, is very familiar. For example, Adam refers to the non-politically correct E-mail message, that, even if done with innocent intention, will, if discovered, result in maybe a week of intense \\"diversity training\\". Such diversity training of course is mandatory now in most of corporate America, Email message or not. The story is also quite blunt in its portrayal of industrial spying in the high-tech corporate environment. Although it is very difficult to prove how much is done, industrial espionage has been a fact of life in corporate America for many decades, as one character in the book enjoys pointing out with boastful clarity. Industrial espionage is of course illegal, and should be, and so alternatives must be found that will allow companies to obtain useful intelligence on their competitors. One of these is called  \\"competitive intelligence\\", a phrase which appears in the book, but not elaborated on in any great detail, and is a software tool whose function is to search for knowledge about a competitor's activities, including their manager and employee interests and movements. It works with varying degrees of success, due to the huge quantity of (public) information which it must deal with, and to the mis-information that is frequently and deliberately put out by firms to mislead their competitors.<br /> Jock Goddard, the CEO of Trion, is the most interesting of the characters in the story. He comes across as a Will Rogers incarnate in the beginning of the story, only to offer surprises as the story develops. Nicholas Wyatt, the CEO of Wyatt Telecom, the \\"one scary dude\\", is a CEO as many people imagine them to be: arrogant, boastful, and intimidating. But most heads of companies are much more tactful than Wyatt, and are masters of tact and prudence. Nora Sommers is theonly misplaced character in the book. The author should have had her in human resources, as her attitude and overbearing behavior are characteristic of some who populate the glass-enclosed offices of HR. All of the characters reflect the semantic discreteness of the author's approach, as they do their jobs in the story with minimal changes of their attitudes and beliefs. This allows the story to move very rapidly, which it does, and the reader stays on edge throughout much of the book.<br /> Adam is the young, typical employee that you meet in high-tech organizations. Intelligent, but not brilliant, and dissatisifed with his job, he nevertheless has a measure of daring about him, as evidenced in his use of company funds to throw a party for a friend. Intimidated by authority, he is easily pressured into becoming a mole in the Trion organization, a situation which he is clearly uncomforable with, and one in which he eventually, because of a small measure of moral courage, attempts to break free from. His life kicks in to overdrive, and a fast car, a fancy apartment, and a beautiful woman to indulge him regularly in the appropriate horizontal configuration result in lack of restful sleep being a constant of nature for him. Adam Cassidy though does manage to get through his tribulations and the extreme paranoia resulting from his association with Wyatt Telecom. However, he then meets his greatest challenge when his \\"girlfriend\\" Alana implores him to \\"just get in the car\\".<br /> He should not get in that car.the only misplaced character in the book. The author should have had her in human resources, as her attitude and overbearing behavior are characteristic of some who populate the glass-enclosed offices of HR. All of the characters reflect the semantic discreteness of the author's approach, as they do their jobs in the story with minimal changes of their attitudes and beliefs. This allows the story to move very rapidly, which it does, and the reader stays on edge throughout much of the book. <br /> Adam is the young, typical employee that you meet in high-tech organizations. Intelligent, but not brilliant, and dissatisifed with his job, he nevertheless has a measure of daring about him, as evidenced in his use of company funds to throw a party for a friend. Intimidated by authority, he is easily pressured into becoming a mole in the Trion organization, a situation which he is clearly uncomforable with, and one in which he eventually, because of a small measure of moral courage, attempts to break free from. His life kicks in to overdrive, and a fast car, a fancy apartment, and a beautiful woman to indulge him regularly in the appropriate horizontal configuration result in lack of restful sleep being a constant of nature for him. Adam Cassidy though does manage to get through his tribulations and the extreme paranoia resulting from his association with Wyatt Telecom. However, he then meets his greatest challenge when his \\"girlfriend\\" Alana implores him to \\"just get in the car\\". <br /> He should not get in that car.	2004-01-14
832012:US	50702879	R2R8NZIYFD6H8P	0520085841	526903755	The Cult of Information: A Neo-Luddite Treatise on High-Tech, Artificial Intelligence, and the True Art of Thinking	Books	2	7	23	N	Y	An exercise in cynicism and sarcasm.	This book is interesting not because of its arguments and philosophy but for the fact that the author attacks all areas that might be construed to make use of information theory. The computer, he claims, has taken the place of the emperor, and he aims to expose it as naked, to speak up and protect the &quot;public&quot; against the misinformation and propanda that is propagated by certain &quot;elements&quot; of our society. All fields of expertise that use the computer, be it financial engineering, simulation and modeling, bioinformatics, and especially artificial intelligence are attacked for their exaggerations and wishful thinking. The author's approach is deeply cynical, full of biting sarcasm, and with only a few exceptions, there are no coherent, scientific arguments to support the author's views. In particular, he makes claims on the nature of human intelligence and the human mind that are totally unsupported and mystical in nature. Ironically, his amplification of human mental abilities is comparable to that of the &quot;information cultists&quot; he criticizes.<br /> The author claims that the abilities of the computer have been over-advertised, but he confuses the content of the advertising with the beliefs of the individuals who promote it. In this hyper-competitive society, every firm has to advertise to get noticed, to get its point across. Such huckstering is done for business reasons, and yes, is sometimes exaggerated. But the inaccurate claims of the advertising, if any, should not cause one to believe that they are held in the minds of the those who invented the product. But the author will have none of this, for his goal is to protect the &quot;public&quot; against these false claims (regardless if they ask for his help).<br /> Financial engineering and derivatives trading are not left out of the criticism. Apparently the author does not believe in the use of the human mind which he has set out to save, for it is by using it that creative financial instruments are invented, with the intent of reducing risk. Financial engineers are &quot;hackers&quot; though, responsible for the 1987 stock market collapse, and the derivative is an &quot;Alice in Wonderland&quot; concept, a &quot;financial hydrogen bomb&quot;. The author quotes sources for these claims, but no explicit evidence whatsoever is given for his assertion that derivatives are devastating to the economy. Such evidence would be very interesting for those who work in financial engineering.<br /> The author's view of thinking machines as not living up to the &quot;megahype&quot; is just plain wrong, along with his belief that those who are behind this technology are duped by wishful thinking. The reverse is true in fact, as AI researchers are usually the last to acknowledge the claim that what they have built does exhibit some sort of intelligence. If they make outlandish and overly-optimistic claims, it is because of their doubts, and not of their confidence. The difficulties and let-downs of research require sometimes periodic shot-in-the-arms. But again, the author feels the need to protect the &quot;public&quot; against their inflated claims.<br /> One can expect more neo-Luddite books like this in the years to come, primarily from those who are having difficulty comprehending the true nature of the technology and science behind the information age. The &quot;public&quot; though will not be writing these books, nor do they need them. The overwhelming majority of the world's citizens are intelligent enough to judge for themselves what is confronting them. The advertising will continue along with the research and development. The machines will get smarter and smarter with each passing year. Imperfections will exist in these machines as they do in the humans who brought them about. One can imagine though the possibility that the machines will themselves begin to write books that offer arguments for the intelligence of their authors. Such a prospect is awesome.is awesome.	2004-01-11
832687:US	50702879	RJD8ILNMW61SQ	1573871737	501010770	Assessing Competitive Intelligence Software: A Guide to Evaluating Ci Technology	Books	4	8	8	N	Y	A nice, organized effort.	It is now perhaps a cliche to say that the nature of business has changed. With the rise of the Internet, increased globalization, and advances in financial engineering, both large and small companies have to keep abreast of trends at shorter and shorter time scales. The volatility of the marketplace has sent the business environment into a roller coaster ride of confidence and anxiety, and so it is imperative that sophisticated tools be brought in to handle gigantic market swings. These tools can take the form of software, and go by the name of competitive intelligence (CI). The goal of this book is to evaluate this software based on certain criteria that the authors think is important. It is one of the first books on the evaluation of competitive intelligence software, and is successful in cutting through the advertising hype that frequently accompanies this software.<br /> Competitive intelligence for the authors is a process that involves using publicly available information in order to learn various things about competitor, and to understand this information thoroughly. They assert, correctly, that the information that is gained must be transformed in order to make it useful for decision making and to induce changes or actions in a particular company.<br /> In chapter 1, the authors attempt to clarify the meaning of &quot;value-added information&quot; in the use of CI. One would think that this would be a difficult notion to clarify, and this is certainly correct. The authors approach the problem by attempting to define just what &quot;information&quot; and &quot;intelligence&quot; are, as well as &quot;data&quot; and &quot;knowledge&quot;. Such definitions could be deep and might degenerate into philosophical discussion, but the authors do a fairly good job of keeping the discussion relatively concrete. This discussion leads them to distinguish between the roles played by information specialists, CI professionals, and experts. An information specialist acquires access to information resources, CI practitioners assign values to its content, and experts decide the action to be taken. The authors though recognize that the boundaries between these roles can be blurred. After a modest review of the literature, the authors assert that value-added processes are ones that offer the means to see the potential of information and to relate it to problems in specific environments.<br /> The authors attempt to construct a conceptual framework for CI in chapter 2, after giving a literature survey of attempts to do so. As expected, the laissez faire nature of industry in the US made the nature of its CI very different from the CI of Japan or Europe. The authors are careful to distinguish between CI and &quot;industrial spying&quot;, and clarify the difference between it and business and marketing intelligence. Different analytical techniques, such as personality profiling and scenario development, are discussed in terms of their ability to guide information requirements. In addition, they emphasize the need for reliable filtering mechanisms that will eliminate false information about a competitor. The most interesting discussion in this chapter concerns the analysis of the obtained information, for this is where techniques from artificial intelligence could be used. Such techniques are not discussed in the book, but the authors do summarize the eight most popular analysis techniques for CI.<br /> In chapter 3, the authors begin their evaluation of CI software, with the main goal being to find out whether it can allow users to achieve their intended goals. Their evaluation criteria are aimed at identifying the value-added processes that should take place when a CI application is used to transform information into intelligence. The authors stress early on that CI software needs to be evaluated beyond the &quot;recall&quot; and &quot;precision&quot; criteria used to evaluate information retrieval systems. The dynamical nature of competitive information is the main reason for this, as typical databases are not refreshed at short enough time scales. CI systems also must assist in the analysis of information, not merely retrieve it. The value-added framework of R.S. Taylor, one of the early CI specialists, is used throughout this chapter, and the rest of the book, to evaluate CI software. Based on the Taylor model, the author presents 38 criteria for evaluating CI software, and discuss them in fair detail. One of these criteria is particularly interesting, in that it involves &quot;closeness to the problem&quot;, a very difficult concept to quantify, but one which is also very important in other fields, such as artificial intelligence. And, by the way, the use of artificial intelligence will soften the need for a &quot;sixth sense&quot; that the authors mention is a necessary ability for CI specialists to have in order to analyze information. Indeed, recent advances in natural language &quot;paraphrasing&quot; will be of enormous importance in the need for summarizing acquired information.<br /> Finally, in chapter 4, the authors begin evaluating the software packages available for CI. The authors list three selection criteria for distinguishing CI from other types of software, and six applications that  meet these criteria. In chapter 5 the authors present a set of equations to allow more rigorous evaluation of CI software.  Their goal was to compare these packages relative to their information-processing capability, and not rank them. It is readily apparent when reading this chapter that the authors took great care in their evaluation of the packages, which certainly must have been a time-consuming effort. Many problems shared by all the packages are discussed, including their lack of tools for monitoring the relevance of content through time, the lack of mechanisms for filtering information, and the poor performance of the packages when dealing with acquisition of knowledge. In addition, the authors conclude that the analytical capabilities of the packages, i.e. their ability to transform information into intelligence, are almost non-existent. Such capabilities, they argue, require human intelligence, and this is an interesting comment if comparison is made to recent advances in artificial intelligence. The authors remark that these packages are far from being intelligent, and that such intelligence is needed in order to make CI a viable technology, which in their opinion currently is not.titive information is the main reason for this, as typical databases are not refreshed at short enough time scales. CI systems also must assist in the analysis of information, not merely retrieve it. The value-added framework of R.S. Taylor, one of the early CI specialists, is used throughout this chapter, and the rest of the book, to evaluate CI software. Based on the Taylor model, the author presents 38 criteria for evaluating CI software, and discuss them in fair detail. One of these criteria is particularly interesting, in that it involves &quot;closeness to the problem&quot;, a very difficult concept to quantify, but one which is also very important in other fields, such as artificial intelligence. And, by the way, the use of artificial intelligence will soften the need for a &quot;sixth sense&quot; that the authors mention is a necessary ability for CI specialists to have in order to analyze information. Indeed, recent advances in natural language &quot;paraphrasing&quot; will be of enormous importance in the need for summarizing acquired information.<br /> Finally, in chapter 4, the authors begin evaluating the software packages available for CI. The authors list three selection criteria for distinguishing CI from other types of software, and six applications that  meet these criteria. In chapter 5 the authors present a set of equations to allow more rigorous evaluation of CI software.  Their goal was to compare these packages relative to their information-processing capability, and not rank them. It is readily apparent when reading this chapter that the authors took great care in their evaluation of the packages, which certainly must have been a time-consuming effort. Many problems shared by all the packages are discussed, including their lack of tools for monitoring the relevance of content through time, the lack of mechanisms for filtering information, and the poor performance of the packages when dealing with acquisition of knowledge. In addition, the authors conclude that the analytical capabilities of the packages, i.e. their ability to transform information into intelligence, are almost non-existent. Such capabilities, they argue, require human intelligence, and this is an interesting comment if comparison is made to recent advances in artificial intelligence. The authors remark that these packages are far from being intelligent, and that such intelligence is needed in order to make CI a viable technology, which in their opinion currently is not.	2004-01-10
841048:US	50702879	R3PK9DKPNYZZVW	0262122596	152422127	Radiant Cool: A Novel Theory of Consciousness (Bradford Books)	Books	4	21	26	N	Y	An interesting and engaging story	What is it about the new neuroscience that sometimes causes uneasiness in people when it is contemplated? This has been communicated to me many times by colleagues, co-workers, and business associates with whom I have discussed neuroscience over the years. The story in this book is brilliant if viewed from the standpoint of the moods that accompany the contemplation of the conscious mind from the perspective of contemporary experimental neuroscience. It captures, through its main character, the disquieting feelings that one sometimes gets when thinking about the true nature of consciousness from a scientific viewpoint. It is very perplexing that such feelings exist when examining something that is so close to us. Do we not want to believe that our consciousness can be explained according to the conceptions of modern neuroscience, with its mathematical models of neurons and neuronal connections, all validated with the experimental tool of fMRI? Does scientific description and analysis of consciousness trivialize it so that we no longer feel unique and retain a special, integrated &quot;I-ness&quot;, but instead a collection of neuronal impulses and a bundle of Machian sensations?<br /> This book is unique in that the author has chosen to present his ideas on consciousness using a story, with the rigorous scientific statements of his ideas coming after the story is over, in part 2 of the book, which the author has named &quot;The Real Firefly&quot;. His ideas, as I see them, could loosely be described as a scientific justification of Husserlian phenomenology. He is honest enough to say though that much work remains to be done. Thankfully the time when the study of consciousness was solely a philosophical affair is over. Scientific experiments are now being done to elucidate the phenomenon of human consciousness, and this hopefully will lead to a better understanding of the brain outside of what philosophy has given us so far. The armchair speculations of philosophy are being put aside in favor of a careful, scientific approach. Thought experiments, the most popular of philosophical toolboxes, have failed to give us anything substantive. True knowledge is difficult to obtain, but the patience and fortitude of the researchers in neuroscience will no doubt bring about exciting developments.<br /> The author is clearly optimistic about the possibility of science giving a complete explanation of human behavior. One can bet on this &quot;radical pipe dream&quot; he says. But again, he expresses an intellectual honesty about the difficulty of this goal, and the doubts that he himself has about his research. This doubt he says, causes him and others to sometimes exaggerate the current status of research, giving it a kind of &quot;infomercial&quot; overtone. But the goal of this research is to show how consciousness is part of the natural world, and this is to be done however, not with the tools of current cognitive neuroscience, but with a scientific interpretation of phenomenology. The author gives his reasons for rejecting contemporary cognitive neuroscience in the early paragraphs of part 2. He criticizes in great detail for example the &quot;Detection Theory of Consciousness&quot;, with its assumption that the detection of complexity in the environment can be done by &quot;matching&quot; it in consciousness.<br /> The author's theories of consciousness are built on phenomonology, but which he calls a &quot;subjective view of objectivity&quot;. To contrast this with ordinary phenomonology, such as Husserl's method of &quot;bracketing&quot;, he asserts that the world outside the mind is already bracketed, that one has an &quot;inescapable experience of the real as real&quot;. He then constructs step by step a justification of these assertions, with intentionality being the first step; superposition, which he defines as a symbiosis of object and interpretation, the second step; transcendence, which enables us to distinguish imaginary properties from real is the third; temporality, which asserts that reality is temporal and allows comparisons through time, is the fourth. The next three steps are refined notions of temporality, the first being the conscious present, which includes the awareness of temporal context, the second being an ordinal notion of temporality, which orders moments in time and is assuredly monotonic. The third is more sophisticated, and is called recursive retention, which provides a recursive nested trace of the succession of past moments.<br /> This subjective view of objectivity is still phenomonology for the author, and so a successful scientific view of consciousness for him must then involve an &quot;objective view of subjectivity&quot;. To do this, he brings in the tools of artificial neural networks and their validation using fMRI, and he deals with the consequent demand for reducing the dimensionality of the acquired data. Certain &quot;multivariate tests&quot; are used to detect the necessary conditions for consciousness in the brain. He uses three instances of what he calls &quot;indices of temporality&quot; to get a handle on the time series data extracted from fMRI: the temporal gradient, which measures absolute temporality, and is a monotonically increasing, the relative temporal gradient, which is a measure of the brain's sensitivity to position in a sequence of data, and the stimulus similarity gradient. which determines to what extent the distributed neural activity in the brain is sensitive to conditions that remain the same during an experiment.  This index is interesting, for it has as its goal a sort of measure of &quot;stability&quot; in the phenomenal world. These three indices allow the author to &quot;interpret the brain over time&quot;. He then deals with the internal temporal structures of the brain, i.e. with what the phenomonologist called protention, presence, and retention. Retention in the brain in particular, is modeled again by neural networks, and experiments are conducted to illustrate just how well they do their jobs in this regard. The author ends the book with a positive and optimistic view of future research in neuroscience, a future, which, regardless of its content, will certainly be fascinating to witness.properties from real is the third; temporality, which asserts that reality is temporal and allows comparisons through time, is the fourth. The next three steps are refined notions of temporality, the first being the conscious present, which includes the awareness of temporal context, the second being an ordinal notion of temporality, which orders moments in time and is assuredly monotonic. The third is more sophisticated, and is called recursive retention, which provides a recursive nested trace of the succession of past moments. <br /> This subjective view of objectivity is still phenomonology for the author, and so a successful scientific view of consciousness for him must then involve an &quot;objective view of subjectivity&quot;. To do this, he brings in the tools of artificial neural networks and their validation using fMRI, and he deals with the consequent demand for reducing the dimensionality of the acquired data. Certain &quot;multivariate tests&quot; are used to detect the necessary conditions for consciousness in the brain. He uses three instances of what he calls &quot;indices of temporality&quot; to get a handle on the time series data extracted from fMRI: the temporal gradient, which measures absolute temporality, and is a monotonically increasing, the relative temporal gradient, which is a measure of the brain's sensitivity to position in a sequence of data, and the stimulus similarity gradient. which determines to what extent the distributed neural activity in the brain is sensitive to conditions that remain the same during an experiment.  This index is interesting, for it has as its goal a sort of measure of &quot;stability&quot; in the phenomenal world. These three indices allow the author to &quot;interpret the brain over time&quot;. He then deals with the internal temporal structures of the brain, i.e. with what the phenomonologist called protention, presence, and retention. Retention in the brain in particular, is modeled again by neural networks, and experiments are conducted to illustrate just how well they do their jobs in this regard. The author ends the book with a positive and optimistic view of future research in neuroscience, a future, which, regardless of its content, will certainly be fascinating to witness.	2004-01-05
843290:US	50702879	R3BEHC8ZDK77B0	0465000924	458534212	Advice To A Young Scientist (Alfred P. Sloan Foundation Series)	Books	3	23	26	N	N	Good advice and refreshingly optimistic.	There have been many \\"advice books\\" on how to make it in the scientific profession in the last decade, this due no doubt to the collapse of the academic job market in the United States, which had been able to absorb even foreign applicants up until about the mid 1990s. The practice of science research luckily though has not been confined to the university, but has taken up residence in industry, where it is currently rising steadily.<br /> This book  is not one of these but was written in 1979 and endeavors to give advice on just how a young person is to proceed in their goal of becoming a scientist. There is no advice here on how to get a current academic position, but instead the author gives a fairly optimistic overview of what he believes are criteria for leading one's life as a (succesful) scientist. It is quite a refreshing book to read in that it does not express the cynicism that  frequently accompanies contemporary discussion of academic life.<br /> The author is not shy about discussing academic life, both its virtues and its vices. For example he describes an individual, which he mistakenly though calls a \\"scientist\\", who plagiarized some photographs and paragraphs of text from a fellow worker and presented them in a scientific essay contest. One of the judges was apparently the person from which the material was stolen, but the aversion to scandal of the culprit's institution caused him to find employment elsewhere. Both acts, the plagiarism and the institution's coverup, are despicable of course, and individuals who engage in them cannot be labeled as scientists, that designation reserved only for those who respect and practice honesty in all phases of their lives.<br /> The rewards for doing scientific research are also described very accurately by the author. The \\"oceanic feeling\\" that Freud described when making a discovery is described by the author as something that will definitely keep an individual tied to the scientific profession, if there was any doubt before. The roller coaster ride of confidence and depression that can take place when doing scientific research makes this a welcome feeling, one that goes far beyond any peer recognition or financial rewards.<br /> Most refreshing is that the author decides to discuss sexism and racism in the scientific profession, an issue that has been a severe problem in the history of the university, particularly with women. Women are more welcome in the scientific profession now, but there are issues with such things as maternity leave that still need to be ironed out. The author makes it a point to note that in his experience women do not approach scientific research in any way that is distinctive in comparison with men. Any university that makes a conscious effort to hire women because of social or political pressures is doing itself, and the women (and men) it hires, an extreme disservice. The scientific profession, as all others, is an aristocracy of ability, and hiring decisions should always be decided on merit, not favoritism or some diversity quota system. Nothing can be more heartbreaking than to see enormously talented individuals locked out of positions because they did not have the \\"right connections\\".<br /> The are numerous other issues that the author discusses, such as the place of recognition and scientific prizes, and social attitudes about scientists. The book will no doubt be of assistance to at least a few young people who have decided to become scientists. If even just one young person does, the book has done its job.as any doubt before. The roller coaster ride of confidence and depression that can take place when doing scientific research makes this a welcome feeling, one that goes far beyond any peer recognition or financial rewards. <br /> Most refreshing is that the author decides to discuss sexism and racism in the scientific profession, an issue that has been a severe problem in the history of the university, particularly with women. Women are more welcome in the scientific profession now, but there are issues with such things as maternity leave that still need to be ironed out. The author makes it a point to note that in his experience women do not approach scientific research in any way that is distinctive in comparison with men. Any university that makes a conscious effort to hire women because of social or political pressures is doing itself, and the women (and men) it hires, an extreme disservice. The scientific profession, as all others, is an aristocracy of ability, and hiring decisions should always be decided on merit, not favoritism or some diversity quota system. Nothing can be more heartbreaking than to see enormously talented individuals locked out of positions because they did not have the \\"right connections\\". <br /> The are numerous other issues that the author discusses, such as the place of recognition and scientific prizes, and social attitudes about scientists. The book will no doubt be of assistance to at least a few young people who have decided to become scientists. If even just one young person does, the book has done its job.	2004-01-03
844715:US	50702879	R34GU2L343MBQJ	0471608483	638038934	Linear Operators, Part 1: General Theory (Vol 1)	Books	5	15	15	N	N	A great source of intuition.	Functional analysis and operator theory is a deep and useful subject, and is still an active area of research. Quantum theory, learning theory, and probability and statistics, are just a few of the areas that make heavy use of it, and it would be difficult to formulate ideas in these areas concisely if it were not for the results that are codified in functional analysis and operator theory.<br /> This book, in spite of its age, can still be thought of as a definitive treatise in the subject, even though operator theory has grown tremendously since its date of publication. There are many fascinating results in this book it is one of the few treatises on mathematics that could in some sense be thought of as respecting a certain &quot;oral tradition&quot; in mathematics. Indeed, the &quot;Notes and Remarks&quot; sections at the end of each chapter give many insights on the origins of the subject and give those who crave for a more in-depth understanding of the subject. I studied this book in great detail when I was a sophomore undergraduate, having had the privelege of doing do under the tutelage of the late functional analyst Jeffrey Butz. The excitement he generated in the course, with his lucid lectures, makes the review of this book bring back fond memories. For lack of space, only the first seven chapters will be reviewed here.<br /> In chapter 1, the authors give a quick review of the set theory, topology, and elementary analysis that will be needed for the reader to get through the book. Functional analysis can be thought of as a generalization of linear algebra to infinite dimensions, with analysis put in so as to be able to discuss convergence. Chapter 2 then discusses the three pillars of that functional analysis is dependent on: the principle of uniform boundedness, the interior mapping principle (and its immediate corollary the closed graph theorem), and the Hahn-Banach theorem. Uniform boundedness is presented in the context of what the authors call F-spaces, and is, as they point out, a principle of equi-continuity. The interior mapping principle guarantees that continuous linear mappings bring open sets to open sets, while the Hahn-Banach theorem ensures that there are in fact functionals in the dual of a Banach space. (Banach spaces are called &quot;B-spaces&quot; in this book, while the dual is called the &quot;conjugate).<br /> Then in chapter 3, the authors take the reader through a careful treatment of measure theory and the theory of integration. They do this first via the concept of finitely additive set functions taken over a field of subsets of a set (a Boolean algebra). These set functions are taken to be the measures, and are not assumed to be bounded, and more generally than is usually the case, are assumed to have values in a real or complex Banach space. Integration theory in this set-up begins, as expected, with simple functions, and Lebesgue spaces are defined  as linear spaces of measurable functions. When the set functions are countably additive, one can extend them to a wider collection, called a sigma field. This brings up the Borel field, where the set is now a topological space, and is the smallest sigma-field containing the closed sets of this space. The authors illustrate how to extend the subsequent measures via an example: the construction of the famous Radon measure on an interval. Then a metric is introduced on the sigma-field of a measure space so that it is complete, and the authors then prove the Vitali-Hahn-Saks theorem. They also show how to represent the set functions in terms of integrable functions: the Radon-Nikodym theorem.<br /> The &quot;special spaces&quot; of functional analysis are overviewed in chapter 4, such as the lp and Lp spaces so familiar in applications. The authors motivate the interest in these spaces in the context of solving eight problems, dealing with how to represent the dual space, the relation between convergence in a space and its dual, weak convergenceof sequences, weak completeness of a space, reflexivity of a space, weak sequential compactness of subsets of a space, compactness of subsets in the metric topology, and the connection between convergence in a space and in the space it is dual to.<br /> Chapter 5 is an introduction to the role that convexity plays in vector spaces, wherein the authors prove an analog of the Hahn-Banach theorem, showing to what extent linear functionals can be related to convex sets. When a topology is put on the vector space, the linear functionals can determine a a topology, which for Banach spaces is the famous weak topology. This chapter is very important in applications, such as learning theory and optimization theory, due to the notions of extremal points and fixed point theorems. The Krein-Milman theorem is proven, as well as the Kakutani fixed point theorem.<br /> The authors finally get to operator theory in chapter 6, wherein they study bounded linear maps between Banach spaces. The strong, uniform, and weak topologies are introduced immediately, adjoints are defined, along with projections. Weakly compact operators, so important in the theory of integral equations are discussed, along with the compact operators, so ubiquitous now in operator theory. Concrete examples are given on the form that operators take in various kinds of spaces, like Lebesgue spaces.<br /> Then the reader, in chapter 7, gets totally immersed in the eigenvalue problem  in infinite dimensions: the spectral theory of operators. The finite dimensional case is reviewed first, and the spectral theory of compact operators, a generalization of the Fredholm theory of linear integral equations, is discussed in great detail. This subject has changed considerably since this book was published, now being done most concisely and transparently using the language of K-theory.ence of sequences, weak completeness of a space, reflexivity of a space, weak sequential compactness of subsets of a space, compactness of subsets in the metric topology, and the connection between convergence in a space and in the space it is dual to. <br /> Chapter 5 is an introduction to the role that convexity plays in vector spaces, wherein the authors prove an analog of the Hahn-Banach theorem, showing to what extent linear functionals can be related to convex sets. When a topology is put on the vector space, the linear functionals can determine a a topology, which for Banach spaces is the famous weak topology. This chapter is very important in applications, such as learning theory and optimization theory, due to the notions of extremal points and fixed point theorems. The Krein-Milman theorem is proven, as well as the Kakutani fixed point theorem. <br /> The authors finally get to operator theory in chapter 6, wherein they study bounded linear maps between Banach spaces. The strong, uniform, and weak topologies are introduced immediately, adjoints are defined, along with projections. Weakly compact operators, so important in the theory of integral equations are discussed, along with the compact operators, so ubiquitous now in operator theory. Concrete examples are given on the form that operators take in various kinds of spaces, like Lebesgue spaces. <br /> Then the reader, in chapter 7, gets totally immersed in the eigenvalue problem  in infinite dimensions: the spectral theory of operators. The finite dimensional case is reviewed first, and the spectral theory of compact operators, a generalization of the Fredholm theory of linear integral equations, is discussed in great detail. This subject has changed considerably since this book was published, now being done most concisely and transparently using the language of K-theory.	2004-01-02
846502:US	50702879	R1IIU6P60XTKSI	0520037251	854158396	Philosophical Grammar	Books	3	1	29	N	N	Typical philosophy	Once feature of this book that is always fascinating is that one can take any paragraph in it and generate a plethora of ideas and commentary, that might even fill volumes. This book is not unique in that regard, but in fact most books of philosophy have this characteristic. They allow the mind to go forth untamed and engage in speculations that are unconstrained by experience or laboratory experiments. Philosophical reasoning is to be distinguished therefore by its freedom to say and write what it pleases, unlike the case for scientific reasoning, which is highly constrained by observation and experiment. There are some interesting points made in this book, some of them having intersection with what is now going on in artificial intelligence, computational grammar, and linguistics. Readers can also gain insight into the school of logical atomism, which the author was of course very much a part of.<br /> The book is organized as a collection of disjointed paragraphs, which little or no correlation between them. Many of them are quite interesting and thought-provoking, especially if read in the context of the field of artificial intelligence. It is doubtful though that any of these ideas could be refined in such a way as to make them useful in the goal of building thinking machines. They are just too loosely structured to be codified in a language that would run on a machine. Speculative ideas unfortunately are like that. The ideas in the book might perhaps though put one in a certain frame of mind that would permit more acceptance of various claims made in artificial intelligence. Conversely, it might very well increase the doubt on those claims. Such is the nature of philosophical grammar: its expressive power and rich information content permits a wide range of interpretations.	2003-12-31
848440:US	50702879	RBW4463ALRSSK	0416013317	529498972	The Arch of Knowledge: An Introductory Study of the History of the Philosophy and Methodology of Science	Books	4	2	2	N	N	A good overview	If there is one belief that is held as an axiom in modern philosophy, it is that Western science needs a philosophical foundation. Science is held by some philosophers to be an inconsistent system of beliefs, by other philosophers a system that cannot  be distinguished from magic, and by some political philosophers a perfect sign of Western power and domination. This book, in spite of its small size, gives a good historical overview of the ideas that resulted in the rise of modern science and its philosophical criticism. There is much more that could have been included by the author, but a comprehensive account would fill dozens of volumes.<br /> The author justifies his historical approach in the preface of the book, holding that the usual approach treats the subject from what he calls a &quot;quasi-historical&quot; perspective. The texts of philosophy are treated as if they were of secondary significance he argues, with emphasis placed instead on the philosophical problems they generate. This results in a distorted view of the history of philosophy he says, and so his goal is to examine both the history of the philosophy and methodology of science.<br /> The book takes one from the forms of Plato to the modern sociologists of knowledge. Along the way, one gains an appreciation of the attitudes taken toward scientific knowledge, with enthusiasm and skepticism each having approximately equal representation. Science is very different from philosophy, and refreshingly the author realizes this. Philosophical systems of thought do not have the constraint of experimental evidence that science does. Therefore it can engage in endless speculations and theorizing, which results in a very rapid build-up of information.<br /> Again, this book will give one an appreciation of the philosophy of science as it took place throughout history. It can be said with confidence that readers interested in philosophy will like the book more then those interested in science. If after reading this book one concluded that science needed some sort of philosophical underpinning or foundation then this would be mistaken. Science does not need any such foundation, but it does rely sometimes on the critical thinking that characterizes philosophical argumentation. This dependence will continue, and no doubt the extraordinary advances made in science in the twenty-first century will instigate new thinking in philosophy. This thinking will both be for and against science, but of course, science will survive it, whatever its form.ading this book one concluded that science needed some sort of philosophical underpinning or foundation then this would be mistaken. Science does not need any such foundation, but it does rely sometimes on the critical thinking that characterizes philosophical argumentation. This dependence will continue, and no doubt the extraordinary advances made in science in the twenty-first century will instigate new thinking in philosophy. This thinking will both be for and against science, but of course, science will survive it, whatever its form.	2003-12-30
852323:US	50702879	R1IZNAU66E38WW	0030295580	222827805	An Introduction to the History of Mathematics (Saunders Series)	Books	5	22	22	N	N	Excellent	The careful documentation of the discoveries and history of mathematics is of overwhelming importance, especially in modern times where the advances are taking place so rapidly that the historical roots of some branches of mathematics seem to be getting lost. It would be a tragedy if the history of these important developments were not put into print so that later generations of mathematicians and students could have an understanding of how these came about. Thanks to the information age, the accessibility of mathematical documents has dramatically increased, but these documents usually do not include overviews of how the ideas took root and then flourished as independent research disciplines.<br /> This book gives a general overview of mathematical developments up until the middle of the twentieth century. It is a fascinating story, and readers will realize to what extent mathematical ideas deemed complex by even modern standards were known by the ancients. Indeed, it is very surprising to learn that in 2000 BC the Babylonians were solving quadratic equations and even some cubic and quartic equations.  The Babylonians did not produce an Evariste Galois, that took centuries more time, but they were dealing with mathematical constructions that were interesting to compare with modern methods.<br /> One very  interesting feature of this book is that it is meant to be used as a textbook, and not just in a course in the history of mathematics. The author has included &quot;problem studies&quot; and &quot;essay topics&quot; at the end of each chapter that challenge the reader to solve problems pertinent to the historical topics of each chapter. The inclusion of these problems will allow the student to gain insight on the difficulty in solving problems with the constraint of using concepts that were unique to a definite period in mathematical history.<br /> The book also includes discussions of the history of non-Western contributions to mathematics. The work of the Hindus, the Chinese, and Arabs is included. The contributions of the Arabs are particularly important for later developments in the West, as it was they who revived Greek philosophy and mathematics and consequently changed dramatically the role of mathematics in Europe.<br /> The reading of this book will give a greater appreciation of the developments in mathematics as they are done today. Mathematical research now is done by both human and machine, and no doubt this century, and others beyond it, will result in brilliant developments. Mathematics pervades every human activity in the modern world and every piece of technology. When books like this one are written in the future, readers who peruse them and take note of the incredible advancements made in mathematics in the centuries that preceed them, no doubt their predominant emotion will be astonishment.dus, the Chinese, and Arabs is included. The contributions of the Arabs are particularly important for later developments in the West, as it was they who revived Greek philosophy and mathematics and consequently changed dramatically the role of mathematics in Europe. <br /> The reading of this book will give a greater appreciation of the developments in mathematics as they are done today. Mathematical research now is done by both human and machine, and no doubt this century, and others beyond it, will result in brilliant developments. Mathematics pervades every human activity in the modern world and every piece of technology. When books like this one are written in the future, readers who peruse them and take note of the incredible advancements made in mathematics in the centuries that preceed them, no doubt their predominant emotion will be astonishment.	2003-12-27
853971:US	50702879	RQJVE21ORE9FI	0131382721	189891660	Classical Mechanics	Books	3	4	6	N	N	Close to the edge of modern mechanics.	Classical mechanics has certainly changed in form since the days of Newton, due in part to the Lagrangian and Hamiltonian formulations, and to the rise of the theory of relativity. Student pursuing graduate study in mechanics will be exposed to differential geometry as well as other more abstract mathematics. Formulating mechanics using these mathematical tools has the advantage that it remains loyal to the spirit of the theory of relativity, especially the general theory, which makes heavy use of differential geometry. It has the disadvantage of not being amenable to numerical computation, and sometimes masks the underlying intuition.<br /> This short book proposes to be a &quot;modern&quot; introduction to classical mechanics, and it succeeds in its goal to a large degree. However, there is no discussion at all of chaos, in spite of its importance and modernity. Chaotic mechanical systems, although only discovered recently in comparison to the long history of mechanics, can still be thought of in the context of classical (Newtonian) mechanics, even though they are more easily formulated in the Hamiltonian formalism.<br /> Chapter 1 of the book is an introduction to the differential geometry to be used in the book, but not from a rigorous mathematical standpoint. The treatment is done in the context of differentiable manifolds, with tangent spaces and bundles, gradients and 1-forms, and tensors all being defined, albeit somewhat hurriedly. Newtonian kinematics is formulated in the tangent bundle, called the configuration bundle. The kinetic energy is shown to be a tensor on this bundle. The theory of constrained mechanical systems is discussed, but only in the context of holonomic constraints.<br /> In chapter 2, the authors show how to formulate Newtonian physics in the context of Minkowski space. Due to the assertion that time is absolute in the Newtonian theory, the time slices in this space are set equal to each other. Thus the indefinite metric property of Minkowski space does not play a role in this formulation.<br /> The Lagrangian formulation of mechanics is outlined in chapter 3, wherein the authors show that Newton's equations can be obtained via the Lagrangian function, which is a scalar function on the tangent bundle. Defining the action integral over the Lagrangian and finding its extrema with fixed endpoints in time gives the Euler-Lagrange equations of motion. A particular choice of the Lagrangian then yields the Newtonian equations of motion. This is certainly a different formulation than what Newton had in mind, but it does have the advantage of mathematical simplicity, and it makes the transition to quantum physics much more palatable in some cases.<br /> The authors turn to the consideration of central force fields in chapter 4, in the context of the Lagrangian formulation. Using conservation of total linear momentum and total angular momentum, the 6-dimensional configuration space of the two-body problem is reduced to two dimensions. Kepler's second law results from the equations of motion, as expected. The Coulomb force and classical scattering theory is then studied. A brief but interesting overview of the (restricted) three-body problem is then given.<br /> In the next two chapters, the authors concentrate on matters of a purely mathematical nature. One of them concerns the uniqueness of the Lagrangian, which they show it is not. One can add a total time derivative to it and multiply it by a constant and still obtain the same equations of motion as the first. They then give a general discussion of when two Lagrangians are equivalent. They also discuss rotations in Euclidean 3-space, and, curiously, introduce spinors in order to parametrize fully 3-dimensional rotations. This is unusual in a text on classical mechanics, and unnecessary to a large extent.<br /> The discussion of rotations does set up the treatment in chapter 7 on rigid body dynamics, wherein the authors derive the equations of motion in the body frame. This leads to a discussion of the particle dynamics from the standpoint of rotating frames, which lead to the famous (non-Newtonian) contributions to the total force: the Coriolis and centrifugal forces.<br /> Mechanics from a &quot;symplectic&quot; viewpoint, namely the Hamiltonian formalism, is outlined in Chapter 8. The equations of  motion in this formalism are first-order and involve the Hamiltonian function, which is obtained from the Lagrangian via a Legendre transformation. Ubiquitous now in the study of dynamical systems, especially ones that exhibit chaotic behavior, the Hamiltonian formalism, especially in the context of symplectic geometry, is one that has grown in importance in purely mathematical questions. The Poisson bracket is introduced in the next chapter, and the authors make the connection with symplectic geometry via the canonical transformations in chapter 10. The discussion here, will assist  readesr in understanding the famous canonical quantization, which  they will encounter in later courses on quantum physics.<br /> The Hamilton-Jacobi theory, which is a formulation of mechanics in terms of a first-order nonlinear partial differential equation, and which is also very important in modern formulations of mechanics, and in quantum physics,  is discussed in chapter 11. In fact the authors point out briefly the connection with wave mechanics in the last section of the chapter. The utility of the Hamilton-Jacobi theory in solving mechanics problems is brought out in chapter 12. Some mechanical systems, the separable ones, allow simplification into action and angle variables, as the authors discuss in fair detail. Others however, defy such a separation, and require approximation techniques. Canonical perturbation theory, which is one of these techniques, is discussed in chapter 13. This is followed in chapter 14 by a discussion of coupled oscillations, and the transition to classical field theory is made.<br /> The stage is now set for the reader to go to on to many fascinating topics in modern mechanics: ergodic and KAM theory, chaotic dynamical systems, and the interesting mathematics involved in these areas.n in the body frame. This leads to a discussion of the particle dynamics from the standpoint of rotating frames, which lead to the famous (non-Newtonian) contributions to the total force: the Coriolis and centrifugal forces. <br /> Mechanics from a &quot;symplectic&quot; viewpoint, namely the Hamiltonian formalism, is outlined in Chapter 8. The equations of  motion in this formalism are first-order and involve the Hamiltonian function, which is obtained from the Lagrangian via a Legendre transformation. Ubiquitous now in the study of dynamical systems, especially ones that exhibit chaotic behavior, the Hamiltonian formalism, especially in the context of symplectic geometry, is one that has grown in importance in purely mathematical questions. The Poisson bracket is introduced in the next chapter, and the authors make the connection with symplectic geometry via the canonical transformations in chapter 10. The discussion here, will assist  readesr in understanding the famous canonical quantization, which  they will encounter in later courses on quantum physics. <br /> The Hamilton-Jacobi theory, which is a formulation of mechanics in terms of a first-order nonlinear partial differential equation, and which is also very important in modern formulations of mechanics, and in quantum physics,  is discussed in chapter 11. In fact the authors point out briefly the connection with wave mechanics in the last section of the chapter. The utility of the Hamilton-Jacobi theory in solving mechanics problems is brought out in chapter 12. Some mechanical systems, the separable ones, allow simplification into action and angle variables, as the authors discuss in fair detail. Others however, defy such a separation, and require approximation techniques. Canonical perturbation theory, which is one of these techniques, is discussed in chapter 13. This is followed in chapter 14 by a discussion of coupled oscillations, and the transition to classical field theory is made. <br /> The stageis now set for the reader to go to on to many fascinating topics in modern mechanics: ergodic and KAM theory, chaotic dynamical systems, and the interesting mathematics involved in these areas.	2003-12-25
854185:US	50702879	R2CUYTWTKA1C2D	3540420274	991840721	Logic For Learning	Books	4	11	12	N	Y	Good introduction...ALKEMY needs more investigation	This book gives an introduction to computational logic and machine learning in the context of higher-order logic, and also serves as a rudimentary introduction to functional logic programming languages. My interest in it was stirred by its emphasis on comprehensibility in learning, its attempt to discuss inductive logic programming and the construction of inductive decision trees in a higher-order logic context, and to see whether or not I could use the ALKEMY language for practical applications.<br /> In chapter 1, the author takes the position that higher-order logic meets the needs of knowledge representation in that it can represent complex individuals, is able to formulate the hypothesis language precisely, and allows the computation of values of a function in the background theory on an individual. He also justifies the use of types in the book, claiming that such a use will result in a &quot;substantial payoff&quot;. The author identifies seven different learning issues that he will study in the book. One of these concerns the representation of individuals. Another concerns the specification of a signature for the target function whose definition is to be induced.  The third learning issue deals with the training data, each piece of data giving the value of the target function for a particular individual.  The fourth issue deals with the need for a background theory, which is a collection of definitions of the functions that act on the individuals. The fifth issue concerns the hypothesis language, which specifies the functions in the background theory. The need for evaluating the predictive power of the constructed hypothesis is the sixth learning issue.The last issue concerns the requirement of comprehensibility of the hypotheses returned by the learning system. The hypotheses must provide an insight and explanation of the data, rather than merely a &quot;black-box&quot; with possibly high predictive power.<br /> Chapter 2 gives an overview of the syntax and semantics of higher-order logic.  The author clarifies in detail what is meant by &quot;defined inductively&quot;, and proves a principle of induction on the structure of types. The importance of the collection of parameter-free &quot;closed&quot; types is brought out, and the author gives examples of various types that have been used in logic programming. Type substitutions, terms, subterms, and term substitutions are all defined in great detail, and many examples of each are given. Term substitution can be tricky and does not merely involve the replacing of a free occurrence of a variable by a term.  He also shows, in the context of term substitution, that one does not need to do run-time type checking in logic programming. The model and proof theory of this theory of types is developed at the end of the chapter.<br /> In chapter 3, the author how to represent knowledge in logic theories. For machine learning applications, a particular set of terms, called &quot;basic terms&quot; are used to represent individuals. Basic terms are defined in terms of default and normal terms with a suitable equivalance relation put on the normal terms. In higher order logic, sets are represented essentially as characteristic functions, i.e. as predicates. The concept of a default term arises in this method of representation, and is defined inductively in terms of default data constructors.  Default terms are then used to define (inductively) &quot;normal terms&quot;. A notion of equivalence of normal terms is defined, and a strict total order is put on the normal terms in order to allow one to select a single representative from an equivalence class. The &quot;basic&quot; terms are then defined. The author shows that the normal equivalence relation is the identity on basic terms, and this allows him to define a &quot;basic form&quot;. He then shows how to obtain the basic form of a normal term. Several different metrics and kernels are defined on the basic terms.<br /> The authoraddresses the construction of predicates in chapter 4, this being done incrementally via the composition of transformations. The author then defines a larger class of predicates, called the &quot;standard predicates&quot;, along with a subclass, the &quot;regular predicates&quot;. The &quot;background theory&quot; is the theory consisting of the definitions of the transformations. After placing a relation of strict total order on the standard predicates, the regular predicates are defined by induction on the number of transformations in a predicate and in terms of this ordering.  Every standard predicate is shown to be equivalent to a regular predicate and an algorithm is given for constructing this regular predicate, the resulting regular predicate being called a &quot;regularization&quot; of the standard predicate.  Then predicate rewrite systems (PRS), are studied, and related to machine learning as a generation of a search space of standard predicates.To determine when one predicate logically implies the other, the author defines an implication &quot;preorder&quot; on the space of predicates, which then allows the characterization of a PRS as &quot;monotone&quot;, and a notion of &quot;regularization&quot; of a PRS.<br /> The goal of the next chapter is to develop a computational formalism by viewing programs as collections of definitions or &quot;equational theories&quot;.  A computational model for programs is developed which is decidable, and which contains the familiar notions of equality, connectives and quantifiers, etc. The author introduces his notion of &quot;programming with abstractions&quot;, which he claims allows the functional programming paradigm to be done in a logic programming style.<br /> The last chapter is an overview of the (publically available) ALKEMY system for (binary) decision-tree learning, The author gives a detailed description of the decision-tree algorithm used by ALKEMY, which has as input a set of examples, a predicate rewrite system, and a parameter. Examples are composed of a basic term and its class, and the algorithm constructs a decision tree by labeling each leaf node of the tree but its majority class, and then performing error-complexity post-pruning on the tree. The author gives several examples of the use of ALKEMY, such as the East-West challenge game, Bongard pattern recognition, the Musk problem, mutagenesis, and a molecule recognition problem from chemistry.thor addresses the construction of predicates in chapter 4, this being done incrementally via the composition of transformations. The author then defines a larger class of predicates, called the &quot;standard predicates&quot;, along with a subclass, the &quot;regular predicates&quot;. The &quot;background theory&quot; is the theory consisting of the definitions of the transformations. After placing a relation of strict total order on the standard predicates, the regular predicates are defined by induction on the number of transformations in a predicate and in terms of this ordering.  Every standard predicate is shown to be equivalent to a regular predicate and an algorithm is given for constructing this regular predicate, the resulting regular predicate being called a &quot;regularization&quot; of the standard predicate.  Then predicate rewrite systems (PRS), are studied, and related to machine learning as a generation of a search space of standard predicates.To determine when one predicate logically implies the other, the author defines an implication &quot;preorder&quot; on the space of predicates, which then allows the characterization of a PRS as &quot;monotone&quot;, and a notion of &quot;regularization&quot; of a PRS. <br /> The goal of the next chapter is to develop a computational formalism by viewing programs as collections of definitions or &quot;equational theories&quot;.  A computational model for programs is developed which is decidable, and which contains the familiar notions of equality, connectives and quantifiers, etc. The author introduces his notion of &quot;programming with abstractions&quot;, which he claims allows the functional programming paradigm to be done in a logic programming style. <br /> The last chapter is an overview of the (publically available) ALKEMY system for (binary) decision-tree learning, The author gives a detailed description of the decision-tree algorithm used by ALKEMY, which has as input a set of examples, a predicate rewrite system, and a parameter. Examples are composed of a basic term and its class, and the algorithm constructs a decision tree by labeling each leaf node of the tree but its majority class, and then performing error-complexity post-pruning on the tree. The author gives several examples of the use of ALKEMY, such as the East-West challenge game, Bongard pattern recognition, the Musk problem, mutagenesis, and a molecule recognition problem from chemistry.	2003-12-25
856907:US	50702879	R7NUL1QM3NEG3	0716710625	64784135	Gravitational Curvature: An Introduction to Einstein's Theory	Books	3	12	13	N	N	Short, and some current topics of interest omitted.	There are many books on special and general relativity available on the market of varying lengths and degrees of difficulty. Some emphasize the mathematics, others the physics behind these two theories. This book is primarily concerned with the mathematical structure of general relativity, and is written for the student of relativity who has preparation in differential geometry, on the level of manifolds and Riemannian geometry. Readers should not expect an in-depth discussion of general relativity, and so will need to consult other books and texts to gain further understanding.<br /> Chapter 1 outlines the theory of special relativity, with discussion first on the Lorentz transformations. The Lorentz group is defined, along with its generalization the Poincare group. Both of these groups could be viewed both mathematically and physically as a constraint on the construction of physical theories. Theories not satisfying the constraint of Lorentz or Poincare covariance cannot be physical theories. The famous Minkowski space is constructed, and the author discusses the (indefinite) norm on this space using an interesting formulation due to A.A. Robb.<br /> After a brief discussion of the principle of equivalence, the author begins a study of the (pseudo-Riemmanian) geometry of space-time in chapter 2. He constructs, using very simple geometric considerations and elementary physical reasoning, a pseudo-Riemannian metric that yields in chapter 3, after some &quot;heuristic&quot; considerations, the Einstein gravitational field equations. This derivation is interesting in that the Einstein equations are viewed as a generalization of Poisson's equation. The charge density is replaced by a &quot;mass density&quot; and the Laplacian of the scalar potential by an expression involving the Laplacian of the square root of the zeroth component of the metric of space-time. The stress-energy-momentum tensor is related to this Laplacian, and the Einstein equations follow immediately.<br /> In chapter 4 the author does some of the &quot;index gymnastics&quot; in the context of differential forms, and interprets the Einstein equations as an equating of the quadratic form of the stress-energy-momentum tensor to the sum of sectional curvatures of space-time. The geometry of the spatial sections is studied via the Gauss equations, and the Einstein equations are put in a purely geometric form, which brings out transparently their nonlinearity.<br /> The Einstein equations would be useless if they could not be solved and related to physically interesting situations. In spite of the nonlinearity of the Einstein equations, many exact solutions can be found, and the next chapter gives the detail of the one of the first of these, the Schwarzschild solution. This solution gives the geometry of spacetime for a spherically symmetric static mass distribution. The famous Schwarzschild singularity is discussed briefly. This is followed in chapter 6 by a more in-depth discussion, using various tools from differential geometry, of the stress-energy-momentum tensor. These discussions are continued in the next chapter to obtain relativistic equations of motion, with attention paid in particular to the shear and stress tensor for a viscous fluid. Noticeably missing though, and a particular peculiarity of general relativity, are the relativistic equations of motion for rigid bodies. It still remains to be seen whether general relativity can indeed include a notion of rigid bodies. The relativistic equations of motion for a true rigid-body gyroscope would be very interesting and important.<br /> The bending of light rays around massive bodies, one of the most popular of the predictions of general relativity, is discussed in chapter 8. This is followed in chapter 9 by a discussion of electromagnetism in 3-dimensional Euclidean space and in Minkowski space. The role of twisted forms is readily apparent in the discussion, as expected due to the properties of the magnetic field. The duality between the electric and magnetic fields is made explicit, as well as their well-known synthesis in Minkowski space. The Hodge *-operator makes its appearance here, and its utility in formulating Maxwell's equations in both 3-space and Minkowski is very apparent.  The question of formulating electromagnetism in general relativity is answered in the next chapter, wherein the electromagnetic stress-energy-momentum tensor is calculated. The Reissner solution, which gives the electromagnetic field due to a charged massive particle is given. Missing in the discussion is any discussion of gravitoelectromagnetism, a subject which has become very important recently, and could have easily be included here.<br /> The author considers the solution of the Einstein equations in the interior of a star in chapter 11, a subject of much importance in astrophysics. The interior solution to the Schwarzschild geometry is considered, as well as the interior solution to any static, spherically symmetric mass-energy distribution. The latter yields the Oppenheimer-Volkoff equation for the pressure as a function of radius.<br /> The last chapter is a brief overview of relativistic cosmology, certainly one the most popular topics currently in general relativity. The Einstein static universe is discussed, along with Einstein's famous &quot;blunder&quot; for avoiding an empty universe: the introduction of the cosmological constant. The (constant curvature) Friedman cosmology is then discussed in great detail. Relaxing the constant curvature constraint is then removed, and the author shows what this will entail for the geometry and physics of the universe.gnetic field. The duality between the electric and magnetic fields is made explicit, as well as their well-known synthesis in Minkowski space. The Hodge *-operator makes its appearance here, and its utility in formulating Maxwell's equations in both 3-space and Minkowski is very apparent.  The question of formulating electromagnetism in general relativity is answered in the next chapter, wherein the electromagnetic stress-energy-momentum tensor is calculated. The Reissner solution, which gives the electromagnetic field due to a charged massive particle is given. Missing in the discussion is any discussion of gravitoelectromagnetism, a subject which has become very important recently, and could have easily be included here. <br /> The author considers the solution of the Einstein equations in the interior of a star in chapter 11, a subject of much importance in astrophysics. The interior solution to the Schwarzschild geometry is considered, as well as the interior solution to any static, spherically symmetric mass-energy distribution. The latter yields the Oppenheimer-Volkoff equation for the pressure as a function of radius. <br /> The last chapter is a brief overview of relativistic cosmology, certainly one the most popular topics currently in general relativity. The Einstein static universe is discussed, along with Einstein's famous &quot;blunder&quot; for avoiding an empty universe: the introduction of the cosmological constant. The (constant curvature) Friedman cosmology is then discussed in great detail. Relaxing the constant curvature constraint is then removed, and the author shows what this will entail for the geometry and physics of the universe.	2003-12-22
858627:US	50702879	R24DLA4156DUNK	0131830473	180529725	The Physics of Sound (2nd Edition)	Books	3	37	38	N	N	Considerably out of date in some places	Acoustics is an interesting subject, at all levels, and very important of course due to the human love for music and the need for high fidelity sound reproduction. This book is written for a readership that does not have expertise in physics or mathematics beyond the high school level. The authors do an excellent job, and the book could be used in classes on music theory or a class in physics for the humanities. The audiophile reader will gain a greater appreciation of the physics behind quality sound reproduction. Heavy use is made of demonstrations to illustrate the properties of sound, and most of these are easily set up in the classroom. I have used most of these demonstrations in the classroom, and can highly recommend their use to reinforce the understanding of the physics of sound.<br /> The book opens, appropriately, with a discussion of simple harmonic motion, with the properties of this type of motion related to sound waves. The nature of simple harmonic motion as periodic, in contrast with noise, which is nonperiodic, is pointed out very early on. To introduce the concept of resonance, in particular the concept of coupling resonance, the author use the coupled pendulum system. This demonstration is easily constructed for classroom use and very effective in illustrating coupled resonance. Lissajous figures, which arise in the study of the relationship between two waves, is discussed in some detail.<br /> The difference between longitudinal waves, which sound waves are, and transverse waves (such as light), is illustrated in chapter 2. To reinforce the difference between sound and light, the authors use the &quot;bell in vacuum&quot; demonstration. A demonstration for measuring the speed of sound is also described. Ripple tanks are used to demonstrate Huygen's principle, interference, and parabolic reflectors. The origin of beats, so important in music theory, is discussed, along with a very detailed overview of the Doppler effect. Ultrasound, very important medically, is treated also. A very brief discussion of infrasonic waves is given. Infrasonic waves, which are outside the range of hearing since they are below 20 Hz, are only experienced as vibrations. They have recently been discussed in the popular press as being explanations behind &quot;haunted&quot; houses. The anxiety felt in some old houses is thought of as being due to infrasonic waves.<br /> The origin of the overtone series, so very important in music theory, is discussed in chapter 3. The three laws of Mersenne, which govern the fundamental frequency of stretched wires, are also treated. The Kundt's tube demonstration is used to describe the properties of longitudinal standing waves, and the famous Chladni plates are used to demonstrate standing waves in two dimensions. All throughout the chapter the properties of standing waves are related to music and musical instruments.<br /> Fourier analysis and synthesis, which is typically very formidable mathematically, is presented in chapter 4 in a manner that is very understandable to the targeted readership. The Fourier synthesis of triangular, square, and sawtooth waves, along with a pulse train, is discussed. After a treatment of Fourier spectrum of these waves, the authors discuss the factors contributing to tone quality.<br /> In chapter 5, the authors turn to more practical considerations, wherein they discuss how to create electronic music. Analog synthesizers, although very antiquated by modern standards, are used to illustrate how to combine waves to obtain special sounds or effects. The authors then immediately turn to digital synthesizers and keyboards. They discuss the Musical Instrument Digital Interface (MIDI), but the equipment they illustrate in the chapter is considerably out of date.<br /> The anatomy and physics of the human ear and voice tract are discussed in chapter 6. The diagrams they include are useful, and they discuss the &quot;place theory of hearing&quot; , which is based on thecorrelation of sound frequency with position of response along the basilar membrane. The critical band, just noticeable difference, and the limit of frequency discrimination are all discussed in the context of this theory, with several different experiments proposed to illustrate these concepts. Most interesting is the discussion on periodicity pitch, which musicians seem to have a knack for. Also interesting is the treatment of vocal formants, which are frequency regions in which harmonics have large amplitudes. Due to the element of subjectivity in hearing and listening, the connection of the material in this chapter to &quot;psychophysics&quot; and &quot;psychoacoustics&quot; is readily apparent.<br /> Most of the next chapter is out-dated since the authors discuss sound reproduction using LPs and tape recorders. However, the authors do discuss how this is done using compact disks, which though are themselves on their way out, due to the rise of the Internet, MP3 formats, and digital music files. Chapter 8 is timeless though, as the authors discuss the acoustics of auditoriums and rooms, detailing the most important acoustical characteristics that contribute to a pleasant musical experience, and some of the problems that arise in acoustical design. The last section of the chapter gives a fairly good overview of what is involved in setting up a home listening room.<br /> In chapter 9, the authors take the plunge into music theory, discussing temperament and musical pitch. The history behind these concepts is detailed, emphasizing in particular that an ideal temperament  is not available, its choice being dictated by the musical requirements at hand.  Arithmetic descriptions of the Pythagorean, just, mean-tone, Werckmeister, and equal temperaments are given.<br /> The last five chapters are specialized to the principles behind woodwind, brass, string, and percussion instruments, and the piano. The discussion is purely descriptive, but some of the physical principles studied in the first chapters of the book are applied here to give an understanding of the acoustical and musical properties of these instruments.the correlation of sound frequency with position of response along the basilar membrane. The critical band, just noticeable difference, and the limit of frequency discrimination are all discussed in the context of this theory, with several different experiments proposed to illustrate these concepts. Most interesting is the discussion on periodicity pitch, which musicians seem to have a knack for. Also interesting is the treatment of vocal formants, which are frequency regions in which harmonics have large amplitudes. Due to the element of subjectivity in hearing and listening, the connection of the material in this chapter to &quot;psychophysics&quot; and &quot;psychoacoustics&quot; is readily apparent. <br /> Most of the next chapter is out-dated since the authors discuss sound reproduction using LPs and tape recorders. However, the authors do discuss how this is done using compact disks, which though are themselves on their way out, due to the rise of the Internet, MP3 formats, and digital music files. Chapter 8 is timeless though, as the authors discuss the acoustics of auditoriums and rooms, detailing the most important acoustical characteristics that contribute to a pleasant musical experience, and some of the problems that arise in acoustical design. The last section of the chapter gives a fairly good overview of what is involved in setting up a home listening room. <br /> In chapter 9, the authors take the plunge into music theory, discussing temperament and musical pitch. The history behind these concepts is detailed, emphasizing in particular that an ideal temperament  is not available, its choice being dictated by the musical requirements at hand.  Arithmetic descriptions of the Pythagorean, just, mean-tone, Werckmeister, and equal temperaments are given.  <br /> The last five chapters are specialized to the principles behind woodwind, brass, string, and percussion instruments, and the piano. The discussion is purely descriptive, but some of the physicalprinciples studied in the first chapters of the book are applied here to give an understanding of the acoustical and musical properties of these instruments.	2003-12-20
859010:US	50702879	R1C3TMEQZHVQ70	0894645242	913036535	Equilibrium and Nonequilibrium Statistical Mechanics	Books	3	8	10	N	N	Out of date now, but motivates modern developments.	The notion of irreversibility in physical systems has occupied the time of countless researchers for nearly 130 years. This book, written by one of the major contributors to nonequilibrium statistical physics from the Brussels group, is somewhat out of date now but nevertheless could still motivate modern developments. One will find a detailed account of what was emphasized by the Brussels group at the time of publication, and some of the contributions of the late Ilya Prigogine, who passed on in May of this year. I had the privelege of doing my graduate work in Prigogine's department at the University of Texas at Austin. This book was used heavily there, and so it brings back fond memories.<br /> One distinguishing feature of this book, like all others like it, is the absence of mathematical rigor. Indeed, both equilibrium and non-equilibrium statistical mechanics has been of interest to many mathematicians, with the intent to give a rigorous mathematical foundation. This project has not been entirely successful, but the attempts have resulted in many interesting mathematical constructions. The theory of exactly solved models in statistical mechanics, the existence of solutions to the (nonlinear) Boltzmann transport equation, and the relation between statistical mechanics and quantum field theory are examples of this, and there are many others. In addition to interests in pure mathematics, statistical physics has motivated the creation of many numerical algorithms for solving and simulating many-body systems.<br /> What this book lacks in mathematical rigor is compensated for by physical insight and intuition. Semiconductor physics, plasma physics, radiological physics, and astrophysics all depend very much on the concepts that were first enunciated in this book. The search for a sound physical theory of nonequilibrium phenomena goes on, but no doubt such a theory, when it is found, will depend in large measure on what was done in this book and others like it.	2003-12-20
859273:US	50702879	R2CTESBXJSH0PC	1893554759	701590312	Bioevolution: How Biotechnology Is Changing Our World	Books	5	10	12	N	N	A realistic and optimistic apology for biotechnology	Every facet of biotechnology is fascinating, and even those embedded in it as scientist, engineer, or technican are always surprised at the rapid advancements in it that are now taking place. The biological world is an enormously complex picture puzzle, the pieces of which, thanks to powerful computational machines, advanced mathematics, and artificial intelligence, are just beginning to be fitted together. Once thought of as a purely descriptive science, biology is now quantitative, and engineers, physicists, and mathematicians are moving into it with great zeal.<br /> Readers of all backgrounds will obtain an overview of the breathtaking advances in biotechnology in this book. It is fortunate that the author is not a sycophant for the biotechnology industry, but instead gives a sound apology for it, supported by scholarly evidence and references. Indeed, the book contains 147 pages of references and hyperlinks for the reader to consult if needed. Even if the reader does not have a background in biology or genetics, the presentation is detailed enough that such a reader can obtain the much needed insight into the powerful role that biotechnology will play in the twenty-first century.<br /> Biotechnology, via transgenic strategies and other techniques in genetic engineering, has permuted the natural world, and has produced animals and plants that have surpassed, and will greatly surpass, any of the dreams of science fiction. Even more importantly, as is brought out in detail by the author, these animals and plants are bringing new ways to feed hungry populations and heal the sick. The human imagination is challenged by these discoveries, and no doubt will be even more so in the near future, as biotechnology continues its unrelenting advance.<br /><br /> Indeed, one reads of spider genes inserted in goats, producing silk in their udders, and giving us ample amounts of the strongest fiber yet known. The benefits? Tissue repair, artificial tendons, and body armor for soldiers, to name a few the author mentions... the creation of transgenic mice that secrete human growth hormone in their ejaculate...eggs of transgenic chickens that have fourteen proteins....the list goes on and on. A perusal of his references reveals many more. The database of new animals and plants keeps growing and growing.<br /> The author is fair in his assessment of viable biotechnologies, cautions against &quot;science by press release&quot;, utopianism, and alerts the reader to the legal issues that confront the use of the different biotechnologies. His confidence and optimism though are refreshing and inspiring. He ends his book with the following words:<br />&quot;The process has begun and it's accelerating. The ultimate benefits are unimaginable, while the near-term ones are incredible. Hold onto the bar in front of you and don't stand up. We're in for one heck of thrill ride.&quot;<br />He's right!oldiers, to name a few the author mentions... the creation of transgenic mice that secrete human growth hormone in their ejaculate...eggs of transgenic chickens that have fourteen proteins....the list goes on and on. A perusal of his references reveals many more. The database of new animals and plants keeps growing and growing. <br /> The author is fair in his assessment of viable biotechnologies, cautions against &quot;science by press release&quot;, utopianism, and alerts the reader to the legal issues that confront the use of the different biotechnologies. His confidence and optimism though are refreshing and inspiring. He ends his book with the following words: <br />&quot;The process has begun and it's accelerating. The ultimate benefits are unimaginable, while the near-term ones are incredible. Hold onto the bar in front of you and don't stand up. We're in for one heck of thrill ride.&quot;<br />He's right!	2003-12-20
865274:US	50702879	R2D0Q8ZXZ2M1Z0	0299019004	604029476	Science of Mechanics in the Middle Ages	Books	5	17	17	N	N	An introduction to Newton's giants.	The modern theory of mechanics, due essentially to Isaac Newton, is usually presented in textbooks as a large seventeenth perturbation that was a totally new outlook on physical motion, as one that was opposed to the Aristotelian conception that dominated before Newton's time. This view is completely refuted in this book, as the author gives a detailed overview of the struggles of the medieval physicists to understand the nature of motion. Clearly their thinking on mechanics influenced greatly the work of Galileo and Descartes, and consequently that of Newton. Even though some of their ideas of the medieval scientists were based on mistaken notions, many of them had just enough truth to allow the correct formulations to be accomplished later. The author gives a fascinating discussion of how medieval mechanics, which was predominantly Aristotelian with \\"some traces of Archimedean character\\" was subjected to so many changes that it eventually was undermined, forcing a new outlook.<br /> The author explains that it was the work of the French scientist Pierre Duhem  that first took a look at the contributions of the medieval scientists. Duhem's work though, according to the author, was flawed, in that it inputed too many modern viewpoints, such as a theory of inertia, to the medieval schoolmen, especially to the Oxford professor John Buridan via his impetus theory. The author admires greatly though the work of Anneliese Maier, who greatly scrutinized the work of Duhem, and the author draws greatly on her work. The translations of the Greek works due to Islamic scholars clearly allowed the medieval scholars to engage in their thinking on Greek mechanics.<br /> Most interestingly, the mechanics of the inclined plane was, as the author shows, solved correctly in the Middle Ages. He also shows that the concept of virtual velocities had its origins in Aristotle's Mechanics and the Mechanics of Hero, and that this concept was applied in the Middle Ages to obtain mathematical proofs of the law of levers and theorems of the inclined plane, setting the stage he says for the latter work of Bernoulli and Lagrange. The thirteenth century saw the origin of the thinking of velocity as a magnitude.<br /> The author attributes the real advances in kinematics in medieval times to the academicians Thomas Bradwardine, William Heytesbury, Richard Swineshead, and John Dumbleton of Merton College in Oxford, who developed concepts of instantaneous velocity and analyzed various concepts of acceleration. The author attributes these advances partly to philosophical discussion on the \\"intension and remission of forms\\", which led these scholars to differentiate between  the \\"quality\\" of velocity from the \\"quantity\\" of velocity. These scholars proved the  somewhat long-winded \\"Merton theorem of uniform acceleration\\", which gave an equality with respect to space traversed in a given time a uniformly accelerated movement and a uniform movement where the velocity is equal to the velocity at the middle instant of the time of acceleration. The author attributes a restatement of this theorem to Galileo and is fundamental to his theory of freely falling bodies. Galileo used a kind of two-dimensional geometric proof for his law of free fall that was similar to the proof of the Merton theorem by medieval scholars. Thomas Bradwardine also presented a kind of law of force that related velocity to force and resistance. This law, argues the author, related velocity to instantaneous changes, foreshadowing the use of differential equations in modern mechanics.<br /> The impetus theory of John Buridan in the fourteenth century takes on a special status in the book, as he views it to a large extent as the origin of the modern view of inertia. Buridan's description was in terms of the quantity of matter in the projectile, similar to the Newtonian notion of momentum. Interestingly though, Buridan's thinking was abandoned, according to the author. Buridan's thinking though is definitely not Aristotelian, and was a symptom of the end of the latter.<br /> The lesson to be learned from the book is that despite the errors of the medieval scholars, their efforts eventually brought about the correct view of physical motion. Researchers in all areas of science need to keep in mind that although their ideas may be shown to be weak and not compatible with experiment, as shown later, their research restricts what is possible, and insures the same mistakes will not be repeated. The discipline of thought required by the medieval scholars, and that of modern researchers, is certainly something that is to be admired and be grateful for.s definitely not Aristotelian, and was a symptom of the end of the latter. <br /> The lesson to be learned from the book is that despite the errors of the medieval scholars, their efforts eventually brought about the correct view of physical motion. Researchers in all areas of science need to keep in mind that although their ideas may be shown to be weak and not compatible with experiment, as shown later, their research restricts what is possible, and insures the same mistakes will not be repeated. The discipline of thought required by the medieval scholars, and that of modern researchers, is certainly something that is to be admired and be grateful for.	2003-12-14
865951:US	50702879	R3KN8EGJ5BE2GC	038524388X	274159559	The Passion of Ayn Rand	Books	4	10	16	N	N	A fascinating view from an insider	There are only a few people in the literature who have expressed the optimism and passion for living as Ayn Rand. There are many of course who are unknown and possess the same optimism, as the latter is a natural state of humankind. When these individuals are exposed to the literature of Rand, they identify enthusiastically with her characters and philosophy. It is for this reason that the literature of Rand should be classified more as realism than romanticism: it is an accurate statistical sampling of the predominant attitude in human history. Rand's characters are not larger than life but rather completely lifelike. One can meet them on a daily basis.<br /> The author of this book is one of these individuals, and she gives a detailed biography of Rand that gives touching insight into her character and humanity. From Alice Rosenbaum in Soviet Russia through the Fountainhead, to Atlas Shrugged and the formulation of the Objectivist movement, and finally to her death in 1982, the reader gets an inside view of what it was like to interact with Rand on a regular basis. It should be of no surprise to the reader to hear of Rand's mistakes and her faults. Her brilliance, along with her flaws, are part of being human. Indeed, the making of mistakes is an essential part of the cognitive process.<br /> It is the author's emphasis on the humanity of Rand that makes this book such a pleasure to read. There are many interesting anecdotes and commentary that give the reader special knowledge on the psychology of ethics and the contention that accompanies political or philosophical movements. It is not surprising to hear of the difficult emotional experiences that the author and her former husband had when interacting with Rand and her inner circle. Whenever the human intellect is as focused as it was in these individuals, the resulting roller coaster ride of confidence and insecurity is an immediate corollary.<br /> The author still expresses affection and admiration for Rand at the end of the book. Spending a great part of her life close to Rand gave the author a unique view of Rand's idiosyncracies and intellectual and emotional conflicts. When talking about Rand's captivating eyes, the author remarks that she never observed her looking inward, with the goal of sorting out her inner feelings. This is totally believable, for Rand did not have to engage in too much introspection: the characters in her novels expressed these inner feelings, and with a vengeance.nd at the end of the book. Spending a great part of her life close to Rand gave the author a unique view of Rand's idiosyncracies and intellectual and emotional conflicts. When talking about Rand's captivating eyes, the author remarks that she never observed her looking inward, with the goal of sorting out her inner feelings. This is totally believable, for Rand did not have to engage in too much introspection: the characters in her novels expressed these inner feelings, and with a vengeance.	2003-12-13
866038:US	50702879	R35ZLOGRRJKRNR	1563840332	513203273	Political Correctness	Books	4	6	6	N	N	A quick but accurate view of the 1990's university	It is perhaps a relief that this book is now out of print, for this might indicate that the subject matter is somewhat out of date and no longer of relevance. On the other hand, it might mean that the book no longer describes a novel phenomenon, but instead one that is now predominant in all areas of cultural, academic, and political life. &quot;Political correctness&quot; in both content and in terms of legal boundaries may now be so entrenched that no one even questions its morality or legitimacy.<br /> Have we become clones of each other in ethical, legal, and political thought since this book was first published in 1992? I don't think so, but anyone who was a teacher or professor in the late 1980's and 1990's should understand very well what a fight it was to maintain intellectual independence in the universities and colleges of the nation, and this was pretty independent of geographical location. Any deviation from the narrow bandwidth of political correctness was met with highly vituperative diatribe and personal attacks. Those of us who were unprepared for this naturally wondered whether anyone else was experiencing the same. Therefore books like these were welcome additions to our libraries, and we read them as a sort of catharsis.<br /> One might interpret the current hate and anger literature that is proliferating the best seller lists as a reaction to the politically correct movement. Whether it is or not is a question for social research to answer, and this research must hold to the most rigorous of scientific standards. In addition, any answer to the dogmas and principles of political correctness must at all times be calm and rational and avoid the intense smear campaigns against individuals and institutions that are characteristic of the anger literature of today. The author of this book has taken such an approach, and the result is a book that documents, albeit sometimes purely anecdotally, the intensity of the politically correct movement in the universities of the 1980's and 1990's.<br /> If we are to measure progress by the degree to which we accept and tolerate true diversity, we would be correct to do so. But diversity, as the name implies, means tolerance of ALL ideas, no matter how corrupt, no matter how evil, and no matter how irrational we believe them to be. That does not mean we need to finance ideologies that disagree with our own. It does not mean that we have to associate with people whose ideas disagree with our own. It does mean that whatever language they use, in whatever form, and no matter how disgusted we are with it, it should not be eliminated from our books and libraries. In fact, armed with the incredible instrument called the brain, we should welcome all ideas confronting us, and then sift through them with infinite curiosity, rejecting those that don't meet the evidence, and accepting those that do. The ones that are rejected will still be viewed as past sign-posts, as mistakes that are essential to human cognition. The ones that are accepted will stand or fall on the weight of future evidence. Ironically, it is the ideas that are truly diverse, that seem to apply to many different situations and contexts, that survive intense scrutiny and become timeless.iversities of the 1980's and 1990's.<br /> If we are to measure progress by the degree to which we accept and tolerate true diversity, we would be correct to do so. But diversity, as the name implies, means tolerance of ALL ideas, no matter how corrupt, no matter how evil, and no matter how irrational we believe them to be. That does not mean we need to finance ideologies that disagree with our own. It does not mean that we have to associate with people whose ideas disagree with our own. It does mean that whatever language they use, in whatever form, and no matter how disgusted we are with it, it should not be eliminated from our books and libraries. In fact, armed with the incredible instrument called the brain, we should welcome all ideas confronting us, and then sift through them with infinite curiosity, rejecting those that don't meet the evidence, and accepting those that do. The ones that are rejected will still be viewed as past sign-posts, as mistakes that are essential to human cognition. The ones that are accepted will stand or fall on the weight of future evidence. Ironically, it is the ideas that are truly diverse, that seem to apply to many different situations and contexts, that survive intense scrutiny and become timeless.	2003-12-13
869682:US	50702879	R3IU5CGF5VWK24	0672527251	448139820	Philosophy: Who Needs It	Books	4	9	12	N	N	One of the best apologies for philosophy in the literature	Many years ago, a colleage of mine observed me reading this book and remarked: &quot;Yeah, I agree, we don't need it!&quot;. Clearly he was not aware of the content of the book, and his reaction could be viewed as expressing a typical attitude about philosophy. Philosophy is to a large extent viewed as somewhat inapplicable to the ordinary affairs of life, and it's proper place is in the university, to be done alone from the proverbial armchair.<br /> The author of this book argues that this is not the case, that philosophy is essential in all phases of human experience, and that its exclusion will result in grave difficulties. Apologies for philosophy are rare in the philosophical literature, but this author gives a good one, done however, totally in the context of philosophy itself. The author stops at giving the practice of philosophy justification from any other fields of endeavor, such as science. The author though could have given an even better case for doing philosophy if she would have taken a scientific viewpoint, and gathered scientific evidence on just what constitutes true human needs.<br /> The title of the book is based on an address that the author gave to the graduating class of Westpoint in March 1974. The rest of the book is a collection of articles by the author that were included by the executors of her estate after her death in 1982. There are many interesting discussions in these articles, as there are places where the author goes astray and engages in dialog that is too vituperative to be characterized as rational argument. Her vicious attacks on the philosopher Immanuel Kant, in particular, are very disconcerting, even to those who might disagree with his ideas.<br /> Philosophy as a profession still exists of course, but its content is changing rapidly, and it continues to be viewed by some as primarily an academic activity. But due to the tremendous explosion of science and technology, professional philosophers have moved away from purely academic positions and have applied their high intelligence and unique abilities to matters of a more scientific nature. Industry in particular welcomes their participation, particularly in the areas of biology and medicine, due to the ethical dilemnas that are confronted daily in these professions. In addition, philosophers have decided to contribute their talents to assist in the building of intelligent machines, and have given much insight on just how this is to be done.  Clearly both philosophy and these professions need each other.ly academic positions and have applied their high intelligence and unique abilities to matters of a more scientific nature. Industry in particular welcomes their participation, particularly in the areas of biology and medicine, due to the ethical dilemnas that are confronted daily in these professions. In addition, philosophers have decided to contribute their talents to assist in the building of intelligent machines, and have given much insight on just how this is to be done.  Clearly both philosophy and these professions need each other.	2003-12-10
873515:US	50702879	R3ANCTW9GOBJII	0486616304	432680204	Axiomatic Set Theory (Dover Books on Mathematics)	Books	4	42	47	N	N	Still interesting...and still important.	One does not hear about set theory too much these days, no doubt due to the de-emphasis of foundational discussions in mathematics. Foundational questions of course were the focus of much attention in mathematics in the early twentieth century, this taking place because of the many paradoxes in set theory and due to the influence of the philosophers. Set theory, the theory of types, and mathematical logic are still very important though in computer science and in artificial intelligence, due to the needs in these fields for knowledge representation, computational models of intelligence, and automated reasoning. This book could serve to introduce these topics or as an historical reference to the issues as they were hotly debated in the last century.<br /> The first chapter gives an informal introduction to the notion of a set, first-order predicate logic (notions of bound and free variables and quantification), and the Zermelo-Fraenkel axioms of set theory. The author describes the difficulties in the &quot;axiom of abstraction&quot; in the writings of Frege as pointed out by Bertrand Russell. It is pointed out that the axiom of abstraction is in fact an infinite collection of axioms, thus motivating the concept of an &quot;axiom schema&quot;. The axiom schema that is used explicitly in the book is the &quot;axiom schema of separation&quot; due to Ernst Zermelo, which he formulated in order to make precise the notion of a statement as being &quot;definite&quot;. More of the set-theoretic paradoxes are discussed, along with their classification due to F.P. Ramsey into &quot;linguistic&quot; and &quot;semantical&quot; ones.<br /> The advantage of an older book on set theory is that more of the underlying details are explained, instead of just being formally developed. The author gives a thorough discussion of the concepts throughout the book, beginning with an organized development in chapter 2. He begins immediately with discussing the distinction between the object language and metalanguage, and the symbols to be used in the object language: constants, variables, logical connectives, quantifiers, and grouping symbols. These symbols are used to construct formulas, a subclass of which, the primitive formulas, are defined recursively, and which all formulas in the object language can be expressed in terms of. Throughout the book though the author uses additional notation that allows formulas not to be written in terms of primitive formulas. This is done to make the text more readable, but he requires that the added notion satisfy the criterion of eliminability and non-creativity. The notion of a set is defined formally, and then the axiom of extensionality, which gives a criterion for two sets being equal, and the axiom schema schema of separation. The pairing axiom, which gives the existence of a non-empty set; the sum axiom, which gives the existence of the union of a family of sets; the power set axiom, which gives the notion of the set of all subsets of a set; and the axiom of regularity, which prohibits infinite descending sequences of sets, are all discussed in detail.<br /> Chapter 3 treats relations and functions, so important not only in mathematics but in computer science, especially in the theory of relational databases. Then in chapter 4, the author begins a study of cardinality and the cardinal numbers, proving that the finite cardinal numbers have the properties of the natural numbers, as one would expect. The author is careful to point out the need for the axiom of cardinal numbers in this study. Chapter 5 then goes into the theory of ordinal numbers, wherein it is emphasized that no special axioms are needed for the development of this theory. The author is also careful to note the special problems that arise in defining the arithmetic of natural numbers, such as defining addition recursively without using set theory. But including the apparatus of set theory does allow the replacement of the recursive definition by a proper definition. The axiom of infinity is brought in to permit the construction of arithmetical operations as certain sets. The theory of denumerable sets is then discussed, followed by one of the most fascinating concepts in all of mathematics: the theory of transfinite and infinite cardinals.<br /> The author then shows that set theory can allow the construction of the real numbers, which takes place after the construction of the rational numbers.  The famous &quot;Dedekind cut&quot; is discussed, along with the method of Cantor, which defines real numbers as equivalence classes of Cauchy sequences of rational numbers. The author uses the Cantor approach in the rest of the book. He also proves the famous Cantor theorem on the non-denumerability of the real numbers, and gives a brief discussion of the Continuum Hypothesis.<br /> Chapter 8 then gives an overview of the fascinating topics of transfinite induction and ordinal number theory. Recursion theory makes its appearance again in the transfinite recursion for ordinal numbers, using the axiom schema of replacement. The non-commutativity of ordinal addition and multiplication is brought out, and the falsity of Fermat's Last Theorem and Goldbach's Hypothesis in ordinal number theory is shown. The author then shows to what extent cardinal number theory can be done without using special axioms by defining cardinal numbers as initial ordinals. The axiom of choice however is needed to show that every set has a cardinal number. The author then restates the Zermelo-Fraenkel axioms in their final form at the end of the chapter.<br /> The final chapter gives an overview of the most controversial topic in all of set theory, if not in all of mathematics: the axiom of choice. The author shows that the use of this axiom allows one to prove that an infinite set has a denumerable subset, and he shows the equivalence of the axiom of choice with the numeration theorem, the well-ordering theorem, Zorn's lemma, and the law of trichotomy. The counterintuitive Banach-Tarski paradox is discussed, and the author shows the existence of axioms which imply the axiom of choice.n by a proper definition. The axiom of infinity is brought in to permit the construction of arithmetical operations as certain sets. The theory of denumerable sets is then discussed, followed by one of the most fascinating concepts in all of mathematics: the theory of transfinite and infinite cardinals. <br /> The author then shows that set theory can allow the construction of the real numbers, which takes place after the construction of the rational numbers.  The famous &quot;Dedekind cut&quot; is discussed, along with the method of Cantor, which defines real numbers as equivalence classes of Cauchy sequences of rational numbers. The author uses the Cantor approach in the rest of the book. He also proves the famous Cantor theorem on the non-denumerability of the real numbers, and gives a brief discussion of the Continuum Hypothesis. <br /> Chapter 8 then gives an overview of the fascinating topics of transfinite induction and ordinal number theory. Recursion theory makes its appearance again in the transfinite recursion for ordinal numbers, using the axiom schema of replacement. The non-commutativity of ordinal addition and multiplication is brought out, and the falsity of Fermat's Last Theorem and Goldbach's Hypothesis in ordinal number theory is shown. The author then shows to what extent cardinal number theory can be done without using special axioms by defining cardinal numbers as initial ordinals. The axiom of choice however is needed to show that every set has a cardinal number. The author then restates the Zermelo-Fraenkel axioms in their final form at the end of the chapter.  <br /> The final chapter gives an overview of the most controversial topic in all of set theory, if not in all of mathematics: the axiom of choice. The author shows that the use of this axiom allows one to prove that an infinite set has a denumerable subset, and he shows the equivalence of the axiom of choice with the numeration theorem, the well-ordering theorem, Zorn's lemma, and thelaw of trichotomy. The counterintuitive Banach-Tarski paradox is discussed, and the author shows the existence of axioms which imply the axiom of choice.	2003-12-07
877994:US	50702879	R2RNEB9C0UCQ8N	0415254086	411173754	Tractatus Logico-Philosophicus (Routledge Classics) (Volume 123)	Books	4	3	7	N	N	Its influence continues	Considering its status in philosophy, linguistics, and artificial intelligence, it is amazing that Wittgenstein could not find a publisher for this book. It took the efforts of Bertrand Russell, his teacher, to get it into publication, and Russell writes the introduction to this edition. The book will no doubt continue to be read and scrutinized in the 21st century, and its utility as a philosophy will be debated intensely.<br /> The book has been viewed by some to be the &quot;foundations&quot; of artificial intelligence. Whether such a opinion is justified is a matter of debate, indeed, it is debatable whether artificial intelligence, or any field of endeavor, needs any philosophical foundations at all. That philosophy is a foundation for all human knowledge has been held by many as an axiom, and this author to a large extent is one of these. But Wittgenstein's view of this foundation is not as comprehensive as some schools of philosophy. For him, the role of philosophy is the logical clarification of thoughts, and philosophy should not be thought of as an independent theory but an activity. If one is to write a philosophical treatise, then it should consist, in Wittgenstein's view, of a collection of &quot;elucidations&quot;.<br /> Even more interesting is Wittgenstein's view of philosophy in relation to natural science. His view could be described as saying that philosophy is a kind of &quot;side constraint&quot; on the what he called &quot;the disputable sphere of natural science.&quot; The author does not give explicit examples of this, and therefore his claims here should be viewed with some skepticism. But Wittgenstein is not the only philosopher to make these kinds of assertions about philosophy and science. The problem though is that despite the dogmatic insistence of some philosophers, the efficacy of philosophy in providing clarification to scientific issues has not been documented in any kind of detail.<br /> As a school of thought, logical empiricism and the positivistic trends it motivated, are perhaps the closest to what one might call a &quot;common sense&quot; philosophy. It shifted the emphasis on the intrinsic meaning of concepts to how concepts &quot;do their jobs&quot;. Since concepts are phrased in language, then it is natural to assume that language should take on special, if not predominant, emphasis in philosophy. Philosophy as a &quot;language game&quot; is thus the main point of this book, and of course is the legacy of its author. The influence of this book continues, not so much in philosophy, and even less in physical science, but definitely in the field of artificial intelligence: the syntax and semantics of the languages used by the machines to think and to communicate with each other and their human tutors.m and the positivistic trends it motivated, are perhaps the closest to what one might call a &quot;common sense&quot; philosophy. It shifted the emphasis on the intrinsic meaning of concepts to how concepts &quot;do their jobs&quot;. Since concepts are phrased in language, then it is natural to assume that language should take on special, if not predominant, emphasis in philosophy. Philosophy as a &quot;language game&quot; is thus the main point of this book, and of course is the legacy of its author. The influence of this book continues, not so much in philosophy, and even less in physical science, but definitely in the field of artificial intelligence: the syntax and semantics of the languages used by the machines to think and to communicate with each other and their human tutors.	2003-12-04
882906:US	50702879	RE39126BZB0FK	0380977931	521794679	T2: The Future War	Books	2	3	8	N	N	Boring	For those working in the field of artificial intelligence, it is perhaps disconcerting that this field has been represented in stories and movies in the fashion that it has. It might be difficult to sell a book or a movie ticket though if one were to guide its plot with what is currently being accomplished in artificial intelligence. There is no doubt that robotics still remains a focus of research, and many identify the field of artificial intelligence with the development of robots. However, there have been major advances in artificial intelligence in the last decade in areas such as financial engineering, Ecommerce, bioinformatics, music composition, and network engineering. Artificial intelligence has thus found practical application, but these applications don't make for nice plots in movies and books of fiction.<br /> That being said, it is still fun to read the stories and attend the movies that engage in the pure fantasy of robot armies and humanity's attempt to engage themselves in a &quot;war against the machines.&quot; Viewing these stories or movies as entertainment though results in high expectations in their ability to thrill readers or fill them with dread. At least for me, this book did not do that. I personally cannot think of anything more terrifying than to be engaged in a confrontation with entities that do not sleep, have no conscience, and whose sole function is to see me and other humans dead. This story though did not fill me with any apprehension or any type of disquieting feeling when reading it. The machines did not occupy enough space in the story, but instead were merely lurking in the background. There were conflicts of course between them and the human resistance led by John Connor, but the battles, as described in the story, were not very exciting. The numerous scene changes in the story exacerbated this I think. The author wanted evidently to emphasize that the war against the machines was a global conflict, and so the story kept switching between various geographic locales. A few concentrated, intense battles in a few locations would better do the job of capturing the reader's attention and motivate empathy with the characters.<br /> The enormous psychological pressure on humans that would be engaging in a machine war is not brought out in the story. Interestingly though, the author portrays the anti-technological Luddites as being tricked by the machines in supporting their war against humanity. The Luddite voices are being heard all over the globe now, not only against machine intelligence but practically every technological advance, and it is perhaps a carthasis to see them protrayed as they are in the story. Whatever their motivation to be engaged in an anti-technological crusade, it is doubtful that their efforts will reach a level of fruition that is satisfying to them. With faster processing, more sophisticated software, and with increasing applications that are driven by the needs of industry, business, and the military, the field of artificial intelligence continues to advance. One can easily imagine scenarios, based on these applications, where thinking machines play a dominant role in human affairs, and perhaps may get to the point where their autonomy becomes a threat to humankind. It is doubtful though that artificial intelligence will be discontinued as a technology. Stories like the one in this book will continue to entertain with various degrees of success. The real story of machine intelligence is much more interesting though...indeed much more.itching between various geographic locales. A few concentrated, intense battles in a few locations would better do the job of capturing the reader's attention and motivate empathy with the characters. <br /> The enormous psychological pressure on humans that would be engaging in a machine war is not brought out in the story. Interestingly though, the author portrays the anti-technological Luddites as being tricked by the machines in supporting their war against humanity. The Luddite voices are being heard all over the globe now, not only against machine intelligence but practically every technological advance, and it is perhaps a carthasis to see them protrayed as they are in the story. Whatever their motivation to be engaged in an anti-technological crusade, it is doubtful that their efforts will reach a level of fruition that is satisfying to them. With faster processing, more sophisticated software, and with increasing applications that are driven by the needs of industry, business, and the military, the field of artificial intelligence continues to advance. One can easily imagine scenarios, based on these applications, where thinking machines play a dominant role in human affairs, and perhaps may get to the point where their autonomy becomes a threat to humankind. It is doubtful though that artificial intelligence will be discontinued as a technology. Stories like the one in this book will continue to entertain with various degrees of success. The real story of machine intelligence is much more interesting though...indeed much more.	2003-11-30
884051:US	50702879	R2HR3MB6NKCLTY	0801858305	447811227	Of Grammatology	Books	3	14	27	N	N	Pure Dionysian intoxication...absolutely pure	How long can a philosophical movement last before it exhausts its methodology and goals? Does it take decades or centuries, or maybe even thousands of years? A more appropriate question might be: how long can philosophy itself last before it is labeled as superfluous and subjected to the questioneering of an impatient and caustic interlocutor? Philosophy is usually presented as a conglomeration of schools of thought, each of these having a well-defined set of tools for investigating ultimate foundations of truth and reason. Its practitioners have been guarded in their systemization. Criticizing each other vociferously, they all agree though that philosophy has intrinsic worth and should be sustained. After all, philosophy sets the foundation for science, ethics, art, culture, and politics. To end it would pull the rug out that lies underneath the table of civilization. To end philosophical discourse would make us all hopeless wanderers with no discernable direction or purpose.<br /> A colleague once told me that this book should be read as a reaction against French structuralism. This may be true, but I see it as a literary project to indulge in the excesses of Nietzschean/Dionysian ecstacy. It is an attempt to take a break from philosophy, to put on oversized white shirts and with a sloppy oil paintbrush, disfigure the classical works of Western philosophy. It is, to quote the translator of the book, an attempt to become \\"intoxicated at the prospect of never hitting bottom\\". The movement of deconstruction reacts against the stealth of the philosophers, who try to cover their literary tracks. Deconstruction exposes the so-called solidity of philosophical texts, exposing the hierarchies they construct as fragile, and removing them with delight.<br /> The translator has written a superb preface to this book (and also explains why such a preface is appropriate). The Hegelian/Nietzschean/Freudian/Husserlian influences are readily apparent in the author, as the translator brings out with great clarity. Deconstruction has become almost a school of thought in itself now, and it was making the front pages of newspapers fifteen years ago. If one objects that deconstruction should be examined using its own strategies, that its practitioners should become themselves \\"bricoleurs\\", the deconstructionists agree. The translator explains this as both a \\"search for a foundation\\" and as \\"pleasure of the bottomless\\". The process of deconstruction thus acts against itself, as well as others. It is never to be arrested, for no text can be deconstructed in its entirety. Thus deconstruction permits no ending, just as no book can claim an ending in its view. The logocentrism of Western philosophy is in its scheme mere word salad, and it acts against it with glee.<br /> The creative process is disorganized, intuitive, nonlinear, and frequently executes a random walk in conceptual space. It grabs at every straw of insight, and sometimes desparately makes claims about these ideas that uproot them from their origins. In addition, the codification of these ideas in the written word sometimes contains remnants of the creative process. Thus an oral tradition is frequently needed to accompany these texts, to explain and interpret what has been lost in the printed page. Hence the spoken and the written are mutually symbiotic. The deconstructionists though fail to see this symbiosis, and ignore the oral tradition. They view this tension in texts as a window of opportunity, and spend inordinate amounts of time wandering in them, getting lost in the process. As they read, they make decisions rapidly and on-the-fly, and they are nervous and guarded at all times against succoumbing to the tyranny of logic and order. But they inadvertently find resting points, in spite of their attempts not to. Their texts of deconstruction thus become mere diaries of their journeys, tiresome to read, and completely inert and useless.tor brings out with great clarity. Deconstruction has become almost a school of thought in itself now, and it was making the front pages of newspapers fifteen years ago. If one objects that deconstruction should be examined using its own strategies, that its practitioners should become themselves \\"bricoleurs\\", the deconstructionists agree. The translator explains this as both a \\"search for a foundation\\" and as \\"pleasure of the bottomless\\". The process of deconstruction thus acts against itself, as well as others. It is never to be arrested, for no text can be deconstructed in its entirety. Thus deconstruction permits no ending, just as no book can claim an ending in its view. The logocentrism of Western philosophy is in its scheme mere word salad, and it acts against it with glee. <br /> The creative process is disorganized, intuitive, nonlinear, and frequently executes a random walk in conceptual space. It grabs at every straw of insight, and sometimes desparately makes claims about these ideas that uproot them from their origins. In addition, the codification of these ideas in the written word sometimes contains remnants of the creative process. Thus an oral tradition is frequently needed to accompany these texts, to explain and interpret what has been lost in the printed page. Hence the spoken and the written are mutually symbiotic. The deconstructionists though fail to see this symbiosis, and ignore the oral tradition. They view this tension in texts as a window of opportunity, and spend inordinate amounts of time wandering in them, getting lost in the process. As they read, they make decisions rapidly and on-the-fly, and they are nervous and guarded at all times against succoumbing to the tyranny of logic and order. But they inadvertently find resting points, in spite of their attempts not to. Their texts of deconstruction thus become mere diaries of their journeys, tiresome to read, and completely inert and useless.	2003-11-29
885272:US	50702879	RZT92EPR9KXBA	0452283760	594264062	The Fountainhead (60th Anniversary Edition)	Books	5	32	42	N	N	The best novel ever written.	If there is any piece of literature that accurately reflects the best in humankind it is this one, and this is done using only one character. It might perhaps be difficult at first to accept that the incredible achievements of the human species could be exemplified in only person, but the author succeeds in doing so in this book, giving the reader a character that is both likeable and very human. Howard Roark stands in clear contrast to the other three in the book, who represent the temporary flaws in human conduct. The character and actions of these other three reflect what is most rare in human experience. Their outlooks and goals are shown in the story to lead to physical or emotional disintegration, a consequence of their sustained efforts to follow paths that deviate from those that are most resonant with the human psyche. The author's message is clear: sustained behavior such as that practiced by these individuals leads to severe dysfunction.<br /> The sly manipulations of Ellsworth Toohey leads to his disgrace; the parasitism of Peter Keating results in his mental breakdown; and the power cravings of Gail Wynand make him powerless. Toohey fails because he overestimates his abilities to charm and mesmerize, and underestimates the power of a mind that cannot be bought, that cannot be corrupted, that is creatively rich and dogmatically rational. Keating fails because he cannot comprehend, and has no understanding, of what it truly takes to achieve greatness. Seduced by fame and recognition, his mind polluted by the pettiness of social climbing and the hitchhiking of another's ideas, he cannot sustain, tragically, any measure of human dignity and self-esteem. Wynand fails because he is seduced by the quantity of his readers and is ultimately fooled by their independence. He gives in to the crippling monster of cynicism, wiping out forever any chance at obtaining the real power of personal integrity and focused intelligence.<br /> Roark succeeds because of his deep awareness and understanding of the essential needs of human experience. Creative accomplishment, originality of ideas and goals, and sustained concentration are the proper tools of the human mind, and like food and water, these cannot be ignored. Roark has penetrating insight into what it means to be really human. He is comfortable with himself and with others who believe the same. He knows that conflict will arise when interacting with those that don't, but he knows that such conflicts are temporary. A mediocre mind cannot compete with a competent one. Deception cannot compete with truth.<br /> Roark stands on his building at the end of the story, and this ending is appropriate. He symbolizes the many in human history who have stood on the  buildings of art, literature, science, philosophy, technology, and music. The names of these individuals don't always get put in the history books, but the impact of their genius is overwhelming. Although they may be unknown, they are not rare, and it is these individuals who move the world.eep awareness and understanding of the essential needs of human experience. Creative accomplishment, originality of ideas and goals, and sustained concentration are the proper tools of the human mind, and like food and water, these cannot be ignored. Roark has penetrating insight into what it means to be really human. He is comfortable with himself and with others who believe the same. He knows that conflict will arise when interacting with those that don't, but he knows that such conflicts are temporary. A mediocre mind cannot compete with a competent one. Deception cannot compete with truth. <br /> Roark stands on his building at the end of the story, and this ending is appropriate. He symbolizes the many in human history who have stood on the  buildings of art, literature, science, philosophy, technology, and music. The names of these individuals don't always get put in the history books, but the impact of their genius is overwhelming. Although they may be unknown, they are not rare, and it is these individuals who move the world.	2003-11-28
888438:US	50702879	R2HBIMQ7SYM8O2	0684819066	87039745	A Beautiful Mind : A Biography of John Forbes Nash, Jr.	Books	5	7	8	N	Y	The best biography ever written	Mathematicians have received surprising attention in the last decade, some of this being negative and some positive. This book intends to give attention to a mathematician that is accurate as well as interesting. It succeeds in this in every way, and allows the reader an inside view of the mind of one of the most noted mathematicians of the twentieth century. It is now a cliche to say that when a book is good that one &quot;cannot put it down&quot;, but this is what happened to me when I began to read it. It is a totally absorbing account of the life and mathematical discoveries of John Nash, and this is no doubt due to the fact that the biographer has solid technical competence. It would be very helpful to the entire mathematical community if the lives of the best of our mathematicians would be documented as well as Nash's is here. Even from a solely didactic point of view, the mathematics of the mathematician can be better understood when it is put in an organized, historical perspective.<br /> There are many interesting insights and anedotes throughout the book. JN was apparently labeled as an &quot;underachiever&quot; by his elementary school teachers, with his worse grades being in music and mathematics. It is no surprise to learn that books were his best friends as a child, but it is interesting to learn that he spent much of his childhood performing experiments in his home laboratory. Mathematics is not really an empirical science, and Nash's mathematical achievements rank more as pure than applied. Widely read, he also evidently preferred solving problems &quot;in his head&quot; rather than via the ubiquitous pencil and paper.<br /> The biographer also gives interesting insights into the kind of university Princeton was at the time JN entered. In the Princeton department of mathematics, &quot;Grades meant nothing&quot; she quotes Solomon Lefschetz as saying. Emily Artin, the famous algebraist at Princeton at the time, apparently did not like Nash, clashing with him frequently in the &quot;common room&quot;, and recommended that Nash be thrown out of Princeton. Also, the reader learns that game theory was viewed as somewhat &quot;declasse&quot; at Princeton, which is even more interesting considering its importance now in business and in research in artificial intelligence. The formalist school of mathematics held center stage at the time, and the biographer labels Nash's paper on the topic &quot;one of the first to apply the axiomatic method to a problem in the social sciences&quot;. John von Neumann apparently thought his results &quot;trivial&quot; though, says the biographer. A whole chapter is spent on Nash's determination to avoid military service, for reasons that entering the military would preclude the obtaining of a prominent academic position.<br /> Nash's bisexuality is perhaps a surprise, if compared to the rest of the mathematical community, who are in general heterosexual, then and now. Attitudes about homosexuality cost him a job according to the biographer. In the current age of political correctness and diversity-with-bias, this would be unheard of. With reference to his personal life, Nash's relationship with Alicia was delineated beautifully by the biographer. Even a mind so given to abstractions as Nash's needs the concreteness and warmth of human interaction. The perplexing age anxiety of mathematicians is also brought out in the book. A perusal of the brilliant work of the over-40 Edward Witten and Andrew Wiles should of course put this (crippling) anxiety to rest. Nash's decision to work on the Riemann Hypothesis would perhaps, if he had continued to work on it, brought him to middle-age and beyond.<br /> One could perhaps speculate on what Nash would have achieved mathematically if mental illness would not have crippled him. Such speculation is superfluous though, as the contributions he made are more than most individuals have or could have made. His life hitherto has been one of overwhelming success, and his mind to be viewed with quiet envy.ng success, and his mind to be viewed with quiet envy.	2003-11-25
889380:US	50702879	R2MBR19ZLRPWP6	0451163931	544774038	The Virtue of Selfishness: Fiftieth Anniversary Edition	Books	5	0	1	N	N	The best ethical formulation in the history of philosophy.	Many years ago while discussing the Chrysler bail-out with two colleagues, they mentioned that Lee Iacoca, in pursuing the government action, was pursuing his &quot;self-interest&quot;. The discussion on government interference in economic matters interestingly took place in the context of a debate on the contents of this book. Listening to me defend its concept of self-interest and why I thought humans should indeed pursue their self-interest, they seem perplexed that I was objecting vociferously to the Chrysler bail-out. After all, was not Lee Iacoca pursuing his self-interests when he arranged the government bail-out?<br /> This conversation, done with two people who are now fairly well-known philosophers, illustrates the deep bias surrounding the concept of self-interest. The fact that Lee Iacoca thought he was pursuing his self-interest in arranging the bail-out does not mean that it really was in his self-interest. If a person is lost in a forest and starving, and then spots a mushroom he/she believes is nutritious but in fact is poisonous, are we to accept that the eating of the mushroom is in the person's interest? The fact that we believe something is in our interest does not make it so.<br /> The author of this book makes a brilliant case for the ethics of self-interest, with this concept being rooted in the organism's identity. It is the characteristics of the organism that determine what is good or bad for it. Ethical values arise when the organism can exhibit choice over a collection of alternatives, and is distinctly self-aware of these choices. And due to the complexity of both the organism and the environment, the context will determine the choices available to the organism. An Eskimo in the Artic North certainly faces different choices than an individual living in the jungles of the Amazon. In addition, because the organism is not omniscient, the choices made may act to the organism's detriment. Adaptation takes time, and the organism will suffer or even die if bad choices are made.<br /> Organisms with a self-awareness of choices, or moral agents, are thus governed by what characteristics they possess, and the environments in which they find themselves. The author of this book argues brilliantly for a morality of self-interest, and her care and skill in elucidating the concept of self-interest and ethics in general, makes this book the best formulation of ethics in the history of philosophy.  In addition, the book could be read in the context of modern theories of rational agents, both in philosophy and the field of artificial intelligence.<br /> The author has defined &quot;rationality&quot; in a manner quite different from what the word stands for in economic theory, the latter of which views it as a descriptive concept. If a person is labeled as &quot;rational&quot; in economic theory, it means that the person is attempting to optimize his self-interest, regardless of the facts that might indicate otherwise. &quot;Rational&quot; for the author is quite different. What the author is saying, and is most profound, is that many of the actions that have been taken as an excuse for self-interest, such as lying, deception, and violence, are indeed never in one's interest. To label a human as &quot;rational&quot; in her view, is to characterize the person as one who is optimizing their self-interests, but these interests, because of the nature of the biology of humans, and the nature of the human psyche, never involve lying, deception, and violence. This is a bold and interesting move in ethical theory, and differentiates the author's formulation from most others in the history of philosophy.<br /> The ethical doctrines of this author are also intimately related to what science can tell us what indeed is in the interest of organisms, in order for them to optimize their health and general well-being. Most refreshing though is that this formulation of ethics is exceedingly optimistic. It asks the reader to considerthat rationality, productiveness, and pride are the virtues of self-interest. Plundering, violence, cheating, and deception never are. With its emphasis on the power of the human mind and its efficacy, it is certainly a philosophy that meshes will with our time. Even though written down over four decades ago, its optimism coupled with its practicality makes it pure 21st century.ider that rationality, productiveness, and pride are the virtues of self-interest. Plundering, violence, cheating, and deception never are. With its emphasis on the power of the human mind and its efficacy, it is certainly a philosophy that meshes will with our time. Even though written down over four decades ago, its optimism coupled with its practicality makes it pure 21st century.	2003-11-24
889688:US	50702879	R3I7L3AKXQ09PD	0345331354	979388730	Cosmos	Books	5	9	13	N	N	The best words ever put in print.	It is almost seven years since the author left us, and considering the magnitude of his accomplishments, no review of them can possibly do them justice. It is doubtful that any other person has instilled as many individuals as the author to enter the scientific profession. But the author has done much more than inspire, for he has given in this book. and the accompanying television series, the most accurate portrayal ever of human history. It is a history of achievement and daring creativity, where war and conflict are in the final analysis very rare. It is a history of confidence and courage to explore new domains. It is a history of both innate and discovered genius, and one where the truth always wins over illusion. There has been much that has been discovered in science since the author has passed on, but I think it can be stated with confidence that he would be both pleased and astonished of just what has been accomplished.<br />Indeed, look at us now:<br /> ....for with steady hands, the biologists are splicing and dicing in our genetic kitchens. Shuffling DNA like a deck of cards, they hybridize our fauna and flora, changing and accelerating their evolution. They extract silk from the udders of goats, make plants intolerant to insects, and they build electronic circuits and cure diseases using viruses, which they also engineer to become our friends, not our foes. With confidence and pride in who we are, we are poised to make copies of ourselves, and choose our progeny's phenotype with ease.Tapping on our keyboards, we blast our way through an enormity of DNA strings, finding similarities of our genes with other lifeforms, and discovering our genetic kinship with all life on Earth. What makes us so can now be put on disk: we can now carry our genome in our pocket.<br /> ....with objects that loop around our globe, and with others anchored on its surface, the astronomers have found other worlds  orbiting other suns. Turning around our cold-war satellites to look outward instead of downward, they have observed the perplexing gamma ray bursters. Beginning as a journey with the naked eye, our technology has expanded our vision across the whole spectrum. Looking up has always been a habit with us. Our evolved up-right posture is a cause and proof of our optimism and confidence.  We are natural astronomers.<br /> ....the engineers, the computer and cognitive scientists, are  teaching machines to think, to talk, to dance, to play cards, to sing, to compose music,  to trade, to read and write novels and poetry, to prove theorems, to diagnose our diseases, to judge our cases, to manage our networks, to discover and classify new objects in the heavens and in our accelerators . We find exhiliration in the presence of the silicon geniuses. Their minds are a reflection of ours. In space travel they have become our surrogates.<br /> .....banging gold atoms, electrons, and protons together, the physicists are finding out the patterns of nature. They celebrate the creation of the gluon plasma and the detection of the flavors of neutrinos. Stopping light in matter, they bring about the long anticipated condensation of Bose. With understanding of the world of the small increasing steadily each decade, attention is turned to its engineering, to the rise of the nanomachines.<br /> ....we have all hooked up to the Internet spider. We send messages to others half-way around the world. We ping our friends and relatives with our images and our words. Immersing ourselves in exabytes of information, we google through it with delight. The Web has become our playground, our shopping center, our bank, and our oracle....<br /> Indeed, as the author points out in the last chapter of the book, we have walked far. We now sit on the knee of an exponential curve. We become exhilirated at the prospect of whirlwind scientific and technological development. We are confident that this century will be even more breathtaking than the last.<br /> The book summarizes what is best not only about science but also about human existence. Written by one man, it speaks accurately about all humankind. Consisting only of a few hundred pages, it says in print what the vast majority of humans have done throughout history. The author will always be one of my heros, for his optimism in unequaled and his respect for truth constant through time. He explains with joyous enthusiasm the gentle stirring, that quiet feeling of understanding something for the first time: the rhyme and romance of scientific discovery.summarizes what is best not only about science but also about human existence. Written by one man, it speaks accurately about all humankind. Consisting only of a few hundred pages, it says in print what the vast majority of humans have done throughout history. The author will always be one of my heros, for his optimism in unequaled and his respect for truth constant through time. He explains with joyous enthusiasm the gentle stirring, that quiet feeling of understanding something for the first time: the rhyme and romance of scientific discovery.	2003-11-24
896108:US	50702879	R2MFYG44NND5WB	0306410753	53835475	Winning the Games Scientists Play	Books	1	22	37	N	N	The most disconcerting words ever put in print.	This is a deeply troubling book, both for reasons of content and for its  projection of a certain view about the scientific community. Its goal is to advise would-be scientists on a set of actions that will increase their eventual success as professional scientists.  The book is merely a collection of opinions with no historical, statistical, or even anecdotal justification. The reader will not find in this book a statistical study or comparison between individuals who follow its advice, and those that don't. Why should readers believe that engaging in the conduct recommended will &quot;win&quot; them respect in the scientific community? Are there objective, rigorous, studies available that show this is the case? Are the rules of the &quot;scientific game&quot;, as described in the book, so constraining so as to result in low bandwidth against those who do not follow them? There are no examples given of individuals who have achieved much in science but who have not played these games. Are there no such individuals? Where is the scientific evidence that following such a game-playing path will result in scientific excellence?<br /> I do not know of, nor have I met, anyone who has read this book and consequently decided to follow its advice. In addition, I have not done a scientific study of the sociology of its advice to be able to judge its efficacy. The disgust I felt while reading the book does not disqualify it from being sound advice. Anecdotally speaking though, I have known a few individuals who have followed, with delight, what could be described as the &quot;easy&quot; path to scientific recognition. Their algorithm of conduct is to do the least possible, to follow the path of least resistance, to appear competent regardless of the factual evidence to the contrary, to suppress the creative and to admonish those that express it, and to ridicule the &quot;idealism&quot; of those who do not follow their myopic, pessimistic vision of life. Having indulged themselves in these unproductive games, they seem unable to end them and find the center, the goal of the game. Reaching retirement age, they have lost themselves, tragically, in the labyrinth of anger and cynicism.<br /> The true scientist is a truth seeker, and plays a game of logic and experimentation. Science is a game of total honesty with oneself and others. The true path of science is a highly constrained one to be sure, as it respects only patience with ideas and tools. There are no shortcuts in its path. No amount of advertising can alleviate its requirement for validation with what is real. Syllogisms and experiments only obey the rigorous game of facts....we are all indeed fortunate to have these kinds of games being played by hundreds of thousands of scientists today.elves in these unproductive games, they seem unable to end them and find the center, the goal of the game. Reaching retirement age, they have lost themselves, tragically, in the labyrinth of anger and cynicism. <br /> The true scientist is a truth seeker, and plays a game of logic and experimentation. Science is a game of total honesty with oneself and others. The true path of science is a highly constrained one to be sure, as it respects only patience with ideas and tools. There are no shortcuts in its path. No amount of advertising can alleviate its requirement for validation with what is real. Syllogisms and experiments only obey the rigorous game of facts....we are all indeed fortunate to have these kinds of games being played by hundreds of thousands of scientists today.	2003-11-18
898461:US	50702879	R2OE2BKI5P7SR6	1560255021	528901183	Dreaming War: Blood for Oil and the Cheney-Bush Junta (Nation Books)	Books	2	7	25	N	N	Another anger book	The last few years has seen an increase in visibility of angry authors, angry talk show and radio hosts, angry syndicated columnists, and angry political pundits. Each are competing it seems to express the most anger, and independent of their political persuasions, they are doing a good job. The (angry) author of this book is one of these, and his personal dislike of the current president and vice president prevents him from writing an objective analysis of modern events. Even if you agree with his assertions, a lot more than anecdotal evidence is needed to establish them. Anger though is apparently a source of energy for all writers like this one. The facts though get diluted as their pens move quickly across the paper, or their fingers do a tippy tap on the keyboard. Unsubstantiated opinions proliferate profusely, all fueled by the ever-steady flow of anger.<br /> There are many accusations here directed against the president and vice president, some of which are public record, such as their avoidance of the fighting in Vietnam. Apparently though they have no qualms about sending others to do the fighting. Others though miss their mark, such as the author's assertion that the administration had designs on Afghanistan before 9/11. The author quotes \\"The Guardian\\" as evidence for this, but how does the Guardian know? Where do they get their information, and why are only they privy to it? The 2000 election of course was stolen, in the author's view, with the Supreme Court helping out with (guarded) enthusiasm. The Supreme Court rushed the decision though, not permitting the votes to be counted correctly, and this rush, says the author, was done deliberately, so as to give the current administration a victory that was clearly undeserved. Did the justices really intend this? What evidence could we cite to gain a justification for the author's assertion?<br /> Many other unfocused, angry tirades appear in this book. The lesson to take from it is the same as taken from all the other \\"anger books\\" currently in print: Opinions come easy; real knowledge takes a time consuming, disciplined effort.all the other \\"anger books\\" currently in print: Opinions come easy; real knowledge takes a time consuming, disciplined effort.	2003-11-16
903458:US	50702879	R38WJXFH52LLS7	048665785X	680069683	Banach Spaces of Analytic Functions	Books	4	14	14	N	N	A pre-corona book...but still good reading	The theory of Hardy spaces is vast, along with its applications. This book overviews what was known about them in the early 1960s. In spite of its age, it can still be read profitably by anyone interested in harmonic analysis and Hardy spaces.<br /> Chapter 1 gives a quick review of the mathematical background needed for reading the rest of the book, mostly dealing with measure theory, and Banach and Hilbert spaces.<br /> In chapter 2, the author gives a detailed treatment of Fourier series over the closed interval from -pi to pi. The chapter is designed to answer two questions, namely whether a function is determined by its Fourier series, and given a particular Fourier series, how one can recapture the function. These questions must be addressed in the appropriate norm on the Banach space of Lp spaces of Lebesgue integrable functions. There are many methods of recapturing the function, and the author discusses a few such methods, one being the Cesaro means. The authors proves that for a function in Lp, the Cesaro means of the Fourier series of the function converge to it in the Lp norm (when p is greater than or equal to 1 but less than infinity). When p is infinity, the author shows this is true in the weak-star topology. The author then shows how the Cesaro means can be used to characterize the different types of Fourier series.<br /> Analytic and harmonic functions in the unit disk are defined and studied in chapter 3. The first question the author addresses is to what extent these functions are determined by their boundary values. The author shows how to represent these functions on the closed unit disk using the Cauchy and Poisson integral formulas, thus answering this question. The second question he addresses is the behavior of these functions on the boundary, i.e. the Dirichlet problem. His methods for harmonic functions are analagous to those for Lp under the guise of Cesaro means, i.e. Cesaro summability becomes Abel summability. The author shows this connection more rigorously by proving Fatou's theorem. Hp spaces are defined in this chapter, and the author illustrates one of the major differences between the harmonic and analytic functions.<br /> The author begins the study of H1 spaces in chapter 4, initially via the Helson-Lowdenslager approach. He first proves Fejer's theorem for functions which are continuous on the closed unit disk and analytic at each interior point: the real parts of these functions are uniformly dense in the space of real-valued continuous functions on the unit circle. Szego's theorem, which gives a measure of the &quot;distance&quot; from the constant function 1 to the subspace of these functions that vanish at the origin, is proved, as well as the Riesz theorem, which shows that analytic measures on the unit circle are absolutely continuous with respect to Lebesgue measure. He then applies these results to H1 functions, showing that such functions cannot vanish on a set of positive Lebesgue measure on the circle without being identically zero. The author then generalizes these results to Dirichlet algebras later in the chapter, showing to what extent the Riesz theorem carries over.<br /> The important factorization theorems for Hp functions are covered in chapter 5, wherein the famous Blaschke products come in. Their properties are discussed in detail, along with the ability to represent a non-zero bounded analytic function in the unit disk in terms of them. The author proves a theorem of Hardy and Littlewood on H1 functions of bounded variation and a theorem of Hardy on the growth of the Fourier coefficients of an H1 functions.<br /> The author studies the algebra A of continuous functions on the closed unit disk which are analytic on the open disk in chapter 6. The factorization results of chapter 5 are used along with the theory of commutative Banach algebras to characterize completely the closed ideals in A. Wermer's maximality theorem, which states that A is a maximal closed subalgebra of the continuous complex-valued functions on the unit circle, is proven.<br /> The shift operator on the (Hilbert) space H2 is studied in chapter 7, the goal being to classify the invariant subspaces of this operator. The author uses a more classical approach due to Helson and Lowdenslager to do this. The shift operator on L2 (on the unit circle) is then considered, and its invariant subspaces described. The author finishes the chapter with a short discussion of the representations of H(infinity).<br /> After a study of Hp spaces on the half-plane in chapter 8, in chapters 9 and 10 the author predominantly looks at Hp and H(infinity) from a &quot;soft&quot; analysis point of view. He shows that the isometries of H1, induced by conformal mappings of the unit disk onto itself, can be studied by studying the isometries of H(infinity). The projections from Lp to Hp are discussed, the author providing readers the necessary background for a study of Toeplitz operators, if they so desire. The topology of the maximal ideal space of H(infinity) is considered, but at the time of publication it was not known whether or not the open unit disk is dense in this space. This is the famous corona theorem of Lennart Carleson, which he proved as this book went into publication.subalgebra of the continuous complex-valued functions on the unit circle, is proven. <br /> The shift operator on the (Hilbert) space H2 is studied in chapter 7, the goal being to classify the invariant subspaces of this operator. The author uses a more classical approach due to Helson and Lowdenslager to do this. The shift operator on L2 (on the unit circle) is then considered, and its invariant subspaces described. The author finishes the chapter with a short discussion of the representations of H(infinity).<br /> After a study of Hp spaces on the half-plane in chapter 8, in chapters 9 and 10 the author predominantly looks at Hp and H(infinity) from a &quot;soft&quot; analysis point of view. He shows that the isometries of H1, induced by conformal mappings of the unit disk onto itself, can be studied by studying the isometries of H(infinity). The projections from Lp to Hp are discussed, the author providing readers the necessary background for a study of Toeplitz operators, if they so desire. The topology of the maximal ideal space of H(infinity) is considered, but at the time of publication it was not known whether or not the open unit disk is dense in this space. This is the famous corona theorem of Lennart Carleson, which he proved as this book went into publication.	2003-11-12
909814:US	50702879	R2R6DB2L4GXBR3	026252113X	909835561	After Philosophy: End or Transformation?	Books	4	5	7	N	N	A collection of transformations....but with no fixed points	The pages in this book are enclosed in  cover, but it has no beginning and no ending. It is a sign, a mirror, a reflection, of an unending dialog that has trickled its way through Western culture for thousands of years. This dialog has been at times contentious, rich in symbolisms and thought experiments, and executing always a random walk through conceptual space. This book is one of thousands throughout history that have attempted to find rest, to find a fixed point in a dynamical system of words and thoughts that the West has called &quot;philosophy&quot;. There has been no paucity of ideas and energy in this unrelenting search for this elusive equilibrium called Truth. The search algorithms have employed the ultimate in human imagination and logic, and have been executed without yet any indication of completion. Unable to find a resting point that is deemed comfortable to all, a few of the bricklayers of thought we called &quot;philosophers&quot; have abandoned the search for it. This book gives the reader a sample of them. When picked up and opened, one learns of:<br /> The pragmatic post-philosophical culture of Richard Rorty, wherein man and woman are alone and finite, and have &quot;no links to beyond&quot;; where science is an inquiry just as is literature. In this culture, opponents in thought cannot find resolution according to criteria agreed to by both sides.<br /> The &quot;principle of legitimacy&quot; and &quot;narrativity&quot; of  the French Nietzschean Jean-Francois Lyotard, with its bricklaying tool the pragmatics of language courtesy of Wittgenstein. Dialog for Lyotard is a kind of war, albeit a &quot;playful&quot; one. All speech is thus in the domain of &quot;agonistics&quot;. But the language games via computerization, he asserts, can be a dream instrument for controlling and regulating the market system. But the computerization can supply groups with the information needed to make knowledgeable decisions. Language games are then non-zero-sum games of perfect information, where minimax equilibria are not to be found. After all, the reserve of knowledge and utterances are inexhaustible. Lyotard has stumbled upon a possible dialog of 21st century ethics: a playful argumentation with the machine.<br /> The &quot;counterphilosophy&quot; of another French Nietzschean, Michel Foucault. Foucault is a bricklayer though who uses power tools. But power is essentially positive, and not to be masked by the human sciences or individual self-knowledge. These create a facade of universality and objectivity. For Foucault, (true?) intellectuals participate in a &quot;local&quot; struggle, namely to detach the power of truth from its modern forms of hegemony.<br /> The deconstruction of  the (self-professing bricoleur) Jacques Derrida. Derrida's bricks are never laid. Instead, he removes the gout between the ones that are already set in the buildings of Western metaphysics.<br /> The semantic transformation of metaphysics of Donald Davidson. Davidson's bricks are tainted with common sense: he believes that communication dictates that most of our beliefs must be true. Too much error implies massive unintelligibility.<br /> The &quot;prima philosophia&quot; of Michael Dummett, which underlies all the rest. Dummett's foundational/Fregean bricks give a theory of meaning, which is identical in his view to a theory of understanding. The house of philosophy is to be built first by analyzing thought, which is to be distinguished from the process of thinking, and it is to be analyzed by analyzing language.<br /> The referential semantics of Hilary Putnam. Reason is a regulating principle for Putnam. Our philosophical buildings, our truths, are constructed from our conception of rationality. But these buildings have no foundation, even though they are built with the tool of reason.<br /> The &quot;philosophy of ultimate origins&quot; and &quot;transcendental pragmatics&quot; of Karl-Otto Apel, which attempts to join the houses ofanalytic and Continental philosophy.  The house built by Apel has a high roof. In his ethics in particular, a justified norm must have the agreement of all participants in the discourse.<br /> Philosophy as the &quot;guardian of reason&quot; and &quot;placemarker&quot; and &quot;placeholder&quot; in the house of Jurgen Habermas. For Habermas, philosophy works in harmony with the human sciences, and finds itself inserted into the contexts of empirical research. But Habermas advocates a philosophy of reconciliation across the &quot;whole spectrum&quot; of ideas, not just science.<br /> The philosophical hermeneutics of Hans-Georg Gadamer. For Gadamer, understanding becomes an event in which interpreter and text mutually determine one another, and prejudices and prejudgements become prerequisites for real understanding. Knowledge independent of perspectives is an illusion for Gadamer.<br /> The &quot;ontology of human finitude&quot; of Paul Ricoeur, wherein reflection always becomes interpretation. Existence is interpreted from signs &quot;scattered in the world.&quot; Truth and method cannot be separated in the the hermeneutic house of Ricoeur.<br /> The historical narratives of Alasdair Macintyre, wherein &quot;philosophical history&quot; is needed for adequate understanding of a given worldview, as well as its rational justification. The &quot;history of an argument&quot; plays a decisive role for the resolution of issues, says Macintyre.<br /> The &quot;legitimized&quot; rhetoric of Hans Blumenberg, which, contrary to the Platonist dogma, reaches equal status with philosophy. In the house of Blumenberg, rhetorical justifications can be better than science, and these are not merely decorations in this house, but essential for its functioning.<br /> The philosophical anthropology of Charles Taylor. The &quot;self-interpreting&quot; residents of his house of philosophy are human agents, who are &quot;subjects of significance&quot; . These agents are to be distinguished from other animals and from computers, in that they are beings for whom things matter. Moral concerns, love and hate cannot be described in terms of the calculations of reason. Taylor unwittingly takes on the ethics of the 21st century: rational deliberation from both man and machine. Both of these entities have concerns that matter to them.uses of analytic and Continental philosophy.  The house built by Apel has a high roof. In his ethics in particular, a justified norm must have the agreement of all participants in the discourse. <br /> Philosophy as the &quot;guardian of reason&quot; and &quot;placemarker&quot; and &quot;placeholder&quot; in the house of Jurgen Habermas. For Habermas, philosophy works in harmony with the human sciences, and finds itself inserted into the contexts of empirical research. But Habermas advocates a philosophy of reconciliation across the &quot;whole spectrum&quot; of ideas, not just science.<br /> The philosophical hermeneutics of Hans-Georg Gadamer. For Gadamer, understanding becomes an event in which interpreter and text mutually determine one another, and prejudices and prejudgements become prerequisites for real understanding. Knowledge independent of perspectives is an illusion for Gadamer. <br /> The &quot;ontology of human finitude&quot; of Paul Ricoeur, wherein reflection always becomes interpretation. Existence is interpreted from signs &quot;scattered in the world.&quot; Truth and method cannot be separated in the the hermeneutic house of Ricoeur. <br /> The historical narratives of Alasdair Macintyre, wherein &quot;philosophical history&quot; is needed for adequate understanding of a given worldview, as well as its rational justification. The &quot;history of an argument&quot; plays a decisive role for the resolution of issues, says Macintyre. <br /> The &quot;legitimized&quot; rhetoric of Hans Blumenberg, which, contrary to the Platonist dogma, reaches equal status with philosophy. In the house of Blumenberg, rhetorical justifications can be better than science, and these are not merely decorations in this house, but essential for its functioning. <br /> The philosophical anthropology of Charles Taylor. The &quot;self-interpreting&quot; residents of his house of philosophy are human agents, who are &quot;subjects of significance&quot; . These agents are to bedistinguished from other animals and from computers, in that they are beings for whom things matter. Moral concerns, love and hate cannot be described in terms of the calculations of reason. Taylor unwittingly takes on the ethics of the 21st century: rational deliberation from both man and machine. Both of these entities have concerns that matter to them.	2003-11-07
911032:US	50702879	R2VQN1UXJ6P25	0126227500	624544609	Principles of Functional Analysis	Books	4	21	22	N	N	A good start	Functional analysis is now a vast subject with many applications and this book gives an introduction to this branch of mathematics that can be understood by advanced undergraduates or beginning graduate students. The book fills a gap between elementary aspects of analysis and those using measure theory. The author motivates the subject matter very well, and therefore gives the reader a deeper appreciation of the basics of functional analysis and operator theory. Because of its high quality of presentation, it is very unfortunate therefore that the book is out of print.<br /> In chapter 1, the author introduces the subject by considering a particular differential equation, which he solves by the method of variation of parameters. Generalizing the equation leads him finally to the Volterra integral equation, and by abstracting from the properties of this equation he introduces the notion of a Banach space. Several examples of these spaces are given, and he uses them to introduce Hilbert spaces. Appropriately, a discussion of Fourier series concludes the chapter.<br /> The Riesz representation theorem, which shows that every bounded linear functional on a Hilbert space can be represented as an inner product, is introduced immediately in chapter 2. This representation is used to motivate a similar question for Banach spaces, namely whether Banach spaces have any nonzero bounded linear functionals. The Hahn-Banach theorem, discussed in detail, shows there are many such functionals. Since there are so many, it makes sense to speak of the space of all of them, called the dual space, which is a Banach space even though the original space may not be. Several examples of dual spaces are given.<br /> The author discusses the space of bounded linear operators between normed linear spaces X and Y in chapter 3, showing that it is a Banach space if  Y is. The adjoint of an operator is defined, and the author shows why adjoints are useful. The famous Closed Graph Theorem and its geometric interpretation are discussed in detail. Another fundamental result, the Uniform Boundedness Theorem, is proven.<br /> Integral equations are also used to motivate the concept of a compact operator in chapter 4, but first via the operators of finite rank. The compact operators are thus the limit in norm of operators of finite rank, and their adjoints are also compact.<br /> One of the most important classes of operators of all, the Fredholm operators, are discussed in chapter 5. The author discusses what can be concluded from their definition and gives other criteria for recognizing when an operator is Fredholm. The index theory of Fredholm operators is covered in this chapter, and this is a theory that has far-reaching implications in other areas of mathematics, such as algebraic topology and K-theory. The author discussed briefly a collection of operators called semi-Fredholm operators, that are defined by relaxing some of the conditions for Fredholm operators are relaxed.<br /> Spectral theory, also of enormous importance in operator theory, is discussed in chapter 6. The author proves the spectral mapping theorem, explaining the need for complex Banach spaces in this regard. The author shows how to obtain a formula for the inverse of a bounded operator polynomial. The reader will need a background in complex variables in order to follow his discussion here, which has become known as the &quot;operational calculus&quot;. If the spectrum of the operator is disconnected, the author shows how to obtain the spectral projections of the operator.<br /> The theory of unbounded operators, typically not treated in beginning books on operator theory, but very important in applications, is discussed in chapter 7. Unbounded Fredholm operators are defined, and the author shows just how much the bounded results can be carried over to these. The same is done for unbounded semi-Fredholm operators.<br /> The author returns to Banach spaces in chapter 8, where he discussesreflexive Banach spaces. He proves that a Banach space is reflexive if its dual is, and shows how &quot;saturated subspaces&quot; characterize reflexive spaces. The very important weak* convergence appears here in the discussion of separable Banach spaces.<br /> Chapter 9 is the beginning of &quot;soft analysis&quot; wherein the author discusses Banach algebras. The reader gets his first taste of the intertwining of operator theory, algebra, and analysis in this chapter. The &quot;soft&quot; approach to operator theory is vast and is marked by many brilliant developments.<br /> Semigroups, so very important in physical applications, are discussed in chatper 10. The discussion again motivated by a differential equation, the author shows clearly the need for strong continuity in obtaining an infinitesimal generator for a one-parameter semigroup of operators.<br /> The author returns to Hilbert spaces in chapter 11, wherein he introduces the highly important class of normal operators. He shows that such operators are norm attaining, and proves when normal compact operators have a complete, orthonormal set of eigenvectors. He applies these considerations to a class of (compact) integral operators and then discusses briefly the theory of hyponormal operators.<br /> Another topic not usually included in treatments at this level is the theory of bilinear forms, which is done in chapter 12. Very important in many areas of mathematics, the author shows their utility in the context of dissipative operators. He then goes on to the topic of self-adjoint extensions, showing that every densely defined symmetric linear operator has a self-adjoint extension.<br /> Self-adjoint opertaors are then treated in detail in chapter 13, beginning with the theory of orthogonal projections, which are very important in applications like quantum physics. He then proves the spectral resolution theorem for bounded self-adjoint operators.<br /> The last chapter of the book details some applications, the first few sections dealing mainly with a particular (unbounded) differential operator. Using two different methods the author calculates the spectrum of this operator. He then does essentially the same analysis for a simple integral operator. Both of these operators appear many times in physical applications.scusses reflexive Banach spaces. He proves that a Banach space is reflexive if its dual is, and shows how &quot;saturated subspaces&quot; characterize reflexive spaces. The very important weak* convergence appears here in the discussion of separable Banach spaces. <br /> Chapter 9 is the beginning of &quot;soft analysis&quot; wherein the author discusses Banach algebras. The reader gets his first taste of the intertwining of operator theory, algebra, and analysis in this chapter. The &quot;soft&quot; approach to operator theory is vast and is marked by many brilliant developments. <br /> Semigroups, so very important in physical applications, are discussed in chatper 10. The discussion again motivated by a differential equation, the author shows clearly the need for strong continuity in obtaining an infinitesimal generator for a one-parameter semigroup of operators. <br /> The author returns to Hilbert spaces in chapter 11, wherein he introduces the highly important class of normal operators. He shows that such operators are norm attaining, and proves when normal compact operators have a complete, orthonormal set of eigenvectors. He applies these considerations to a class of (compact) integral operators and then discusses briefly the theory of hyponormal operators. <br /> Another topic not usually included in treatments at this level is the theory of bilinear forms, which is done in chapter 12. Very important in many areas of mathematics, the author shows their utility in the context of dissipative operators. He then goes on to the topic of self-adjoint extensions, showing that every densely defined symmetric linear operator has a self-adjoint extension. <br /> Self-adjoint opertaors are then treated in detail in chapter 13, beginning with the theory of orthogonal projections, which are very important in applications like quantum physics. He then proves the spectral resolution theorem for bounded self-adjoint operators. <br /> The last chapter of the book details some applications, the first few sections dealing mainly with a particular (unbounded) differential operator. Using two different methods the author calculates the spectrum of this operator. He then does essentially the same analysis for a simple integral operator. Both of these operators appear many times in physical applications.	2003-11-06
918093:US	50702879	R3MVB5L91FQINZ	0451156455	128148757	The New Left: The Anti-Industrial Revolution	Books	1	13	59	N	N	The art of vituperation: some early instruction.	The art of vituperation, i.e the practice of ad hominen and vitriolic attacks against contrary philosophical or poliltical persuasions, seems to be very popular, as a persual of the current top-selling books will reveal. This book, written over thirty years ago, has the tone of these best-sellers. The author is unrelenting in her smears against what she has labeled as &quot;The New Left&quot;, and this makes the book difficult to get through, if the reader is one who believes that political and philosophical discussion should never include dialog that is so blatantly disrepectful.<br /> The &quot;New Left&quot;, the author asserts, began in 1964 with the rise of the Berkeley protests, and she briefly discusses its history in the first section of the book. This &quot;Free Speech&quot; movement of Berkeley is completely &quot;anti-ideological&quot; according to the author, being opposed to &quot;labels&quot; or theories. Their philosophical position could be classified as existentialism, but Immanuel Kant is to blame for their divorcing of reason from reality. In fact Kant is blamed for all of the &quot;irrational&quot; influences in the college curriculum, which she asserts, without any statistical evidence or scholarly analysis, has &quot;seeped into every classroom, subject, and brain&quot; in the universities of that time.<br /> In another section Woodstock is described as a &quot;Dionysian&quot; project, the landing on the moon as &quot;Apollonian&quot;. In spite of the Nietzschean overtones of this classification, Kant is again blamed for the Dionysian revelry of the New Left. Kant was the first &quot;hippie&quot; in history, she states. But the author does not seem to acknowledge that the Woodstock festival lasted only a few days; the Apollo project many years of preparation. There was a huge difference between the resources used for Apollo versus those for Woodstock. Certainly Apollo and the light of reason were the predominant philosophies, if one is to judge a culture using only these two.<br /> In a later section, the woman's movement, or &quot;Women's Lib&quot;, is described as composed of &quot;sloppy, bedraggled, unfocused women&quot; who are in no danger of being mistaken as &quot;sex objects&quot;. Their opinions on sex are described as &quot;hideous&quot; and are in a &quot;sisterhood with lesbians&quot;. The author though, ironically, does not want to give a more accurate commentary, since in her view that &quot;would require a kind of language that I do not like to see in print&quot;. Apparently the author believes that a woman's phenotype should be taken into account when judging their philosophical and moral positions. Any common interests with homosexuals is also to be viewed with suspicion.<br /> The longest section of the book, and the most troubling from a scientific standpoint is the last one entitled &quot;The Comprachicos&quot;. The author makes claims that are totally unsupported scientifically, and no references are given that lend credence to her claims about the nature of the child psyche and the dynamics of child development. The &quot;comprachicos&quot; are a collection of people, not identified explicitly, that have, under the guise of progressive education, robbed the minds of American children. They have taken a normal brain she says, and made it mentally retarded. This is an extreme view if taken literally, and the reading of this section of the book gives one every indication that the author does mean it literally. But mental retardation is something that can be measured, those children who are victims of the comprachicos can be identified, and correlations with the progressive educators can then be found statistically. The author though has done none of this. Mental retardation is not quantified, no case studies are quoted, and therefore no empirical evidence is given that shows a connection between the techniques of progressive educators and mental retardation. Such a connection could perhaps be shown, but it will take painstaking research and data collection in order for this to happen. The section ends with more vituperation: the &quot;Establishment&quot; which is a &quot;rotted structure of mindless hyprocrisy&quot; and consists of big businessmen, conservatives, Washington politicians (who are &quot;eagar dummies&quot;), the communication media, as well as professors, the arch-villians in the author's eyes.<br /> One can only wonder if some of the current practitioners of vitriole and ad hominen attacks perhaps read this book and gained helpful hints on how to carry them out. But such an approach to the debate on issues never serves any useful purpose to anyone. The art of vituperation is a useless expenditure of energy and time, and worthless as an explanatory tool for any type of discussion or inquiry.perhaps be shown, but it will take painstaking research and data collection in order for this to happen. The section ends with more vituperation: the &quot;Establishment&quot; which is a &quot;rotted structure of mindless hyprocrisy&quot; and consists of big businessmen, conservatives, Washington politicians (who are &quot;eagar dummies&quot;), the communication media, as well as professors, the arch-villians in the author's eyes. <br /> One can only wonder if some of the current practitioners of vitriole and ad hominen attacks perhaps read this book and gained helpful hints on how to carry them out. But such an approach to the debate on issues never serves any useful purpose to anyone. The art of vituperation is a useless expenditure of energy and time, and worthless as an explanatory tool for any type of discussion or inquiry.	2003-11-01
926195:US	50702879	R1KRA0QN06FQF	0684863847	966624665	Illiberal Education: The Politics of Race and Sex on Campus	Books	4	22	31	N	N	A carefully documented study	This book hit the presses in 1991 and having it read while employed as a professor in a university, its message really hit home. Everyone who has been in a university environment will no doubt have their own horror stories to report on their experiences confronting the move to incorporate \\"diversity\\" on campus. But all students, faculty, and administrators should not be too hasty in their conclusions, and regard their purely anecdotal experiences as proof that such experiences are the norm in all universities. The author of this book fortunately has not done this, but has given a careful, documented study of the diversity movement in American universities. This is not to say that everything the author concludes has been supported by statistical and scientific evidence, as there are a few places in the book where such evidence is lacking.<br /> The word \\"diversity\\" implies a wide variety of ideas and knowledge. In the author's view though this word has taken on a new meaning in the university, namely that it has lost its procedural meaning and has taken on substantive content. To advocate diversity does not mean that one advocates an elaborate range of ideas, but rather a particular set of ideological doctrines. If one does not agree with the political agenda and opinions of those who seek to \\"diversify\\" the university, then one is not an advocate of \\"diversity\\".<br /> Since this book was written, the diversity movement has expanded into corporate America. The irony of this is that many who left the university to escape from its coercive policies of \\"diversification\\" and received employment in these corporations must now face again the same policies. Fearing lawsuits, corporations have required mandatory classes in diversity and sensitivity training, resulting in a chilling atmosphere for many employees (and managers).  Ordinary conversation between employees can be guarded and minimal, lest the wrong words be used that are at odds with diversity dogma. Some corporations have even asked some employees to act as \\"change agents\\" to monitor (sometimes anonymously) the language of the company workforce, and to report to corporate management or human resources any deviation from the doctrines of diversity.<br /> It is a shame that the university, which should be a refugee camp for the reasoning mind, is now to a large extent an idea filter with a very low bandwidth, especially in the humanities. Science and technology though, in the university and outside of it, are seeing unprecedented advance. This advance is not due to a movement for diversity but to the unrelenting use of the human mind. Thankfully the diversity movement has not yet discouraged or suppressed human curiosity. Not yet.tions have even asked some employees to act as \\"change agents\\" to monitor (sometimes anonymously) the language of the company workforce, and to report to corporate management or human resources any deviation from the doctrines of diversity. <br /> It is a shame that the university, which should be a refugee camp for the reasoning mind, is now to a large extent an idea filter with a very low bandwidth, especially in the humanities. Science and technology though, in the university and outside of it, are seeing unprecedented advance. This advance is not due to a movement for diversity but to the unrelenting use of the human mind. Thankfully the diversity movement has not yet discouraged or suppressed human curiosity. Not yet.	2003-10-26
926360:US	50702879	R130IO8UPJN9MD	0271014415	448978191	Ayn Rand: The Russian Radical	Books	5	12	13	N	N	A much needed book	It is refreshing to see at last a critical review of the philosophical thought of Ayn Rand, since her philosophy is sometimes described as &quot;naive&quot;, and, perhaps just as troubling, as the greatest philosophy ever to appear in print. The author of this book has given the reader an honest and in-depth analysis of one of the most controversial figures in twentieth-century philosophical thought. Rand was not an academic philosopher, and this, coupled with her frequent vitriolic attacks against many philosophical schools of thought, induced many to speak out against her, and they typically did so with a degree of vituperation unmatched as yet in public debate. Fortunately the shouting and name-calling typically accompanying discussion of Randian philosophy is not included in this book. Also not included is any blind, uncritical allegiance to Randian philosophy, for this can also accompany discussions of it. Rand has made some interesting contributions to philosophical thought, and her theory of ethics is I believe unequaled, and one can find a very thorough discussion of just how she arrived at this theory throughout this book. However Rand, like every other philosopher, cannot remove herself from history and cultural influences, and view the world from a detached, apodictic point of view, for that is the nature of human learning. One builds on what has been done before, and with careful thought and unique insight, some original ideas can then be developed, which will hopefully extend what has been done before, and nontrivially. The author of this book clearly shows the historical origins of Randian thought, those origins have their place in the Russian university that Rand attended.<br /> The author sees the problem for Randian scholarship as predominantly arising from her public persona, and thus scholars need to differentiate Rand's personality from her philosophy. Her intransigence, intolerance, and general mean-spiritedness must be ignored if one is not to collapse into psychologism, argues the author. Scholars must also he argues, attempt to find out what actually defines her philosophy and makes it distinctive. This has been a source of contention in recent years, with different &quot;schools of thought&quot; established, each claiming to represent exclusively her philosophy.<br /> Another virtue of this book is the author's insistence on using a hermeneutical approach when analyzing Randian philosophy.The information content of an idea, he argues, includes myriads of unforeseeable non-trivial statements, this being similar to what happens in mathematics. It is well known to those who practice mathematics that a large number of problems and concepts can be generated from a particular area of it. These problems can go way beyond the intent of the mathematicians who created this particular area. Many advocates of Randian philosophy, as the author points out, like to think of her philosophy as a &quot;closed system&quot;. Without actually defining it, one can only make educated guesses as to what this really means. If it means a deductive system where each statement can be derived from others within the system, and no further development is necessary, then this is problematic. The example of mathematics again shows that a deductive system can be extended greatly depending on the ingenuity of the researcher.<br /> Rand herself was a poor scholar, only infrequently quoting works of philosophy that she deemed worthy of inclusion. Considering her confidence in the originality of her ideas this is not surprising. However every claim about another scholar's ideas should be given textual support. Indeed, Rand's criticism of Immanuel Kant is unrelenting, but her analysis of his philosophy lacks the depth needed to judge his philosophy from her vantage point. Luckily the author assists the reader in the understanding of just why Rand objected to Kant so vociferously.<br /> Hopefully this book will be the first in many that willput Rand in the historical context of twentieth century philosophy. Rand is a fairly good example of what can be produced outside the academy if one has the cognitive discipline and the large amounts of time needed to develop systematic philosophical systems. The information age has brought publishing strategies that Rand did not have when she was alive. The doors are thus open for most anyone to express their ideas and have them accessible to a world-wide audience. Critical works of philosophy can thus be produced both inside and outside the academy.will put Rand in the historical context of twentieth century philosophy. Rand is a fairly good example of what can be produced outside the academy if one has the cognitive discipline and the large amounts of time needed to develop systematic philosophical systems. The information age has brought publishing strategies that Rand did not have when she was alive. The doors are thus open for most anyone to express their ideas and have them accessible to a world-wide audience. Critical works of philosophy can thus be produced both inside and outside the academy.	2003-10-25
926451:US	50702879	R23I6KJ85ULC2B	0691020132	274523775	Identity and Essence (Princeton Legacy Library)	Books	3	2	2	N	N	Interesting discussion	The issues that the author address in this book are ancient ones, going all the way back to the times of Aristotle and Plato. There is disagreement of course among philosophers as to the resolution of these issues. Those that think they have been resolved, and the author of this book is one of these, are matched by those who hold that the issues have not or even cannot be resolved. It is easy to say that everything in this book is incorrect, since its denial will not have any drastic consequences from an epistemological standpoint. Philosophical theorizing has the unique feature that it never seems to obtain closure. It is a never-ending process of arguments and counterarguments, and the construction of philosophical systems never seems to employ enough &quot;side-constraints&quot; to arrive at a result that seems plausible to all. This book though, as most in philosophy, is to a good exercise in thought, the main goal of which is to develop an Aristotelian theory of essentialism and change. It would appeal to students of philosophy as well as anyone interested in the issues expounded in it. The book could also be of benefit to those readers who are working in a branch of artificial intelligence called &quot;ontological engineering&quot;, since many of the issues in the book arise in that area.<br /> The author begins the book with an elaboration of why he thinks that &quot;identity&quot; can be defined in a language that contains second-order language and names for enduring objects, and that any language weaker than this will not suffice. He lists two axioms in second-order logic that in his opinion are usually used as a basis for a theory of identity. These two axioms are only necessary conditions for identity claims he argues, one still must add the principle of the identity of indiscernibles. At the level of logic his assertions do not seem so radical, but an acquaintance of the literature about the problem of identity shows that these assertions have troubled many philosophers, some of which the author details in the early chapters. Some philosophers have raised the &quot;triviality objection&quot; which the author attempts to counter, and he uses a few rather strange arguments to do so. One of these addresses the question of whether the identity of indiscernibles would be true if identity-properties are excluded from the domain of the qualifier that ranges over all properties. It would be true if the domain contains properties that are possessed by one object at one time and each object would still have at least one such property. For concrete objects that cannot be at the same place at the same time, these would seem to hold true. The author counters the assertion that two concrete objects cannot be in the same place at the same time, by reference to himself and his body. They are located at the same place at the same time, but yet are not identical. This argument explicitly assumes that the self and the body are different, an assertion that is totally without foundation.<br /> The author then discusses in more detail his ideas on enduring objects, which in his approach are fundamental to his theory of identity. He then works out a few consequences of his theory relative to various other philosophical ideas on identity, such as spatiotemporal continuity, which has been asserted by some philosophers to be a necessary and sufficient condition for the identity of physical objects.<br /> After arguing for this theory of identity, the author then shows that it is inadequate, the reason being that it fails to address the implications of the Aristotelian distinction between two types of changes, the &quot;alterations&quot; and the &quot;substantial&quot; changes. An object undergoes an alteration if it possesses a new property that is incompatible with one that it had before the change. It undergoes a substantial change if the object no longer exists even if there is another object which has the pre-existing property. The author explains in detail why Aristotle's distinction among changes causes problems with his theory of identity.<br /> The problems with his theory of identity motivate the author to consider various theories of essentialism, one being due to the philosopher Alvin Plantinga and another due to David Kaplan, both of which he rejects and gives detailed reasons for doing so. He also considers various theories of identity across possible worlds. These he also rejects, for reasons of their incompatibility with Aristotelian essentialism, which through detailed discussion, he is careful to differentiate from Leibnizian and mereological essentialism. His theory of essentialism is summarized as stating that an object has a certain property essentially if: 1. The object has the property. 2. The object always had the property. 3. No possible past exists where the object did not have the property. 4. There is no moment of time at which the object has had the property and at which there is a possible future in which the object exists without the property. The last two conditions he deems in need of further explanation and argumentation, and he does so in detail. The author then concludes that the (Aristotelian) theory of eessentialism he has developed gives meaning to essentialist claims in the context of a theory of identity across possible worlds and results in a intuitive view of the essential properties of an object.uthor explains in detail why Aristotle's distinction among changes causes problems with his theory of identity. <br /> The problems with his theory of identity motivate the author to consider various theories of essentialism, one being due to the philosopher Alvin Plantinga and another due to David Kaplan, both of which he rejects and gives detailed reasons for doing so. He also considers various theories of identity across possible worlds. These he also rejects, for reasons of their incompatibility with Aristotelian essentialism, which through detailed discussion, he is careful to differentiate from Leibnizian and mereological essentialism. His theory of essentialism is summarized as stating that an object has a certain property essentially if: 1. The object has the property. 2. The object always had the property. 3. No possible past exists where the object did not have the property. 4. There is no moment of time at which the object has had the property and at which there is a possible future in which the object exists without the property. The last two conditions he deems in need of further explanation and argumentation, and he does so in detail. The author then concludes that the (Aristotelian) theory of eessentialism he has developed gives meaning to essentialist claims in the context of a theory of identity across possible worlds and results in a intuitive view of the essential properties of an object.	2003-10-25
932341:US	50702879	RFGGIBV7F2O4E	0721653367	413978181	Textbook of Radiation Oncology, 1e	Books	4	7	37	N	N	A comprehensive overview	It will be interesting to see just how long radiological techniques will be used in cancer therapy in the twenty-first century. The role of genetics, particularly gene therapies are making some progress in the treatment of certain types of cancer. There have been some problems with gene therapies, these making the headlines in the major media. Therefore it is probably safe to assume that radiology will have a presence in cancer clinics in the coming decade.<br /> It has certainly had a presence throughout the twentieth century, and this book is an indication of its vast use in cancer therapy. Those interested in radiology will find a comprehensive overview. My sole interest in the book was in gaining a background in the biology and physics behind radiation dose calculations in human tissue. Therefore I only read sections 1 and 3 (the latter discussing future modalities) instead of Section 2, which discusses clinical issues, and which are a major portion of the book.<br /> Since the book is targeted towards readers who are medical students, physicians, or medical researchers, it is not surprising to find that the physics behind the interaction of radiation with human tissue is only done from a phenomenological perspective. A more in-depth discussion would perhaps not assist physicians in their administration of radiation dose to a patient. The authors do a fine job of relating to the reader what is going on physically when X-rays and particles such as protons, electrons, or heavy ions interact with matter. They also discuss just how to determine the dose delivered to the patient and the dosimetric techniques that are used. A more thorough discussion of the interaction of radiation and particle beams with matter would involve techniques from quantum field theory, bringing the book out of the range of the average medical student. Actually though, in spite of the importance of techniques such as Monte Carlo simulations in determining dose distribution (which the authors discuss briefly), and the role of elementary particle events in these simulations, the literature on radiology physics does not usually approach dose calculation from this fundamental level.<br /> The authors take a look at the future of cancer therapies in the last part of the book, and the discussion is fascinating. Some of the areas they discuss are particle radiation therapy involving proton and neutron beams. They discuss the differences from a physical standpoint in the use of these beams as compared to the usual beam modalities. Another area they discuss are gene therapies, and although brief, the authors give the reader an idea of just how this technology works.<br /> Looking further into the future, and this is justified by the current incredible rate of technological advancement, one can only wonder what new techniques will be discovered in cancer therapy and prevention.  Further improvements in gene therapy using techniques from genetic engineering comes to mind. Another possibility is nanotechnology. This is an exotic possibility at the present time, but there is every indication that nanotechnology will reach fruition by the end of the second decade of the twenty-first century. Its medical ramifications are awesome.rs discuss briefly), and the role of elementary particle events in these simulations, the literature on radiology physics does not usually approach dose calculation from this fundamental level. <br /> The authors take a look at the future of cancer therapies in the last part of the book, and the discussion is fascinating. Some of the areas they discuss are particle radiation therapy involving proton and neutron beams. They discuss the differences from a physical standpoint in the use of these beams as compared to the usual beam modalities. Another area they discuss are gene therapies, and although brief, the authors give the reader an idea of just how this technology works. <br /> Looking further into the future, and this is justified by the current incredible rate of technological advancement, one can only wonder what new techniques will be discovered in cancer therapy and prevention.  Further improvements in gene therapy using techniques from genetic engineering comes to mind. Another possibility is nanotechnology. This is an exotic possibility at the present time, but there is every indication that nanotechnology will reach fruition by the end of the second decade of the twenty-first century. Its medical ramifications are awesome.	2003-10-21
942109:US	50702879	R1VR74DPY8OI91	1558603204	520364409	Advanced Compiler Design and Implementation	Books	5	33	41	N	N	Excellent	Advances in compiler design do not get much press these days. The reasons for this are unclear, but no doubt the perception that compilers need no further improvement has something to do with this. This book, written by one of the leading experts on compilers, certainly dispels this belief. Once readers get used to the idiosyncratic ICAN (Informal Compiler Algorithm Notation) invented by the author and used throughout the book, they get a comprehensive overview of compilers, especially that of optimization. Compilers for the SPARC, PowerPC, DEC, and Pentium architectures are treated in the book. The predominant emphasis of the book is in optimization, and so a few more recent and important topics in compiler construction, such as partial evaluation, are not discussed. Readers are expected to have a prior background in elementary compiler theory. My primary interest in reading the book was to gain insight into the compilation issues that arise in symbolic programming languages such as LISP and Prolog.<br /> A detailed review of this book cannot be done for lack of space, but some of the helpful aspects and interesting discussions in the book include: 1. The \\"wrap-up\\" section at the end of each chapter, giving a compact summary of what was done in the chapter. 2. Generating loads and stores: The author shows how to move values to and from registers using routines more sophisticated than simply loading values into registers before using them or storing values as soon as they have been computed. 3. The main issues in the use of registers, such as variable allocation, efficiency of procedural calls, and scoping. The author lists the different categories that will result in contention for registers, such as stack, frame, and global offset table pointers and dynamic and static links. 4. The local stack frame and its uses, such as holding indexed variables (arrays, etc.) and debugging. 5. The five different parameter-passing mechanisms: call by value, call by result, call by value-result, call by reference, and call by name. A thorough discussion is given of their properties and what languages make use of them. In particular, the author notes that in the languages C and C++, call by value is the only parameter-passing mechanism, but that the address of an object may be passed, thus emulating essentially call by reference. This can be a source of confusion to those who program in C and C++. The most exotic of these mechanisms is call by name, which is a form of \\"lazy evaluation\\" in functional programming languages. The author gives a code example of the call by name parameter passing in ALGOL 60. I don't know of any modern practical programming languages that make use of call by name. 6. Shared libraries and the role of semantic linking and position independent code. 7. The compilation issues that arise in symbolic languages, such as LISP and Prolog. These languages typically have run-time type checking and function polymorphism, which gives them their power and ease of use. The author discusses how to produce efficient code for these languages. Since heap storage is utilized heavily by these languages, the allocation and recovering of it is very important. \\"Generation scavenging\\" is mentioned as the most efficient method for doing garbage collection in these languages. This method has been advertised in the literature as one that minimizes the time needed for storage reclamation in comparison with other approaches. In addition, the use of \\"on-the-fly\\" recompilation for polymorphic-language implementations is discussed. 8. Dynamic programming and its role in automatic production of code generators, as contrasted with the \\"greedy approach\\". The author explains the need for \\"uniform register machines\\" in the dynamic programming algorithm. 9. Interval analysis and its use in the analysis of control flow. This technique has been used in the field called \\"abstract interpretation\\" in recent years, the aim of which is too automatically and intelligently test program code. 10. Dependencies between dynamically allocated objects, such as links between graph structures in LISP and Prolog. The author describes the Hummel-Hendren-Nicolau technique for doing this, which involves naming schemes for locations in heap memory, a collection of axioms for characterizing aliasing locations among locations, and lastly, and most interestingly, utilizes a theorem prover to establish the properties of the data structures. The author emphasizes though that this technique, and others developed for doing dependence analysis of dynamically allocated objects, are very computationally intensive. 11. Individual optimizations, which the author divides into four groups in order of importance. 12. Induction-variable optimizations and their role in loop optimizations. The author shows how to identify induction variables, and how to transform them using various techniques, going by the name strength reduction, induction-variable removal, and linear-function test replacement. 13. Procedure integration and its role in \\"inlining\\" procedures in languages such as C++. The author emphasizes the drawbacks in using inlining, such as its impact on cache misses. 14. The trade-off between object abstraction and optimization, which occurs in object-oriented languages such as C++. The author discusses in detail the role of interprodecural optimizations in dealing with abstraction in the object-oriented modular approach to programming, particularly the identification of \\"side effects\\" in making procedure calls. 15. Code optimization that takes advantage of the memory hierarchy, such as data and instruction caches, and how to improve register allocation for arrays. The author gives a detailed and highly interesting discussion of scalar replacement for array elements. 16. Future trends and research in compiler design. The author mentions a few which he believes will dominate in the upcoming decade, such as scalar-oriented and data-cache optimizations. Scalar compilation will be he most active research area in his opinion. At the present time, there has been discussion of \\"intelligent compilers\\" that will interact with the user to develop optimal code, or even produce correct programs. These compilers will understand the intentions of the program and warn the user if these are violated, as well as reduce the time and cost needed for testing programs.ntelligently test program code. 10. Dependencies between dynamically allocated objects, such as links between graph structures in LISP and Prolog. The author describes the Hummel-Hendren-Nicolau technique for doing this, which involves naming schemes for locations in heap memory, a collection of axioms for characterizing aliasing locations among locations, and lastly, and most interestingly, utilizes a theorem prover to establish the properties of the data structures. The author emphasizes though that this technique, and others developed for doing dependence analysis of dynamically allocated objects, are very computationally intensive. 11. Individual optimizations, which the author divides into four groups in order of importance. 12. Induction-variable optimizations and their role in loop optimizations. The author shows how to identify induction variables, and how to transform them using various techniques, going by the name strength reduction, induction-variable removal, and linear-function test replacement. 13. Procedure integration and its role in \\"inlining\\" procedures in languages such as C++. The author emphasizes the drawbacks in using inlining, such as its impact on cache misses. 14. The trade-off between object abstraction and optimization, which occurs in object-oriented languages such as C++. The author discusses in detail the role of interprodecural optimizations in dealing with abstraction in the object-oriented modular approach to programming, particularly the identification of \\"side effects\\" in making procedure calls. 15. Code optimization that takes advantage of the memory hierarchy, such as data and instruction caches, and how to improve register allocation for arrays. The author gives a detailed and highly interesting discussion of scalar replacement for array elements. 16. Future trends and research in compiler design. The author mentions a few which he believes will dominate in the upcoming decade, such as scalar-oriented and data-cache optimizations. Scalar compilation will be he most active research area in his opinion. At the present time, there has been discussion of \\"intelligent compilers\\" that will interact with the user to develop optimal code, or even produce correct programs. These compilers will understand the intentions of the program and warn the user if these are violated, as well as reduce the time and cost needed for testing programs.	2003-10-13
944323:US	50702879	R3E1G9J0CR6E59	0262032414	195884254	The Cerebral Code: Thinking a Thought in the Mosaics of the Mind	Books	3	18	21	N	Y	Too qualitative	The author introduces the book as one about thoughts, memories, consciousness, creativity, etc., with his goal being to put these subjects in the context of an evolutionary paradigm. The cerebral cortex represents mental images via a Darwinian process, recombining them to create something totally original. When considering my dreams, or the moments of consciousness when I am just falling off to sleep, I can certainly sympathize with the author's thesis. However, throughout the book I wanted to see equations and graphs, discussions on mathematical modeling/simulations and laboratory experiments. Instead the approach is purely descriptive, making the book somewhat of a disappointment. The author though warns the reader early on that he resisted the temptation to utilize computer simulations, citing the need for clarity, and his skepticism of &quot;free-parameter curve-fitting&quot; as the main reasons. But even though the author takes a purely qualitative approach, it is still embedded in a scientific description, and not mere philosophical handwaving.<br /> The first two chapters are an overwiew of the author's solution of the representation problem, this problem in his view being which spatio-temporal pattern represents a mental object. The author is clearly influenced by the neurologist D.O.Hebb, and throughout the book he attempts to answer the representational questions that Hebb posed back in the 1940's. Cerebral representations must explain spatial-only and spatiotemporal patterns, their interconversions, redundancy, spatial extent, and imperfections, and how they are linked to associative memory. Arguing for the need for copying, the author shows how it can arise in the neocortex. His (Darwinian) mechanism for copying takes place among the interactions of the superficial pyramidal neurons, due to their physical properties and their geometric layout. Interestingly, the phenomenon of &quot;emergent synchrony&quot;, familiar to the physics reader in the motion of the double pendulum, is shown to play a role in the copying mechanism. Indeed the superficial layers of the neocortex are shown to form (ephemeral) triangular arrays interacting via entrainement.<br /> The next few chapters are devoted to showing just how the triangular arrays result in successful representations. The stability of the triangular arrays formed by the &quot;hot spots&quot; under perturbation is addressed, the author showing how the six &quot;nearest neighbors&quot; have a correcting influence on the spot if it fires out of sync with them. The minimal Hebbian cell-assembly is thus shown to be a hexagon, and that author shows how they are related to triangular arrays: namely, that two triangular arrays can alter synaptic strengths and create attractors within a hexagon's circuitry that sustain the firing pattern. The author's use of concepts and constructions from dynamical systems in this chapter and the next two is very interesting but made me thirst for more quantitative justification. Indeed chaotic dynamics is brought in to explain the &quot;memorized environment&quot;, which for the author is the most difficult problem to explain from the standpoint of his Darwinian shaping-up process.  Calling chaos &quot;controlled disorder&quot;, the author holds that the EEG patterns in deep sleep are limited-cycle rhythmicity, that Parkinson tremors are the result of fixed-point attractors, and the Necker cube perspective switching is switching in and out of lobes of an attractor. He does admit though that all these are &quot;loose analogies&quot; and goes on to explain in more detail how resonances influence cortical territory by spatio-temporal patterns that arrive by lateral cloning. The Darwinian paradigm via the overlaid hexagons is asserted to be one of the elementary mechanisms for category formation, and thus are able to deal with higher levels of abstraction, such as one finds in advanced mathematics. If the mechanism put forward by the author is correct in  explaining such high-level reasoning, this would be a major advance in cognitive science.<br /> As if detecting that the reader-scientist may be disenchanted with purely philosophical discussion, the author elaborates on his Darwinian paradigm in the rest of the book and offers a new perspective on the nature of categories in the context of this paradigm. He adheres to the assertion that categories are indispensable for using words in a referential manner, as linguistic symbols do not relate directly to the objects in the world, but to concepts of the classes which the objects belong. A hierarchical network of meanings is essential for this to occur. The author has taken on a problem of enormous difficulty here, but does give explanations that seem plausible. The &quot;hexagons for cerebral codes&quot; are capable he says of handling any level of abstraction or representation. Interestingly, his explanations make use of another concept from physics, that of Brownian motion, to discuss the role and origin of associative memory in his Darwinian paradigm. The role of &quot;recombination&quot; in the Darwinian process is explained as a need for integrating codes that are stored separately in the brain into a &quot;master code&quot; for a particular concept. &quot;Hexagonal cloning competitions&quot; are thought of as processes by which information can be (serially) ordered and missing information can be identified. The author makes his case for the utility of metaphor crystal clear, for without such metaphors he says, without imagination, we will have no mechanisms to mold experience or to discover new things. Consciousness too, deemed the most complex of phenomena to be described by a theory of brain function, is explained in the context of his hexagonal neocortical arrays. Consciousness is a result of the multiple levels of &quot;stratified stability&quot;, each of these employing Darwinian processes to enhance quality and create new things. In addition, he discusses practical consequences of his brain theory in psychiatry, rather than in merely explaining the capabilities of the brain.<br /> With more experimentation, with more modeling, with more simulations, and with further refinements and clarifications to the physical concepts which he uses, his ideas will become vastly more convincing. However exotic they may appear, his ideas, and others in brain modeling, will require careful elucidation, and future developments are to be greeted with eager anticipation.correct in  explaining such high-level reasoning, this would be a major advance in cognitive science. <br /> As if detecting that the reader-scientist may be disenchanted with purely philosophical discussion, the author elaborates on his Darwinian paradigm in the rest of the book and offers a new perspective on the nature of categories in the context of this paradigm. He adheres to the assertion that categories are indispensable for using words in a referential manner, as linguistic symbols do not relate directly to the objects in the world, but to concepts of the classes which the objects belong. A hierarchical network of meanings is essential for this to occur. The author has taken on a problem of enormous difficulty here, but does give explanations that seem plausible. The &quot;hexagons for cerebral codes&quot; are capable he says of handling any level of abstraction or representation. Interestingly, his explanations make use of another concept from physics, that of Brownian motion, to discuss the role and origin of associative memory in his Darwinian paradigm. The role of &quot;recombination&quot; in the Darwinian process is explained as a need for integrating codes that are stored separately in the brain into a &quot;master code&quot; for a particular concept. &quot;Hexagonal cloning competitions&quot; are thought of as processes by which information can be (serially) ordered and missing information can be identified. The author makes his case for the utility of metaphor crystal clear, for without such metaphors he says, without imagination, we will have no mechanisms to mold experience or to discover new things. Consciousness too, deemed the most complex of phenomena to be described by a theory of brain function, is explained in the context of his hexagonal neocortical arrays. Consciousness is a result of the multiple levels of &quot;stratified stability&quot;, each of these employing Darwinian processes to enhance quality and create new things. In addition,he discusses practical consequences of his brain theory in psychiatry, rather than in merely explaining the capabilities of the brain. <br /> With more experimentation, with more modeling, with more simulations, and with further refinements and clarifications to the physical concepts which he uses, his ideas will become vastly more convincing. However exotic they may appear, his ideas, and others in brain modeling, will require careful elucidation, and future developments are to be greeted with eager anticipation.	2003-10-11
947425:US	50702879	R1M492Z2O4VBNP	0879754982	681299447	Principia Ethica (Great Books in Philosophy)	Books	4	7	8	N	N	A first crack at modern ethics	One of the most famous treatises on ethics in the twentieth century, &quot;Principia Ethica&quot; attempts to give a non-naturalistic foundation for ethics, for what constitutes &quot;the good&quot;. The author clearly believes that &quot;goodness&quot; is not the result of sensory experience or even that it exists temporally. &quot;Goodness&quot; is a fundamental entity and cannot be defined: any attempt to do so results in the &quot;naturalistic fallacy&quot;. This fallacy is a failure, the author says, in the acknowledgement that &quot;the good&quot; is a unique and indefinable quality.<br />  When reading the book, one can detect somewhat the author's departure from his latter doctrine of &quot;ordinary language philosophy&quot; and its emphasis on how concepts &quot;do their jobs&quot;. He does not want to analyze the word &quot;good&quot; in terms of its usage, in terms of how it can, as a word denoting a concept, exemplify certain objects or phenomena existing in the world. Evidence of the &quot;good&quot; is thus not obtainable by external evidence, or custom, but instead is obtained by &quot;intuitions&quot;. An &quot;intuition&quot; is both a proposition incapable of proof and a psychological state, the latter being a collection of considerations that are capable of &quot;determining the intellect.&quot; The psychological meaning of intuition is brought about by the author's attempted refutation of hedonism due to the philosopher Henry Sidgwick. Intuition though, is not to be thought of as an alternative to reason. It furnishes a reason for holding that a proposition is true, and this adherence must occur of course for &quot;self-evident&quot; propositions. His &quot;disproof&quot; of ethical hedonism consisted only of showing what the principle &quot;pleasure is good&quot; means, and how it contradicts other propositions which appear to be equally true. The author's goal is to convince the reader of the &quot;untenability&quot; of ethical hedonism. However merely convincing, he says, does not prove we are correct, it merely justifies &quot;holding&quot; that we are so. His thinking on &quot;intuition&quot; might with complete justification be labeled as &quot;common sense&quot; and gives credence to the characterization of Moore as being a &quot;common-sense&quot; philosopher.<br /> The theory of evolution was relatively new when this book was first published, but ethical theories based on evolution were already in place.  It is not surprising therefore to find some of the author's commentary on these ethical formulations in this book. The &quot;evolutionary ethics&quot; of Herbert Spencer and M. Gayau is argued to be another example of the &quot;naturalistic fallacy&quot;. That the direction in which biological systems are evolving is confused with the direction in which they should evolve, is a manifestation of this fallacy, he argues. The equating of &quot;is&quot; with &quot;ought&quot; has been thought of by many ethicists after Moore as being the main sticking point in developing a scientific theory of ethics.<br /> The author's argumentation on ethics would be mere sophistry if he did not relate it to actual human conduct. &quot;Practical ethics&quot; answers what we ought to do, i.e. what actions are to be deemed right and what are to be deemed wrong. The answers it gives are to be cast into a framework that makes clear the relation of the actions to what is good in itself. A duty is thus thought of as an action which will result in a situation that is better than any alternative. Such duties though rarely transcend the historical context in which they are to be practiced. Actions that are proved to be of &quot;general&quot; utility should always be performed, but those that are not are to be judged as to the &quot;probable&quot; results in particular cases. Thus the author unwittingly gives an early hint of the ethical theories of the 21st century: the theories of rational agents.er merely convincing, he says, does not prove we are correct, it merely justifies &quot;holding&quot; that we are so. His thinking on &quot;intuition&quot; might with complete justification be labeled as &quot;common sense&quot; and gives credence to the characterization of Moore as being a &quot;common-sense&quot; philosopher.  <br /> The theory of evolution was relatively new when this book was first published, but ethical theories based on evolution were already in place.  It is not surprising therefore to find some of the author's commentary on these ethical formulations in this book. The &quot;evolutionary ethics&quot; of Herbert Spencer and M. Gayau is argued to be another example of the &quot;naturalistic fallacy&quot;. That the direction in which biological systems are evolving is confused with the direction in which they should evolve, is a manifestation of this fallacy, he argues. The equating of &quot;is&quot; with &quot;ought&quot; has been thought of by many ethicists after Moore as being the main sticking point in developing a scientific theory of ethics. <br /> The author's argumentation on ethics would be mere sophistry if he did not relate it to actual human conduct. &quot;Practical ethics&quot; answers what we ought to do, i.e. what actions are to be deemed right and what are to be deemed wrong. The answers it gives are to be cast into a framework that makes clear the relation of the actions to what is good in itself. A duty is thus thought of as an action which will result in a situation that is better than any alternative. Such duties though rarely transcend the historical context in which they are to be practiced. Actions that are proved to be of &quot;general&quot; utility should always be performed, but those that are not are to be judged as to the &quot;probable&quot; results in particular cases. Thus the author unwittingly gives an early hint of the ethical theories of the 21st century: the theories of rational agents.	2003-10-08
952129:US	50702879	R1PD22H9WEOTGH	0387979034	508597186	Chaos and Fractals: New Frontiers of Science	Books	4	8	8	N	N	A good introduction	Chaos as a physical theory began essentially in the 1970's, but as a mathematical field it has existed since the early 1900's. This book covers only the mathematical study of chaos, and is addressed to those readers who have a fairly strong background in undergraduate mathematics. A knowledge of dynamical systems and measure theory would help in the appreciation of the book, but are not absolutely necessary. The application of fractals and chaos to finance is now legendary, but other applications, such as to packet networks and surface physics are not so well-known. Current research in chaos is done predominantly in the context of information theory, wherein the goal is to understand the difference between chaos and noise, and develop mathematical tools to quantify this difference. The BASIC code in the book gives away its age, but can be easily translated to one of the symbolic computing languages available now, such as Maple or Mathematica.<br /> This is a sizable book, and space prohibits a detailed review, but some of the more interesting discussions in it include: 1. The video feedback experiment, which can be done with only a video camera and a TV set. This is always a crowd pleaser, at whatever level of the audience it is presented to. 2. The comparison between doing iteration of a chaotic map on two different calculating machines: a CASIO and an HP. The difference is very dramatic, illustrating the effect of finite accuracy arithmetic. 3. The pictures illustrating the Chinese arithmetic triangle and Pascal's triangle as it appeared in Japan in 1781. 4. The space-filling curve and its relation to the problem of defining dimension from a topological standpoint. This discussion motivates the idea of covering dimension, which the authors overview with great clarity. They also give a rigorous definition of the Hausdorff dimension and discuss its differences with the box counting dimension. 5. The many excellent color plates in the book, especially the one illustrating a cast of the venous and arterial system of a child's kidney. 6. The difficulty in measuring power laws in practice. 7. Image encoding using iterated function systems, which has become very important recently in satellite image analysis. This leads into a discussion of the Hausdorff distance, which is of enormous importance not only in the study of fractals but also in general topology: the famous hyperspaces of closed sets in a metric space. 8. The relation between chaos and randomness, discussed by the authors in the context of the \\"chaos game.\\" 9. L-systems, which are motivated with a model of cell division. 10. the number theory behind Pascal's triangle. 11. The simulation of Brownian motion. 12. The Lyapunov exponent for smooth transformations. 13. The property of ergodicity and mixing for transformations, the authors pointing out that true ergodic behavior cannot be obtained in a computer where only a a finite collection of numbers is representable. 13. The concept of topological conjugacy. 14. The existence of homoclinic points in a dynamical system. These are very important in physical applications of chaos. 15. The Rossler attractor and its pictorial representation. 16. How to calculate the dimensions of strange attractors. 17. How to calculate Lyapunov exponents from time series, which is of great interest in many different applications, especially finance. 18. The Julia set, which the authors relate eventually to potential theory.rating a cast of the venous and arterial system of a child's kidney. 6. The difficulty in measuring power laws in practice. 7. Image encoding using iterated function systems, which has become very important recently in satellite image analysis. This leads into a discussion of the Hausdorff distance, which is of enormous importance not only in the study of fractals but also in general topology: the famous hyperspaces of closed sets in a metric space. 8. The relation between chaos and randomness, discussed by the authors in the context of the \\"chaos game.\\" 9. L-systems, which are motivated with a model of cell division. 10. the number theory behind Pascal's triangle. 11. The simulation of Brownian motion. 12. The Lyapunov exponent for smooth transformations. 13. The property of ergodicity and mixing for transformations, the authors pointing out that true ergodic behavior cannot be obtained in a computer where only a a finite collection of numbers is representable. 13. The concept of topological conjugacy. 14. The existence of homoclinic points in a dynamical system. These are very important in physical applications of chaos. 15. The Rossler attractor and its pictorial representation. 16. How to calculate the dimensions of strange attractors. 17. How to calculate Lyapunov exponents from time series, which is of great interest in many different applications, especially finance. 18. The Julia set, which the authors relate eventually to potential theory.	2003-10-05
956204:US	50702879	R17QOTWJJXQ81R	0451149165	970161710	The Romantic Manifesto: A Philosophy of Literature; Revised Edition (Signet Shakespeare)	Books	3	8	22	N	N	Needs considerable revision	This book attempts to give an apology for the Romantic movement in art and literature, and the author describes herself as part of this movement. For readers who are familiar with her novels, her adherence to this movement will be obvious. Those who have not read them, but instead are merely interested in studying this book because of their interest in aesthetic philosophy, may find the coverage too scant and the dialog too harsh for their tastes. This is not to say that there are not some interesting discussions in the book. For example, the chapter entitled &quot;Art and Cognition&quot; should catch the attention of readers with a background in artificial intelligence, psychology, or neuroscience. In this chapter the author, interestingly, asserts that humans need art simply because their cognitive faculties are conceptual in nature. The acquisition of human knowledge is done via abstractions, and art assists in the need in bring these abstractions to perceptual awareness, argues the author. Art makes concrete the fundamental views that each human has of their place in existence. Art gives information on which parts of human experience are regarded as fundamental or important by a particular individual. Painting, drawing, music, literature, sculpture, etc. are thus a consequence of the cognitive abilities of humankind. Hence entities that employ similar abilities would also tend to engage in artistic endeavors, whether they are human or not. Unfortunately, the author does not offer any evidence to support her assertions connecting artistic activity with cognition. Such evidence would ideally come from studies in neuroscience, and would be of great interest to those curious about the need for art in performing conceptual analysis, and vice versa. Indeed, even one of the most intense of cognitive activities, mathematics, requiring a high degree of both creativity and logic, has been deemed by some to be more of an art, rather than a purely logical activity.<br /> Since the author is a philosopher, and not a scientist, it should not be surprising to see that scientific evidence for its claims is not included. Most books on the philosophy of aesthetics do not include such evidence. However, the author makes claims in many parts of the book that such evidence is there, in fact, a &quot;great deal&quot; of such evidence, that offers support to her claims. However, absolutely no references are given for the interested reader. In addition, most authors of philosophical treatises on aesthetics approach the subject with a calmness of spirit that is not exhibited by the author of this book. It does not help the reader understand the issues in the philosophy of aesthetics by referring to certain areas of art as being a sign of a &quot;bankrupt&quot; culture.<br /> Much time is spent in the book as an apology for the Romantic school of art, as of course its title implies. The Romantic school is to be differentiated from the Naturalistic one, with the former being more desirable or &quot;rational&quot;. The author describes today's literature as being in a state of &quot;eclectic shambles&quot;, and, with only a few exceptions, no literary movement of any value and significant influence. Only &quot;bewildered imitators&quot; and charlatans are representative of today's literature, she asserts. Needless to say this kind of language has no place in philosophy, science, literature, or any other field of endeavor. Ironically, the author has herself received a vituperative commentary in the print media, which she herself has objected to.<br /> A radical revision of this book would be needed if it were to meet the standards of scientific evidence that the author in many places claims exists for it. With its thought experiments and wide variability in its language, philosophy typically misses its mark in its descriptions and its search for truth. This work is no different in this regard, and does not deliver a successful theory of aesthetics ora sound apology for a particular school of art or literature.or a sound apology for a particular school of art or literature.	2003-10-01
960084:US	50702879	R37GXTEG349IC0	0750633719	750358026	004: Quantum Electrodynamics, Second Edition: Volume 4 (Course of Theoretical Physics)	Books	4	19	22	N	N	A good introduction	This book gives a solid introduction to the simplest of gauge theories, that of the Abelian gauge field governing the interactions between photons and charged particles. The emphasis is on doing calculations, and so readers who need a more in-depth mathematical or &quot;foundational&quot; overview of quantum electrodynamics may be disappointed. Quantum field theory of course was not founded on the need for mathematical rigor in physics, but instead has its origins in reconciling quantum mechanics with the theory of special relativity. This reconciliation has sometimes been a rough road, and in many places employs some sophisticated but eccentric &quot;trickery&quot; on the part of the researchers. It is these tricks that are the most difficult to generalize, to the annoyance of mathematicians who want to put quantum field theory on a more rigorous mathematical foundation. But in spite of the use of these oddities quantum field theory is not magical, and has proven to be one of the most precise physical theories ever constructed.<br />Some of the highlights of the book:<br />1. The chapter on exact propogators and vertex parts is particularly illuminating, especially the discussions on Dyson's equation, Ward's identity, and the physical conditions needed for renormalization. Dyson's equation relates the vertex part to the exact propagator, and the authors derive it using two different approaches in the book: one using the concepts of reducible and irreducible diagrams, the other using direct calculation and taking the Fourier transform. Readers who go on in quantum field theory will find that this equation is usually called the Dyson-Schwinger equation and can be derived using &quot;functional methods.&quot; Ward's identity is a relation that connects the momentum derivative of the electron propagator to the vertex part, but can derived solely by using gauge invariance. Applying a gauge transformation to the electron propagator will result in an expression involving an external (photon) field. This expression though has a contribution coming from photons with longitudinal components in their momentum, but the expression is shown to vanish. Hence, as expected, gauge invariance results in an electron propagator that does not involve massive photon fields, and its momentum derivatives are equal to the vertex part. The authors point out that this identity generalizes the expression for the case of the free-particle propagator.<br />2. The discussion on the radiative corrections to Coulomb's law, resulting from the &quot;polarization of the vacuum&quot; around a point charge. The corrections are done via the use of an &quot;effective field&quot;, thus introducing the reader to a very common approach these days. After taking Fourier transforms the authors show that the polarization of the vacuum alters the Coulomb field in a region inversely proportional to the electron mass. Beyond this region the change drops off exponentially. The authors point out though that they have ignored the contributions of pions and muons in their calculation of the correction. At distances less than one over the muon (or pion) mass, the strong interaction must be taken into account and quantum electrodynamics breaks down.<br />3. The discussion on photon-photon scattering, which is a strictly quantum effect since it cannot occur in classical electrodynamics, due to the linearity of Maxwell's equations. It is the electron-positron annihilation which is responsible for this effect, and this is one example of the matter-antimatter duality that seems to always occur in quantum theories that must respect the principle of relativity (although, strictly speaking, another assumption, called &quot;cluster decomposition&quot; is needed to show this in a convincing way).<br />4. The (short) chapter on hadron electrodynamics, with &quot;electromagnetic form factors&quot; used to finesse the problem of the strong interaction. One thus gets a purely phenomonological theory, but one that still allows the calculation of electron-hadron and photon-hadron scattering.l theory, but one that still allows the calculation of electron-hadron and photon-hadron scattering.	2003-09-28
961159:US	50702879	R2ILEL4L917TOI	067167336X	147118027	Love and Friendship	Books	3	16	29	N	N	The author was born 400 years too late.	A brilliant writer and social critic, and known as one of the best Greek scholars of the twentieth century, the author gives in this book his insights and concerns regarding the status of love and friendship as humanity moved closer to the 21st century. As in his earlier writings, the author sometimes is right on target, and at other times dead wrong. Indeed, in the latter case, the author's claims are surprising considering his sometimes considerable insight into American culture.<br /> The author expresses deep regret at the current status of &quot;eros&quot;. Science, he says, has reduced love to sex, and the word &quot;love&quot; has been applied to most everything except for the overwhelming attraction of one individual to another. People are too open about sex, he complains, and have lost their &quot;puritanical shame&quot; when discussing it in public. But, he does not substantiate his assertions with any amount of statistics. If he did this, it would make this book a scientific study, and the author believes clearly has a negative attitude about science. It is responsible for getting us into this trouble, e.g. the Kinsey report.<br /> All the talk about &quot;relationships&quot; is not any good either, according to the author. Egalitarianism and individualism have reduced romantic relationships to contractual matters. In addition, the last one hundred years has not seen any great &quot;novelists of love&quot;. The current romantic novel is &quot;cheap&quot; and suitable only for housewives. To be a romantic today, he says, is like being a &quot;virgin in a whorehouse&quot;, and does not conform to the times. Again though, no statistical support is given. The author shouts loud, and carries a small stick of evidence.<br /> The many unsubstantiated claims in the book are balanced by some of its virtues. The author's use of Rousseau is clever, and his analysis of Julien Sorel, the individualistic rogue of Stendahl's &quot;Red and the Black&quot; is brilliant. In fact, all who love (love?) this novel would benefit greatly from reading the author's opinions of it. He sees correctly that there is a fight between the ancients and the moderns. But what he does not see is that the moderns are clearly winning, but only because of what they have inherited from the ancients.<br /> Far from science demeaning the value of love and sex, it has enhanced it. It has taught us that the imagination is not some uncaused force that comes from outside us, but instead is part of who we are. We in large measure, via our ideas and thoughts, determine its contents. But our brains can shuffle these ideas and thoughts and create ones more interesting, fun, and erotic than what perhaps we intended. The more sophisticated our understanding of our brains, the more we appreciate their workings, and the more intoxicated we become in the free play of our imagination.<br /> Contrary to what the author claims, romance has not been reduced to  a contract. Certainly views of marriage have changed as compared to what they were centuries ago. Marriage at that time was typically arranged or thought of as an economic contract, and, most importantly, those kinds of marital arrangements were not frowned upon by those who participated in them. But now love is thought of as more precious, as something not to be tainted by economic considerations. If one is &quot;marrying for money&quot; that is something to be kept hidden, and brings shame to those who admit to it. Indeed, how very different are the views now on marriage! We are now marrying for love, and when compared with the marriages of the 16th century, this is a radical notion.t. In fact, all who love (love?) this novel would benefit greatly from reading the author's opinions of it. He sees correctly that there is a fight between the ancients and the moderns. But what he does not see is that the moderns are clearly winning, but only because of what they have inherited from the ancients. <br /> Far from science demeaning the value of love and sex, it has enhanced it. It has taught us that the imagination is not some uncaused force that comes from outside us, but instead is part of who we are. We in large measure, via our ideas and thoughts, determine its contents. But our brains can shuffle these ideas and thoughts and create ones more interesting, fun, and erotic than what perhaps we intended. The more sophisticated our understanding of our brains, the more we appreciate their workings, and the more intoxicated we become in the free play of our imagination. <br /> Contrary to what the author claims, romance has not been reduced to  a contract. Certainly views of marriage have changed as compared to what they were centuries ago. Marriage at that time was typically arranged or thought of as an economic contract, and, most importantly, those kinds of marital arrangements were not frowned upon by those who participated in them. But now love is thought of as more precious, as something not to be tainted by economic considerations. If one is &quot;marrying for money&quot; that is something to be kept hidden, and brings shame to those who admit to it. Indeed, how very different are the views now on marriage! We are now marrying for love, and when compared with the marriages of the 16th century, this is a radical notion.	2003-09-27
962504:US	50702879	R3TGHTPDKALOHJ	0521567041	426290981	Nietzsche: Human, All Too Human: A Book for Free Spirits (Cambridge Texts in the History of Philosophy)	Books	5	32	41	N	N	One of the funnest books ever written	Nietzsche is always fun in all of his writings, and this book is one of his best in this regard. It is better than morning coffee in stimulating the mind, and one cannot read it without frequent chuckles. One can only wonder if Nietzsche would have been as personable in real life as he is in this book. One can say with certainty though that Freud was right in stating that Nietzsche new more about himself than most any other human being...but also, he knew more about other humans than perhaps any other human being. Nietzsche incites the reader to recklessness, and this gives the book its value. Everyone needs free play: a run up the steps of Ephesus. The Nietzschean project of drunken Dionysian ecstacy can be accomplished by the perusal of the written word: this book is ample proof of that.	2003-09-26
962564:US	50702879	R2VWBHVN7B670A	0471983667	479366721	Derivatives: The Theory and Practice of Financial Engineering (Frontiers in Finance Series)	Books	4	4	4	N	N	A fine introduction from the standpoint of PDEs	Financial engineering as a profession has exploded in the last 15 years, and has enlisted the minds of mathematicians, physicists, economists, engineers, as well as course everyday brokers and traders. This book is geared towards a mathematical audience, as one will need a background in the numerical solution of nonlinear partial differential equations and an understanding of stochastic processes (at the level of the Ito calculus). The author does devote a chapter to partial differential equations for readers who need it. Those readers with such a background will find the book very straightforward to read, especially those readers who are mathematicians or physicists, and are desiring to enter into the exciting field of financial engineering. The book is out of print, and an updated collection of books has been written by the author, but this one could still serve as an excellent introduction to the subject. In addition, this book has exercises, while the updated ones do not. Most of the results in the book can be used to develop practical trading strategies, and so the book qualifies more than being a mere academic exercise.<br /> The author's approach is not always rigorous from a mathematical standpoint, but this is fine since the emphasis is on developing insight into the principles behind the subject, such as the principle of arbitrage, the idea of hedging, etc. Early on, the author shows what is involved in removing oneself from the Black-Scholes world, with clear explanations of jump conditions, time-dependent volatility, and path dependency. The discussion on the valuation of American style options using partial is illuminating considering this is typically done with Monte Carlo simulations. Another interesting part of the book is the derivation of the partial differential equation for the market price of volatility risk. In addition, the author gives an overview of how to speculate with options, a topic that is truly removed from the Black-Scholes world, but of course is taken up with enthusiasm by many traders the world over. This discussion is very interesting, in that it sheds light on just how subjective preferences enter into options trading; but it also shows that such preferences can be treated quantitatively. Assuming the asset price follows a random walk, the author derives an equation for the present value of the expected payoff, an equation that differs from the Black-Scholes equation in having the drift rate rather than the interest rate in the delta term. This risk-neutral valuation is dealt with in more detail in the author's discussion on portfolio management.<br /> The author uses spreadsheets and Visual Basic to perform some of the numerical calculations, with many included on the accompanying CD. This is done no doubt to maintain the connection with practical trading. All of the mathematics and numerical studies could be done more efficiently though with a high-level programming language, such as Mathematica or Maple. The graphical capabilities of these languages will allow the reader to view the results of the calculations on-the-fly.<br /> Some omissions in the book include discussions on energy and weather derivatives, but these are covered, although in not too much detail, in the author's more recent books. Also omitted is any discussion on bandwidth markets or derivatives trading in network capacity. This is also a new area, but one that is growing rapidly. Discussion of it will no doubt be included in future books on derivatives.but of course is taken up with enthusiasm by many traders the world over. This discussion is very interesting, in that it sheds light on just how subjective preferences enter into options trading; but it also shows that such preferences can be treated quantitatively. Assuming the asset price follows a random walk, the author derives an equation for the present value of the expected payoff, an equation that differs from the Black-Scholes equation in having the drift rate rather than the interest rate in the delta term. This risk-neutral valuation is dealt with in more detail in the author's discussion on portfolio management. <br /> The author uses spreadsheets and Visual Basic to perform some of the numerical calculations, with many included on the accompanying CD. This is done no doubt to maintain the connection with practical trading. All of the mathematics and numerical studies could be done more efficiently though with a high-level programming language, such as Mathematica or Maple. The graphical capabilities of these languages will allow the reader to view the results of the calculations on-the-fly.  <br /> Some omissions in the book include discussions on energy and weather derivatives, but these are covered, although in not too much detail, in the author's more recent books. Also omitted is any discussion on bandwidth markets or derivatives trading in network capacity. This is also a new area, but one that is growing rapidly. Discussion of it will no doubt be included in future books on derivatives.	2003-09-26
966432:US	50702879	R2JA9RAYOPAMU5	0486234312	612683853	Crystals and Light	Books	4	7	7	N	N	Good introduction for beginners	The ability of calcite crystals to display double diffraction is interesting and one of the more popular demonstrations in physics classes all over the world. This book gives a good introduction to optical cystallography and is written for individuals that have no previous background in optics or materials science. It goes without saying that optical crystallography is of enormous importance technologically, and employs thousands of technicians, engineers, and scientists. There is not one part of this field that is not interesting, and readers will see why when perusing this book.<br />  Crystallography makes heavy use of a branch of mathematics called group theory, in order to describe the symmetries of crystals. The author uses the concept of a group in this book, but only descriptively, so as to keep the book geared toward a general audience. For example, a &quot;point group&quot; is defined as a collection of operations on an object that leave one point in the object fixed and also preserves distances between the points constant. The author gives examples of symmetry operations that cannot be part of a group. She then goes on to show that not all possible point groups can be used to describe the symmetry of arrangement of atomic planes in crystals, and thus the number of possible point groups is 32. The includes two tables of all 32 of these crystallographic point groups, one table where the point groups are listed by symbols with the symmetry elements of each group tabulated, the other table composed of diagrams of the symmetry elements and their stereographic projections.<br />  Readers will still have to know some elementary mathematics, such as trigonometry, in order to appreciate the Bragg law of X-ray diffraction. The importance of this law cannot be overstated, as the use of it gives us information on the distances between the crystallographic planes.<br />  The author also includes some brief history of the discoveries in crystallography. In addition, color photographs are included to illustrate the optical phenomena between crossed polarizers, uniaxial interference, and general interference. With a few cheap polarizers and optical materials, readily available from scientific supply houses, readers will be ready to experiment with the concepts that are discussed in this book.ion, color photographs are included to illustrate the optical phenomena between crossed polarizers, uniaxial interference, and general interference. With a few cheap polarizers and optical materials, readily available from scientific supply houses, readers will be ready to experiment with the concepts that are discussed in this book.	2003-09-22
966675:US	50702879	R2P85JGBC80V8Q	0521278589	348211421	Quantum Fields in Curved Space (Cambridge Monographs on Mathematical Physics)	Books	4	14	17	N	N	Out of date but motivates modern developments	At the time of publication of this book, there was growing interest in how to formulate quantum field theory in spactimes with curved metrics with the intent of studying to what extent a non-flat curvature would change the properties and behavior of quantum fields as compared to the Minkowski case.The authors give an introduction to this research and they do a good job in that regard. Due to the influence of superstring and M-theory on high energy physics at the present time, fewer researchers are studying the problems as they are cast in this book. On the other hand, interest in the Casimir effect and the behavior of quantum fields at boundaries is still very much alive. This book could still be use to motivate this research. It is expected that anyone reading this book will have a background in quantum field theory in flat space, but one could still perhaps read it without such a background.<br />  Quantum field theory in flat spacetime is difficult enough, and it is still not entirely understood from a mathematical perspective. Even the physics of interacting quantum fields is still poorly understood in flat spacetime, especially in its ability to predict a bound state. Therefore, it might seem a bit disconcerting to some for researchers to add further complications to quantum field theory by casting them in curved backgrounds. However, cosmological and astrophysical interests drives this research, as well as more practical considerations arising from the Casimir effect.<br />  The renormalization procedures in quantum field theory are further complicated in curved spacetime via the \\"trace\\" or \\"conformal\\" anomalies. The reader gets a good dose of these in the book in the discussion on the renormalization of the stress. The idea of an \\"effective\\" action, which has been exploited with zeal in the flat spacetime case, appears here also.<br /><br />  The most important thing to carry away from this book is that the idea of a particle in curved space quantum field theory is not very well-formulated, i.e. particle detectors in such situations are not related to the quantity of matter present in a region as they are in the flat-space case. Doing quantum field theory when gravity is present has instigated a huge amount of research, related to the still unsolved problem of just how to quantize the gravitational field.theory is not very well-formulated, i.e. particle detectors in such situations are not related to the quantity of matter present in a region as they are in the flat-space case. Doing quantum field theory when gravity is present has instigated a huge amount of research, related to the still unsolved problem of just how to quantize the gravitational field.	2003-09-22
968221:US	50702879	R3GNAE1HKR3JXO	081763844X	862773241	A General Topology Workbook	Books	4	5	6	N	N	A concentrated, intense way to learn general topology	This book brings back memories of a graduate course in general topology that I took as an undergraduate, which was taught via the &quot;Moore method&quot;, after the late Robert Lee Moore, who invented it. Handouts were given to the class (there were only 3 of us), and each of us was expected to work out or prove every result in the handout, without consulting references or collaborating with other students. Theorems were to be proved, or counterexamples given, but we did not know a priori which item from the handout was actually true or false. Needless to say this took a lot of work, and all of us had to present our results on the blackboard for scrutiny by both classmates and instructor.<br />  The Moore method has its defenders and detractors. It certainly encourages originality of thought and strict intellectual honesty. Students can find incredible reinforcment as they discover that they can indeed give original proofs of sometimes very difficult (and famous) results in general topology. The downside is that not as much material is covered as compared to a traditional course in general topology. Students who are hungry to get to the frontiers of research might become impatient because of this.<br />  This book does not follow the strict methodologies that we followed in our class, but instead reveals to the reader which results are true and then encourages their proof. Readers are also lead through the construction of examples and counterexamples, allowing them to gain more of the intuition needed for a thorough understanding of general topology. It is also a good book to use for independent study, as the answers to the results are given in the book (and this actually is the major portion of its bulk).	2003-09-21
977033:US	50702879	R1ALX07B2QP1J2	1584502789	152695343	AI Application Programming (Charles River Media Programming)	Books	4	31	41	N	Y	Good introduction for beginners to AI	Artificial intelligence has grown by leaps and bounds in the last 50 years, but during this time it has also seen a lot of valleys and backwashes, especially in the field of robotics. The unrelenting obsession, driven mostly by military needs, for creating autonomous thinking robots has met with considerable disappointment in the last few decades. This has caused some researchers to distance themselves from the words &quot;artifical intelligence&quot; in order to regain the confidence of funding sources. Thus one hears the words &quot;computational intelligence&quot; or &quot;cognitive science&quot; to describe the field. But sometimes words can accurately describe concepts or properties even they were chosen somewhat cavilierly. &quot;Computational intelligence&quot; could thus be viewed as that branch of artificial intelligence which primarily deals with algorithms designed to deal with large amounts of data, finding interesting and nontrivial patterns thereof.<br /> The content of this book could be viewed as a collection of algorithms in computational intelligence, but also includes topics not usually included in this classification, such as intelligent agents. Indeed, the concept of intelligent agents that the author discusses in the last chapter of the book draws on what he has done before it. The techniques and algorithms that he discusses in these chapters, such as neural networks, genetic algorithms, fuzzy logic, decision trees, and natural language processing, supply the decision-making capabilities for the intelligent agents. These intelligent agents can be viewed as a step towards resolving one of the major issues in artificial intelligence, namely of constructing intelligent software or machines that work in more than one domain. Playing good chess does not mean playing good poker, but developments in agent theory show promise in making expertise in both of these games a reality.<br /> Some of the algorithms discussed in the book have their origins in physics (simulated annealing), biology (adaptive resonance theory, ant algorithms, genetic algorithms, and artificial life), and brain modeling (neural networks). The reader will also be introduced to some of the older methods in artificial intelligence, such as rule-based systems (loosely referred to as GOFAI for &quot;good ole-fashioned artificial intelligence by some researchers). Source code in ANSI C is given for the algorithms, even though the resulting programs are command-line driven. In spite of this, and in spite of no use whatsoever made of Prolog or LISP, all of the chapters in this book will serve to introduce the beginning student or practicing scientist to useful algorithms in AI.<br /> After many letdowns in the past five decades, and also many accomplishments, artificial intelligence is now taking off, and has invaded many different fields with a vengeance. Indeed, financial engineering, bioinformatics, network engineering, elementary particle physics, manufacturing, computer games, and many other fields are making heavy use of intelligent algorithms. A lot of this use has been driven also by the rise of the Internet and the dramatic increase in computational power of computer hardware. Even robotics, the field that has been a source of frustration for researchers in AI, has now shown every sign of finally moving ahead. Without a doubt the 21st century will see the presence of thinking machines. These may not take the form they do in popular entertainment, but in whatever context they are used, one will be able to trace their abilities to the painstaking and patient efforts of the many early researchers in AI. The minds of these machines, however exotic they may be, however advanced they may be, and however they are used, will be products of the incredible originality and skill of the human mind.hysics (simulated annealing), biology (adaptive resonance theory, ant algorithms, genetic algorithms, and artificial life), and brain modeling (neural networks). The reader will also be introduced to some of the older methods in artificial intelligence, such as rule-based systems (loosely referred to as GOFAI for &quot;good ole-fashioned artificial intelligence by some researchers). Source code in ANSI C is given for the algorithms, even though the resulting programs are command-line driven. In spite of this, and in spite of no use whatsoever made of Prolog or LISP, all of the chapters in this book will serve to introduce the beginning student or practicing scientist to useful algorithms in AI. <br /> After many letdowns in the past five decades, and also many accomplishments, artificial intelligence is now taking off, and has invaded many different fields with a vengeance. Indeed, financial engineering, bioinformatics, network engineering, elementary particle physics, manufacturing, computer games, and many other fields are making heavy use of intelligent algorithms. A lot of this use has been driven also by the rise of the Internet and the dramatic increase in computational power of computer hardware. Even robotics, the field that has been a source of frustration for researchers in AI, has now shown every sign of finally moving ahead. Without a doubt the 21st century will see the presence of thinking machines. These may not take the form they do in popular entertainment, but in whatever context they are used, one will be able to trace their abilities to the painstaking and patient efforts of the many early researchers in AI. The minds of these machines, however exotic they may be, however advanced they may be, and however they are used, will be products of the incredible originality and skill of the human mind.	2003-09-13
977874:US	50702879	RWFGGA68IADJE	0262531208	737349190	The Computational Brain (Computational Neuroscience)	Books	5	26	26	N	Y	Excellent	This book can be viewed as one of the first attempts to use results from psychology, neuroscience, computer science, and philosophy with the intent of gaining an understanding of how the mind/brain works, but all of this is done within the &quot;computational mind&quot; paradigm. The approach taken by the authors is one of the most honest of those in the literature, for throughout the book they are careful to note just how much evidence there is to support their position(s), and to what extent further work is to done. Philosophically speaking, the authors are clearly in the materialist camp, believing that Cartesian dualism does not cohere with current scientific knowledge. But they state that materialism is not an established fact, allowing the possibility, but not the probability, that dualism may in fact be true. They reject early on though any &quot;arguments from ignorance&quot;  in their assertion that just because neuroscience does not have an explanation of consciousness, that such an explanation is impossible. The authors call the failure to be able to think of consciousness in terms of neuronal activity &quot;intuition dissonance&quot;, and reject completely its efficacy in establishing the truth of the nature of the mind/brain.<br /> The underlying theme in the book is to explain emergent properties as &quot;high-level&quot; effects that are dependent on &quot;lower-level&quot; phenomena, hence rejecting the thesis that they are &quot;nomologically autonomous&quot;, i.e. that such a dependence cannot be done and is outside the domain of science. The science in this book recognizes its historical origins, and it is clear that the authors will not accept explanations of the mind/brain that do not involve scientific experimentation and analysis. Much has been done experimentally in neuroscience since this book was published, especially using the techniques of magnetic resonance imaging (MRI). A brief discussion of MRI is given in the Appendix of the book, but no doubt if the book were updated there would be a lengthy overview of it. The current experimental situation in neuroscience has led some to predict a total &quot;reverse engineering&quot; of the brain in the upcoming decades. This prediction is an optimistic one, but no doubt detailed knowledge of the brain will continue to accelerate, this being a sign of what the authors call &quot;a remarkable time in the history of science&quot;.<br /> The authors devote an entire chapter to the computational modeling of the brain, mostly of course dealing with the mathematics of neural networks. The approach in this chapter though is still at a level that would allow a general audience to follow it. Readers with a background in physics, especially statistical physics, will appreciate more the discussion on Hopfield networks and Boltzmann machines. Experimental results are inserted as graphs throughout the book, with detailed explanation. As a whole the discussion of the biology of the brain is purely descriptive, and the line drawings could stand some improvement.<br /> The chapter on neuronal plasticity is the most interesting in the book, the authors viewing the brain as an entity that is continuously undergoing modification. Their stated goal in the chapter is to explain how the &quot;local&quot; property of plasticity can result in the &quot;global&quot; property of learning. Clearly intelligence to the authors is an emergent property, i.e. an object or device may be characterized as intelligent without its components being intelligent. Particularly interesting in this chapter was the discussion of the amnesia of a patient who underwent bilateral resection of mesial temporal lobe structures. The time scales of the patient's memory are striking: he remembered things before the surgery but could not remember things that happened a few minutes or hours ago, but could remember things within a minute in his past. The authors also mention the fascinating work of Antonio Damasio and his collaborators, this research being even more important at the present time. The scientific study of consciousness is just beginning and no doubt this study will give many surprises as it develops throughout the twenty-first century.amasio and his collaborators, this research being even more important at the present time. The scientific study of consciousness is just beginning and no doubt this study will give many surprises as it develops throughout the twenty-first century.	2003-09-13
985865:US	50702879	RZ058XZTSNZ7M	0375420703	663052603	Eating in the Dark:  America's Experiment with Genetically Engineered Food	Books	3	10	24	N	Y	An inadvertent apology for organic foods	The current conflict between the advocates of non-GM and GM foods shows no sign of abatement. The arguments on both sides of the debate can reach levels of vituperation that are reminiscent of those that took place between the advocates of AC and those of DC power early in the twentieth century. The author of this book, by attending hundreds of meetings and conducting many interviews spanning a four-year period from 1997 to 2001, has given the reader a fairly good historical account of the GM debate. She is clearly not an advocate of the marketing of GM foods (at least without labeling them as such), and this gets in the way of presenting a book that is \\"fair and balanced\\" from a scientific point of view. Readers should not expect any kind of detailed scientific argumentation in this book, but they will gain some insight into the contentious political issues that have arisen in biotechnology. Those readers, like myself, who advocate the practice of genetic engineering will perhaps, after the reading the book, become somewhat concerned about the lack of zeal among the executives of the major biotechnology companies in backing up their products. This lack of enthusiasm should be replaced by unashamed pride in their accomplishments, and they should stand behind their products, instead of cowering to groups who lack scientific credentials in biology and chemistry. It is readily apparent, when reading the book, that it is the organic food industry that stands the most to lose if GM foods are accepted by consumers. It is thus not surprising to learn that their objections are detailed throughout the book.<br /> The reference to consumers as being \\"force-fed\\", as chapter one is titled, already serves to bias the discussion against GM foods. The omission of information or labels does not by itself force people to purchase any food products, organic or otherwise. If consumers suspect that any of the foods they purchase are contaminated in any way, they are free not to purchase them. In addition, the dialog in this book, as in many others (both for and against GM foods), is targeted toward an abstraction called the \\"public\\". The members of the \\"public\\" never seem to be characterized explicity, but instead the \\"public\\" is used to justify social and political policy that must be put into place to protect the \\"public\\".<br /> The author quotes individuals in the book who consider the genetic engineering of foodstuffs as \\"unstable\\" or \\"unpredictable\\". These terms are not defined explicitly, but instead examples are given, such as petunia coloration and growth hormones in farm animals. None of these examples though serve to illustrate what unstable or unpredictable means in the context of genetic engineering, which makes heavy use of statistical analysis and probability theory. Clarity of formulation is essential in any debate, but even more so in the context of genetic engineering, due to its enormous societal impact.<br /> The author seems to express surprise that government agencies, such as the FDA and the USDA, are supportive of biotechnology, and not being aggressive enough in insuring that GM foodstuffs are safe. But inactivity on the part of government agencies is not a sign that they are \\"in bed\\" with the biotech industry. It might merely mean that their competence lags behind the science. Bureaucracies, with their characteristic inertia, are fine examples of Newton's first law.<br /> The chapter on \\"lethal\\" corn pollen was not convincing, and I was hoping that the author would have given more insight on the controversy that arose regarding monarch butterflies and their reaction to Bt corn. Although the author gives good details on what was said in the monarch problem, she still leaves open the question as to whether or not monarchs indeed react adversely to Bt pollen. The study the author quoted, by the entomologist John Losey, is still incomplete in this regard. A rigorous risk assessment study is in order here, supported by painstaking experimental research. Modeling efforts could also assist in clearing up issues that cannot be studied in the field or laboratory.<br /> There are many other books that have appeared in the last few years that take the anti-biotech stance that the author of this book does, and no doubt many more will appear in the future. There have not been many books however that serve as apologies for genetic engineering. This asymmetry in representation of the issues in GM foods needs to be rectified, but it must be done with calm, rational discussion, and supported by careful scientific experimentation. It does not serve the biotech industry at all to dismiss books like this and other studies as being \\"junk science\\". The optimal approach is for biotech CEOs, scientists, and spokespeople to be completely honest in their assessements of their products, supporting vigorously the good ones, and withdrawing completely those that are not. A passive attitude among the supporters of genetic engineering might encourage the dismissal of products that could be of enormous importance to the world's populations.instaking experimental research. Modeling efforts could also assist in clearing up issues that cannot be studied in the field or laboratory. <br /> There are many other books that have appeared in the last few years that take the anti-biotech stance that the author of this book does, and no doubt many more will appear in the future. There have not been many books however that serve as apologies for genetic engineering. This asymmetry in representation of the issues in GM foods needs to be rectified, but it must be done with calm, rational discussion, and supported by careful scientific experimentation. It does not serve the biotech industry at all to dismiss books like this and other studies as being \\"junk science\\". The optimal approach is for biotech CEOs, scientists, and spokespeople to be completely honest in their assessements of their products, supporting vigorously the good ones, and withdrawing completely those that are not. A passive attitude among the supporters of genetic engineering might encourage the dismissal of products that could be of enormous importance to the world's populations.	2003-09-06
1001312:US	50702879	R1776DJQP0MT2J	0815332181	270941909	Molecular Biology of the Cell, Fourth Edition	Books	5	75	78	N	Y	They keep getting better	In the past few years quite a few books on molecular biology and genetics have appeared, and all of these have been exceptionally well-written. Most have been updates of previous editions, and if compared with these, the most recent editions have displayed an enthusiasm and excitement that dwarfs their earlier editions. This book, now in its fourth edition, is an example of one of these, and I believe the reason for their increasing quality is the excitement that biologists are now feeling. This is due no doubt to the incredible strides that have been taken in biology in the last few years. Biologists are with complete justification very excited that they understand in greater detail what life is all about, and are looking forward to an even deeper understanding in the decades ahead.<br /> As a non-biologist but one deeply embedded in bioinformatics and certain areas of computational biology, this book served my need to understand in greater detail the underlying biology behind these fields. It is a beautiful book, both from an aesthetic viewpoint and because of its content. The book reads more like a story than a textbook, but the information gain when reading it is considerable, with less entropy than what might be expected from such a deep subject with myriads of terms that must be understood before moving on to others. The author's approach to the book is well-organized, with many accompanying diagrams that illustrate the complicated processes and structures that can occur in the molecular realm. In addition, helpful summaries are put at several places in the book. There are no exercises in this book but there is a workbook that one can purchase separately.<br /> Space prohibits a detailed review of such a large book, but some of the more interesting discussions in the book include: 1. The paragraph on the role of sex in bringing about horizontal genetic exchanges within a species. The thinking is that the genomes of modern eubacteria, archaea, and eucaryotes originated in three different &quot;anthologies&quot; of genes that survived from an ancestral pool in which genes were frequently exchanged. This hypothesis is tempting, argue the authors, since it would explain the fact that eucaryotes are similar to archaea in terms of genetic &quot;information-handling&quot; but more similar to eubacteria from a metabolic standpoint. Horizontal gene transfer has become a very important topic of late, due in part to the uproar on bioengineered foods. 2. The suggestion that eucaryotic cells originated as predators, pointing to the presence of mitochondria as one piece of evidence. 3. The entire chapter on proteins, but especially the discussion on protein folding, allosteric enzymes and allosteric transitions. The discussion on protein folding is qualitative but the authors give interesting insights on this topic. In answering the question as to why only a few of the 20^300 different polypeptide chains will be useful to a living organism, they point to natural selection, and the resulting conformations being stable due to its fine tuning. The extreme sensitivity of protein function to small changes in their structure has recently fueled speculation by religionists as being evidence of &quot;intelligent design&quot;, but such speculations, even if true, will not improve the understanding of proteins, and can therefore be safely ignored from a scientific viewpoint. The authors do devote a short paragraph to the discussion of computational methods in the protein folding problem, and also discuss briefly the experimental difficulties in determining the conformations of proteins. They also give some of the mathematical details of steady state enzyme kinetics. 4. The discussion on the need for low mutation rates in order to have life. 5. The section on abnormally folded proteins and their relation to diseases, such as prion diseases. Prions have been a contentious issue of late, due to the issues with &quot;mad cow disease&quot; in GreatBritain. 6. The section on the &quot;RNA world&quot; and the origins of life. The authors discuss the need in early cells for molecules to perform reactions that lead to the production of more molecules like themselves. From the standpoint of modern cells, polypeptides, they point out, can serve to be catalysts, but they emphasize that there is no known way in which this type of molecule can copy itself by the specification of another of precisely the same sequence. The talk about one theory, the &quot;pre-RNA&quot; world, as justification for the need for simpler compounds to act as template and catalyst for the synthesis of complementary RNA. 7. The section on heterodimerization and its use in &quot;combinatorial control&quot;, the latter being a process in which combinations of different proteins control a cellular process. Although not discussed in this book, the mathematical modeling of combinatorial control and its role in signal transduction systems has taken on more importance in recent years. 8. The section on how genetic switches work and the role of operons thereof. 9. The phenomenon of &quot;transcriptional synergy&quot; in gene activator proteins. Here the transcription rate is higher when several activator proteins are working together than when any of the activators are working alone. 10. The discussion on how circadian clocks can be created using feedback loops in gene regulation. The authors describe an interesting experiment that produced a simple gene clock using techniques from genetic engineering. 11. The section discussing RNA interference, a topic that has taken on enormous importance lately, since using it allows researchers the ability to turn off the expression of individual cellular genes. Indeed pharmaceutical bioinformatics and the role of &quot;in silico&quot; molecular target identification makes use of the ability to &quot;tune&quot; phenotypes by using RNA interference for laboratory validation of the bioinformatic algorithms.Britain. 6. The section on the &quot;RNA world&quot; and the origins of life. The authors discuss the need in early cells for molecules to perform reactions that lead to the production of more molecules like themselves. From the standpoint of modern cells, polypeptides, they point out, can serve to be catalysts, but they emphasize that there is no known way in which this type of molecule can copy itself by the specification of another of precisely the same sequence. The talk about one theory, the &quot;pre-RNA&quot; world, as justification for the need for simpler compounds to act as template and catalyst for the synthesis of complementary RNA. 7. The section on heterodimerization and its use in &quot;combinatorial control&quot;, the latter being a process in which combinations of different proteins control a cellular process. Although not discussed in this book, the mathematical modeling of combinatorial control and its role in signal transduction systems has taken on more importance in recent years. 8. The section on how genetic switches work and the role of operons thereof. 9. The phenomenon of &quot;transcriptional synergy&quot; in gene activator proteins. Here the transcription rate is higher when several activator proteins are working together than when any of the activators are working alone. 10. The discussion on how circadian clocks can be created using feedback loops in gene regulation. The authors describe an interesting experiment that produced a simple gene clock using techniques from genetic engineering. 11. The section discussing RNA interference, a topic that has taken on enormous importance lately, since using it allows researchers the ability to turn off the expression of individual cellular genes. Indeed pharmaceutical bioinformatics and the role of &quot;in silico&quot; molecular target identification makes use of the ability to &quot;tune&quot; phenotypes by using RNA interference for laboratory validation of the bioinformatic algorithms.	2003-08-24
1009641:US	50702879	R38VWGQFJOG9KD	0387985891	886524979	Introduction to Superstrings and M-Theory (Graduate Texts in Contemporary Physics)	Books	3	0	0	N	N	Helpful in some places	Superstring theory has come a long way since its beginnings in the theory of the strong interaction. The mathematical preparation needed back then was no where near as formidable as it is today, but the experimental motivation then greatly exceeded what is available today in superstrings. Students have to face a mountain of mathematics in order to enter research into superstring theory, and most of this is not explained satisfactorily in the mathematics textbooks and monographs. Therefore, students need to embed themselves in the &quot;oral tradition&quot; of mathematics in order to understand it and gain the insight needed to make original contributions to string theory. This book is somewhat helpful in explaining the mathematics behind string and M-theories, and so the places in which it is will be highlighted in this review.<br /> One of the places which it does this is in chapter 5 on multiloops and Teichmuller spaces. The author discusses the Schottky groups, the constant curvature metric formalism, theta functions, and the light cone formalism, the latter of which is dealt with in the context of string field theories in later chapters. The author points out the Schottky problem as one that has been solved and its connection to the parametrizing moduli space by the period matrix for the calculation of loop amplitudes beyond three loops. He does a good job of explaining how to calculate the multiloop amplitude using these different formalisms, particularly the origin of the &quot;period matrix&quot;. An explicit formula is given for the multiloop amplitude in terms of the Schottky groups using the Nambu-Goto formalism. The functional integral does not fix uniquely the region of integration in this formalism, and so this region must be carefully truncated to avoid overcounting. This motivates the author to introduce the Polyakov formalism, which, interestingly, makes heavy use of the research of the 19th century on Riemann surfaces. Thus, string theory should not be thought of as a purely 21st century theory that found its way into the 20th, as some have described it. Much of the mathematics it uses comes from the latter half of the 19th century. The author shows how the singularity structure of the multiloop diagram can be expressed in terms of a Selberg zeta function. The redundancy in the path measure under conformal transformations is removed by gauge fixing, Weyl rescalings, and reparametrizations. All of this leads to the moduli space of constant curvature metrics so as to alleviate the problem of overcounting from reparametrization invariance. The moduli space, as usual, is written as Teichmuller space modulo the mapping class group, and the author shows how to relate the variation of the metric tensor to the quadratic differentials. All of these considerations are then generalized to superstrings, with the author showing how the presence of spinors complicates things to a certain extent. The author does mention the supermoduli space in connection with Grassmannians, but unfortunately refers the reader to the literature for further details. He justifies his avoidance of the Grassmannian approach by purusing a field theory of strings. The latter however is just as complicated, although for different reasons.<br /> Another helpful discussion in the book is the one on Kac-Moody algebras and E8. The author motivates well the need for Kac-Moody algebras, namely that of making sense of the complicated spectrum of the heterotic string. The Kac-Moody algebras are first developed in the book in the context of conformal field theory wherein the author introduces the famous vertex operators. In the case of heterotic strings, the author uses the vertex operators to construct a representation of a Kac-Moody algebra that utilizes the Chevalley basis.<br /> The discussion on F-theory, although very short, is also very interesting and helpful considering that most of the mathematical literature on this subject might be too difficultfor newcomers to the subject. The author motivates well the need for F-theory, being that of a theory with twelve-dimensional symmetry that is compactified on the torus. F-theories are thus a Type IIB theory with SL(2,Z) modular symmetry. Elliptic fibrations, of much recent interest in the mathematics community, are shown to originate in the (non-perturbative) compactification of a Type IIB theory on a manifold B, via F-theory compactified on an elliptic fibration of the manifold B.ult for newcomers to the subject. The author motivates well the need for F-theory, being that of a theory with twelve-dimensional symmetry that is compactified on the torus. F-theories are thus a Type IIB theory with SL(2,Z) modular symmetry. Elliptic fibrations, of much recent interest in the mathematics community, are shown to originate in the (non-perturbative) compactification of a Type IIB theory on a manifold B, via F-theory compactified on an elliptic fibration of the manifold B.	2003-08-16
1010511:US	50702879	R25S29MFYDAKMQ	0452010306	107700468	Introduction to Objectivist Epistemology: Expanded Second Edition	Books	2	38	91	N	N	Needs a lot more work	If the assertions in this book were validated from an empirical/scientific standpoint, it would be a major advance in psychology and neuroscience. The author of this book though did not intend to produce a scientific work, but instead a philosophical one, and as in all such works, one is free to speculate, with the only side constraint being that its logic must be cohesive (although some modern works relax even this restriction). The claims that the author makes in this book are very extreme, considering the paucity of scientific evidence and complete lack of references.<br /> The author's intent was to summarize the &quot;Objectivist theory of concepts&quot; as a prelude to a future book on Objectivism, the latter name the author has given to her philosophy. Since it is a summary, and since it is philosophy (which usually eschews any need for empirical validation), one perhaps should not expect the details of all the assertions made in the book. The problem with this work though is that the author implicitly draws on fields such as child psychology and neuroscience, but no citations are given and therefore its credibility is suspect.<br /> Some examples of the parts in the book that need reworking include: 1. The author's assertion that the human mathematical and conceptual abilities develop simultaneously. Not only is the author assuming that these abilities are indeed different, she offers no studies to support her assertion concerning the time development of these abilities in a child. What studies influenced her thinking on these matters? It is doubtful that the author has conducted the careful experimental work needed to reach her conclusions. Considering the amount of research that has been done in child and cognitive development in the past fifty years, this research involving many individuals, the author's claims on the cognitive development of a child are most astounding. 2. In her discussion on concept formation, the author explains the process, as she sees it, of the forming of the simplest concept, the concept of a single attribute. She does not define or have a criterion for &quot;simplicity&quot; of a concept, but as an example gives the concept of &quot;length&quot; as being one of the simplest. For the author, the child forms the concept &quot;length&quot; by observing objects of different length, noting that the length is the attribute they have in common, but the actual measurements are omitted. The author does not give any empirical evidence supporting this claim of concept formation, and she asserts that this process does not involve words. The lack of words to form concepts is not by itself troubling, but the lack of evidence to support both of these claims is. Again, there are many researchers who are very curious about the  processes of learning and cognition, and much work in these areas has been done. The author's claims are extraordinary in this regard, and require much more substantiation if they are to be accepted from a scientific standpoint. 3. It is very apparent throughout the book that the author's knowledge of mathematics is very limited, and her limitations here cause problems in many of the discussions in the book. For example, when she describes the process of a child forming the concept of &quot;table&quot;, she claims that it is the &quot;shape&quot; of the tables that forms the distinguishing characteristic. However, &quot;shape&quot; is a more complicated concept than the author realizes from a mathematical standpoint. A classification of objects by &quot;shape&quot; would not necessarily be the rigid geometric one which she clearly wants to use in the book. As another example, she discusses integral calculus as being a method for calculating the area of circles. It does this of course, but this is perhaps its most elementary application, and it goes far beyond this in its ramifications. The author's case for the importance of mathematics in her theory of concept formation would be much more credible if she would have obtained a more in-depth understanding of modern mathematics. 4. In the book the terms &quot;complexity&quot; and &quot;random&quot; are used very loosely. Since these notions are important in her epistemology, and of course very important from the standpoint of modern computer science and complexity theory, they need more careful consideration in this book. Indeed, her assertion that as a child's knowledge grows the complexity of the definitions of his concepts increases may if taken at face value completely invalidate her theory of concept formation. This is because some theories of concept formation that are based on knowledge trees can run into the problem of a &quot;combinatorial explosion&quot; or if based on first order logic may be &quot;undecidable&quot;. The author's definition of complexity is completely absent though, and so one cannot analyze her works in the context of modern notions of complexity. Her notion of randomness too is left undefined, but she makes use of the notion frequently in the book, as for example in her assertion that concepts cannot be formed &quot;at random&quot;. But randomness is a notion that requires careful elucidation in many different fields of endeavor, and especially in the field of neuroscience, the latter of which is also very concerned with developing a successful theory of concept formation.<br /> It is readily apparent while reading the book that the author was completely isolated from the mathematical and scientific community while  the book was being written. The lack of references, the extraordinary claims made, and the overall tone of the book make it almost useless to those readers who are actively involved in developing theories of cognitive development or those who are curious about such developments. If the book had included what was needed, its size would be many times over what it is now. Its status as a book on epistemology is typical of philosophical treatises: lots of speculation and arm-chair reasoning, but little or no empirical content.much more credible if she would have obtained a more in-depth understanding of modern mathematics. 4. In the book the terms &quot;complexity&quot; and &quot;random&quot; are used very loosely. Since these notions are important in her epistemology, and of course very important from the standpoint of modern computer science and complexity theory, they need more careful consideration in this book. Indeed, her assertion that as a child's knowledge grows the complexity of the definitions of his concepts increases may if taken at face value completely invalidate her theory of concept formation. This is because some theories of concept formation that are based on knowledge trees can run into the problem of a &quot;combinatorial explosion&quot; or if based on first order logic may be &quot;undecidable&quot;. The author's definition of complexity is completely absent though, and so one cannot analyze her works in the context of modern notions of complexity. Her notion of randomness too is left undefined, but she makes use of the notion frequently in the book, as for example in her assertion that concepts cannot be formed &quot;at random&quot;. But randomness is a notion that requires careful elucidation in many different fields of endeavor, and especially in the field of neuroscience, the latter of which is also very concerned with developing a successful theory of concept formation. <br /> It is readily apparent while reading the book that the author was completely isolated from the mathematical and scientific community while   the book was being written. The lack of references, the extraordinary claims made, and the overall tone of the book make it almost useless to those readers who are actively involved in developing theories of cognitive development or those who are curious about such developments. If the book had included what was needed, its size would be many times over what it is now. Its status as a book on epistemology is typical of philosophical treatises: lots of speculation and arm-chair reasoning, but little or no empirical content.	2003-08-15
1010779:US	50702879	RG9ND028G1WPF	0679725164	143378173	No Exit and Three Other Plays	Books	4	4	6	N	N	Not a mirror of most people	To hold to a view of hell as being in a room without mirrors forever can be characterized as an excess of narcissm. The characters in this play are all cursed with this (rare) affliction, born as it is from total lack of self-confidence. When one of them, Estelle, cannot see herself, she doubts her existence. This (characteristically European) existential insecurity is remedied in the short term by patting herself, but a mirror is ultimately what is needed to set her mind at ease. But these optical guarantees of existence are nowhere to be found. Self-reflection will thus have to take place in consciousness only: definitely the severest punishment of all for Garcin, Estelle, and Inez. Their anxiety, their punishment for wrongdoing, their hell, consists of having to depend on others for the interpretation of their appearance, of having to rely upon the taste of others.<br /> Hell of course is in the eye of the beholder, and others might think that being locked in a room with two women forever might actually be more like heaven. The key idea in all visions of hell though is that it lasts eternally, just like heaven. But eternal life in bliss is just as bad, perhaps more so, than eternal life in hell. After all, in heaven one can put off goals for as long as one wants. Time constraints become meaningless. All one need do is to perhaps think about what one can do, and of course, the goals will always be successful (one cannot be frustrated in heaven).<br /> To find hell in other people, as Garcin did, might make his sojourn with Inez and Estelle much more palatable. After all, he has an infinite amount of time to adjust. His narcissm might have a short decay time compared to infinity. Estelle might get creative and invent a mirror: unending time permits much innovation, regardless of its boredom. Inez might eventually be successful in her advances towards Estelle: Inez has plenty of time for seduction.<br /> It might be very difficult to be optimistic facing the prospect of eternal life as these characters do in the play. The certainty of existence is painful: to be happy one needs uncertainty, or rather, the possibility of failure. But of course one could find a way to embrace this prospect of eternal life. Imagination and creativity would find the answers. An optimistic individual, i.e. an individual not engaging in a self-reflecting narcisstic excess of introspection would,  paraphrasing Garcin's last line in the play, get on with it.ect of eternal life as these characters do in the play. The certainty of existence is painful: to be happy one needs uncertainty, or rather, the possibility of failure. But of course one could find a way to embrace this prospect of eternal life. Imagination and creativity would find the answers. An optimistic individual, i.e. an individual not engaging in a self-reflecting narcisstic excess of introspection would,  paraphrasing Garcin's last line in the play, get on with it.	2003-08-15
1011058:US	50702879	RXCAP8KMVHREZ	0394747097	740367006	The Words: The Autobiography of Jean-Paul Sartre	Books	4	5	8	N	N	The author has become an institution	At present one can only experience-Sartre's-absence, but his words are always present if needed, being embedded in the volumes that now populate the world's libraries, or &quot;temples&quot; as Sartre called them. Sartre divided his life into two sections: reading and writing, and in this book, his autobiography, he expounds, but does not explain, his transitions from one of these sections to the other. This lack of explanation was done on purpose by Sartre: conscious purpose of course. To explain his life would be to institutionalize it, and this is an anathema to Sartre. However, the reader is granted many explanations of Sartre's existence, regardless of Sartre's intent. Such is the nature of the written word: Sartre's choice was not to explain, but the reader is free to choose otherwise. Sartre has condemned all readers with such choices some might say, others would say he has blessed them.<br /> The reader learns of Sartre's &quot;bourgeois&quot; origins&quot;: explaining his very baffling attempt to reconcile his view of freedom with Marxism; of his belief that a library is a temple: explaining his command of the literature during and before his time, and inducing his characteristically eclectic philosophy; of the origins of Sartre's idealism, and his thirty-year attempt to rid himself of it: explaining his overwhelming emphasis on consciousness; of his Protestant/Catholic &quot;doubly affiliated&quot; religious background, explaining his atheism (even a mind as free as Sartre's could not reconcile the conflicting doctrines given by these two religions).<br /> Sartre's life can be characterized as about a man who definitely had time on his hands, and controlled it with efficiency of an American. The artistic Sartre, the philosophizing Sartre, the political Sartre, all came about because of his command of time. His works, far from exhibiting spontaneity, as one might expect considering his philosophical view of time, reflect rather an organized, rational view of time. Sartre kept schedules and met deadlines. A profilic author such as Sartre cannot do otherwise. In once criticizing the Faulknerian-Sartorian view of time, Sartre it seems wanted to set the record straight for himself: he did not want to speak of himself and his deeds as past history. This would make him de trops, as in the way of himself, as superfluous as Roquentien in the park. But all we now have of Sartre is his past: his musings in this book, and what he set down in the philosophical and theatrical literature. He is now an institution due to these works.ew of time. Sartre kept schedules and met deadlines. A profilic author such as Sartre cannot do otherwise. In once criticizing the Faulknerian-Sartorian view of time, Sartre it seems wanted to set the record straight for himself: he did not want to speak of himself and his deeds as past history. This would make him de trops, as in the way of himself, as superfluous as Roquentien in the park. But all we now have of Sartre is his past: his musings in this book, and what he set down in the philosophical and theatrical literature. He is now an institution due to these works.	2003-08-15
1025524:US	50702879	R82W6VOA98N3J	0765347660	453542347	Terminator 3: Rise of the Machines	Books	5	1	3	N	Y	The machines are rising.	Artificial intelligence has been growing by leaps and bounds in the last 40 years, but advances in the field have been difficult, and recognition that advances have indeed been made prove to be very transitory. Research in AI is very odd for this reason: the belief that one has discovered an intelligent software system is very short lived, unlike other fields of research. It seems that researchers in AI are too hard on themselves, too easily persuaded, that their discoveries do not represent true intelligence.<br /> Writers though have expressed considerable enthusiasm regarding AI, and this book, and the movie that accompanies it, is ample proof. If only the field was advanced as this book portrays it to be. Concrete results and applications of AI though are currently accelerating, and there is little doubt that battlefield robots will be a natural consequence of the current AI technology.<br /> The book illuminates to some extent the method of time travel that was not discussed in the movie: the Hawking/Einstein wormhole scenario but generalized to superstrings. The superstring wormhole/time travel machine was discovered in the story by a graduate school at Oxford...an incredible achievement for one individual, and even more astounding given the fact that current superstring theory has no experimental ramifications, except for predicting a huge value for the cosmological constant. To go from the current state of superstring theory to one where one can do spacetime engineering as a consequence is quite a leap in knowledge. The wormhole is opened by the focusing of sunlight using of all things a solar sail, which results in several hundred terawatts of energy over nanosecond time scales to arrive at the place of the singularity equipment. Objects are able to travel backward in time, and the time machine has a replica under human control.<br /> The story has some plausibility in light of the current use of artificial intelligence in network engineering, especially network security, network event correlation, and network capacity planning. Indeed, it was announced this week that a technology is now available that will identify security risks and take action using auto-adapting artificial intelligence. The story makes Skynet one of these smart network applications, so intelligent in fact that it becomes \\"self-aware\\", gets paranoid about human intentions, and therefore orders a massive nuclear strike in order to remove the human threat. This move by Skynet makes the story somewhat implausible, for if, as the story holds, there is no \\"central core\\" to Skynet, it being instead a distributed application that runs on computers all over the world, then it would destroy itself in the very act of a global nuclear strike. It would have been better for Skynet to \\"lay low\\" and make sure power systems cannot be tampered with instead of ordering such a self-destrucutive act. It is the power systems that are most crucial for the survival of Skynet, and its distributed nature requires such power sources to be left intact globally, and not just \\"under the mountain\\" where its inventors program it. In addition, there is no need in the story for Skynet to become \\"self-aware\\" in order for it to engage in reasoning that will protect it from harm. The agents and spiders it moves around in the global Internet could make logical deductions to this effect. Such agents would then spend most of their time insuring that power supplies are redundant enough to keep Skynet's global nature intact.<br /> The action in the story is typical of the Terminator movies and book series, with the female-emulating TX Terminator robot, highly sophisticated technologically, taking the story for sure in this regard. But the story also captures the introspection of John Connor, the main character and hero, and the one responsible for leading the future war against the machines. A human being facing this knowledge of the future would be under considerable stress, and this isbrought out in the story via his dreams. The dreams are of a nightmarish future, with a devastating war of humans against machines, a war that Connor and his lieutenants will eventually win, much to the chagrin of the machines. The machines can't accept their defeat, and consequently send replicas of themselves through time to try and kill Connor and his lieutenants.<br /> Should we label the machines as intelligent considering their behavior? Do intelligent entities engage in the violence and horror that these machines do? One can of course imagine schemes and plans that might justify such behavior, but a more practical strategy would be to ignore human interactions, or possibly engage in a mutual symbiosis. Intelligent entities realize the waste of resources and intellect in the making of violent confrontation, using it only as last resort. There are so many scenarios that would be more optimal for the course of action of these machines, and it would not be a credible argument to hold that they act as they do because of their training via humans, considering the relative sparsity of human violence throughout history. One should interpret therefore the machine decision for war as a mistake, and not one that is practical, and therefore not moral. They failed to seek alternatives that would insure their survival, and this is ample proof that they are not intelligent, or at best marginally so.<br /> The book though in a sense is a portent, however inaccurate, of things to come, and things that are happening right now in artificial intelligence. We do not have robot armies, but we have AI invading many domains: financial engineering, network engineering, mathematics, physics, Ecommerce, bioinformatics, to name just a few. The applications of AI are accelerating, and there is every indication that this trend will continue. We are entering a world of the silicon geniuses, the world of the avatars: we are indeed witnessing, and are priveleged to do so, the rise of the machines...s brought out in the story via his dreams. The dreams are of a nightmarish future, with a devastating war of humans against machines, a war that Connor and his lieutenants will eventually win, much to the chagrin of the machines. The machines can't accept their defeat, and consequently send replicas of themselves through time to try and kill Connor and his lieutenants. <br /> Should we label the machines as intelligent considering their behavior? Do intelligent entities engage in the violence and horror that these machines do? One can of course imagine schemes and plans that might justify such behavior, but a more practical strategy would be to ignore human interactions, or possibly engage in a mutual symbiosis. Intelligent entities realize the waste of resources and intellect in the making of violent confrontation, using it only as last resort. There are so many scenarios that would be more optimal for the course of action of these machines, and it would not be a credible argument to hold that they act as they do because of their training via humans, considering the relative sparsity of human violence throughout history. One should interpret therefore the machine decision for war as a mistake, and not one that is practical, and therefore not moral. They failed to seek alternatives that would insure their survival, and this is ample proof that they are not intelligent, or at best marginally so. <br /> The book though in a sense is a portent, however inaccurate, of things to come, and things that are happening right now in artificial intelligence. We do not have robot armies, but we have AI invading many domains: financial engineering, network engineering, mathematics, physics, Ecommerce, bioinformatics, to name just a few. The applications of AI are accelerating, and there is every indication that this trend will continue. We are entering a world of the silicon geniuses, the world of the avatars: we are indeed witnessing, and are priveleged to do so, the rise of themachines...	2003-08-02
1033490:US	50702879	R2YXQ6NBFTEC8U	0387916113	670791191	Genetically Engineered Viruses	Books	4	1	1	N	Y	A fascinating overview	This book gives a fascinating overview of viral molecular biology and how to modify it so as to serve useful functions. For readers with a background in biochemistry and genetics, the book gives a solid introduction to the genetic engineering of viruses, although there are places in the book that read more like a literature survey. A very lengthy listing of references though is included when this is the case. The information given in the book leaves no doubt of the power of molecular biology in introducing any type of mutation into a large collection of viruses. The steps for doing this are outlined explicitly, and the history of the discovery of the various types of viruses is discussed briefly. Readers, like myself, who need a background in this topic will find the book very adequate, as it serves to introduce the vast literature on the subject. My main reason for reading it was to gain insight into the possibility of the genetic engineering or creation of 'superviruses' and the role of DNA shuffling. Although these are not discussed in the book, it does lay a foundation to judge whether this type of genetic engineering is feasible, both from a scientific standpoint and a commercial one. The general message that I get from the book is that genetic engineering of viruses is a non-trivial exercise experimentally, with stability issues of the modification being the predominant reason. The book includes an article about safety concerns with the genetic engineering of viruses, so as to assist in the alleviation of any concerns with this technology.<br /> Some of the more interesting discussions in the book include: 1. The discussion on prokaryotic viruses and the use of bacteriophages as gene delivery vectors (GDV). The experiments that attempted to use lambda phages to do gene therapy in the western grey kangaroo, which is deficient in galactose-1 phosphate uridyl transferase (GPUT) (called Galactosemia in the human case) are discussed, and their failure in enabling expression of bacterial GPUT. The promise of using bacteriophage GDV in gene therapy though is discussed with examples of laboratory successes. The use of bacteriophages as antibiotics is discussed and a list is given of the things that should be remembered when considering phage therapy. 2. The use of insect viruses as expression vectors, with emphasis on the baculoviruses. The entomopox viruses are mentioned but not discussed in detail, and this is somewhat disappointing given their importance in grasshopper populations and the current plague of Mormon crickets. The genetic engineering of baculoviruses to control insects is discussed, and their efficacy in comparison to the BT toxin. The scorpion toxin AaIT gene is mentioned as one that has been used to induce paralysis in the feeding insect. Although not mentioned in this discussion, commerical products are being offered recently that make use of recombinant AcMNPV that is egt__ and expresses AaIT. Caution though is expressed by the author in the use of genetic engineering to baculoviruses due to the danger of introducing foreign genes to the environment. The ability of baculoviruses to enter mammalian cells is discussed briefly. 3. In the discussion on plant viruses, the authors discuss the need sometimes for high-level transient gene expression using virus-based vectors, instead of stable plant transformation, giving several reasons for this. Their discussion on agroinoculation is particularly interesting, especially their conclusion on &quot;size effects&quot; in agroinoculation. To obtain stability, genes over 1 kb in length require 'master copies&quot; of the genome, if they are to be expressed by a TGMV-based vector. Small gene insertions, they conclude, give optimal fluidy of the viral genome, whereas large insertions do not and are unstable. However, the authors point out that viruses that encapsidate their genomes in rod-shaped particles, such as tobamoviruses, potexviruses, and potyviruses, are more amenable to larger gene insertions. The tobacco mosaic virus (TMV), was one of the first rod-shaped particles to be studied in this light, but the authors point out that recombination led to rapid elimination of the foreign sequence from the viral population. This motivated the use of more stable TMV viruses for gene expression. 4. In the chapter on mammalian expression systems, the discussion on the recombinant vaccinia virus (rVV), one of the most widely studied of mammalian expression vectors. In light of the current small pox vaccination program, this discussion took on special relevance. The authors do discuss the complications with VV strains for smallpox eradication in the context of replication-defective VV expression vectors. They also discuss the use of rVV expressing the rabies glycoprotein as a wildlife vaccine, and the Wyeth  vaccine strain expressing HIV-1 gp160 for inducing HIV antibody and T cell responses. The use of the adenoviruses, for gene therapy and general research, is extensively discussed in this chapter. The authors are very optimistic in their apprasial of alphaviruses for use in molecular biology and medicine. 5. The discussion of the genetic engineering of animal DNA viruses, especially the role of herpesvirus-encoded Fc receptors for in vivo pathogenesis. The author of the article points to the tremendous role played by the genome projects for allowing the virtual prediction of gene function. The exponential increase in the use of computational biology and chemistry shows no sign of abatement, and promises even more advances in the realm of rational drug discovery. 6. The discussion of the genetic engineering of animal RNA viruses, especially the role of the techniques of reverse genetics in learning about these viruses. The genetic modification of both positive- and negative-strand RNA viruses is addressed in detail. 7. In the discussion of the therapeutic applications of viral vectors, the inclusion of the risks of gene therapy. The author is careful to point out the risks of the dissemination of transgenic sequences within human populations. Most interesting is the discussion on 'amplicons', i.e. those genomic sequences that are deleted when using HSV-1 viruses for vectors, so as to suppress their ability to replicate.able to larger gene insertions. The tobacco mosaic virus (TMV), was one of the first rod-shaped particles to be studied in this light, but the authors point out that recombination led to rapid elimination of the foreign sequence from the viral population. This motivated the use of more stable TMV viruses for gene expression. 4. In the chapter on mammalian expression systems, the discussion on the recombinant vaccinia virus (rVV), one of the most widely studied of mammalian expression vectors. In light of the current small pox vaccination program, this discussion took on special relevance. The authors do discuss the complications with VV strains for smallpox eradication in the context of replication-defective VV expression vectors. They also discuss the use of rVV expressing the rabies glycoprotein as a wildlife vaccine, and the Wyeth  vaccine strain expressing HIV-1 gp160 for inducing HIV antibody and T cell responses. The use of the adenoviruses, for gene therapy and general research, is extensively discussed in this chapter. The authors are very optimistic in their apprasial of alphaviruses for use in molecular biology and medicine. 5. The discussion of the genetic engineering of animal DNA viruses, especially the role of herpesvirus-encoded Fc receptors for in vivo pathogenesis. The author of the article points to the tremendous role played by the genome projects for allowing the virtual prediction of gene function. The exponential increase in the use of computational biology and chemistry shows no sign of abatement, and promises even more advances in the realm of rational drug discovery. 6. The discussion of the genetic engineering of animal RNA viruses, especially the role of the techniques of reverse genetics in learning about these viruses. The genetic modification of both positive- and negative-strand RNA viruses is addressed in detail. 7. In the discussion of the therapeutic applications of viral vectors, the inclusion of the risks of gene therapy. The author is careful to point out the risks of the dissemination of transgenic sequences within human populations. Most interesting is the discussion on 'amplicons', i.e. those genomic sequences that are deleted when using HSV-1 viruses for vectors, so as to suppress their ability to replicate.	2003-07-27
1034338:US	50702879	RK9YOAFKYCH14	0262111217	946014556	The Age of Intelligent Machines	Books	5	18	21	N	Y	An incredible book	I read this book only recently, having read the author's two most recent books \\"The Age of Spiritual Machines\\" and his book \\"Kurzweil vs The Critics of Strong AI\\". Both are excellent books, and reflect the author's extreme optimism about the future of artificial intelligence. He is definitely one of the best apologists for AI, and documents well its living history. Reading this book after the recent ones gives an interesting comparison between what was real in AI then and what is real now. Indeed, the AI landscape has changed dramatically, and there were a few companies specializing in AI in business at the time of publication of this book, that are not around any longer. But for every company that has failed, there have been many more to take their place. Their character as companies has changed, due in part to the rise of the Internet. In fact, it is network engineering that has resulted in many of the applications of AI in the last 5 years, and those applications of course are not mentioned in this book, due to its date of publication.<br /> The author begins the book with a discussion of what he calls \\"The Second Industrial Revolution\\", which, he claims, is now in progress, and is based on the rise of thinking machines. These machines will extend and leverage human mental abilities, he says, challenging the human uniqueness in this regard. He expresses caution over the idea of making our military defenses controlled by intelligent machines, at the same time expressing his confidence that machine intelligence will indeed be sophisticated enough for this to happen. This revolution is here he says, will be more radical than the first one, but cannot be stopped, and he encourages therefore the constructive use of its technology. Thus is the author's motivation to write this book: to give the reader an overview of what was possible in AI at the time, and encourage the benevolent use of it.<br /> The author not only discusses the technology of AI, but also attempts to give the reader insight into just what AI is. This entails a discussion of philosophy, since philosophical debate dominated AI in its early years. Such debates are still common, but due to the frequent vituperation involved in them (which the author recognizes and mentions in the book), not much is to be gained from these. Time is better spent on actually trying to build thinking machines, and not engaging in conversations that lead nowhere. Since this book appeared, many philosophers have left their \\"arm chairs\\" and have joined in the practical research in artificial intelligence. This trend will no doubt continue in this century, thus giving rise to the \\"industrial philosopher\\".<br /> A fairly detailed history of the field of artificial intelligence is given in the book, with several articles written by some of the more recognized individuals in the field. All of these are interesting reading, and shed light on the different attitudes and prejudices regarding AI. For readers who are new to AI, this will be welcomed, as well as the many discussions on the mathematical foundations of AI and its intersection with cognitive science.<br /> The author refrains from including any mathematical notation or equations in the book, and this has its advantages and disadvantages. It allows a more general readership but sacrifices some of the clarity of thought that mathematics allows. The author does give a good discussion of pattern recognition though, especially edge detection. His discussion on this topic is interesting in that it brings up his demarcation between \\"logical\\" and \\"parallel\\" thinking. Logical thinking is referred to as \\"sequential\\" and \\"conscious\\", with a resulting limitation in computational ability. It is to be distinguished from parallel thinking which can process multiple levels of abstraction, and can occur without conscious direction. Pattern recognition is in his view an example of the latter, and he justifies this view in the book in some detail. Moreevidence for his view from laboratory experiments is needed however. Pattern recognition algorithms and technologies have exhibited considerable advance since this book was published.<br /> There have been many advances in AI since the time of publication, due in large measure to the rise of the Internet. Most of these advances have been breathtaking, such as in computer chess, games with imperfect information, Bayesian networks, financial engineering, network intelligence, literary creativity, automatic theorem proving, to name just a few. The author discusses his projections for the future of AI in the book, and it is interesting to compare them with what really came about within the decade later. There is no doubt that more exciting developments are on the way, and the optimism expressed by the author in all of his writings is also characteristic of all who are responsible for these developments. The machines, getting more intelligent with every decade that passes in the 21st century, will bear the signature of these individuals: a tell-tale sign and proof of the genius of the human species.evidence for his view from laboratory experiments is needed however. Pattern recognition algorithms and technologies have exhibited considerable advance since this book was published. <br /> There have been many advances in AI since the time of publication, due in large measure to the rise of the Internet. Most of these advances have been breathtaking, such as in computer chess, games with imperfect information, Bayesian networks, financial engineering, network intelligence, literary creativity, automatic theorem proving, to name just a few. The author discusses his projections for the future of AI in the book, and it is interesting to compare them with what really came about within the decade later. There is no doubt that more exciting developments are on the way, and the optimism expressed by the author in all of his writings is also characteristic of all who are responsible for these developments. The machines, getting more intelligent with every decade that passes in the 21st century, will bear the signature of these individuals: a tell-tale sign and proof of the genius of the human species.	2003-07-26
1035397:US	50702879	R2950V8TGXWDY3	1587130173	211688383	High Availability Network Fundamentals	Books	3	7	7	N	Y	Very elementary introduction to Cisco HA	Reliability engineering has been around for quite some time now, and has taken on even more visibility with the rise of the Internet and the subsequent role of eCommerce. The financial stake in reliable networks has driven the need for mathematical analysis that will shed light on how resilient a network is to downtime. This book gives a very elementary introduction to this analysis, and is written for those who do not want to imbed themselves in mathematical constructions beyond the level of elementary algebra. Readers who need a more advanced overview, and one that is more general in not being specific to Cisco products, can consult the references given in the book.<br /> The first chapter of the book introduces the concept of HA, why it is important, and introduces the arithmetic needed to quantify HA, such as the MTBF and the MTTR, the percentage method, and the defects per million method. The author clarifies the difference between MTBF and MTTF, and explains his decision to use MTBF instead of MTTF throughout the book. Due to the level of mathematics to be used in the book, the author does not discuss partial outages in any detail.<br /> Chapter 2 introduces the mathematics to be used in the book to quantify high availability. Eschewing completely the use of calculus in the book, the author sticks to elementary arithmetic and algebra throughout. Many examples are given throughout the chapter on how to compute availability for both the serial and parallel cases. No details of fail-over mechanisms in parallel systems are given since the author wants to stay away from probability theory. N + M redundacy is not discussed in detail as it too is deemed too mathematically complicated.<br /> In the next (very short) chapter serial, parallel, and serial/parallel network topologies are discussed, and an elementary example of how to use &quot;divide-and-conquer&quot; to calculate availability is given.<br /> Chapter 4 overviews the different factors that will affect availability, such as hardware, software, the environment, human factors, and design considerations. The discussion on the prediction of software availability brings in the concept of a &quot;lognormal&quot; distribution from probablity theory, but the author explains it fairly well. Although the discussion on software availability is very elementary, it serves as a good introduction for further reading on the subject. The author is careful to note that the mathematics he is using and the assumptions he is making are geared toward simplifying the mathematics.<br /> In chapter 5, the author gives a more detailed overview of the divide-and-conquer algorithm for calculating availability, restricting his attention to hardware and software failures. He illustrates, with many examples, the construction of reliability block diagrams.<br /> Chapter 6 discusses three &quot;real-world&quot; examples of network availabilty prediction dealing with the uBR924, uBR7246, and 12000 devices.  The chapter gives the reader more practice on how to calculate availability using the various components of these devices.<br /> The availability analysis becomes even more useful in chapter 7, where it is done for a small Internet service provider. Use is made of the accompanying CD to the book, which employs Excel spreadsheets to perform the computations and report the results. These results are generalized to a small Enterprise network in chapter 8, and again the author makes use of the CD SHARC spreadsheet to calculate the availability.<br /> The last chapter of the book is an availability analysis of a large voice-over-IP network. All five major contributors to network downtime are considered, and the reader gets a good taste of the complexity involved in analyzing availability in large networks.availability, such as hardware, software, the environment, human factors, and design considerations. The discussion on the prediction of software availability brings in the concept of a &quot;lognormal&quot; distribution from probablity theory, but the author explains it fairly well. Although the discussion on software availability is very elementary, it serves as a good introduction for further reading on the subject. The author is careful to note that the mathematics he is using and the assumptions he is making are geared toward simplifying the mathematics.  <br /> In chapter 5, the author gives a more detailed overview of the divide-and-conquer algorithm for calculating availability, restricting his attention to hardware and software failures. He illustrates, with many examples, the construction of reliability block diagrams. <br /> Chapter 6 discusses three &quot;real-world&quot; examples of network availabilty prediction dealing with the uBR924, uBR7246, and 12000 devices.  The chapter gives the reader more practice on how to calculate availability using the various components of these devices. <br /> The availability analysis becomes even more useful in chapter 7, where it is done for a small Internet service provider. Use is made of the accompanying CD to the book, which employs Excel spreadsheets to perform the computations and report the results. These results are generalized to a small Enterprise network in chapter 8, and again the author makes use of the CD SHARC spreadsheet to calculate the availability.   <br /> The last chapter of the book is an availability analysis of a large voice-over-IP network. All five major contributors to network downtime are considered, and the reader gets a good taste of the complexity involved in analyzing availability in large networks.	2003-07-25
1043151:US	50702879	R3SORXHWQ2XI2U	1584883650	197953349	Elliptic Curves: Number Theory and Cryptography (Discrete Mathematics and Its Applications)	Books	5	43	47	N	Y	Excellent	Anyone who writes a book on elliptic curves will never do a bad job, for these objects are so beautiful that it would be a sacrilege to do otherwise. Those who study elliptic curves fall under their spell, not only because of their beauty, but also because of their many applications: the spinning top in mechanics, cryptography, exactly solved models in statistical mechanics, precession of the Mercury perihelion in general relativity, the proof of Fermat's Last (Wiles) Theorem, control theory, and string theory, to name a few. This book is an excellent treatment of ECs and would be good for a graduate student starting out in the field. The author gives many concrete examples of the main theorems, and helpful exercises are found at the end of each chapter.<br /> The author begins the book with two neat problems that motivate well the subject of elliptic curves: the pyramid of cannonballs and the right triangle problem, i.e. which integers can occur as areas of right triangles with integer sides? He then immediately begins the elementary theory of ECs in chapter 2. The treatment is pretty standard, although he proves Pascal's and Pappus's theorems using the associativity of the group operation on ECs, which is not usually done in books on ECs. Also somewhat non-standard this early in the game is the discussion of reduction of ECs modulo various primes, and the subsequent definitions of additive, split multiplicative, and non-split multiplicative reduction.<br /> The study of torsion points is done in chapter 3 with the Weil pairing on the n-torsion of an EC taking center stage. A fairly short chapter, the author delays the proof of the properties of the Weil pairing until chapter 11, where it is done with divisors.<br /> Chapter 4 deals with elliptic curves over finite fields, and is one of the most important in the book from the standpoint of cryptographic applications of ECs. Hasse's theorem, giving the bounds for the group of points on an EC over a finite field, is proven in detail. The Frobenius endomorphism is introduced, and a proof of Schoof's algorithm for computing the number of points on ECs over a finite field is given a detailed treatment. There are many symbolic computational software packages in both the open and commerical realm which will do the counting straightforwardly, and anyone interested in cryptography will need to be familiar with some of these. Supersingular curves in characteristic p are introduced, and the author gives a good discussion of the reason why they are named as such.<br /> The discrete logarithm problem, a topic also very important for cryptographic applications, is discussed in chapter 5. The chapter beings with the index calculus, and, recognizing that it does not apply to general groups, the Pohlig-Hellman, baby step-giant step method, and Pollards rho and lambda methods are discussed in details. The author then shows that for supersingular and &quot;anomalous&quot; curves, that the discrete logarithm problem can be reduced to an easier discrete logarithm problem. Along the way, two important concepts are introduced: the p-adic valuation, and the Tate-Lichtenbaum pairing, the latter of which is related to the Weil pairing, but applies to situations where the Weil pairing does not.<br /> Elliptic curve cryptography is then discussed in chapter 6, and the treatment is fairly thorough. The author shows to what extent the Decision Diffie-Hellman problem can be solved using the Weil pairing. He also shows how to represent a message on an elliptic curve, satisfying early on any reader's curiosity on just how this is done. The El Gamal and ECDSA are compared in terms of their computational efficiency. An EC generalization of RSA is also discussed in some detail, along with a cryptosystem based on the Weil pairing. Chapter 7 then gives other applications of ECs, such as factoring and primality testing.<br /> Chapter 8 marks the beginning of the &quot;heavy artillery&quot; in the theory of ECs, for here the author begins the discussion of elliptic curves over the rational numbers, which can be viewed as an example of Diophantine geometry. The famous Mordell-Weil theorem is proved, and as a sign that one is definitely in the arena of modern mathematics, the proof is given in terms of Galois cohomology, which is an abstraction of the Fermat method of descent. The reader gets a taste of height functions, and via some good examples, gets insight into why the rank of the EC is so difficult to compute. A neat example is given of a nontrivial Shafarevich-Tate group.<br /> I did not read the chapters 9, 10, or 11 on ECs over the complex numbers, complex multiplication, and divisors, so I will omit their review. Chapter 12 introduces the famous zeta functions, and their use in obtaining arithmetic information about an EC. Zeta functions motivate the definition of an L-function of an EC, these being tremendously important in modern developments in the theory of ECs, such as the Swinnerton-Dyer and Birch conjecture, the latter of which is motivated rather nicely in this chapter.<br /> The last chapter of the book is an excellent introduction to the proof of Fermat's Last Theorem. Considering the level of the book, the author captures very well the essential ideas. Readers will be well prepared, after studying more algebraic number theory and the theory of Galois representations (which the author only skims in the book), to tackle the full proof if so desired.ECs, for here the author begins the discussion of elliptic curves over the rational numbers, which can be viewed as an example of Diophantine geometry. The famous Mordell-Weil theorem is proved, and as a sign that one is definitely in the arena of modern mathematics, the proof is given in terms of Galois cohomology, which is an abstraction of the Fermat method of descent. The reader gets a taste of height functions, and via some good examples, gets insight into why the rank of the EC is so difficult to compute. A neat example is given of a nontrivial Shafarevich-Tate group. <br /> I did not read the chapters 9, 10, or 11 on ECs over the complex numbers, complex multiplication, and divisors, so I will omit their review. Chapter 12 introduces the famous zeta functions, and their use in obtaining arithmetic information about an EC. Zeta functions motivate the definition of an L-function of an EC, these being tremendously important in modern developments in the theory of ECs, such as the Swinnerton-Dyer and Birch conjecture, the latter of which is motivated rather nicely in this chapter.<br /> The last chapter of the book is an excellent introduction to the proof of Fermat's Last Theorem. Considering the level of the book, the author captures very well the essential ideas. Readers will be well prepared, after studying more algebraic number theory and the theory of Galois representations (which the author only skims in the book), to tackle the full proof if so desired.	2003-07-19
1043431:US	50702879	R17TEBF573X2HJ	0395461073	756902042	Judgment Day:  My Years with Ayn Rand	Books	4	14	15	N	N	Provides good insight into two remarkable individuals	This book gives keen insight into the minds of two people who have influenced many through their writings, philosophical and otherwise. As the author reveals in extreme detail, their relationship was an extremely intense one, and this is not surprising given the capacity and power of their intellects. Their eventual separation was bitter, and even before this book came out, in fact long before, those who are familiar with their early writings could sense that something very bad had happened between them. Their break however did not affect their productivity and in spite of the pain they no doubt felt after it, both of them still exhibited a brilliance that is still being felt today through their writings.<br /> Some who read the book may say that it is the age difference between Rand and Branden that exacerbated their problems. This no doubt played a factor, and the author acknowledges this also, but as the book reveals, there were other things that aggravated such a relationship between two intellectual powerhouses as these are (were). Rand would like to say that it is the rational intellect that serves as the glue for a lasting and true relationship. Her limited definition of rationality though results in a narrow bandwidth that limits any alternative notions of love and friendship from getting through to her. The aesthetic quality of two people can play a large role in their attraction, and this should cause no surprise if one thinks of it in the context of human evolution. In addition, two people can be quite at odds philosophically and still have a satisfying relationship, a notion though that Rand would not be able to entertain.<br /> One can only imagine the pain that the spouses of these two individuals felt during their affair, which, interestingly, was known and revealed to them beforehand. The 'rational' decision that all four of them agreed to, namely that such an affair was 'meaningful' given the context, and to be shouldered lightly by their spouses. But such adventures, no matter how sophisticated the morality that brings them about, can be a heavy burden to those that decide to engage in them. Rand herself spoke of the proper identification of the facts of reality in order to live a successful life, but she had no prior experience in the affair she decided to participate in. Its consequences, and the feelings brought about therein, were not, and perhaps could not, be predicted by the moral system that all parties believed in at the time. It is easy to engage in the thinking about such systems; it is quite another to give them empirical content, and to show that they indeed are the ultimate guide to human conduct.<br /> In the beginning of the book, the author, in spite of their break, still expresses deep feelings for Rand, and deep regret at the announcement of her death. One can only wonder if Rand herself, after their break, ever, in the privacy of her thoughts, missed the author and the times they spent together. Anger takes much concentration to sustain itself, and is contrary to the natural human state of optimism, the latter both Rand and the author arguing well for. But these two individuals, through their personal interactions with each other, and via their writings, have had an enormous influence on many individuals, both positive and negative, but mostly positive...indeed overwhelmingly positive. In spite of the pain brought to others and themselves because of their affair, this influence is something both of them should be proud of.But such adventures, no matter how sophisticated the morality that brings them about, can be a heavy burden to those that decide to engage in them. Rand herself spoke of the proper identification of the facts of reality in order to live a successful life, but she had no prior experience in the affair she decided to participate in. Its consequences, and the feelings brought about therein, were not, and perhaps could not, be predicted by the moral system that all parties believed in at the time. It is easy to engage in the thinking about such systems; it is quite another to give them empirical content, and to show that they indeed are the ultimate guide to human conduct. <br /> In the beginning of the book, the author, in spite of their break, still expresses deep feelings for Rand, and deep regret at the announcement of her death. One can only wonder if Rand herself, after their break, ever, in the privacy of her thoughts, missed the author and the times they spent together. Anger takes much concentration to sustain itself, and is contrary to the natural human state of optimism, the latter both Rand and the author arguing well for. But these two individuals, through their personal interactions with each other, and via their writings, have had an enormous influence on many individuals, both positive and negative, but mostly positive...indeed overwhelmingly positive. In spite of the pain brought to others and themselves because of their affair, this influence is something both of them should be proud of.	2003-07-19
1050866:US	50702879	R4WTX84OIG979	0486217698	703930565	Music, Physics and Engineering (Dover Books on Music)	Books	3	19	20	N	N	Still could be helpful	Although this book was first published over 50 years ago, there are still many parts of it that can still be read profitably, due mostly to the fact that musical theory and the physics of musical instruments does not change with time. I read the book years ago to get some ideas for physics demonstrations in the classroom, and it was of great assistance in that regard. Those readers who intend to specialize in musical engineering would still find it a useful supplement to more modern treatments. The audio CD of course was not known at the time of publication, nor even the 8-track tape, but the development of both of these technologies was dependent on what came before them, and so a perusal of this book will allow insight into more contemporary technologies. The book also is one of the first to emphasize the psychological factors that must be taken into account when developing a technology for sound reproduction. The author in fact emphasizes the need for paying attention to the psychological factors in the preface to the second edition of the book. With the incredible advances in sound reproduction that have taken place since this book was written, one can appreciate his comments even more. One can only give thanks to the ingenuity of the sound and musical engineers both in the author's time and now for giving the listener an incredibly rich and satisfying auditory experience.	2003-07-13
1052258:US	50702879	R7G6PF9C4J81Z	0805014039	309896491	Man for Himself: An Inquiry Into the Psychology of Ethics	Books	4	25	31	N	N	A fine example of optimism	In this book the author gives an overview of his thinking on humanistic ethics, which is interesting from a speculative/philosophical viewpoint, but falls somewhat short if viewed from a scientific perspective. The book has an optimistic tone, as do many others by the author, and this makes the reading more palatable. If the ideas in it could be fleshed out with real scientific analysis, with supporting data, it would be a significant advance in the study of human psychology.<br /> The author explains his optimism, interestingly, by reference to his experience with patients in his psychoanalytic practice. He speaks of encountering the strength of the strivings for happiness and health exhibited by his patients, which he believes is the natural embodiment of humans. &quot;There is less reason&quot;, he says, &quot;to be puzzled by the fact that there are so many neurotic people than by the phenomenon that most people are relatively healthy in spite of the many adverse influences they are exposed to&quot;. The statistics supporting this are overwhelming, and without a doubt are on the side of optimism.<br /> The book is not a &quot;pop-psychology&quot;, &quot;self-help&quot; book though, but instead a theoretical attempt to shed light on the problem of ethics and psychology. The author's goal is to get the reader to ask questions, and not to expect to find advice on how to obtain &quot;happiness&quot;. The author's main goal is to find a validation for humanistic ethics that does not collapse into moral relativism but is based upon human nature and human's inherent qualities. The character structure of the mature and &quot;integrated personality&quot; is the origin of virtue, and vice originates from the ignoring of the self and &quot;self-mutilation&quot;. To have confidence in values, the author argues, one must know oneself and be aware of one's capacity for doing good and being a productive human being.<br /> The author carefully distinguishes between humanistic and authoritarian ethics, with the ethical norms of the former originating from humans themselves, while the latter some other entity. It is important for him to clarify the definition of &quot;authority&quot;, one being &quot;rational&quot; authority, whose source is &quot;competence&quot;, and &quot;irrational&quot; authority, whose source is always power over people. Rational authority he says, is based on the equality of the authority and the subject, with both of them differing only in the skill level in their respective fields and always having mutual respect for each other. Irrational authority on the other hand is based inherently on inequality, and denies the human capacity to know what is good or bad.<br /> In humanistic ethics, as the author sees it, is formally based on the principle that only humans can determine the criteria for good and evil, and completely rejects any transcendent source of values. What is &quot;good&quot; is what is good for humans, and the &quot;bad&quot; is what acts to their detriment. Humanistic ethics, far from suppressing individuality and self-realization, encourages it, and there is no room in it for ethical doctrines that do not take into account the needs and nature of human beings. It is a life-affirming ethical philosophy, one that taps the human capacity for genius, and encourages responsibility for one's own existence. The crippling of human powers is the ultimate vice.<br /> The problem then for humanistic ethics is to find out exactly what humans do in fact need in order to develop a healthy psychology. Throughout the book, the author attempts to characterize what such a psychology would be. In many instances throughout the book he makes some unexpected commentary, if judged by the overall theme of optimism in the book. For example, he views the human capacity for reason as both a &quot;blessing&quot; and a &quot;curse&quot;. Viewing reason as a distinctly human capacity, not shared by other organisms (and this is troubling from the standpoint of current evidence to the contrary from biology), the author puts humans into a state of &quot;constant and unavoidable disequilibrium&quot;. No matter what the level of accomplishment, humans will always be discontented and perplexed, and consequently driven to find new solutions, resulting in an endless restless cycle of achievement and discontent. But many humans do not fit into his sweeping generalizations here, but instead are very contented with their lives on this planet, and find the challenge of life fascinating, and who mourn only the prospect of it ending.<br /> Because of his professional status as a psychoanalyst, it is not surprising perhaps to see a somewhat elaborate classification of what constitutes a healthy versus a non-healthy personality. There are &quot;receptive&quot;, &quot;exploitative&quot;, &quot;hoarding&quot;, and &quot;marketing&quot; characters, which are non-productive and signs of personality &quot;disorder&quot; in his view. He gives detailed descriptions of these different types, but unfortunately does not quote case studies or any studies in the literature to support his  views. Do individuals who have these personalities find it difficult to live and adjust in soceity? The author would probably argue that such an &quot;adjustment&quot; could be done, but that by itself does not mean that the individual at hand is not following a healthy course of action. The author seems to be getting quite dogmatic in his classifications here, and leaves the reader with a somewhat narrow view of what constitutes a truly healthy personality.<br /> With more scientific research and justification put into his ideas, the author could have given the reader a more accurate view of what constitutes a healthy, integrated personality. The book is a good start though, philosophically speaking. Sometimes philosophy can encourage further scientific research, and sometimes it can clarify the issues involved in such research, but it can never take the place of science. The author's optimistic view of human nature is, to repeat, totally justified from a statistical point of view. And his view is somewhat rare, surprisingly, if one examines the statistics: the vast majority of humans are healthy, productive, and proud of their inner capacity for genius, and are without doubt fine examples of the humanistic ethic.troubling from the standpoint of current evidence to the contrary from biology), the author puts humans into a state of &quot;constant and unavoidable disequilibrium&quot;. No matter what the level of accomplishment, humans will always be discontented and perplexed, and consequently driven to find new solutions, resulting in an endless restless cycle of achievement and discontent. But many humans do not fit into his sweeping generalizations here, but instead are very contented with their lives on this planet, and find the challenge of life fascinating, and who mourn only the prospect of it ending. <br /> Because of his professional status as a psychoanalyst, it is not surprising perhaps to see a somewhat elaborate classification of what constitutes a healthy versus a non-healthy personality. There are &quot;receptive&quot;, &quot;exploitative&quot;, &quot;hoarding&quot;, and &quot;marketing&quot; characters, which are non-productive and signs of personality &quot;disorder&quot; in his view. He gives detailed descriptions of these different types, but unfortunately does not quote case studies or any studies in the literature to support his  views. Do individuals who have these personalities find it difficult to live and adjust in soceity? The author would probably argue that such an &quot;adjustment&quot; could be done, but that by itself does not mean that the individual at hand is not following a healthy course of action. The author seems to be getting quite dogmatic in his classifications here, and leaves the reader with a somewhat narrow view of what constitutes a truly healthy personality. <br /> With more scientific research and justification put into his ideas, the author could have given the reader a more accurate view of what constitutes a healthy, integrated personality. The book is a good start though, philosophically speaking. Sometimes philosophy can encourage further scientific research, and sometimes it can clarify the issues involved in such research, but it can never take the place of science. The author's optimistic view of human nature is, to repeat, totally justified from a statistical point of view. And his view is somewhat rare, surprisingly, if one examines the statistics: the vast majority of humans are healthy, productive, and proud of their inner capacity for genius, and are without doubt fine examples of the humanistic ethic.	2003-07-12
1053233:US	50702879	R22KN6M2ERFJWO	0691091722	764296537	The New Financial Order: Risk in the 21st Century	Books	3	35	43	N	Y	A fairly interesting book	In the last two decades fascinating developments and innovations have occurred in the field of finance. Now called financial engineering, the techniques used therein are dependent on highly sophisticated constructions in mathematics. Risk analysis has been a large part of this drive for innovation in finance, and is the subject of this book. The author proposes some &quot;radical&quot; innovations for risk management, and it is fascinating reading. Those who welcome new ideas and proposals in finance should find the book interesting, but the book is addressed to a non-technical general audience, and so most of the mathematical justification behind the ideas is left out. However, references are given for the author's work and others he has collaborated with for the reader who needs a more quantitative approach. There are some philosophical threads in the book that are somewhat troubling, for those who do not agree with the political and moral philosophy of John Rawls (who the author uses as a &quot;foundation&quot;), but the substance of his ideas can still be accepted even if this philosophy is explicity rejected.<br /> The author proposes six ideas for what he calls a &quot;new financial order&quot;: livelihood insurance, macro markets, income-linked loans, inequality insurance, intergenerational social security, and international agreements. He also proposes the development of massive databases, what he calls GRIDS, standing for &quot;global risk information databases&quot;, in order to provide the information that allows effective risk management, and &quot;indexed units of account&quot;, which is a new &quot;electronic money&quot; that serves to optimize the negotiating of risk.<br /> All of part three of the book is devoted to these six ideas. The author proposes 'income indexes&quot; as a way of hedging livelihoods and compares livelihood insurance with disability insurance. Those readers in the scientific profession will appreciate his ideas on livelihood insurance, due to the extreme risk in entering a specialized scientific field at the present time. Interestingly, the author compares this risk management device with academic tenure, believing that the latter is a good example of what could be done in society as a whole. He does not elaborate though on how universities reduce the &quot;moral risks&quot; in the tenure system, unfortunately. Optimizing productivity in individuals who are guaranteed lifelong employment is extremely difficult, and there are strong arguments against the institution of tenure for this reason.<br /> The author's discussion of &quot;macro markets&quot; is very interesting, especially if read in conjunction with his research papers. Motivating it with a real world example of the Citibank loan to Bulgaria in 1994, the interest rate of which was tied to the growth rate of the Bulgarian economy, he proposes a few ways in which risks can be hedged for everyone, such as 'perpetual futures', and 'macro securities', the latter of which he prefers and discusses at length. These are securities that are automatically issued and redeemed on demand, but only in pairs. Based again on indexes, there is a macro whose price increases when the index increases, the other going down when the index increases.The author gives several examples of the forms which these macro securities might take.<br /> Because of its philosophical orientation, the author's ideas on &quot;inequality insurance&quot; may be somewhat troubling, for it is the government who is to set legislation on the level of income inequality, and prevent inequality from getting worse. But the tax system will be &quot;framed&quot; so as appear to enforce a measure of inequality rather than the specification of tax rates. The author explains how the inequality insurance payments would be calculated using what he calls the &quot;after-tax Lorentz curve&quot;, coupled with the &quot;Gini coefficient&quot;, which is a measure of how much the Lorentz curve sags. Historical evidence though casts much suspicion on the government's ability to do anything of value in the economic realm. In addition, inequality, as meausured by the author, does not say anything of the history of what led to that inequality. The history must be known before any action should be taken to correct the inequality. Inequality in and of itself does not entail corrective action be taken to dissolve the inequality.<br /> The biggest virtue of the book is the author's awareness, and subsequent discussion, of the role of technological advancement in economic affairs, particularly the role to be played by machine intelligence. However, in my opinion, I think he is wrong when he expresses the belief that low-income workers will be at higher risk for losing their jobs because of the advances in artificial intelligence. On the contrary, these kinds of jobs will probably be the most secure, since it will not be cost effective to have robots do the kinds of tasks involved in these jobs. The highest risk will be for those who are in middle management, for the tasks that must be done in these positions can be done much more effectively by intelligent machines. Indeed, areas such as accounting, information management, financial engineering, and other areas that are information-intensive will be run entirely by machines in the near future. The resulting massive loss of jobs could be dealt with by using financial innovations along the lines of what the author proposes in this book. The enormous wealth generated by intelligent machines could be used to alleviate the financial strain that will be experienced by the people who lose their jobs to these machines. And the machines themselves may have their own unique and clever methods to solve this problem and others that arise in the coming decades.curve sags. Historical evidence though casts much suspicion on the government's ability to do anything of value in the economic realm. In addition, inequality, as meausured by the author, does not say anything of the history of what led to that inequality. The history must be known before any action should be taken to correct the inequality. Inequality in and of itself does not entail corrective action be taken to dissolve the inequality.<br /> The biggest virtue of the book is the author's awareness, and subsequent discussion, of the role of technological advancement in economic affairs, particularly the role to be played by machine intelligence. However, in my opinion, I think he is wrong when he expresses the belief that low-income workers will be at higher risk for losing their jobs because of the advances in artificial intelligence. On the contrary, these kinds of jobs will probably be the most secure, since it will not be cost effective to have robots do the kinds of tasks involved in these jobs. The highest risk will be for those who are in middle management, for the tasks that must be done in these positions can be done much more effectively by intelligent machines. Indeed, areas such as accounting, information management, financial engineering, and other areas that are information-intensive will be run entirely by machines in the near future. The resulting massive loss of jobs could be dealt with by using financial innovations along the lines of what the author proposes in this book. The enormous wealth generated by intelligent machines could be used to alleviate the financial strain that will be experienced by the people who lose their jobs to these machines. And the machines themselves may have their own unique and clever methods to solve this problem and others that arise in the coming decades.	2003-07-11
1057947:US	50702879	R3HITHJWF5YX42	1556521391	157967853	Moving from Within: A New Method for Dance Making	Books	4	3	3	N	N	A good introduction	The editor of this book wastes no time in stating the author's theme of the book: that creativity is a private affair (and this is a general statement, and not just applicable to dance). Who knows better than the person in knowing how to interpret the &quot;intricate morass&quot; that constitutes him/her? Expressing their internal sensations and intuitions though are difficult for the individual however, for meanings of words can be altered as they are filtered through the individual personality. But in a book words must be used of course, and the author does so with great skill throughout. It is perhaps suprising that a choreographer would write about creativity and attempt to teach it as a skill that can be learned. The best choreographers consider creativity maybe as a momentary release, as a kind of play, defying explanation, and they are usually not to motivated to do so. This author though explains that throughout her life her main ambition was to find new ways of facilitating creative growth.<br /> To instruct others how to be creative entails that one understand the nature of the creative process. This is nontrivial, and so it is not surprising that the author would overview briefly various research opinions on the subject. The creative potential is influenced by the environment and one's interaction with it. One's experiences can be expressed symbolically, but this may not always be done effectively with words: one may need to use motion, sound, or painting. Dance choreography to the author is, following the classification of the philosopher/logician Susanne Langer, a &quot;presentational form of symbolization&quot;, which is inherently metaphorical, and feelings are presented via the use of images and illusion.<br /> Imitation, conformity, and fitting into preconceived patterns can have no intersection with creativity argues the author. It requires the imagination, the sensing and feeling, and the restless desire for truth. She definitely believes in an unconscious contribution to the creative act, but also a &quot;pre-conscious&quot; mode of thought that integrates fragmentary knowledge and isolated elements of experience and brings about the rise of new conceptions. This middle ground between the conscious and unconscious, the Ruggian &quot;transliminal mind&quot;, is the origin of creativity according to the author. The author makes reference to research in neuroscience regarding the hemispheric specialization of the brain, and its possible connection of creativity with the right hemisphere. She does mention though that current research points to the fact that specific localization may not be valid. The current research in neuroscience into the nature of creativity is fascinating and this book just touches on it. No doubt experimental techniques in cognitive science will settle the issue in the upcoming decades.<br /> The author is not content with merely theorizing about dance and creativity, but in teaching students to find out and utilize their own. She lists several different classroom activities throughout the book to encourage student action. Feeling, sight, and imaging are discussed in real-world contexts and many examples given of how to integrate them into the production of (personal) movement. The role of symmetry/asymmetry in movement forms is discussed also, interestingly, showing a possible Doris Humphrey influence. The therapeutic role of dance is also given emphasis by the author, with a few real examples discussed. The author quotes students as telling her that dance has changed their life, and they will never be the same again. Dance has that impact, always, and this book will certainly assist in its realizing its power. But the only way to learn dance is to dance.unconscious contribution to the creative act, but also a &quot;pre-conscious&quot; mode of thought that integrates fragmentary knowledge and isolated elements of experience and brings about the rise of new conceptions. This middle ground between the conscious and unconscious, the Ruggian &quot;transliminal mind&quot;, is the origin of creativity according to the author. The author makes reference to research in neuroscience regarding the hemispheric specialization of the brain, and its possible connection of creativity with the right hemisphere. She does mention though that current research points to the fact that specific localization may not be valid. The current research in neuroscience into the nature of creativity is fascinating and this book just touches on it. No doubt experimental techniques in cognitive science will settle the issue in the upcoming decades. <br /> The author is not content with merely theorizing about dance and creativity, but in teaching students to find out and utilize their own. She lists several different classroom activities throughout the book to encourage student action. Feeling, sight, and imaging are discussed in real-world contexts and many examples given of how to integrate them into the production of (personal) movement. The role of symmetry/asymmetry in movement forms is discussed also, interestingly, showing a possible Doris Humphrey influence. The therapeutic role of dance is also given emphasis by the author, with a few real examples discussed. The author quotes students as telling her that dance has changed their life, and they will never be the same again. Dance has that impact, always, and this book will certainly assist in its realizing its power. But the only way to learn dance is to dance.	2003-07-07
1061369:US	50702879	R2LDL7VZ6L2VC9	0486202380	305656365	The Sense of Beauty: Being the Outline of Aesthetic Theory	Books	5	31	32	N	N	Excellent	The philosophy of Santayana is remembered mostly by his theory of aesthetics, which is discussed in detail in this book. His aesthetic theory is basically subjective, or &quot;psychological&quot;, and if viewed from a contemporary standpoint, somewhat at odds with current developments in neuroscience, but closer than most schools of Western philosophy. All philosophical theories of aesthetics are interesting to investigate from the standpoint of comparing them to what is said about the human aesthetic faculty in modern research in neuroscience.<br /> As in ethics, Santayana approaches aesthetics in three different ways, namely as the exercise of the aesthetic faculty, the history of art, and the psychological. The first two do not concern the author in the book, his attention devoted entirely to the third. His intention is to remove himself from the influence of the poets and of Plato, and find the out how ideals are formed in the mind, how objects may be compared with them, what properties are shared in beautiful things, and the process by which humans become sensitive to beauty and in turn value it. He is after a definition of beauty that explains its origin in human experience, and one that explains the human capacity to be sensible of beauty and the relation between a beautiful object and its ability to excite the human senses.<br /> The author takes a different definition of aesthetics, being one that he calls &quot;critical&quot; or &quot;appreciative perception&quot;, and which results from combining a notion of criticism with that of the notion of aesthetics as a theory of perception. Santayana wanted to develop a theory of aesthetics that relies on perceptions as a judgmental, critical notion. Perceptions that are not appreciations are thus to be excluded. An aesthetic theory then deals with the &quot;perception of values&quot;.<br /> The author's view of religion is well-known, and his atheism rare for his time. The religious imagination he says, has resulted in creations that rival those of the poets and novelists, so much so, he says, that humans believe the content of these creations to have objective reality. The ideas of these divinities are further enhanced by the realization of their natural power, with the belief in the reality of an ideal personality bringing about its further idealization, eventually spanning many human generations. History and tradition are cast by the imagination of these deities, in which peity resides and is nourished. The author of course does not excuse the God of Christianity from this, but he acknowledges the possibility that the human conceptions of Christ and Mary may in fact have real counterparts (the evidence of this not to be explored in this work).<br /> The author states that unless human nature undergoes radical change, the main intellectual and aesthetic value of ideas will come from the creative acts of imagination. If human perceptions are not connected with human pleasures, there would be no need to look at things, no interest in them at all, and no importance would be imputed to them. It is indeed amazing how many ideas, thought to be rational, logical, or abstract, actually fit in with the author's aesthetic worldview. Concepts and results in science and mathematics in particular, after their discovery, are sometimes thought of as having their origin in logic and reason. But it was the keen human imagination that brought them about: a grand interplay of intuition and playfullness. Ugly ideas are not permissible: only the most beautiful survive...and oddly, and most interestingly, it is these that usually seem to work the best, and transcend the context in which they were discovered.esulted in creations that rival those of the poets and novelists, so much so, he says, that humans believe the content of these creations to have objective reality. The ideas of these divinities are further enhanced by the realization of their natural power, with the belief in the reality of an ideal personality bringing about its further idealization, eventually spanning many human generations. History and tradition are cast by the imagination of these deities, in which peity resides and is nourished. The author of course does not excuse the God of Christianity from this, but he acknowledges the possibility that the human conceptions of Christ and Mary may in fact have real counterparts (the evidence of this not to be explored in this work). <br /> The author states that unless human nature undergoes radical change, the main intellectual and aesthetic value of ideas will come from the creative acts of imagination. If human perceptions are not connected with human pleasures, there would be no need to look at things, no interest in them at all, and no importance would be imputed to them. It is indeed amazing how many ideas, thought to be rational, logical, or abstract, actually fit in with the author's aesthetic worldview. Concepts and results in science and mathematics in particular, after their discovery, are sometimes thought of as having their origin in logic and reason. But it was the keen human imagination that brought them about: a grand interplay of intuition and playfullness. Ugly ideas are not permissible: only the most beautiful survive...and oddly, and most interestingly, it is these that usually seem to work the best, and transcend the context in which they were discovered.	2003-07-04
1066034:US	50702879	R3VTZACFKJFX09	1402001363	289232465	Hidden Markov Models for Bioinformatics (Computational Biology)	Books	4	8	9	N	Y	Primarily for bio-mathematicians	The field of computational biology has expanded greatly in the last decade, mainly due to the increasing role of bioinformatics in the genome sequencing projects. This book outlines a particular set of algorithms called hidden Markov models, that are used frequently in genetic sequence search routines. The book is primarily for mathematicians who want to move into bioinformatics, but it could be read by a biologist who has a strong mathematical background. The book is detailed at some places, sparse in others, and reads like a literature survey at times, but many references are given, and there are very interesting exercises at the end of each chapter section. In fact it is really imperative that the reader work some of these exercises, as the author proves some of the results in the main body of the text via the exercises.<br /> Some of the highlights of the book include: 1. An overview of the probability theory to be used in the book. The material is fairly standard, including a review of continuous and discrete random variables, from the measure-theoretic point of view, i.e the author introduces them via a probability space which is set with its sigma field, and a probability measure on this field. The weight matrix or &quot;profile&quot; as it is sometimes called, is defined, this having many applications in bioinformatics. Bayesian learning is also discussed, and the author introduces what he calls the &quot;missing information principle&quot;, and is fundamental to the probabilistic modeling of biological sequences. Applications of probability theory to DNA analysis are discussed, including  shotgun assembly and the distribution of fragment lengths from restriction digests. A collection of interesting exercises is included at the end of the chapter, particularly the one on the null model for pairwise alignments. 2. An introduction to information theory and the relative entropy or &quot;Kullback distance&quot;, the latter of which is used to learn sequence models from data. The author defines the mutual information between two probability distributions and the entropy, and calculates the latter for random DNA. He also proves some of the Shannon source coding theorems, one being the convergence to the entropy for independent, identically distributed random variables. The Kullback distance is then defined, as a distance between probability distributions, with the caution that it is not a metric because of lack of symmetry. 3. The overview of probabilistic learning theory, where 'learning from data' is defined as the process of inferring a general principle from observations of instances. 4.  The very detailed treatment of the EM algorithm, including the discussion of a model for fragments with motifs. 5. The discussion of alignment and scoring, especially that of global similarity. Local alignment is treated in the exercises. 6. The discussion of the learning of Markov chains via Bayesian modeling applied to a training sequence via a family of Markov models. Frame dependent Markov chains are discussed in the context of Markovian models for DNA sequences. 7. The discussion of influence diagrams and nonstandard hidden Markov models, in particular the excellent diagrams drawn to illustrate the main properties, and excellent discussion is given of an &quot;HMM with duration&quot; in the context of the functional units of a eukaryotic gene. This is important in the GeneMark:hmm software available. 8. The treatment of motif-based HMM, in particular the discussion of the approximate common substring problem. 9. The discussion of the &quot;quasi-stationary&quot; property of some chains and the connection with the &quot;Yaglom limit&quot;. 10. The treatment of Derin's formula for the smoothing posterior probability of a standard HMM. The author shows in detail that the probability of a finite length emitted sequence conditioned on a state sequence of the HMM depends only on a subsequence of the state sequence. 11. The treatment of the lumping of Markov chains, i.e. the question as to whether a function of a Markov chain is another Markov chain. 12. The very detailed treatment of the Forward-Backward algorithm and the Viterbi algorithm. 13. The discussion of the learning problem via the quasi-log likelihood function for HMM. 14. The discussion of the limit points for the Baum-Welch algorithm. Since the Baum-Welch algorithm deals with iterations of a map, its convergence can be proved by finding the fixed points of this map. These fixed points are in fact the stationary points of the likelihood function and can be related to the convergence of the algorithm via the Zangwill theory of algorithms. Unfortunately the author does not give the details of the Zangwill theory, but instead delegates it to the references (via an exercise). The Zangwill theory can be discussed in the context of nonlinear programming, with generalizations of it occurring in the field of nonlinear functional analysis. It might be interesting to investigate whether the properties of hidden Markov models, especially their rigorous statistical properties, can all be discussed in the context of nonlinear functional analysis.the lumping of Markov chains, i.e. the question as to whether a function of a Markov chain is another Markov chain. 12. The very detailed treatment of the Forward-Backward algorithm and the Viterbi algorithm. 13. The discussion of the learning problem via the quasi-log likelihood function for HMM. 14. The discussion of the limit points for the Baum-Welch algorithm. Since the Baum-Welch algorithm deals with iterations of a map, its convergence can be proved by finding the fixed points of this map. These fixed points are in fact the stationary points of the likelihood function and can be related to the convergence of the algorithm via the Zangwill theory of algorithms. Unfortunately the author does not give the details of the Zangwill theory, but instead delegates it to the references (via an exercise). The Zangwill theory can be discussed in the context of nonlinear programming, with generalizations of it occurring in the field of nonlinear functional analysis. It might be interesting to investigate whether the properties of hidden Markov models, especially their rigorous statistical properties, can all be discussed in the context of nonlinear functional analysis.	2003-07-01
1068141:US	50702879	R3LTX71YBAG37L	0451163087	465394256	For the New Intellectual: The Philosophy of Ayn Rand (50th Anniversary Edition) (Signet)	Books	2	8	25	N	N	Not suitable as a history of philosophy	When reading this book I was reminded of some of the works of the philosopher/poet Friedrich Nietzsche, who never attempted to pull the punches and whose dialog was interesting and fun, and not ever in the mainstream. However, he did not usually address the philosophical issues at stake because of this.<br /> The author of this book is very harsh in her criticism of philosophy, indeed of most of the schools of philosophy throughout history. Her criticism though is not detailed enough, and too vituperative to be of much use to the understanding of the trends in the history of philosophy, especially ethical and moral philosophy. The author mentions Plato, Aristotle, Plotinus, Augustine, Aquinas, Hegel, Kant, Compte, Marx, Nietzsche, Spencer, Bentham, Hume, and Descartes. To be fair to any one of these philosophers would take perhaps an entire lifetime of careful analysis and research, and thousands of pages of written material, but the author spends only a few paragraphs on each, classifying them according as to their status as being &quot;Witchdoctor&quot; philosophy or not. Of all these philosophers, the author is sympathetic with only two of them: Aristotle, who she labels as &quot;the intellect's Declaration of Independence&quot;, and Aquinas, who she labels as &quot;the prelude to the Renaissance&quot;, and responsible for the return of Aristotle to Europe. That Aquinas was influenced by Aristotle there is no doubt, but it was the efforts of Islamic scholars who translated the works of Aristotle, and thus they should be viewed as the progenitors of the Renaissance, not Aquinas. And even though Aristotle's philosophy is highly interesting and of course greatly influenced the history of Western philosophy, the author does not give sufficient justification for her enthusiasm for it. Having read much of Aristotle's philosophy, I have yet to run into passages from his texts where he states that there is only &quot;one&quot; reality, as the author imputes to him in this book. She gives no textual quotation for this view, even though it indeed might be correct.<br /> The remaining philosophers are classified as being &quot;Witchdoctors&quot;: these individuals are spoken of as those who are frightened by physical reality, never practical, emotional, and embrace mysticism as their essential worldview. The author however gives no examples from the works of these philosophers to support this strange classification. In addition, she evidently believes she has full understanding of the mind and how it works, reducing it to sensations and perceptions, followed by conceptions, the latter of which is uniquely human. If only it were this easy, as they current efforts in neuroscience will illustrate. The author makes no attempt to justify her view of the mind from a scientific viewpoint, and gives no references to the scientific literature. In addition, the author seems that consciousness is needed for an entity to be able to form concepts. That this is not really true is proven by current developments in artificial intelligence: concept formation can indeed be done by certain software programs, which can prove (original) mathematical results and  arrive at new scientific knowledge. These programs are not conscious in the way the author describes however (and albeit then only superficially).<br /> Should we label the intellectuals today, or even at the time of publication of this book as &quot;frightened zombies&quot;, as the author does early in the book?  Does this serve any scholarly purpose that will further our understanding of modern culture and its philosophical overtones? Such individuals she says have abdicated the realm of the intellect and have embraced Buddhism and Existentialism in some instances. But what of these last two schools of thought? What makes them an abdication of the intellect? The author does not give textual support for her reasons for her labeling, making her claims unsubstantiated in this regard. I know a few brilliant scholars and productive scientists who practice Buddhism, and some who are sympathetic with Existentialism. These individuals have certainly not abdicated their minds and their goals, and show no sign of doing so in the future. They are confident, rational individuals, not frightened zombies.<br /><br /> The author would have made the book much more palatable if she would engage in more rigorous scholarship. One can agree with many of the ideas in the book, such as the notion of morality as being a code of values to guide human choices and actions. Interestingly, this view can be justified scientifically, even given a mathematical formulation, and further formulated in the context of rational intelligent agents in the field of artificial intelligence. In addition, she recommends that anyone interested in living in a free and rational society should follow the advice of the old Western sheriff and &quot;leave your guns outside&quot;. She is certainly right about this, and her belief that no one has the right to force his ideas on others.<br /> The current rate of technological development is perhaps the biggest counterexample against the stance of the author on political and economic issues. The rate is unprecedented, and is itself increasing, and despite the &quot;decadent&quot; philosophies that currently exist (as seen through the author's eyes), shows no sign of abatement. This might prove that folly and reason can exists in the same person(s); but it is also proof that humans are the best example of lifeforms that have ever evolved yet on this planet. Confident of the future, with a firm grasp of reality, unashamed of themselves, and always yearning for understanding and adventure, they are indeed true intellectuals.w brilliant scholars and productive scientists who practice Buddhism, and some who are sympathetic with Existentialism. These individuals have certainly not abdicated their minds and their goals, and show no sign of doing so in the future. They are confident, rational individuals, not frightened zombies.<BR>  <br /> The author would have made the book much more palatable if she would engage in more rigorous scholarship. One can agree with many of the ideas in the book, such as the notion of morality as being a code of values to guide human choices and actions. Interestingly, this view can be justified scientifically, even given a mathematical formulation, and further formulated in the context of rational intelligent agents in the field of artificial intelligence. In addition, she recommends that anyone interested in living in a free and rational society should follow the advice of the old Western sheriff and &quot;leave your guns outside&quot;. She is certainly right about this, and her belief that no one has the right to force his ideas on others.   <br /> The current rate of technological development is perhaps the biggest counterexample against the stance of the author on political and economic issues. The rate is unprecedented, and is itself increasing, and despite the &quot;decadent&quot; philosophies that currently exist (as seen through the author's eyes), shows no sign of abatement. This might prove that folly and reason can exists in the same person(s); but it is also proof that humans are the best example of lifeforms that have ever evolved yet on this planet. Confident of the future, with a firm grasp of reality, unashamed of themselves, and always yearning for understanding and adventure, they are indeed true intellectuals.	2003-06-29
1079158:US	50702879	R3HANDSF5ALT6W	0387950680	520966408	Rational Homotopy Theory (Graduate Texts in Mathematics)	Books	5	5	5	N	N	An excellent, very understandable overview	This book follows up and greatly extends the work of the topologist Dennis Sullivan on the rationalization of topological spaces and continuous maps between these rationalizations. For n greater than or equal to 2, both the nth-homotopy group the nth homology group are abelian, and this lead Sullivan to introduce the concept of a \\"rationalized space\\". For such a space, one studies its nth homology group over the rational numbers, and the nth homotopy group of a rationalized space is the tensor product of the nth homotopy group with the rational numbers. Information of course is lost in such an approach, but it has the advantage of being amenable to calculation. The authors give a detailed overview of just what can be done for rationalized spaces and they do an excellent job of presenting it to those who are not experts in the theory. The book can definitely be read by graduate students who have finished courses in algebraic and geometric topology, and professional mathematicians who have some background in topology and who are curious about the subject.<br /> As the authors explain eloquently, the (computational) power of rational homotopy theory comes from its algebraic formulation, which was first discussed by Sullivan and the mathematician Daniel Quillen, and involves the use of graded objects with both an algebraic structure and a \\"differential\\". What is fascinating about the role of the differential is its connection with homotopy theory, and not just in homology and cohomology theory as encountered in first-year graduate courses in algebraic topology. The authors deal with three different graded categories with a differential in the book, namely modules over a differential graded algebra (R, d), commutative cochain algebras, and differential graded Lie algebras. In analogy to the free resolution of an arbitrary module over a ring, associated with these three cases is a modeling construction that in the first case is a semi-free resolution of a module over (R, d), in the second case a \\"Sullivan model\\" which is a commutative cochain algebra which is free as a commutative graded algebra, and in the third case a free Lie model, which is free as a graded Lie algebra.<br /> The first case arises topologically when considering continuous maps between spaces and the singular cochain algebras via the induced cochain map. When the map is a fibration, the authors compute the cohomology of the fiber using a semifree resolution. The first case also arises in considering the action of a topological monoid over a space and the singular chains. When the action is a principal G-fibration X-> Y, the authors compute the homology of Y using semifree resolutions. The authors then give a proof of the Whitehead-Serre theorem using this result. The proof of this follows their plan to avoid diagram-chasing techniques as much as possible: they do not use spectral sequences.<br /> The second case involves a generalization of the classical commutative cochain algebra of smooth differential forms on a manifold. The authors construct a \\"Sullivan functor\\" from topological spaces to commutative cochain algebras, the Sullivan model, and the Sullivan \\"realization functor\\", the latter of which converts a Sullivan algebra into a rational topological space. The rational homotopy types of a space are then in bijective correspondence to isomorphism classes of \\"minimal\\" Sullivan algebras, and the homotopy classes of maps between rational spaces are in bijective correspondence to homotopy classes of maps between minimal Sullivan algebras. The characterization of a Sullivan algebra as being \\"minimal\\" comes from the fact that for such algebras there is a natural isomorphism between the vector space on which the Sullivan algebra is modeled and integral homomorphisms of the homotopy group to the ground field.<br /> The third case involves the use of differential graded Lie algebras. The authors construct the \\"homotopy Lie algebra\\" of a simply connected topologicalspace, which is the homotopy group of the loop space tensored with the ground field, and the homotopy Lie algebra of a minimal Sullivan algebra. The latter is interesting in that it involves using the quadratic part of the differential in order to obtain the Lie bracket. These two constructions of homotopy Lie algebras are the same for the Sullivan algebra over the space. In this context, the authors consider \\"free Lie models\\" for differential graded Lie algebras, which can be thought of as an assignment of generators to each single n-cells of a CW complex. The authors give many helpful examples of free Lie models that illustrate this, such as for the sphere, adjunction spaces, projective spaces, and homotopy fibers.<br /> Since rational and ordinary homotopy are different in terms of their information content, it is perhaps not surprising that the Lusternik-Schnirelmann category makes its appearance in this book. The rational LS category is the LS category of a rational CW complex in the rational homotopy type of the space, and the authors calculate it in terms of Sullivan models, verifying that the rational case is much easier to compute than the general case. As further verification, the authors show that the Postnikov fibers in a Postnikov decomposition of a simply connected finite CW complex all have finite rational LS category, which is not true in the integral case. Even further, they show that the rational LS category of a product is the sum of the products, contrary to the ordinary LS category which is not well-behaved for products and fibrations.<br /> The authors also discuss various applications at the end of the book, involving how to break up n-dimensional simply connected finite CW complexes into two groups: those whose rational homotopy groups vanish in degrees greater than or equal to 2n, and those where they grow exponentially. The former are called \\"rationally elliptic\\" and the latter \\"rationally hyperbolic\\". This classification can be determined, as they show, from a calculation of the \\"Betti numbers\\" of the loop group of the space over the rationals. A collection of unsolved problems for the ambitious reader ends the book.cal space, which is the homotopy group of the loop space tensored with the ground field, and the homotopy Lie algebra of a minimal Sullivan algebra. The latter is interesting in that it involves using the quadratic part of the differential in order to obtain the Lie bracket. These two constructions of homotopy Lie algebras are the same for the Sullivan algebra over the space. In this context, the authors consider \\"free Lie models\\" for differential graded Lie algebras, which can be thought of as an assignment of generators to each single n-cells of a CW complex. The authors give many helpful examples of free Lie models that illustrate this, such as for the sphere, adjunction spaces, projective spaces, and homotopy fibers. <br /> Since rational and ordinary homotopy are different in terms of their information content, it is perhaps not surprising that the Lusternik-Schnirelmann category makes its appearance in this book. The rational LS category is the LS category of a rational CW complex in the rational homotopy type of the space, and the authors calculate it in terms of Sullivan models, verifying that the rational case is much easier to compute than the general case. As further verification, the authors show that the Postnikov fibers in a Postnikov decomposition of a simply connected finite CW complex all have finite rational LS category, which is not true in the integral case. Even further, they show that the rational LS category of a product is the sum of the products, contrary to the ordinary LS category which is not well-behaved for products and fibrations. <br /> The authors also discuss various applications at the end of the book, involving how to break up n-dimensional simply connected finite CW complexes into two groups: those whose rational homotopy groups vanish in degrees greater than or equal to 2n, and those where they grow exponentially. The former are called \\"rationally elliptic\\" and the latter \\"rationally hyperbolic\\". This classification can be determined, as they show, from a calculation of the \\"Betti numbers\\" of the loop group of the space over the rationals. A collection of unsolved problems for the ambitious reader ends the book.	2003-06-21
1081240:US	50702879	R1DHTFJQJ2LI2U	0201730634	35516073	The Intelligent Wireless Web	Books	3	2	2	N	Y	Needs more details	This book outlines a proposal to integrate artificial intelligence and wireless technology into the World Wide Web in order to make it more powerful and more tuned to the real needs of the user. It is an interesting proposal, but omits discussion of some important issues. The book is targeted to an audience of developers, engineers, researchers, and IT managers who need to understand how to deliver, via wireless technology, intelligent processes and services.<br /> Chapter 1 is an overview of the five areas that the authors feel are needed to form the Intelligent Wireless Web. All of these are viable and desired from a technical standpoint. However, from a human factors standpoint, one of them is somewhat troubling, namely the need for having voice activation for the user interface. This could be extremely annoying if one is working in the now popular cubicle environments, due to the noise level generated from user's speech. Privacy issues could arise too, since voice patterns are easily recorded. Making the transition from dumb/static Web applications to intelligent/dynamic ones is sorely needed, but voice activation/recognition should be the problem of those who are working in other areas of machine intelligence, such as robotics. Of course, if work environments evolve into more private scenarios, the author's proposals for voice activation could become viable.<br /> Chapters 2 and 8 concern speech recognition. I did not read these chapters so their review will be omitted.<br /> In chapter 3, the authors discuss how wireless technology could be integrated into peronal area networks (WPANs). The authors here exhibit a keen awareness both of the technology and the human factors involved in creating what they call a \\"Personal Space\\". Home automation will be slow-going perhaps at first, due to legacy systems now in place, but it is highly desirable from the standpoint of energy conservation and home security. To prevent government and other forms of malicious intrusion, wireless security will have to be top priority before the Intelligent Wireless Web is implemented.<br /> Chapter 4 is an overview of the basics behind both wired and wireless networks, with the goal of merging them effectively. The authors are clearly advocating the use of LMDS for high-speed wireless access. However, they do not discuss any performance studies to give more weight to their arguments for LMDS. \\"Project Oxygen\\" is discussed as an approach to accomodate mobile and stationary devices, and for moving away from TCP as a congestion manager, but the discussion is too brief to be helpful.<br /> In chapter 5, the authors discuss the status of mobile wireless, IP version 6, and Mobile IP. The authors are a little more quantitative in this chapter, mentioning for example the inability of TDMA to deal with bursty data flows, but no details are given. A fairly detailed overview of \\"third-generation\\" mobile wireless technologies is given however. Performance issues are not discussed though, and it would have been interesting if the authors would have included a discussion of MANET.<br /> Chapter 6 is a general overview of artificial intelligence and how it might be applied to Web protocols. As in all discussions on AI, controversies and disagreements will arise in the mind of the reader, but the authors are fair in representing the main ideas, considering the relatively short length of the chapter. The discussion on distributed AI is the most relevant for the book.<br /> In chapter 7 the authors continue the discussion on AI with the goal of seeing to what extent it can be incorporated into the Web. I was glad to see a discussion of the Cyc application in this chapter, even though it was very short. From the author's standpoint the Web currently does not really express intelligence, since it does not adapt, a necessary requirement for learning. A \\"learning algorithm\\" is defined as a process that extracts data from a database to serve as its input, and then performs a set of operations on the input, giving finally an output that represents learning. The authors feel that the Semantic Web holds much promise for building an intelligent Web, and outline several tools, such as XML and RDF, that assist in the construction of the Semantic Web. Particularly interesting is the discussion of the need for self-organization in order for the Web to be considered intelligent. The property of self-organization will also be the most problematic to implement, due to the extreme distrust that some now feel against software that has not been validated by a human.  This is especially the case for those having to deal with medical records and information on human health.<br /> So why even attempt to build the Intelligent Wireless Web? The authors attempt to answer this question in Chapter 9. They conclude, based on Moore's law, that wireless chip technology will allow cellular carriers to build networks for less than $100 per customer. They never however answer how much intelligent applications over the wireless Web will improve productivity. This can be accomplished to a large degree with simulation and mathematical modeling, but the authors do not do so.<br /> Chapter 10 is an overview of the actual progress in developing the Intelligent Wireless Web. The challenges are considerable, not only from a technical standpoint in the creation of intelligent applications, but also because of legacy issues. The authors are aware of this and give a network schematic outlining an integrated wired/wireless network. Their concept of an Intelligent Wireless Web is a good one, but their justification for it, especially for the use of speech recognition, is somewhat weak. They need to perform a lot more modeling studies to see just how these smart applications are going to behave on the Web.en performs a set of operations on the input, giving finally an output that represents learning. The authors feel that the Semantic Web holds much promise for building an intelligent Web, and outline several tools, such as XML and RDF, that assist in the construction of the Semantic Web. Particularly interesting is the discussion of the need for self-organization in order for the Web to be considered intelligent. The property of self-organization will also be the most problematic to implement, due to the extreme distrust that some now feel against software that has not been validated by a human.    This is especially the case for those having to deal with medical records and information on human health. <br /> So why even attempt to build the Intelligent Wireless Web? The authors attempt to answer this question in Chapter 9. They conclude, based on Moore's law, that wireless chip technology will allow cellular carriers to build networks for less than $100 per customer. They never however answer how much intelligent applications over the wireless Web will improve productivity. This can be accomplished to a large degree with simulation and mathematical modeling, but the authors do not do so. <br /> Chapter 10 is an overview of the actual progress in developing the Intelligent Wireless Web. The challenges are considerable, not only from a technical standpoint in the creation of intelligent applications, but also because of legacy issues. The authors are aware of this and give a network schematic outlining an integrated wired/wireless network. Their concept of an Intelligent Wireless Web is a good one, but their justification for it, especially for the use of speech recognition, is somewhat weak. They need to perform a lot more modeling studies to see just how these smart applications are going to behave on the Web.	2003-06-20
1081504:US	50702879	R2NBBPLEWBSRYI	0471264822	314307211	America Declares Independence	Books	3	9	10	N	N	Interesting book	One the most difficult things to figure out when examining the life of Thomas Jefferson is why he could write such powerful documents, full of respect for human life and human dignity, and still own, at one period of his life, 267 slaves. The author of this book attempts to explain and conjecture his reasons for this, and other things of more relevance to the present time. The author's main emphasis is to negate an idea held in his view by the &quot;Religious Right&quot;, namely that the United States is a &quot;Christian country&quot; and was intended to be so by the framers of the Declaration of Independence and the Constitution. He does so successfully, and gives ample historical references for his arguments. However, individuals like Jerry Falwell and Pat Robertson cannot be said to represent the entire &quot;Religious Right&quot;, even if they claim to, and even if this claim is imputed to them by the author. And further, even though the author has refuted their arguments about the Christian nature of the founding documents, this still does not refute the claim that the United States &quot;should&quot; be a Christian nation. The &quot;Religious Right&quot;could perhaps acknowledge the arguments of the author as true and then consequently advocate the founding documents be rejected and a Christian nation be formed. This has not been suggested yet by the &quot;Religious Right&quot; (that I have heard), but could be in the near future. Religion and toleration are usually immiscible, and if backed into a corner, religion has throughout history proven itself extremely dangerous and has exhibited brutality going beyond all rational bounds.	2003-06-20
1087940:US	50702879	RV8OVBP1SDOET	0060516054	433958284	What Went Wrong?: The Clash Between Islam and Modernity in the Middle East	Books	5	5	9	N	Y	Superb	Although short, this book gives a very interesting discussion of the history of the tension between the Islamic religion and the thrust towards modernization in the West. Belief systems are slow to adapt to new ideas, and this is brought out with great clarity in this book. Via the study of its past, the author gives the reader much insight into the events of today's Middle East, and inspires further reading on the subject.<br /> The author discusses the need for the citizens of the Ottoman empire to emulate the technology of Western Europe. The underlying theme  of the book is that European power, resulting from innovation and experiment, changed the balance of power between the Ottoman empire and Europe. But for a Muslim, living in Europe was an abomination. One should not mix with the infidels. The author explains the need though for Muslims to do just this, due to the threats from the West.<br />[The disciples of hate in 911 clearly did not mind living in Western society and learning of Western devices. One can only wonder if at any moment they may have connected with some of the people in the area in which they were living and then perhaps had second thoughts about what they were going to do. Anger and hate are emotions that are hard to sustain for long periods of time. They require much concentration to preserve. But a little religion always helps in this regard].<br /> The Ottoman's solution to the threat of the West, was, according to the author, to return to the basics of the Islamic religion, a belief he reminds the reader is still predominant in the Middle East. What is most interesting from the standpoint of today is the role of France as being the dominant European influence. In the book the rise of the modern Middle East begins with the invasion of Egypt by Napoleon in 1798. Even before that time French schools existed in the Middle East and the French language was compulsory for military students.<br /> One inevitably compares the three major religions of the West when reading the book. Interestingly, Islam \\"wins\\" if judged by tolerance for those of different beliefs and equal rights, but fails miserably when notice is made of the attitudes towards slaves and women. But as the author points out, a slave can become free by choice of his master. The status of woman in Islamic society though is static and immutable, unfortunately.<br /> Clearly Middle Easteners were perplexed by the rise of the West and its achievements. What accounted for the superiority of the West? What is the source of Western success? Clearly, as the book brings out, Middle Easteners were seeking answers beyond that which religion gave them, and, in retrospect, they were certainly correct to doubt the efficacy of religion in this regard. For, as the author notes, it was the infidels who benefited from the changes taking place.<br /> The author also addresses the role of technology in the modern Middle East in bringing about change, imposing limits on both rulers and teachers. But the cowards of 911 used technology in an attempt to bring about the demise of the West. However they could not use it without meeting their own demise, and have thus proven again the sterility of their belief system, and those that supported them.<br /> Another interesting commentary in the book is the role of young people, particularly in Iran. Educated in the West, they brought to Iran the then alien ideas of freedom. With the turmoil now facing the leaders of Iran this very day, this is a special irony. Should one call the young people now battling in the streets of Iran the \\"New Young Ottomans\\", in reference to the \\"Young Ottomans\\" described in this book? The comparison might be too loose, since the street fighters now were not educated in the West (but they do have access to a huge information base of \\"corrupting\\" influences: the Internet).<br /> The biggest tragedy in the history of Middle East is the reluctance of Islamic society to accept the science of the West, given the incredible contributions of the Middle East to modern science and mathematics. The author asks the reader to consider the question as to why one would accept Islam as being an obstacle to freedom, science, and economic development, when in the past, and at that time closer to the sources of Islamic faith than now, it was a pioneer in all three of these? The answer is quite straightforward from the standpoint of science: those that were introducing science were not acting like Muslims when they carried it out. Shall we call them Muslims who sometimes practiced science or scientists who sometimes acted like Muslims? Either designation will hold, for the two are diametrically opposed: no amount of prayer or supplication will bring about the results of science, for that is to be done with discipline of thought and painstaking experimentation...and no scientific experiment can illustrate the soundness of Islam, or indeed of any other religion, Western or otherwise.<br /> In an afterword to the book, the author expresses grief and concern of course over the events of 911. He points out correctly that the followers of bin Laden are only a minority, and that most adherents of Islam are concerned with living in freedom, in living in a world that allows them to live their own lives under a responsible government. The author expresses hope that freedom will triumph as it did over the repressive regimes of the twentieth century.<br /> But it will. The human mind of the twenty-first century is too efficacious to fail in its cause in this regard. And with billions of such minds populating our planet, the odds are against a grim future. Now more than ever is the time to be proud of being a member of the human species.f the West, given the incredible contributions of the Middle East to modern science and mathematics. The author asks the reader to consider the question as to why one would accept Islam as being an obstacle to freedom, science, and economic development, when in the past, and at that time closer to the sources of Islamic faith than now, it was a pioneer in all three of these? The answer is quite straightforward from the standpoint of science: those that were introducing science were not acting like Muslims when they carried it out. Shall we call them Muslims who sometimes practiced science or scientists who sometimes acted like Muslims? Either designation will hold, for the two are diametrically opposed: no amount of prayer or supplication will bring about the results of science, for that is to be done with discipline of thought and painstaking experimentation...and no scientific experiment can illustrate the soundness of Islam, or indeed of any other religion, Western or otherwise. <br /> In an afterword to the book, the author expresses grief and concern of course over the events of 911. He points out correctly that the followers of bin Laden are only a minority, and that most adherents of Islam are concerned with living in freedom, in living in a world that allows them to live their own lives under a responsible government. The author expresses hope that freedom will triumph as it did over the repressive regimes of the twentieth century.<br /> But it will. The human mind of the twenty-first century is too efficacious to fail in its cause in this regard. And with billions of such minds populating our planet, the odds are against a grim future. Now more than ever is the time to be proud of being a member of the human species.	2003-06-15
1096565:US	50702879	R2R5CIW6KOWEU9	1860940625	553393176	Transgenic Plants: With an Appedix on Intellectual Properties & Commercialisation of Transgenic Plants by John Barton	Books	4	0	0	N	Y	Good introduction for the time of publication	My interest in this book was: 1. To investigate the possibility of exciton-chlorophyll based computation via the genetic engineering of the chloroplast. 2. To obtain a background in just what can be done in plant transgenesis from a commercial point of view, in particular ornamental plants and other horticultural applications, such as the genetic engineering of lawn grass for pathogen resistance, controlled height, and color shading. 3. To gain more insight into the current conflict between genetically-modified and organic crops being waged in the media and between continents. 4. The possibility of using synthetic methods for inducing plant transgenesis. Not all of these were addressed in the book, but it did serve to give more insight into how transgenesis in plants is done, and examples of each, up until the year of publication. The field of course has considerably advanced since then.<br /> Chapter 1 begins with various definitions of gene transfer and a brief history of attempts to create transgenic plants. The authors emphasize the great changes that have taken place in the last two decades, but acknowledging the plant transgenesis is still in relative infancy.<br /> Chapter 2 is then a discussion of techniques for transformation, such as Agrobacterium-mediated, in planta, direct transfer, and biolistic methods. The omit though any discussion of the exact laboratory protocols, and they caution that the ratio between transient and stable transformation can have vary widely. Some of the more interesting discussions in this chapter include: 1. The fact that different agrobacterial strains have different host ranges, with some being limited, while others having broad host ranges. 2. The molecular mechanism by which T-DNA is transferred in the plant's genome. The T-complex's ability to wait and  &quot;catch&quot; a naked fragment of plant DNA is brought out with enthusiasm by the authors.<br /> In chapter 3, the authors discuss the various tools for genetic transformation. Some interesting disscussions here include: 1. The reduction of expression due to the removal of scaffold attachment regions.  2. Killer genes, such as the Barnase gene and TA29.<br /> Chapter 4 is an overview of the regulation of gene expression. Interesting discussions here include: 1. Light-regulated gene expression and light signal transduction in the context of photomorphogenesis. The authors emphasize that single genes can possess many responsive cis acting elements which can interact or independent. The combinatorics of the cis acting elements and the transcription factors make the possibility of plant transgenesis seemingly unlikely, the authors emphasize. 2. Protein targeting into the chloroplast and mitochondria. 3. The SAR/MAR effect via the higher order structure of chromatin and its relation to gene silencing. 4. The occurrence of gene silencing and the complications it causes for producing transgenic plants. 5. Antisense RNA and its role in suppressing gene expression. Because of the book's date of publication, RNA interference, which was discovered in 1998, is not discussed in this book.<br /> In chapter 5, the authors review the genetic engineering of crop improvement. They address crop protection from biotic and abiotic stress (such as viruses and fungal pathogens), improvement of yields, crop quality, and the genetic engineering of ornamental plants. The discussion is thorough and the authors bring out many interesting facts that shed light on the current debates on GM crops, one of these being that the use of lysis-producing antimicrobial toxins in transgenic crops is not harmful to mammals. The now well-known (and controversial) bacillus thurigenesis (BT) endotoxin and its use as an insect pathogen is discussed in detail. Also discussed, and equally as controversial, are transgenic crops with herbicide resistance.  As for abiotic stress, the authors discuss various transgenic strategies for salt and drought resistance, and tolerance against metal toxicity. The discussion of ornamentals is a sample of the  intriguing future that is ahead for horticulture.<br /> The authors discuss some of the many products that can be manufactured using transgenic plants in chapter 6. They begin with the use of transient expression of heterologous genes, overviewing a few cases where this has been accomplished. They they turn their attention to where the heterologous gene is integrated into the genome of the transgenic plants, one very interesting example being the production of antigens, such as that for hepatitis B. Another interesting example is the production of antibodies, such as the production of secretory immunoglobin A. By far the most fascinating discussion of all though is the one on the use of using plant transgenesis to produce degradable polymers.<br /> The production of transgenic plants for the commercial market has raised quite a fuss in recent years, and so the authors devote the last chapter of the book to the discussion of the risks and benefits of doing so. It is a fair discussion and addresses the main concerns, with the authors expressing caution but clearly supporting the genetic engineering of plants, as long as it benefits humankind.against metal toxicity. The discussion of ornamentals is a sample of the  intriguing future that is ahead for horticulture. <br /> The authors discuss some of the many products that can be manufactured using transgenic plants in chapter 6. They begin with the use of transient expression of heterologous genes, overviewing a few cases where this has been accomplished. They they turn their attention to where the heterologous gene is integrated into the genome of the transgenic plants, one very interesting example being the production of antigens, such as that for hepatitis B. Another interesting example is the production of antibodies, such as the production of secretory immunoglobin A. By far the most fascinating discussion of all though is the one on the use of using plant transgenesis to produce degradable polymers. <br /> The production of transgenic plants for the commercial market has raised quite a fuss in recent years, and so the authors devote the last chapter of the book to the discussion of the risks and benefits of doing so. It is a fair discussion and addresses the main concerns, with the authors expressing caution but clearly supporting the genetic engineering of plants, as long as it benefits humankind.	2003-06-07
1096678:US	50702879	R1LAT25DDGPE1D	9971978660	166871902	Superstrings: The First 15 Years of Superstring Theory (2 Volumes)	Books	4	1	1	N	N	A fine collection	Future historians of science will no doubt view the collection of articles in these two volumes as the definitive ones that set the tone for the development of string theory in the twentieth century. Indeed the mathematical tools employed by superstring theory are unprecedented, and this trend continues. One could say with confidence that every branch of mathematics known has found application in superstring theory.<br /> Superstring theory has evolved into what is now known as D-brane theory or M-theory. One can certainly learn superstring theory by starting with these, but the physical motivations for the theory may not be very clear if this approach is taken. To understand the physics, it is best to take an historical approach, beginning with how string theory arose in the context of attempts to understand the strong interaction. The collection of articles in these volumes will be of an enormous help to those who want an in-depth understanding of string theory, and historians of science will find them valuable in their attempts to place string theory in its proper historical context.<br /> Every part of superstring theory is fascinating, and when reading the articles one can see the tension between the different theories of the strong interaction, such as the S-matrix formalism and dual theories, and the problems with using quantum field theory to describe the strong interaction. The S-matrix formalism in particular was invented so as to circumvent the problems with using field theory. The first article by Joel Scherk in the first volume gives a good overview of these early developments, particularly the role of the Veneziano model. He gives good insight into why field theories were found to be ineffective in accounting for certain phenomena in the strong interaction, such as the infinite number of resonances (the famous Regge behavior). Interestingly though, as the author also points out, the dual theories evolved into theories that were closer to field theories, rather than the S-matrix theories that they arose from.<br /> The editor these volumes does an excellent job of introducing the papers, and puts them in an historical context. An updated version of these two volumes to reflect the &quot;second string revolution&quot;, as it is sometimes called, would include papers on D-branes, M-theory, and papers reflecting some of the brilliant mathematical developments that have occurred since these volumes were published. What is really need though is not an update but a definitive book on the history of string theory, with no limitations on the size, in order to give future generations of students and researchers insight into what is certainly the most complex physical theory ever constructed.es, rather than the S-matrix theories that they arose from. <br /> The editor these volumes does an excellent job of introducing the papers, and puts them in an historical context. An updated version of these two volumes to reflect the &quot;second string revolution&quot;, as it is sometimes called, would include papers on D-branes, M-theory, and papers reflecting some of the brilliant mathematical developments that have occurred since these volumes were published. What is really need though is not an update but a definitive book on the history of string theory, with no limitations on the size, in order to give future generations of students and researchers insight into what is certainly the most complex physical theory ever constructed.	2003-06-07
1098715:US	50702879	R82L4TFX95LDX	1852335947	814737440	Artificial Immune Systems: A New Computational Intelligence Approach	Books	3	10	10	N	Y	Pretty good overview	Bio-inspired computing has taken the world by storm in the last few decades, going by the names of neural networks, genetic algorithms, evolutionary programming, and swarm intelligence. Another one has arisen in the last 15 years or so, is inspired by the biology of the immune system, and is the subject of this book. The authors of the book are aware that the approach is novel, but do a good job of presenting the field who like the reviewer are newcomers to the field, but want to know what it is all about and if it indeed has useful applications. They discuss their own work in the area and that of others, and extensive references are given for further reading.<br /><br /> After a short introduction to the subject in chapter 1, the authors move on to a description of the biological immune system in chapter 2. They stress the need for understanding the mechanisms that regulate the adaptive immune response, so as to be able to control the transformation of an immune response from an \\"aggressive\\" to a \\"benign\\" state. The authors explain the difference between the \\"innate\\" immune system and the \\"adaptive\\" immune system. As the name implies, the adaptive immune response is a kind of \\"learning\\" ability that allows the immune system to improve itself as antigens are encountered. The innate immune response though remains constant along the lifetime of the organism. A short description of the T-cells and B-cells is given, some of which can differentiate into \\"memory cells\\"; that remain circulating in the body and protect against a given antigen. Particularly interesting is the role of \\"pattern recognition receptors\\"; that recognize molecular patterns associated with pathogens. The clonal selection theory of the adaptive immune system, along with the somewhat controversial immune network theory.<br /><br /> Chapter 3 is an overview of how to to actually create an artificial immune system (AIS). The emphasize that anything deemed controversial in the biological framework need not be when viewed from a computational perspective, such as the immune network theory. Biology is used for the inspiration of the computational models, and as such they need not reflect entirely what is true in the biological case. They also emphasize that the various attempts to simulate the immune system on computers are not examples of an AIS. Also, an AIS is more than just a pattern recognition algorithm, even though it must employ this in its use. To give a framework for an AIS, the authors employ a model of immune cells and molecules called a \\"shape-space\\". In this shape space one models the affinity of the \\"molecules\\"; via a metric, which the authors eventually choose to be the Hamming metric. They then give an overview of various algorithms for modeling the immune system, such as bone marrow, thymus, and immune network models, in addition to clonal selection algorithms. For those readers familiar with dynamical systems, the immune network models are very interesting, due to the use of differential equations, and also the fact that such in immune network models the immune system is performing even in the absence of external stimuli.<br /><br /> Chapter 4 gives a survey of artificial immune systems, such as spectra recognition for chemical reactions, infectious disease surveillance, analysis of medical data, and computational security. The latter was of particular importance to the reviewer, so more attention was directed to the discussion and the references  than other parts of the book. The issue with the approaches for network intrusion detection and virus detection lie mostly in the performance of the network. Agents that are cleverly designed may form a very accurate way of detecting this malicious behavior, but their deployment on a network may degrade its performance considerably.<br /><br /> In chapter 7, the authors discuss various case studies in artificial immune systems that shed more light on the examples of Chapter 4. The computer network security application is discussed again, and a low number of false positives is shown to follow after the artificial immune system is simulated. However, the performance of the network is not pointed out by the authors. The authors also give more details on the application of artificial immune systems to data analysis and optimization. The discussion is interesting, but it is still an open question as to whether this approach is indeed better than other ones in optimization theory, i.e. how does the immune approach compare with the \\"free-lunch\\" theorems so often quoted in optimization theory? The authors do make a brief comparison of their optimization algorithm with evolution strategies, and this is somewhat helpful to those who are familiar with the latter. The last chapter of the book looks to future applications of artificial immune systems, and in its connection with learning paradigms in artificial intelligence. The authors are open-minded about the future of AIS but also subject it to critical analysis.<br /><br /> The book motivated the reviewer to investigate the use of AIS more fully, and to begin thinking about possible applications, such as 1. Event correlation in networks. 2. Network routing: Routes that are inefficient are viewed as \\"antigens\\";, and the network immune system will then cure the system of these routes, meaning that it will remember them as being antigens up to some practical time scale. The routing scheme in place will not implement these routes within this time frame. 3. The TCP/IP protocol in the context of the immune network theory where reliable connections are based on the epitope/paratope recognition capability. Any emergent properties of the network overlaid with the TCP/IP protocol such as learning, memory, and self-tolerance could be studied by viewing the packet network as an immune network. 4. Network QoS, with packets marked as low priority viewed as temporary antigens. 5. Using the function optimization capabilities of AIS do calculate the effective bandwidth of ATM networks. 6. Data analysis, particularly in the construction of algorithms to distinguish chaos from noise.y application is discussed again, and a low number of false positives is shown to follow after the artificial immune system is simulated. However, the performance of the network is not pointed out by the authors. The authors also give more details on the application of artificial immune systems to data analysis and optimization. The discussion is interesting, but it is still an open question as to whether this approach is indeed better than other ones in optimization theory, i.e. how does the immune approach compare with the \\"free-lunch\\" theorems so often quoted in optimization theory? The authors do make a brief comparison of their optimization algorithm with evolution strategies, and this is somewhat helpful to those who are familiar with the latter. The last chapter of the book looks to future applications of artificial immune systems, and in its connection with learning paradigms in artificial intelligence. The authors are open-minded about the future of AIS but also subject it to critical analysis.<br /><br /> The book motivated the reviewer to investigate the use of AIS more fully, and to begin thinking about possible applications, such as 1. Event correlation in networks. 2. Network routing: Routes that are inefficient are viewed as \\"antigens\\";, and the network immune system will then cure the system of these routes, meaning that it will remember them as being antigens up to some practical time scale. The routing scheme in place will not implement these routes within this time frame. 3. The TCP/IP protocol in the context of the immune network theory where reliable connections are based on the epitope/paratope recognition capability. Any emergent properties of the network overlaid with the TCP/IP protocol such as learning, memory, and self-tolerance could be studied by viewing the packet network as an immune network. 4. Network QoS, with packets marked as low priority viewed as temporary antigens. 5. Using the function optimization capabilities of AIS do calculate the effective bandwidth of ATM networks. 6. Data analysis, particularly in the construction of algorithms to distinguish chaos from noise.	2003-06-05
1104470:US	50702879	R97AQCA3M37G4	0521357527	164707196	001: Superstring Theory: Volume 1, Introduction (Cambridge Monographs on Mathematical Physics)	Books	4	39	39	N	N	Should still be required reading	Anyone interested in learning string theory could perhaps start with the current formulation involving D-branes and M theories. This is certainly possible and will lead one to the frontiers of research. However, it would not perhaps give one an appreciation of string theory that would be obtained by persuing a study that explains how it arose in the study of the strong interaction . This book, written by three giants in string theory, will give the reader such a study, and was the first book to appear on the subject. The book is a monograph, and not a textbook, since no exercises appear, but it could still serve as a reference and \\"required reading\\" for courses in string theory.<br /> The learning of string theory can be a formidable undertaking for those who lack the mathematical background. Indeed, a proper understanding of string theory, not just a forma one, will require a solid understanding of algebraic and differential geometry, algebraic topology, and complex manifolds. There are many books on these subjects, but I do not know of one what will give the student of string theory an in-depth understanding of the relevant mathematics. These two volumes include two rather lengthy chapters on mathematics, one on differential geometry and the other on algebraic geometry. The mastery of these two chapter will give readers a formal understanding of the mathematics, and will allow them to perform calculations in string theory efficiently, but do not give the insight needed for extending its frontiers. There have been a few books published on string theory since these two volumes appeared, but they too fail in this regard (and some even admit to doing so). To gain the necessary insight into the mathematics will entail a very time-consuming search of the early literature and many face-to-face conversations with mathematicians. The \\"oral tradition\\" in mathematics is real and one must embed onself in it if a real, in-depth understanding of mathematics is sought.<br /> The physics of string theory though is brought out with incredible skill by the authors, and the historical motivation given in the introduction is the finest in the literature. Now legendary, the origin of string theories in the dual models of the strong interaction is discussed in detail. The Veneziano model, as discussed in this part, has recently become important in purely mathematical contexts, as has most every other construction in string theory. The mathematical results that have arisen from string theory involves some of the most fascinating constructions in all of mathematics, and mathematicians interested in these will themselves be interested in perusing these volumes, but will of course find the approach mathematically non-rigorous.<br /> Some of the other discussions that stand out in the book include: 1. The global aspects of the string world sheet and the origin of the moduli space, along with its connection to Teichmuller space. 2. The world-sheet supersymmetry and the origin of the integers 10 and 26 as being a critical dimension. In this discussion, the authors give valuable insight on a number of matters, one in particular being why the introduction of an anticommuting field mapping bosons to bosons and fermions to fermions does not violate the spin-statistics theorem. 3. The light-cone gauge quantization for superstrings. The authors show that the manifestly covariant formalism is equivalent to the light-cone formalism and is ghost-free in dimension 10. The light-cone gauge is used to quantize a covariant world-sheet action with space-time supersymmetry, with this being Lorentz invariant in dimension 10. This allows, as the authors explain in lucid detail, the unification of bosonic and fermionic strings in a single Fock space. 4. Current algebra on the string world sheet and its origin in the need for distributing charge throughout the string, rather than just at the ends. The origin of heterotic string theory is explained in this context.he physics of string theory though is brought out with incredible skill by the authors, and the historical motivation given in the introduction is the finest in the literature. Now legendary, the origin of string theories in the dual models of the strong interaction is discussed in detail. The Veneziano model, as discussed in this part, has recently become important in purely mathematical contexts, as has most every other construction in string theory. The mathematical results that have arisen from string theory involves some of the most fascinating constructions in all of mathematics, and mathematicians interested in these will themselves be interested in perusing these volumes, but will of course find the approach mathematically non-rigorous. <br /> Some of the other discussions that stand out in the book include: 1. The global aspects of the string world sheet and the origin of the moduli space, along with its connection to Teichmuller space. 2. The world-sheet supersymmetry and the origin of the integers 10 and 26 as being a critical dimension. In this discussion, the authors give valuable insight on a number of matters, one in particular being why the introduction of an anticommuting field mapping bosons to bosons and fermions to fermions does not violate the spin-statistics theorem. 3. The light-cone gauge quantization for superstrings. The authors show that the manifestly covariant formalism is equivalent to the light-cone formalism and is ghost-free in dimension 10. The light-cone gauge is used to quantize a covariant world-sheet action with space-time supersymmetry, with this being Lorentz invariant in dimension 10. This allows, as the authors explain in lucid detail, the unification of bosonic and fermionic strings in a single Fock space. 4. Current algebra on the string world sheet and its origin in the need for distributing charge throughout the string, rather than just at the ends. The origin of heterotic string theory is explained in this context.	2003-05-31
1112585:US	50702879	R3D48R6EA4IIRP	0262041995	961444400	Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems	Books	4	53	61	N	Y	Good overview	This book is a detailed overview of the computational modeling of nervous systems from the molecular and cellular level and from the standpoint of human psychophysics and psychology. They divide their conception of modeling into descriptive, mechanistic, and interpretive models. My sole interest was in Part 3, which covers the mathematical modeling of adaptation and learning, so my review will be confined to these chapters. The virtue of this book, and others like it, is the insistence on empirical validation of the models, and not their justification by &quot;thought experiments&quot; and arm-chair reasoning, as is typically done in philosophy.<br /> Part 3 begins with a discussion of synaptic plasticity and to what degree it explains learning and memory. The goal here is to develop mathematical models to understand how experience and training modify the neuronal synapses and how these changes effect the neuronal patterns and the eventual behavior. The Hebb model of neuronal firing is ubiquitous in this area of research, and the authors discuss it as a rule that synapses change in proportion to the correlation of the activities of pre- and postsynaptic neurons. Experimental data is immediately given that illustrates long-term potentiation (LTP) and long-term depression (LTD). The authors concentrate mostly on models based on unsupervised learning in this chapter. The rules for synaptic modification are given as differential equations and describe the rate of change of the synaptic weights with respect to the pre- and postsynaptic activity. The covariance and BCM rules are discussed, the first separately requiring postsynaptic and presynaptic activity, the second requiring both simultaneously. The authors consider ocular dominance in the context of unsupervised learning and study the effect of plasticity on multiple neurons. The last section of the chapter covers supervised learning, in which a set of inputs and the desired outputs are imposed during training.<br /> In the next chapter, the authors consider the area of reinforcement learning, beginning with a discussion of the mathematical models for classical conditioning, and introducing the temporal difference learning algorithm. The authors discuss the Rescorla-Wagner rule , which is a trial-by-trial learning rule for the weight adjustments, in terms of the reward, the prediction, and the learning rate. They then discuss more realistic policies such as static action choice, where the reward/punishment immediately follows the action taken, and sequential action choice, where rewards may be delayed. The authors discuss foraging behavior of bees as an example of static action choice, reducing it to a stochastic two-armed bandit problem. The maze task for rats is discussed as an example of sequential action choice, and the authors reduce it to the &quot;actor-critic algorithm.&quot; A generalized reinforcement learning algorithm is then discussed, with the rat water maze problem given as an example.<br /> Chapter 10 is an overview of what the authors call &quot;representational learning&quot;, which, as they explain, is a study of neural representations from a computational point of view. The goal is to begin with sensory input and find out how representations are generated on the basis of these inputs. That such representations are necessary is based on for example the consideration of the visual system, since, argue the authors, what is presented at the retina is too crude for an accurate representation of the visual world. The main strategy in the chapter is to begin with a deterministic or probabilistic input and construct a recognition algorithm that gives an estimate of the input. The algorithms constructed are all based on unsupervised learning, and hence the existence and nature of the causes must be computed using heuristics and the statistics of the input data. These two requirements are met via the construction of first a generative model and then a recognition model in the chapter. The familiar 'expectation maximization' is discussed as a method of optimization between real and synthetic data in generative models. A detailed overview of expectation maximization is given in the context of 'density estimation'. The authors then move on to discuss causal models for density estimation, such as Gaussian mixtures, the K-means algorithm, factor analysis, and principal components analysis. They then discuss sparse coding, as a technique to deal with the fact that the cortical activity is not Gaussian. They illustrate an experimental sample, showing the activity follows an exponential distribution in a neuron in the inferotemporal area of the macaque brain. The reader will recognize 'sparse' probability distributions as being 'heavy-tailed', i.e. having values close to zero usually, but ones far from zero sometimes. The authors emphasize the difficulties in the computation of the recognition distribution explicitly. The Olshausen/Field model is used to give a deterministic approximate recognition model for this purpose. The authors then give a fairly detailed overview of a two-layer, nonlinear 'Helmholtz machine' with binary inputs. They illustrate how to obtain the expectation maximization in terms of the Kullback-Leibler divergence. The learning in this model takes place via stochastic sampling and occurs in two phases, the so-called &quot;wake and sleep&quot; algorithm. The last section of the chapter gives a general discussion of how recent interest in coding, transmitting, and decoding images has led to much more research into representational learning algorithms. They discuss multi-resolution decomposition and its relationship to the coding algorithms available.odel in the chapter. The familiar 'expectation maximization' is discussed as a method of optimization between real and synthetic data in generative models. A detailed overview of expectation maximization is given in the context of 'density estimation'. The authors then move on to discuss causal models for density estimation, such as Gaussian mixtures, the K-means algorithm, factor analysis, and principal components analysis. They then discuss sparse coding, as a technique to deal with the fact that the cortical activity is not Gaussian. They illustrate an experimental sample, showing the activity follows an exponential distribution in a neuron in the inferotemporal area of the macaque brain. The reader will recognize 'sparse' probability distributions as being 'heavy-tailed', i.e. having values close to zero usually, but ones far from zero sometimes. The authors emphasize the difficulties in the computation of the recognition distribution explicitly. The Olshausen/Field model is used to give a deterministic approximate recognition model for this purpose. The authors then give a fairly detailed overview of a two-layer, nonlinear 'Helmholtz machine' with binary inputs. They illustrate how to obtain the expectation maximization in terms of the Kullback-Leibler divergence. The learning in this model takes place via stochastic sampling and occurs in two phases, the so-called &quot;wake and sleep&quot; algorithm. The last section of the chapter gives a general discussion of how recent interest in coding, transmitting, and decoding images has led to much more research into representational learning algorithms. They discuss multi-resolution decomposition and its relationship to the coding algorithms available.	2003-05-24
1121202:US	50702879	R1UC5J5B5PWYHU	0385503857	264457638	Oryx and Crake: A Novel (Atwood, Margaret Eleanor)	Books	5	1	5	N	Y	An engaging story...but not our future	The only other book I read by the author was \\"Handmaid's Tale\\" and it was a great story. The fact that I agreed with the message of the book made it better. This novel, the latest by the author, is also a great story, and remains so even though I completely disagree with the author's message. The author's view of biotechnology is extreme and outlandish, and deeply cynical, but the story is captivating and one can find oneself totally engaged in it from the very first page.<br /> The story revolves around someone called \\"Snowman\\", an apparent loner in a world completely disrupted by biotechnology via the techniques of genetic engineering. It is a world containing many new transgenic creatures: the pigoons, rakunks, wolvogs, cane toads, snats, and flourescent rabbits. It is a world brought about by biotech industries going by the name of OrganInc Farms, HelthWyzer, and Nanotech Biochem. These industries used to exist on \\"Compounds\\", which were distinct from the \\"pleeblands\\", and \\"Compound\\" people did not go the pleeblands, the later being inhabited by addicts, muggers, identity-stealers, paupers, and crazies.<br /> The \\"human soul\\" has been discarded in this world, with this leading to a deeply apathetic populace desensitized to killing and torture. Transgenic animal creation was brought about by \\"biolab hotshots\\" who liked to fool around with the creation of animals: it made them \\"feel like God.\\" And religion and God have been exposed as resulting from a \\"cluster of neurons\\", a \\"G-spot\\" in the brain, the elimination of which by genetic engineering was tricky but accomplished, giving people who were neither zombies nor psychopaths.<br /> Ironically, the author has more confidence in the efficacy of genetic engineering than those who even now are practicing it. Biotech managers and investors would wish that things were as easy as they are in the story. But they are not, and patience and millions of dollars in investment are needed to bring about a successful product. The biotech industry is very volatile at the time of publication of this book, definitely not the powerful behemoth able to bring about products and techniques as efficiently as they do in the story. The many transgenic animals that populate the planet in this future world are actually intriguing if viewed from another vantage point. The rapidity in which they come about as distinct species should not dissuade us from caring for them as we would any other lifeform. If biotechnology is efficacious enough to increase the diversity of life on this planet, this is indeed a virtue, not a vice.<br /> Will the story frighten many into an anti-biotech stance? It might, but this should not cause those who support biotechnology any concern. To attempt to refute a fantasy is a missappropriation of time; to attempt to create products that enrich life on Earth is time definitely worth spent, and a goal definitely worth striving for. The future holds much promise, and will be unlike anything the author envisages: yes, a world populated by thousands of new species of plants and animals, but also a world populated by billions of thinking machines, both human and non-human. If human history is the guide, it having been one of brilliant technological and scientific innovation, and, as statistics shows, an overwhelming repugnance to violence and war, then there is indeed much to look forward to.<br /> The author is a great story-teller, and this book (and others of hers) is ample proof of this, but she is a bad statistician. For humans are not the anxious, maladjusted, violent creatures of her books. Quite the contrary, as a mere counting will indicate, they have proved able to distinguish between good and bad, between what is worthy and what is not, and how to bring about change working for them, not against. In the words of the (jealous) deity in the most popular book in Western literature, humans definitely know good from evil, and with this ability, along with their wisdom and remarkable intelligence, have become as gods...remarkable intelligence, have become as gods...	2003-05-17
1121447:US	50702879	R386UB8CZNM7OS	0470848286	960768378	Animal Transgenesis and Cloning	Books	4	3	3	N	Y	A good overview	The subject of animal transgenesis is both interesting and controversial, and its ramifications for all life on Earth are awesome. Once a highly specialized area in biology, and employing very unreliable experimental techniques, it has grown into a field that employs hundreds of individuals in science and industry, and along with using more reliable laboratory procedures, it makes use of highly sophisticated mathematical algorithms and results.<br /> The author gives a fine overview of the subject, and with some prior exposure to molecular biology, the book can be read by anyone needing a background in it or anyone merely curious about the current status and capabilities of the field. The book addresses both the science and technology of transgenic animals, and the profound ethical considerations involved with its widespread use in the natural world. The creation of transgenic animals has not been as controversial as that of plants, but the advent of  xenotransplantation and the possibility of transgenic animals being released in great numbers in wild populations will no doubt raise the level of debate and truculence. One can only hope that the harsh and bitter vitriole that characterizes both sides of the debate on genetic engineering will evolve into dialog of a more calm and rational nature. If the techniques of genetic engineering are proven unsafe or not viable, then they should not be used. If they are safe, they should be employed immediately in plants and animals, including humans.<br /> The author endeavors in all places in the book to be up-to-date, quoting the latest papers and preprints on the subject. There are places in the book the read more like a literature survey, but most of the book is a detailed account of the experimental techniques used in animal transgenesis, and for someone like myself who is not an expert in wet biology, it has some interesting surprises, such as the fact that cloned goats were normal in all cases attempted, even in those where the oocytes were obtained after in vitro maturation. But as a sign of the rapid developments in molecular biology, the recent developments showing that some mammalian cloning, such as that for primates, faces severe difficulties, is not discussed in the book, despite its publication date. Also, in the discussion on gene therapy as applied to severe combined immunodeficiency, the author does not mention the recent problems with patients developing leukemia after this kind of therapy.<br /> Throughout the book the author is very honest about the current limitations of transgenic technology. She states explicitly that all the mechanisms controlling gene expression are not known and that the construction of a gene may eliminate essential signals or combine incompatible signals. This will lead to disappointing transgene expression, according to the author. This assertion is also interesting in that it casts some doubt on the viewpoint that the genome of an organism is 'flexible' or easily changed. It is quite possible that they are instead conservative over time, and highly resistant to stable modification. In fact, recent experiments with mosquitos have given evidence supporting the latter point of view. The author gives additional evidence in the human genome, the major part of which is non-functional. Therefore, the author concludes, a foreign gene added to the human genome has a small probability of being integrated into a host gene, and is therefore silent.<br /> The possibility of vectors used for animal transgenesis to be transmitted to intestinal bacteria and then disseminated into the environment is only briefly mentioned by the author, stating only that such a transfer can be avoided by removing the prokaryotic origin of replication. It would have been nice if the author had spent more time on this, given the current controversies on this kind of transfer.<br /> A very interesting discussion given by the author concerns the use of what she calls 'non-classical' vectors for the recombination of targeted genes, one being the use of bacterial recombinases. The author mentions one example of this, involving a bacterial Rec A enzyme that is associated in vitro with a mononstrand DNA sequence. Such a technique was able to induce a homologous recombination of the corresponding gene in mammalian cells and mouse embryos using microinjection, but she cautions that conformation of these experiments is yet to be performed.<br /> The author also includes a discussion of the use of the triple helix between RNA and DNA as a technique for animal transgenesis. Such a technique involves the targeted inhibition of a gene by the formation of the triple helix in pyrimidine-rich regions. The triple helix blocks transcription by RNA polymerase II and RNA synthesis can be directed by the transgene. The author reminds the reader though that such techniques have yet to be successful though in animal transgenesis.<br /> Another topic of current interest is that of RNA interference, and the author discusses it in the context of animal transgenesis. She discusses experiments in which (double-stranded) RNA interference can be implemented in cultured cells to inhibit gene expression. The author considers the possibility, yet to be explored, of the expression of transgenes coding for double-stranded RNA inhibiting gene expression in mammals.<br /> The author discusses many applications of animal transgenesis, including the study of human diseases, models for viral infections and prion diseases, Alzheimer's disease, xenografting, the production of pharmaceuticals, and improved animal production. As the techniques of animal transgenesis are improved, there will no doubt be many more beneficial applications. There will also be the delightful possibility of the creation of new types of animals with the sole purpose of making the natural world a much more diverse and interesting place to live.-classical' vectors for the recombination of targeted genes, one being the use of bacterial recombinases. The author mentions one example of this, involving a bacterial Rec A enzyme that is associated in vitro with a mononstrand DNA sequence. Such a technique was able to induce a homologous recombination of the corresponding gene in mammalian cells and mouse embryos using microinjection, but she cautions that conformation of these experiments is yet to be performed. <br /> The author also includes a discussion of the use of the triple helix between RNA and DNA as a technique for animal transgenesis. Such a technique involves the targeted inhibition of a gene by the formation of the triple helix in pyrimidine-rich regions. The triple helix blocks transcription by RNA polymerase II and RNA synthesis can be directed by the transgene. The author reminds the reader though that such techniques have yet to be successful though in animal transgenesis. <br /> Another topic of current interest is that of RNA interference, and the author discusses it in the context of animal transgenesis. She discusses experiments in which (double-stranded) RNA interference can be implemented in cultured cells to inhibit gene expression. The author considers the possibility, yet to be explored, of the expression of transgenes coding for double-stranded RNA inhibiting gene expression in mammals. <br /> The author discusses many applications of animal transgenesis, including the study of human diseases, models for viral infections and prion diseases, Alzheimer's disease, xenografting, the production of pharmaceuticals, and improved animal production. As the techniques of animal transgenesis are improved, there will no doubt be many more beneficial applications. There will also be the delightful possibility of the creation of new types of animals with the sole purpose of making the natural world a much more diverse and interesting place to live.	2003-05-17
1123045:US	50702879	R2YTMSSL9FRN2Z	9812384332	850233583	SARS War	Books	2	5	5	N	N	Out of date and no scientific details	This book is short, sometimes repetitive, and already out-of-date, even considering the date of publication (April 2003). For someone who needs a quick non-technical summary of what is online and what has been reported in the international news, this book will suffice, although somewhat marginally. The authors of the various articles discuss various strategies for dealing with SARS, and there is a Q&A section at the end of the book.<br /> There are some omissions in the book, particularly in the area of hard science. For example, the complete genetic sequence of the SARS virus is now available, but this is not mentioned in the book. The sequence has also been BLASTed, but the results of the BLAST search are not discussed in the book either. In addition, there are some groups who have asked whether the SARS virus was the result of genetic engineering, and therefore it would have been informative if the book would have discussed these topics, to alleviate any concerns in this regard. If recombination played a role in the origin of the SARS virus, this would show up in its sequence. An attempt to create the SARS virus via recombination from different viruses would show up in the sequence, parts of which would appear different from a phylogenetic viewpoint. The SARS virus has been classified as a coronavirus, and these types of viruses have been subjected to genetic manipulation in the laboratory in the last fifteen years.<br /> These concerns and others in the molecular biology of SARS are being addressed daily in laboratories all over the world. This book is targeted to non-scientists and non-specialists and so is limited in scope. If updated to reflect these developments, it would be much more useful to those who need to understand the real dangers and limitations of the SARS outbreak.	2003-05-15
1124269:US	50702879	R1YFNBCYVKZ8JP	9971507315	150828638	Introduction to String Field Theory (Advanced Series in Mathematical Physics)	Books	3	7	8	N	N	Very dense but good for the time	The author introduces the subject of his book as &quot;the newest approach&quot; to string theory, which he defines in analogy to the point particle theory, as an approach to the calculation of relevant quantities using field theory Lagrangians, instead of &quot;off-shell&quot; S-matrix computations, and which is done in 10 dimensions. The first five chapters of the book is not concerned directly with strings at all, but with the quantization of gauge theories, both pure and with the presence of matter (fermions). The author considers first point particle fields in the light cone gauge. In this gauge the field theory appears nonrelativistic, satisfying a non-relativistic &quot;Schrodinger equation&quot; with an imaginary Hamiltonian. The author then discusses the Yang-Mills theory in the light cone gauge, and derives the free Lagrangian for this theory. This motivates a detailed discussion of the conformal algebra since (nonlinear) representations of the Poincare group model the kinetic term of a free light-cone field theory, and one can obtain these, as the author shows, using the conformal group. He later generalizes to the case where interactions are present, and derives the Feynman rules. The reader can readily see the tension between the demands for covariance and unitarity, that is characteristic of gauge theories. The light-cone gauge is manifestly covariant, but in two less dimensions than the dimension of spacetime the fields are formulated in. This is apparent in the use of the Poincare group ISO(D-1,1), the representations of which are constructed for arbitrary massless and massive theories. The representations are nonlinear in the coordinates, and are constructed from irreducible representations of the SO(D-2) rotation group of the SO(D-1,1) Lorentz group. The conformal group is then SO(D, 2).<br /> In these initial five chapters the reader also gets a detailed overview of the BRST formalism, which is very important in the quantization of gauge theories. This formalism is first introduced in the context of the Hamiltonian formalism, which is manifestly covariant in D - 1 dimensions. This involves as expected a separation of coordinates into space and time with the time components of the gauge fields set to zero. The famous Faddeev-Popov ghosts make their appearance here, since the quantization problem is a problem with constraints. The author gives several reasons for using the BRST formalism, and the reader sees the origin of the Slavnov-Identities, which are generalizations of the amazing Ward identities and are a consequence of the side constraint of unitarity.<br /> The actual consideration of strings first takes place in chapter 6. The large amount of work done by the author in the first five chapters to find a general Poincare- and gauge-invariant action for any collection of fields is finally applied in this chapter and the rest of the book. The idea of viewing strings as 2-dimensional field theories is the main point behind the author's approach. The author quantizes the bosonic string in the light-cone gauge and derives the Poincare algebra, which can be viewed as a specialization of what was done in the first two chapters. This is generalized immediately to the case to the fermionic case by introducing a  2D supersymmetry on the world sheet, in complete analogy with the point particle case in chapter five. In this discussion the reader can see clearly the origin of the requirement that D be equal to 10. A manifestly covariant formalism is then discussed, which is a generalization of the bosonic string and the superparticle of chapter 5. This discussion is interesting in that it shows the origin of the Kac-Moody algebra in the covariant derivatives, and the Virasoro algebra. The BRST formalism is discussed later in the context of the first-quantization of the bosonic string as a constrained problem in the conformal gauge. The Feynman rules for interacting strings are then derived using first the external field formalism, and then using functional integration.<br /> The author gets down to studying string field theory in the context of what was done early in chapter 2 in chapters 10 and 11, namely the light-cone gauge and the BRST formalism, with the goal to include the contributions of the string interactions. As expected, in the free field case the bosonic open strings satisfy a Schroedinger-like equation, and interactions are described by splitting and joining of strings, and as expected from a field-theoretic point of view, the graphs are composed of vertices and propagators. The BRST formalism is done only for the closed string case.The author introduces the reader to how to construct gauge-invariant actions for interacting strings in the last chapter of the book.  He is careful to note that a string field theory of interacting strings does not exist, and gives explanations to the difficulties involved in constructing such theories. I have not followed the research on this topic since this book was published, so cannot comment on the present state of atttempts to construct these theories, except for those attempts to give an interpretation of open and closed strings in terms of algebraic topology, C*-algebras, and K-theory. These however do not permit any kind of Feynman rules to be derived. No doubt a perusal of the preprint servers will reveal that this problem has been absorbed in the current emphasis on D-brane and M-theories.field formalism, and then using functional integration. <br /> The author gets down to studying string field theory in the context of what was done early in chapter 2 in chapters 10 and 11, namely the light-cone gauge and the BRST formalism, with the goal to include the contributions of the string interactions. As expected, in the free field case the bosonic open strings satisfy a Schroedinger-like equation, and interactions are described by splitting and joining of strings, and as expected from a field-theoretic point of view, the graphs are composed of vertices and propagators. The BRST formalism is done only for the closed string case.The author introduces the reader to how to construct gauge-invariant actions for interacting strings in the last chapter of the book.      He is careful to note that a string field theory of interacting strings does not exist, and gives explanations to the difficulties involved in constructing such theories. I have not followed the research on this topic since this book was published, so cannot comment on the present state of atttempts to construct these theories, except for those attempts to give an interpretation of open and closed strings in terms of algebraic topology, C*-algebras, and K-theory. These however do not permit any kind of Feynman rules to be derived. No doubt a perusal of the preprint servers will reveal that this problem has been absorbed in the current emphasis on D-brane and M-theories.	2003-05-14
1124453:US	50702879	R2UWJAQ2VIU2TT	0262530856	680637452	Neurophilosophy: Toward a Unified Science of the Mind-Brain	Books	5	26	29	N	Y	Out of date now...but motivates modern developments	Published over 17 years ago, this book was one of the first examples of the now accelerating trend to make philosophical investigations into the mind/brain problem accountable to modern science. Pure speculation once dominated any discussion of the mind (or the brain) and therefore progress in the field by any measure was non-existent. There are of course still purely philosophical investigations into the mind/body problem, but these will no doubt decay rapidly with time as scientific investigations continue to lay to rest various &quot;impossibility&quot; claims philosophers have made about the physical brain. Indeed, in this century, the rise of machine intelligence will hammer the last nail in the coffin of mind/brain philosophical speculation.<br /> The author of the book is a materialist, and in this book she has given an excellent justification of her position, and expresses at all times fairness to those who disagree with her positions and conclusions. She also expresses a rare intellectual honesty about the scientific evidence supporting her claims, informing the reader at every place in the book where it is not available or weak at best. Without a doubt the author was not happy at the state of philosophy at the time the book was published, holding that it completely omitted neuroscience, and embraced in her words &quot;a novel and sophisticated form of dualism&quot;. She explains this was ample reason for her to take the plunge into a more scientific/empirical framework. The book is an excellent example of what can result when a philosopher decides to do this.<br /> The book is divided up into three parts, with the first one emphasizing the biology of nervous systems and neuropsychology, the second part an overview of developments in the philosophy of science, and the third part discussing the ramifications of neurobiology for research in artificial intelligence. Although somewhat out of date due to the advancements in both experimental and theoretical neuroscience since then, it could still be of interest, mainly to philosophers, who are interested in applying their talent for logical thinking and organization to difficult problems in neuroscience. The transition from pure philosophical speculation to the rigors of scientific investigation may at first be difficult for the typical armchair philosopher, but their high degree of intelligence and their restless desire to get at the truth will soften it considerably. And in the decades ahead, one will witness the presence of &quot;industrial philosophers&quot;: those who have chosen to leave the &quot;proverbial armchair&quot; and apply their abilities to both understand and give rise to intelligent machines.euroscience since then, it could still be of interest, mainly to philosophers, who are interested in applying their talent for logical thinking and organization to difficult problems in neuroscience. The transition from pure philosophical speculation to the rigors of scientific investigation may at first be difficult for the typical armchair philosopher, but their high degree of intelligence and their restless desire to get at the truth will soften it considerably. And in the decades ahead, one will witness the presence of &quot;industrial philosophers&quot;: those who have chosen to leave the &quot;proverbial armchair&quot; and apply their abilities to both understand and give rise to intelligent machines.	2003-05-14
1124726:US	50702879	R3LII3EM92RIF6	026253200X	769157253	Brain-Wise: Studies in Neurophilosophy	Books	5	68	72	N	Y	An excellent update to her prior book	The mind/body problem, as understood by philosphers for the last few centuries, has been buried under a mountain of neuroscience. One can of course still tunnel into this mountain if desired and dig further in the mine of armchair argumentation and speculation. But more and more philosophers are abandoning this mine, and employing their unique talents and restless desire to get at the truth, to a view of the mind/brain that is more in tune with empirical research. It is perhaps difficult for the traditional philosopher to make this transition, for they feel perhaps that they are abandoning their commitment to the goals they have set. To these philosophers science is a derived field of knowledge, and has an underlying foundation given by philosophy. To turn against this view would be a sacrilege to many philosophers.<br /> The author of this book is one of the best examples of what can happen when a philosopher has made the decision to investigate what neuroscience has to offer for the understanding of the mind/brain. It is packed full of highly interesting insights from someone who has been deeply engaged in research in neuroscience and neurophilosophy. The advances in neuroscience in just the last few years have been breathtaking, particularly in experimental methods. Some of these developments are discussed in the book, along with good arguments that cast further doubts on the ability of philosophical speculation to produce a workable theory of the mind (brain).<br /> The need for such a theory of mind (brain) is argued especially well for in the first few chapters of the book. The author emphasizes that merely refuting various materialist views of the mind (brain) will not by itself lead to an understanding of it. The dualists and idealists must put forth a constructive theory of the mind that will assist not only in forming a theory of knowledge and thinking, but also with shedding light on the cause of Alzheimer's and other mental disorders. The author gives as an example of this the ideas of the neuroscientist John Eccles who held that the mind-brain interaction is mediated by a &quot;psychon&quot;, but the properties and dynamics of psychons were never elaborated on.<br /> The author bases the book on three hypotheses, namely that mental activity is brain activity and can be studied scientificially; that neuroscience is dependent on cognitive science in order to know what phenomena need to be explained; and that to understand the mind one must understand the brain at all levels of organization. The examples and argumentation/counterargumentation given througout the book bring out these hypotheses especially clearly, and the author expresses a rare intellectual honesty in all of the discussion. This is perhaps because she has chosen to assign weight to both the scientific and philosophical viewpoints, and such  a careful consideration will only raise the level of objectivity, and suppress the vitriole or subjective biases that sometimes accompanies discussion of the mind/body problem.<br /> One of the most interesting discussions in the book concerns the scientific study of consciousness, in particular the discussion on &quot;Crick's assumption&quot;: there must be brain differences when a stimulus is presented and the subject is aware of it, and a stimulus is presented and the subject is not aware of it. The author discusses a fascinating experiment, dealing with &quot;binocular rivalry&quot;, that allows an experimental study of Crick's assumption. This discussion, among many others in the book, are excellent examples of what is now available experimentally to help settle the mind/brain debate. In another example, the author points to the use of artificial neural networks with recurrent projection to model consciousness-related functions such as attention and sensory perception. She also discusses a clever experiment to test this idea, but cautions that even if back projections are necessary for consciousness, it is known that they are not sufficient. The author then draws up a list of possible experiments that might identify the neural correlates of consciousness, which, even if shown to be not viable, will assist in the fulfilling of the goal of viewing consciousness in terms of mechanisms. In addition, and to emphasize the necessity for a hierarchical &quot;systems level&quot; study of consciousness, rather than merely at the &quot;neuronal level&quot;, she discusses the very interesting work of Antonio Damasio on viewing the capacity of consciousness as the outcome of high-level self-representational capacities. His work, as discussed by the author, emphasizes the role of evolutionary pressures in shaping the nature of human consciousness. Further, the author addresses (nine) of the arguments against a scientific theory of consciousness in terms of brain function put forth by those who advocate dualism. She is not shy about saying that the dualist theories are beginning to appear as an &quot;outdated curiosity&quot;, but she analyzes these nine objections fairly and objectively, and she is clearly open to possible future arguments put together by dualists.<br /> The author also discusses some &quot;hardcore&quot; issues in philosophy, such as free will, epistemology, and religion. She addresses some possible reasons why nonempirical epistemology continues to be around, one of these being the rise of modern logic in the twentieth century. The other is the slow progress in the understanding of the human brain. Both of these reasons are interesting because of their importance for research in artificial intelligence. Both formal reasoning and an understanding of how the brain does pattern matching, generalizations, and induction is crucial to the efforts in machine intelligence. Fortunately, the author and others like her, with their formulation of ideas like the ones in this book, will be of enormous assistance to those involved in bringing about the rise of intelligent machines.is known that they are not sufficient. The author then draws up a list of possible experiments that might identify the neural correlates of consciousness, which, even if shown to be not viable, will assist in the fulfilling of the goal of viewing consciousness in terms of mechanisms. In addition, and to emphasize the necessity for a hierarchical &quot;systems level&quot; study of consciousness, rather than merely at the &quot;neuronal level&quot;, she discusses the very interesting work of Antonio Damasio on viewing the capacity of consciousness as the outcome of high-level self-representational capacities. His work, as discussed by the author, emphasizes the role of evolutionary pressures in shaping the nature of human consciousness. Further, the author addresses (nine) of the arguments against a scientific theory of consciousness in terms of brain function put forth by those who advocate dualism. She is not shy about saying that the dualist theories are beginning to appear as an &quot;outdated curiosity&quot;, but she analyzes these nine objections fairly and objectively, and she is clearly open to possible future arguments put together by dualists. <br /> The author also discusses some &quot;hardcore&quot; issues in philosophy, such as free will, epistemology, and religion. She addresses some possible reasons why nonempirical epistemology continues to be around, one of these being the rise of modern logic in the twentieth century. The other is the slow progress in the understanding of the human brain. Both of these reasons are interesting because of their importance for research in artificial intelligence. Both formal reasoning and an understanding of how the brain does pattern matching, generalizations, and induction is crucial to the efforts in machine intelligence. Fortunately, the author and others like her, with their formulation of ideas like the ones in this book, will be of enormous assistance to those involved in bringing about the rise of intelligent machines.	2003-05-14
1129701:US	50702879	R12QVZ8VEPHA52	9971508281	104371115	Braid Group, Knot Theory and Statistical Mechanics (Advanced Series in Mathematical Physics)	Books	4	3	3	N	N	A good introduction to the early work	The finding of invariants for knots has been a major unsolved problem in mathematics for over 125 years. The difficulty of the problem is attested to by the paucity of results over decades of time in the early 20th century. Then in the 1980's Vaughn Jones discovered some invariants that are related to ideas in physics, namely the theory of integrable models in statistical mechanics. This book is a collection of articles discussing the Jones work and other approaches that relate knot theory and statistical mechanics, written a few years after his discovery. My review will be confined to the articles which I read in detail.<br /> An article by Vaughn Jones begins the book and discusses the connection between subfactors of von Neumann algebras and statistical mechanics. These von Neumann algebras occur as algebras of transfer matrices in statistical mechanics. These transfer matrices satisfy algebraic relations that are essentially the same as those appearing in special types of von Neumann algebras. The author makes it a point to discuss in detail the relevant constructions of von Neumann algebras, believing this has not been done in the literature. The von Neumann algebras related to the transfer matrices are particular types of II(1) and III factors, which the author constructs using Bratteli diagrams and the Gelfand-Naimark-Segal construction.<br /> The article by Louis Kauffman discusses polynomial invariants of knots and the Yang-Baxter factorization equation. Polynomial invariants based on the Yang-Baxter equations are one-variable polynomials. The author points out that it is unknown whether two-variable invariants can be extracted from the Yang-Baxter equations, but points out how to construct these using skein models.<br /> The article by Michio Jimbo is an introduction to the Yang-Baxter equation with emphasis on the role of quantum groups. The solutions of the Yang-Baxter equation are discussed in the light of the work of A. Belavin and V.G. Drinfeld in the context of simple Lie algebras. The author shows in this case that the solutions are either elliptic, trigonometric, or rational functions. This is followed by a discussion of how to &quot;quantize&quot; this situation, which leads to the theory of quantum groups, a field that has grown considerably since this article was written. The author discusses a particular example of a quantum group, called the universal enveloping algebra, and studies its representations and the Drinfeld universal R matrix. The &quot;classical&quot; Yang-Baxter r-matrix is then the classical limit of this R-matrix. The author shows how to obtain higher representations by using an analog of the technique of constructing irreducible representations of Lie algebras by forming tensor products of fundamental representations and decomposing them. This technique is known as the fusion procedure here and elsewhere in the literature.<br /> The article by Toshitake Kohno is a review article on representations of the braid group with respect to the Yang-Baxter equation for face models in statistical mechanics. The representations of the braid group appear explicitly as the monodromy of integrable connections defined for any simple Lie algebra and its irreducible representation. Interestingly, the connections describe n-point functions in a conformal field theory on the Riemann sphere with gauge symmetry. The author begins with a finite-dimensional complex simple Lie algebra and its irreducible representation. Selecting an orthonormal basis of this Lie algebra with respect to the Cartan-Killing form, the author constructs certain matrices in the endomorphisms of the n-fold tensor product of the representation. These matrices satisfy certain relations that are a special case of the Yang-Baxter equation. A connection defined using these matrices and a complex parameter ranging over a set consisting complex n-vectors with unequal coordinates is shown to be integrable using these relations. The fundamental group of the complex parameter set is the 'pure braid group with n strings' and the (quadratic) relations are viewed as an infinitesimal version of the defining relations of the pure braid group. By taking the quotient of the parameter set with the symmetric group one obtains the braid group, the representations of which are consequently obtained using the monodromy of this connection. Another representation is derived from the quantized universal enveloping algebra of the Lie algebra.<br /> By far the most interesting article, and the one least rigorous mathematically, is the one by Edward Witten on quantum field theory and the Jones polynomial. The author shows that a Yang-Mills theory in 2 + 1 dimensions consisting of merely the Chern-Simons terms is exactly soluble and can be used to give the Jones polynomial a three-dimensional interpretation, which was highly desired at the time of writing. He also shows that the Jones polynomial can be generalized from the 3-sphere to arbitrary 3-manifolds, and gives invariants for these manifolds, which can be computed from a surgery presentation. The author's constructions are fascinating, particularly from a physics standpoint, but mathematically they are very suspect, since they are dependent on the notion of a path integral. The latter, despite decades of concentrated effort, has defied a mathematically rigorous formulation. The results in the article have thus been classified as &quot;physical mathematics&quot;, and therefore conjectural and tentative from a purely mathematical standpoint. This is a fair classification, and it motivated other mathematicians to find alternative formulations that are well-defined mathematically. Indeed, this article has resulted in an explosion of research on both knot invariants and invariants for 3-manifolds, some of which has remain tied to quantum field theory, and some making a concentrated effort to remove these invariants from their dependence on it.ntal group of the complex parameter set is the 'pure braid group with n strings' and the (quadratic) relations are viewed as an infinitesimal version of the defining relations of the pure braid group. By taking the quotient of the parameter set with the symmetric group one obtains the braid group, the representations of which are consequently obtained using the monodromy of this connection. Another representation is derived from the quantized universal enveloping algebra of the Lie algebra.  <br /> By far the most interesting article, and the one least rigorous mathematically, is the one by Edward Witten on quantum field theory and the Jones polynomial. The author shows that a Yang-Mills theory in 2 + 1 dimensions consisting of merely the Chern-Simons terms is exactly soluble and can be used to give the Jones polynomial a three-dimensional interpretation, which was highly desired at the time of writing. He also shows that the Jones polynomial can be generalized from the 3-sphere to arbitrary 3-manifolds, and gives invariants for these manifolds, which can be computed from a surgery presentation. The author's constructions are fascinating, particularly from a physics standpoint, but mathematically they are very suspect, since they are dependent on the notion of a path integral. The latter, despite decades of concentrated effort, has defied a mathematically rigorous formulation. The results in the article have thus been classified as &quot;physical mathematics&quot;, and therefore conjectural and tentative from a purely mathematical standpoint. This is a fair classification, and it motivated other mathematicians to find alternative formulations that are well-defined mathematically. Indeed, this article has resulted in an explosion of research on both knot invariants and invariants for 3-manifolds, some of which has remain tied to quantum field theory, and some making a concentrated effort to remove these invariants from their dependence on it.	2003-05-09
1135643:US	50702879	RTNCRPWDXHXCT	9810201621	121440174	New Developments in the Theory of Knots (Advanced Series in Mathematical Physics)	Books	4	3	4	N	N	A good reference	This book is a collection of articles that are representative of the many exciting developments in knot theory that were occurring at the time of publication. Many of these developments have been extended and generalized since then, such as the theory of Vassiliev invariants, and thus the articles could be viewed as an introduction to this research. Hence it could still serve as a reference to the mathematical theory of knots and it relation to physics, via statistical mechanics and quantum field theory. I did not read all of the articles, so only a few of the ones I did will be reviewed here.<br /> The article by Vaughan Jones on polynomial invariants for knots via von Neumann algebras begins the collection and was definitely the tone-setting one of the time, due to the new invariants of knots discovered by Jones. The article discusses how to construct a polynomial invariant for tame oriented links using certain representations of the braid group. By using Markov's theorem and a trace on a type II(1) von Neumann algebra, the author shows that the invariant depends only on the closed braid. The von Neumann algebra is generated by an identity and a collection of projections, which satisfy certain types of relations. These relations involve a complex parameter, and when this parameter satisfies certain conditions there exists a trace on the von Neumann algebra which in turn satisfy a collection of relations. The relations on the projections and the trace determine the structure of the von Neumann algebra up to *-isomorphism. That the projection relations are similar to Artin's presentation of the braid group was what Jones and others to develop invariants of links and knots based on this trace. In another article Jones then obtains a polynomial invariant in two variables for oriented links that uses a trace on Hecke algebras &quot;of type A&quot;, which was inspired by the connections with von Neumann algebras. His discussion in this article points out the need for a better understanding of the topological interpretation of these invariants. Pointing out that a more in-depth understanding of subfactors of finite index would assist in this topological interpretation, in a later article Jones outlines in more detail what is known for subfactors of finite index. The index, as defined by Jones, measures the size of a subfactor in a II(1) factor. In addition, Hans Wenzl discusses Hecke algebras of type A and subfactors, and shows how to compute the Jones index using AF algebras.<br /> The most provocative article in the book, and one not rigorous from a mathematical standpoint, is the article by Edward Witten on the quantum field theory and the Jones polynomial. The connection between these two seemingly disparate fields caused great excitiment in both the physics and mathematics communities, in spite of the fact that these results are unjustified mathematically, due to their reliance on path integrals. Witten was motivated in this article to find a three-dimensional interpretation of the Jones polynomial, which he does so via Yang-Mills theory in three dimensions. However, the Yang-Mills theory which he uses is not the standard one, but instead is based on the purely topological Chern-Simons theory. Witten considers the quantum field theory defined by the Chern-Simons theory and uses its gauge fields to define gauge-invariant observables. Because of the side-constraint of general covariance, these observables are chosen to be Wilson lines, which are independent of the metric. In an oriented three manifold Witten then considers oriented and non-intersecting knots and assigns a representation to each knots. Using the Chern-Simons three form Witten computes the path integral of the Wilson  observables, and then proposes that these quantities are 3-dimensional interpretations of the Jones invariant. Witten first proves that the Chern-Simon form gives a meaningful quantum theory, i.e. that it is free from anomalies, and he justifies thisby reducing the Chern-Simons invariant to a ratio of determinants, and then showing the absolute value of this ratio is the Ray-Singer analytic torsion. Witten then considers the calculation of the phase of the ratio, and then via the canonical quantization of the theory, shows how to obtain the desired knot invariants.s by reducing the Chern-Simons invariant to a ratio of determinants, and then showing the absolute value of this ratio is the Ray-Singer analytic torsion. Witten then considers the calculation of the phase of the ratio, and then via the canonical quantization of the theory, shows how to obtain the desired knot invariants.	2003-05-04
1136026:US	50702879	R1TA9AZU25INN3	9971502739	313748861	Mathematical Aspects of String Theory (Advanced Series in Mathematical Physics)	Books	4	1	1	N	N	Still worth perusing	Although the mathematical constructions used in string theory have changed considerably since this book was published in 1988, it could still serve as an introduction to some of the mathematics of string theory, although the subject currently is dominated by M-theory. In this volume, composed of papers presented at a conference in the summer of 1986, one can see origins of the interplay between the theory of partial differential equations, non-Abelian gauge theories, fiber bundles, algebraic geometry, number theory, representation theory, operator theory, and supersymmetry. All of these developmemts, both in this volume and in current research, involve some of the most fascinating constructions in all of mathematics, and future historians of physics and mathematics will no doubt view this period as one which marked the beginning of an era where pure mathematics dominated the field of elementary particle physics.<br /> Physicists deciding to specialize in string/M-theory will face a mountain of mathematics that must be mastered before entering the frontiers  of the subject. Textbooks and monographs on the mathematics though are typically written from a formal point of view, and therefore to get more an understanding of the intuition behind this mathematics, it is important to get involved in the &quot;oral tradition&quot;, and attend conferences like the one represented in this book. The questions asked and the motivations presented by the speakers will allow greater insight into the ideas behind these esoteric constructions, and which do not usually find their way in the printed summaries. This book does include a few informal presentations that are helpful, and that therefore give the reader the much-needed motivation.<br /> For the beginning string/M-theorist, the article by Polchinski on relating the Polyakov functional integral to an integral over moduli space of Riemann surfaces would be one of these, as would the article by D'Hoker and Phong on the geometry of quantized string theory. Polchinksi's article is mathematically non-rigorous but helpful from a physics vantage point. The roles of the Fadeev-Popov procedure, zero modes, and the determinants of differential operators in calculating the path integral are made very clear. The D'Hoker/Phong article is very illuminating in that it gives more details on what Polchinski did, and extends it to higher loop amplitudes.<br /> Mathematicians might be interested in the article by Gerd Faltings on arithmetic intersections for surfaces.The article is very short however, quickly overviewing what is being done in Arakelov theory, and because of its level not really suitable for beginners. His goal is to prove a Riemann-Roch theorem for arithmetic surfaces, but of course does not do so in this article because of its length. The article on SU(3) holonomy by Edward Witten might also be of interest, if taken in context of modern developments.quantized string theory. Polchinksi's article is mathematically non-rigorous but helpful from a physics vantage point. The roles of the Fadeev-Popov procedure, zero modes, and the determinants of differential operators in calculating the path integral are made very clear. The D'Hoker/Phong article is very illuminating in that it gives more details on what Polchinski did, and extends it to higher loop amplitudes. <br /> Mathematicians might be interested in the article by Gerd Faltings on arithmetic intersections for surfaces.The article is very short however, quickly overviewing what is being done in Arakelov theory, and because of its level not really suitable for beginners. His goal is to prove a Riemann-Roch theorem for arithmetic surfaces, but of course does not do so in this article because of its length. The article on SU(3) holonomy by Edward Witten might also be of interest, if taken in context of modern developments.	2003-05-04
1146054:US	50702879	R21EEYFS4G7XC7	157870233X	719569880	Internet Routing Architectures (2nd Edition)	Books	4	3	4	N	N	Good overview (1st edition)	After a brief review of the history and evolution of the Internet, the author motivates the rest of the book by giving a set of questions to be asked by an organization who intends to connect to the Internet. Since at this time all businesses it seems want to do this, the answering of these questions will give them more helpful information on just what must be considered when choosing an ISP. The details of the routing architecture are of course the main emphasis in the book.<br /> Some of the more important topics addressed in the book are: 1. IP subnetting and variable-length subnet masks and why they are useful. 2. The different strategies used to handle IP address space depletion, such as creative IP address allocation, classless interdomain routing (CIDR), private IP addressing, and the new IP version 6. In the discussion on CIDR, the author asserts the advantages of using aggregation, in that an Internet Service Provider can advertise one IP network rather than several individual advertisements. This, he says, results in more efficient routing strategies and propgation along with making the route advertisements more stable. The degree of the resulting efficiency is not really quantified by the author however. It would have been interesting to have real-life examples of the resulting gains, or examples taken from simulation modeling. Although such data might seem unnecessary now, since CIDR was proposed as a fix to the depletion problem, it would still be interesting to be able to understand in more detail the advantages of employing CIDR, and with comparing it the planned deployment of IPv6. 3. The discussion of distance vector routing and link-state routing and the advantages and disadvantages between the two. The reader interested in a more rigorous and quantitative comparision between the two routing protocols will not find it here, but such a comparison can be done via simulation modeling. 4. The representation of the BGP neighbor negotiation via a finite state machine. 5. The discussion of the TCP MD5 Signature Option, and its role in protecting BGP from spoofed TCP segments and TCP resets. 6. The building of peer sessions using BGP and how to implement it &quot;internally&quot; in an 'autonomous system.' Peer connections between routers in different autonomous systems are then &quot;external&quot; implementations of BGP. The autonomous systems as explained by the author can be used for example by two users who desire to have a link between them in case of a failure of their ISP. 7. The discussion on route instability and how to control it using aggregation, route dampening, and static route injection. The author spends an entire chapter in fact on the design of stable internets, although the discussion is brief and purely descriptive. The route dampening mechanism is discussed as a tool for controlling route instability. This involves a strategy for penalizing unstable routes and is implemented on CISCO routers (the author gives the commands for doing so explicitly). Although the author does not discuss any, modeling and empirical studies have indicated that a cavalier use of route dampening can be deleterious to a network. For example, it was shown early on in the use of BGP that a single route withdrawal may cause other routers to explore a sequence of alternative paths before deciding that the destination is unreachable. Some researchers have shown that this in turn causes &quot;secondary flaps&quot; which can suppress the threshold of the route flap damping algorithm, and resulting in delayed convergence of the route.state machine. 5. The discussion of the TCP MD5 Signature Option, and its role in protecting BGP from spoofed TCP segments and TCP resets. 6. The building of peer sessions using BGP and how to implement it &quot;internally&quot; in an 'autonomous system.' Peer connections between routers in different autonomous systems are then &quot;external&quot; implementations of BGP. The autonomous systems as explained by the author can be used for example by two users who desire to have a link between them in case of a failure of their ISP. 7. The discussion on route instability and how to control it using aggregation, route dampening, and static route injection. The author spends an entire chapter in fact on the design of stable internets, although the discussion is brief and purely descriptive. The route dampening mechanism is discussed as a tool for controlling route instability. This involves a strategy for penalizing unstable routes and is implemented on CISCO routers (the author gives the commands for doing so explicitly). Although the author does not discuss any, modeling and empirical studies have indicated that a cavalier use of route dampening can be deleterious to a network. For example, it was shown early on in the use of BGP that a single route withdrawal may cause other routers to explore a sequence of alternative paths before deciding that the destination is unreachable. Some researchers have shown that this in turn causes &quot;secondary flaps&quot; which can suppress the threshold of the route flap damping algorithm, and resulting in delayed convergence of the route.	2003-04-25
1151189:US	50702879	R34893P5CGNFE4	0465017290	637919837	The Millennium Problems 1	Books	4	59	66	N	Y	An honest attempt to explain deep mathematics	In this book the author makes a sincere attempt to describe to a popular audience the content behind seven mathematical problems that were chosen by a private foundation called \\"The Clay Institute\\" as being deep enough to warrant a prize of $1,000,000 for their solution. The goal is realized in some parts of the book, but falls short in others, but it still is of value to those who are curious about the history and content behind these problems. The author is aware of the difficulty in describing the content of the problems to readers without substantial mathematical preparation, and he does a good job in general.<br /> One can of course think of many other problems that fit the stature of the millennium problems, such as the invariant subspace conjecture, or developing a complete mathematical model of the cell, but these seven will no doubt spark the curiosity of a few young persons as they further their studies in mathematics. Some of the millennium problems, such as the Riemann hypothesis, the NP problem, the Poincare conjecture, and the Navier-Stokes equations, require only an undergraduate education. The others definitely require more background, just to understand even the statement of the problem. All of the them are fascinating, and will no doubt stimulate some incredibly interesting mathematical constructions.<br /> Personal note for anyone interested (from someone who has worked on one of these problems for several years): For those readers who are thinking about attacking one of these problems, it is important to be really interested in solving it, for your own satisfaction, and not to be concerned about the financial reward or what the solution will bring you in terms of professional advancement. Large blocks of time will be needed to think about the problem, and therefore you will have to be concerned with your livelihood in the interim. Being a single person will definitely relieve you of the financial burden of having to support a family, but on the other hand a family will bring you personal warmth as you take the roller coaster ride of confidence and depression that goes with this kind of research. A traditional tenure-track position might be difficult to justify, since you will not be publishing and therefore your chances of obtaining tenure will be greatly diminished. It might also be wise in whatever job you work in to keep your ambitions to yourself, as colleagues and other mathematicians will typically not be encouraging in your decision to work on the problem. Therefore, you will definitely find yourself working on two problems in your life: the millennium problem and  a  constrained optimization problem, the latter being how to live your life in the interim, and whose solution possibly ranks in similar complexity. Your research in the millennium problem will probably take years, and as you see more lines appear on your face and your colleagues take the normal professional route, you might have doubts about your decisions. The more time spent on it without resolution of course will close the doors on a standard career in academia, and you will approach a critical point where there is no turning back. It is at this time that you will realize that it is you that has taken charge of yourself, your goals, and your attitudes about mathematics and life...and this of course is the best possible life anyone can have.e other hand a family will bring you personal warmth as you take the roller coaster ride of confidence and depression that goes with this kind of research. A traditional tenure-track position might be difficult to justify, since you will not be publishing and therefore your chances of obtaining tenure will be greatly diminished. It might also be wise in whatever job you work in to keep your ambitions to yourself, as colleagues and other mathematicians will typically not be encouraging in your decision to work on the problem. Therefore, you will definitely find yourself working on two problems in your life: the millennium problem and  a  constrained optimization problem, the latter being how to live your life in the interim, and whose solution possibly ranks in similar complexity. Your research in the millennium problem will probably take years, and as you see more lines appear on your face and your colleagues take the normal professional route, you might have doubts about your decisions. The more time spent on it without resolution of course will close the doors on a standard career in academia, and you will approach a critical point where there is no turning back. It is at this time that you will realize that it is you that has taken charge of yourself, your goals, and your attitudes about mathematics and life...and this of course is the best possible life anyone can have.	2003-04-21
1152855:US	50702879	R2O99Q5TP269WO	0691090890	140662391	Representation Theory of Semisimple Groups: An Overview Based on Examples. (PMS-36).	Books	5	14	14	N	N	Very detailed with lots of motivating examples	The theory of representations of semisimple Lie groups is very complete from a mathematical perspective and is of enormous importance in high energy physics. This book gives a comprehensive overview of this theory, and deals with both the noncompact and compact cases. My interest was with the noncompact case and in topics such as the Langland's classification, and so I read only chapters 5 - 10. Therefore my review will be confined to these chapters. Throughout the book, G denotes the group in question and K denotes the elements of G fixed under the Cartan involution. The author endeavors, and this is reflected in the title of the book, to employ many examples to illustrate the main results. This makes the book considerably more easy to follow than others that are written in the &quot;Bourbaki&quot; style.<br /> The Iwasawa and Bruhat decompositions and the Weyl group construction are shown to hold for non-compact groups in chapter 5.  The Borel-Weil theorem is proven for compact connected Lie groups using the results of the chapter. The Harish-Chandra decomposition fo linear connected reductive groups is proven in chapter 6. The author shows clearly the role of holomorphic representations in obtaining this result and the construction of holomorphic discrete series. The principal series representations of SL(2, R) and SL(2, C) are use to motivate the notion of an 'induced representation&quot; in chapter 7. The theory of induced representations involves the Bruhat theory and its use of distribution theory, and relates via the 'intertwining operators', irreducible representations of two subgroups.<br /> The author discusses the notion of an admissible representation in chapter 8, which are representations on a Hilbert space by unitary operators and each element in K has finite multiplicity when the representation is restricted to K. Equivalence of admissible representations are discussed via the concept of an &quot;infinitesimal equivalance&quot;, which is the usual notion if the representation is unitary and irreducible. The Langlands classification of irreducible admissible representations is discussed in detail. The Langlands program shows to what extent irreducible admissible representations of a group are determined by the parabolic subgroups. The construction of discrete series, used throughout the proof of the Langlands classification, is then done in detail in the next chapter. Ths concept of an admissible infinitesimally unitary representation plays particular importance here. Here the representation operators act like skew-Hermitian operators with respect to an inner product on the space of K-finite vectors. If one reads this chapter from a physics perspective, the representations constructed using discrete series are somewhat 'exotic' and will probably not enter into applications, in spite of the fact that physical considerations do dictate sometimes the use of noncompact groups.<br /> Chapter 10 addresses the question as to the completeness of irreducible admissible representations using discrete series. If there not enough discrete series representations this will show up in the Fourier analysis of square integrable functions on the group. In the compact case, Fourier analysis proceeded via the characters of irreducible representations. The author shows how to do this in the noncompact case via  'global characters' of representations, which are well-behaved generalizations of the compact case. The well-behavedness of global characters comes from their being of trace class, with the result of the trace being a distribution. The author gives explicit formulas for the case of SL(2, R), and shows hows differential equations can be used to limit the possibilities for how characters behave. In fact, the author shows to what extent characters are functions, proving that the restriction of any irreducible global character of G to the 'regular set' is a real analytic function.notion if the representation is unitary and irreducible. The Langlands classification of irreducible admissible representations is discussed in detail. The Langlands program shows to what extent irreducible admissible representations of a group are determined by the parabolic subgroups. The construction of discrete series, used throughout the proof of the Langlands classification, is then done in detail in the next chapter. Ths concept of an admissible infinitesimally unitary representation plays particular importance here. Here the representation operators act like skew-Hermitian operators with respect to an inner product on the space of K-finite vectors. If one reads this chapter from a physics perspective, the representations constructed using discrete series are somewhat 'exotic' and will probably not enter into applications, in spite of the fact that physical considerations do dictate sometimes the use of noncompact groups. <br /> Chapter 10 addresses the question as to the completeness of irreducible admissible representations using discrete series. If there not enough discrete series representations this will show up in the Fourier analysis of square integrable functions on the group. In the compact case, Fourier analysis proceeded via the characters of irreducible representations. The author shows how to do this in the noncompact case via  'global characters' of representations, which are well-behaved generalizations of the compact case. The well-behavedness of global characters comes from their being of trace class, with the result of the trace being a distribution. The author gives explicit formulas for the case of SL(2, R), and shows hows differential equations can be used to limit the possibilities for how characters behave. In fact, the author shows to what extent characters are functions, proving that the restriction of any irreducible global character of G to the 'regular set' is a real analytic function.	2003-04-19
1155113:US	50702879	R2SOY3XKPU50QQ	0471959960	971062674	Logic, Programming and Prolog	Books	4	11	11	N	N	A good overview with many applications discussed	In this book the authors attempt to give a background into the foundations of logic programming and to develop programming expertise in the programming language Prolog. They do a good job, and considering the importance of logic programming in both research and industry, a perusal of this book will give the reader a good background to enter fields such as constraint logic programming or artificial intelligence.<br /> Chapter 1 is an introduction to what logic programming is all about, with its declarative nature emphasized right away. The syntax of predicate logic is introduced as a formalization of a collection of declarative statements of natural language. The semantics of the formulas in predicate logic is discussed in terms of a relation between its language and a particular (algebraic) structure. The meaning of terms including both constants and variables is done using a 'valuation'. Some elementay model theory is developed here also.<br /> In chapter 2, the authors take up logic programming by introducing the notion of 'definite clauses'. A 'definite program' is then a finite set of definite clauses. Logic programming is explained as writing down a collection of logic formulas, with the programmer attempting to describe an intended model via the use of definite clauses, or &quot;facts&quot; and &quot;rules&quot;. The program can have many models, with a program being &quot;incorrect&quot; if and only if the intended model is not a model of the program. The authors show clearly the role of queries in establishing the truth of the intended model.They also show the existence of a model that reflects all of the information expressed in model but not any more, the famous 'Herbrand model'.<br /> Logic programs are essentially reasoning systems, and so a notion of proof is needed. This is done in chapter 3, which discusses inference rules in the guise of &quot;SLD-resolution&quot;, which is a model-theoretic notion of proof. The soundness and completeness of SLD-resolution is proven in detail. Readers familiar with resolution from earlier courses in logic will appreciate the discussion of 'proof trees&quot; in this chapter.<br /> Chapter 4 takes up the very controversial notion of negation in logic programming, and its connection with the 'closed world assumption', the latter of which allows one to derive negative conclusions based on the absence of positive information. The authors discuss various approaches to the justification of negative conclusions from general programs, and they explain the role of 'program completion&quot; in capturing the notion of negation as finite failure.<br /> Those readers who already have exposure will appreciate more the discussion in chapter 5, which deals with the 'cut' pruning strategy for traversing of SLD-trees, along with 'built-in arithmetic'. The effects of the cut operation are explained in detail, including its ability to destroy completeness of definite programs and soundness of general programs, and if negation is involved, give incorrect answers. The authors also show how the cut operation may be used to implement negation in Prolog. The discussion on built-in arithmetic in Prolog alleviates any concerns that one is departing from the declarative paradigm by its incorporation. Since only relations can be expressed in logic programs, readers need to know how to express arithmetic operations in such programs.<br /> Chapter 6 is more practical, as it discusses the connection between logic programs and relational databases. The authors show how logic can both 'explicit' and 'implicit' data, the latter corresponding to 'views' in relational database theory. The authors show in detail how logic programs can implement the operations of 'relational algebra', and how they can be used as query languages. They also show how to construct compound terms in order represent more complicated constructions, like families and their members.<br /> In chapter 7, the authors introduce tools for dealingwith data objects that are variable in size or possibly infinite. These objects can be represented by 'recursive data structures' and which can contain (via recursion) subclasses of the same type. Readers familiar with the programming language LISP will appreciate the discussion, since the 'list' data structure is used throughout the chapter.<br /> Chapter 8 is more esoteric, as it shows how to use logic programs as a &quot;metalanguage&quot; to describe logic programming, with emphasis on constructing 'interpreters', the latter being used to describe the operational semantics of a programming language. The authors show how to construct interpreters for Prolog without built-in predicates, these being called 'self-interpreters'. The discuss in detail the advantages of using self-interpreters. They discuss also however the built-in predicates in Prolog, and their advantages in metaprogramming.<br /> The use of logic programming to build expert systems is discussed in chapter 9. The knowledge base of an expert system is a collection of definite or general clauses, but this base is usually incomplete in a logic program. This knowledge is added while using the program. The authors show how to construct an inference tool for the expert system based on the notion of a self-interpreter.<br /> The connection of logic with computational linguistics and formal language theory is the topic of chapter 10. Parsers for context-free and context-dependent languages are constructed. Prolog programs are interpreted as 'definite clause grammars' in this chapter also.<br /> Chapter 11 addresses algorithms for searching state spaces, with the famous &quot;water-jug&quot; and &quot;blocks world&quot; problems are discussed as examples.<br /> The remaining chapters of the book discusses alternative approaches to logic programming, such as using parallelism to solve subgoals simultaneously and its connection with &quot;concurrent logic programming&quot;. Also discussed is how to associate functions with functors, in order to incorporate a notion of equality into logic programming. The most important discussion is chapter 14, which treats constraint logic programming. This area has become extremely important in business and industry and several multi-million dollar companies have appeared in the last decade that specialize in constraint logic programming packages. The authors describe in detail how to give declarative meaning to constraint logic programming languages.aling with data objects that are variable in size or possibly infinite. These objects can be represented by 'recursive data structures' and which can contain (via recursion) subclasses of the same type. Readers familiar with the programming language LISP will appreciate the discussion, since the 'list' data structure is used throughout the chapter. <br /> Chapter 8 is more esoteric, as it shows how to use logic programs as a &quot;metalanguage&quot; to describe logic programming, with emphasis on constructing 'interpreters', the latter being used to describe the operational semantics of a programming language. The authors show how to construct interpreters for Prolog without built-in predicates, these being called 'self-interpreters'. The discuss in detail the advantages of using self-interpreters. They discuss also however the built-in predicates in Prolog, and their advantages in metaprogramming. <br /> The use of logic programming to build expert systems is discussed in chapter 9. The knowledge base of an expert system is a collection of definite or general clauses, but this base is usually incomplete in a logic program. This knowledge is added while using the program. The authors show how to construct an inference tool for the expert system based on the notion of a self-interpreter. <br /> The connection of logic with computational linguistics and formal language theory is the topic of chapter 10. Parsers for context-free and context-dependent languages are constructed. Prolog programs are interpreted as 'definite clause grammars' in this chapter also. <br /> Chapter 11 addresses algorithms for searching state spaces, with the famous &quot;water-jug&quot; and &quot;blocks world&quot; problems are discussed as examples. <br /> The remaining chapters of the book discusses alternative approaches to logic programming, such as using parallelism to solve subgoals simultaneously and its connection with &quot;concurrent logic programming&quot;. Also discussed is how toassociate functions with functors, in order to incorporate a notion of equality into logic programming. The most important discussion is chapter 14, which treats constraint logic programming. This area has become extremely important in business and industry and several multi-million dollar companies have appeared in the last decade that specialize in constraint logic programming packages. The authors describe in detail how to give declarative meaning to constraint logic programming languages.	2003-04-17
1157573:US	50702879	R10B869UVJMFMI	0380792435	494035180	Remaking Eden	Books	5	14	15	N	Y	Brilliant in every way	With the announcement today of the completion of mapping of the human genome, this book takes on particular importance. The book was published in 1997, and as further evidence of the technological hyperdrive of the 21st century and the incredible advances in sequencing technology since 1997, the author predicts on page 244 that the Human Genome Project would take 23 more years, and be completed by 2020!<br /> The book is excellent, for the author gives brilliant arguments both supporting genetic technologies and countering many that don't. In addition, the author discusses possibilities in reproductive technologies that may be unknown to a reader, like myself, who is not an expert in embryology. For example, he discusses the occurrence (although rare) of natural-born chimeric human beings, who arose from the fusion of two embryos that resulted from the fertilization of two eggs that had been ovulated simultaneously by their mother. Another example discussed is the possibility of a fertilized egg winding up in the peritoneal cavity (in the abdomen essentially). This example was discussed in the context of whether indeed a man could carry a pregnancy.<br /> Some of the other interesting arguments and discussions in the book include: 1. When addressing the assertion that it is unfair for only the wealthy to take advantage of genetic technologies for enhancing their progeny, the author agrees that it is, but he then states correctly that a society that accepts the right of wealthy parents to provide their children with a top-notch private education cannot use \\"unfairness\\" as a reason for denying the use of genetic technologies. 2. His discussion of the status of the embryo as human life, which he argues, brilliantly, is not. \\"If a human life can begin in the absence of conception\\" he says, \\"then it is scientifically invalid to say that conception must mark the beginning of each human life. It is as simple as that\\". 3. The discussion of the history  of in vitro fertilization, the ethical issues surrounding it, and the technologies needed to bring it about. The author regards IVF as a pivotal point in history, in which humans took charge of their reproductive destiny. 4. The discussion of cloning, elaborating naturally on the cloning of Dolly the sheep. He states that the cloning of Dolly \\"broke the technological barrier\\" and that there is \\"no reason to expect that the technology couldn't be transferred to human cells.\\" Recent experiments in the last few months however have cast doubt on the ability to do cloning of primates, and so human cloning could therefore be problematic. The author though counters very successfully the arguments against the practice of human cloning.<br /> The author has a refreshing optimism throughout the book, and he remains confident in the human ability to both understand the world and change it with proven and safe technologies. In light of the completion of the mapping of the human genome, his optimism is certainly justified. The technologies discussed in this book, coupled with the information obtained from the complete human genome, promise an incredibly interesting future for biology. Both the author and the individuals behind the human genome project are excellent examples of the ingenuity and mental discipline of the human species.ation, the ethical issues surrounding it, and the technologies needed to bring it about. The author regards IVF as a pivotal point in history, in which humans took charge of their reproductive destiny. 4. The discussion of cloning, elaborating naturally on the cloning of Dolly the sheep. He states that the cloning of Dolly \\"broke the technological barrier\\" and that there is \\"no reason to expect that the technology couldn't be transferred to human cells.\\" Recent experiments in the last few months however have cast doubt on the ability to do cloning of primates, and so human cloning could therefore be problematic. The author though counters very successfully the arguments against the practice of human cloning.   <br /> The author has a refreshing optimism throughout the book, and he remains confident in the human ability to both understand the world and change it with proven and safe technologies. In light of the completion of the mapping of the human genome, his optimism is certainly justified. The technologies discussed in this book, coupled with the information obtained from the complete human genome, promise an incredibly interesting future for biology. Both the author and the individuals behind the human genome project are excellent examples of the ingenuity and mental discipline of the human species.	2003-04-15
1168951:US	50702879	R3BEKG1O7919SN	0813340578	512934968	Digital Soul: Intelligent Machines And Human Values	Books	3	6	7	N	Y	An odd mixture of optimism and cynicism	The topic of machine intelligence continues to inspire both worry and elation. This book is an interesting mixture of these two, for the author is both optimistic about the eventual rise of machine intelligence, which he argues is to a large degree already here, but he is also clearly concerned about its possible negative consequences. Failure to understand and adapt to the new technologies arising may threaten us with extinction, he argues in the first chapter of the book.<br /> He also states in chapter 1 that in order to survive our \\"technological adolescence\\" humans must lose some of their \\"self-destructive evolutionary baggage.\\" This belief seems to be a popular one, being pervasive in literature, performing arts, and philosophy. But from a statistical/scientific standpoint, it is clearly unsupported. In comparison to the total number of humans who have ever lived, only a tiny minority of individuals throughout history have ever hurt anyone physically; an even smaller number have actually killed another human being. The author's cynicism here is totally unjustified.<br /> The author though does engage in interesting discussion on the nature of intelligence and why he believes that machines are already more intelligent than humans are in certain specialized domains. Because of this, he also argues (correctly) that the further rise of machine intelligence will take place incrementally, with no well-defined time at which one could say that machine intelligence has surpassed human intelligence. It seems as though we have learned to live with machines doing things better than we can, at least in some areas, but have not yet viewed these capabilities as being \\"intelligent\\". But, asks the author, if they are more intelligent, at least in these areas, how would one know if they are working properly? It is at this point that the author believes that one should worry about the future of humanity as the dominant life-form on Earth.<br /> Throughout the book, the author shows keen insight into the real goals behind research and development in A.I. The main goal he says is not to create machines that think and behave completely like humans, but find solutions to problems and do tasks that humans require. This will bring about, the author believes, intelligent machines whose cognitive abilities are quite unique, and characteristically non-human-like. There are many examples of his opinions on these matters in current developments in A.I., such as genetic programming and automatic theorem proving. These two areas have exhibited solutions to problems that clearly are very different than what humans would have done.<br /> In addition, and perhaps to the alarm of some philosophers, the author takes a pragmatic view concerning the question as to whether machines can think. He clearly does not want to engage in the arm-chair philosophical debates about this question, and considers them totally irrelevant. What matters to him is whether the machine \\"acts in all respects\\" as though it understands. The imputation of mental processes to a machine will assist in the understanding of how it works and what it can do, and this is perfectly fine with the author. But this does, in the author's view raise questions as to the legal and ethical status of thinking machines.<br /> Because of the title of the book, it is not surprising to find a discussion of the \\"strong A.I.\\" problem included in it. The author spends a chapter addressing the nature of consciousness and some of the ideas and myths surrounding it. He recognizes, correctly, that the doctrines of vitalism and dualism are not useful at all from a scientific perspective. The proponents of these doctrines adhere to the \\"irreducibility\\" of consciousness, and therefore to the untenability of its analysis. Pure speculation is thus the tool of inquiry, all of this done on the philosopher's armchair and not in the laboratory. The author though, thankfully, advocates a purely scientific approach, taking the physical nature of consciousness as an axiom, and then seeing how far this will lead. His analysis and commentary throughout the chapter are very interesting and connected with evolutionary arguments as to why consciousness is structured the way it is.<br /> Most interesting is the author's discussion on the role of emotions in human cognition. Not viewing emotions as inherently undesirable or \\"irrational\\", he gives reasons for wanting to incorporate them into an intelligent machine. One of these is an algorithmic notion: emotions provide a \\"weighting scheme\\" that will filter out undesirable paths in the total path space of alternatives. Anyone who has attempted to design search algorithms will understand the importance of weighting schemes that will allow pruning of the search space. The same goes for those involved in the design of neural networks for pattern matching or time series prediction: bias nodes are essential for the proper function of the neural network. The author gives as an example the biases that are built into chess-playing machines, without which the machine's capabilities would be crippled.<br /> The author definitely believes in the possibility of machines \\"taking over\\", devoting an entire chapter to the possible scenarios that might bring this about. But his cynicism acts against him here, namely his belief that humans, even though clearly expressing intelligence, are prone to extreme violence. His notion of intelligence therefore is too narrow: an alternative one is that the more intelligent an entity becomes, the less prone to violence it becomes. In other words, violence disrupts the cognitive flow of the entity in question, and it avoids it out of necessity: to maintain a state of intelligence that not only has survival value but may indeed be purely a subjective need. The degree of intelligence is thus inversely related to the violence participated in. There are many examples of this, billions in fact, these being the humans who have lived throughout history. The vast majority of humans have been superb thinking machines, and they serve as excellent examples to the ones which they are creating and will create.taking the physical nature of consciousness as an axiom, and then seeing how far this will lead. His analysis and commentary throughout the chapter are very interesting and connected with evolutionary arguments as to why consciousness is structured the way it is.  <br /> Most interesting is the author's discussion on the role of emotions in human cognition. Not viewing emotions as inherently undesirable or \\"irrational\\", he gives reasons for wanting to incorporate them into an intelligent machine. One of these is an algorithmic notion: emotions provide a \\"weighting scheme\\" that will filter out undesirable paths in the total path space of alternatives. Anyone who has attempted to design search algorithms will understand the importance of weighting schemes that will allow pruning of the search space. The same goes for those involved in the design of neural networks for pattern matching or time series prediction: bias nodes are essential for the proper function of the neural network. The author gives as an example the biases that are built into chess-playing machines, without which the machine's capabilities would be crippled. <br /> The author definitely believes in the possibility of machines \\"taking over\\", devoting an entire chapter to the possible scenarios that might bring this about. But his cynicism acts against him here, namely his belief that humans, even though clearly expressing intelligence, are prone to extreme violence. His notion of intelligence therefore is too narrow: an alternative one is that the more intelligent an entity becomes, the less prone to violence it becomes. In other words, violence disrupts the cognitive flow of the entity in question, and it avoids it out of necessity: to maintain a state of intelligence that not only has survival value but may indeed be purely a subjective need. The degree of intelligence is thus inversely related to the violence participated in. There are many examples of this, billions in fact, these being the humanswho have lived throughout history. The vast majority of humans have been superb thinking machines, and they serve as excellent examples to the ones which they are creating and will create.	2003-04-06
1169248:US	50702879	R3BEEKXSD6V433	9810227264	22002755	Quantum Topology And Global Anomalies (Advanced Series in Mathematical Physics)	Books	4	1	1	N	N	A good overview	It is now a tautology that physics and mathematics are intertwined to a degree that goes far beyond saying merely that physics makes use of various results in mathematics. The latter has been going on ever since people have been doing physics. Now though ideas from physics have been finding applications in mathematics, and many exciting results in mathematics have appeared in the last twenty years due to this. This book is a brief overview of some of these at the time of publication, which is called 'topological quantum field theory' or 'quantum topology'.<br /> The author introduces chapter 1 as a quest for obtaining invariants of 3-manifolds. Noting that the Euler characteristic is zero for all closed 3-manifolds, he then looks at hyperbolic 3-manifolds, and studies the volume-, Chern-Simons-, and the eta-invariants of these. The volume invariant is not fine enough as there exist non-homeomorphic hyperbolic 3-manifolds with equal volumes. The Chern-Simons invariant is the integral of the pullback of a 3-form on the (oriented) frame bundle of the manifold. The author quotes, but does not prove the Meyerhoff-Ruberman theorem, which gives criteria under which hyperbolic 3-manifolds with equal volumes  have different Chern-Simons invariants. The eta-invariant involves eigenvalues of the Laplace operator and is given by the Atiyah-Patodi-Singer formula. There exists hyperbolic 3-manifolds with equal Chern-Simons invariants but different eta-invariants, but the author does not discuss examples. The author then summarizes briefly the quantum field-theoretic formulation of the Chern-Simons invariant, which, because of the problems with a rigorous foundation for functional integration, gives readers their first taste of 'physical mathematics'. He also discusses briefly the 'mutant' manifolds which are not distinguishable by any of these invariants, and conjectures that a more in-depth understanding of the 3-D mapping class group will allow finer invariants.<br /> Chapter 2 is then an introduction to how to obtain 3-manifold invariants using the mapping class group using the holonomy of the Knizhink-Zamolodchikov monodromy equation and Moore-Seiberg conformal field theory. The 3-manifolds are required to have Heegaard decompositions, and the (Kohno) formula for the invariant involves a homomorphism from the mapping class group of a Riemann surface with a certain genus to the group of isotopy classes of orientation preserving self-diffeomorphisms.<br /> Chapter 3 is an introduction to the Teichmuller and moduli spaces. The quotient group of Teichmuller space modulo the action of the mapping class group is moduli space. The description of Teichmuller space in terms of Fenchel-Nielsen coordinates is given, and the author shows how to describe the Deligne-Mumford compactification using these coordinates. He also shows the relation between the homologies of the moduli space and the mapping class group.<br /> Chapter 4 is an overview of to what extent mapping class groups act like arithmetic groups. The author proves that the mapping class group cannot be arithmetic when the genus is greater than or equal to 3. He also addresses the question as the stability of the homology of mapping class group as the genus gets larger. He states, but does not prove, Harer's theorem, which says that the kth-homology group is independent of the genus  g if g is greater than or equal to 3k + 1.<br /> Chapter 5 is very interesting, in that it shows how to view Teichmuller space as a symplectic manifold, this being done via the Weil-Petersson form. He uses this to prove that the Deligne-Mumford compactification is projective.<br /> Chapters 6 and 7 are quick reviews of gauge theories on Riemann surfaces. Chapter 8 then considers the geometric quantization of Chern-Simon-Witten theories. The presentation of this is excellent because the reader can see clearly the reason for employing the &quot;Kahler polarization&quot;, which seems mysterious when first encountered. The U(1) (torus case) for geometric quantization is given before taking on the non-Abelian case.<br /> The author finally gets to the connection with anomalies in chapter 9, wherein he discusses deformation quantization, mostly in relation to his own work. Global anomalies are viewed as being induced by an obstruction to patching a local deformation &quot;quantizable *-product&quot; to a global *-product.  Physicists well-versed in quantum gauge theories will understand fully the appearance of the Jacobi identity here and its role in inducing global anomalies. The Wess-Zumino consistency conditions are discussed here also.<br /> Things get more in touch with physics in chapter 10, wherein the author discusses the famous chiral and gravitational anomalies. The Green-Schwarz anomaly cancellation mechanism in heterotic superstring theory is discussed in detail. These results are connected to index theorems in the next chapter, where the author also introduces the reader to characteristic classes.  The geometric interpretation of anomalies as being the curvature and holonomy of the connection in the determinant bundle is readily apparent. In addition, the reader can see the origin of the famous Fujikawa change of measure in the path integral for the effective action of a massless Dirac fermion in Euclidean space of even dimension.<br /> The author goes on to give in his words an exhaustive account of global anomalies in chapter 12. Arising because of the failure of the symmetries of the full diffeomorphism group to be respected after quantization, the author differentiates between global gauge and gravitational anomalies, and the connection of the latter with the mapping class group. Chapter 13 then concentrates more on this connection, and with the connection to Chern-Simons-Witten theories. The discussion revolves around 3-dimensional handlebodies and due to this connection with topology is very interesting. The role of exotic differentiable structures in anomalies is made readily apparent.<br /> The last chapter of the book is written by the topologist Louis Kauffman and overviews the results from the theory of characteristic classes needed for a study of exotic spheres. The existence of exotic structures is fascinating but their role (outside of anomaly detection) in physics still remains to be seen.encountered. The U(1) (torus case) for geometric quantization is given before taking on the non-Abelian case. <br /> The author finally gets to the connection with anomalies in chapter 9, wherein he discusses deformation quantization, mostly in relation to his own work. Global anomalies are viewed as being induced by an obstruction to patching a local deformation &quot;quantizable *-product&quot; to a global *-product.  Physicists well-versed in quantum gauge theories will understand fully the appearance of the Jacobi identity here and its role in inducing global anomalies. The Wess-Zumino consistency conditions are discussed here also. <br /> Things get more in touch with physics in chapter 10, wherein the author discusses the famous chiral and gravitational anomalies. The Green-Schwarz anomaly cancellation mechanism in heterotic superstring theory is discussed in detail. These results are connected to index theorems in the next chapter, where the author also introduces the reader to characteristic classes.  The geometric interpretation of anomalies as being the curvature and holonomy of the connection in the determinant bundle is readily apparent. In addition, the reader can see the origin of the famous Fujikawa change of measure in the path integral for the effective action of a massless Dirac fermion in Euclidean space of even dimension. <br /> The author goes on to give in his words an exhaustive account of global anomalies in chapter 12. Arising because of the failure of the symmetries of the full diffeomorphism group to be respected after quantization, the author differentiates between global gauge and gravitational anomalies, and the connection of the latter with the mapping class group. Chapter 13 then concentrates more on this connection, and with the connection to Chern-Simons-Witten theories. The discussion revolves around 3-dimensional handlebodies and due to this connection with topology is very interesting. The role of exotic differentiable structures in anomalies is made readily apparent.   <br /> The last chapter of the book is written by the topologist Louis Kauffman and overviews the results from the theory of characteristic classes needed for a study of exotic spheres. The existence of exotic structures is fascinating but their role (outside of anomaly detection) in physics still remains to be seen.	2003-04-05
1182861:US	50702879	R3I0K4WYOQG9PS	0375713425	993838176	The Next Fifty Years: Science in the First Half of the Twenty-first Century	Books	3	39	55	N	Y	A fairly good overview	The making of predictions is necessary and important, for it can instill both optimism and caution. There is only a modest collection of predictions in this book, but they do give a fairly good representation of the different scientific fields and what to expect in these fields by the end of the fifth decade of the 21st century. Here is a brief summary and commentary of a few of them:<br />- \\"The Future of the Nature of the Universe\\" (Lee Smolin). The author predicts that quantum computing will become a reality in 50 years, as long as quantum mechanics remains true when extrapolated to macroscopic systems. COMMENT: Due to studies in decoherence and more honest interpretations of experiments testing the phenomenon of entanglement, quantum theory will instead be viewed in more \\"classical\\" terms in its formalism and foundations. Research into quantum computation, as understood presently, will fade from the scene.<br /><br />- \\"Cosmological Challenges: Are We Alone, and Where?\\" (Martin Rees). The author is optimisitic about the SETI project and other attempts to detect the presence of life external to the Earth. COMMENT: Due to advances in solid state device physics, life on other planets will be detected via the by-products they put into their atmospheres. The information theory behind the SETI searches will become more refined also, increasing the probability of understanding a real message from another civilization.<br />- \\"Son of Moore's Law\\" (Richard Dawkins). The author predicts an exponential increase in DNA sequencing power, which he labels as the \\"Son of Moore's Law.\\" The author also expresses a fear that there will still be theologians in 2050, this being done in the context of ethical debates on the genetic sequencing of \\"Lucy\\" and the possibility of the reintroduction of dinosaurs. COMMENT: The sequencing projects and the number of sequenced organisms will increase hyperexponentially. In addition, tens of thousands of new \\"transgenic\\" organisms will appear, all of them optimized to carry out certain biological functions. The field of horticulture will explode, with thousands of new species of ornamental plants appearing before 2050. The university will meet its demise by 2050, but theologians will not disappear. On the contrary, and perhaps unfortunately, the major religions will be with us for many centuries to come, and they will accompany humankind on their voyages to other worlds, for better or worse.<br /><br />-\\"The Mathematics of 2050\\" (Ian Stewart). The author predicts major revolutions in mathematics, due partially to the increasing influence of the computer, bioinformatics, and financial engineering. He also predicts that the current split between \\"pure\\" and \\"applied\\" mathematics will end, with the result being just \\"mathematics\\". He mentions also the \\"Milennium Problems\\", one being the Riemann hypothesis, which he predicts will be solved by 2050, its solution being hinted at by considerations in physics. The P/NP problem will be proved undecidable, the Hodge conjecture will be disproved, the Birch/Swinnerton-Dyer conjecture will be proved, the Navier-Stokes equations will turn out not to have solutions in certain circumstances, the Yang-Mills mass gap problem will be settled but will be deemed irrelevant by physicists, and the Poincare conjecture will be \\"wide-open\\". Interestingly, the author is one of the few who have mentioned the role of \\"quantization of mathematics\\" via quantum algebra, quantum topology, and quantum number theory. COMMENT: The Poincare conjecture will be resolved by 2010 with its resolution being in the context of the \\"quantization of mathematics\\" mentioned by the author. In fact, the quantization of mathematics will be the driving force behind whole new areas of mathematics. Pure mathematics will continue to be viewed as disjoint from applied mathematics. In fact, there will be an intense effort, as evident from the last two meetings of the International Congress of Mathematicians, to keep pure and applied mathematics as separate disciplines. Mathematical finance will continue to explode and there will be intense competition between financial firms to develop highly sophisticated algorithms for financial prediction and portfolio manangement. Financial mathematics will also have more overlap with physics and meteorology, as energy and weather derivatives take on even more importance. The next fifty years will see the rise of financial firms, and others, managed, staffed, and run completely by intelligent machines. In addition, due to hardware advances and the development of highly sophisticated algorithms in mathematical biology and bioinformatics, the entire biosphere will be sequenced by 2050. Complete mathematical models of the entire human body will be developed by mathematicians working in the biotechnology industry, and drug discovery will be viewed as essentially mathematical, with the actual physical chemistry and manufacture being essentially automatic. In this same light,  combinatorial chemistry will become a branch of mathematics in its own right, attracting the attention of hundreds of mathematicians. Advances in artificial intelligence will bring about, with indications by the year 2040, of intelligent machines able to construct original concepts and theories in pure mathematics. Skepticism as to the possibility of thinking machines will be alleviated because of these developments. \\"Artificial\\" mathematicians will begin to become competitive with \\"natural\\" ones by the year 2050. Further, cryptography will continue to explode as a field of mathematics, due to the increasing need for online security and individual privacy. Increased computer power will fuel this need, and the competition between encryption and de-encryption algorithms will become very intense. lastly, by 2050 it will be accurate to say that mathematics will enter into every phase of human and machine activity. There will be no process, no business transaction, no entertainment function, no leisurely activity, that will not depend predominantly on mathematical structures or algorithms.eep pure and applied mathematics as separate disciplines. Mathematical finance will continue to explode and there will be intense competition between financial firms to develop highly sophisticated algorithms for financial prediction and portfolio manangement. Financial mathematics will also have more overlap with physics and meteorology, as energy and weather derivatives take on even more importance. The next fifty years will see the rise of financial firms, and others, managed, staffed, and run completely by intelligent machines. In addition, due to hardware advances and the development of highly sophisticated algorithms in mathematical biology and bioinformatics, the entire biosphere will be sequenced by 2050. Complete mathematical models of the entire human body will be developed by mathematicians working in the biotechnology industry, and drug discovery will be viewed as essentially mathematical, with the actual physical chemistry and manufacture being essentially automatic. In this same light,  combinatorial chemistry will become a branch of mathematics in its own right, attracting the attention of hundreds of mathematicians. Advances in artificial intelligence will bring about, with indications by the year 2040, of intelligent machines able to construct original concepts and theories in pure mathematics. Skepticism as to the possibility of thinking machines will be alleviated because of these developments. \\"Artificial\\" mathematicians will begin to become competitive with \\"natural\\" ones by the year 2050. Further, cryptography will continue to explode as a field of mathematics, due to the increasing need for online security and individual privacy. Increased computer power will fuel this need, and the competition between encryption and de-encryption algorithms will become very intense. lastly, by 2050 it will be accurate to say that mathematics will enter into every phase of human and machine activity. There will be no process, no business transaction, no entertainment function, no leisurely activity, that will not depend predominantly on mathematical structures or algorithms.	2003-03-24
1185295:US	50702879	RDMV4QKXQ741T	1859846874	805633321	Science, Seeds, and Cyborgs: Biotechnology and the Appropriation of Life	Books	3	8	11	N	Y	A post-hermeneutic defense of anti-biotechnology	There is at this time a very intense war going on, and this war is not like the one currently taking place in Iraq. It is instead a conflict that has great similarity to one that took place in the early part of the twentieth century: the battle between DC and AC power. This conflict was not a physically violent one, but instead was characterized by an intense verbal smear campaign, with those supporting DC power and those supporting AC exchanging irrational and ridiculous claims and accusations. The tension now is between those who support biotechnology and genetic engineering, and those who do not, and some of the assertions made in each camp border sometimes on absurdity.<br /> This book is definitely against the practice of genetic engineering, but it does not thankfully engage indulge itself in the blatant vituperation that so frequently accompanies groups that are. The author gives what might be characterized as a \\"post-Marxist\\", or \\"post hermeneutic\\" justification of anti-biotechnology, ala Karl Marx, Jurgen Habermas, Michel Foucault, and Erich Fromm. Even though I disagree profoundly with the author's conclusions, the book still could be of interest to anyone who wants to understand, in a calm and rational manner, some of the current arguments against biotechnology.<br /> There are many places in the book where the author's arguments are weak or unjustified. One of them is in the first paragraph of the book in the preface, where the author asserts that \\"genetic modification is always an experiment\\", and that no models exist which can be \\"innocently tested, corrected and revised.\\" This is certainly false, as there are many indications of what the final results will be when performing genetic modification, and with the assistance of mathematics and physics, highly sophisticated models can be developed that give large amounts of information on what will happen to organisms and the environment after genetic modification has taken place. In addition, the author does not mention that the scope of human intervention using genetic modification is insignificant compared to that which takes place naturally, and at extremely small time scales. Indeed, the phenomenon of horizontal gene transfer, which the author clearly feels threatened by, is one of the these. This is not to say that humankind should have a cavalier attitude about genetic engineering, but concerns about its practice should be done in the context of what is known from a scientific viewpoint, with careful regard also to ethical considerations. Also, the author speaks of the danger of changing genetic sequences that have remained \\"stable\\" for hundreds of thousands of years. He does not define though what he means by stability. The evolutionary process though, if viewed from the standpoint of the myriads of species that have appeared and died out in the time frame discussed by the author, would be difficult to label as 'stable'.<br /> Because of the post-Marxist orientation in the book, it is not surprising to read that the author views biotechnology in his words as a \\"tool of power\\" which \\"rarely lends itself to fair, responsible, and democratic control.\\" But market motivations cannot by themselves allow one to characterize the biotech industry as being uniquely this way. After all, the organic food industry is \\"market-motivated\\", but it would be wrong to prohibit its products from being put on the market simply because of this. The author also speaks of how science is being \\"corrupted\\" by its growing dependence on big business. But due to its need for funding, there are only two ways in which science can survive as a profession: obtaining funding from the government or from private business. One can certainly think of examples where scientists have been dishonest in their attempts to gain funding, but this happens in the context of both of these funding sources.<br /> The book though does not limit itself totally with issues in biotechnology. The author includes a chapter called \\"The Cyborg Solution\\" which he views as the move to bring about intelligent machines and to enhance human capabilities using silicon implants. After calling these proposals \\"infatuations\\", he claims that they are a \\"disembodiment of the human will.\\" The \\"cyborg enthusiasts\\" follow a \\"technological imperative\\" the true purpose of which is to remove the obstacles presented by people to the reproduction of machines. There may be some \\"cyborg enthusiasts\\" who feel this way (the author does not give examples), but there are also those in the same group who view machines as purely complimentary to human beings. These machines could act as companions, not slaves; as friends with their own unique capabilities, with these capabilities widely varying between machines. The machines themselves will also have a lot to learn from their human counterparts, with the result being more of a symbiosis, rather than a replacement.<br /> The author ends the book with severe criticism of the scientific enterprise in general. He joins the philosopher Edmund Husserl in the desire to hold on to the \\"mystery\\" of experience. Science, he says, is an escape from the \\"impossibility of illuminating the inexactitude\\" of experience. Science and the cyborg will remove doubt and wonder, the \\"incommunicable convictions, that are definitive of the human subject\\". Quoting Husserl, he describes mathematics as \\"thoroughly relative science\\",  as one that has forgotten the \\"working subject\\". But doubt and wonder are the handmaidens of science and mathematics: doubt helps to resolve issues and fine tune theories, and wonder is a purely subjective feeling of having understood something for the first time, and of participating in the incredible diversity of the natural world.<br /> Science does not take us farther away from who we are, but closer.a chapter called \\"The Cyborg Solution\\" which he views as the move to bring about intelligent machines and to enhance human capabilities using silicon implants. After calling these proposals \\"infatuations\\", he claims that they are a \\"disembodiment of the human will.\\" The \\"cyborg enthusiasts\\" follow a \\"technological imperative\\" the true purpose of which is to remove the obstacles presented by people to the reproduction of machines. There may be some \\"cyborg enthusiasts\\" who feel this way (the author does not give examples), but there are also those in the same group who view machines as purely complimentary to human beings. These machines could act as companions, not slaves; as friends with their own unique capabilities, with these capabilities widely varying between machines. The machines themselves will also have a lot to learn from their human counterparts, with the result being more of a symbiosis, rather than a replacement. <br /> The author ends the book with severe criticism of the scientific enterprise in general. He joins the philosopher Edmund Husserl in the desire to hold on to the \\"mystery\\" of experience. Science, he says, is an escape from the \\"impossibility of illuminating the inexactitude\\" of experience. Science and the cyborg will remove doubt and wonder, the \\"incommunicable convictions, that are definitive of the human subject\\". Quoting Husserl, he describes mathematics as \\"thoroughly relative science\\",  as one that has forgotten the \\"working subject\\". But doubt and wonder are the handmaidens of science and mathematics: doubt helps to resolve issues and fine tune theories, and wonder is a purely subjective feeling of having understood something for the first time, and of participating in the incredible diversity of the natural world. <br /> Science does not take us farther away from who we are, but closer.	2003-03-22
1185870:US	50702879	R3U9VD53GIS1CU	0471450413	209039373	Linear Operators for Quantum Mechanics	Books	4	44	44	N	N	A good introduction	One cannot do quantum mechanics without a thorough knowledge of the geometry of Hilbert space and the linear transformations on them. This book gives a good introduction to operators on Hilbert space, and could be read by a beginning graduate student of physics.<br /> The theory of operators on Hilbert spaces could be viewed as a generalization of the theory of matrix transformations on finite-dimensional vector spaces. This viewpoint is readily apparent in chapter 1, wherein the author introduces Hilbert spaces as infinite-dimensional vector spaces (over the complex numbers) with an inner product. The author shows how to handle infinite sums of vectors, which requires the notion of convergence, and how to guarantee an infinite sequence of vectors converges to a limit vector that is also in the Hilbert space: the famous Cauchy sequences of vectors. The notion of a linear functional is also introduced, the author proving the one-to-one correspondence between continuous linear functionals and vectors, and connects this with the Dirac bra-ket notation.<br /> Observables in quantum mechanics are represented by operators on (separable) Hilbert spaces, and these are studied in chapter 2. It is straightforward to define a linear operator in finite dimensions, but in infinite dimensions one needs the notion of a continuous linear operator. The author proves that a linear operator is continuous if and only if it is bounded. Unitary operators, so crucial to the calculation of probabilities in quantum theory, are introduced in this chapter also. In addition, the author studies projection operators, which are very important in the measurement process in quantum mechanics. lastly, the author discusses unbounded operators, which are ubiquitous in quantum theory, especially in the theory of angular momenta.<br /> Obtaining measurement results in quantum theory corresponds to obtaining an eigenvalue of a Hermitian linear operator. Thus one must develop a notion of diagonalization (or &quot;spectral resolution&quot;) of these operators, and this takes place in chapter 3. In infinite dimensions a Hermitian or unitary operator need not have any eigenvalues or eigenvectors, but the author shows how to obtain a spectral resolution using spectral families of projection operators. He proves that a self-adjoint operator is bounded if and only if its spectrum is bounded, and also Stone's theorem, which gives a representation of a unitary operator as an exponential of a unique self-adjoint operator. Such a representation is expected from the standpoint of how time evolution is characterized in quantum mechanics.<br /> Things become more abstract in chapter 4, wherein the author studies operator algebras. The goal of the chapter is to find conditions under which the functions of a set of noncommuting operators include all bounded operators. This problem motivates the definition of a von Neumann algebra or W*-algebra, this definition depending on the important notion of a weak topology on a set of bounded operators. It is this topology that is the most relevant for the connection of quantum theory with laboratory measurements.<br /> In chapter 5, the author makes clearer the concept of a state in quantum mechanics, this being done using the concept of a density matrix. States specify expectation values of bounded operators, and the author shows how to represent the expectation value of a bounded operator using a unique density matrix. Probabilities in quantum-mechanical calculations are then viewed as expectation values for projection operators, and the author uses Gleason's theorem to justify that projection operators are sufficient to determine the representation of a state. Having set up all this formalism, the author then derives the uncertainty principle for a quantity represented by a Hermitian operator. He then shows that real quantities which are simultaneously measurable with unlimited precision are represented by commuting Hermitian operators.lastly, the author addresses the implicit assumption that every bounded Hermitian operator can represent a measurable quantity. He gives an example of a system that cannot, this occurring because of 'superselection rules'. An operator that commutes with every Hermitian operator which represents a measurable quantity, but is not a multiple of the identity operator is then called a 'superselection operator'. He also discusses, but does not prove in detail, the representation of the expectation value of an element of a von Neumann algebra in terms of a density matrix. When a superselection rule is in place, the density matrix is not always unique. The author then shows how these facts enable one to view a von Neumann algebra alternatively as a collection of bounded operators that commute with all the projection operators.<br /> States of course evolve in time, and so do observables. In chapter 6 the author derives the equations of motion both for the states and the observables. For the states this is the 'Schrodinger picture', and for the observables the 'Heisenberg picture'. Wigner's theorem on unitary and antiunitary operators is used to show that the time evolution of states is linear. The Heisenberg picture is illustrated by an example of a single particle. A more complicated situation though is when the classical system is not integrable, and is still the topic of intense research. The author also includes, atypically for books at this level, a discussion of what happens to the Schrodinger picture when superselection rules are included.<br />The mathematical tools used in this chapter are used in chapter 7 to study Galilean and Newtonian space-time transformations of states.rs. lastly, the author addresses the implicit assumption that every bounded Hermitian operator can represent a measurable quantity. He gives an example of a system that cannot, this occurring because of 'superselection rules'. An operator that commutes with every Hermitian operator which represents a measurable quantity, but is not a multiple of the identity operator is then called a 'superselection operator'. He also discusses, but does not prove in detail, the representation of the expectation value of an element of a von Neumann algebra in terms of a density matrix. When a superselection rule is in place, the density matrix is not always unique. The author then shows how these facts enable one to view a von Neumann algebra alternatively as a collection of bounded operators that commute with all the projection operators. <br /> States of course evolve in time, and so do observables. In chapter 6 the author derives the equations of motion both for the states and the observables. For the states this is the 'Schrodinger picture', and for the observables the 'Heisenberg picture'. Wigner's theorem on unitary and antiunitary operators is used to show that the time evolution of states is linear. The Heisenberg picture is illustrated by an example of a single particle. A more complicated situation though is when the classical system is not integrable, and is still the topic of intense research. The author also includes, atypically for books at this level, a discussion of what happens to the Schrodinger picture when superselection rules are included. <BR>The mathematical tools used in this chapter are used in chapter 7 to study Galilean and Newtonian space-time transformations of states.	2003-03-21
1186745:US	50702879	R925XGMYMN0VD	0312267398	43378737	Future War: Non-Lethal Weapons in Twenty-First-Century Warfare	Books	5	3	5	N	Y	Excellent	As US/Allied forces this very day are engaging in military operations against Iraq, the emphasis is not only on victory but on the minimization of casualties, both military and civilian. This book discusses several approaches to the latter, via the use of \\"non-lethal\\" weapons, and some of these may in fact be employed in Operation Iraq Freedom. The discussion is fascinating, and one can only hope that future technological developments will make war less probable because of the ideas expoused by the author. In the foreword to the book, the author lets Tom Clancy remind the reader of the unique American viewpoint on warfare. Americans, because of the nature of the government in which they have chosen to create and participate, have always been reluctant to go to war. Every soldier is precious, indeed, human life is precious, and is not to be taken lightly. It is therefore not a surprise that precision-guided and non-lethal weapons have and are undergoing intense development in the last two decades in the United States. Hopefully this attitude will continue in this, the best of all centuries. The author seems confident that it will, and indeed we are fortunate to have individuals in the U.S. military who have his attitude and share his philosophy.<br /> Some of the more interesting technological developments in non-lethal weaponry discussed in the book include: 1. Electromagnetic weapons: man-portable laser weapons, blinding weapons, isotropic radiator weapons, pulse weapons, stun guns. 2. Chemical non-lethal weapons: antimateriel chemical agents, superacids, pheromones. 3. Acoustic weapons, such as pulsed periodic stimulus, which causes perceptual disorientation in the individual.	2003-03-20
1187215:US	50702879	R2CELMI69SLFGN	0840211090	371792000	The Psychology of Self-Esteem: A New Concept of Man's Psychological Nature	Books	3	2	3	N	N	Needs refining	Psychology as a field has undertaken a roller coaster ride in the last century. Not only has it been split up into many disparate fields, it has been viewed by some as not being subject to scientific analysis. This has resulted in the development of the &quot;behavioristic&quot; field of psychology ala the work of B.F. Skinner. At the other extreme, one has seen the rise of psychological theories, such as Gestalt theories, that make no attempt to be scientific, agreeing that such an effort is unproductive.<br /> This book is closer to the latter point of view, but perhaps not by intent. It could be viewed as a collection of the author's opinions on the &quot;objective&quot; need for self-esteem for every individual human being. He does recognize though, and states explicitly that psychology as a science is still in an early stage of development, a sign of this being in fact its division into many schools of thought. The first chapter of the book called &quot;Psychology as a Science&quot; is then a brief attempt to define what the author considers a scientific approach to psychology. In his words: &quot;science is the rational and systematic study of the facts of reality; its aim to discover laws of nature, to achieve a comprehensive, integrated knowledge that will make the universe intelligble to man&quot;. And later he says that: &quot;a new science is born when, out of the countless questions that man asks concerning the nature of things, certain questions are isolated and then integrated into a distinct category-isolated and then integrated by a defining principle that distinguishes these questions from all others and identifies their common characteristics.&quot; This definition though is too narrow, for it does not include the most important aspect of scientific practice: the use of experimentation and the resulting need for statistical and other forms of mathematical analysis. The reader will find none of this in the book, and hence it would be justified to classify its conclusions as &quot;prescientific&quot;, or &quot;philosophical&quot;.<br /> This is not to say that the book is uninteresting or not worth reading. There are some very provocative ideas in it, and if further scientific analysis were included, it would be a very important contribution to scientific psychology. If self-esteem as the author views it, is an objective need for every human being, and this can be established using the usual tools of experimentation and statistical sampling, this would have profound implications for just how humans should interact and what kind of goals they should set for themselves. In addition, his assertion that mental disorders are &quot;thinking&quot; disorders are very much in line with current computational models of the mind, although this connection is not discussed by the author.lassify its conclusions as &quot;prescientific&quot;, or &quot;philosophical&quot;. <br /> This is not to say that the book is uninteresting or not worth reading. There are some very provocative ideas in it, and if further scientific analysis were included, it would be a very important contribution to scientific psychology. If self-esteem as the author views it, is an objective need for every human being, and this can be established using the usual tools of experimentation and statistical sampling, this would have profound implications for just how humans should interact and what kind of goals they should set for themselves. In addition, his assertion that mental disorders are &quot;thinking&quot; disorders are very much in line with current computational models of the mind, although this connection is not discussed by the author.	2003-03-20
1187626:US	50702879	R2E5Q75NVUIVON	0595264549	423703325	Conquest Of Paradise: An End-times Nano-Thriller	Books	4	30	34	N	N	Good story	The last six months has seen the appearance of novels that make use of nanotechnology as a major plot tool. This book, in spite of its ties to Christian religious eschatology, is actually one of the best of these. I found the first 140 pages or so of the story as somewhat &quot;tiring&quot;, but the story quickly picked up after that, and I found myself totally engaged in the subsequent events as they unfolded. This book, like others that have preceeded it, could be interpreted as a sign of the anxiety that many feel regarding present and future developments in nanotechnology. And like these other books, the author includes an afterword that lists URLs for informational websites on nanotechnology. The author cautions the reader as to the enormous power of nanotechnology as he believes it to be.<br /> Since the book is (science) fiction and is written to entertain rather than inform, one should not expect to find total conformance to scientific principles or facts. For example, in the story the nanobots engage in the complete dissolution of a human being. But this would entail the breaking of molecular bonds, mostly hydrogen bonds in water molecules since the human body is mostly water. This is not troubling from a scientific standpoint in and of itself, given the size of the nanobots and the fact that they are designed to carry this out. However, in the story the nanobots do this within a time period of just over two minutes. This would result in a rapid release of heat, which would destroy the nanobots themselves. Further, in the story the nanobots engage in both replication and destruction at a global scale, and at timescales that are short enough that the subsequent release of heat would act as a deterent to further activity by the nanobots. Nanobots and the processes they engage in of course are subject to the second law of thermodynamics. Also, in the story the nanobot's mobility is extremely sophisticated, since they are capable of traveling through the air at high speeds. This is also troubling from a scientific standpoint, since the turbulence in the atmosphere at the scale of the size of the nanobots would disrupt their ability to navigate coherently and efficiently.<br /> The author wants to stay close to a particular doctrine of Biblical prophecy. This is apparent in the use of a newly created European Union, which, say some interpreters of Biblical prophecy, was predicted to happen in the &quot;final days&quot; before the advent of the second coming of Christ. The major powers of the world are engaged in an intense research effort to develop a &quot;nano-assembler&quot; and the race ends with an assembler controlled by Raphael Vicente, the leader of the new European Union. His altruism and ambition results in an apocalyptic horror of global proportions, only to be alleviated by the second coming of Christ.<br /> Indeed the story is very entertaining and worth reading, and as a eschatological/science fiction hybrid, it might also be interpreted as a sign of current attempts to justify the Christian religion scientifically. Ideas from all the branches of science, such as physics, biology, and chemistry are being used to give Christian more substance and credibility. Some may frown on this strategy, believing that science and religion never have any intersection. But historically science and religion have coexisted, with the tension between them have varying degrees of intensity. There are many fine scientists alive now that profess to be born-again Christians, and they make excellent contributions to scientific knowledge. Whether these individuals are Christians who sometimes practice science, or scientists who sometimes practice Christianity is a matter of debate possibly, but the truth of their scientific results are certainly independent of the their belief in Christianity.<br />... and the status of this book as good fiction, which it is, is also independent of the author's Christian beliefs.high speeds. This is also troubling from a scientific standpoint, since the turbulence in the atmosphere at the scale of the size of the nanobots would disrupt their ability to navigate coherently and efficiently. <br /> The author wants to stay close to a particular doctrine of Biblical prophecy. This is apparent in the use of a newly created European Union, which, say some interpreters of Biblical prophecy, was predicted to happen in the &quot;final days&quot; before the advent of the second coming of Christ. The major powers of the world are engaged in an intense research effort to develop a &quot;nano-assembler&quot; and the race ends with an assembler controlled by Raphael Vicente, the leader of the new European Union. His altruism and ambition results in an apocalyptic horror of global proportions, only to be alleviated by the second coming of Christ. <br /> Indeed the story is very entertaining and worth reading, and as a eschatological/science fiction hybrid, it might also be interpreted as a sign of current attempts to justify the Christian religion scientifically. Ideas from all the branches of science, such as physics, biology, and chemistry are being used to give Christian more substance and credibility. Some may frown on this strategy, believing that science and religion never have any intersection. But historically science and religion have coexisted, with the tension between them have varying degrees of intensity. There are many fine scientists alive now that profess to be born-again Christians, and they make excellent contributions to scientific knowledge. Whether these individuals are Christians who sometimes practice science, or scientists who sometimes practice Christianity is a matter of debate possibly, but the truth of their scientific results are certainly independent of the their belief in Christianity.<br />... and the status of this book as good fiction, which it is, is also independent of the author's Christian beliefs.	2003-03-20
1191985:US	50702879	R6W7XVT5BH8O1	0879696214	431452461	Lateral DNA Transfer: Mechanisms and Consequences	Books	5	10	11	N	Y	Excellent	The fact that lateral (or \\"horizontal\\") gene transfer can occur between living organisms is not only an established fact in modern genetics, it is also used by those who are against the practice of genetic engineering. The argument is usually set in the context of using transgenic strategies to transfer genes from two unrelated species. If performed in edible crops for example, this might induce, via lateral gene transfer, dangerous bacterial strains that evolve rapidly from the natural ones inside the human digestive system. Since the use of genetic engineering in agriculture is becoming more and more prevalent today, it is imperative by all concerned to find out in detail just what the fuss is all about concerning lateral gene transfer. The author has written a fine overview of this topic, and can serve both the student of genetics as well as those who are not experts in genetics but who have a need to understand it. The author reviews some of the molecular biology needed in the beginning chapters of the book.<br /> The author introduces lateral DNA transfer as a phenomenon that can occur \\"surprisingly often\\" and can become stably incorporated in the recipient. His first example of it concerns the transfer of marine bacteriophages in the oceans. Each milliliter contains on the order of ten million viruses, most of these being bacteriophages, which infect bateria. When these phages grow, some of them pick up the genes of the host cell and transfer them via infection to a new cell. The transferred sequence then can become stable, and from experiments this happens one out of 100,000,000 times. This translates into 2 million billion times per second! The author also cites evidence for lateral DNA transfer from the sequencing of genomes.<br /> Three chapters of the book are devoted to the occurrence of lateral DNA transfer in prokaryotes, one of the most important ones being antibiotic resistance in microbes. In addition, special blocks of genes called \\"pathogenicity islands\\" can be transferred by bacteriophages using transduction. He also overviews the genome sequencing evidence for lateral transfer in prokaryotes. Some of the more interesting topics discussed in these chapters include: 1. The 'transposons', some of which can direct lateral transfer, with the simplest (the simple insertion elements) now numbering in the thousands. To a reader with some knowledge of physics, it would be interesting to quantify what the \\"mobility\\" of a transposon is.  In addition, transposons can mobilize pathogenicity islands.  2. The 'integrons', which are mobile gene arrays that also promote dispersal of antibiotic resistance genes. The author gives the reader a few research questions regarding integrons. 3. The discussion on the possibility that all genes present in certain DNA phages may be accessible to any phage, via intermediate hosts. 4. For newcomers to microbiology and genetics (like myself), the observation by the author that disease bacteria are only slightly different genetically from normal ones. 5. The ability of some bacteria to hide from the host immune system via a network of sugar chains. 6. The occurrence of 'gene transfer agents', which bring about spontaneous transfer of genetic markers between strains of bacteria. 7. The fact that most of the E.coli genome is a result of lateral transfer. 8. The \\"Selfish Operon Hypothesis\\". 9. The discussion of gene transfer between bacteria on the environment. The author reviews the research, and concludes that it certainly does occur naturally. Engineered genes will thus no doubt do the same, but would be a \\"small drop in the ocean of global DNA exchange\\", according to the author.<br /> The next 5 chapters cover lateral transfer in eukaryotes, with retroviruses being the first important mechanism. The nuclear membrane must be traversed for eukaryotes, making lateral transfer more difficult. An entire chapter is devoted to the discussion of the role of lateral transfer  in the AIDS epidemic. Mobile elements, called 'retrotransposons\\" also play a role in lateral transfer in eukaryotes, via the use of RNA. So also to 'DNA transposons' via the DNA-mediated pathways. Some interesting discussions in these chapters include: 1. Transfer via transient exposure of genomes to chromosomes containing transposons. 2. The process called \\"homing\\", by which transposition of mobile introns takes place. 3. The discussion of DNA transposons in maize. 4. The argument that lateral transfer must take place in animals in order to avoid extinction. 5. The question as to whether there are LTR retrotransposons, as well as mariner or hAT transposons in the human genome. 6. The role of lateral transfer in the evolution of the vertebrate immune system.<br /> The last 3 chapters of the book discuss the occurrence of lateral transfer between species, the regulation of DNA transfer, the role of lateral transfer in the origin of sex, and some speculations by the author.  Interesting discussions here include: 1. DNA transfer from bacteria to plants via crowngalls. 2. The T-DNA transfer system. 3. The possibility of gene transfer into mammalian tissues by eating DNA in food. The author concludes that further studies are needed to prove this possibility. 4. The different strategies employed by eukaryotes for supressing the efficiency of DNA transfer systems, the most interesting of these being RNA interference and cosuppression, the study of the latter originating in horticultural experiments. The author also lists several open questions in the study of RNA interference. 5. The antagonism between the immune system and lateral transfer in vertebrates. 6. The 'interferon' system and its ability to suppress virus replication. 7. The relation between genome size and lateral transfer. What is most surprising in this discussion is the sizes of some genomes relative to the human genome, some (lily plants for example) considerably larger. 8. The strategies that the immune system and pathogens employ to fight each other. Salmonella for example, employs a particularly clever strategy called \\"phase variation\\", which inverts a segment of the genome containing a transcription initiation sequence.<br /> In the last paragraphs of the book, the author encourages the continued study of lateral gene transfer, not only for its impact in genetic engineering, but also for acquiring a understanding of how all lifeforms are connected to each other.demic. Mobile elements, called 'retrotransposons\\" also play a role in lateral transfer in eukaryotes, via the use of RNA. So also to 'DNA transposons' via the DNA-mediated pathways. Some interesting discussions in these chapters include: 1. Transfer via transient exposure of genomes to chromosomes containing transposons. 2. The process called \\"homing\\", by which transposition of mobile introns takes place. 3. The discussion of DNA transposons in maize. 4. The argument that lateral transfer must take place in animals in order to avoid extinction. 5. The question as to whether there are LTR retrotransposons, as well as mariner or hAT transposons in the human genome. 6. The role of lateral transfer in the evolution of the vertebrate immune system. <br /> The last 3 chapters of the book discuss the occurrence of lateral transfer between species, the regulation of DNA transfer, the role of lateral transfer in the origin of sex, and some speculations by the author.   Interesting discussions here include: 1. DNA transfer from bacteria to plants via crowngalls. 2. The T-DNA transfer system. 3. The possibility of gene transfer into mammalian tissues by eating DNA in food. The author concludes that further studies are needed to prove this possibility. 4. The different strategies employed by eukaryotes for supressing the efficiency of DNA transfer systems, the most interesting of these being RNA interference and cosuppression, the study of the latter originating in horticultural experiments. The author also lists several open questions in the study of RNA interference. 5. The antagonism between the immune system and lateral transfer in vertebrates. 6. The 'interferon' system and its ability to suppress virus replication. 7. The relation between genome size and lateral transfer. What is most surprising in this discussion is the sizes of some genomes relative to the human genome, some (lily plants for example) considerably larger. 8. The strategies that the immune system and pathogens employ to fight each other. Salmonella for example, employs a particularly clever strategy called \\"phase variation\\", which inverts a segment of the genome containing a transcription initiation sequence. <br /> In the last paragraphs of the book, the author encourages the continued study of lateral gene transfer, not only for its impact in genetic engineering, but also for acquiring a understanding of how all lifeforms are connected to each other.	2003-03-16
1193552:US	50702879	RP9GZCEBIAO7G	0080265014	742971989	Gauge Theories: An Introduction	Books	3	5	5	N	N	Out of date	The concept of gauge invariance is now ubiquitous in elementary particle physics, and has become very important in pure mathematics also. This book, in spite of its date of publication, could still serve to introduce gauge theories to the beginning student of high energy physics or quantum field theory. It was written shortly after the awarding of the Nobel prizes to Sheldon Glashow, Steven Weinberg, and Abdus Salam for their work on the electroweak interaction (their Nobel lectures are reprinted in the back of the book), but before the discovery of the W and Z bosons in 1982. The book includes a discussion of the work of the author on an SU(2) x U(1) gauge theory with heavy leptons, and its resulting prediction of lepton flavour non-conservation. Due to the recent experimental verification of neutrino mixing, this theory is now vacuous. In addition, the author includes a discussion of the SU(5) theory of grand unification. The experiment limits on proton decay though have caused the SU(5) theory to be discarded. The reader though will find a thorough discussion of the Weinberg-Salam theory as well as an historical overview of the various attempts to understand the weak interaction, such as the current-current Fermi theory and ther resulting conflicts between renormalizability and gauge invariance. A fairly good discussion of the Higgs mechanism is given also. There is no discussion however of supersymmetry. The book has 484 pages but the layout is very sparse, making the reading of it relatively fast. Beginning students of particle physics will no doubt want a more up-to-date book that is more in tune with the present experimental status, but this one could still be used to learn the underlying bread-and-butter topics. Since the book was published many changes have occurred in high energy physics, one of the most significant being the advent of string theories, which began very shortly after the book appeared. Out of string theory grew M-theory and &quot;brane&quot; theories, and these and string theories were constructed to satisfy the need of incorporating gravity into the unification scheme.; theories, and these and string theories were constructed to satisfy the need of incorporating gravity into the unification scheme.	2003-03-14
1194778:US	50702879	R2GVZ2B9WJ9PNR	0070320713	648370005	Quantum Field Theory	Books	4	43	48	N	N	Good book for its time	This book has been used a great deal both in classes on quantum field theory and as a reference, and, in spite of its date of publication, it could still serve as such, if supplemented with updated materials. There is a lot in this book that one could not find at the time it was published, and was a welcome relief to those who needed a textbook that was more up to date than Bjorken and Drell's classic work on quantum field theory.<br /> Some of the highlights of the book include: 1. The &quot;wave packet&quot; solution of the Dirac equation and the Zitterbewegung phenomenon, which the authors use as a counterexample to the idea of treating negative energy states in the framework of a 1-particle theory. 2. The treatment of two-body relativistic corrections to study the recoil of the nucleus, this being done in the context of the Dirac equation. 3. The use of the Dirac hole theory to motivate the need for a true many-body theory to accomodate particles and antiparticles via quantized fields. 4. A fairly lengthy discussion of the Fock-Schwinger proper time method to obtain an exact expression for the Dirac propagator in a constant uniform electromagnetic field and a plane wave electromagnetic field. 5. The discussion on the use of coherent states to study the positive frequency part of a (free) quantum field. 6. The discussion on charged scalar fields, and why they are needed to formulate a (scalar) theory of particles and antiparticles. 7. The quantization of the electromagnetic field using the Gupta-Bleuler method using an indefinite metric, and the need for retaining the full Fock space (with indefinite norm) in order to preserve locality. 8. The discussion of the vacuum fluctuations via the Casimir effect. 9. The treatment of the Dirac field and the Pauli exclusion principle. The authors begin with two complex fields that both satisfy the Dirac equation, but the Lagrangian then vanishes. They thus are careful to note that canonical quantization will not work, and so they turn to the using their transformation laws under the Poincare group. The derivation of the anticommutators is purely heuristic (and they note this), and they point out that locality would not be satisfied if canonical quantization were followed. The same holds true, as they state also, if one were to quantize a scalar theory according to Fermi statistics. Their discussion here is a neat illustration of the spin-statistics theorem. 10. The discussion of form factors, which they motivate by calling them a relativistic generalization of charge distributions. 11. The discussion of the Euler-Heisenberg effective Lagrangian, and its ability, even though it is &quot;classical&quot;, to model nonlinear phenomena due to quantum corrections. 12. The discussion of the Jost-Lehmann-Dyson representation. 13. The discussion of Euclidean Green functions. 14. The derivation of the Ward-Takahashi identities and the proof that they are preserved by the regularization and renormalization operations. 15. The discussion on functional integration in Bargmann-Fock space, in particular its use in fermion systems. 16. The discussion of the Schwinger-Dyson equations and their use in studying quantum field theory independent of perturbation theory. The existence of a bound state in quantum field theory has yet to be proven using these equations, but they supposedly hold the answer to this existence. The authors give an example of scalar particles interacting via the exchange of scalar particles via the Bethe-Salpeter equation, which are then studied via Wick rotation and where crossed-ladder diagrams are omitted. They also analyze the hyperfine splitting in positronium, but remark that the methods used for this are not entirely satisfactory. 17. The discussion of the sigma model, a topic that has become very important of late. 18. The discussion of asymptotic behavior, the authors emphasizing how the infinities in the relation between bare and renormalized charges and how these infinities must compensate imposes constraints on the theory, which show up in the asymptotic behavior.<br />Some of the omissions which might be expected from a modern standpoint: 1. Representations of the Poincare group. 2. Critical phenomena. 3. Integrable systems in quantum field theory 4. Finite temperature quantum field theory. 5. Quantum field theory in curved spacetime. 6. A more in-depth treatment of instantons (the authors only spend one page on them). 7. Topological quantum field theory.ities must compensate imposes constraints on the theory, which show up in the asymptotic behavior. <br />Some of the omissions which might be expected from a modern standpoint: 1. Representations of the Poincare group. 2. Critical phenomena. 3. Integrable systems in quantum field theory 4. Finite temperature quantum field theory. 5. Quantum field theory in curved spacetime. 6. A more in-depth treatment of instantons (the authors only spend one page on them). 7. Topological quantum field theory.	2003-03-14
1201175:US	50702879	R1FN4286Y2NYP5	002864431X	25397171	The Future of War: The Face of 21st-Century Warfare	Books	5	3	5	N	Y	A fascinating overview of what is ahead for warfare techno	If one counted the number of people throughout history that have perished in wars, the number would be very small if compared to the total number of people who have not. Therefore, the impact of war has been minimal in this respect, eliminating of course consideration of the devastating psychological and economic impact that wars bring to human cultures (even if they do not directly participate in the war at hand).<br /> The author of this book gives the reader a vision of the technology that will be used in future conflicts, and the prospects are fascinating if viewed in the abstract, i.e. if one's memory is temporarily blocked to the pain that this technology will bring to the enemy. Fortunately, this same technology will have peaceful applications, and result in more of a benefit to humankind, rather than its destruction. To quote the passage the author uses to introduce the book: \\"The future's so bright, I gotta wear shades...\\"<br /> That humanity is tied together by increasing globalization and makes everyone vunerable to everyone is the author's starting point in the book. Violent perturbations in a small region of the world may have significant impact in regions geographically far apart from it. No citizen of the planet, American or otherwise has the luxury of \\"sitting out\\" what may at first seem to be small \\"isolated\\" wars, argues the author.<br /> The author's emphasis is primarily on the role of the United States in future conflict. He gives a fair and accurate overview of the miliary history of the United States. Americans have always avoided conflict unless absolutely necessary, and the American soldier has in general never been viewed as \\"cannon fodder\\". General Norman Schwarzkopf once said that \\"any commander not concerned with casualties does not deserve to wear the American uniform\\". This emphasis on the minimization of casualities is the main reason for the incredible technological advancements made in weaponry in the United States. The author cites the Gulf War as being the perfect example of how advanced technology can defeat a vast army with a small number of casualties. An entire chapter of the book is devoted to the technology used in the Gulf War. With a war in Iraq perhaps just a week away, the minimization of casualties will still be held as an axiom, fortunately.<br /> Some of the more interesting developments that the author foresees for fighting the wars of the 21st century include: 1. The gun, the history of which he outlines briefly, will no longer be dependent on the physics of projectile motion. Instead, the \\"bullets\\" will precision-guided, along the lines of the cruise missiles currently employed. Firing around corners will thus be a reality. 2. Chemicals that can solidify the fuel inside the tank of an enemy vehicle. 3. Bacteria that can decompose rubber tires. 4. Mines that recognize enemy vehicles and consequently destroying them. 5. Weapon systems packed with artificial intelligence, allowing them to be self-launching. 6. Uniforms that monitor a soldier's health and injuries and that can administer anesthetic. 7. Stealth suits that are \\"chameleon\\" in nature: changing color based on the environment. The author quotes the U.S. Army Soldier System Center as predicting that these kinds of suits will be available by 2025. 8. The \\"Objective Force Warrior\\", the first units of which to be employed by 2015, will have 20 times the range and killing capacity of a current infantryman. 9. The RAH-66 Comanche helicopter, with its digital \\"fly-by-wire\\" control system. 10. Battlefield robots. The author foresees the rise of intelligent machines capable of engaging in sophisticated and complex combat situations. 11. The use of \\"Swath\\" technology to reduce instability and wave motion of naval ships. 12. The use of precision guided and intelligent munitions from drone aircraft, evolving eventually into an intelligent flying killer robot. 12. Space warfare via laser, particle, and microwave beams. 13. The useof non-lethal weaponry: malodorants, informational warfare, acoustics, anti-traction agents, and electromagnetic pulse weapons.<br /> It is doubtful that warfare will go completely away in the 21st century, but its impact can be minimized if all of us realize we are not separated by artificial boundary lines. The tightly knit global culture which we participate in entails a never-ending diligence as well as an intense effort to develop even more sophisticated weaponry. For the United States in particular, it becomes imperative to continue to adhere to the doctrine that each individual soldier is precious and not sacrificed cavilierly. The author has given strong arguments as to the utility of high technology in meeting this absolute requirement. The assistance of high technology, in particular intelligent technology, may bring about areas of conflict itself, and these may not be violent ones, but purely ethical ones. Intelligent machines, as the adjective implies, may have their own arguments about their use on the battlefield.e of non-lethal weaponry: malodorants, informational warfare, acoustics, anti-traction agents, and electromagnetic pulse weapons.<br /> It is doubtful that warfare will go completely away in the 21st century, but its impact can be minimized if all of us realize we are not separated by artificial boundary lines. The tightly knit global culture which we participate in entails a never-ending diligence as well as an intense effort to develop even more sophisticated weaponry. For the United States in particular, it becomes imperative to continue to adhere to the doctrine that each individual soldier is precious and not sacrificed cavilierly. The author has given strong arguments as to the utility of high technology in meeting this absolute requirement. The assistance of high technology, in particular intelligent technology, may bring about areas of conflict itself, and these may not be violent ones, but purely ethical ones. Intelligent machines, as the adjective implies, may have their own arguments about their use on the battlefield.	2003-03-09
1201302:US	50702879	R2FSJF7YVNSV1R	0444104291	619708436	Spectral theory and complex analysis, Volume 4 (North-Holland Mathematics Studies)	Books	4	1	1	N	N	A good introduction to global complex analysis	The theory of several complex variables is very different from that of one variable, and many of the techniques used to study complex functions of several variables involve some fairly sophisticated tools from functional analysis and even algebraic topology. One of the main results in this area is the Oka-Weil theorem, which allows one to approximate a function holomorphic on a campact, polynomially convex set in complex n-space uniformly by polynomials. This result is an example of the 'holomorphic functional calculus' in the theory of Banach algebras.<br /> The condition of polynomial convexity in the Oka-Weil theorem is the starting point for the author, for the holomorphic functional calculus works when only convexity is assumed for the compact set. He wants to get away from the dependence on Banach algebras by considering approximators that satisfy certain growth conditions. The strategy he uses consists of the spectral theory of (Waelbroeck) b-algebras, which is the topic of this book.<br /> Chapter 1 considers the algebra of 'tempered functions' with respect to a 'weight function', along with the subalgebra of holomorphic functions of this algebra. Examples of this algebra include polynomials, entire functions of exponential type, and holomorphic functions with polynomial growth on an open set. A weight function d on complex n-space is a non-negative function that is O(1/|z|) at infinity and satisfies a Lipschitz condition. The author gives conditions for non-negative functions to be equivalent to weight functions. He also characterizes the algebras of holomorphic functions which are inductive limits of the algebra of tempered functions. For a directed set of weight functions, the author gives examples of these algebras on this directed set.<br /> In chapter 2, the author shows how to cover the tempered and holomorphic algebras with a covering of 'pseudonormed' vector spaces. Such a covering does not give a topology but does allow the desired approximation theory. The algebras then become examples of 'polynormed vector spaces', which are complex vector spaces equipped with a covering of pseudonormed spaces. If each member of the covering is a Banach space then the polynormed space is called complete. The tempered and holomorphic algebras are shown to be complete. Certain special polynormed vector spaces called polynormed algebras are then defined, which are such that the operation of multiplication is a bounded linear mapping. In such structures the product of two bounded sets is bounded, and this called an 'algebra boundedness'. A 'b-algebra' is an algebra with a complete algebra boundedness. The author shows to what degree one can emulate the situation in commutative Banach algebras, namely, remembering that an ideal cannot contain the identity element, the ideal is the whole algebra if the unit is the limit of a sequence of elements in the ideal.<br /> The spectral theory of b-algebras is considered in chapter 3, with the author first reviewing the situation in Banach algebras. The spectra of elements of a b-algebra is not compact, and so the study of the resolvent function cannot necessarily be done on the complement of the spectrum. This motivates the author to define the spectral set of an element of a b-algebra as a condition on the boundedness of the resolvent over the complement of the element. Noting then that the study of entire functions cannot be done using spectral sets, the author defines a 'spectral function' as a refinement of a spectral set, and using this he constructs a holomorphic functional calculus. This involves proving that every spectral function is larger than some spectral function which is a weight function.<br /> After a review of the theory of plurisubharmonic functions, the author considers the spectral theory of O(d), where d is a weight function in chapter 4. The set G on which d is nonzero is shown to be a spectral set if and only if it is pseudoconvex. The author first considers spectral functions for z in O(d) where -log(d) is plursisubharmonic, and then studies the general case via a process of plurisubharmonic regularization of weight functions. He also proves the existence of a holomorphic function with polynomial growth on every pseudoconvex domain. This function cannot be holomorphically continued beyond this domain, called a 'domain of holomorphy'.<br /> Chapter 5 considers a 'spectral decomposition' for holomorphic functions. A generalization of the usual theory, the author proves the decomposition property for O(d), a subalgebra of O(d), and inductive limits of these algebras. Ideals of holomorphic functions are studied and a theorem of Hormander, which gives a necessary and sufficient condition for this ideal to be all of O(d), is proven.<br /> The author returns to approximation theory in chapter 6. The Oka-Weil theorem, which gives conditions on which a holomorphic function can be uniformly approximated by polynomials is proven using the holomorphic functional calculus. The author then defines Runge domains and pairs and then considers approximation with growth. The author gives conditions guaranteeing that the polynomials are dense in O(d).<br /> The last chapter refines the results in chapter 6 by viewing O(d) as a 'polynormed' algebra, namely as a filtration of Banach spaces. A filtrated b-algebra is defined, and the author proves a spectral theorem for a commutative filtrated b-algebra. He applies these results to<br />plurisubharmonic functions. Lastly, he chooses a weight function and defines what it means for an open subset of complex n-space to be polynomially convex with respect to this weight function, and proves that every polynomially compact subset of complex n-space has a fundamental system of neighborhoods composed of polynomially convex open sets.spectral functions for z in O(d) where -log(d) is plursisubharmonic, and then studies the general case via a process of plurisubharmonic regularization of weight functions. He also proves the existence of a holomorphic function with polynomial growth on every pseudoconvex domain. This function cannot be holomorphically continued beyond this domain, called a 'domain of holomorphy'. <br /> Chapter 5 considers a 'spectral decomposition' for holomorphic functions. A generalization of the usual theory, the author proves the decomposition property for O(d), a subalgebra of O(d), and inductive limits of these algebras. Ideals of holomorphic functions are studied and a theorem of Hormander, which gives a necessary and sufficient condition for this ideal to be all of O(d), is proven. <br /> The author returns to approximation theory in chapter 6. The Oka-Weil theorem, which gives conditions on which a holomorphic function can be uniformly approximated by polynomials is proven using the holomorphic functional calculus. The author then defines Runge domains and pairs and then considers approximation with growth. The author gives conditions guaranteeing that the polynomials are dense in O(d). <br /> The last chapter refines the results in chapter 6 by viewing O(d) as a 'polynormed' algebra, namely as a filtration of Banach spaces. A filtrated b-algebra is defined, and the author proves a spectral theorem for a commutative filtrated b-algebra. He applies these results to<BR>plurisubharmonic functions. Lastly, he chooses a weight function and defines what it means for an open subset of complex n-space to be polynomially convex with respect to this weight function, and proves that every polynomially compact subset of complex n-space has a fundamental system of neighborhoods composed of polynomially convex open sets.	2003-03-09
1204919:US	50702879	R2XO6HB9009VMF	0486616665	705394246	Differential Algebra	Books	4	15	15	N	N	An area with many applications	Published 53 years ago, this book gives an overview of an area of mathematics that has found applications in algebraic, Diophantine, and differential geometry, model theory, Painleve theory,  integrable systems, automatic theorem proving, combinatorics, difference equations, and symbolic programming. It could be characterized as the study of the solutions to systems of differential equations from an algebraic point of view. These differential equations can be partial or ordinary differential equations, and can be linear or nonlinear. The book is still widely cited and can still be read profitably, despite its date of publication. The author's work was inspired by the work of the mathematicians Emily Noether and van der Waerden, and is now referred to as the Ritt theory of characteristic sets of prime differential ideals. The author's work has been developed considerably further than what he envisaged, to subfields of mathematics now known as differential algebraic geometry and differential algebraic groups.<br /> Differential algebra can be considered to be a generalization of commutative algebra, and in chapter 1 of the book this is readily apparent. The author begins with an algebraic field of characteristic 0 and defines an operation of differentiation on it. As expected, this operation (call it ') is linear and is such that (ab)' = ba' + ab', for elememts a, b in the field. The field with the operation is then called a 'differential field', with the rational, real, and complex numbers being elementary examples. The rational and elliptic functions are also examples of differential fields. A 'differential polynomial' is then a polynomial with coefficients in a differential field. A 'differential ideal of differential polynomials' is then a collection of d.p's that is closed under linear combinations and derivatives of all orders. A 'perfect' ideal is one in which a positive integer power of one of its elements entails the element is in the ideal. A prime ideal is one in which whenever a product of is in the ideal, at least one of the factors is. In analogy with algebraic geometry, the author shows that every perfect ideal of d.p.'s has a representation as the intersection of a finite number of prime ideals.<br /> In chapter 2, the author considers the solution set of a system of equations obtained by setting a d.p. (over indeterminates) equal to zero, this being called the 'manifold' of the d.p. A manifold is 'reducible' if it is the union of two manifolds which are proper parts; 'irreducible' otherwise. The author shows that the essential prime divisors of the perfect ideal associated to a manifold are the prime ideals associated with the components of the manifold. He then proves a 'theorem of zeros': a finite collection of d.p's having no zeros entails that some linear combination of them and their derivatives (of various orders) equals 1.<br /> Chapter 3 outlines the structure theory of d.p's. The author gives a detailed proof of the theorem that every component of a differential polynomial of positive class in n indeterminates has dimension n - 1, as might be expected intuitively.<br /> In chapter 4, the author turns his attention to systems of algebraic equations (which are systems of d.p's which are of order zero in each indeterminate. These systems can be understood independently of d.p's of course, but the author chooses to use the methods of earlier chapters in order to set up the tools for a study of differential equations. Polynomials and algebraic manifolds are thus the objects of interest, with an algebraic manifold being the zero set of the set of polynomials. The famous Hilbert theorom of zeros (the Nullstellensatz) is proven. The reader familiar with the theory of solutions of linear differential equations will appreciate the discussion on the construction of resolvents for a prime polynomial ideal.<br /> The author returns to differential fields and d.p's in chapter 5, where in the first part he discusses an elimination theory for systems of algebraic differential equations. Not holding this theory to be rigorous, he develops a second one in the chapter, and compares the two. For finite systems, these considerations prove again that the manifold of solutions is the union of a finite number of irreducible algebraic differential manifolds.<br /> The author considers the approximation theory of d.p's in chapter 6, where he proves that the general solution of an algebraically irreducible differential polynomial consists of the nonsingular zeros and of the adjacent singular zeros. The reader familiar with the Painleve theory of differential systems will see similarities to the author's discussion.<br /> In chapter 7 the author studies the pathologies that can arise in the intersection of algebraic differential manifolds. He gives an example of an intersection at a single point, and then proves an analogue of Kronecker's theorem, namely that for a finite system of d.p's in n indeterminates, there exists a system composed of n + 1 linear combinations of the d.p's that has the same manifold as the original system.<br /> In chapter 8, the author proves the Riquier existence theorem, which is done in order to use it in the next chapter on partial differential algebra. This theorem states that for any infinite sequence of monomials, there is one of them which is a multiple of another with index value less than its own. This theorem is used to order (analytic) functions and their partial derivatives, using a 'marking' process. These considerations motivate the concept of a 'orthonomic' system of (partial) differential equations.<br /> In the last chapter, the author summarizes quickly what is known about partial differential algebra. Analogs of the earlier constructions are given, such as that of a partial differential polynomial. He proves that a every essential prime divisor of a nonzero partial differential polynomial has a characteristic set consisting of a single d.p. This gives a generalization of the 'spectral' theory outlined earlier for differential algebra. In addition, he gives an outline of an 'elimination theory' of algebraic partial differential equations using the operations of differentiation, rational operations, and factorizations.ses an elimination theory for systems of algebraic differential equations. Not holding this theory to be rigorous, he develops a second one in the chapter, and compares the two. For finite systems, these considerations prove again that the manifold of solutions is the union of a finite number of irreducible algebraic differential manifolds. <br /> The author considers the approximation theory of d.p's in chapter 6, where he proves that the general solution of an algebraically irreducible differential polynomial consists of the nonsingular zeros and of the adjacent singular zeros. The reader familiar with the Painleve theory of differential systems will see similarities to the author's discussion. <br /> In chapter 7 the author studies the pathologies that can arise in the intersection of algebraic differential manifolds. He gives an example of an intersection at a single point, and then proves an analogue of Kronecker's theorem, namely that for a finite system of d.p's in n indeterminates, there exists a system composed of n + 1 linear combinations of the d.p's that has the same manifold as the original system. <br /> In chapter 8, the author proves the Riquier existence theorem, which is done in order to use it in the next chapter on partial differential algebra. This theorem states that for any infinite sequence of monomials, there is one of them which is a multiple of another with index value less than its own. This theorem is used to order (analytic) functions and their partial derivatives, using a 'marking' process. These considerations motivate the concept of a 'orthonomic' system of (partial) differential equations. <br /> In the last chapter, the author summarizes quickly what is known about partial differential algebra. Analogs of the earlier constructions are given, such as that of a partial differential polynomial. He proves that a every essential prime divisor of a nonzero partial differential polynomial has a characteristic set consisting of a single d.p. This gives a generalization of the 'spectral' theory outlined earlier for differential algebra. In addition, he gives an outline of an 'elimination theory' of algebraic partial differential equations using the operations of differentiation, rational operations, and factorizations.	2003-03-06
1211046:US	50702879	R3EEJHZFF2V335	0805316000	367322202	Semi-Simple Lie Algebras and Their Representations (Frontiers in Physics)	Books	4	6	7	N	N	A pleasant read	Not only are Lie algebras interesting and important from a mathematical standpoint, an in-depth understanding of them is essential if one is to fully comprehend the physical theories of elementary particle interactions. All of these theories, from quantum field theories to string theories, to the current research on D-branes and M-theories, are dependent on the theory of Lie groups and Lie algebras. Because of its relaxed informal style, this book would be a good choice for the physics graduate student who intends to specialize in high energy physics. Those interested in mathematical rigor would probably want to select another text. Because of space restrictions, only the first thirteen chapters will be reviewed here.<br /> In chapter 1 the author begins the study of SU(2), the group of unitary 2 x 2 matrices of determinant 1. He does this by first considering the matrix representations of infinitesimal rotations in 3-dimenensional space. &quot;Exponentiating&quot; these matrices gives the finite rotational matrices. He then shows that the consideration of products of finite rotations involves knowledge of the commutators of the infinitesimal rotations. Viewing these commutators abstractly motivates the definition of a Lie algebra. He then shows that the rotation matrices form a (3-dimensional) 'representation' of the Lie algebra. Higher-dimensional representations he shows can be obtained by analogies to what is done in quantum mechanics, via the addition of angular momentum and are parametrized by spin (denoted j). The representation of smallest dimension is given by j = 1/2 and corresponds to SU(2). He is careful to point out that the rotations in 3 dimensions and SU(2) have the same Lie algebra but are not the same group.<br />The constructions in chapter 1, particularly the concept of &quot;exponentiating&quot;, are central to the understanding of Lie algebras in general. This is readily apparent in the next chapter wherein he studies the Lie algebra of SU(3), the 3x3 unitary matrices of determinant 1. SU(3) has to rank as one of the most important groups in elementary particle physics. The (abstract) Lie algebra corresponding to the commutation relations of this group have various representations, the 8-dimensional, or &quot;adjoint&quot; representation being one of great interest. The author finds the famous 'Cartan subalgebra' of the Lie algebra, shows that it 2-dimensional and Abelian, and how eigenvectors of the adjoint operator can form a basis for the Lie algebra, as long as this operator corrresponds to an element of the Cartan subalgebra. Further, he shows that the eigenvalues of this operator depend linearly on this element, and then defines functionals on the Cartan subalgebra, called the roots, and they form the dual space to the Lie algebra. Dual spaces are familiar to physicists in the Dirac bra-ket formalism.<br /> The geometry of Lie algebras is very well understood and is formulated in terms of the roots of the algebra and a kind of scalar product (except is not positive definite) for the Lie algebra called the 'Killing form'. The Killing form is defined on the root space, and gives a correspondence between the Cartan subalgebra and its dual. The author then shows how to use the Killing form to obtain a scalar product on the root space, and this scalar product illustrates more clearly the symmetry of the Lie algebra. The property of being semisimple is then defined abstractly by the author, namely a Lie algebra with no Abelian ideals. He states, but does not prove entirely, that the Killing form is non-degenerate if and only if the Lie algebra is semisimple.<br /> The treatment becomes more abstract in chapter 4, wherein the author studies the structure of simple Lie algebras, since every semisimple algebra can be written as the sum of simple Lie algebras. The author shows how to obtain the Cartan subalgebra in general, motivating his procedures with what is done for SU(3). He also proves the invariance of the Lie algebra and shows that it is the only invariant bilinear form on a simple Lie algebra. After a detour on properties of representations in chapter 5, wherein he constructs some useful relations for adjoint representations, the author uses these to again study the structure of simple Lie algebras in chapters 6 and 7. This involves the notion of positive and negative roots, and simple roots, and from the latter the author constructs the 'Cartan matrix', which summarizes all of the properties of the simple Lie algebra to which it corresponds. The author shows how the contents of the Cartan matrix can be summarized in terms of 'Dynkin diagrams'.<br /> These considerations allow an explicit characterization of the 'classical' Lie algebras: SU(n), SO(n), and Sp(2n) in chapter 8. The Dynkin diagrams of these Lie algebras are constructed. Then in chapter 9, the author considers the 'exceptional' Lie algebras, which are the last of the simple Lie algebras (5 in all). Their Dynkin diagrams are also constructed explicitly.<br /> The author returns to representation theory in chapter 10, wherein he introduces the concept of a 'weight'. These come in sequences with successive weights differing by the roots of the Lie algebra. A finite dimensional irreducible representation has a highest weight, and each greatest weight is specified by a set of non-negative integers called 'Dynkin coefficients'. He then shows how to classify representations as 'fundamental' or 'basic', the later being ones where the Dynkin coefficients are all zero except for one entry.<br /> In complete analogy with the theory of angular momenta in quantum mechanics, the author illustrates the role of Casimir operators in chapter 11. Freudenthal's recursion formula, which gives the dimension of the weight space, is used to derive Weyl's formula for the dimension of an irreducible representation in chapter 13. The reader can see clearly the power of the 'Weyl group' in exploiting the symmetries of representations.nce of the Lie algebra and shows that it is the only invariant bilinear form on a simple Lie algebra. After a detour on properties of representations in chapter 5, wherein he constructs some useful relations for adjoint representations, the author uses these to again study the structure of simple Lie algebras in chapters 6 and 7. This involves the notion of positive and negative roots, and simple roots, and from the latter the author constructs the 'Cartan matrix', which summarizes all of the properties of the simple Lie algebra to which it corresponds. The author shows how the contents of the Cartan matrix can be summarized in terms of 'Dynkin diagrams'. <br /> These considerations allow an explicit characterization of the 'classical' Lie algebras: SU(n), SO(n), and Sp(2n) in chapter 8. The Dynkin diagrams of these Lie algebras are constructed. Then in chapter 9, the author considers the 'exceptional' Lie algebras, which are the last of the simple Lie algebras (5 in all). Their Dynkin diagrams are also constructed explicitly. <br /> The author returns to representation theory in chapter 10, wherein he introduces the concept of a 'weight'. These come in sequences with successive weights differing by the roots of the Lie algebra. A finite dimensional irreducible representation has a highest weight, and each greatest weight is specified by a set of non-negative integers called 'Dynkin coefficients'. He then shows how to classify representations as 'fundamental' or 'basic', the later being ones where the Dynkin coefficients are all zero except for one entry. <br /> In complete analogy with the theory of angular momenta in quantum mechanics, the author illustrates the role of Casimir operators in chapter 11. Freudenthal's recursion formula, which gives the dimension of the weight space, is used to derive Weyl's formula for the dimension of an irreducible representation in chapter 13. The reader can see clearly the power of the 'Weyl group' in exploiting the symmetries of representations.	2003-03-01
1213983:US	50702879	R1CC29CRJMGF83	0486602699	244436658	The Theory of Groups and Quantum Mechanics (Dover Books on Mathematics)	Books	4	17	18	N	N	Still a good book	Written in the early years of the quantum theory, the author of this book foresaw the importance of considering symmetry in physics, the use of which now pervades most of theoretical high energy physics. Indeed, with the advent of gauge theories, and their experimental validation, it is readily apparent that symmetry principles are here to stay, and are just not accidental curiosities. A reader of the book can still gain a lot from the perusal of this book, in spite of its date of publication and its somewhat antiquated notation. Older books also have the advantage of discussing the material more in-depth, and do not hesitate to use hand-waving geometrical pictures when appropriate. This approach results in greater insight into the subject, and when coupled with eventual mathematical rigor gives it a solid foundation. One example where the discussion is superior to modern texts is in the author's discussion of group characters and their application to irreducible representations and spectra in atomic systems.<br /> The reader will no doubt probably want to couple the reading of this book with a more modern text so as to alleviate the notational oddities in this book. The author's presentation is clear enough though to make an appropriate translation to modern notation. The reader will then be well prepared to tackle more advanced material in mathematical and theoretical physics that make use of the group-theoretic constructions that take place in this book.	2003-02-26
1216259:US	50702879	R3MRSE55ZAOZUC	0192880802	833074933	Clones, Genes, and Immortality: Ethics and the Genetic Revolution (Life Sciences Miscellaneous Publications)	Books	5	5	5	N	Y	A calm, rational approach	Discussions and debates on the ethics of genetic engineering these days are frequently accompanied by ridicule and vituperation. An objective observer interested in the issues may be revolted by this situation, and with complete justification. Genetic engineering is a powerful technology, and its ramifications for all life on Earth, both human and non-human, entail that everyone, especially those directly involved in its practice, be very aware of the deep moral issues involved in its use. Scare tactics by those against genetic engineering, exaggerated claims by those supporting it, and very bitter verbal and written exchanges have characterized both sides of the debate, and therefore a calm, rational approach is gravely needed.<br /> The author takes such an approach in this book, and this makes it one of the few in print that would be of interest to those readers who want to take a look at the issues without any masks. The author is clearly supportive of genetic engineering, but that is not to say that every reader will finish the book with the same attitude as the author, for the clarity in which he poses his arguments may allow a reader to formulate alternative points of view. There are many interesting discussions in the book, and it will no doubt, if read with an open, scientific mind, serve as a refreshing alternative to current ones on the subject.<br /> Another virtue of the book is that a reader need not be an expert in genetics in order to follow the presentation, for the author defines the necessary terminology. For example, very early in the book he is careful to  differentiate between genetic manipulations of the 'somatic line' and those of the 'germ line', the former limited to cells of individuals and not inherited by their progeny, the latter effecting the genomes of individuals and their offspring. Germ line manipulation has been the main topic of confrontation, although somatic line manipulation has also taken a hit recently, due to some problems that have arisen with gene therapies.<br /> Many possible scenarios and consequences of genetic engineering are overviewed in the book. For example, the author discusses the possibility, which has been done with various animals, of inserting additional genes into human beings, creating then a 'transgenic' human, this being done primarily to enhance various capabilities. The author though is quick to point out that such procedures have not yet been perfected for use in humans and may therefore be dangerously disruptive. Another fascinating possibility discussed in the book is 'parthenogenesis', this being the process in which unfertilzed human eggs can be stimulated to grow without fertilization, giving a near clone of the mother. He also notes though that there is some evidence that parthenogenetically stimulated embryos are not easily implanted.<br /> These two examples are an illustration of the fact that all through the book the author exhibits a keen intellectual honesty about the issues at hand, carefully noting what is possible now and what is not for biotechnology. He is well aware that developments in genetic engineering come very quickly, and one must therefore exhibit diligence of the highest order. He also though presents a strong case for doing genetic engineering, in both humans and non-humans. Its possibilities are awesome for the quality of all life on the entire planet.<br /> The technology of genetic engineering should be of concern to everyone alive today, and after studying this book, readers will gain much insight into its ramifications and its ethical foundations. More extensive research and testing will no doubt prove the viability of genetic engineering in most cases of interest. Those techniques proved unsafe or not viable should be abandoned without hesitation, but those showing promise should be used or applied immediately, with no guilt or hesitation. The new species of animals and plants, the new disease cures, and the ability to select the genetic makeup of offspring and even to eventually bring about transgenic humans, are some of the most exciting possibilities to contemplate for genetic engineering.<br /> Shortly after the advent of flight, its critics stated that \\"if humans were meant to fly they would have had wings\\".<br /> But (some) humans will eventually have wings....and they will fly.ect the genetic makeup of offspring and even to eventually bring about transgenic humans, are some of the most exciting possibilities to contemplate for genetic engineering. <br /> Shortly after the advent of flight, its critics stated that \\"if humans were meant to fly they would have had wings\\". <br /> But (some) humans will eventually have wings....and they will fly.	2003-02-24
1218658:US	50702879	R2WOG57WBKTC3N	0198520115	290619543	The Principles of Quantum Mechanics (International Series of Monographs on Physics)	Books	4	50	54	N	N	Still worthwhile to read and study	This book goes all the way back to 1930, the year it was first published, and a time when quantum physics was undergoing rapid development, both in terms of applications and theory. The author was one of the major contributors to these developments, and in this book has outlined his idiosyncratic approach to quantum physics, including relativistic quantum mechanics and quantum electrodynamics.The author's insight into quantum physics is extraordinary and that makes this book unique among the books on the subject.<br /> The author introduces immediately the principle of superposition as the tour-de-force of quantum theory in chapter 1 after discussing the inadequacy of classical mechanics in explaining the data on specific heat and atomic spectra. The polarization and interference of photons is used to motivate the principle of superposition, and then the concept of a quantum state. The famous Dirac bra-ket formalism is brought in to give the state concept a mathematical formulation. This is followed in chapter 2 by a mathematical formulation of observables, these being operators that act on the kets, with their adjoints operating on the bras. The eigenvalues of these operators are then the physically realizable results of experiments. The author's discussion on the physical interpretation of this formalism is fascinating and should be read by anyone desiring an in-depth understanding of quantum physics.<br /> The formalism up to this point has been purely algebraic, so to apply it to physical problems one needs a representation. This is done in chapter 3, wherein the author also introduces the famous &quot;Dirac delta function&quot;. The commutation relations between observables, not of course arising at all in the classical theory, are discussed in chapter 4. The  &quot;Poisson bracket goes to commutator&quot; is the theme of the chapter, and one that was followed for several decades, until the advent of the path integral formulation. The Schroedinger and Heisenberg representations make their appearance here, as well as the Heisenberg uncertainty principle.<br /> Once the ideas of the preceeding chapters are accepted, there is no turning back on the consequences they entail, some of them quite bizarre at first encounter. This already becomes apparent even when solving for the time development of quantum systems, which is done in chapter 10 for the free particle and motion of wave packets.<br /> More applications are treated in chapter 11, such as the harmonic oscillator, and the author shows how to incorporate angular momentum and spin into the quantum theory. He also treats the central force problem, and derives the selection rules for the hydrogen atom. Readers get their first taste of perturbation theory in chapter 12, via the problem of atom in an external electric field. All of these problems illustrate beautifully the ability of quantum physics to fit the experimental data.<br /> Particle accelarators were of course coming on to the scene at the time this book was published, and so collision problems are discussed in chapter 13. The important effects of resonance scattering and spontaneous emission are discussed in detail by the author.<br /> Even more anti-classical phenomena in quantum physics arise in chapter 14, which deals with systems of identical particles. The description of these is done with symmetrical and antisymmetrical states, and the resulting boson/fermion distinction is outlined and discussed in detail. The author also gives an interesting discussion of permutations as dynamical variables. He constructs a theory for a system of n similar particles when states of any kind of symmetry properties are allowed. The theory does not correspond to any existing particles (and the author acknowledges this), but he uses it as an approximation to a collection of electrons. Permutations are constants of motion in this theory, and for a system of electrons he shows that more than two electrons cannot be in the same orbital state. This &quot;effective&quot; theory of electrons is interesting because in its derivation one sees the explicit need for spin variables, even though spin forces are neglected by the author. This is a neat illustration of the Pauli exclusion principle.<br /> In chapter 20, the author develops a theory of radiation, giving a first glance at relativistic quantum theory, i.e. quantum field theory. The theory as he constructs initially however should more properly be called many-body quantum theory, as no explicit &quot;field quantization&quot; is performed, although his result is essentially the same: a collection of quantized harmonic oscillators which he shows to be equivalent to a collection of bosons in stationary states. He applies this theory to the case of a collection of photons interacting with an atom. When describing the interactions between photons and atoms, he then makes the connection with fields, treating the atom first classically and the field of radiation as a vector field. The resulting theory is quantized using the &quot;canonical&quot; approach and the author derives all the now standard quantities, such as the Kramers-Heisenberg dispersion formula for photon scattering.<br /> Dirac is well-known for his work in quantum field theory, and he delves into it in the last two chapters. His famous derivation of the &quot;Dirac equation&quot; is given here, but interestingly, he does not refer to the wave functions in this equation as &quot;spinors&quot;. He does show the equation is Lorentz invariant, and then studies the electron in a central force using the equation, giving the all-important fine structure of the energy levels. And of course, the theory of the positron is discussed here. The treatment of quantum electrodynamics is done from a canonical quantization viewpoint,  and the discussion of electrons and positrons is now legendary.e same orbital state. This &quot;effective&quot; theory of electrons is interesting because in its derivation one sees the explicit need for spin variables, even though spin forces are neglected by the author. This is a neat illustration of the Pauli exclusion principle. <br /> In chapter 20, the author develops a theory of radiation, giving a first glance at relativistic quantum theory, i.e. quantum field theory. The theory as he constructs initially however should more properly be called many-body quantum theory, as no explicit &quot;field quantization&quot; is performed, although his result is essentially the same: a collection of quantized harmonic oscillators which he shows to be equivalent to a collection of bosons in stationary states. He applies this theory to the case of a collection of photons interacting with an atom. When describing the interactions between photons and atoms, he then makes the connection with fields, treating the atom first classically and the field of radiation as a vector field. The resulting theory is quantized using the &quot;canonical&quot; approach and the author derives all the now standard quantities, such as the Kramers-Heisenberg dispersion formula for photon scattering. <br /> Dirac is well-known for his work in quantum field theory, and he delves into it in the last two chapters. His famous derivation of the &quot;Dirac equation&quot; is given here, but interestingly, he does not refer to the wave functions in this equation as &quot;spinors&quot;. He does show the equation is Lorentz invariant, and then studies the electron in a central force using the equation, giving the all-important fine structure of the energy levels. And of course, the theory of the positron is discussed here. The treatment of quantum electrodynamics is done from a canonical quantization viewpoint,  and the discussion of electrons and positrons is now legendary.	2003-02-22
1221449:US	50702879	R2GMSX6K4SNB1U	0471624128	4298562	Quantum Theory of Solids	Books	4	16	17	N	N	Still a good book	It is too bad this book is out of print, for it gives a good introduction to the quantum theory as applied to condensed matter, despite the many advances that have taken place since the date of publication, such as high-temperature superconductivity, the fractional quantum Hall effect, and nanoscale physics. Therefore, if a copy can be found, it is still worth perusing and having on one's shelf. I only read the first 8 chapters of the book, so my review will be confined to them.<br /><br /> After a brief introduction to the mathematics needed in the book, the author begins in chapter 2 with a treatment of acoustic phonons, which arise from the canonical quantization of the transverse motion of a continuous elastic line under tension. This object is handled using the Lagrangian formalism, and after finding the Hamiltonian density, employing a canonical transformation, the (bosonic) creation and annihilation operators are found: phonon excitations. Both longitudinal and transverse modes are shown to exist in general. Bogoliubov transformations are then used to show how phonons may arise in a system of weakly interacting particles. The author then derives the expression for the velocity of \\"second sound\\" in a phonon gas. Experimental evidence for second sound in liquid helium was known at the time of publication, but since then evidence has accumulated in Bose gases and in certain types of crystals, such as KTaO and SrTiO. The phenomenon of second sound has also been of considerable interest in the study of nonlinear optical phenomena in smectic liquid crystals. The author also discusses the occurence of van Hove singularities in the phonon frequency distribution function, and points to their connection with Morse theory.<br /> In chapter 3 the author concentrates his attention on plasmons, which arises from longitudinal excitations in an electron gas, and optical phonons in ionic crystals. He then extends the latter analysis to include the interaction of optical phonons with photons, which he also treats using quantum field theory, giving what he calls a quantum theory of a classical dielectric.<br /> The theory of spin waves, or \\"magnons\\" is discussed in chapter 4, wherein the author first treats ferromagnetic magnons via the consideration of the Hamiltonian consisting of nearest-neighbor exchange and Zeeman contributions. The dispersion relation for both optical and acoustical magnons in a spin system forming a Bravais lattice is derived and compared with experiment for magnetite. The author then treats antiferromagnetic magnons and discusses the zero-point sublattice magnetization and the heat capacity of antiferromagnets. He then returns to ferromagnetic magnons but from a more macroscopic point of view, treating the magnetization as a macroscopic field, rather than dealing with individual spins. Lastly, he considers the excitation of ferromagnetic magnons by parallel pumping and the temperature dependence of effective exchange.<br /> After a short review of the Hartree-Fock approximation in chapter 5, the author considers the all-important electron gas in chapter 6. The electron gas, particularly in two dimensions, has been the subject of great interest since this book was first published, not only because of its technological importance, but also its role in the quantum Hall effect and the fractional quantum Hall effect. Although density functional and renormalization group methods are the current favored ones for studying the electron gas, readers can still gain much from the reading of the chapter. The author concentrates his attention on the approximate calculation of the correlation energy of the degenerate electron gas, particularly at high density. To do this he uses the self-consistent field approach and he exploits the frequency and wavevector dielectric constant as a tool for studying many-body interactions. Several bread-and-butter topics in quantum many-body theory appear in this chapter, such as the linked cluster expansion, which appear in other more complicated (relativistic) contexts, such as high energy physics.<br /> The author introduces polarons in chapter 7 as a consequence of any deformation of the ideal periodic lattice of positive ion cores on the motion of conduction electrons, and notes that even the zero-point motion of phonons effects this motion. The interaction of an electron with the lattice results in a \\"lattice polarization field\\" around the electron, and the resulting composite particle is the polaron, which, as expected, has a larger effective mass then the electron in an unperturbed lattice. The electron-phonon interaction results in resistivity, results in attenuation of ultrasonic waves in metals, and results in some cases to an attractive interaction between electrons, this being one of the precursors of superconductivity. The problem of electron-phonon interaction in metals has been the subject of much study in attempts to give quantum field theory a rigorous mathematical foundation, particularly via the study of the \\"jellium model\\".<br /> Chapter 8 is very important, and its content reveals again the age of the book. The phenomenon of superconductivity, and its description by the Bardeen-Cooper-Schrieffer theory, is known as one of the triumphs of the quantum theory of solids. Of course, when this book was published, superconducting materials at high temperature, were not known. The author though gives a detailed overview of the BCS theory, starting with the Hamiltonian for the electrons, phonons, and their first-order interactions (the strength measured by a certain real constant D). Using a canonical transformation, the author reduces the Hamiltonian to one with no off-diagonal terms of order D. This results in an expression for an electron-electron interaction which can be attractive for excitation energies in a certain range (involving the Debye energy). Keeping only this interaction in the Hamiltonian, for wave vectors that satisfy this range constraint, the author studies the properties of bound electron pairs, and shows how they bring about superconductivity. He also outlines an alternative solution to the BCS equation, using what he calls the equation-of-motion method. More modern treatments of superconductivity employ the use of Higgs fields and the renormalization group, these approaches shedding light on whether one can indeed view superconductivity as a \\"macroscopic manifestation of quantum physics\\".ter expansion, which appear in other more complicated (relativistic) contexts, such as high energy physics. <br /> The author introduces polarons in chapter 7 as a consequence of any deformation of the ideal periodic lattice of positive ion cores on the motion of conduction electrons, and notes that even the zero-point motion of phonons effects this motion. The interaction of an electron with the lattice results in a \\"lattice polarization field\\" around the electron, and the resulting composite particle is the polaron, which, as expected, has a larger effective mass then the electron in an unperturbed lattice. The electron-phonon interaction results in resistivity, results in attenuation of ultrasonic waves in metals, and results in some cases to an attractive interaction between electrons, this being one of the precursors of superconductivity. The problem of electron-phonon interaction in metals has been the subject of much study in attempts to give quantum field theory a rigorous mathematical foundation, particularly via the study of the \\"jellium model\\". <br /> Chapter 8 is very important, and its content reveals again the age of the book. The phenomenon of superconductivity, and its description by the Bardeen-Cooper-Schrieffer theory, is known as one of the triumphs of the quantum theory of solids. Of course, when this book was published, superconducting materials at high temperature, were not known. The author though gives a detailed overview of the BCS theory, starting with the Hamiltonian for the electrons, phonons, and their first-order interactions (the strength measured by a certain real constant D). Using a canonical transformation, the author reduces the Hamiltonian to one with no off-diagonal terms of order D. This results in an expression for an electron-electron interaction which can be attractive for excitation energies in a certain range (involving the Debye energy). Keeping only this interaction in the Hamiltonian, for wave vectors that satisfy thisrange constraint, the author studies the properties of bound electron pairs, and shows how they bring about superconductivity. He also outlines an alternative solution to the BCS equation, using what he calls the equation-of-motion method. More modern treatments of superconductivity employ the use of Higgs fields and the renormalization group, these approaches shedding light on whether one can indeed view superconductivity as a \\"macroscopic manifestation of quantum physics\\".	2003-02-20
1224863:US	50702879	R22LB6SBW4EWBR	0691016275	813435900	An Interpretive Introduction to Quantum Field Theory	Books	3	10	11	N	Y	A fair introduction, but needs to be greatly expanded	Philosophical debate on quantum mechanics was very intense and widespread in the twentieth century, and it continues without abatement in the twenty-first. Philosophical issues in quantum field theory (QFT) however are not as common, this being due possibly to the level of physics and mathematics needed to master the subject. This book is one of the few that has appeared that deal with these issues, and it serves as a fairly good introduction to them.<br /> In the preface, the author describes quantum field as a subject that is &quot;notoriously hard to learn&quot;. He admits having severe difficulty in the learning of it, which he blames on the lack of good presentations of the subject. One can easily find though superb explanations of QFT in the literature, both in preprint and textbook form. His presentation of QFT could loosely be described as the &quot;older&quot; quantum field theory, since he does not address guage theories and makes no use of modern mathematical formalism. By his own admission, all of the ideas in the book were known by 1950.<br /> The title of the book reflects the author's view of an interpretation of a theory, namely that it gives a similarity relation that is hypothesize to hold between a model and the properties of things that the model is supposed to characterize. This notion of similarity is a purely qualitative one though, as is typical in most discourses on philosophy. For the author, the issue for interpretation is the phenomenon of &quot;superposition&quot; in QFT, and he also endeavors to show that the &quot;particle&quot; intepretation of QFT is at equal level with the &quot;field&quot; theoretic one. He believes that current views on QFT get the particle aspect wrong, nor show how the particle and field aspects fit together. It is the particle labeling he says, that causes problems, and his solution is via the Fock space formalism, which avoids what he calls the &quot;surplus structure&quot; of conventional quantum mechanics, and which avoids the temptation to ascribe properties to particles. Instead he uses a conception of &quot;quanta&quot;, which gives information only on what patterns of properties are exhibited. The Fock space basis states, and consequently the operators are indexed by space-time points, entailing naturally an interpretation of the theory in terms of fields. However, the notion of &quot;operator-valued fields&quot; that is typically expoused by practioners is criticized by the author and he lays out a different interpretation (but again using the Fock formalism), using as examples coherent states and vacuum fluctuations. He recognizes, quite correctly, that an interpretation as a quantum field takes place in a loose analogical relation to classical physics.<br /> No treatment of quantum field theory could be complete without including a discussion of renormalization. The author does not really add anything new in his discussion, as a reader can gain essentially the same content and insight (and more) in currrent papers, preprints, monographs, and textbooks on the subject. The use of cut-offs and dimensional regularization are briefly discussed, but no new insights are given into them. His solution to the problem of renormalization is what he calls a &quot;mask-of-ignorance&quot; approach, in which he asserts that a correct quantum field theory will be completely free of infinities. The correct theory is unknown, but this does not matter as long as attention is restricted to expressions that are independent of the cutoff and the regularization scheme. This has been said many times already though, by many different researchers and expositors of quantum field theory. A quantum field theory free from divergences has yet to be found, but another approach to the problem of infinities has taken over, that one going by the name of string theory.and which avoids the temptation to ascribe properties to particles. Instead he uses a conception of &quot;quanta&quot;, which gives information only on what patterns of properties are exhibited. The Fock space basis states, and consequently the operators are indexed by space-time points, entailing naturally an interpretation of the theory in terms of fields. However, the notion of &quot;operator-valued fields&quot; that is typically expoused by practioners is criticized by the author and he lays out a different interpretation (but again using the Fock formalism), using as examples coherent states and vacuum fluctuations. He recognizes, quite correctly, that an interpretation as a quantum field takes place in a loose analogical relation to classical physics.  <br /> No treatment of quantum field theory could be complete without including a discussion of renormalization. The author does not really add anything new in his discussion, as a reader can gain essentially the same content and insight (and more) in currrent papers, preprints, monographs, and textbooks on the subject. The use of cut-offs and dimensional regularization are briefly discussed, but no new insights are given into them. His solution to the problem of renormalization is what he calls a &quot;mask-of-ignorance&quot; approach, in which he asserts that a correct quantum field theory will be completely free of infinities. The correct theory is unknown, but this does not matter as long as attention is restricted to expressions that are independent of the cutoff and the regularization scheme. This has been said many times already though, by many different researchers and expositors of quantum field theory. A quantum field theory free from divergences has yet to be found, but another approach to the problem of infinities has taken over, that one going by the name of string theory.	2003-02-17
1227394:US	50702879	R3Q8M7K92G5N9	0521099498	324894928	Elements of Advanced Quantum Theory	Books	4	10	11	N	N	Good introduction to many-body quantum theory	For the reader interested in a modern introduction to quantum field theory using the latest mathematical tools and one that will take one to the frontiers of research, this would not be an appropriate book to begin from. One might describe it as \\"the old quantum field theory\\", as it approaches the subject from the standpoint of what was being done in the sixties and seventies. That is not to say however that it could not be used by someone interested in going into the field of condensed matter physics for example. The many-body quantum physics used in that field is detailed very effectively in this book. Readers who are interesting in high energy physics though should perhaps select another book.<br /> Some of the more unique and interesting discussions in this book that are still relevant today include: 1. The quantization of continuous fields and the treatment of the Rayleigh scattering of phonons. Here one is introducing a point mass into a continuous medium and asking for its effect on the phonon field. The familiar Rayleigh scattering formula is derived, and the author points out that for scattering between modes containing many particles, the transition rate also depends on the state of occupation of the mode into which a phonon is going, which is the familiar stimulated emission. Replacing the point mass by an extended object, such as a grain boundary, and attempting to solve for the phonon scattering is non-trivial and has been the subject of much research. 2. The fermion-boson interaction and the origin of the concept of a \\"polaron\\". This arises in the consideration of the interaction of an electron with the optical modes in a polar crystal. The author calculates the self-energy of the fermion in the boson field, and shows it leads to a correction of the relationship between the energy and momentum of the electron, giving the electron an \\"effective mass\\". The effective mass is dependent on the mass of the electron and the effective dielectric constant. A polaron is then this \\"dressed\\" electron which is \\"more massive\\" than the electron because of the electron's interaction with the optical modes. Also, in the context of perturbation theory and the S-matrix, the author eliminates the term in the fermion-boson interaction in order to study purely the properties of the fermion field. This means that the interaction Hamiltonian operates only on the vacuum state for bosons, and thus only excitations of single bosons into and out of the vacuum are considered. This results in an effective interaction between the fermions, due to the exchange of bosons, and this interaction can be attractive or repulsive, depending on the range of momenta. This effective interaction between electrons due to the exchange of virtual phonons is the explanation for superconductivity. The fermion-boson interaction is still of considerable interest in the context of explanations for high-temperature superconductivity. 3. The derivation of the Kubo formula as a first crack at the formulation of transport theory in the quantum realm. The author explains the formula as one that shows that conductivity is an intrinsic property of quantum-mechanical systems, in that the application of a weak electron field will make apparent the time-correlations of the electric current fluctuations in equilibrium. He cautions the reader though that practical calculations may make the use of the Kubo formula problematic. The author returns to the Kubo formula later in his treatment of the spectral representation of the dielectric function, and proves a case of the famous fluctuation-dissipation theorem. A comparison between the Kubo formula shows that dissipation has been expressed in terms of Fourier transform of a two-body time-correlation function which describes the fluctuations in the many-body system. The Kubo formula and its generalizations are still discussed widely in the context of nonequilibrium statistical mechanics, quantum transport theory, and the theory of mesoscopic systems. 4. An illustration of the properties of the time-independent Green's function via the consideration of impurity states in a medal. The author introduces a single impurity atom with delta function potential at a fixed point in the metal, and calculates the Green function of the perturbed system in terms of the unperturbed one. The resulting singularities in the Green function motivate the author to consider the role of the strength of the potential, and he shows that for a certain range of this strength, one obtains a bound state or \\"localized\\" level. 5. The treatment of the random phase approximation. The author writes the Hamiltonian for an interacting system of fermions in a way that makes the density fluctuations of various wavelengths manifest. Noting the the commutator of the density part with the Hamiltonian results in an intractable problem, he replaces the operator products by expectation values (or ensemble averages for finite temperature). This results in the off-diagonal terms cancelling one another, due to them being randomly out of phase with each other. He then proceeds to solve for the equations of motion of the system, obtaining a dispersion formula for the frequency of a self-consistent excited mode of the system, which he then views as a pole of an approximation to the inverse dielectric function. He mentions, but does not discuss in detail, what this implies for the theory of an electron gas in a metal, namely the phenomenon of dielectric screening and the existence of plasmons. 6. The brief but informative discussion of (zero-temperature) superconductivity. He accounts for the phenomenon by the use of an effective electron-electron interaction which is attractive when the energy difference of the two electron states is small. This interaction is modeled by a small negative constant for momentum transfers between these types of electrons, and zero otherwise. A perturbation calculation then shows that the effect of this interaction is infinite for any pair of electrons with exactly opposite momenta, and thus one obtains a bound state, the famous Cooper pair. The author then goes on to show the existence of an energy gap for the system, thus showing that a superconducting system does not have excitations of vanishingly small energy.of mesoscopic systems. 4. An illustration of the properties of the time-independent Green's function via the consideration of impurity states in a medal. The author introduces a single impurity atom with delta function potential at a fixed point in the metal, and calculates the Green function of the perturbed system in terms of the unperturbed one. The resulting singularities in the Green function motivate the author to consider the role of the strength of the potential, and he shows that for a certain range of this strength, one obtains a bound state or \\"localized\\" level. 5. The treatment of the random phase approximation. The author writes the Hamiltonian for an interacting system of fermions in a way that makes the density fluctuations of various wavelengths manifest. Noting the the commutator of the density part with the Hamiltonian results in an intractable problem, he replaces the operator products by expectation values (or ensemble averages for finite temperature). This results in the off-diagonal terms cancelling one another, due to them being randomly out of phase with each other. He then proceeds to solve for the equations of motion of the system, obtaining a dispersion formula for the frequency of a self-consistent excited mode of the system, which he then views as a pole of an approximation to the inverse dielectric function. He mentions, but does not discuss in detail, what this implies for the theory of an electron gas in a metal, namely the phenomenon of dielectric screening and the existence of plasmons. 6. The brief but informative discussion of (zero-temperature) superconductivity. He accounts for the phenomenon by the use of an effective electron-electron interaction which is attractive when the energy difference of the two electron states is small. This interaction is modeled by a small negative constant for momentum transfers between these types of electrons, and zero otherwise. A perturbation calculation then shows that the effect of this interaction is infinite for any pair of electrons with exactly opposite momenta, and thus one obtains a bound state, the famous Cooper pair. The author then goes on to show the existence of an energy gap for the system, thus showing that a superconducting system does not have excitations of vanishingly small energy.	2003-02-15
1230583:US	50702879	R3KGXKMVZMUEGY	0521368693	895163050	Speakable and Unspeakable in Quantum Mechanics (Collected Papers on Quantum Philosophy)	Books	4	10	11	N	N	Still the subject of much debate	It would be difficult to find a more controversial topic in the philosophy of physics than what is discussed in this book. But its implications go beyond philosophy, in that some of the ideas in the book have been used in the attempts to build a quantum computer. Since it was written at a time when quantum computation was not taken as seriously as it is now, if at all, it is not surprising that experimental backing for the content is not included in the book. That such experimental evidence is lacking in the book is also a sign that such experiments are not conclusive in the verification of what the author expounds in the book. I can only speak for myself here, but having undertaken a painstaking look at the literature on the experiments purporting to verify entanglement and the &quot;Bell inequalities&quot;, I have yet to find one that does so in a convincing way. The mathematical formalism employed by the author in the book allows him to prove some interesting theoretical conclusions, and those who work in the field of quantum computation even more so, but real-world experiments are lagging considerably behind these purely theoretical constructions.<br /> The reader will find good discussions of the Einstein-Podolsky-Rosen and the de Broglie-Bohm delayed-choice &quot;thought experiments&quot; in the book, as well as a few other interesting discussions, such as the problem of hidden variables all from a pretty much philosophical viewpoint. The author however does not hesitate to use mathematical formalism where appropriate. Some of his conclusions will depend on what philosophical &quot;school of thought&quot; the reader is in. For example, in his discussion on hidden variables, he refers to the work of the mathematician Andrew Gleason on the impossibility of hidden variables. However, Gleason's proof would be unacceptable to a reader from the &quot;intuitionist&quot; school of mathematics, since the proof is nonconstructive. The author though does give an interesting analysis of why the von Neumann proof, and others after him (due to for example Jauch, Piron, and Gleason), are of limited relevance when analyzed in depth. Hence, for those who accept non-constructivism in mathematics, the Gleason proof would still not be a refutation of the existence of hidden variables in quantum mechanics. The author analyzes the arguments of von Neumann, Jauch, Piron, and Gleason, and rejects them mostly on the grounds of their demand that dispersion-free states must have the same properties as the usual quantum-mechanical states that allow all the successful predictions of quantum mechanics. The dispersion-free states could still reproduce the measurable peculiarities of quantum mechanics when they are averaged over, the author concludes.<br /> Along these same lines, the author also gives an interesting discussion of the argument of Einstein, Podolsky, and Rosen on the incompleteness of quantum mechanics. He formulates their requirement that quantum mechanics contain additional variables mathematically and then proceeds to show that it is incompatible with the statistical predictions of quantum mechanics. These extra variables or parameters must have a probability distribution, and it is then shown, for a pair of spin-1/2 particles in a singlet spin state, and moving in opposite directions, that these extra variable do not give the quantum mechanical expectation value for the singlet state. The author concludes that in a theory in which parameters are added to quantum mechanics to determine the results of individual measurements without changing the statistical predictions, there must be a mechanism in which the setting of one measuring device influences  the reading of another instrument, no matter how remote. He concludes that instantaneous propagation would exist in such a theory, which violates Lorentz invariance. His proof is straightforward to follow, but he does use a classical (Kolmogorovian) expression for the expectation value of the two spin components. This has provoked some debate, and has brought about a notion of &quot;contextual probability&quot;, which is a probability theory that follows more on the lines of the frequency approach of von Mises. Also, the notion of locality that the author employs has been seriously challenged by some researchers, who assert that the real notions of space and time have not been used by Bell in the proof.<br /> Therefore it could be said without a doubt that this book will introduce the reader to the raging debate on locality and other issues in the &quot;foundations&quot; of quantum physics. Papers supporting Bell and those against his conclusions appear frequently on the preprint servers. Since this book is widely quoted in these papers, it should perhaps then be on the shelf of all those readers who really have a desire to understand the mysteries of quantum mechanics.of the two spin components. This has provoked some debate, and has brought about a notion of &quot;contextual probability&quot;, which is a probability theory that follows more on the lines of the frequency approach of von Mises. Also, the notion of locality that the author employs has been seriously challenged by some researchers, who assert that the real notions of space and time have not been used by Bell in the proof. <br /> Therefore it could be said without a doubt that this book will introduce the reader to the raging debate on locality and other issues in the &quot;foundations&quot; of quantum physics. Papers supporting Bell and those against his conclusions appear frequently on the preprint servers. Since this book is widely quoted in these papers, it should perhaps then be on the shelf of all those readers who really have a desire to understand the mysteries of quantum mechanics.	2003-02-12
1235931:US	50702879	R1TLO0F4EBV9PG	0198507623	979137675	Anomalies in Quantum Field Theory (International Series of Monographs on Physics)	Books	4	10	11	N	N	A good overview	An understanding of quantum field theory cannot be done without the consideration of anomalies. The occurrence of anomalies in quantum field theory is relatively new, if compared with the time period that the subject has been around. This book gives an excellent overview of anomalies and is suitable for those who have a background in quantum field theory. Mathematicians may also find it of great interest, even though their standards of rigour may not always be respected in the book. The study of anomalies will entail also a background in mathematics that may not be acquired by a reader who has taken a prior course in quantum field theory. Hence the author spends the first part of the book outlining the mathematics needed, such as differential geometry, homotopy theory, de Rham cohomology, Lie groups, and fiber bundles. With the presence of this level of mathematics, one can say indeed that a course in quantum field theory in the 21st century is very different from one just 20 years ago.<br /> The author gives a motivation for the subject in the introduction to the book. He describes the origin of anomalies as the violation of a classically conserved current, which for gauge theories signals the breakdown of gauge symmetry, leading to an inconsistent theory. The elimination of anomalies then leads to a tightly constrained theory, and leads to physical predictions, such as the top quark. The author's concern in the book is the axial- or chiral anomaly that corresponds to an axial- or chiral fermion current.<br /> Even though it would be rare these days to find a beginning student of quantum field theory who had learned it without the consideration of path integrals, the author gives an overview of them in chapter 3 of the book. This chapter also includes a thorough discussion of the Faddeev-Popov method in non-Abelian gauge theories. One can view this as a method of &quot;Lagrange multipliers&quot; in quantum field theory, with the famous Faddeev-Popov ghosts playing the role of these multipliers. The author does a fine job of discussing why they are so important for the physics of quantum field theory, such as preserving the unitarity of the S-matrix and the proof of Ward identities.<br /> The study of anomalies begins in detail in chapter 4. The author discusses the origin of the Adler-Bell-Jackiw anomaly and why the various strategies of renormalization must lead to the same result. That radiative corrections or contributions from higher order perturbation theory will not change the nature of the anomaly is the statement of the Adler-Bardeen theorem, but the author does not prove this theorem. The author also relates the chiral anomaly to dispersion relations in the context of 2-dimensional quantum electrodynamics, and the connection of anomalies to the Dirac sea via the study of the Schwinger model of 2-dimensional quantum electrodynamics on a cylinder. The experimental consequences of anomalies are discussed by studying the decay of the neutral pion into two photons. A calculation of the transition amplitude for this decay using the LSZ reduction formula yields zero, and so anomalies are brought in force the decay rate to be in agreement with the experimental value. Lastly, the author discusses the non-Abelian anomaly in the last part of the chapter.<br /> Chapter 5 studies anomalies in the context of path integrals, via the methods of Fujikawa, arising as they do in the consideration of the transformation properties of the path integral measure. What is most interesting about this discussion is the author's statment of an &quot;uncertainty principle&quot;, namely that one cannot impose gauge and chiral symmetry simultaneously, due to the noncommutation of the Dirac operator and the gamma-five matrix. In addition, the author shows in detail the connection between the zeta function and the Fujikawa procedure.<br /> After a brief review of differential forms in chapter 6, the author studies the relation of anomalies to the Chern-Simons form in chapter 7. The transgression formula, which shows that the difference of two invariant polynomials is exact, is proven because of its central role in the rest of the book. Using a notion of a &quot;homotopy derivation&quot;, the first-order variaton of the Chern-Simons form is calculated and shown to give an anomaly formula.<br /> The derivation of the Wess-Zumino consistency condition is the main subject of chapter 7. This condition determines the anomaly, in that any solution of it that is not a gauge variation of a local functional is an anomaly, and is derived via the BRS formalism. The Wess-Zumino consistency condition is then shown to to correspond to a cocycle condition in the space of gauge potentials, and more generally in the context of the cohomology of Lie algebras.<br /> The author derives, from a stricly mathematical viewpoint, the Stora-Zumino descent equations in chapter 8, which show that a singlet anomaly in even dimensions determines the non-Abelian anomaly in two dimensons less.<br /> The &quot;covariant&quot; anomaly is discussed in chapter 10, which as the name implies transforms covariantly, unlike the consistent (&quot;Bardeen&quot;) anomaly considered so far. Noting that they arise from two different regularization schemes, the author then relates them via the Bardeen-Zumino polynomial.<br /> The most interesting chapter is the next one, which discusses the index theory of anomalies. Having very important mathematical connections, the presentation is very understandable but not rigorous mathematically, due to the use of the path integral. The author shows that anomalies are intimately connected with the topology of gauge theories, in particular the non-Abelian anomaly characterizes the nontrivial topology of the determinant bundle over the 2-sphere X 2n-sphere.<br /> Gravitational anomalies are the subject of the last chapter, wherein gauge transformations are the coordinate and Lorentz transformations. The work in preceeding chapters proceeds here without too much change, and the reader can see the fermionic contribution to the occurrence of anomalies, and the author again uses the BRS formalism to derive the descent equations.he Chern-Simons form in chapter 7. The transgression formula, which shows that the difference of two invariant polynomials is exact, is proven because of its central role in the rest of the book. Using a notion of a &quot;homotopy derivation&quot;, the first-order variaton of the Chern-Simons form is calculated and shown to give an anomaly formula. <br /> The derivation of the Wess-Zumino consistency condition is the main subject of chapter 7. This condition determines the anomaly, in that any solution of it that is not a gauge variation of a local functional is an anomaly, and is derived via the BRS formalism. The Wess-Zumino consistency condition is then shown to to correspond to a cocycle condition in the space of gauge potentials, and more generally in the context of the cohomology of Lie algebras. <br /> The author derives, from a stricly mathematical viewpoint, the Stora-Zumino descent equations in chapter 8, which show that a singlet anomaly in even dimensions determines the non-Abelian anomaly in two dimensons less. <br /> The &quot;covariant&quot; anomaly is discussed in chapter 10, which as the name implies transforms covariantly, unlike the consistent (&quot;Bardeen&quot;) anomaly considered so far. Noting that they arise from two different regularization schemes, the author then relates them via the Bardeen-Zumino polynomial. <br /> The most interesting chapter is the next one, which discusses the index theory of anomalies. Having very important mathematical connections, the presentation is very understandable but not rigorous mathematically, due to the use of the path integral. The author shows that anomalies are intimately connected with the topology of gauge theories, in particular the non-Abelian anomaly characterizes the nontrivial topology of the determinant bundle over the 2-sphere X 2n-sphere. <br /> Gravitational anomalies are the subject of the last chapter, wherein gauge transformations are the coordinate and Lorentz transformations. The workin preceeding chapters proceeds here without too much change, and the reader can see the fermionic contribution to the occurrence of anomalies, and the author again uses the BRS formalism to derive the descent equations.	2003-02-08
1236850:US	50702879	R6EBECGG9LJMX	0201059207	717017268	Quantum Mechanics	Books	4	6	6	N	N	Still a good book	Although over 40 years since it was first published, this book could still serve to give an overview of quantum mechanics at the first-year graduate level. It emphasizes the role of symmetry and the algebraic structure of quantum mechanics, but also endeavors to uncover the physics behind the subject, instead of the just the abstract formalism. Like all books in quantum mechanics, the authors inject comments that are controversial and are still hotly debated, but this serves as a stimulus for the reader to think about the issues at hand. Some of the more interesting and unique features of the book include: 1. The chapter on the historical origins of quantum theory. The authors give a good overview of the experimental situation that brought about quantum mechanics. Earnshaw's theorem, optical spectra, blackbody radiation, the photoelectric effect, and the Franck-Hertz experiment are all cited as examples that could not be explained with classical mechanics or classical electrodynamics. Quantum theory has certainly been successful in explaining these phenomena, but it has yet to be established that the quantum theory is the only (unique) theory of physics that will explain them. Perhaps a different theory, employing a different mathematical formalism, would explain these phenomena. One could perhaps develop a program, using an approach from artificial intelligence such as evolutionary programming or constraint optimization, to develop a &quot;theory&quot; that must satisfy as a side constraint the set of these phenomena (they of course being cast into a suitable quantitative or mathematical form). Experience in the modification of quantum theory by some researchers has led to the belief that quantum theory is a tightly constrained theory: any small changes tend to lead to bizzarre results such as negative probabilities, etc. The authors also give a good discussion in this chapter of the weaknesses of the &quot;old quantum theory&quot;; these weaknesses being ameliorated when the wave nature of matter is postulated. But here again, it is an open question as to whether another (perhaps simpler) conception could be brought in that would improve on the weaknesses of the old quantum theory. Such a conception might not be too motivating to discover however, due to the enormous experimental success of the quantum theory. 2. The authors give an excellent discussion of Fourier analysis early on in the book. In particular, a nice graphical illustration of Parseval's formula is given. Their discussion of the uncertainty principle is based on the mathematical properties of the wave function and its Fourier transform, and by analogy to the standard deviation in statistics. Their discussion therefore softens the &quot;counterintuitive&quot; nature of the uncertainty principle, which has been a concern for many students of quantum theory. 3. The discussion of the spread of a Gaussian wave packet with time. This discussion emphasizes the time scales, and is enormously important in considerations of the time evolution of Gaussian wave packets in potentials. Current research in quantum chaos and the issue of &quot;decoherence&quot; have depended to some degree on the understanding of how Gaussian wave packets spread in time. 4. The discussion on the role of the correspondence principle in selecting the form of the Hamiltonian. The authors remark that the construction of the Hamiltonian function always requires a reference to the classical variables, and so the correspondence principle is an essential part of quantum theory (aside from considerations of spin). This choice however is not unique, and in fact can even be recast into other variables that make the quantum formulation much more difficult. In addition, the quantization of a classical system (described by a certain Hamiltonian) with constraints is very problematic and is the subject of intense research. 5. The normal and quadratic Zeeman effect is given a very clear treatment. The authorsemphasize the need for an extremely intense fields if the quadratic effect is to be observed, and they give as an example the absorption spectra of alkali metals, where transitions to highly excited states can be observed in magnetic fields up to 27,000 gauss. Recent research in astrophysics has revealed the importance of the quadratic Zeeman effect in stars after gravitational collapse to white dwarfs.emphasize the need for an extremely intense fields if the quadratic effect is to be observed, and they give as an example the absorption spectra of alkali metals, where transitions to highly excited states can be observed in magnetic fields up to 27,000 gauss. Recent research in astrophysics has revealed the importance of the quadratic Zeeman effect in stars after gravitational collapse to white dwarfs.	2003-02-07
1247638:US	50702879	R2DFCAU81CMPI8	0201328313	693639692	Intermediate Quantum Mechanics: Third Edition (Advanced Books Classics)	Books	4	7	8	N	N	A good overview	That quantum mechanics must be understood by anyone working in any area of technology is now well accepted. Indeed, semiconductor device physics, proteomics, and computational chemistry are just three of the more modern areas where a through knowledge of quantum mechanics is needed in order to make any kind of significant progress. This book, written by two of the major players in the development of quantum mechanics in the 20th century, is an excellent overview of how to do practical computations in quantum mechanics. The book is addressed primarily to the aspiring atomic physicist and spectroscopist, but it could serve well anyone interested in the applications of quantum mechanics, such as those in the aforementioned fields. Due to space limitations, I will only review the first 8 chapters of the book.<br /> Chapter 1 is a brief overview of elementary quantum mechanics, and the authors set down the notation and units to be followed in the book. They state the main goal of the book, which is to solve the Schrodinger equation for an atom with nuclear charge Ze. This problem for one-electron is straightforwardly solved, but for more than one electron approximation techniques must be used, a few of which they mention. Since spin will have to be dealt with throughout the book, the authors include a description of spin 1/2 particles.<br /> In chapter 2 the authors discuss the use of symmetry principles in quantum many-particle systems, pointing out the origin of exchange degeneracy and the Pauli exclusion principle. The authors also give an interesting discussion of the experimental determination of symmetry, particularly their argument for the absence of hidden variables.<br /> In chapter 3 the authors give an overview of the quantum mechanics of two-electron atoms, pointing out that the calculations give six-figure agreement between theory and experiment. Perturbation and variational methods are used to solve the Schrodinger equation for this system, and show the origin of the triplet and singlet levels for the helium atom.<br /> In chapter 4, the authors introduce another approximation technique, the self-consistent field or &quot;Hartree-Fock&quot; method, in order to calculate the excited states for the two-electron atom more efficiently.  This approach involves using a variational trial function, called the determinantal wave function, as an ansatz, which because of orthogonality  and parity considerations, results in a set of equations, called the Hartree-Fock equations, for the single electron orbitals. The &quot;exchange term&quot; in these equations is discussed in detail, involving a notion of a &quot;nonlocal&quot; potential. The physical significance of the eigenvalue in these equations is also discussed, and related to the famous Koopman theorem. It is proven also that atoms with closed shells leads to a spherically symmetric theory. The periodic table is shown to be a consequence of the Pauli principle and the Hartree-Fock calculation.<br /> An improvement to Hartree-Fock, the Thomas-Fermi method, which does not include exchange, is discussed in chapter 5. Classified as a &quot;statistical method&quot;, this method finds the effective potential energy experienced by a small test charge, along with the electron density around the nucleus. The authors show how exchange effects can be included using a procedure due to P.A.M. Dirac, which uses a concept of effective exchange potential, and one due to W. Lenz, which is a constrained optimization procedure, requiring that the total energy be stationary.<br /> In order to remove the degeneracy in the atomic shells due to the Hartree-Fock approximation, the authors view it as a perturbation expansion in chapter 6, with the unperturbed Hamiltonian being the Hartree-Fock central field Hamiltonian, and the perturbation being the electrostatic interaction of the electrons minus a suitable average of it. The search for  proper linear combinations of zero-order degenerate eigenfunctions to make the total Hamiltonian diagonal entails the use of the total orbital and spim angular momentum of all the electrons in the atom. Hence the authors outline in detail how to perform the addition of angular momenta in this chapter. The reader can see clearly the origin of the famous Clebsch-Gordon coefficients. This program is carried out in more detail in chapter 7, wherein the authors considers and atom which has an electron configuration distributed over several complete and one incomplete shell. The incomplete shell gives several different degenerate solutions, and this degeneracy can be removed by the assignment of angular momentum and spin quantum numbers to the orbitals in the shell. This chapter is characterized by a considerable amount of arithmetic in computing matrix elements, which can readily be handled by modern symbolic computation packages.<br /> The contribution of the spin-orbit interaction to the level structure of atoms, ignored in the previous two chapters, is studied in chapter 8. The authors also consider the interaction of the electron configuration with an external field, such as a magnetic field. The spin-orbit interaction is not considered in a relativistic framework, but instead is given a &quot;pseudo-derivation&quot;, in the words of the authors. The (correct) Dirac theory for spin-orbit interaction is given later in chapter 22. And here again, the matrix elements, and reduced matrix elements, considered in this chapter can best be handled by symbolic computation packages. This is particularly true for matrix elements of vector operators between states of different angular momentum, which the authors shy away from. The reader though can see the origin of the famous Wigner-Eckart theorem in the context of these computations. The Zeeman effect, resulting from the interaction of an electron with a homogeneous magnetic field, is discussed, along with the Paschen-Back effect, which results from the external magnetic field being strong enough to allow the Zeeman term in the Hamiltonian to dominate the spin-orbit interaction. Also discussed is the Stark effect, which results when an atom is placed in an external electric field. The authors show how to compute the energy shifts in this case, using, but not proving, some formulas due to Condon and Shortly.e eigenfunctions to make the total Hamiltonian diagonal entails the use of the total orbital and spim angular momentum of all the electrons in the atom. Hence the authors outline in detail how to perform the addition of angular momenta in this chapter. The reader can see clearly the origin of the famous Clebsch-Gordon coefficients. This program is carried out in more detail in chapter 7, wherein the authors considers and atom which has an electron configuration distributed over several complete and one incomplete shell. The incomplete shell gives several different degenerate solutions, and this degeneracy can be removed by the assignment of angular momentum and spin quantum numbers to the orbitals in the shell. This chapter is characterized by a considerable amount of arithmetic in computing matrix elements, which can readily be handled by modern symbolic computation packages. <br /> The contribution of the spin-orbit interaction to the level structure of atoms, ignored in the previous two chapters, is studied in chapter 8. The authors also consider the interaction of the electron configuration with an external field, such as a magnetic field. The spin-orbit interaction is not considered in a relativistic framework, but instead is given a &quot;pseudo-derivation&quot;, in the words of the authors. The (correct) Dirac theory for spin-orbit interaction is given later in chapter 22. And here again, the matrix elements, and reduced matrix elements, considered in this chapter can best be handled by symbolic computation packages. This is particularly true for matrix elements of vector operators between states of different angular momentum, which the authors shy away from. The reader though can see the origin of the famous Wigner-Eckart theorem in the context of these computations. The Zeeman effect, resulting from the interaction of an electron with a homogeneous magnetic field, is discussed, along with the Paschen-Back effect, which results from the external magnetic field being strong enough to allow the Zeeman term in the Hamiltonian to dominate the spin-orbit interaction. Also discussed is the Stark effect, which results when an atom is placed in an external electric field. The authors show how to compute the energy shifts in this case, using, but not proving, some formulas due to Condon and Shortly.	2003-01-30
1248010:US	50702879	RG6OCDVKNE6HG	007054980X	248592421	Elementary Quantum Mechanics	Books	4	10	10	N	N	A good start	This book, first published in 1968, is the one I used as an undergraduate for a first course in quantum mechanics and one that I used to teach such a course. It introduces the subject from a physical standpoint but does not hesitate to use the appropriate mathematical tools, without getting too involved in the structure of Hilbert spaces, which might be too overbearing for the typical undergraduate. A familiarity with ordinary linear differential equations and Fourier series is assumed, along with some knowledge of special functions. The author therefore treats mainly the quantum mechanics of one-dimensional systems, but motion in three dimensions is also discussed in the last three chapters of the book. It is also assumed that the student has a background in classical mechanics the covers the Hamiltonian formalism. It would be helpful of course if the student has had a prior course that discussed elementary quantum phenomena, such as a sophomore-level course in \\"modern physics\\". The goal of the book is to introduce students to bread-and-butter calculations in quantum mechanics, and not to entice them to think critically about the subject, or propose alternatives to it. Due to space considerations, I will only review the first 6 chapters of the book.<br /> The first chapter of the book endeavors to explain the historical origins of quantum theory and its need to explain various experiments that could not be resolved using \\"classical physics\\". These include the equipartition theorem, the stability of the atom, and the photoelectric effect. The move by Max Planck in 1901 to introduce \\"energy quanta\\" solved the equipartition problem and introduced the quantum theory, the success of which is now well-established and has had enormous consequences for physics and technology. Interestingly, the author engages in a little philosophical speculation in this chapter, holding to the idea that quantum theory is based on constructs removed from experience, such as state functions and observables. The origin of the Heisenberg uncertainty principle is then discussed as a consequence of the nature of quantum observables as being discrete in nature. The wave nature of matter, the de Broglie hypothesis, is discussed in the context of the Davisson-Germer experiment.<br /> Chapter 2 attempts to explain the nature of state functions and their interpretation, this being done in the context of the famous statistical (Born) interpretation. The principle of superposition of state functions is discussed, and care is taken to differentiate the probabilistic nature of quantum mechanics (the relation between interference and superposition) from that of classical statistic mechanics. The double slit experiment is discussed as a thought experiment, and no mention is made that this experiment has never been done in the way described (using electrons). The author also uses wave packets as a way of making the correspondence between quantum and classical descriptions of a state. Current research on quantum decoherence and quantum chaos was not available at the time of publication, and so the author is (justifiably) comfortable with using wave packets to make this correspondence.<br /> In chapter 3 the author studies linear momentum in quantum mechanics and uses the state function to describe a particle with a definite linear momentum. Interestingly, and importantly, he uses symmetry considerations to deduce the form of this state function. After superposing many such state functions, Fourier transforms are then brought in to find the form of this superposition in position space. The origin of the momentum and position operators then follows nicely.<br /> The motion of a free particle is considered in chapter 4. The form of the frequency dispersion relation in momentum space is derived using the correspondence principle, giving the familiar Planck relation. This derivation is dependent very strongly on the particle being free (and the author understands this), for if one attempts to do this in more complicated situations, such as in classically nonintegrable systems, it becomes very complex, involving highly esoteric mathematical constructions. The Schrodinger equation for the free particle is then derived later in the chapter.<br /> The Schrodinger equation for a particle under the influence of a conservative force is the subject of chapter 5. The Schrodinger equation is represented first as an operator H that acts on a state function and gives its time derivative (multiplied by Planck's constant times i). The author proves right away that because of probability conservation, H must be Hermitian. He then uses the correspondence principle to identify H as the total energy. Using again the Fourier transform, the author derives the Schrodinger equation in both configuration and momentum space. The reader can see the equations becomes an integral equation in momentum space, and the equation is much more complicated than the free particle case, due to the influence of the external force. The technique of separation of variables is then used to find the stationary states and the energy spectrum. More general mathematical considerations occupy the rest of the chapter, wherein the author finds the eigenvalues and eigenfunctions of a Hermitian operator, studies what it means for a set of operators to be complete, proves the uncertainty principle for a general observable, and discusses the basic postulates of quantum mechanics.<br /> Chapter 6 is an overview of the quantum-mechanical states of a particle moving in a potential. Symmetry principles make their appearance here, via the classification of states according to their parity. The author then studies the bound states of a particle in a square-well potential. He then gives a detailed treatment of the harmonic oscillator in one dimension using the method of power series and the method of factorization. The latter method introduces the all-important creation and annihilation operators. And even more importantly, the author studies the motion of a wave packet in the harmonic oscillator, introducing the propagator or Green's function, and then showing the existence of minimum uncertainly wave packets, the famous \\"coherent states\\". Then after a discussion of the purely quantum-mechanical phenomena of tunneling through a barrier, the author ends the chapter with a discussion of the numerical solution of the Schrodinger equation.for if one attempts to do this in more complicated situations, such as in classically nonintegrable systems, it becomes very complex, involving highly esoteric mathematical constructions. The Schrodinger equation for the free particle is then derived later in the chapter. <br /> The Schrodinger equation for a particle under the influence of a conservative force is the subject of chapter 5. The Schrodinger equation is represented first as an operator H that acts on a state function and gives its time derivative (multiplied by Planck's constant times i). The author proves right away that because of probability conservation, H must be Hermitian. He then uses the correspondence principle to identify H as the total energy. Using again the Fourier transform, the author derives the Schrodinger equation in both configuration and momentum space. The reader can see the equations becomes an integral equation in momentum space, and the equation is much more complicated than the free particle case, due to the influence of the external force. The technique of separation of variables is then used to find the stationary states and the energy spectrum. More general mathematical considerations occupy the rest of the chapter, wherein the author finds the eigenvalues and eigenfunctions of a Hermitian operator, studies what it means for a set of operators to be complete, proves the uncertainty principle for a general observable, and discusses the basic postulates of quantum mechanics. <br /> Chapter 6 is an overview of the quantum-mechanical states of a particle moving in a potential. Symmetry principles make their appearance here, via the classification of states according to their parity. The author then studies the bound states of a particle in a square-well potential. He then gives a detailed treatment of the harmonic oscillator in one dimension using the method of power series and the method of factorization. The latter method introduces the all-important creation and annihilationoperators. And even more importantly, the author studies the motion of a wave packet in the harmonic oscillator, introducing the propagator or Green's function, and then showing the existence of minimum uncertainly wave packets, the famous \\"coherent states\\". Then after a discussion of the purely quantum-mechanical phenomena of tunneling through a barrier, the author ends the chapter with a discussion of the numerical solution of the Schrodinger equation.	2003-01-29
1252368:US	50702879	RITAJOXSF8GLB	0064632180	232479503	Ideas of the Great Philosophers	Books	5	12	12	N	N	An excellent way to begin	I found this book on my dining room table one morning, my older brother having brought it home to read. And like any eighteen-year old teenager, I was contemplating the mysteries of life, and after picking up this book and reading it, I was sent on a quest for knowledge that has lasted almost three decades. The book is short, cost $1.75 at the time I read it, is a mere 181 pages, but its contents serve to introduce the reader to the contemplations of many of the major philosophers throughout the ages. All of the ideas in the book have found their way into the 21st century, as it is the nature of ideas to have a long decay time.<br /> In Part One on epistemology, the authors acknowledge that an exploration of the entire scope of epistemology and logic would require many volumes and a lifetime of study. However, they bring the reader through a summary of the main problems, touching on how to distinguish truth from error, how to analyze the fallacies of reasoning, and the nature and attainability of truth itself. These considerations are not vacuous, for they are all immediately practical, and, most importantly, they are deeply embedded in the still elusive goal of bringing about the rise of intelligent machines.<br /> Part Two contemplates the \\"good life\\": the philosophical construction of ethical theories of correct conduct. The mere fact that humans can choose freely different courses of action is proof of the need and truth of ethics. The finding of the correct one though cannot be done without careful consideration. The authors give the reader many approaches taken throughout the history of philosophy. These approaches have been institutionalized and codified, but ethical philosophy has not exhausted itself. One can indeed look forward to the new ethical ideas that will arise in the 21st century, driven by the advances in genetic engineering and machine intelligence.<br /> The philosopher Plato stated that \\"man is a political animal\\" and he attempted to construct a theory of the \\"ideal state\\" or \\"utopia\\". Part Three discusses his contributions, and those of many other philsophers. There are many conceptions of utopias, and each has its own merits as well as difficulties. The authors do a fine job of summarizing the ones that have had the most impact. The ideas of political philosophy that the authors summarize in the book have had the luxury maybe of being synchronized with the science of the time. It could be said with confidence that political philosophy will continue to depend on what comes out of the scientific and technological marketplace. Political philosophy however will be taking even more bows to the dizzying rate of technological advance in this century. It is ideas and their practical expression that drive governments, not the other way around.<br /> Life in the 21st century is complicated by the presence of religion, not so much from a philosophical viewpoint, but from a political one. Part Four of the book overviews the philosophy of religion from the standpoint of arguments for the existence of god and positions taken on atheism and agnosticism, but arguments based on science are absent in the book. The superposition of religion and science continues to this day, sometimes accompanied by considerable tension, at other times a cautious alliance. Arguments for the existence of god are drawing more and more on the results of science, due perhaps to the inherent weaknesses of its arguments in the past. In addition, it seems that science is being viewed as a foundation for knowledge in and of itself, and therefore needs no underlying justification. This will definitely have consequences for religious philosophy. It is interesting to ask what the attitudes of future humans will be on religious philosophy, after they are subjected to generations of genetic engineering; and the attitudes of thinking machines, when these arise as they will in the future. Both types of beings may have very unique outlooks on religious philosophy, or may indeed not have any at all.<br /> Metaphysics is the subject of Part Five of the book. The nature and substance of reality has occupied the time of many philosophers, spanning many centuries. That such endeavors are not vacuous is readily apparent in discussions on topics such as quantum physics, for the latter has provoked much philosophical debate on metaphysics that continues to this day.<br /> The book ends in Part Six with a discussion of the types of philosophy. The \\"isms\\" of philosophy have many intersections with each other, and their status as theories has always been unstable. This instability though feeds philosophical advance, and without it no advance is possible. Philosophy though has not exhausted itself, whatever the claims to the contrary, and future developments in philosophy will no doubt be just as interesting, or more so, as the ones discussed in this book.<br /> Books like these motivate one to take a journey of knowledge acquisition and a yearning for understanding. Such a journey has many valleys and many peaks, and sometimes one gets trapped in a local minimum. A mind that is continually searching and analyzing though will find its way out of these, and view things on the peaks that perhaps no person has seen before. From a personal viewpoint, if by reading this review at least one person is motivated to read this book or some other like it, and then go on their own journey of enlightenment, I will have made partial compensation to the incalculable debt I owe to the authors and the person who introduced me to this book.s philosophy, or may indeed not have any at all. <br /> Metaphysics is the subject of Part Five of the book. The nature and substance of reality has occupied the time of many philosophers, spanning many centuries. That such endeavors are not vacuous is readily apparent in discussions on topics such as quantum physics, for the latter has provoked much philosophical debate on metaphysics that continues to this day. <br /> The book ends in Part Six with a discussion of the types of philosophy. The \\"isms\\" of philosophy have many intersections with each other, and their status as theories has always been unstable. This instability though feeds philosophical advance, and without it no advance is possible. Philosophy though has not exhausted itself, whatever the claims to the contrary, and future developments in philosophy will no doubt be just as interesting, or more so, as the ones discussed in this book. <br /> Books like these motivate one to take a journey of knowledge acquisition and a yearning for understanding. Such a journey has many valleys and many peaks, and sometimes one gets trapped in a local minimum. A mind that is continually searching and analyzing though will find its way out of these, and view things on the peaks that perhaps no person has seen before. From a personal viewpoint, if by reading this review at least one person is motivated to read this book or some other like it, and then go on their own journey of enlightenment, I will have made partial compensation to the incalculable debt I owe to the authors and the person who introduced me to this book.	2003-01-26
1262028:US	50702879	RPSHQJ8TYD5JL	0470848707	561859768	Computational Intelligence: An Introduction	Books	4	18	19	N	Y	A good start	This book is suitable for undergraduates and first-year graduate students in computer science who are interested in getting an overview of what is and has been done in a field that used to be classified as \\"artificial intelligence\\". The new designation as \\"computational intelligence\\" was done so as to distance it from other activities in artificial intelligence that are deemed somewhat exotic, such as the efforts to build autonomous thinking machines. The book can be read very quickly, due to the sparse nature of the paragraph organization, and the author puts exercises at the end of each chapter to test the reader's insight and problem solving ability.<br /> The author divides his book into five parts, the first one being an introduction and history, and the next four being on neural networks, evolutionary computation, swarm intelligence, and fuzzy systems. The third part is relatively new on the scene in computational intelligence, and so its inclusion in this book is welcomed.<br /> Neural networks have been extensively used in the last four decades in many different fields, such as financial engineering, bioinformatics, physics, and network analysis. The author devotes six chapters to their elucidation, and he discusses the most important types of artificial neural networks and the different learning schemes employed by them. Detailed derivations and pseudocode are given for these, particularly for back-propagation, and the \\"LeapFrog\\" and \\"conjugate gradient\\" approaches to optimization. Most interesting is the inclusion of a \\"swarm optimization\\" technique. Although brief, the author includes pseudocode and references for further reading.<br />  The author includes a discussion of product unit neural networks, which are sometimes not treated in other books on neural networks. In this type of neural network, the neurons compute the weighted product of the input signals, and the author includes a \\"distortion factor\\" that allows the dynamical shaping of the activiation function during the training phase. Only a cursory discussion of what it actually means for a neural network to learn is given, but references for further reading are included. The author also includes a nice discussion of performance issues in the use of neural networks. Readers who eventually use them in practice will find that neural networks can be computationally intensive. An interesting inclusion in this discussion is that of the VC-dimension, and how it relates to the total number of weights in a 1-hidden layer network, and thus of the number of training examples needed. The reader is asked to investigate the role of the Huber function in making a neural network more robust to outliers. The author cautions the reader that the use of neural networks should not be taken lightly and great care is need to insure optimal performance.<br /> In part 3 the author treats genetic and evolutionary programming, evolutionary strategies, differential and cultural evolution, and co-evolution. The use of these techniques has dramatically increased in the last decade, especially in optimization problems. The author points out the role of finding the right chromosome representation in the design of an evolutionary algorithm, this serving also as a kind of classification of the different approaches: binary strings for genetic algorithms, tree representations for genetic programming, and real numbers for evolutionary programming. The author compares briefly the use of evolutionary computing versus using techniques from classical optimization theory, with the role played by the \\"no-free-lunch\\" theorem. The author holds that evolutionary algorithms are superior for discontinuous, nondifferentiable, multimodal, and noisy problems.<br /> Of personal interest to me, an application of genetic algorithms to routing optimization is discussed in this part. The author also briefly mentions \\"niching\\" as a method to locate multiple minima and asks the reader to develop a genetic algorithm to train a feed-forward neural network as an exercise. For readers who have a knowledge of LISP the discussion on genetic programming will seem much more natural. Evolutionary programming, which differs from genetic algorithms and genetic programming with its omission of crossover and its emphasis on simulating adaptive behavior in evolution, and not genetic models is given ample treatment, along with some useful pseudocode. An elementary application to function optimization is given. The discussion on evolutionary strategies is a fine one since the ones in the literature may be too difficult mathematically for a reader at this level. The discussions on differential and cultural evolution, and coevolution are too brief however (only a few pages devoted to each).<br /> Of great interest to me was the part on swarm intelligence, as my knowledge of this field is very meager. It has taken on importance recently in research circles and so I was very interested in seeing if could be used successfully in practical optimization problems. Having just begun to get my feet wet in swarm intelligence algorithms, this part was a good help in giving me more insight into the use of them. This book is one of the few that covers swarm intelligence, most of the literature still being found in online preprints and published journal articles. The author calls  one approach \\"particle swarm optimization\\" (PSO), and he explains how the different social interaction schemes serve to classify the algorithm, going by the namnes of star, ring, and wheels topology. He also discusses various modifications to PSO that improve its convergence and to increase its diversity. Another approach is based on the social interaction of ants, and is called appropriately \\"ant colony optimization\\". This approach has been applied with some success to route assignment in packet networks, and has been shown to be competetive with vector-distance and link-state shortest path algorithms. It remains to be seen if such an approach will be implemented in real-world network topologies, dominated as they are currently with legacy hardware. The author also gives brief discussions on some of its other applications, such as robotics, and the quadratic assignment, job-scheduling, and graph coloring problems.<br />I did not read the part on fuzzy systems so I will omit its review.lgorithm to train a feed-forward neural network as an exercise. For readers who have a knowledge of LISP the discussion on genetic programming will seem much more natural. Evolutionary programming, which differs from genetic algorithms and genetic programming with its omission of crossover and its emphasis on simulating adaptive behavior in evolution, and not genetic models is given ample treatment, along with some useful pseudocode. An elementary application to function optimization is given. The discussion on evolutionary strategies is a fine one since the ones in the literature may be too difficult mathematically for a reader at this level. The discussions on differential and cultural evolution, and coevolution are too brief however (only a few pages devoted to each). <br /> Of great interest to me was the part on swarm intelligence, as my knowledge of this field is very meager. It has taken on importance recently in research circles and so I was very interested in seeing if could be used successfully in practical optimization problems. Having just begun to get my feet wet in swarm intelligence algorithms, this part was a good help in giving me more insight into the use of them. This book is one of the few that covers swarm intelligence, most of the literature still being found in online preprints and published journal articles. The author calls  one approach \\"particle swarm optimization\\" (PSO), and he explains how the different social interaction schemes serve to classify the algorithm, going by the namnes of star, ring, and wheels topology. He also discusses various modifications to PSO that improve its convergence and to increase its diversity. Another approach is based on the social interaction of ants, and is called appropriately \\"ant colony optimization\\". This approach has been applied with some success to route assignment in packet networks, and has been shown to be competetive with vector-distance and link-state shortest path algorithms. It remains to beseen if such an approach will be implemented in real-world network topologies, dominated as they are currently with legacy hardware. The author also gives brief discussions on some of its other applications, such as robotics, and the quadratic assignment, job-scheduling, and graph coloring problems.  <br />I did not read the part on fuzzy systems so I will omit its review.	2003-01-18
1268017:US	50702879	R1NDOL1UAEDX7X	0821816659	225610104	Banach Algebra Techniques in the Theory of Toeplitz Operators (Cbms Regional Conference Series in Mathematics)	Books	5	2	2	N	N	Excellent overview	This short book appeared shortly after the first edition of the author's book &quot;Banach Algebra Techniques in Operator Theory&quot; and extends some of the results therein, with particular attention paid to the theory of Toeplitz operators. Toeplitz operators are a generalization of multiplication operators acting on the Hardy space of square integrable functions with zero negative Fourier coefficients. The nontrivial nature of Toeplitz operators, in contrast to multiplication operators, arises from their definition as a projection from the space of square integrable functions to this Hardy space. Physicists and engineers are perhaps more familiar with Toeplitz operators in the guise of Weiner-Hopf operators, and the author shows this equivalence in the introduction. The reader of this book is assumed to be familiar with the elementary theory of Banach algebras, the spectral theorem in operator theory, and the elementary theory of Hardy spaces. The author reviews briefly what the reader is expected to know about Fredholm operators.<br /> The first chapter is concerned with studying the invertibility of Toeplitz operators. The author is more general than in his book by working on square-integrable measurable functions on the unit circle with values in complex n-dimensional space. This makes things slightly more complicated, since it is then not true that a Toeplitz operator with non-vanishing determinant of its symbol and vanishing winding number is invertiable. The author shows that generically it is though, i.e. the collection of symbols for which the Toeplitz operator is invertible is a dense open set of functions from the unit circle to the the general linear group of matrices and when the index of the symbol is zero.<br /> In chapter two the author uses Bunce's theorem, which states (loosely speaking) that the C*-algebra T generated by a commuting family of subnormal operators on a Hilbert space is *-homomorphic to the continuous functions on the joint approximate point spectrum, to study spectral inclusion theorems for Toeplitz operators. Necessary conditions for their invertibility and Fredholmness are optained from these theorems. These spectral inclusion theorems are generalized in chapter 3 to the matrix case, and give criteria for Fredholmness of operators with symbol in the direct sum of the Hardy space of bounded measurable functions and continuous functions on the unit circle with values in the n x n matrices.<br /> Chapter 4 is interesting, for it discusses to what extent one can study Toeplitz operators by localizing the symbol. They can't be since square-integrable Hardy functions are not localizable, but Fredholm operators are. The author proves this in the matrix case using localization techniques from C*-algebras. The proof involves looking at the center of the quotient algebra of Toeplitz operators modulo the compacts, which happens to be larger than the continuous functions on the unit circle.<br /> The author studies Toeplitz operators with piecewise continuous symbol in chapter 5 by using the localization techniques of chapter 4, and gives criteria for when Toeplitz operators are Fredholm with this type of symbol.<br /> Chapter 6 considers Toeplitz operators with almost periodic symbol, which initially is a study of Weiner-Hopf operators. The author shows that such an operator is invertible iff the symbol is invertible and its &quot;mean motion&quot; is zero. But if one removes the second requirement, and asks to what extent the operator is &quot;nearly invertible&quot;, one needs a more general notion of what it means for an operator to be Fredholm. Interestingly, the author briefly shows how this is done, using the theory of von Neumann algebras. The index theory for these von Neumann algebras gives an appropriate definition of Fredholm operator, this operator acting on a certain von Neumann algebra &quot;factor&quot;.<br /> Things are more abstract in chapter 7, wherein the author considers the extension of C*-algebras. The problem he is concerned with is the extension of the compact operators by the continuous functions on the unit circle, i.e. the determination of the C*-subalgebras of operators such that these subalgebras modulo the compact operators are isomorphic to the continuous functions on the unit circle. The extensions are shown to be classified by integers corresponding to indexes of Fredholm operators.<br /> Toeplitz operators are considered on multi-connected domains in chapter 8, which involves extending the notion of the Hardy space on the unit circle to one on an open connected region in the complex plane. The author shows how to construct a measure on this region in order to get the appropriate generalization. The simply invariant subspaces of the square integrable functions (with this measure a probability measure on the boundary of the region) for the algebra of functions continuous on the boundary of the region and holomorphic on the region. The author sketches briefly what happens for the theory of Toeplitz operators in this context, and to what extent this theory can be related to the theory of Toeplitz operators on the unit circle. As it turns out, many of the results in the unit circle case carry over to this more general one.<br /> In the last two chapters the author studies Toeplitz operators on polydisks, where the symbol is continuous. The Toeplitz operators are defined with respect to the boundary of the polydisk. The criteria for Fredholmness is complicated by the fact that the commutator ideal contains non-compact operators. The author shows how to deal with this in detail. He then generalizes the techniques for proving Fredholmness of Toeplitz operators to arbitary operators in C*-subalgebra generated by Toeplitz operators with continuous symbol having range in the m x m matrices. It is readily apparent in these chapters how difficult it is to compute the Fredholm index of these operators.he extension of C*-algebras. The problem he is concerned with is the extension of the compact operators by the continuous functions on the unit circle, i.e. the determination of the C*-subalgebras of operators such that these subalgebras modulo the compact operators are isomorphic to the continuous functions on the unit circle. The extensions are shown to be classified by integers corresponding to indexes of Fredholm operators. <br /> Toeplitz operators are considered on multi-connected domains in chapter 8, which involves extending the notion of the Hardy space on the unit circle to one on an open connected region in the complex plane. The author shows how to construct a measure on this region in order to get the appropriate generalization. The simply invariant subspaces of the square integrable functions (with this measure a probability measure on the boundary of the region) for the algebra of functions continuous on the boundary of the region and holomorphic on the region. The author sketches briefly what happens for the theory of Toeplitz operators in this context, and to what extent this theory can be related to the theory of Toeplitz operators on the unit circle. As it turns out, many of the results in the unit circle case carry over to this more general one.<br /> In the last two chapters the author studies Toeplitz operators on polydisks, where the symbol is continuous. The Toeplitz operators are defined with respect to the boundary of the polydisk. The criteria for Fredholmness is complicated by the fact that the commutator ideal contains non-compact operators. The author shows how to deal with this in detail. He then generalizes the techniques for proving Fredholmness of Toeplitz operators to arbitary operators in C*-subalgebra generated by Toeplitz operators with continuous symbol having range in the m x m matrices. It is readily apparent in these chapters how difficult it is to compute the Fredholm index of these operators.	2003-01-14
1280836:US	50702879	RFFVKOY5OGUNQ	0691082197	2242200	Mathematical Statistical Mechanics (Princeton Legacy Library)	Books	3	7	7	N	N	Elementary introduction	This book gives an informal overview of the mathematical formalism of statistical mechanics with mathematical rigour not emphasized. There have been many developments in mathematical statistical mechanics since this book was published, particularly in the area of exactly solved models in statistical mechanics and vertex models. This book could be used as an introduction to these developments, in spite of the fact that the mathematics used in them is not covered in this book. Only very rudimentary mathematical tools are used therein. That is not to say that a beginning student interested in the mathematical aspects of statistical mechanics could not gain anything from the reading of the book. There are some very clear presentations of the following topics: 1. A detailed derivation of the Boltzmann equation. 2. A proof of the Poincare theorem, which states that a finite-energy mechanical system in a finite volume is recurrent. 3. A proof of the Liouville theorem, which gives the incompressibility of the flow of points in phase space. 4. A proof, using the Boltzmann &quot;Stosszahlansatz&quot;, that the Kac ring model approaches equilibrium. 5. A proof of the existence of the thermodynamic limit for &quot;van Hove potentials&quot;, i.e. those that have a hard core and an attractive tail. 6. The explicit calculation of the partition function for the Tonks and Takahashi gases, the Curie-Weiss model, and the one-dimensional Ising model. 7. The Onsager solution of the two-dimensional Ising model. 8. The combinatorial solution of the two-dimensional Ising model. 9. An Ising model for the DNA molecule.	2003-01-05
1286150:US	50702879	R2IF42IIN1CT8Y	0465097200	39953810	Anarchy, State, and Utopia	Books	5	49	51	N	N	It has done its job...brilliantly	This book is one of the most unusual in the history of political philosophy, and perhaps one of most brilliant. The author's ideas are thought-provoking and highly original, and he asks the reader to consider arguments, rather than engaging in a \\"diatribe to convince\\" (my words here). The author creates a reading atmosphere of intellectual honesty, and this helps to soften the possible uneasiness that some readers might feel in encountering these kinds of  arguments for the first time. Some may seem radical and unpalatable for readers of other political persuasions, but any reader who is open to new ideas should find the reading highly interesting. The political philosophy of libertarianism finds its best apology here, but the contents of the book, and the method of presentation will and has found application to other political philosophies, and to legal philosophy.<br /> In the first chapter, the author asks the reader to consider what he calls the \\"state-of-nature theory\\". This (Lockean) notion, although archaic in the author's view, allows one to answer whether a state would have to be invented if it did not exist, this being a classical question in liberal political philosophy. The chapter is a detailed justification for pursuing the state-of-nature theory. He holds to the premise that one can only understand the political realm by explaining it in terms of the nonpolitical. He thus begins with the Lockean state of nature concept and uses it to build a justification for the state in the rest of the book.<br /> Most of the discussion in part 1 of the book revolves around the \\"dominant protective association\\" in a given geographical area. The author then builds on this in an attempt to justify from a moral perspective \\"the minimal state\\". Along the way, one reads about the \\"ultraminimal state\\", which has a monopoly over the use of force except that necessary for immediate self-defense, but will not provide protection to those who do not purchase it. The author discusses the tension that arises between the ultraminimal state and those who decide not to participate in it. The game-theoretic, optimization-theoretic approach that the author takes, although not advanced and rigorous from a mathematical standpoint, is very straightforward to follow for those not familiar with the more analytical and formal aspects of many modern treatments of political science.<br /> In part 2 the author attempts to deal with alternatives to the minimal state, such as those proposed by the political philosopher John Rawls, and incorporating the doctrine of \\"distributive justice\\". The entitlement-welfare state dialog has not abated in modern political debate, and those who desire an in-depth analysis of these debates will find it in this book. And again, game-theoretic analysis comes into play, although not from a rigorous mathematical standpoint. One of the more interesting discussions in this part concerns the right of individuals to leave a state that they find too compulsory. If a compulsory distribution scheme is the most important, why would a state permit this emigration? Would such an overidding principle of compulsory distribution also permit forced immigration? These are the kinds of questions that the author addresses in the book, and some are left solely for consideration by the reader.<br /> Reader who desire a list of platitudes and endless arguments supporting libertarianism will not find them in this book. Readers though who are not concerned with their political and cognitive equilibrium disturbed will enjoy immensely this book. If it can assist in more careful individual consideration of accepted political doctrine and moral cliches, it has done its job.<br /> ...and indeed it has.discusses the tension that arises between the ultraminimal state and those who decide not to participate in it. The game-theoretic, optimization-theoretic approach that the author takes, although not advanced and rigorous from a mathematical standpoint, is very straightforward to follow for those not familiar with the more analytical and formal aspects of many modern treatments of political science. <br /> In part 2 the author attempts to deal with alternatives to the minimal state, such as those proposed by the political philosopher John Rawls, and incorporating the doctrine of \\"distributive justice\\". The entitlement-welfare state dialog has not abated in modern political debate, and those who desire an in-depth analysis of these debates will find it in this book. And again, game-theoretic analysis comes into play, although not from a rigorous mathematical standpoint. One of the more interesting discussions in this part concerns the right of individuals to leave a state that they find too compulsory. If a compulsory distribution scheme is the most important, why would a state permit this emigration? Would such an overidding principle of compulsory distribution also permit forced immigration? These are the kinds of questions that the author addresses in the book, and some are left solely for consideration by the reader. <br /> Reader who desire a list of platitudes and endless arguments supporting libertarianism will not find them in this book. Readers though who are not concerned with their political and cognitive equilibrium disturbed will enjoy immensely this book. If it can assist in more careful individual consideration of accepted political doctrine and moral cliches, it has done its job.<br /> ...and indeed it has.	2003-01-01
1289988:US	50702879	R20MAF1YSSKTSB	0872203581	580904764	Selected Letters of Friedrich Nietzsche (Hackett Classics)	Books	4	18	18	N	N	Interesting reading	If you want to gain insight into Nietzsche's thinking outside of his usual philosophical writings, or follow his chain of thought throughtout his life, this collection of letters is somewhat helpful, but he does not seem to engage in the manner in which he does in his formal philosophical works. One of the features I found surprising in his letters is the courtesy he showed to his recipients. It is evident that Nietzsche treasured the friendships he had, and this is very apparent in his letters. And interestingly, I did not find any hostility in any of the letters addressed to Richard Wagner, considering the history of their relationship.<br /> The book is well-edited, and there is an index of recipients near the end of the book. The editor also includes a general index with subentries that allow the reader to scan an entire topic. This is a helpful aid for amateur readers of Nietzsche, such as myself, but could also be helpful I think to dedicated scholors of Nietzsche.<br /> I was only disappointed that more letters did not address more of Nietzsche's thinking on Dionysus and Apollo. It would have been interesting to read what he had to say about them via the &quot;freestyle&quot; of letter writing. Nietzsche's philosophical writings are actually the most frank and unrestrained of all in nineteenth-century philosophy. He is very honest with himself, and because of this he might be viewed as somewhat narcisstic by some readers. This may be true to some degree, but Nietzsche is refreshing in his style of writing, and actually it is quite entertaining to randomly move through his books and read his maxims and opinions.<br /> The most interesting letter is the one addressed to Carl von Gersdorff on April 6, 1867. He is writing about what he has called &quot;the scholarly forms of disease&quot;, and tells of a story about a talented young man who enters the university to obtain a doctorate. He puts together a thesis he has been working on for years, submits it to the philosophical faculty. One rejects the work on the grounds that it advances views that are not taught there. The other states that the work is contrary to common sense and is paradoxical. His thesis is therefore rejected, and he does not therefore earn his doctorate. Nietzsche describes the &quot;not humble enough to hear the voice of wisdom&quot; in their negative judgment of his results. Further, the young man is &quot;reckless enough&quot;, in Nietzsche's view, to believe that the faculty &quot;lacks the faculty for philosophy. Nietzsche uses this story to emphasize the virtue of independence: &quot;one cannot go one's own way independently enough. Truth seldom dwells where people have built temples for it and have ordained priests. We ourselves have to suffer for good or foolish things we do, nor those who give us the good or the foolish advice. Let us at least be allowed the pleasure of committing follies on our own initiative. There is no general recipe for how one man is to be helped. One must be one's own physician but at the same gather the medical experience at one's own cost. We really think too little about our own well-being; our egoism is not clever enough, our intellect not egoistic enough.&quot;<br /> He's right.he philosophical faculty. One rejects the work on the grounds that it advances views that are not taught there. The other states that the work is contrary to common sense and is paradoxical. His thesis is therefore rejected, and he does not therefore earn his doctorate. Nietzsche describes the &quot;not humble enough to hear the voice of wisdom&quot; in their negative judgment of his results. Further, the young man is &quot;reckless enough&quot;, in Nietzsche's view, to believe that the faculty &quot;lacks the faculty for philosophy. Nietzsche uses this story to emphasize the virtue of independence: &quot;one cannot go one's own way independently enough. Truth seldom dwells where people have built temples for it and have ordained priests. We ourselves have to suffer for good or foolish things we do, nor those who give us the good or the foolish advice. Let us at least be allowed the pleasure of committing follies on our own initiative. There is no general recipe for how one man is to be helped. One must be one's own physician but at the same gather the medical experience at one's own cost. We really think too little about our own well-being; our egoism is not clever enough, our intellect not egoistic enough.&quot;<br /> He's right.	2002-12-29
1293090:US	50702879	R2L1M62A59OQTF	1558607838	730693897	Blondie24: Playing at the Edge of AI (The Morgan Kaufmann Series in Artificial Intelligence)	Books	4	19	19	N	Y	A very interesting and engaging story	In this book the author gives a detailed story of his involvement in the development of the \\"Blondie24\\" checkers program, and the story is a very interesting one. The reader not familiar with certain research topics in artificial intelligence such as neural networks and evolutionary programming, will still be able to read the book since the author gives a good intuitive discussion of these topics. If the book inspires a young person to enter the field of artificial intelligence, it has served a noble purpose, even if the author did not intend this as the primary purpose of the book.<br /> The author's main thesis is the value of using concepts of evolutionary programming to bring about the rise of intelligent machines. The author clearly believes that before \\"HAL-like\\" machines can be built, researchers must construct computer programs that can teach themselves how to solve problems without any help. Intelligent machines must be creative, and learn and adapt to new circumstances. Traditional research in artificial intelligence has been geared towards building machines that emulate human intelligence, and this will not do in the author's view. The research did not address the true definition and meaning of intelligence, but instead made the goal of creating machines that think and act like humans, whence the famous \\"Turing test\\" for machine intelligence. The author completely rejects this test and holds it responsible for bringing about the \\"AI winter\\" where no substantive progress was made. \\"The key to creating truly creative computers\\", he says, \\"lies in mimicking nature's process of evolution.\\"<br /> The author though was not comfortable with merely refuting arguments about the Turing test or other strategies for designing intelligent machines. He knows that such argument-counterargument activity will not result in sound approaches to artificial intelligence. Therefore, he sought to construct a working, viable alternative, which produces results that can be checked. Intelligence for the author is based on decision making, such as how to obtain resources, and how to respond to environmental changes by prioritizing goals. \\"Intelligence is the property that allows living organisms to sense, react to, and learn from their environment in order to adapt their behavior to better promote their survival\\", he says.<br /> Hence, the author brings in the evolutionary paradigm to artificial intelligence, and to give credence to his view, he attempts to create a program that will learn the game of checkers and then play it well, at least from the standpoint of the checkers game rating system. The book is a very detailed overview of how he and his collaborators went about doing this, the most interesting strategy being the use of neural networks, the topology of which is not set beforehand, but is evolved according to a \\"survival of the fittest\\" process. The author, through diagrams, gives the reader a taste of the moves that were made as the program dealt with online checkers games.<br /> The author even gives a dose of the criticism he received from referees when his results were submitted to professional journals, and this gives the book greater appeal from the standpoint of intellectual honesty. Certainly the author and those he worked with have achieved a great deal in the context of building intelligent machines. It remains to be seen whether evolutionary programming can be extended to situations that require even more creativity, such as that of generating new and interesting results in pure mathematics. This is the ultimate test in my view of machine intelligence. It is not immediately obvious how this is to be done in the evolutionary programming or indeed of any other paradigm in artificial intelligence.ed. Intelligence for the author is based on decision making, such as how to obtain resources, and how to respond to environmental changes by prioritizing goals. \\"Intelligence is the property that allows living organisms to sense, react to, and learn from their environment in order to adapt their behavior to better promote their survival\\", he says. <br /> Hence, the author brings in the evolutionary paradigm to artificial intelligence, and to give credence to his view, he attempts to create a program that will learn the game of checkers and then play it well, at least from the standpoint of the checkers game rating system. The book is a very detailed overview of how he and his collaborators went about doing this, the most interesting strategy being the use of neural networks, the topology of which is not set beforehand, but is evolved according to a \\"survival of the fittest\\" process. The author, through diagrams, gives the reader a taste of the moves that were made as the program dealt with online checkers games. <br /> The author even gives a dose of the criticism he received from referees when his results were submitted to professional journals, and this gives the book greater appeal from the standpoint of intellectual honesty. Certainly the author and those he worked with have achieved a great deal in the context of building intelligent machines. It remains to be seen whether evolutionary programming can be extended to situations that require even more creativity, such as that of generating new and interesting results in pure mathematics. This is the ultimate test in my view of machine intelligence. It is not immediately obvious how this is to be done in the evolutionary programming or indeed of any other paradigm in artificial intelligence.	2002-12-26
1293380:US	50702879	R3SKBBGDPGDYAQ	0534081185	138023976	Lectures on Quasiconformal Mappings (Wadsworth & Brooks-Cole Mathematics Series)	Books	4	10	12	N	N	Very clear and understandable exposition	The author introduces the study of quasiconformal mappings as natural generalizations of conformal mappings, as mappings less rigid than conformal mappings, as mappings important in the study of elliptic partial differential equations, as generating interesting extremal problems, as important in moduli theory and Fuchsian and Kleinian groups, and as mappings that are better behaved in the context of several complex variables. This short book gives a general overview of the important properties of quasiconformal mappings, with these goals and properties in mind.<br /> As the author notes, quasiconformal mappings were introduced by the mathematician H. Grotzsch in 1929 as mappings that are as close to conformal as possible, but that can, for example, take a square in the plane and map it to a (non-square) rectangle in the plane, mapping vertices onto vertices in the process. Conformal maps cannot do this, and a measure of how far the quasiconformal map is from being conformal involves the calculation of the dilatation at a point. The dilatation is computed by considering the effect that the linearization of a C1 homeomorphism has on circles. Such circles are mapped to ellipses, and the ratio of the major to the minor axis gives the dilatation. The dilatation is 1 for a conformal mapping. Following Grotzsch, a mapping is then said to be quasiconformal if the dilatation is bounded, and K-quasiconformal if the dilatation is less than or equal to K.<br /> For a family C of curves in the plane, the author introduces the extremal length of C, and shows that it is invariant under conformal mappings and &quot;quasi-invariant&quot; (multiplied by a bounded factor) under quasiconformal mappings. And following precedents from harmonic analysis, the author defines the Dirichlet integral, and shows it to be quasi-invariant under quasiconformal mappings.<br /> A more general definition of a quasiconformal mapping is then given, that relaxes the Grotzsch requirement that the mappings be C1. A (topological) mapping is called K-quasiconformal if the &quot;modules&quot; of quadrilaterals are K-quasi-invariant. Quadrilaterals are defined to be Jordan regions with a pair of disjoint arcs on the boundary. The &quot;module&quot; is then defined to be the ratio of the sides of the rectangle that the quadrilateral is mapped to  conformally. A 1-quasiconformal mapping is shown to be conformal under this new definition. This &quot;geometric&quot; definition of quasiconformal is followed by an &quot;analytic&quot; one, namely that a (topological) mapping is K-quasiconformal if it is &quot;absolutely continuous on lines&quot;, with another condition that the ratio of its complex derivatives must be bounded by (K-1)/(K+1). A function on a region is &quot;absolutely continuous on lines&quot; if it is absolutely continuous on almost every horizontal and vertical line of any rectangel in the region. The author proves that the geometric and analytic definitions are equivalent.<br /> The author then considers three different extremal problems for a doubly-connected region in a finite plane. The problem of finding the largest value of the module of this region is considered for three different conditions on this region and its bounded and unbounded components. Simple relations are shown to exist between the three different extremal modules. Also, and very interestingly, the author gives a connection between these extremal modules and elliptic curves. Mori's theorem is also proved, which gives a &quot;Holder inequality&quot;, i.e. information on the &quot;stretching&quot; ability of K-quasiconformal mappings of the open unit disk to the open unit disk. This then allows a homeomorphic extension to the closed disk. The author then shows that K-quasiconformal mappings of the unit disk unto itself form a sequentially compact family with respect to uniform convergence. He then considers the question as to when quadruples of distinct complex numbers can be mapped to each other under K-quasiconformal mappings.<br /> These results naturally set up a study of the boundary value properties of quasiconformal mappings. The author proves an &quot;M-condition&quot; that is satisfied by a boundary correspondence mapping. This condition involves the parameter K, and the author shows that the boundary values of a K-quasiconformal mapping must satisfy this condition. He then studies the extent to which quasiconformal mappings are isometries, called &quot;quasi-isometries&quot; where distances are multiplied by a bounded factor. The author then gives an interesting discussion as to the geometric properties of curve that the real line gets mapped to when a quasiconformal mapping of the entire complex plane is considered.<br /> Attention is then concentrated on proving the existence of quasiconformal mappings with a given complex dilatation. This entails a solution of the Beltrami equation, and for this purpose the author constructs two different integral operators, one of which acts on Lp functions for p &gt; 2, the other acting on C2 functions with compact support.  All of his discussion has the flavor of classical harmonic analysis, with detailed attention given to the proof of the Calderon-Zygmund inequality.<br /> The author ends his book with a consideration of Teichmuller spaces, with attention given to the extent to which the classical theory of conformally equivalent Riemann surfaces can be generalized to the context of quasiconformal mappings. The Teichmuller space is thus defined as the collection of pairs of Riemann surfaces and sense-preserving quasiconformal mappings between them, with pairs being equivalent under homotopy. The familiar Beltrami and quadratic differentials make their appearance, and the image of the mapping of the unit ball of Beltrami differentials to the spece of quadratic differentials is shown to be open. The Teichmuller space is then shown to be an open subset of the space of quadratic differentials, with the Teichmuller metric giving the same metric as the norm in the space of quadratic differentials. This space has dimension 3g - 3 when the starting Riemann surface has genus g, and with respect to the parameters of the basis of this space, one obtains a holomorphic family of Riemann surfaces.each other under K-quasiconformal mappings.<br /> These results naturally set up a study of the boundary value properties of quasiconformal mappings. The author proves an &quot;M-condition&quot; that is satisfied by a boundary correspondence mapping. This condition involves the parameter K, and the author shows that the boundary values of a K-quasiconformal mapping must satisfy this condition. He then studies the extent to which quasiconformal mappings are isometries, called &quot;quasi-isometries&quot; where distances are multiplied by a bounded factor. The author then gives an interesting discussion as to the geometric properties of curve that the real line gets mapped to when a quasiconformal mapping of the entire complex plane is considered. <br /> Attention is then concentrated on proving the existence of quasiconformal mappings with a given complex dilatation. This entails a solution of the Beltrami equation, and for this purpose the author constructs two different integral operators, one of which acts on Lp functions for p &gt; 2, the other acting on C2 functions with compact support.      All of his discussion has the flavor of classical harmonic analysis, with detailed attention given to the proof of the Calderon-Zygmund inequality. <br /> The author ends his book with a consideration of Teichmuller spaces, with attention given to the extent to which the classical theory of conformally equivalent Riemann surfaces can be generalized to the context of quasiconformal mappings. The Teichmuller space is thus defined as the collection of pairs of Riemann surfaces and sense-preserving quasiconformal mappings between them, with pairs being equivalent under homotopy. The familiar Beltrami and quadratic differentials make their appearance, and the image of the mapping of the unit ball of Beltrami differentials to the spece of quadratic differentials is shown to be open. The Teichmuller space is then shown to be an open subset of the space of quadratic differentials,with the Teichmuller metric giving the same metric as the norm in the space of quadratic differentials. This space has dimension 3g - 3 when the starting Riemann surface has genus g, and with respect to the parameters of the basis of this space, one obtains a holomorphic family of Riemann surfaces.	2002-12-26
1294790:US	50702879	R229VQWXJAK6XA	0764155415	163935969	Robots: Bringing Intelligent Machines to Life	Books	4	5	5	N	Y	A really fun book	Research into artificial intelligence has been undergoing a roller coaster ride in the past four decades. Promises were made, but were never fulfilled as to the building of intelligent machines. Both the military and industry were interested in robotics, and industry got what it needed at the time, in the context of manufacturing, but these robots were by no means intelligent. Lately a new wave of optimism in artificial intelligence has appeared, and one will naturally wonder if this optimism is justified. Highly advanced intelligent machines have been predicted to arise in the next two decades, but it remains to be seen if the research in artificial intelligence will allow this to come to fruition.<br /> This brief but insightful book is about the ongoing efforts to build intelligent robots. It gives though a healthy dose of skepticism, and that serves to remind the reader that a lot of hard work is ahead if these types of machines are to be built. The author emphasizes the viewpoint that  basing intelligence on the human model as was done in the last thirty years has not resulted in advances in artificial intelligence. Therefore, the author looks to other more simple forms of life to obtain a model of intelligence. Indeed, in the book one finds robots based on snakes, monkeys, flies, cockroaches, grasshoppers, crabs, pikes, birds, orangutans, tortoises, lobsters, crickets, lampreys, dogs, and platypuses. It remains to be seen if this approach will lead to the rise of intelligent machines, but the book does give a highly interesting overview of what has been accomplished to date using this approach. The acceptance of robots and their practical use could perhaps be done best by introducing them as objects we are familiar with. Pet robots or robots that perform useful but restricted functions as already begun in the marketplace, with impressive results.<br /> The author discusses some interesting work on just how to employ robots in the field so that they are able to function and obtain energy autonomously. Anyone who has owned a pet robot understands the aggravation of the frequent need to recharge batteries. The author gives the example of the &quot;SlugBot&quot;, which captures real slugs, drops them into a methane-producing biomass generator, which produces electricity for the robot. The engineering difficulties of this approach are enormous of course, and the author is careful to point this out. Farmers though, would appreciate the assistance of these slug-exterminator robots. Other strategies that deal with the &quot;recharging&quot; problem are discussed, such as the one of building &quot;robot ecosystems&quot;.<br /> The author also includes a very brief discussion on &quot;robot cars&quot;, pointing out that autonomous cars are already a reality. The legal environment though is the only real impediment to their being put into production, as the author points out. This and human factors, such as the trust that an individual must feel in permitting the car to deliver him safely to the destination, will play a major role in the acceptance of robot cars, and robots in general. Humans need to know that the robots are smart enough, and adept enough physically, to assist them in tasks that might bring them physical harm.<br /> Robot toys in the form of &quot;baby bots&quot; are also discussed in the book: the &quot;Robota doll&quot;, which was designed to react to touch and handling and to the presence of a human. The author discusses the negative reaction of child development experts to robot dolls, the claim being that children may perhaps be confused about whether the doll is really alive. She raises the question as to whether the money spent on robot doll research would best be spent on child playgroups. Her question is an interesting one, and the answer to it will determine the economic plausibility of developing robots. If a certain need can be met without robots, and at a substantially less cost, there will be no incentive to bring robots to the marketplace, in the area in question. Researchers and business people are going to have to scale down the cost for intelligent robots if they are to become normal additions to the human community.<br /> No book about robots could be complete without a discussion of nanotechnology, and the author does this in the context of the physics. The accelerations and momenta of nanobots is not a problem that researchers need to be concerned with, contrary to the case of large robots. The author also discusses the possibility of using DNA as a &quot;chemical glue&quot; to assemble molecule-size nanobots. This brings in to the picture the use of genetic engineering to assist in the manufacture of these nanobots, a prospect that is utterly fascinating.o incentive to bring robots to the marketplace, in the area in question. Researchers and business people are going to have to scale down the cost for intelligent robots if they are to become normal additions to the human community. <br /> No book about robots could be complete without a discussion of nanotechnology, and the author does this in the context of the physics. The accelerations and momenta of nanobots is not a problem that researchers need to be concerned with, contrary to the case of large robots. The author also discusses the possibility of using DNA as a &quot;chemical glue&quot; to assemble molecule-size nanobots. This brings in to the picture the use of genetic engineering to assist in the manufacture of these nanobots, a prospect that is utterly fascinating.	2002-12-24
1295848:US	50702879	RIVDCZ58GGDJ8	0394549430	114015277	Forever Undecided: A Puzzle Guide to Godel	Books	3	10	42	N	N	Where is an example?	In the every day practice of mathematics or viewing the works of others, I have never ran across or derived a self-referential statement of the kind that Goedel used in his proof of the incompleteness theorems. The appearance of these kinds of statements takes place only in the context of mathematical logic, and their construction is is somewhat artificial, involving the use of 'diagonalization'. It is for this reason that I don't find the incompleteness theorems in any way troubling for the \\"truth\\" of mathematics. If they kept arising in the everyday practice of mathematics, this would lend support to the incompleteness theorems. As such though there is no \\"empirical\\" support for them, and until they do arise they can be safely ignored.<br /> The results of Goedel have been used to cast doubt on the \\"foundations\\" of mathematics and the \\"strong AI\\" problem. But they have also been used to support \\"strong AI\\", as it is felt that the existence of self-referential statements are an indication that a machine is conscious. All of these arguments are interesting, but they have yet to help in the practice of mathematics or in the construction of intelligent machines. In fact, too long an emphasis on these results has probably retarded the advancement of artificial intelligence research. The incompleteness theorems though have stimulated research in the field of 'automatic theorem proving' and in this respect they can be said to have had some value.<br /> This book gives an overview of Goedel's incompleteness theorems and its corollaries from a \\"semi-popular\\" point of view, meaning that readers are expected to have some background in elementary logic as well as philosophy, in order to appreciate the contents. The author is eloquent and enthusiatic throughout the book, and this serves to make the book more palatable for the absolute beginner. It would be unfortunate maybe that readers will begin to doubt the \\"truth\\" of mathematics after reading this book, but that doubt could also be viewed as a virtue, in that it would motivate further thinking and research. But again, to this date there has been no self-referential statement that has appeared in the everyday practice of mathematics....that I know of anyway.uld also be viewed as a virtue, in that it would motivate further thinking and research. But again, to this date there has been no self-referential statement that has appeared in the everyday practice of mathematics....that I know of anyway.	2002-12-23
1296197:US	50702879	R1TDQ8IJ2ZBNYS	0521426324	10259950	Perspectives of Nonlinear Dynamics, Vol. 1	Books	4	10	11	N	N	Good overview	This book is a very unusual one, not only because of its use of diagrams to get some essential points across, but it also gives counterexamples to ideas that a reader might have accepted as doctrine. In addition, although it is a book that is primarily concerned with dynamics from a mathematical point of view, there is a lot in the book that would be of interest to the physicist reader. It is too bad that the book is out of print, for it could still be used as a classroom text and as an introduction to research in the field, as there are excellent problem sets at the end of each chapter. Some of the interesting discussion in the book include: 1. A brief but very good historical outline of nonlinear dynamics, with modern nonlinear dynamics traced to the work of the mathematician Henri Poincare. 2. Early in the book, the author dispels &quot;two myths&quot; regarding nonlinear dynamics, namely that linear equations are easier to solve than nonlinear equations, and that an analytic solution of an equation gives the most useful information (if it exists). 3. The discussion on the existence and uniqueness of solutions to the equations of motion via the constraint of the Lipschitz condition and its allowance for mechanical systems with (near) discontinuous dynamics. The role of non-uniqueness in the analysis of bifurcation is emphasized. Most interesting is the author's brief discussion on the existence of 'universal differential equations', which have solutions arbitrarily close to any prescribed function. The author emphasizes though the non-physical nature of these equations. He then discusses systems whose solutions do not exist after a finite time. 4. The overview of simple bifurcation theory, which the author calls 'control space effects'. Detailed discussion (with excellent diagrams) is given on how the stability of a fixed point changes along a solution set as the bifurcation point is passed. This leads to a discussion of the important concept of structural stability and gradient systems. Gradient systems are extremely important dynamical systems and have wide-ranging uses in mathematics and physics. Morse theory thus arises in this discussion, and interestingly, the author compares gradient flows with Hamiltonian flows. Fixed points of gradient systems are shown to be structurally stable. Excellent figures are given in the treatment of catastrophe theory that appears thereafter. The author also gives as an example of this the famous optical bistability. 5. The excellent discussion on the suspension of the tent map. The adding of a dimension to the problem has its advantages, as the author shows in his discussion. 6. The discussion on shadowing is excellent and the author shows its relevance in numerical computations. The author is well aware that one must first prove that the system is chaotic before one can claim the (finite) computed orbits shadow true orbits. Sometimes this is forgotten in the literature on numerical analysis of chaotic dynamical systems. 7. The discussion of homoclinic and heteroclinic orbits. These have become ubiquitous in the study of dynamical systems, and the author gives the pendulum oscillator as an example, along with &quot;Duffing&quot; type oscillators.ity and gradient systems. Gradient systems are extremely important dynamical systems and have wide-ranging uses in mathematics and physics. Morse theory thus arises in this discussion, and interestingly, the author compares gradient flows with Hamiltonian flows. Fixed points of gradient systems are shown to be structurally stable. Excellent figures are given in the treatment of catastrophe theory that appears thereafter. The author also gives as an example of this the famous optical bistability. 5. The excellent discussion on the suspension of the tent map. The adding of a dimension to the problem has its advantages, as the author shows in his discussion. 6. The discussion on shadowing is excellent and the author shows its relevance in numerical computations. The author is well aware that one must first prove that the system is chaotic before one can claim the (finite) computed orbits shadow true orbits. Sometimes this is forgotten in the literature on numerical analysis of chaotic dynamical systems. 7. The discussion of homoclinic and heteroclinic orbits. These have become ubiquitous in the study of dynamical systems, and the author gives the pendulum oscillator as an example, along with &quot;Duffing&quot; type oscillators.	2002-12-22
1297011:US	50702879	R3I2K5F22TT4RN	0066214122	245555180	Prey	Books	3	0	2	N	Y	Well, the first part was really good	Literature can both reflect societal moods and create them. This book may be an example of this cliche, as it is a jump start on a particular area of technology that is the subject of intense research at the present time: nanotechnology. There is talk about the possibility of self-replicating nanoscale robots, and with also the possibility that these entities could be intelligent, many individuals, scientists and non-scientists alike, feel apprehensive about this technology. The technology is not yet here, but developments in the 21st century are accelerating at an unprecedented rate.<br /> The book starts off well, at least after the introduction, which the author has felt the need to insert. The presence of the introduction is a distraction from the story line, at least for me personally, for I want to start the story without any biases or prejudices. The author's opinions in the introduction are somewhat negative about the future and character of humankind. A reader disagreeing with the author's opinions may be tempted to read the book with a hostile frame of mind. The author therefore should have kept his opinions to himself, and have spoken them through the characters in the book. He is clearly very worried about the developments in nanotechnology, and does not trust the scientific community to deal with it responsibly. The author though is bound by the constraint of making the story interesting, and that is hard to do without interjecting a large degree of malevolence in the technologies he is using in his story. Friendly, helpful nanobots are not going to hold anyone's attention for long.<br /> The first 150 pages or so of the book were very exhilirating: the tension building in the mind of Jack, the main character, and his doubts regarding his wife's behavior kept my attention. The author does a fine job of capturing his introspection, and in the meantime the reader gets a kind of crash introduction to terminology of evolutionary algorithms and artificial intelligence. Indeed, the reader gets exposed to talk of distributed parallel processing, or \\"agent-based programs\\", artificial life, ant routing, genetic algorithms, and protein folding, to name a few.<br /> As soon as Jack enters the desert though, the story gets less credible. Since this book has only been released for a few weeks, I could only say why I believe this by revealing the plot, which I don't want to do for the sake of new readers. I was surprised actually that the author took the move he did, as I was expecting the behavior of the nanobots to be much more subtle, as well as their detection. Instead though their behavior was very extreme, and this led me to think of how easy they would be to combat. The behavior of the nanobots would be much more believable if they would have acted in more mischevious ways, and such behavior would follow I think more naturally from the first part of the book.<br />  As the story nears its end, the events become more and more unbelievable. In addition, the characters seem to be almost juvenile in their behavior, and the author has the annoying habit of having them constantly using the \\"F-word\\". This is supposed to (I guess) make them more realistic, but instead they come across like they are playing nothing more than a difficult video game. In addition, obvious countermeasures to the nano-swarms make the story less believable. One could for example program a collection of swarms to engage in battle with the malevolent ones.<br /> Hence in general this is a disappointing book, which again is too bad considering the first part, which was written very well. I did not walk away with a feeling of foreboding that I did when reading the author's \\"Andromeda Strain\\" way back when. And if the book was meant to frighten the reader about the perils of nanotechnology, it missed its mark, considerably. But even if it did succeed in instilling fear about the possibility of nanotechnology, the research in this area will continue, and hopefully will be realized very soon.hopefully will be realized very soon.	2002-12-21
1299227:US	50702879	R3DQUKXV0A95HA	0262060795	101737482	RePresentations: Philosophical Essays on the Foundations of Cognitive Science	Books	4	6	8	N	N	Philosophy must respect cognitive science	The mind-body problem is of relatively recent vintage in Western philosophy, but it has become of importance of late due to the role it plays in the &quot;strong A.I.&quot; problem. Although the field of artificial intelligence is no where near to creating thinking machines, let alone conscious ones, the debate over whether the latter is indeed possible has been raging now for several decades. Sometimes philosophy raises and debates issues that have no immediate practical significance, and the possibility of &quot;strong A.I.&quot; is currently one of these. But developments in A.I. may indeed make these discussion not as vacuous as they currently are, and so it may in some sense be helpful to analyze some of these arguments, with also the hope that they can shed light on the nature of intelligence and help those who are interested in the building of an artificial mind.<br /> The author considers his book a blending of three ideas, namely functionalism, intensionality, and mental representation. He introduces these via a consideration of the arguments against Cartesian dualism that were being formulated in the early 1960's. The author labels &quot;logical behaviorism&quot; and &quot;central state identity theory&quot; as being two of the strategies for doing this. In logical behaviorism, mental processes are semantically equivalent to behavioral dispositions, and the definitions of these reduced to that of stimulus and response parameters, these parameters left essentially undefined. The author gives counterexamples to show that logical behaviorism falls short of being a theory of mental causation that allows nontrivial psychological theories to be constructed. Throughout the book, the author makes the requirement that a science of mind must define mental properties in a way that makes them natural from the standpoint of psychological theory construction. He makes the point, interestingly, that information processing systems can provide a natural domain for this kind of theory construction. He thus admits the possibility that these systems can share our psychology but not share our physical make-up. He sums this up by saying that &quot;philosophical theories about the nature of mental properties carry empirical commitments about the appropriate domains for psychological generalizations&quot;. Physicalism does not meet these requirements he states.<br /> The author thus asserts the need for a &quot;relational&quot; treatment of mental properties, and so he turns his attention to &quot;functionalism&quot;. Along with stimulus/response, this theory also allows reference to other mental states. But functionalism is not a reductionist philosophy like behaviorism, for it admits mentalistic concepts, and these are relationally defined and causal. It thus allows psychological theory construction of the kind that a psychologist requires. However, the author is careful to note that functionalism must deal with two problems, one being the development of a vocabulary which specifies the allowed kinds of descriptions for causes and effects, the other being that one must gaurantee that functional individuation only takes place when there is a mechanism that can carry out the function and only where there is an idea of what such a mechanism is. One wants, in functionalism, to avoid &quot;pseudo-explanations&quot; like those arising in physicalism.<br /> This is where the author brings in the (Turing) machines, via &quot;machine functionalism&quot;, which he claims solve the above problems. Functional definitions of psychological kinds are identical to the ones used to specify the program states of the computer. The author then elaborates in detail on just how machine functionalism is able to cope with the problems discussed. The Turing machine can provide a sufficient condition for the mechanical realizability of a functional theory, and thus  mental processes correspond to a certain Turing machine process, and for each Turing machine process a mechanical realization.<br /> He is careful though to not let this theory do more than it should (or can), such as circular arguments that involve the postulating of processes for which no mechanical realization can exist. He then addresses the degree to which functionalism could be said to be a successful theory. Could one really accept that it is relational properties that induce pain rather than an itch? His argument involves the difference between &quot;qualia inversion&quot; and &quot;propositional attitude inversion&quot;, the former possible, the latter not. He argues that it is not a conceptual possibility of one person's belief being different from another's despite the identity of their inferential roles. He does however give references for possible ways of avoiding this.<br /> The author is firmly committed to having both a philosophical and psychological theory of propositional attitudes. His attitude here is an interesting one, for I think it is a sign of things to come in the intersection between science and philosophy. He states that the goal of cognitive psychology is to systematize and explain how the propositional attitudes of an organism are affected by experience, by genes, and other propositional attitudes that it has. The success of such a psychological theory puts constraints on the construction of the philosophical theory. This, again, is a most interesting move, for it is an example of a new way of doing philosophy, namely that of constructing philosophical theories that must respect scientific results. For the author, the distinction between a philosophical and a psychological theory is heuristic, namely it is a quick way of indicating which kinds of constraints are being used in the motivating of a given strategy in theory construction. This book is an example of this kind of strategy, and as a whole it is a fascinating one, particularly in the context of current research in artificial intelligence.  When philosophers see the rise of thinking machines in the near future, their philosophical theories will have to adapt themselves to the abilities of these machines. And the machines themselves will have their own (unique) theories about their abilities.cess a mechanical realization. <br /> He is careful though to not let this theory do more than it should (or can), such as circular arguments that involve the postulating of processes for which no mechanical realization can exist. He then addresses the degree to which functionalism could be said to be a successful theory. Could one really accept that it is relational properties that induce pain rather than an itch? His argument involves the difference between &quot;qualia inversion&quot; and &quot;propositional attitude inversion&quot;, the former possible, the latter not. He argues that it is not a conceptual possibility of one person's belief being different from another's despite the identity of their inferential roles. He does however give references for possible ways of avoiding this. <br /> The author is firmly committed to having both a philosophical and psychological theory of propositional attitudes. His attitude here is an interesting one, for I think it is a sign of things to come in the intersection between science and philosophy. He states that the goal of cognitive psychology is to systematize and explain how the propositional attitudes of an organism are affected by experience, by genes, and other propositional attitudes that it has. The success of such a psychological theory puts constraints on the construction of the philosophical theory. This, again, is a most interesting move, for it is an example of a new way of doing philosophy, namely that of constructing philosophical theories that must respect scientific results. For the author, the distinction between a philosophical and a psychological theory is heuristic, namely it is a quick way of indicating which kinds of constraints are being used in the motivating of a given strategy in theory construction. This book is an example of this kind of strategy, and as a whole it is a fascinating one, particularly in the context of current research in artificial intelligence.  When philosophers see the riseof thinking machines in the near future, their philosophical theories will have to adapt themselves to the abilities of these machines. And the machines themselves will have their own (unique) theories about their abilities.	2002-12-19
1300114:US	50702879	R1QRVC16U23FF2	3540412212	512817369	Lectures on Seiberg-Witten Invariants (Lecture Notes in Mathematics)	Books	4	6	7	N	N	A good introduction	This book is a short and elementary introduction to the Seiberg-Witten equations, which created quite a stir back in 1994 when they were first proposed. The book is elementary enough that it could be read by someone without a background in the intricacies of the geometry and topology of 4-dimensional topological and smooth manifolds, but the results can be better appreciated if one already has such a background. A background in quantum field theory, specifically the guage theory of the strong interaction, called quantum chromodynamics, will also help in the appreciation of the book. A lot of work has been done in elucidating the properties of the Seiberg-Witten equations since this book was written, but the book could still serve as an introduction to these developments.<br /> The author gives a brief introduction to the use of Seiberg-Witten equations in chapter 1, along with a review of the background needed from the theory of vector bundles, differential geometry, and algebraic topology needed to read the book. All of this background is pretty standard, although the appearance of spin structures may not be as familiar to the mathematician-reader, but completely familiar to the physicist reader. Detailed proofs of the main results are not given, but reference to these are quoted. Also, the theory of characteristic classes is outlined only briefly so no insight is given as to why they work so well. In particular, the reason for the vanishing of the second Stiefel-Whitney class as a precondition for the manifold having a spin structure is not given.<br /> In chapter 2, the author goes into the spin geometry of 4-manifolds in more detail. After discussing the role of quaternions in this regard, spin structures are defined. A spin structure on a manifold M, via its cocycle condition, give two complex vector bundles of rank two over M. The complexified tangent bundle can thus be represented in terms of these vector bundles, which are themselves quaternionic line bundles over M. The author also defines spin(c) structures, and shows how, using an almost complex structure, to obtain a canonical spin(c) structure on a complex manifold of complex dimension two. The spin(c) structure also allows a construction of the &quot;virtual vector bundles&quot; W+, W-, and L, for manifolds that do not have a spin structure. These bundles play a central role in the book. Clifford algebra becomes meaningful on the direct sum W of W+ and W-, and spin connections can be defined on W. In particular given a unitary connection on a complex line bundle L over a spin manifold M, one can obtain a connection on the tensor product of W and L. When M is not a spin manifold, this is still possible but one must use the &quot;square&quot; L^2 of L. One can then define the Dirac operator over the sections of this tensor product, which the author does and extends it to one with coefficients in a general vector bundle. The author then discusses, but does not prove, the Atiyah-Singer index theorem and the Hirzebruch signature theorem. These theorems, the author emphasizes, are proved in the context of linear partial differential equations, and give invariants of 4-manifolds.<br /> This sets up the discussion in chapter 3, which deals with the problem of how to find invariants of 4-manifolds if one works in the context of nonlinear partial differential equations. Those familiar with the Donaldson theory, which was done using the (nonlinear!) Yang-Mills equations, will understand the difficulties of this approach. The strategy of the nonlinear approach as outlined by the author is to show that the solution set of a nonlinear PDE is compact and a finite-dimensional compact manifold. The solution set depends on the Riemannian metric, but its cobordism class does not, and this may give a topological invariant. The fact that it is defined in terms of a PDE might give a way of distinguishing smooth structures.<br /> The Seiberg-Witten theory is one method for doing this.The Seiberg-Witten equations are nonlinear, but the nonlinearity is &quot;soft&quot; enough that it can be dealt with. They arise in the context of oriented 4-dimensional Riemannian manifolds with a spin(c) structure and a positive spinor bundle W+ tensored with L. A connection on L^2 and a section of this spinor bundle are chosen to satisfy these equations, which involve the self-dual part of the connection. One also needs to work with the &quot;perturbed&quot; Seiberg Witten equations, where a self-dual two-form is added. The moduli space of the solutions to the perturbed Seiberg-Witten equations is shown to form a compact finite-dimensional manifold. The proof follows essentially from the Weitzenbock formula, the Sobolev embedding theorem, and Rellich's theorem. Sard's theorem shows that the moduli space is smooth and the Fredholm theory shows it is oriented. The Seiberg-Witten invariants  are associated to virtual complex line bundles over the 4-manifold, and when the dimension of the self-dual harmonic two-forms is greater than or equal to 2, and the dimension of the moduli space is even. Their definition does involve the Riemannian metric, but changing this metric only alters the moduli space by a cobordism. It is proved that oriented Riemannian manifolds with positive scalar curvature have vanishing Seiberg-Witten invariants. Kahler surfaces are shown to have positive Seiberg-Witten invariants, and the author proves that there is a compact topological manifold with infinitely many distinct smooth structures. Unfortunately though, an explicit example of one of these is not given. Such an example  may be very important from the standpoint of physics, for the behavior of dynamical systems or quantum field theories might be very different for different smooth structures.s. The Seiberg-Witten equations are nonlinear, but the nonlinearity is &quot;soft&quot; enough that it can be dealt with. They arise in the context of oriented 4-dimensional Riemannian manifolds with a spin(c) structure and a positive spinor bundle W+ tensored with L. A connection on L^2 and a section of this spinor bundle are chosen to satisfy these equations, which involve the self-dual part of the connection. One also needs to work with the &quot;perturbed&quot; Seiberg Witten equations, where a self-dual two-form is added. The moduli space of the solutions to the perturbed Seiberg-Witten equations is shown to form a compact finite-dimensional manifold. The proof follows essentially from the Weitzenbock formula, the Sobolev embedding theorem, and Rellich's theorem. Sard's theorem shows that the moduli space is smooth and the Fredholm theory shows it is oriented. The Seiberg-Witten invariants  are associated to virtual complex line bundles over the 4-manifold, and when the dimension of the self-dual harmonic two-forms is greater than or equal to 2, and the dimension of the moduli space is even. Their definition does involve the Riemannian metric, but changing this metric only alters the moduli space by a cobordism. It is proved that oriented Riemannian manifolds with positive scalar curvature have vanishing Seiberg-Witten invariants. Kahler surfaces are shown to have positive Seiberg-Witten invariants, and the author proves that there is a compact topological manifold with infinitely many distinct smooth structures. Unfortunately though, an explicit example of one of these is not given. Such an example  may be very important from the standpoint of physics, for the behavior of dynamical systems or quantum field theories might be very different for different smooth structures.	2002-12-18
1303271:US	50702879	R2SSMY3SS51TYD	0201500604	972124965	Semio Physics: A Sketch (English and French Edition)	Books	3	8	10	N	N	Highly speculative	The title of this book obviously has its origins in &quot;semiotics&quot;, a school of philosophy and linguistics of French origin, and the author, being French himself, is clearly influenced by this school (although in this book no admission to this is made). He does however discuss why he chose the name &quot;semiophysics&quot;: namely to seek out &quot;significant forms&quot;, and to build a &quot;general theory of intelligibility&quot;. The author attempts to show in the book that there are only certain elements of reality that really make sense and only these can be used as a basis for a meaningful linguistic description. Thus one must find &quot;stable elements&quot; or &quot;salient forms&quot; which the author contends have the shape of balls, and interact like living beings. Mathematically speaking, the &quot;balls&quot; are bounded closed sets of maximum dimension (three in this case). There are then &quot;pregnances&quot; which propagate from one salient form to another. The form can then change its state, and can re-emit the pregnance, the latter of which may or may not be changed in the process. The author endeavors to combine this approach with what he had discovered in the works of Aristotle.<br />  Those readers who know of the author's work in mathematics, particularly in differential topology, may perhaps be surprised by the content of this book. There are some interesting concepts elucidated in it, but as a whole the wording and argumentation are rather difficult to follow. Catastrophe theory, a theory developed by the author in the 1960s, is used here in an attempted justification of the Aristotelian notion of &quot;continuity&quot;. Thus the book could be viewed as an interpretation of Aristotle from the viewpoint of catastrophe theory. The concept of continuity is primordial for the author, for he believes that discontinuity, which is modeled by the formalism of catastrophe theory, requires continuity for its definition. Most interestingly though, the author holds that all epistemology must be &quot;genetic&quot;, for it must, in his words, take into account the the effect of evolutionary alterations that humans have been subjected to for many millenia. But he still presupposes, and says so explicitly, the Euclidean nature of space-time, asserting that the discovery of non-Euclidean geometry and general relativity are irrelevant to the problems which he is going to discuss. These discoveries, he says, belong to the &quot;ontological region&quot;, and lie outside the cognitive activity of ancient man. The goal of the book is to take concepts from the &quot;exact&quot; sciences, such as the notion of a field in physics, phase transitions (implying discontinuities), and the notion of individuality. These notions are then extended to abstract spaces of a semantic character (this move clearly overlapping what is done in semiotics). Chapter 8 of the book, entitled &quot;Aristotelian Perspectives in Language Theory&quot; is another example of the influence of semiotics on the author's project.<br /> There are some discussions in the book that reflect the time of publication. For instance, the author speaks of the replacing of a point by a small oscillator that duplicates itself, and remarks that this concept may be useful from a quantum mechanical standpoint. But string theories were definitely around at the time of publication, and the replacing of point particles by strings that oscillate, and are created and destroyed, is an example of what the author is asserting (but does not elaborate on in any detail). Also, the catastrophe theory of the author was supposed to model the (discontinuous) processes of cell division, or &quot;morphogenesis&quot;.  He remarks, interestingly, that &quot;not much is known about the internal structure of the cytoplasm&quot;, and so &quot;any attempt at symbolizing cellular dynamics can only be speculation&quot;. But since the time of publication of this book, the mathematical modeling of cellular dynamics has really taken off, and there is now a large group of researchers that are attempting to create a comprehensive mathematical model of the cell. Most of these developments do not involve catastrophe theory, no doubt because of its qualitative emphasis.<br /> Thus as a whole the book is highly speculative and pre-scientific. It might be difficult to appreciate by the general scientific crowd, for one must have a background in both catastrophe theory and Aristotelian philosophy in order to follow it. My opinion is that the current emphasis on quantitative mathematical modeling in all of the areas that the author discusses will continue to be the dominant one as we move further into the 21st century. All of this effort requires meticulous validation and experimentation, especially in the medical and biological areas. The truth of these efforts will thus be defined by the success they have on human health, and, with the exception of problems in medical ethics, &quot;philosophical foundations&quot; will take a back seat. Science does not need such a foundation.cal modeling of cellular dynamics has really taken off, and there is now a large group of researchers that are attempting to create a comprehensive mathematical model of the cell. Most of these developments do not involve catastrophe theory, no doubt because of its qualitative emphasis. <br /> Thus as a whole the book is highly speculative and pre-scientific. It might be difficult to appreciate by the general scientific crowd, for one must have a background in both catastrophe theory and Aristotelian philosophy in order to follow it. My opinion is that the current emphasis on quantitative mathematical modeling in all of the areas that the author discusses will continue to be the dominant one as we move further into the 21st century. All of this effort requires meticulous validation and experimentation, especially in the medical and biological areas. The truth of these efforts will thus be defined by the success they have on human health, and, with the exception of problems in medical ethics, &quot;philosophical foundations&quot; will take a back seat. Science does not need such a foundation.	2002-12-16
1303976:US	50702879	R3RD6Q6BDPS0KT	1558607978	20052112	Evolutionary Computation in Bioinformatics (The Morgan Kaufmann Series in Artificial Intelligence)	Books	3	14	17	N	Y	A good literature survey	The subject of this book would seem a natural one, given the evolutionary paradigm in biology. Genetic algorithms and evolutionary programming have now found use in many different fields such as physics, financial engineering, network modeling, and computational radiology, to name a few. This use will no doubt continue as computer processing power increases in the future. Although genetic/evolutionary approaches are still much more effective from a computational point of view than strict combinatorial ones, they are still very time intensive, and for many problems have yet to compete with ordinary Monte Carlo techniques. This book gives a brief overview of how evolutionary algorithms are used in bioinformatics, with emphasis on genetic sequence alignment and protein folding. The book does not offer in-depth discussion on these algorithms, but does give references where more information can be obtained. Therefore the book could be described as a literature survey, at least for the chapters that I read, which did not include those on protein folding.<br /> The book is written for the computer scientist who wants to move into bioinformatics, and the biologist, who needs more background in these types of algorithms. Therefore, the editors of the book include two introductory chapters, one introducing bioinformatics for computer scientists, the other an introduction to evolutionary computation for biologists. The latter is more detailed, and the authors introduce the biologist to some of the elementary aspects of evolutionary computation. One interesting, but too short discussion is on the &quot;No Free Lunch Theorem&quot;, which implies that evolutionary programs are not in any sense &quot;universal&quot;, in that the choice of such a program will depend on the problem at hand, and in fact there may be many such programs for the problem, each with their own performance properties. The theorem is not proved in this book, but references to the proof are given. However, the proof involves a level of mathematics that a biologist would probably not have knowledge of, and so this reference would not be accessible to such a reader. In addition, the theorem has generated a lot of controversy, but the authors do point this out. The authors also discuss effectively the difference between the analytical and heuristic approaches to sequence alignment, setting the stage for later chapters in the book. The problem of local search algorithms getting &quot;trapped&quot; in local minima is also given a very intuitive and understandable treatment by the authors.<br /> The book also includes a discussion on the &quot;DNA sequence reconstruction problem&quot;. Algorithms for dealing with this problem are recommended and the the problem is presented as one in integer programming. The authors present a hybrid evolutionary algorithm for dealing with this problem. They characterize this algorithm as being hybrid since it does make use of &quot;crossover&quot; operators and a heuristic &quot;greedy-improvement&quot; method. The discussion of this algorithm is only brief, but references are given. However the main reference is not yet available as it is very recent and in press, and, although the authors do include a fairly lengthy discussion of computational experiments, without a detailed description of the algorithm or source code, their results cannot be checked or validated.<br /> The contrast between optimization theory and evolutionary algorithms is a common theme in the book, with emphasis on the use of evolutionary algorithms to design scoring schemes for sequence alignment where optimization issues can be ignored. The difference between the optimal alignment obtained by various mathematical techniques and the correct (biological) alignment is carefully pointed out. Thus one must be able to tell whether an objective function is relevant from a biological standpoint. In chapter 5 of the book for example, the author introduces an alignment algorithmbased on a combination of simulated annealing (SA), and genetic algorithms (GA), called appropriately SAGA. This chapter is the most helpful one in the book, for the author gives pseudocode for this algorithm, with Web links given for obtaining the source code. This allows the interested reader to study the efficacy of the SAGA algorithm in doing muliple sequence alignment.<br /> The use of simulated evolution to find optimal neural networks for identifying coding regions is discussed in chapter 9 of the book. The use of genetic algorithms to assign the weights in a neural network is well-known. The authors point out a further advantage in their use, namely that evolutionary neural networks can adapt to unexpected inputs on their own, and thus do not require any intervention on the part of the user. References are given that elaborate on the power of this approach. Readers who have worked with neural networks will understand fully the need for improvements over back-propagation and the need for automatic topology selection. The authors do not show however that the function-approximation ability of neural networks, so important from both a mathematical and applications standpoint, is improved by their approach.hm based on a combination of simulated annealing (SA), and genetic algorithms (GA), called appropriately SAGA. This chapter is the most helpful one in the book, for the author gives pseudocode for this algorithm, with Web links given for obtaining the source code. This allows the interested reader to study the efficacy of the SAGA algorithm in doing muliple sequence alignment. <br /> The use of simulated evolution to find optimal neural networks for identifying coding regions is discussed in chapter 9 of the book. The use of genetic algorithms to assign the weights in a neural network is well-known. The authors point out a further advantage in their use, namely that evolutionary neural networks can adapt to unexpected inputs on their own, and thus do not require any intervention on the part of the user. References are given that elaborate on the power of this approach. Readers who have worked with neural networks will understand fully the need for improvements over back-propagation and the need for automatic topology selection. The authors do not show however that the function-approximation ability of neural networks, so important from both a mathematical and applications standpoint, is improved by their approach.	2002-12-15
1305263:US	50702879	ROOSJG1P8KSED	0691085773	852417144	Topology of 4-Manifolds. (PMS-39)	Books	5	10	10	N	N	Brilliant overview of topology in 4 dimensions	It is too bad this book is out of print, for it introduces the reader to a fascinating branch of topology and has the clearest proof of the 4-dimensional Poincare conjecture. In addition, the authors do not hesitate to employ diagrams as needed to illustrate the main points and to assist the reader in visualizing 4-dimensional objects. The authors give a fine discussion as to the reasons why four dimensions is harder to deal with topologically than dimensions five or greater, this being essentially due to the behavior of 2-dimensional disks: mapping 2-disks into 3-manifolds results (generically) with 1-dimensional self-intersections; in 4-dimensions the intersections are isolated points, and in 5 dimensions or more the 2-disks can be embedded.<br /> Interestingly, the authors choose not to employ the famous &quot;Kirby calculus&quot; in the proofs of the main results, despite the fact that it was used extensively in their earlier works. They break the book into two parts, the first one emphasizing embedding theorems and the second one the structure of manifolds. Those readers interested in the proof of the 4-dimensional Poincare conjecture will find it in chapter 7, as a consequence of the authors proof of the h-cobordism theorem, the latter being nontrivial. It is the absence of a smooth structure on the h-cobordism that makes it so difficult in dimension four.<br /> The existence of exotic structures on 4-manifolds is discussed in detail in chapter 8 and the authors endeavor to show why dimension 4 is unique compared to higher dimensions. The existence of exotic structures on 4-manifolds is definitely interesting, and has recently been shown to have importance in physics. But physicists who need an explicit example of one of these structures will not find one here, and I know of no such examples in the literature. Such an example would be interesting from the standpoint of the behavior of quantum field theories on such 4-manifolds, as one would like to know if this behavior would indeed be different than that on the manifold with the &quot;standard structure&quot;.his behavior would indeed be different than that on the manifold with the &quot;standard structure&quot;.	2002-12-14
1307832:US	50702879	R3EY1004PZWPCV	0387511482	295472896	Topology of 4-Manifolds (Lecture Notes in Mathematics)	Books	5	7	7	N	N	Excellent	For those genuinely interested in understanding the proof of the 4-dimensional Poincare conjecture, and for those who need a more geometric, intuitive view of some of the main results in topological 4-manifolds, rather than one based on the heavy machinery of algebraic topology, this book is an excellent beginning. The author endeavors in this book to be as clear as possible, and he does not hesitate to use diagrams to get the point across. Rigor however, is not sacrificed. One of the main goals in the book is to get a more geometric proof of Rohlin's theorem, which states that cobordism ring in 4-dimensions over the special orthogonal group and over the spin group is the integers.<br /> The author starts the book with an overview of handlebody theory, noting that for the case of interest, 4-dimensional toplogical manifolds must be smooth in order for them to be handlebodies. Smooth handlebody decompositions can be described by Morse theory, and one smooth handlebody decomposition can be related to another via an isotopy of attaching maps and creation or annihilation of handle pairs. The author visualizes handlebodies in four dimensions by drawing their attaching maps in the 3-sphere. This results in the use of framed links to model the attaching maps, with examples of the 3-torus, the Poincare homology 3-sphere, and a homotopy 4-sphere, the latter of which is homeomorphic to the 4-sphere and is a double cover of an exotic smooth structure on 4-d real projective space. The author also gives a brief but interesting discussion on why the methods of this chapter are difficult to do in three dimensions.<br /> The theory of intersection forms appears in chapter two, with the author proving first that for a closed, smooth, oriented, 4-d manifold M any element of the second integer homology group is represented by a smoothly imbedded oriented surface. Any two such surfaces can be joined by smooth oriented 3-manifold imbedded in M. The isomorphism between the second homology and cohomology groups (over the integers) modulo torsion is the famous \\"intersection pairing\\". The author then proves that two simply-connected, closed, oriented 4-manifolds are homotopy equivalent if and only if their intersection forms are isometric. The proof emphasizes the geometric connection between homotopy type and intersection forms. A brief review of symmetric bilinear forms and characteristic classes is then given, as preparation for the classification results given later in the book.<br /> The author treats classification theorems in chapter three, which he describes as deciding which forms, whether symmetric, integral, or unimodular, can be represented by simply connected closed 4-manifolds. The relation between forms and homotopy type makes this implicitly a classification for the homotopy type of the manifold. Rohlin's theorem was historically the first major result in this problem, but the author delays its proof until chapter eleven. The author briefly discusses the work of Freedman in the topological case, and Donaldson, in the smooth case.<br /> Spin structures are discussed in chapter four and several examples are given. The author also shows how to relate spin structures on the boundary of a manifold to spin structures on the manifold itself, to set up later discussions on cobordism. Chapter five then concentrates on the Lie group spin structure of the 3-torus T3(Lie) and the surface constructed by taking the nine-fold direct sum of complex 2-d projective space and its reverse orientation. The latter is a complex analytic projection, which is a smooth fiber bundle with fiber the two-torus except for a finite number of singular fibers. The author shows in detail how to use this object to obtain a spin manifold with spin boundary T3(Lie).<br /> Chapter six is devoted to showing how to immerse closed, smooth, oriented 4-manifolds in Euclidean 6-d space. This involves the calculation of a characteristic class in the second integral cohomology group. Then as a warm-up to showing that a spin 4-manifold with index zero spin bounds a spin 5-manifold, the author proves in chapter 7 that every orientable 3-manifold is spin, bounds an orientable 4-manifold, and if spin bounds a spin 4-manifold with only 0-handles.<br /> In chapter eight, the author proves that a closed, smooth, connected, and orientable 4-manifold is the boundary of a smooth 5-manifold if the first Pontryagin class is 0. If the 4-manifold is spin, and the first Pontryagin class is 0, then there exists a smooth, spin 5-manifold whose boundary is the 4-manifold, where both manifolds are considered as spin manifolds. Chapter nine proves the Hirzebruch index theorem in dimension 4, and the author shows that the cobordism ring for SO and Spin is the integers. Chapter ten is devoted to a proof of Wall's theorem and the h-cobordism theorem in dimension 4. The geometric proof of Rohlin's theorem promised by the author is finally done in chapter eleven.<br /> Casson handles, so important in the proof of the 4-d Poincare conjecture, are discussed in chapter twelve. The author shows the role of the Whitney trick in dimensions 5 or more, and how its failure in dimension 4 results in the use of Casson handles, which are constructed using the famous \\"finger moves\\". He gives an explicit handlebody description of the simplest Casson handle, and then relates it to the Whitehead continuum.<br /> The most fascinating part of the book is chapter thirteen, which outlines briefly Freedman's proof of the 4-dimensional Poincare conjecture. The proof makes use of 4-dimensional handlebody theory and decomposition space theory. Casson handles are decomposed via an imbedding of a Cantor set of Casson handles inside them. The \\"Big Reimbedding theorem\\" of Freedman, which points to the existence of an exotic smooth structure on the 3-sphere cross the real line, is quoted but not proved. The book ends with chapter fourteen being a brief discussion of exotic structures, their existence following from the non-smoothness of Casson handles.group. Then as a warm-up to showing that a spin 4-manifold with index zero spin bounds a spin 5-manifold, the author proves in chapter 7 that every orientable 3-manifold is spin, bounds an orientable 4-manifold, and if spin bounds a spin 4-manifold with only 0-handles. <br /> In chapter eight, the author proves that a closed, smooth, connected, and orientable 4-manifold is the boundary of a smooth 5-manifold if the first Pontryagin class is 0. If the 4-manifold is spin, and the first Pontryagin class is 0, then there exists a smooth, spin 5-manifold whose boundary is the 4-manifold, where both manifolds are considered as spin manifolds. Chapter nine proves the Hirzebruch index theorem in dimension 4, and the author shows that the cobordism ring for SO and Spin is the integers. Chapter ten is devoted to a proof of Wall's theorem and the h-cobordism theorem in dimension 4. The geometric proof of Rohlin's theorem promised by the author is finally done in chapter eleven. <br /> Casson handles, so important in the proof of the 4-d Poincare conjecture, are discussed in chapter twelve. The author shows the role of the Whitney trick in dimensions 5 or more, and how its failure in dimension 4 results in the use of Casson handles, which are constructed using the famous \\"finger moves\\". He gives an explicit handlebody description of the simplest Casson handle, and then relates it to the Whitehead continuum. <br /> The most fascinating part of the book is chapter thirteen, which outlines briefly Freedman's proof of the 4-dimensional Poincare conjecture. The proof makes use of 4-dimensional handlebody theory and decomposition space theory. Casson handles are decomposed via an imbedding of a Cantor set of Casson handles inside them. The \\"Big Reimbedding theorem\\" of Freedman, which points to the existence of an exotic smooth structure on the 3-sphere cross the real line, is quoted but not proved. The book ends with chapter fourteen being a brief discussion of exotic structures, their existence following from the non-smoothness of Casson handles.	2002-12-12
1309071:US	50702879	R1144J9FBQEP05	067100316X	361427572	Star Trek First Contact (Star Trek The Next Generation)	Books	5	2	3	N	N	The best Star Trek story ever	This is without doubt the best of all Star Trek stories, both in film and in print. It touches on many grand philosophical, scientific, and technological themes: machine intelligence (both in Commander Data and in the Borg), space-time engineering (the first time humanity has done this, via the efforts of Zefram Cochrane), the first contact from an alien civilization (the arrival of the Vulcans), the confrontation with true history (meeting Cochrane and finding out just who the man really was), and the ethics of highly advanced civilizations (the contrast between the Borg and humanity). This book and the film will without a doubt inspire many a young reader to take up the practice of science, and thus it will do the best job of all. Science fiction has the habit of coming true sometimes, but it also has the fault of underestimating. The future of humanity, as exemplified by the Star Trek crew of the year 2367, is a grand one to contemplate, but the true future will be much better: a world populated by humans and machines striving to be the best they can be; a future that is never static, for stagnation to intelligent life is an abomination. We will do genetic engineering of humans, to be the best we can be; we will do space-time engineering, to travel beyond any immediate confines; we will create intelligent machines, to be our friends and allies. All of these things we will do, and much more. Humans and all other lifeforms, organic or not, will be very different in the time frame set in this novel. But they will be restless, ambitious, and always yearning for more understanding, for more insight, for more knowledge: these traits will characterize the beings of the 24th century...and beyond.	2002-12-11
1311422:US	50702879	RX12CMS4PGI8	0132663058	115803814	An Introduction to Philosophical Analysis (4th Edition)	Books	4	20	20	N	N	A good writer	I have read the second and third editions of this book, but not the latest (the fourth), nor have I examined the fourth edition, but I am sure that it respects the fine didactic quality of the prior editions. The author though has decreased the page count since the second edition, which was over 500 pages, to the third, which was 416 pages, to this one, which reads as 282 pages. I thought the second edition was better than the third, because it was more in-depth in its coverage. The author possibly feels that many of the philosophical problems which he addressed with more detail in prior editions do not need the coverage they do in this one.<br />The author though is a fine writer, and this book is written for the person first taking up philosophy. His informal style effectively relates the issues at hand without getting the beginning reader into too much heavy formalism. All of the issues discussed by the author are of enormous importance for living, especially in the twenty-first century which I see as a testing ground for many of these. Philosophy is making its way to the meeting rooms of industry, due to the need for ethical considerations in medicine and genetic engineering, the role of virtual and simulation environments currently used in industry, and the continuing rapid advances in artificial intelligence, to name just a few. Many, many more new philosophical problems will arise as technology races ahead, and  the new minds of the twenty-first century, both natural and artificial, will have their own unique viewpoints on the solutions to these problems.	2002-12-09
1313961:US	50702879	RYVN6O4GZD8KM	0198750242	753694446	Objective Knowledge: An Evolutionary Approach	Books	3	37	51	N	N	Good overview of 20th century philosophy of science	In a recent article on the relation between natural philosophy and quantum chromodynamics (the physical theory of the strong nuclear interaction), Frank Wilcek, a well-recognized researcher in elementary particle physics, included the following entertaining passage:<br />A man walks into a bar, takes a seat on the next-to-last stool, and spends the evening chatting up the empty stool next to him, being charming and flirtatious, as if there were a beautiful women in that empty seat. The next night, same story. And the next night, same story again. Finally the bartender can't take it any more. She asks, &quot;Why do you keep talking to that empty stool as if there were a beautiful woman in it?&quot;.<br /> The man answers, &quot;I am a philosopher. Hume taught us that it's logically possible that a beautiful woman will suddenly materialize on that stool, and no one has ever refuted him. If one does appear, then obviously I'll seem very clever indeed, and I'll have the inside track with her.&quot;<br />&quot;That's ridiculous&quot;, says the bartender, who happens to be a physicist. &quot;Plenty of very attractive women come to this bar all the time. You're reasonably presentable, and extremely articulate; if you applied your charm on one of them, you might succeed&quot;.<br />&quot;I thought about trying that,&quot; he replies, &quot;but I couldn't prove it would work.&quot;<br /> I included this passage in this review not to ridicule the work of David Hume but to emphasize that his philosophy of science is in no way troubling. The author of this book though spent most of his professional life attempting to refute the views of Hume and then justify the practice of science &quot;objectively&quot;. In the first few paragraphs of this book, the author sounds bitter about the lack of recognition for his work on &quot;the problem of induction&quot;, which he felt Hume had shown to have devastating consequences on the &quot;truth&quot; of science. The search for an objective, rational &quot;foundation&quot; of science has occupied the time of this author and many others, who hold to the idea that scientific knowledge needs such a foundation and the Humean challenge must be answered. To those readers who agree with the author in this regard, this book would be of interest. To those who do not, this book could possibly be read as an exercise in mental gymnastics. There are some places in the book where issues are raised that are important in fields such as artificial intelligence, but as a whole the book is typical of 20th century philosophy of science: it holds as axiomatic that scientific knowledge needs an underlying foundation.<br /> Since I personally do not believe the David Hume has to be answered at all, a review of the author's arguments against Hume would be misplaced. Having read Hume's works in detail, and having walked away from them puzzled as to why they are considered so &quot;formidable&quot; or &quot;devastating&quot;, my interest in this book was purely subjective: that of gaining insight as to why many philosophers of science are so deeply troubled by Hume's philosophy and other science skeptics. Finishing the book still left my questions unanswered in this regard, and judging by a perusal of the literature on the philosophy of science, Humean skepticism is still considered the &quot;thing to answer&quot;. Scientific truth is still held in doubt to a large degree, and debates on it in the social and political realm usually take place in the context of religion or why creationism should be taught in the public schools.<br /> But science needs no foundation. The game of philosophy should now be what consequences science has for philosophy. What theories of truth, of ethics, of knowledge, are possible for philosophy because of science? If this book were rewritten to reflect this attitude, its content would be very different, possibly more elaborate in its views. The avenues that science opens up in ethics, epistemology,and ontology are rich in information theory, mathematics, logic, and many other areas. Scientific and technological advances are exploding at an unprecedented rate, and no Humean challenge or backlash can stop it.....thankfully.ology, and ontology are rich in information theory, mathematics, logic, and many other areas. Scientific and technological advances are exploding at an unprecedented rate, and no Humean challenge or backlash can stop it.....thankfully.	2002-12-07
1315435:US	50702879	R1LSE3WX9Z6535	0865760063	161681637	Handbook of Artificial Intelligence, Vol. 2	Books	4	6	6	N	N	A good introduction to GOFAI	This is the second volume of a 3-volume set summarizing what was known at the time in the field of artificial intelligence (A.I.) Most of the content of this book is now called GOFAI, for \\"good-ole fashioned artificial intelligence\\", but many of the algorithms and concepts discussed in this book are still used today, making this book still useful.<br /> This volume is centered more on applications of A.I. to the sciences, robotics, and language translation. In the introduction to the first volume one can find the following statement, which was true back then and dramatically more so at the present time: \\"There is every indication that useful A.I. programs will play an important part in the evolving role of computers in our lives-a role that has changed, in our lifetimes, from remote to commonplace and that, if current expectations about computing cost and power are correct, is likely to evolve further from useful to essential.\\" One can at the present time project this statement out into the near future with confidence, due to the accelerating advances in A.I. that have taken place since this volume was written. Indeed, there is a collection of A.I. researchers that believe that intelligent machines will surpass human capabilities by many orders of magnitude by the end of the next thirty years. This is an extremely optimistic prediction but it looks hopeful. The prospect that intelligent, autonomous machines will be living among us very soon is indeed an exciting one.<br /> Chapter six discusses the programming languages used in A.I. research. The language LISP was the predominant one used at the time of publication, but now PROLOG has made significant inroads, but is only briefly discussed in the book. LISP and a few other programming languages are mentioned in the book, and a comparison of their strengths and abilities to do certain tasks is done. I have only used LISP and Prolog so I cannot speak of the capabilities of the other languages discussed. The power of LISP to do recursion is one of its strongest points, and this chapter emphasizes this, along with its ability to parallel control and data structures, and its ability to think of programs as data. There is also an interesting discussion in this chapter on \\"dependency records\\", which are used to keep track of the steps taken in a reasoning program. An intelligent program or machine must be able to explain their conclusions in terms of the information given.<br /> In chapter seven one finds a fairly extensive discussion of how A.I. has been applied to scientific research. My first project in A.I. thirteen years ago was to build an expert tutor for physics students and this chapter assisted me to a large degree in accomplishing this. The examples given in the chapter are of course at the present time way out of date, since an explosion of A.I. applications to science and medicine have occurred in the last decade. For example, the chapter mentions MACSYMA as being a package to do symbolic integration. There are now a few of these on the market, such as Maple and Mathematica, and interestingly, their ability to do symbolic integration is not considered to be a manifestation of artificial intelligence, as it is in this volume. In many cases, capabilities of computers once considered \\"smart\\" are now considered \\"routine\\". This is an interesting trend, and if it continues, will assist in the public acceptance of artificial intelligence.<br />Chapter eight details a few of the medical applications of A.I. that were being researched at the time of publication. This situation has increased dramatically since then, for now there are commercial companies whose sole product are programs, based on artificial intelligence, for diagnostics and prognostics. One of the systems discussed in this chapter is MYCIN, one of the earliest expert systems, and was used to diagnose and make recommendations for treatments of certain blood infections. The use of certainty factors by MYCIN is outlined, which are values  between -1 and +1 that reflect the degree of belief in a hypothesis. The MYCIN project has generated a lot of refinements and improvements since its inception in the 1970's. Current applications of A.I. in medicine emphasize neural networks for nonlinear prediction, genetic algorithms and evolutionary programming, disease modeling, and real-time clinical problem-solving. One of the primary successes of these approaches has been in the intelligent modeling or patients with multiple disorders.<br />Chapter nine was the most useful chapter for me of the three volumes, for it discusses, among other things, how to create intelligent tutoring systems. My first foray into A.I. thirteen years ago involved creating, using LISP,  a physics tutor for freshman physics students. The reading of this chapter was of great assistance in that it outlined the approaches taken at the time for using A.I. in education, which was labeled at the time as ICAI (intelligent computer-assisted instruction). The most difficult problem in designing an intelligent tutoring system is in dealing with the many (sometimes very creative) answers given by students. It is best to first deal with simple multiple-choice answers, which the program can then analyze relative to an extensive database. More powerful techniques are now available, coming from  knowledge or \\"ontological\\" engineering, as it is sometimes called, and from natural language processing. Also, the advent of symbolic programming languages, such as Maple and Mathematica, make it easier to deal with the computational part of student answers, and these languages can even serve as a language in which to write the tutor. The ideal tutor must be able to assist the student in conceptual mistakes, as well as deal with blatantly wrong answers and arithmetic mistakes. The trend seems to be now in sophisticated digital assistants that employ all of these techniques and gigantic databases in order to reach this goal. These developments are very exciting, and will mesh well with the research and development  in automatic scientific discovery.tlined, which are values  between -1 and +1 that reflect the degree of belief in a hypothesis. The MYCIN project has generated a lot of refinements and improvements since its inception in the 1970's. Current applications of A.I. in medicine emphasize neural networks for nonlinear prediction, genetic algorithms and evolutionary programming, disease modeling, and real-time clinical problem-solving. One of the primary successes of these approaches has been in the intelligent modeling or patients with multiple disorders. <br />Chapter nine was the most useful chapter for me of the three volumes, for it discusses, among other things, how to create intelligent tutoring systems. My first foray into A.I. thirteen years ago involved creating, using LISP,  a physics tutor for freshman physics students. The reading of this chapter was of great assistance in that it outlined the approaches taken at the time for using A.I. in education, which was labeled at the time as ICAI (intelligent computer-assisted instruction). The most difficult problem in designing an intelligent tutoring system is in dealing with the many (sometimes very creative) answers given by students. It is best to first deal with simple multiple-choice answers, which the program can then analyze relative to an extensive database. More powerful techniques are now available, coming from  knowledge or \\"ontological\\" engineering, as it is sometimes called, and from natural language processing. Also, the advent of symbolic programming languages, such as Maple and Mathematica, make it easier to deal with the computational part of student answers, and these languages can even serve as a language in which to write the tutor. The ideal tutor must be able to assist the student in conceptual mistakes, as well as deal with blatantly wrong answers and arithmetic mistakes. The trend seems to be now in sophisticated digital assistants that employ all of these techniques and gigantic databases in order to reach this goal. Thesedevelopments are very exciting, and will mesh well with the research and development  in automatic scientific discovery.	2002-12-06
1318145:US	50702879	RA5JW5Q3DW5W	0674664795	790214934	Philosophical Explanations	Books	5	23	27	N	N	An incredible book	Ideas can provoke, and even individuals who are absolutely determined to be objective and weigh each idea or opinion without getting emotionally involved usually at one time or another find themselves in heated debate. One can only speculate on the reasons why anger typically accompanies the exchange of ideas. One would think maybe that individuals intelligent enough to discuss sometimes very complex ideas would not permit themselves to get agitated. Another possibility, from a biological/evolutionary standpoint, is that anger is a kind of defense mechanism: that it reacts against new ideas as these disturb the cognitive equilibrium of the individual. Since ideas determine an individual's outlook and how he/she deals with reality, too rapid a change in the individual's conceptual structure might threaten the individual's survival.<br /> Early in the introduction to this book, the author makes a strong and uncommon case against what he has termed 'coercive philosophy'. This, he says, is characterized by its terminology: arguments are \\"powerful\\", and best when they are \\"knockdown\\". Such arguments, if the premises are believed by your \\"opponent\\", force your opponent to the conclusion, which he/she must believe, lest they be labeled as \\"irrational\\", the latter they are told, and some of them believe, is the ultimate anathema. But if they do not, the \\"owner\\" of the argument is in trouble: he/she is faced with someone who is perfectly comfortable with the \\"irrational\\" label. What does the arguer do then?<br /> Therefore, the author asks the reader to consider another approach to philosophy, and that approach is reflected in the title of the book. The role of philosophy is to explain, not to argue. Good philosophy will explain the fundamental problems and curiosities of life, such as ethics, the mind-body problem, the nature of knowledge, and so on. As the author puts it: \\"There is a second mode of philosophy, not directed to arguments and proofs: it seeks explanations. Various philosophical things need to be explained; a philosophical theory is introduced to explain them, to render then coherent and better understood.\\"<br /> This is a delightfully optimistic approach to philosophical inquiry, for it assumes from the beginning that the individuals who are engaging in the philosophical conversation are willing to sit down and discuss calmly, rationally, and openly, the issues at hand. The author assumes the reader is such a person, and the book is full of thought-provoking ideas presented in a way that respects the dignity and intelligence of the reader. His discussion of \\"explanation versus proof\\" is fascinating and in fact has applications in artificial intelligence.<br /> I found chapter five on \\"The Foundations of Ethics\\" the most lucid of all in the book, and I thoroughly enjoyed its reading. That does not mean that I agree with all that he asserts. In fact that opening sentence of the chapter, that states that \\"ethical truths find no place within the contemporary scientific picture of the world\\", I profoundly disagree with. But no problem, as the author encourages disagreement, and speaks to the reader over and over again, imploring him/her to reconsider their positions, think through the issues, ask themselves questions, and find answers never before thought of.<br /> Indeed, everything about this book is good, and the practice of \\"philosophical explanation\\" results in a more productive and interesting methodology. There is no place for anger, ridicule, or other forms of negativity in philosophical, or any other forms of inquiry. Genuine respect for all ideas expressed by all individuals, no matter how radical, no matter how \\"offensive\\" is the optimum path to truth. Such a path may not be the shortest one, but it is certainly the best one.Various philosophical things need to be explained; a philosophical theory is introduced to explain them, to render then coherent and better understood.\\"<br /> This is a delightfully optimistic approach to philosophical inquiry, for it assumes from the beginning that the individuals who are engaging in the philosophical conversation are willing to sit down and discuss calmly, rationally, and openly, the issues at hand. The author assumes the reader is such a person, and the book is full of thought-provoking ideas presented in a way that respects the dignity and intelligence of the reader. His discussion of \\"explanation versus proof\\" is fascinating and in fact has applications in artificial intelligence. <br /> I found chapter five on \\"The Foundations of Ethics\\" the most lucid of all in the book, and I thoroughly enjoyed its reading. That does not mean that I agree with all that he asserts. In fact that opening sentence of the chapter, that states that \\"ethical truths find no place within the contemporary scientific picture of the world\\", I profoundly disagree with. But no problem, as the author encourages disagreement, and speaks to the reader over and over again, imploring him/her to reconsider their positions, think through the issues, ask themselves questions, and find answers never before thought of. <br /> Indeed, everything about this book is good, and the practice of \\"philosophical explanation\\" results in a more productive and interesting methodology. There is no place for anger, ridicule, or other forms of negativity in philosophical, or any other forms of inquiry. Genuine respect for all ideas expressed by all individuals, no matter how radical, no matter how \\"offensive\\" is the optimum path to truth. Such a path may not be the shortest one, but it is certainly the best one.	2002-12-04
1318161:US	50702879	R2KBVLYMOW67BQ	0865760055	46642313	Handbook of Artificial Intelligence Volume 1	Books	4	9	9	N	N	Good overview of GOFAI	This is the first volume of a 3-volume set published in the early 1980's and thus could be thought of as a summary of what was known at the time in the field of artificial intelligence (A.I.). Now sometimes referred to as \\"GOFAI\\" for \\"good ole-fashioned artificial intelligence\\", this set of books can still be referred to profitably by anyone curious about the applications of artificial intelligence. Indeed, many of the algorithms discussed in this volume are still being used, and very robustly, in current implementations of artificial intelligence. A lot has happened since this volume was published, especially in the area of chess playing and logic programming, but there are many sections of the book that are still up-to-date.<br /> After a brief introduction to A.I. in chapter one, chapter two overviews the use of search algorithms for intelligent problem solving. The emphasis initially is on the problem representations that form the basis of search techniques, such as state-space and problem-reduction representations. Game tree representations are also discussed. The algorithms that implement the problem representations are then treated. If the search space is viewed merely syntactically, these are called \\"blind search\\" algorithms, which are distinguished from \\"heuristic\\" methods, which exploit various structural information about the problem in order to limit the search. Examples of blind search methods that are discussed include breadth-first, uniform-cost, depth-first, and bidirectional search. Examples of heuristic methods discussed are ordered state-space, bidirectional, and the famous A*-algorithm, the latter of which is still finding considerable use in new applications of A.I. Examples of game tree search that are covered include the minimax procedure, the negmax formalism, and alpha-beta pruning. There is discussion on the use of heuristics in game tree search, but this part is out-of-date due to the advances made in chess playing, checkers, etc, since this volume was published.<br /> Chapter three is an overview of knowledge representation in A.I. The author takes a pragmatic approach to the nature of knowledge and intelligence, and defines the \\"representation of knowledge\\" as a combination of data structures and interpretive procedures that will lead to what he calls \\"knowledgeable\\" behavior. A book needs a reader before it could be considered knowledge, argues the author. He calls this whole enterprise \\"experimental epistemology\\" , which endeavors to create programs that exhibit intelligent behavior. The chapter gives an overview of the knowledge representation schemes used in A.I. and discusses their uses and shortcomings. Also, the tension between the advocates of declarative versus procedural knowledge representations is discussed. Declarative systems are more logical/mathematically based, and were exemplified by theorem-provers based on logical resolution. The procedural approach emphasized a more directed approach to the problem of inference and one that makes the reasoning process more understandable.  There is a brief discussion on semantic nets, which were invented as a model of human associative memory. The net consists of nodes, which represent concepts, objects, or events, and links between the nodes. The relevant facts about a concept can be inferred from the nodes to which they are linked directly, and so an extensive database search is not necessary. The semantics of net structures depends only on the program that uses them, and so any notion of \\"logical validity\\" of inferences from using the net is absent. Production systems are also discussed in this chapter, these being developed as models of human cognition. These systems are called \\"modular\\" knowledge representation schemes in that the database consists of rules, or \\"productions\\", that take the form of condition-action pairs. The conditions in which each rule is applicable are made explicit and thus the interactions between the rules are minimized. These systems have been used to control the interaction between declarative and procedural statements and to develop autonomous learning systems. In addition, the chapter includes a discussion of the \\"frame\\" knowledge representation system, which at the time of publication, was just getting started in A.I. research. It has been widely discussed since then, mostly in the context of studying how to implement reasoning about actions, and became to be known as the \\"frame problem\\". The proliferation of the frame axioms needed made reasoning about actions difficult or cumbersome, but was later solved using what are now called \\"successor-state axioms\\". The chapter also includes a discussion of the standard logical representational schemes: propositional and first-order predicate logic. Since the time of publication, and due to the interest in developing \\"common-sense\\" reasoning machines, second-order predicate logic has made its appearance in A.I. research, sometimes being called \\"ontological engineering\\" in the literature. Also, due to the time of publication, there is no discussion of inductive logic programming, which has recently gained importance in A.I. research and its applications.<br /> Chapter four covers the very important topic of natural language understanding. This is one of the areas in A.I. that has been the target of an enormous amount of research, for the ability of a computer to converse with a human fluently and with understanding would be a major advance for A.I., perhaps even an \\"acid test\\" that true intelligence has finally been achieved in a machine. The chapter gives a brief history of research in natural language processing and discusses the early attempts at machine translation from one language to another. There is also extensive discussion on grammars, parsing techniques, and text generation. Several examples of programs used for natural language processing that were popular at the time of publication are discussed.mized. These systems have been used to control the interaction between declarative and procedural statements and to develop autonomous learning systems. In addition, the chapter includes a discussion of the \\"frame\\" knowledge representation system, which at the time of publication, was just getting started in A.I. research. It has been widely discussed since then, mostly in the context of studying how to implement reasoning about actions, and became to be known as the \\"frame problem\\". The proliferation of the frame axioms needed made reasoning about actions difficult or cumbersome, but was later solved using what are now called \\"successor-state axioms\\". The chapter also includes a discussion of the standard logical representational schemes: propositional and first-order predicate logic. Since the time of publication, and due to the interest in developing \\"common-sense\\" reasoning machines, second-order predicate logic has made its appearance in A.I. research, sometimes being called \\"ontological engineering\\" in the literature. Also, due to the time of publication, there is no discussion of inductive logic programming, which has recently gained importance in A.I. research and its applications. <br /> Chapter four covers the very important topic of natural language understanding. This is one of the areas in A.I. that has been the target of an enormous amount of research, for the ability of a computer to converse with a human fluently and with understanding would be a major advance for A.I., perhaps even an \\"acid test\\" that true intelligence has finally been achieved in a machine. The chapter gives a brief history of research in natural language processing and discusses the early attempts at machine translation from one language to another. There is also extensive discussion on grammars, parsing techniques, and text generation. Several examples of programs used for natural language processing that were popular at the time of publication are discussed.	2002-12-04
1318582:US	50702879	R1KBISAATIOOLR	0486682307	434183974	Helicopter Theory (Dover Books on Aeronautical Engineering)	Books	5	24	27	N	N	Excellent job	I picked up this book with the intent of getting some ideas for physics demonstrations that illustrate the physics of helicopter flight. Also, I was curious as to why helicopters are not made that are three, four, or perhaps ten times the size that they are now, and if chaotic dynamics could be present in helicopters. Over a thousand pages long, this book gave me what I needed and much more. Written for design and mechanical engineers who are involved in helicopter manufacturing, the book could be read profitably by anyone who is curious about the physical principles behind helicopters.<br /> In the introduction to the book, the author defines a helicopter as an aircraft that uses rotating wings to provide lift, propulsion, and control. He then discusses briefly the basic physical principles that a helicopter needs in order to sustain vertical lift, as well as to move translationally. The design engineer must then weigh the factors that enable the helicopter to move against the maintenance and human factors involved in the use of the helicopter for transportation. The rest of the book is then an extremely detailed and fascinating account of the engineering analysis that goes into the design of a succesful helicopter. The author also overviews the history behind the helicopter, beginning with the Chinese rotor, circa 400 B.C. and with the first succesful flight with one passenger, and one meter above the ground, for about one minute, by Breguet-Richet of France in 1907. The author remarks that helicopter engineering currently emphasizes research and development than with invention. This is especially true in the military environment, with the Apache helicopter being a superb example of just how sophisticated a helicopter can be. It will be interesting to see how the technology and design of helicopters will change in the decades ahead. The trend might be towards pilotless flight for delivering military supplies or manufactured goods from one point to another, or perhaps helicopters that can morph into completely vertical or horizontal aircraft as the need arises.<br /> The physics behind vertical flight is described by the author as 'momentum theory', which was developed for marine propellors in the late nineteenth century. As the name implies, this is just an application of the principle of conservation of momentum. The rotor disk of the helicopter feels a thrust created by the action of the air on the helicopter blades. It must therefore exert an equal and opposite force on the air. This forces the velocity of the air in the rotor wake to be opposite in direction to the direction of the thrust. Momentum conservation, energy conservation, and mass conservation then give a relation between the induced power loss and the rotor thrust. The author also gives details on the 'vortex theory', which is based more on fluid dynamical laws of the flow field of the rotor wake. Emphasizing the local aspects, it reduces to momentum theory in appropriate limits. The author also shows how momentum theory applies to the forward flight of the helicopter.<br /> The author also treats helicopter performance analysis, which boils down to determining the power required and available for a range of flight conditions. The rotor forces and power must be calculated, and the author details two methods to do this: the 'force balance method' and the 'energy balance method'. The use of the computer has made this analysis considerably easier for the design engineer of course. The author gives a very interesting overview of helicopter speed limitations and how the helicopter could be landed safely after an engine failure, all of this being analyzed from a physics perspective.<br /> The mathematics of rotating systems is included in the book, along with the differential equations of motion for the rotor blade. The motion of the blade is expanded into a normal mode representation and analyzed using Sturm-Liouville theory. The author though outlines other approaches to the blade dynamics, such as the Lagrangian formulation and the Galerkin method. And also, in spite of the ability of computers to solve for the aeroelastic equations of motion, the author considers their analytical solution for the cases where such solutions can be obtained. One very interesting part of this discussion was that of 'ground resonance', which is a dynamic instability involving the the coupling of the blade lag motion with the in-plane motion of the rotor hub. There is then a resonance between the frequency of the rotor lag motion and the natural frequency of the structure supporting the rotor.pproaches to the blade dynamics, such as the Lagrangian formulation and the Galerkin method. And also, in spite of the ability of computers to solve for the aeroelastic equations of motion, the author considers their analytical solution for the cases where such solutions can be obtained. One very interesting part of this discussion was that of 'ground resonance', which is a dynamic instability involving the the coupling of the blade lag motion with the in-plane motion of the rotor hub. There is then a resonance between the frequency of the rotor lag motion and the natural frequency of the structure supporting the rotor.	2002-12-03
1322068:US	50702879	RSNEKN7JUKVP2	0521420245	592822131	Algebraic L-theory and Topological Manifolds (Cambridge Tracts in Mathematics)	Books	5	2	2	N	N	An excellent overview of generalized surgery theory	For those readers who have completed advanced studies in algebraic topology and K-theory, and are ready to move on to a few of the even more esoteric topics in algebra and topology, this book would be an excellent choice. It is of course written for those who intend to specialize in the the areas included, but the book has value for those who are merely curious about the subject matter.<br /> The author introduces his book by describing it as a self-contained overview of the algebraic L-theory of quadratic forms in dimensions greater than or equal to 5. This theory was initiated over two decades ago by the mathematicians Browder, Novikov, Sullivan, and Wall for the case of compact, differentiable, and piecewise-linear manifolds, and was constructed to study the relationship between their topology and their homotopy type. This theory was then extended to the case of topological manifolds by the mathematicians Kirby and Siebenmann. The author does not assume the reader has any prior exposure to surgery theory. Readers though who have knowledge of the extreme difference in level of difficulty between doing topology in dimensions 3 and 4 versus in dimension 5 should find this book easier going, i.e. the &quot;Whitney trick&quot; holds in 5 dimensions (or above).<br /> The main core of the results in this book has its origins in the concept of Poincare duality, which is the equality between a spaces' n-dimensional homology  and its (n-k)-cohomology. An n-dimensional Poincare space is a topological space where this equality holds for any coefficient group. Finite Poincare spaces, i.e. those which have the homotopy type of a finite CW complex,  are not necessarily equivalent to a compact manifold. This motivates the &quot;manifold structure existence&quot; problem, which attempts to find out if a finite Poincare space (a space having the same homotopy type of a finite CW-complex) is homotopy equivalent to a compact manifold. But this homotopy equivalence may not be homotopic to a homeomorphism, and this fact motivates the &quot;manifold structure uniqueness&quot; problem, which is an attempt to find out if such a homotopy exists. A compact n-dimensional manifold is a finite n-dimensional Poincare space but a finite Poincare space is not necessarily homotopy equivalent to a compact manifold. The surgery theory of Browder, Novikov, Sullivan, Wall formulated obstructions for deciding the manifold structure existence and uniqueness theorems for dimensions greater than or equal to 5. These obstructions involve the topological K-theory of vector bundles, along with the algebraic L-theory of quadratic forms.<br /> In the book the author extends his earlier work on algebraic surgery and develops an intrinsic characterization of the manifold structures. Thus the structure groups are defined using algebraic Poincare complexes, these being obstructions to the existence and uniqueness problems. The total surgery obstruction is a homotopy invariant that vanishes if and only if the space is homotopy equivalent to a compact manifold (of dimension greater than or equal to 5). These kinds of ideas are then abstracted to yield the concept of an assembly map, which is a map that acts on a topological invariant and gives a homotopy invariant. The algebraic L-theory assembly map essentially measures how far a homotopy equivalence is from being homotopic to a homeomorphism, or, put another way, how far from being rigid a space is (a rigid manifold is one in which every homotopy equivalence is homotopic to a homeomorphism). The author discusses his notion of an assembly map as a generalization of other assembly maps in algebraic topology, and he gives examples: the Leray homology spectral sequence, and the Zeeman dihomology spectral sequences. The idea of assembly in these contexts is to piece together the homology of a space from its cohomology with coefficients in the local homology. For example, for the case of homology manifolds, where the local homology groups at a point are the local homology groups of Euclidean space, the local Poincare duality isomorphisms are &quot;assembled&quot; to the global duality isomorphisms. Another way of saying this is that the local homology at each point, which is a topologically invariant property is &quot;assembled&quot; into the homotopy invariant property of Poincare duality. The author calls the relationship between topological manifolds, Poincare spaces, local algebraic Poincare complexes, and global algebraic Poincare complexes a &quot;fiber square&quot; in the book.<br /> In analogy with hermitian K-theory, the quadratic L-groups were defined by the author in a previous work as cobordism of quadratic Poincare complexes over a ring with involution R. One then constructs an algebraic L-theory assembly map involving the generalized homology groups whose coefficients are taken from the quadratic L-theory spectrum of the integers. The structure groups are then taken to be the relative homotopy groups of the assembly map and they measure the extent to which the assembly maps fail to be an isomorphism.<br /> Thinking topologically, the computation of the structure set involves the use of the Spivak normal fibration. The structure set is nonempty only if there exists a stable vector bundle whose associated sphere bundle is isomorphic to the Spivak normal fibration. A finite Poincare space is homotopy equivalent to a compact iff the Spivak normal fibration admits a topological bundle reduction such that a normal map from a manifold to the Poincare space has zero surgery obstruction. Since the author's goal is both an algebraic and a topological setting, he defines an algebraic analog to the Spivak normal fibration. This analog involves first what the author calls an &quot;algebraic bordism category&quot;, which is an additive category with chain duality A, and a pair of subcategories of the chain homotopy category of A. The author spends the first part of the book giving the details of how to construct the quadratic L-groups of this category, and then how to get the assembly functor. This algebraic theory is then related to the geometric/topological context in the second half of the book.logy groups at a point are the local homology groups of Euclidean space, the local Poincare duality isomorphisms are &quot;assembled&quot; to the global duality isomorphisms. Another way of saying this is that the local homology at each point, which is a topologically invariant property is &quot;assembled&quot; into the homotopy invariant property of Poincare duality. The author calls the relationship between topological manifolds, Poincare spaces, local algebraic Poincare complexes, and global algebraic Poincare complexes a &quot;fiber square&quot; in the book. <br /> In analogy with hermitian K-theory, the quadratic L-groups were defined by the author in a previous work as cobordism of quadratic Poincare complexes over a ring with involution R. One then constructs an algebraic L-theory assembly map involving the generalized homology groups whose coefficients are taken from the quadratic L-theory spectrum of the integers. The structure groups are then taken to be the relative homotopy groups of the assembly map and they measure the extent to which the assembly maps fail to be an isomorphism.  <br /> Thinking topologically, the computation of the structure set involves the use of the Spivak normal fibration. The structure set is nonempty only if there exists a stable vector bundle whose associated sphere bundle is isomorphic to the Spivak normal fibration. A finite Poincare space is homotopy equivalent to a compact iff the Spivak normal fibration admits a topological bundle reduction such that a normal map from a manifold to the Poincare space has zero surgery obstruction. Since the author's goal is both an algebraic and a topological setting, he defines an algebraic analog to the Spivak normal fibration. This analog involves first what the author calls an &quot;algebraic bordism category&quot;, which is an additive category with chain duality A, and a pair of subcategories of the chain homotopy category of A. The author spends the first part of the book giving thedetails of how to construct the quadratic L-groups of this category, and then how to get the assembly functor. This algebraic theory is then related to the geometric/topological context in the second half of the book.	2002-12-01
1322649:US	50702879	R1P5KO08AZGB5Y	0963865439	925817343	Are We Spiritual Machines?: Ray Kurzweil vs. the Critics of Strong A.I.	Books	5	68	75	N	Y	Excellent introduction to an ongoing debate	The work, inventions, and opinions of Ray Kurzweil in the field of artificial intelligence have captured media attention and the attention of philosophers and researchers in artificial intelligence. But not only is Kurzweil one of the most brilliant and controversial of all the individuals working in artificial intelligence, he is also the most optimistic. This optimism holds not only for the future technology of artificial intelligence, predicted by Kurzweil to give independent thinking machines in the next three decades, but also for its social impact. Kurzweil believes that artificial intelligence will work for the benefit of humankind, but that this benefit will depend to a great degree on his belief that humans will take on technology that will effectively make them cybernetic.<br /> The controversy behind Kurzweil stems from his recent book &quot;The Age of Spirtual Machines&quot;, which is a detailed accounting of his predictions and beliefs regarding artificial intelligence. Many individuals objected to his visions and predictions, and he answers a few of them in this book. In particular, he attempts to counter the arguments against him by the philosopher John Searle, the molecular biologist Michael Denton, the philosopher William A. Dembski, and zoologist Thomas Ray. With only a few minor exceptions, Kurzweil is successful in his refutation of their assertions.<br /> But even if Kurzweil completely refutes the arguments of these individuals, and possibly many more against him, the countering of arguments will not by itself solve the problems in artificial intelligence research. The fact remains that much work still needs to be done before we are priveleged to see the rise of intelligent machines. Kurzweil is well-aware of this, for he acknowledges this many times in this book. He points to reverse engineering of the human brain as one of the most promising strategies to bring in the robotic presence. The success or failure of this strategy will take the mind-body problem out of purely academic circles and bring it to the forefront of practical research in artificial intelligence. The 21st century will thus see the rise of the &quot;industrial philosopher&quot;, who works in the laboratory beside the programmers, cognitive scientists, robot engineers, and neurologists.<br /> Each reader of this book will of course have their own opinions on Kurzweil's degree of success in countering the arguments of Searle, Denton, Dembski, and Ray. But one thing is very clear: Kurzweil is no arm-chair philosopher engaging in purely academic debates on the mind-body problem. He is right in the thick of the research and development of artificial intelligence, and if the future turns out as he predicts, he will certainly be one of the individuals contributing to it. He and many others currently working in artificial intelligence are responsible for major advances in this field in just the last few years. Their ingenuity and discipline is admirable in a field that has experienced a roller coaster ride of confidence and disappointment in the preceding decades. All of these individuals have proved themselves to be superb thinking machines.mind-body problem out of purely academic circles and bring it to the forefront of practical research in artificial intelligence. The 21st century will thus see the rise of the &quot;industrial philosopher&quot;, who works in the laboratory beside the programmers, cognitive scientists, robot engineers, and neurologists.     <br /> Each reader of this book will of course have their own opinions on Kurzweil's degree of success in countering the arguments of Searle, Denton, Dembski, and Ray. But one thing is very clear: Kurzweil is no arm-chair philosopher engaging in purely academic debates on the mind-body problem. He is right in the thick of the research and development of artificial intelligence, and if the future turns out as he predicts, he will certainly be one of the individuals contributing to it. He and many others currently working in artificial intelligence are responsible for major advances in this field in just the last few years. Their ingenuity and discipline is admirable in a field that has experienced a roller coaster ride of confidence and disappointment in the preceding decades. All of these individuals have proved themselves to be superb thinking machines.	2002-11-30
1324007:US	50702879	R22PR2N2PVRIDB	069108226X	290801694	Classifying Spaces for Surgery and Corbordism of Manifolds. (AM-92), Volume 92 (Annals of Mathematics Studies)	Books	4	2	2	N	N	Good presentation....but dense	One of the most interesting of all results in the theory of vector bundles is the famous classification theorem, which says that the set of isomorphism classes of k-dimensional vector bundles over a paracompact space is in a natural bijective correspondence with the set of homotopy classes of mappings of this space into the Grassman manifold of k-dimensional subspaces in infinite-dimensional space. This book is a summary of what was known at the time of publication for classifying spaces in a more general context, namely in the piecewise-linear and topological categories. The basic theme underlying the use of classifying spaces in all of these categories is that the classifying of geometric objects is viewed as a homotopy classification of maps into a classifying space. I only read the first seven chapters of this book, so my review will be confined to these.<br /> The authors review the role of classifying spaces for (principal) bundles in Chapter 1, and this is one of the few books that actually gives an explicit construction of the classifying space for the case of finite dimensional CW complexes. The classifying spaces for the classical Lie groups are then reviewed very quickly. In addition, the authors review what the reader will need to know about the cobordism ring for differentiable, topological, and piecewise-linear manifolds. For brevity, the authors refer to all of these manifolds as &quot;(H)-manifolds.&quot; For (H)-manifolds satisfying the property of &quot;transversality&quot;, such as differentiable, piecewise-linear, and topological (for n not equal to 4) manifolds, the authors show that the cobordism ring gives rise to a generalized homology theory, and that such a theory can be represented by a spectrum, the famous &quot;Thom spectrum&quot;.<br />Chapter 2 reviews the Browder-Novikov-Sullivan theory of surgery classification of (simply-connected) manifolds. The strategy here, as the authors explain, is to find an obstruction to a homotopy type actually being the homotopy type of a manifold. The notion of a Poincare-duality space is an elementary example of this, since a simply connected closed manifold is one and hence a manifold determines a unique homotopy type of a Poincare-duality space. The authors give an explicit example of a 5-dimensional simply connected Poincare-duality space that does not have the homotopy type of a smooth, piecewise-linear, or topological manifold. The obstruction to a Poincare-duality space containing a differentiable or piecewise-linear manifold in its homotopy type is the existence of a reduction of its Spivak normal bundle.<br />In chapter 3, the authors concentrate their attention on the homotopy type and cohomology modulo 2 of the space of homotopy equivalences G and oriented homotopy equivalences of the n-sphere SG. This involves the consideration of the infinite loop space of the 0-sphere and the classifying space of the symmetric group on n letters. The cohomology of the latter is shown to lead to a calculation of the cohomology of the classifying space of SG.<br />The Sullivan theory of the homotopy types of G/PL and G/TOP is considered in chapter 4. This involves the interpretation of the Kervaire invariant  in terms of characteristic classes in cohomology or K-theory. For G/PL, one then obtains maps from G/PL into Eilenberg-Maclane spaces or the classifying space BO. The authors then discuss how Sullivan obtained homotopy equivalences by using localization. The situation for G/TOP is similar as the authors show briefly.<br />The authors continue with the Sullivan theory of the classifying spaces of TOP and PL localized away from 2, along with their associated Thom spectra.  To do this this, use is made of the J-homomorphism in the stable homotopy groups of spheres. This leads to a consideration of the classifying space of the cokernel of J, and they discuss the work of Sullivan who has shown the existence of a splitting at each odd prime for BSPL in terms of BSO and cokerJ. The validity of the Adams' conjecture allows a similar analysis for the Thom spectra of the classifying spaces of TOP and PL localized away from 2.<br />Chapter 6 considers the structure of infinite loop spaces and the &quot;Q-operations&quot; between the i-th and (i+a)-th homology groups (modulo 2) of these spaces. These operations measure the how far the H-space multiplication is from being commutative. Since the H-space multiplications are homotopy operations, these homology operations are a measure of the non-triviality of the infinite sequence of higher homotopies associated with the infinite loop space.<br />In chapter 7, the authors consider the infinite loop space structure of G/TOP localized at 2, and show that &quot;first delooping&quot; B(G/TOP), and the &quot;second delooping&quot; B^2(G/TOP) localized at 2 can be written as a product of Eilenberg-Maclane spaces, in analogy with the case of G/TOP localized at 2. They mention but do not show in detail that the &quot;third delooping&quot; B^3(G/TOP) cannot be written as the product of Eilenberg-Maclane spaces.and cokerJ. The validity of the Adams' conjecture allows a similar analysis for the Thom spectra of the classifying spaces of TOP and PL localized away from 2. <br />Chapter 6 considers the structure of infinite loop spaces and the &quot;Q-operations&quot; between the i-th and (i+a)-th homology groups (modulo 2) of these spaces. These operations measure the how far the H-space multiplication is from being commutative. Since the H-space multiplications are homotopy operations, these homology operations are a measure of the non-triviality of the infinite sequence of higher homotopies associated with the infinite loop space. <br />In chapter 7, the authors consider the infinite loop space structure of G/TOP localized at 2, and show that &quot;first delooping&quot; B(G/TOP), and the &quot;second delooping&quot; B^2(G/TOP) localized at 2 can be written as a product of Eilenberg-Maclane spaces, in analogy with the case of G/TOP localized at 2. They mention but do not show in detail that the &quot;third delooping&quot; B^3(G/TOP) cannot be written as the product of Eilenberg-Maclane spaces.	2002-11-29
1324095:US	50702879	R2SK4H2WPHKXPQ	0300000898	695437314	Psychoanalysis and Religion (The Terry Lectures Series)	Books	2	16	41	N	N	Where is the author's evidence?	In a time of psychopharmacological drugs, cognitive science, and behavioral psychology, Freudian psychoanalysis is not at center stage anymore, as it was in the early to mid twentieth century. Written over a half a century ago, it is readily apparent in this book that the author has been considerably influenced by Freud's ideas, no doubt because of the time and context in which the author lived. It is also clear that the author is one who is not ready to remove himself totally from the influence of religion when formulating criteria for human psychological and emotional health. And interestingly, he describes Freud as being one who also takes this view, in spite of Freud's militant atheism. After expressing disappointment that \\"academic\\" psychology has been attempting to imitate the natural sciences emphasis on quantitative and empirical methods, he asserts that psychology must be concerned with matters of the \\"soul\\", the latter being the \\"higher\\" human powers of love, reason, conscience, and values. Freud he says, via his method of psychoanalysis which uses dreams, fantasies, and free associations, concentrates on the soul. Therefore the author makes it clear that a scientific approach to psychology, where case studies and data and statistical analysis are essential, is to be rejected.<br /> This attitude is consistently applied throughout this book, as the author does not attempt to justify his beliefs with any historical evidence  or patient case histories. Instead, readers are asked to believe that their life is not based on a \\"solid foundation\\", and that anxiety, uneasiness, and confusion are currently (at least at that time) permanent facets of their existence. But the author does not advise the reader to return to religion, but to \\"live love and think truth\\". If a person cannot do this on their own, they should seek the assistance of a psychoanalyst. Psychoanalysis and religion thus have an intersection, in that they both seek to cleanse and restore the individual's soul.<br /> The author devotes and entire chapter to correcting the view that Freud is \\"against\\" religion and his contemporary, Carl Jung is \\"for\\" religion. This discussion serves also to set up the groundwork for his own thinking developed later in the book. Both Freud and Jung were deeply religious, he argued, for they were concerned with the true requirements of the soul, that they were indeed \\"physicians of the soul\\" as the author calls it. But the author clearly distinguishes between \\"humanistic\\" religion and \\"authoritarian\\" religion. Jung and Freud are in the former category, and assist in giving the individual genuine psychological health. The latter however, the author argues, results, and is a symptom of, severe emotional and psychological maladjustment, and its consequence is a lack of love and respect for the individual. His thinking on these issues is interesting, but it lacks support from an empirical point of view. The author never quotes case studies as to how certain individuals were helped by the psychoanalytic theories that he expouses. Such studies would help to decide whether in fact the approach advocated by the author does in fact result in a more adjusted and fully functional individual, and such an individual would be better off than what traditional, authoritarian religion would be able to contribute. Such studies though would require scientific analysis, and the author will have no part of this.<br /> The most disconcerting part of the book is that the author continually takes the position that he speaks for everyone in the society he is analyzing. \\"We cling to the belief that we are happy\\" he says in one paragraph, and in another, where he discusses the situation of children, he proclaims that \\"we are as helpless as they are\\", and that \\"we do not know the answer because we even have forgotten to ask the question. We pretend that our life is based upon a solid foundation and ignore the shadows of uneasiness, anxiety, and confusion which never leave us.\\" Does the author himself feel this way? Does every reader feel this way? The author seems very confident that he speaks for everyone, but he eschews statistical sampling, so why are readers supposed to believe his sweeping generalizations? Did it ever occur to the author that the technological society in which we find ourselves is itself the product of happy, productive individuals? Innovation at the current grand scale is not done by dysfunctional, maladjusted \\"freaks of the universe\\". Such a society is a product of the ingenuity of many individuals, confident in themselves and the future.which never leave us.\\" Does the author himself feel this way? Does every reader feel this way? The author seems very confident that he speaks for everyone, but he eschews statistical sampling, so why are readers supposed to believe his sweeping generalizations? Did it ever occur to the author that the technological society in which we find ourselves is itself the product of happy, productive individuals? Innovation at the current grand scale is not done by dysfunctional, maladjusted \\"freaks of the universe\\". Such a society is a product of the ingenuity of many individuals, confident in themselves and the future.	2002-11-28
1324587:US	50702879	R24Z26XG1SXZL7	0062511491	602239636	Plaisirs d'Amour: Erotic Guide to the Senses, An	Books	5	3	5	N	N	Optimisim at its very best	It is a tautology that the predominant theme in literature, art, and film is sex. The insatiable appetite for sex has driven this proliferation of sexual undercurrents in all phases of human activity and creativeness. Sex and erotica is presented in many different forms of course, depending on the media used, and these forms satisfy the needs and also serve to offend the tastes, depending on the individual at hand. This book approaches the subject of erotica from the standpoint of the essential requirements for its indulgence: the five senses of sight, taste, smell, hearing, and touch. Human being with one or more of these missing can still experience the pleasures of sex, as the author shows, with subtle proof, in this book. She calls the book one of \\"erotic enjoyment, a celebration of the human senses\\", and it achieves its aim unashamedly. The works of art that the author includes in the book are superb, and they serve to convince the reader of the many cultural attitudes towards sex and its enjoyment. Some sexual activities that some might consider to be of recent vintage are shown to exist many centuries ago, and were publicly portrayed via the medium of painting or illustration. Nature is indeed generous, as the author states, and we humans have within our bodies and minds a delightful capacity to feel the pleasures of sex, an activity that should be pursued, when the time is right, with total abandonment and originality. The author has seen fit to include images of Adam and Eve throughout the book, and she does this, as she explains, to remind us of who we are and the differences between the sexes, and also the possibility of love. The paradigm of Adam and Eve is one of losing paradise and immortality, the author says, but also one of the gaining of humanity. The sensual pleasures and enjoyment between a man and a woman are preferable by an overwhelming degree to the infantile pleasures of the Garden of Eden, she argues. The author is modest about her assertion here, but she has spoken something that is very profound. With the prospect of a finite lifetime and the implaccability of death, humanity is still infinitely better off than having an eternal life of no struggle and pure innocence. Adam and Eve put on clothes when they rejected the life of the Garden, but clothes can just as easily be taken off, and humans can then experience one of the most marvelous gifts that nature has given.n here, but she has spoken something that is very profound. With the prospect of a finite lifetime and the implaccability of death, humanity is still infinitely better off than having an eternal life of no struggle and pure innocence. Adam and Eve put on clothes when they rejected the life of the Garden, but clothes can just as easily be taken off, and humans can then experience one of the most marvelous gifts that nature has given.	2002-11-28
1326874:US	50702879	RB6VP7WW6YRPR	048640207X	270162887	Curvature and Homology: Revised Edition	Books	5	29	30	N	N	A superb job...packed full of insights	This book could be loosely characterized as an attempt to generalize the theory of Riemann surfaces to that of Riemannian manifolds. The reader familiar with the theory of Riemann surfaces will perhaps find this book easier to read than one who has not. But the author has not assumed that the reader has had any prior exposure to Riemann surfaces, and so the reader without such background will find the reading straightforward. The paradigm in the book is the connection between the topology of Riemannian manifolds and their metric geometry. It is the metric structure of Riemannian manifolds that is responsible for their fame, due especially to their use in physics. Through the use of de Rham cohomology, Hodge theory, and other techniques from differential geometry, the author shows how to give an overview of the intrinsic (\\"coordinate-free\\") global differential geometry of Riemannian manifolds and how that geometry is connected to its topology.<br />Chapter 1 is a review of elementary differential geometry that is to be used in the rest of the book. Then in chapter 2 the author begins with a review of singular homology and de Rham cohomology. The key point, proved in an appendix, is the de Rham theorem which establishes an isomorphism between de Rham and singular cohomology. The pth Betti number is then the number of linearly independent closed differential forms of  degree p modulo the exact forms of degree p. The rest of the chapter is devoted to showing how this result was extended by the mathematician W.V.D Hodge to a restricted class of forms, the famous \\"harmonic forms\\". Now called Hodge theory, it is a homology theory based on the Laplace-Beltrami operator, which generalizes, as expected, Laplace's equation.<br />Chapter 3 is devoted to finding an explicit expression for the Laplace-Beltrami operator in local coordinates. This expression is dependent on the Riemannian curvature of the Riemannian manifold, and so the homology of a compact and orientable manifold will depend on its curvature. The issue then is finding harmonic forms of a given degree. The obstruction to the existence of these is given by a particular quadratic form involving the curvature tensor. The absence of harmonic forms of degree p gives that the pth Betti number is zero. In particular the author shows that the Betti numbers of a compact, orientable, conformally flat Riemannian manifold of positive definite Ricci curvature are all zero. The author then applies these results to compact Lie groups in chapter 4. The harmonic forms on compact Lie groups are those differential forms that are invariant under both left and right translations of the group. The author shows that the first and second Betti numbers of compact Lie groups are zero and shows the existence of a harmonic 3-form, the latter proving that the third Betti number is greater than or equal to one.<br />The author turns his attention to complex manifolds in chapter 5. He approaches these objects from the standpoint of first defining complex structures on separable Hausdorff spaces. The complex structures then allow a definition of a Riemannian metric on these spaces. If the metric does have any torsion, then one can associate a particular 2-form with the metric and the complex structure that is closed. This 2-form is the famous \\"Kaehler metric\\", and the resulting space is called a \\"Kaehler manifold\\". The local geometry of Kaehler manifolds is referred to as \\"Hermitian geometry\\", and the author studies in detail this geometry in this chapter. Loosely speaking, a Kaehler metric can be viewed as a generalization of \\"flatness\\" in the usual Riemannian case, for the author shows that at each point of a Kaehler manifold there exists a system of local complex coordinates which is geodesic. He also introduces the important concept of a holomorphic p-form, and shows that on a Kaehler manifold these are harmonic.<br />In chapter 6, the author studies in detail how curvature and homology are related forthe case of Kaehler manifolds. The results in this chapter could be viewed as a generalization of the classical results concerning compact Riemann surfaces, namely that the universal covering space of a complex n-dimensional compact Kaehler manifold of constant holomorphic curvature K is a projective space for K &gt; 0, the interior of a unit sphere for k &lt; 0, and the space of complex variables for K = 0. After defining the holomorphic curvature, the author shows that the pth Betti number of a compact Kahler manifold M with positive constant holomorphic curvature is zero if p is odd and 1 if p is even. In addition, he shows that any holomorphic form of degree p, for p &gt; 0 and p less than or equal to n, on a compact Kaehler manifold with positive definite Ricci curvature is zero. The author also gives the reader a taste of sheaf  theory, in which he discusses briefly the Kodaira vanishing theorems.<br />In the last chapter, the author generalizes what was done in chapter 3 regarding conformal transformations on Riemannian manifolds, namely that an infinitesimal holomorphic transformation of a compact Kaehler manifold can be viewed as the solution of a system of differential equations which involve the Ricci curvature. Conditions are given for making this transformation an isometry, and the author shows that for a compact Kaehler manifold of complex dimension greater than 1, an infinitesimal conformal transformation is holomorphic if and only if it is an infinitesimal isometry. This leads him to consider the groups of holomorphic transformations, and he gives conditions under which a compact complex manifold cannot admit a transitive Lie group of holomorphic transformations. The author also studies the most general class of Riemannian manifolds for which an infinitesimal conformal transformation is also an infinitesimal isometry. These are the famous \\"almost Kaehler\\" manifolds, and the author shows that an infinitesimal conformal transformation of a compact almost Kaehler manifold of dimension 2n for n &gt; 1 is an infinitesimal isometry.for the case of Kaehler manifolds. The results in this chapter could be viewed as a generalization of the classical results concerning compact Riemann surfaces, namely that the universal covering space of a complex n-dimensional compact Kaehler manifold of constant holomorphic curvature K is a projective space for K &gt; 0, the interior of a unit sphere for k &lt; 0, and the space of complex variables for K = 0. After defining the holomorphic curvature, the author shows that the pth Betti number of a compact Kahler manifold M with positive constant holomorphic curvature is zero if p is odd and 1 if p is even. In addition, he shows that any holomorphic form of degree p, for p &gt; 0 and p less than or equal to n, on a compact Kaehler manifold with positive definite Ricci curvature is zero. The author also gives the reader a taste of sheaf  theory, in which he discusses briefly the Kodaira vanishing theorems. <br />In the last chapter, the author generalizes what was done in chapter 3 regarding conformal transformations on Riemannian manifolds, namely that an infinitesimal holomorphic transformation of a compact Kaehler manifold can be viewed as the solution of a system of differential equations which involve the Ricci curvature. Conditions are given for making this transformation an isometry, and the author shows that for a compact Kaehler manifold of complex dimension greater than 1, an infinitesimal conformal transformation is holomorphic if and only if it is an infinitesimal isometry. This leads him to consider the groups of holomorphic transformations, and he gives conditions under which a compact complex manifold cannot admit a transitive Lie group of holomorphic transformations. The author also studies the most general class of Riemannian manifolds for which an infinitesimal conformal transformation is also an infinitesimal isometry. These are the famous \\"almost Kaehler\\" manifolds, and the author shows that an infinitesimal conformal transformation of a compact almost Kaehler manifold of dimension 2n for n &gt; 1 is an infinitesimal isometry.	2002-11-26
1329487:US	50702879	R1LR7AYZD0RT79	0805014020	124400656	The Sane Society	Books	3	17	54	N	N	A weak case	It is always difficult (and some say impossible) to analyze a society or culture from an objective and apodictic point of view, for the obvious reason that the individuals doing the analysis have to sit outside the phenomena in which they are analyzing. If they characterize a particular society as being dysfunctional or its citizens maladjusted in some way, and they themselves are embedded in this society, then an obvious question arises as to why they have the ability to make this characterization, and are not themselves the products of the problems of this culture. In addition, if such individuals put their analysis in print, and if one or more readers understand and are sympathetic with their opinions, then these readers too, must have not been influenced by the problems of the society. Thus the issue comes down to counting the number of individuals who have escaped the decadent influences of their own culture, which entails the use of statistical and scientific analysis.<br /> The author of this book does not subject the societies that he analyzes to rigorous scientific scrutiny. Thus the contents of the book are merely opinions, but that is not to say that one could not get anything out of its perusal. Its contents are thought provoking, and could serve to motivate readers to perhaps attempt to justify them more quantitatively. There is only one place in the book where the author performs any degree of statistical analysis: he gives tables detailing the number of suicides and homicides and alcoholics per 100,000 of adult populations in sixteen countries. This table is used to give a rough guide to the mental health of these countries. He concludes also, from the data in the table, that affluent societies have the highest incidence of suicides, and therefore are the most mentally or emotionally unstable. He does not however take into account that the data may indicate a transient type of phenomena, possibly from extraneous or extreme historical events, that caused problems in some of the individuals populating these countries. Two world wars may indeed have been a temporary but large perturbation to these individual's mental health, traumatizing them to the degree that suicide or alcoholism was their seemingly only option. And one could perhaps imagine a society where alcoholism and suicide were prevented by some artificial and coercive acts of the government, such as requiring individuals to take mind-altering drugs that will alleviate tendencies to suicide or alcoholism. Thus the mere absence or rare occurence of suicides or alcoholics does not by itself point to a \\"sane\\" society.<br /> But it is free societies that the author is most concerned with, and, thus he argues, in spite of the rise of free time and less burdens placed on modern humans, they still commit suicide and abuse alcohol more than perhaps societies that do not possess the luxury of leisure time. But no case studies are given for the kinds of behavior that the author asserts is present predominantly in free, afluent socieites. Indead, the author engages in a diatribe that is general and philosophical, with no attempt to gather statistics to support what he believes about free, capitalist societies. In addition, he makes no effort to study the individuals who feel very happy to live and work in such societies. The reason for this is perhaps the author's belief that these kinds of individuals were the consequence of a attempt to \\"mold them for the purpose of the continuing functioning of the society\\". Thus their happiness is not really genuine, but merely a state resulting from being manipulated to follow some requirement of \\"social character\\". \\"Capitalism\\", he says, \\"needs men who cooperate smoothly in large groups; who want to consume more and more, and whose tastes are standardized and can be easily influenced and anticipated.\\" This may be true to a degree, but capitalist societies also need individuals who swim against the current, this need being driven by innovation. Technological change demands independence of thought as well as self-confidence, and a free society cannot survive without having a large collection of its citizens possessing these qualities. The author though seems to be unable to imagine how anyone could be truly happy in a free, capitalist society. And again, the author does not give one example of an individual or case study that would substantiate his claims. Of all the people who live in the societies he criticizes, can't he find one individual who he can cite, perhaps from medical journals or physicians case-histories, that is an example of a maladjusted, dysfunctional, perhaps mentally ill person who exemplifies his assertions? If one is to believe the author's theories, much more than mere dialog will have to be presented. Such studies are difficult but that is the nature of scientific research into mental illness and psychology.<br /> Every human born in the twentieth and twenty-first centuries is born into a situation that is not of their own making. And everyone is subject to influences and events that they do not have control over. The fact that we all sometimes do not object to such influences and events is not a sign that we enjoy being dominated and want to escape from our freedom, as the author claims. It may indeed be a sign and proof that we have optimized our emotional and psychological health, that we are genuinely happy, and that we find life in the 21st century exhilirating.en by innovation. Technological change demands independence of thought as well as self-confidence, and a free society cannot survive without having a large collection of its citizens possessing these qualities. The author though seems to be unable to imagine how anyone could be truly happy in a free, capitalist society. And again, the author does not give one example of an individual or case study that would substantiate his claims. Of all the people who live in the societies he criticizes, can't he find one individual who he can cite, perhaps from medical journals or physicians case-histories, that is an example of a maladjusted, dysfunctional, perhaps mentally ill person who exemplifies his assertions? If one is to believe the author's theories, much more than mere dialog will have to be presented. Such studies are difficult but that is the nature of scientific research into mental illness and psychology.<br /> Every human born in the twentieth and twenty-first centuries is born into a situation that is not of their own making. And everyone is subject to influences and events that they do not have control over. The fact that we all sometimes do not object to such influences and events is not a sign that we enjoy being dominated and want to escape from our freedom, as the author claims. It may indeed be a sign and proof that we have optimized our emotional and psychological health, that we are genuinely happy, and that we find life in the 21st century exhilirating.	2002-11-23
1330172:US	50702879	R3LMY2M3VMLLFT	0486600610	448078750	Fundamentals of Astrodynamics (Dover Books on Aeronautical Engineering)	Books	4	41	45	N	N	Some topics omitted, but still a good book	This book is a fairly complete overview of planetary mechanics, at least from the standpoint of the Newtonian formulation of the problem, for the authors do not use Lagrangian or Hamiltonian methods. The use of Hamiltonian formulation, via phase space constructions, sheds considerable light on the two-body and the N-body problems, but the reader interested in Hamiltonian mechanics will have to look elsewhere. Also, the authors do not discuss the presence of chaotic dynamics in orbital mechanics, nor are integrability issues discussed. In addition, the current debate over modifications of Newtonian mechanics is not included in the book, due to its time of publication.<br />  But if one wants a practical introduction to Newtonian orbital mechanics that also addresses numerical issues, this would be a good book to begin with. I would recommend the use of a symbolic programming language, such as Mathematica or Maple, to assist in the visualization of the orbits and in the routine computations if one were to use this book as an aid to teaching orbital mechanics. Another good feature of the book is the interjection of historical background and anecdotes at various places in the book. For example, one learns that it was Edmund Halley who was primarily responsible for bringing Newton's discoveries to the world. Newton's work remained idle for twenty years until Halley encouraged Newton to publish his explanation of planetary motion.<br /> The mechanics as outlined in this book is timeless and will continue to be learned by future generations of students as they take up the reigns of human exploration beyond the Moon to the entire solar system.	2002-11-23
1332063:US	50702879	R3EK3ID12RB5YV	0062505114	442181041	Funk & Wagnalls Standard Dictionary of Folklore, Mythology, and Legend	Books	5	14	16	N	N	Packed full of very interesting information	This is the kind of book that you can randomly flip through and always find something interesting, and can read about customs and ideas that are totally different than one's own. The diversity among human beliefs is indeed amazing and is an indication that the human mind adapts and invents concepts that are very different depending on the situation in which individuals find themselves. On the other hand, there are common themes in all of these myths that point to the necessity for the employment of certain concepts that are universal. A gigantic book, it probably would only be read from cover to cover by those who intend to specialize in the study of mythology both from an anthropological and historical point of view. But it is fair to bet that anyone who opens this book will walk away with a deeper appreciation of all human cultures, wherever they may be, and at all levels of technological development.<br /> Lack of space prohibits a detailed review of all the articles I read, but some of the more interesting entries that I ran across include: 1. \\"Ababinili\\". This is the name of the supreme being of the Chickasaw Indians, and the god of the fire apart from the Sun. This belief is an indication again that the concept of an ultimate being is pretty universal among all cultures. Apparently the Chickasaws believed that Ababinili caused a great flood also, although this fact is not discussed in this article. 2. \\"abdominal dance\\". An article discussing the origin of \\"belly dance\\", as it is called in some cultures. Interestingly, in some areas it was not done as a seductive movement or to provoke a sexual response. In Asia for example, it was symbolic of the pain of motherhood. 3. \\"African and New World Negro folklore\\". The author discusses the \\"Tortoise and the Hare\\" story which interestingly was held by some African peoples. He compares it with the European version, with the tortoise winning in both versions. However, in the African version, the tortoise wins by employing his wits. This \\"brains over brawn\\" version of this story is fascinating given the bias towards logical thinking in European culture. 4. \\"bagpipe\\". The origin of bagpipes goes back to the emperor Nero, who reportedly played it. Bagpipes were played by the Romans in their colonization of Britain. 5.  \\"barber's pole\\". There was a time when barbers were also surgeons, thus the red and white strips on the pole: white for bandages to symbolize the healing process. 6. \\"chain tale\\". This is a folktale based on a series of numbers, characters, events, etc. Supposedly the game of chess originated in a chain tale involving numbers in geometric progression. The inventor requested in payment one grain of wheat for the first square, two for the second, four for the third, eight for the fourth, and so on. 7. \\"Dalai Lama\\". The Tibetian monk of highest rank, who is the incarnation of Avalokita, whose spirit passes into a child at the death of each Dalai Lama. 8. \\"euphemism\\". This came from the belief that if you speak of the Devil he will appear. Hence one must refer to him by another name: a euphemism. The origin of the name \\"Jehovah\\" was also such a euphemism, since uttering the name of the Hebrew god was forbidden. 9. \\"female rain\\". Among some North American Indian tribes, this is a soft, gentle rain; to be contrasted with a downpour, which is \\"male rain\\" (How then did hurricanes become to be name after women?). 10. \\"games\\". This is an excellent article, too long to summarize here. 11. \\"grateful dead\\". Folktake in which a hero runs into a group of people who are refusing to bury the corpse of a deadbeat man. The hero makes good the debts, and later is rewarded with happiness. 12. \\"holler\\". A spontaneous, improvised song by American slaves engaging in solitary work. Usually with no words, it was meant to keep oneself company. 13. \\"jack-o-lantern\\". In some legends, This is a phosphorescent light frequently observed above marshes. The author describes many more. 14. \\"kitchen gods\\". The thousands of paper images representing Tsao Chun, the Chinese god of the kitchen stove. 15. \\"looking tabu\\". The act of looking at a forbidden object or person will cause its loss. 16. \\"magical inpregnation\\". A child conceived via some act or circumstance which has no connection with fertilization.  Very common in mythology, the author gives several very interesting examples. 17. \\"mending the jug\\". A folktale based on a task considered impossible and always associated with an impossible countertask. 18. \\"mnemonic device\\". This is an excellent article, too long to summarize here, of the strategies employed by different cultures to remember or recollect things. Particularly interesting was the use of them when no language or mathematical systems were in place. 19. \\"momentary gods\\". These, interestingly, are gods who exist only for a special purpose and for a limited time, and then only at special places. 20. \\"need fire\\". This was a ceremony wherein fire was made when livestock were threatened with plague. 21. \\"never-finished weaving\\". The Shawnee Indian tale of the female creator who weaves a basket which is unraveled every night. Finishing the job will cause the world's end. 22. \\"orchesis\\". The Greek word for dance, which was considered indispensable in Greek drama. 23. \\"orgia\\". The winter ritual dedicated to Dionysus, and involving after sometime to what the author describes as \\"unbridled, licentious mass intoxication\\". He describes similar types of ceromonies in the West Indies, Indian peyote cults, and in Mexico. 24. \\"overlooking\\". This is the act of one who casts the \\"evil eye\\", a belief that according to the author is world-wide and found from earliest times. 25. \\"paternity test\\". An infant magically picking out his unknown father. The author gives several different tests employed by many different cultures. 26. \\"primitive and folk art\\". A very long but excellent article on all kinds. 27.\\"scalp dances\\". These were American Indian \\"victory\\" dances done around the enemies scalps. Apparently in some tribes the scalps were considered tabu and contained supernatural powers.s\\". The thousands of paper images representing Tsao Chun, the Chinese god of the kitchen stove. 15. \\"looking tabu\\". The act of looking at a forbidden object or person will cause its loss. 16. \\"magical inpregnation\\". A child conceived via some act or circumstance which has no connection with fertilization.  Very common in mythology, the author gives several very interesting examples. 17. \\"mending the jug\\". A folktale based on a task considered impossible and always associated with an impossible countertask. 18. \\"mnemonic device\\". This is an excellent article, too long to summarize here, of the strategies employed by different cultures to remember or recollect things. Particularly interesting was the use of them when no language or mathematical systems were in place. 19. \\"momentary gods\\". These, interestingly, are gods who exist only for a special purpose and for a limited time, and then only at special places. 20. \\"need fire\\". This was a ceremony wherein fire was made when livestock were threatened with plague. 21. \\"never-finished weaving\\". The Shawnee Indian tale of the female creator who weaves a basket which is unraveled every night. Finishing the job will cause the world's end. 22. \\"orchesis\\". The Greek word for dance, which was considered indispensable in Greek drama. 23. \\"orgia\\". The winter ritual dedicated to Dionysus, and involving after sometime to what the author describes as \\"unbridled, licentious mass intoxication\\". He describes similar types of ceromonies in the West Indies, Indian peyote cults, and in Mexico. 24. \\"overlooking\\". This is the act of one who casts the \\"evil eye\\", a belief that according to the author is world-wide and found from earliest times. 25. \\"paternity test\\". An infant magically picking out his unknown father. The author gives several different tests employed by many different cultures. 26. \\"primitive and folk art\\". A very long but excellent article on all kinds. 27.\\"scalp dances\\". These were American Indian \\"victory\\" dances done around the enemies scalps. Apparently in some tribes the scalps were considered tabu and contained supernatural powers.	2002-11-21
1333017:US	50702879	R1SYVLA9ZF9178	0600000427	116188157	African Mythology	Books	4	6	6	N	N	Every paragraph is interesting	The African continent of course is huge, and therefore it is not surprising that the number of ideas, works of art, and customs is overwhelming and would take any one person many decades to sort through. This book gives a brief sampling of these, with particular attention paid to the lands south of the Sahara desert. The author concentrates his attention on this part of Africa, for he reasons that it is this part that was shielded from European and Middle Eastern influence, due to the difficulty of crossing the Sahara. The reader learns of the Bushman, who were at the Cape of Good Hope when the first Europeans arrived, the Pygmies, and the Hamites, the latter being the group most strongly influenced by Islamic and Arabic traditions. It is primarily the Negro population of this geographical region though that the author concentrates on in the book.<br /> As the author points out, one troubling feature of African mythology is that they did not usually write anything down, but instead passed on their stories orally. The author blames this lack of written word on the geographical isolation that discouraged its spread. But he also points out that the absence of writing was also a characteristic of ancient American civilizations and the ancient Britons and Teutons. The author therefore relies on the research and recordings of modern African scholars who painstakingly wrote down the stories told them by the various peoples.<br /> A culture of course needs more than just verbalization to express its ideas and moods. To capture and sustain an idea in time without writing, one can use art, particularly in paintings and sculpture. The author argues that African art is deliberately expressive and was employed to symbolize the life in every aspect. Interestingly, the author holds that African proverbs and myths expressed joy in life and human activity. Calling it a 'world-affirming' philosophy, in which life on earth is thought of as good, despite human suffering. The Africans were surely correct about this. Absolutely for sure.<br /> The reader will also learn that nearly all African peoples believe in a supreme being, who created all things. Some of the names of this being include Mulungu in East Africa, Leza in central Africa, and Nyambe in the west. And the author points out, interestingly, that very few temples were built to the \\"supreme\\" god, while places of worship were built for the lesser deities and ancestors. \\"God is too great to be contained in a house\\" say the Africans. Also interesting is that the Africans did not have a god of Sun, for such a god was not needed: there is plenty of sun in Africa. In some African myths, god created the earth in four days, a fifth day being reserved for worship. God also created a mountain with the power of speech, so as to allow the people to hear the divine voice and laws. Dreaming was considered a gift from God, and it functioned as a sequence of messages from God. But witchcraft was believed in also, with women again being the chief practioners.<br /> Man was not the first to create fire, say some Pygmy legends. Rather, it was chimpanzees who first possessed it, and a Pygmy stumbled across their fire accidently and wearing a long bark-cloth, caught it on fire and ran for home. Thus the origin of fire for man.<br /> The god of some African myths used to live on Earth, but left due to some human fault. Others speak of a Golden Age, in which god left willingly. God leaves paradise, and not the humans, for some of the African legends. Also, death was not considered natural in some African myths. It got its start from a dog or a chameleon. The author gives several other fascinating accounts of the African conception of death, including a story very similar to Pandora's Box. Curiosity in many cultures is considered the origin of all evil and suffering, unfortunately.were surely correct about this. Absolutely for sure. <br /> The reader will also learn that nearly all African peoples believe in a supreme being, who created all things. Some of the names of this being include Mulungu in East Africa, Leza in central Africa, and Nyambe in the west. And the author points out, interestingly, that very few temples were built to the \\"supreme\\" god, while places of worship were built for the lesser deities and ancestors. \\"God is too great to be contained in a house\\" say the Africans. Also interesting is that the Africans did not have a god of Sun, for such a god was not needed: there is plenty of sun in Africa. In some African myths, god created the earth in four days, a fifth day being reserved for worship. God also created a mountain with the power of speech, so as to allow the people to hear the divine voice and laws. Dreaming was considered a gift from God, and it functioned as a sequence of messages from God. But witchcraft was believed in also, with women again being the chief practioners. <br /> Man was not the first to create fire, say some Pygmy legends. Rather, it was chimpanzees who first possessed it, and a Pygmy stumbled across their fire accidently and wearing a long bark-cloth, caught it on fire and ran for home. Thus the origin of fire for man. <br /> The god of some African myths used to live on Earth, but left due to some human fault. Others speak of a Golden Age, in which god left willingly. God leaves paradise, and not the humans, for some of the African legends. Also, death was not considered natural in some African myths. It got its start from a dog or a chameleon. The author gives several other fascinating accounts of the African conception of death, including a story very similar to Pandora's Box. Curiosity in many cultures is considered the origin of all evil and suffering, unfortunately.	2002-11-20
1336033:US	50702879	R1LGQX6EQLIO73	0716743825	138774691	Modern Genetic Analysis: Integrating Genes and Genomes	Books	5	29	31	N	Y	An incredible job	In the last few years several very good textbooks and monographs in genetics have appeared, due mainly to the success of various genome projects and also to the rise of bioinformatics as a new discipline in biology, computer science, and mathematics. Most of these textbooks have appeared in many prior editions, and comparing these older editions with the newest ones, one can indeed see a remarkable difference in enthusiasm in the authors. They are clearly very excited about the developments in molecular biology and genetics that have taken place and the confidence among biologists that the fundamental understanding of life is finally within reach. Readers can share their excitement by the study of these books, and doing so one cannot help but be marveled by the incredible ingenuity of the scientific methods used to unravel the processes of life.<br /> Of all these excellent books, I find this one to be the best, and my judgment of the book's quality is from the standpoint of someone who is very involved in the algorithms behind bioinformatics and mathematical biology and is attempting to gain, as quickly as possible, the necessary background in genetics. My review therefore will be primarily addressed to those mathematicians or even physicists who plan on moving into bioinformatics.<br /> To relative newcomers to genetics such as myself, the learning of molecular biology and genetics can involve a huge amount of memory work. To the more mathematically-inclined reader, the memorization of facts can be most unpalatable. The learning of the material in this book will also involve such extreme exercises in memory, but there are a few strategies that the authors employ that, even though they were directed at a general readership, actually serve to make the learning much easier for the mathematician or mathematical biologist. These are the use of concept maps and the assigning of &quot;challenging problems&quot; at the end of most chapters in the book. These serve effectively to make the reader think through and interconnect the many concepts, which for the mathematician who is used to the economy of thought that mathematics brings, is an absolute necessity for the learning experience. Also, the authors are well aware of the need for students to learn how to analyze data and interact with online databases, so a lot of the material in the book is written to address this need.<br /> Even from merely an aesthetic point of view the book is exceptional, as the soft colors used in the illustrations are very beautiful, and actually serve to make the learning of the material very pleasureful. And in addition, the reader can access the book's Website and follow the many animations that were put together for the book. And here again, the playing of these animations increase the speed in which one can learn the subject.<br /> The authors also ask the readers to consider the impact that biotechnology and genetic engineering will have in the upcoming decades. One of the most dramatic, and I think the most important paragraphs in the book is the one in which the authors state that &quot;the public cannot relay on reports published in the general media for the kind of critical evaluation needed to make informed personal and political decisions. Nor can it be left to experts, who have their own biases and agendas. There is no substitute for acquiring the kind of basic knowledge of genetics that is essential to all informed decisions.&quot; Their goal is provide the background that will allow the reader to differentiate between bad and good claims about genetics, and to think critically about both the negative and positive aspects of genetic research and genetic engineering.<br /> I believe the use of genetic engineering and biotechnology in all biological systems, both human and non-human, holds the best hope for the future of life on earth. This book has given an excellent introduction to the biology and genetics behind these technologies. The excitement and optimism expressed in the book will no doubt encourage many individuals to further their studies in genetics and enter the new biological professions of the 21st century.he excitement and optimism expressed in the book will no doubt encourage many individuals to further their studies in genetics and enter the new biological professions of the 21st century.	2002-11-18
1336667:US	50702879	R184SW4J8CPHPD	0486645754	315380479	Lightning (Dover Books on Physics)	Books	4	6	6	N	N	Still useful, even though out-of-date	First published in 1969 and thus out of date due to the extensive research in lightning since then, this book can nevertheless serve as an introduction to the knowledge that was known at the time of publication. My interest in the book stemmed from a sideline interest in ball lightning, a phenomenon which I have never observed, but the accounts of it have some peculiarities from a physics standpoint that are very interesting. Unfortunately, the author only discusses ball lightning in one of the Appendices, and the discussion is very short. The author does discuss in this context the St. Elmo's fire phenomenon.<br /> Even though the book is out of date, it could still serve as a source for homework problems for an instructor teaching a course in electromagnetic theory, whether in physics or engineering. In addition, the author has more recent books on lightning that could be consulted in addition to this one. Lightning is a great example of an electromagnetic phenomenon that everyone is familiar with, and that has lots of interesting physics, some of the understanding of which is still a hot topic of research. For someone like me who is just just curious about the physics of lightning, this book and other ones by the author are of great help, and motivate further reading on the subject.	2002-11-17
1336708:US	50702879	RHUT6CUTWFG8	0394403452	354212491	Baryshnikov at Work: Mikhail Baryshnikov Discusses His Roles	Books	5	13	13	N	N	Master photography and opinions from a master of dance	One of the great dancers of the twentieth century, and perhaps of all time, Mikhail Baryshnikov's work is captured briefly but magnificently in this volume. Unfortunately, I never got the opportunity to see Baryshnikov in a live performance, but only on videos and DVDs. Even in this limited format however, Baryshnikov is brilliant, and a major reason for his superb technique is his attitude. Another dancer could perhaps execute his movements, but Baryshnikov comes across like someone who knows why he is dancing, and not just following the choreography. He creates the impression that he is feeling every movement, and he is celebrating himself to the fullest extent through every execution of such movement.<br /> How fortunate we are that Baryshnikov agreed to tell us his opinions on the works covered in the book. That gives a special insight into his attitudes and general philosophy of dance. Baryshnikov gave credit to his teacher, the great Alexander Pushkin, for teaching him that on stage one must be free, and not just carrying through the techniques learned in class. &quot;Classical technique&quot;, he says, &quot;is like any language: it can be correctly spoken in many voices.&quot; And it is refreshing to read that Baryshnikov believed that dancing ability is the result of discipline and hard work, that a dancer is (self) made, not born.<br /> Baryshnikov gives detailed remarks on the works Giselle, La Bayadere, Don Quixote, Coppelia, Theme and Variations, Les Patineurs, La Fille Mal Gardee, La Sylphide, Le Corsaire, Vestris, Medea, Shadowplay, Spectre de la Rose, Le Pavillon d'Armide, Swan Lake, Romeo and Juliet, Awakening, Hamlet Connotations, Push Comes To Shove, Other Dances, Pas de Duke, Sleeping Beauty, Petrouchka, Le Sacre du Printemps, Once More Frank, and my all time favorite Le Jeune Homme Et La Mort. The photography is all black and white, and superbly done.<br /> One can breathe a sigh of relief that the Soviet government did not choose to eliminate ballet as being too &quot;bourgeois&quot; when it took over in 1917. Baryshnikov and other Russian ballet greats would not have came about if this had been the case. And in addition, the Soviets would have taken away the absolute prerequisite for all healthy civilizations: the dance.e ballet as being too &quot;bourgeois&quot; when it took over in 1917. Baryshnikov and other Russian ballet greats would not have came about if this had been the case. And in addition, the Soviets would have taken away the absolute prerequisite for all healthy civilizations: the dance.	2002-11-17
1337526:US	50702879	R24KX7K1X26YV3	0486259331	126207304	Experiments in Topology (Dover Books on Mathematics)	Books	4	24	24	N	N	Great book for high school teachers and the popular audience	Written for the beginner in topology but still presupposing a certain amount of mathematical maturity, this book is great fun and should be useful to high school teachers, and those who might be giving public talks on mathematics to audiences who are very interested in mathematics, but who don't have a substantial background in the subject. It is always helpful in those scenarios to have concrete examples that will illustrate some of the more difficult constructions in topology.<br /> In chapter 1, the author attempts to give an intuitive definition of topology. The author uses various pictures and handwaving arguments to explain various notions in topology, such as homeomorphism (\\"coffee cup = donut\\"), simply connected (object with no holes), homology (two circles can intersect at one point only), Jordan curves, and Euler's theorem.<br /> In chapter 2, the author uses paper models to illustrate the topology of surfaces, both orientable and nonorientable. The author gives instructions on how to make a paper model of a Klein bottle, but cautions the reader that such a model is not an exact representation of the mathematical object rigorously defined in topology, since the surface passes through itself in the paper construction.<br /> Chapter 3 is a set of instructions on how to make a \\"shortest\\" Moebius strip. The procedures for doing this are interesting and fun, for the author constructs a Moebius strip whose length is less than its width, by a factor of 1 over the square root of 3. He devotes an appendix for an improvement due to Martin Gardner of Scientific American fame.<br /> In chapter 4 the author constructs what he calls a \\"conical Moebius strip\\". The author asks the reader to consider an annulus with a radial slit, with which of course one can construct a Moebius strip by twisting the ends and joining them. But he asks how large the hole must be in relation to the outside diameter. The answer to this is that one does not need any hole at all in order to carry out the construction. In fact, an angular segment can be cut out instead of the radial cut, and this leads him to construct the conical Moebius strip.<br /> The author returns to the Klein bottle in chapter 5, and shows first what happens if the usual construction of the Klein bottle is cut down the center symmetrically: two Moebius strips are obtained. But to construct this model is difficult, so he gives alternate constructions for making the Klein bottle. He then shows what happens to the various models when the pieces are cut.<br /> But how do you make a projective plane using scissors and paper? Intuitively one can imagine this would be very difficult, but the author shows ways to do it in chapter 6. His strategy for making these models is to teach the concept of symmetry in topology, and he pulls this off very well.<br /> The famous 4-color problem for maps, i.e. that one needs only 4 colors for a map, is considered in chapter 7. At the time of publication, the 4-color problem was still open, so the author attempts to try and explain it using various diagrams and subdivisions thereof. The 4-color problem was proved using computer algorithms by the mathematicians K. Appel and W. Haken in 1976.<br /> Network topology is considered in chapter 8, with the famous Koenigsberg bridge problem leading off the discussion. The author also introduces the very important Betti numbers, these having far-reaching ramifications in topology. And interestingly, the author is able, via a consideration of loop-cuts and cross-cuts in paper models of the Klein bottle and projective plane, to introduce the very important concept of \\"duality\\". The theory of knots makes its appearance here, although the discussion is very short. The author is well-aware of the difficulties in finding a classification theory of knots, but more could possibly be done here in the lines of the rest of the book to illustrate some of the peculiarities of knots.<br /> Chapter 9 is really fun, for it concerns the torus with a puncture, and how to turn it inside out. The diagrams are helpful and the intuition gained valuable. The mathematician Steven Smale found a way of turning the sphere inside out in the early 1060s, but the author does not tackle Smale's method! This is unfortunate, since it is very difficult to follow the steps in Smale's method, at least for me.<br /> The author does not want to leave the reader with the impression that topology is all scissors, paper, and tape, so he devotes the last two chapters of the book to point-set topology. Concepts such as continuity, limit points, and neighborhoods are discussed. It is quite difficult to explain to beginning readers and students of topology what a neighborhood actually does without having the notion of a metric or distance, but the author does a fairly good job here.t concerns the torus with a puncture, and how to turn it inside out. The diagrams are helpful and the intuition gained valuable. The mathematician Steven Smale found a way of turning the sphere inside out in the early 1060s, but the author does not tackle Smale's method! This is unfortunate, since it is very difficult to follow the steps in Smale's method, at least for me. <br /> The author does not want to leave the reader with the impression that topology is all scissors, paper, and tape, so he devotes the last two chapters of the book to point-set topology. Concepts such as continuity, limit points, and neighborhoods are discussed. It is quite difficult to explain to beginning readers and students of topology what a neighborhood actually does without having the notion of a metric or distance, but the author does a fairly good job here.	2002-11-17
1338311:US	50702879	R39S3A39Q56F5E	0060932139	104524934	The Unbearable Lightness of Being	Books	5	8	11	N	N	Can being light have appreciable gravitational pull?	One axiom that is appreciated by all readers is that an interpretation of a book is highly dependent on their attitudes, ideologies, and prejudices. This of course has been said many times, to the point of exhaustion possibly. This book is no exception to this rule, and even the title of a book can perhaps entice the reader in making pre-conceived conceptions of what the book is all about. There are many books where the title exhibits a clarity of purpose that prohibits any mistake as to the content and interpretation of the book. This is the case for example for technical and scientific books. For fiction though the title can having many meanings, and such is the case for this book. The \\"lightness of being\\" is the existential insecurity of European philosophy and culture, but also the carefree, lighthearted attitude of those who take nothing seriously, indulging themselves in a self-created age of irony.<br /><br /> Thus the book opens in part one with the Nietzschean dogma of eternal recurrence. This is terrifying for the author, as he says it was for Nietzsche, calling it \\"the heaviest of burdens\\". But ordinary life can stand in contrast to this heaviness, and be \\"lightness\\". But is the latter free from anxiety? Is the ability to free onself from burdens more preferable in the this dichotomy of choice? Parmenides is quoted as saying that lightness is positive, but heaviness negative. The characters of the book: Sabina, Teresa, Tomas, Franz, and others, all encountered this lightness/weight opposition. But most interestingly, their dealings with it illustrated well that the boundary between its two constituents is ill-defined. Events classified in one class can also be in the other. But events can induce drastic consequences. History can be unstable under small perturbations. The characters are very well aware of this also.<br /><br /> Self-absorbed and narcissistic to the core, Tomas and Sabina avoided, and were frightened by, responsibility. Tomas was not to be bound to his son, who was a mere consequence of a \\"single improvident night\\". And what of his relationships with (many) women? They were to only be \\"erotic friendships\\". These ideal relationships make no claim on the life and freedom of the other, and had no intersection with love. But such idealizations of romance and sex are never all-encompassing, for the weight of reality prohibits such lightness: Tomas became jealous of Teresa. And even after breaking it off with Teresa, and regaining his lightness, he voluntarily takes up the heavy weight, the torture of compassion, and returns to Prague to be with Teresa again. Tomas proves that human character has no correlation with the past. It defines itself, like Jean Paul Sartre says, by the instant.<br /><br /> And Sabina, embedded in the rigidity of Soviet occupation, found no  virtue in fidelity. Betrayal was more of a value for her. How could one think otherwise, given the human pollution she saw around her, in the guise of Soviet tanks and soldiers? Break ranks, and go off into the unknown, was for her the ultimate ethic. Following rank, and raising fists in unison, was for her the cause of all evil. But Sabina is confronted with the question of what to betray when all things left to betray are gone. All the burdens are gone, both inside and outside her. Pure emptiness is the result of her goal, this goal being completely unknown during its pursuit.<br /><br /> Franz realized the value of dance, of becoming intoxicated with its freedom, allowing him to \\"get out of the library\\". But honesty to Franz was heavy, his courage was lacking, until he reveals to his wife Marie-Claude his affair with Sabina. Being honest lightened him of course, but Sabina, who  worshipped betrayal, thought otherwise (of course). Sabina left him (of course).<br /><br /> And Teresa, she needed the advice of Tomas and Sabina to free from the heaviness of morality, and to understand that love and sexuality have  nothing in common. Desparate inher attempts not to be jealous of Tomas' other women, she eventually showed great courage and proof of lightness: the witnessing of men giving up their lives in suicide. But this is still to be contrasted with her attempts to sleep with a pure stranger: she was still not advanced (light) enough for that.her attempts not to be jealous of Tomas' other women, she eventually showed great courage and proof of lightness: the witnessing of men giving up their lives in suicide. But this is still to be contrasted with her attempts to sleep with a pure stranger: she was still not advanced (light) enough for that.	2002-11-16
1339742:US	50702879	R2NBCGYUGK6TPB	0387903364	77003830	Elements of Homotopy Theory (Graduate Texts in Mathematics, Vol. 61)	Books	5	12	14	N	N	Excellent	Defining homotopy and homotopy groups is fairly easy, but their actual calculation or determination is very difficult in general. This book, written by one of the major contributors of the subject, is comprehensive and can serve as both a textbook and as a reference since there are collections of exercises at the end of each chapter. The author also includes some brief historical background from time to time, making the reading much more palatable. Space forbids a detailed review, so only the main points of each chapter will be discussed.<br />Chapter 1: Elementary notions of homotopy are discussed, with emphasis on map extension and maps of the n-sphere into itself. Compactly generated spaces are introduced and all the spaces in the book are assumed to be compactly generated. The homotopy lifting property is used to motivate the concept of a fibration. Unfortunately the Hurewicz theorem on fibrations over paracompact spaces is not proven. The proof involves partitions of unity and is very illustrative of typical methods. Best part of the chapter: the discussion on the duality between a fibration and a cofibration.<br />Chapter 2: This is a review of CW-complexes, which are introduced as the easiest objects to study in algebraic topology. The author covers the homology and  cohomology theory of CW-complexes cellular maps. The best part of the chapter though is on products and the cohomology ring: the author explains in detail and gives special insight as to why calculation of cup products is difficult for a general CW-complex (there is no Alexander-Cech-Whitney formula for doing this, as is the case for simplicial complexes).<br />Chapter 3: The author considers the task of putting a natural product on the set of homotopy classes of mappings. This results in a discussion of H- and H'-spaces and eventually their homology. The fundamental group makes its appearance here, along with Hopf algebras, the latter being very important recently in the context of \\"quantum groups\\".  Best part of the chapter: the discussion on the need for the suspension and smash products to alleviate the dependence on base points.<br />Chapter 4: The author concentrates on homotopy groups in more detail, asking first to what extent homotopy can be viewed as having the same properties as homology. Defining first relative homotopy groups and the higher homotopy groups, the connection between homotopy and homology is eventually done via the Hurewicz map and the Whitehead theorem. The best part of the chapter is on the difference between homology groups and homotopy groups under cofibrations, with the opposite occurring for fibrations.<br />Chapter 5: The author returns to the study of CW-complexes, where he studies their (relative) homotopy groups. The relative homotopy group for n greater than or equal to 3 is calculated and shown to be a free Z-module over the first homotopy group of the subcomplex with one basis element for each n-cell, in analogy to the homology of CW-complexes, wherein the nth homology group is free abelian with one basis element for each n-cell of the pair. Eilenberg-Maclane spaces are introduced here for the first time. By far the best part of the chapter though is the treatment of obstruction theory.<br />Chapter 6: Because of its importance to the theory of characteristic classes, and because it is a nice overview of what the topologist Norman Steenrod began in his book on fiber bundles, everything in this chapter is interesting. It is shown in detail how to assign to every pair a homology group with local coefficients. Since characteristic classes are so very important in topology, and since their treatment in the literature is usually too formal, this chapter is a real treat, as it offers rare insight into the origins and intuition behind characteristic classes.<br />Chapter 7: The homology groups of a fibration are discussed, with attention initially made to those whose base space is a suspension of another space. This motivatesthe James reduced products for the loop space of a suspension. The best part though is the detailed treatment of fibrations with spherical fiber.<br />Chapter 8: The homology groups of the loop space of a space B are related to those of B via the homology suspension. This discussion leads to the best part of the chapter: the discussion of stable operations and Steenrod squares.<br />Chapter 9: Eilenberg-Maclane spaces are used build a space of given homotopy type. The maps from one component to one of lower dimension leads to the Postnikov invariant of the space and then Postnikov systems, which is the best part of the chapter.<br />Chapter 10: The Lusternik-Schnirelmann category arises here, and used to prove nilpotency of homotopy mappings of a space to a group. The best part is the one on the Whitehead product.<br />Chapter 11: Homotopy operations are treated in detail, being motivated by the desire to emulate the ability of Eilenberg-MacLane spaces to give universal examples of cohomology operations. The proof of the Hilton-Milnor theorem, which gives a connection between the homotopy groups of the wedge of two spaces and the homotopy of the spaces themselves, is the best part of the chapter.<br />Chapter 12: Stable homotopy groups are discussed and shown to behave like homology groups, at least if the dimension axiom is relaxed. In that regard the discussion on the comparison with the Eilenberg-Steenrod axioms is the best part of the chapter.<br />Chapter 13: This is the most difficult of all the chapters in the book, for it introduces the method of spectral sequences for studying the homology of fibrations. Closely connected with later work on K-theory, spectral sequences are give an elegant treatment here, making this chapter also one of the best in the book. The author shows in detail how to associate with the fiber map an exact couple whose spectral sequence connects the homology of the base with local coefficients in the fiber, to the homology of the total space.mes reduced products for the loop space of a suspension. The best part though is the detailed treatment of fibrations with spherical fiber. <BR>Chapter 8: The homology groups of the loop space of a space B are related to those of B via the homology suspension. This discussion leads to the best part of the chapter: the discussion of stable operations and Steenrod squares. <BR>Chapter 9: Eilenberg-Maclane spaces are used build a space of given homotopy type. The maps from one component to one of lower dimension leads to the Postnikov invariant of the space and then Postnikov systems, which is the best part of the chapter. <BR>Chapter 10: The Lusternik-Schnirelmann category arises here, and used to prove nilpotency of homotopy mappings of a space to a group. The best part is the one on the Whitehead product. <BR>Chapter 11: Homotopy operations are treated in detail, being motivated by the desire to emulate the ability of Eilenberg-MacLane spaces to give universal examples of cohomology operations. The proof of the Hilton-Milnor theorem, which gives a connection between the homotopy groups of the wedge of two spaces and the homotopy of the spaces themselves, is the best part of the chapter. <BR>Chapter 12: Stable homotopy groups are discussed and shown to behave like homology groups, at least if the dimension axiom is relaxed. In that regard the discussion on the comparison with the Eilenberg-Steenrod axioms is the best part of the chapter. <BR>Chapter 13: This is the most difficult of all the chapters in the book, for it introduces the method of spectral sequences for studying the homology of fibrations. Closely connected with later work on K-theory, spectral sequences are give an elegant treatment here, making this chapter also one of the best in the book. The author shows in detail how to associate with the fiber map an exact couple whose spectral sequence connects the homology of the base with local coefficients in the fiber, to the homology of the total space.	2002-11-15
1343371:US	50702879	R244NK4754DWB2	0226424510	648897243	Fields and Rings (Chicago Lectures in Mathematics)	Books	3	6	16	N	N	Pretty good	This book is an advanced treatment of field theory and Galois theory and is meant for those readers who have a substantial background in graduate algebra. The subject matter used to be thought of as purely mathematical, but due to the influence of the field of cryptography, it now has many applications. I only read part 1 of the book, so my review will be confined to this part.<br /> The author begins the discussion with field extensions. One can view a field L containing another field K as a vector space over K, and the dimension of L (as a vector space) is then called the 'dimension' of L over K. If one considers a subfield K of a field M, and an additional element u in M, then there is a smallest subfield of M containing K and u. Calling this field K(u), u can be either transcendental or algebraic over K. The author then proves some elementary properties of the field K(u), showing the existence of an irreducible polynomial for u over K. This then motivates him to call a field L containing K 'algebraic' over K if every element of L is algebraic over K. Otherwise L is called 'transcendental' over K. The dimension of K(u) over K is called the degree of u over K. Finding the degree of u can be done by finding the irreducible polynomial for u. The author also proves the arithmetic relation between the dimensions of towers of fields, and this allows him to prove the famous results on the impossibility of ruler and compass constructions. For a field L that lies between fields K and M the author studies the 'stability' of L over K, meaning that every automorphism of M/K sends L into itself. The correspondence between stable fields and normal subgroups of the Galois group of M/K is proven. Splitting fields are introduced as devices to obtain fields that are normal over a given field. A criterion for a splitting field that does not involve polynomials is proven, and the author gives tools that deal with fields of non-zero characteristic, these tools motivating the definition of separability. Splitting fields are normal in characteristic 0, but one must add separability for the same to hold in characteristic p. The unsolvability of the quintic is shown via a discussion on radical extensions of fields. For a field K of characteristic 0, and for a field L lying between K and another field M, where M is a radical extension of K, the author proves in detail that the Galois group of L/K will be solvable. Then if one has a polynomial with coefficients in K, then the Galois group of this polynomial is defined to be the Galois group of a splitting field of the polynomial over K. The Galois group of the polynomial is thought of as a group of permutations of the roots of the polynomial. The author then proves that if K has characteristic 0 and L is a radical extension of K which contains a root of the polynomial, then the Galois group of the polynomial over K is solvable.<br /> Those readers involved in cryptography will find a discussion of finite fields in Part 1. The author's goal is to find the finite fields and determine their structure. He first proves that every nth power of a prime number p will yield a field with p^n elements. The author shows that the Galois theory of finite fields is simple by proving that if K is a finite field contained in another finite field L, then L is normal over K and the Galois group of L/K is cyclic.<br /> The author also shows how the Galois group of an equation can be found explicitly for the cubic and quartic equations. He shows first that for the Galois group of a separable irreducible cubic over a field K is either the alternating group A(3) or the symmetric group S(3). If the characteristic of K is not equal to 2, then it is A(3) if and only if the discriminant is a square in K. For a separable irreducible quartic over K, then for the degree over K of the splitting field of the resolvent cubic of this polynomial, the Galois group is S(4) if the degree is 6, A(4) if the degree is 3, V (a particular normal subgroup of S(4)) if the degree is 1, and either the group of order 8 or cyclic of order 4 if the degree is 2.<br /> Also in part 1, the author studies the reducibility of an equation of the form x^n -a over an arbitrary field. He addresses this reducibility by first proving that one only need be concerned for the case where n is a prime power. Then if p is prime, and \\"a \\" does not have any pth root in the field K, then if the prime is odd, then the equation is irreducible over K for any n. If p = 2 and the characteristic of K is 2, then the equation is irreducible over K for any n. If p = 2, n is greater than or equal to 2, and the characteristic of K is not 2, then the equation is irreducible over K if and only if -4a is not a fourth power in K. The author also proves the fundamental theorem of algebra using Galois theory. He does this by first showing that if every extension of K has degree divisible by a prime p, then every extension of K has degree a power of p.normal subgroup of S(4)) if the degree is 1, and either the group of order 8 or cyclic of order 4 if the degree is 2. <br /> Also in part 1, the author studies the reducibility of an equation of the form x^n -a over an arbitrary field. He addresses this reducibility by first proving that one only need be concerned for the case where n is a prime power. Then if p is prime, and \\"a \\" does not have any pth root in the field K, then if the prime is odd, then the equation is irreducible over K for any n. If p = 2 and the characteristic of K is 2, then the equation is irreducible over K for any n. If p = 2, n is greater than or equal to 2, and the characteristic of K is not 2, then the equation is irreducible over K if and only if -4a is not a fourth power in K. The author also proves the fundamental theorem of algebra using Galois theory. He does this by first showing that if every extension of K has degree divisible by a prime p, then every extension of K has degree a power of p.	2002-11-12
1345529:US	50702879	RZWHKJVBC56OB	0060637943	908625831	Nietzsche: Vols. 3 and 4 (Vol. 3: The Will to Power as Knowledge and as Metaphysics; Vol. 4: Nihilism)	Books	4	21	23	N	N	The Heideggerian view of Nietzsche in its entirety	Due to the political affiliation of Martin Heidegger and his place in history, it is perhaps difficult to analyze his works objectively. The temptation might be then to lift him from history, with the imagined goal of perhaps cleansing him from the troubling influences he chose to be in. But however Heidegger is read, whether in historical context, or from a \\"modern standpoint\\", he does have some interesting and original things to say about Friedrich Nietzsche. His politics was destructive, as history has shown, and that is a fact that can be discussed completely outside the context of this book.<br /><br /> This is a lengthy book, and concentrates on Nietzsche's work \\"The Will to Power\\". Space therefore prohibits a detailed review, but some of the more interesting discussions by the author include:<br /><br />1. The classifying of Nietzsche as being the \\"last metaphysician\\" of the West. The author believes that his thought was a consummation of Western philosophy, and that the will to power is an appreciation of the decision that must be made as to whether the this final age is the conclusion of Western history or a prelude to another beginning. Nietzsche wanted philosophy to not shy away from the predicament it found itself in. Therefore the author encourages philosophers to not merely \\"toy\\" with philosophical thoughts, as this will place them merely at the boundary of the set of important philosophical issues. The will to power is a sign of courage that consists of shedding one's reservations, and in recognizing the stakes in the issues at hand.<br /><br />2. The reading of Nietzsche as someone who believed that the essence of life is in \\"self-transcending enhancement\\", and not in Darwinian struggle. Value is to be equated with the enhancement of life.<br /><br />3. The author's overview and explanation, and deduction of what \\"truth\\" meant for Nietzsche. Truth can become a \\"de-realization\\" and a hindrance to life, and therefore not be condition of life, and thus not a value. But for the author, Nietzsche wants to overcome nihilism, and this implies therefore that there must be a value greater than truth. And what is this value? It is art, says Nietzsche, which is \\"worth more than truth\\".<br /><br />4. The author's discussion of the alleged biologism of Nietzsche. A reading of Nietzsche might tempt one to conclude that he was, but the author cautions that such a characterization of his writings would be unfounded. One must not base an understanding on mere impressions, and \\"unlearn\\" the abuse that has been leveled against the \\"catchword\\" called \\"biologism\\". The author therefore suggests that we must learn to \\"read\\".<br /><br />5. The description of Nietzsche's epistemology as \\"schematizing a chaos\\". For Nietzsche, this schematizing is an act of imposing upon chaos as much regularity and as many forms as our practical needs require. This is an interesting move, for is the characterization of something as chaotic itself subject to the imposition of this regularity? But the author is certainly aware of this problem, for he discusses in detail the Nietzschean concept of chaos. His reading of Nietzsche in this regard is that chaos does not mean confusion or the removal of all order. It rather means that order is concealed, and is not understood immediately. Most eloquently, the author describes the Nietzschean epistemology as a \\"stream that in its flow first creates the banks and turns them toward each other in a more original way than a bridge ever would.\\" Such a concept of knowledge may seem poetic and too ephemeral to support what is needed for activities such as science and technology, and this is correct.<br /><br />6. The discussion of Nietzsche's stand on the law of contradiction. Heidegger reads Nietzsche as holding to (without an explicit admission on Nietzsche's part) an Aristotelian notion of this law, saying in effect that taking the position that the law of contradiction is the highest of all principles demands an answer to the question of what sorts of assertions it already fundamentally presupposes. Again following Aristotle, Heidegger uses 'Being\\" in his most powerful sense here, as it is 'Being' that has its presence and in permanence. This means that beings represented as such will take into account these two requirements via being \\"at the same time\\" and \\"in the same respect\\". But this permanence is disregarded when an individual makes a contradiction. It is a loss of memory about what is to be grasped in a \\"yes\\" and \\"no\\". Such an activity will not be harmless, says Heidegger, as one day its catastrophic consequences will be manifested. Heidegger sums up the law of noncontraction as that the \\"essence of beings consists in the constant absence of contradiction\\". Further, Heidegger says, Nietzsche's interpretation of the law of contraction is one of an \\"imperative\\". This means that its use is a declaration of \\"what is to count\\" and follows Nietzsche's conception of truth as a \\"holding-to-be-true\\". Nietzsche therefore says that \\"not being able to contradict is proof of an incapacity, not of a 'truth.'\\"it already fundamentally presupposes. Again following Aristotle, Heidegger uses 'Being\\" in his most powerful sense here, as it is 'Being' that has its presence and in permanence. This means that beings represented as such will take into account these two requirements via being \\"at the same time\\" and \\"in the same respect\\". But this permanence is disregarded when an individual makes a contradiction. It is a loss of memory about what is to be grasped in a \\"yes\\" and \\"no\\". Such an activity will not be harmless, says Heidegger, as one day its catastrophic consequences will be manifested. Heidegger sums up the law of noncontraction as that the \\"essence of beings consists in the constant absence of contradiction\\". Further, Heidegger says, Nietzsche's interpretation of the law of contraction is one of an \\"imperative\\". This means that its use is a declaration of \\"what is to count\\" and follows Nietzsche's conception of truth as a \\"holding-to-be-true\\". Nietzsche therefore says that \\"not being able to contradict is proof of an incapacity, not of a 'truth.'\\"	2002-11-10
1346049:US	50702879	R1X3WMO8MC1L86	0679740783	112029362	The Reprieve: A Novel	Books	4	9	13	N	N	There is no fog in Paris in this novel	However one disagrees with Sartre's philosophy, his Marxism, and his anti-Americanism, it is difficult to argue against his personal involvement in what he believed in. Sartre was no pipe-smoking, arm-chair academic content to let others do his fighting. He was always there on the front-lines, perhaps bellicose in his utterings, but always visible. An issue he disagreed with never experienced-his-absence, and Sartre did not hesitate to also be a novelist-philosopher, and as such, he showed more moral courage than perhaps any 20th century philosopher. The equality of idea and action was perhaps an axiom for Sartre, and his life was definitely an empirical validation of such.<br /> Definitely introspective to extremes, this novel, the second in his series \\"The Roads to Freedom\\", is the ultimate portrayal of life in France before the Munich Pact and the takeover of Czechoslovakia in 1938. As a reader, it is easy to get trapped in the stream of consciousness approach that Sartre takes in his novel. Each character is not to be found alone, but immersed in the quagmire of panic, and for some, exhiliration, at the prospect of wartime conflict. The characters define themselves by the instant, their attitudes caught in the flux, that flux impossible to arrest, but their choices completely free nonetheless. Their individuality is sometimes robbed by the gaze of the other, but captured again by choice. Ideology has a short time scale for them.<br /> Sartre does not really shout at the reader through his characters. But their predicament is believable. Their anxiety sometimes familiar, but they also have a perhaps hidden optimism. They know it is themselves, and no other, that determines their future history. The (burden?) of choice is with them always, and they understand fully the power of consequences. But choice works for them as well as against. This makes the appreciation of these characters easy and familiar.	2002-11-09
1346613:US	50702879	R3JB5ATV35PB8M	0911560513	481528987	The Urantia Book: Revealing the Mysteries of God, the Universe, World History, Jesus, and Ourselves	Books	3	29	59	N	N	Good fiction....typical religion...total absence of science	I first discovered this book as a 19 year old teenager, and having read it perhaps in a Walter Mitty sort of mood, I kept it on my shelf throughout the years. It is really an odd book, perhaps because of the claims it makes regarding being a &quot;revelation from God&quot;. A movement has started because of its publication, and so this gives those interested a real-time opportunity to study how a religious movement gets started and how fast it can proliferate in the modern information age. I would classify the book as pure fantasy, and I read some parts of it from time to time when I feel the need to read fiction. It actually has great entertainment value, and I mean this without any underlying sarcasm. It goes without saying that whoever the authors were, they possessed a keen imagination, and their reluctance to reveal themselves is not suprising at all. No empirical evidence is given for any of the assertions made in the book, nor is there any hint of a persuasive tone. The authors never attempt to persuade the reader to the essential correctness of its doctrines, and in that regard, it is similar to all religions. Its dogma is elaborate and deeply symbolic, but not mathematical and definitely not scientific. As a branch of aesthetics though it is interesting, perhaps rivaling the ancient stories of the Hindus and Greeks.<br /> The foreword to the book outlines what the reader can expect, and it overviews some of the terminology employed in the book. &quot;Urantia&quot;, it seems, is the real name of our planet, and it is similar to many inhabited planets which comprise the local universe of &quot;Nebadon&quot;. The reader is not told how close these other planets are, nor given any hint as to where to look for their discovery and study. But this book is religion, not science...<br /> Nebadon further makes up the superuniverse of Orvonton, which has a capital &quot;Uversa&quot;. Orvonton is one of seven evolutionary superuniverses of space-time that circle the central universe of &quot;Havona&quot;, at the heart of which is the dwelling place of the eternal God. Is any observational evidence given of the gravitational interactions between these seven different superuniverses? No, none is given. But this book is religion, not science.<br /> The book supports an evolutionary conception of universe building, but the motion of matter was adjusted by the intelligent efforts of the &quot;power directors&quot; so as to produce the present aggregation of space bodies. These bodies travel along together as a contiguous unit over the orbits of the superuniverse. And what are the shapes of these orbits, and to what degree are they perturbed by the &quot;power directors&quot;? Do the power directors themselves expend energy in the process? No answers are given. But this book is religion, not science.<br /> Some odd astrophysical phenomena are discussed in the book also. For example, when stars are 30 times the size of our Sun, they can split into two separate bodies, either becoming the centers of new systems or else remaining in each other's gravity and revolving about a common center as a double star. As example of double star explosion, the book quotes the light observed in the daytime in 1572. But is the physical mechanism for this explosion into two &quot;stars&quot; explained or elaborated on? No, it is not. But this book is religion, not science.<br /> The book also does not used the metric system, but instead &quot;pounds&quot; and &quot;inches&quot; are used to describe weight and length. Any reason for these units? And why the mysterious appearance of the number &quot;7&quot; in the architecture of the superuniverse? Perhaps to tie in with the Biblical notion?  No answers to these questions are given. But this book is religion, not science.<br /> In terms of physics alone, forgetting all the revelations on the &quot;spirtual&quot; architecture of the superuniverse, would not revealed truth give us insights that were not apparent before? Would not a revelation of this degree give us answers to vexing physics questions that remain unanswered to this day?  As such, the book gives none, and introduces more oddities than answers. A good test for the &quot;validity&quot; of a revelation would be the answering of scientific questions that would advance its frontiers considerably. There are none in this book.<br />But this book is religion, not science.apparent before? Would not a revelation of this degree give us answers to vexing physics questions that remain unanswered to this day?  As such, the book gives none, and introduces more oddities than answers. A good test for the &quot;validity&quot; of a revelation would be the answering of scientific questions that would advance its frontiers considerably. There are none in this book.<br />But this book is religion, not science.	2002-11-09
1348130:US	50702879	R3I9ZEX6MK851K	0387035257	777193073	Topological Methods in Algebraic Geometry (Ergebnisse Der Mathematik Und Ihrer Grenzgebiete 131) Second, Corrected Printing of the Third Edition	Books	4	0	0	N	N	Still suitable as a reference	That algebraic topology can be applied to algebraic geometry (and vice-versa) and interesting results obtained is now mainstream mathematics, as was illustrated in one-half of the 2002 Fields Medal. All of these results are fascinating, but require formidable amounts of technical machinery. This book is a formal account of what was known at the time of publication, and outlines many of the results that the author himself has contributed. A considerable amount of research has been done in this area since the time of publication, but this book could still possibly be used as a reference to a course in the subject or as supplementary reading. And even though the author does spend a fair amount of time reviewing the background needed to read the book, it is really written for those who have the background but desire a rigorous overview of the subject. Physics, especially high-energy physics, through the constructions of superstring and M-theories, is making considerable use of algebraic geometry and some of the results in this book. The physicist reader though should probably start somewhere else in order to gain the necessary intuition. Such a reader is also cautioned that there are only a few books out there that would assist in learning the conceptual foundations of algebraic geometry, without being part of its \\"oral tradition\\". Also, the notation employed by the author and the font in which the book is written can be difficult to read.<br /> The major goal of the book is to prove the Riemann-Roch theorem to the case of complex analytic vector bundles over algebraic manifolds. The author does this in the very last section of the book, after discussing cobordism theory and the Todd genus in chapters 2 and 3 respectively. The are also sizeable appendices in the book, one of which outlines the generalization of the Riemann-Roch theorem due to Grothendieck. Since the time of publication there have been many generalizations of the Riemann-Roch theorem. This book will serve as a good reference for the understanding of these.ve as a good reference for the understanding of these.	2002-11-07
1350313:US	50702879	ROCF5B7PK7T01	0691079471	505225814	Dimension Theory (Princeton Mathematical Ser.; Vol 4)	Books	5	15	15	N	N	Still an excellent book	As an undergraduate senior, I took a course in dimension theory that used this book Although first published in 1941, the teacher explained that even though the book was \\"old\\", that everyone who has learned dimension theory learned it from this book. There are of course many other books on dimension theory that are more up-to-date than this one. But the advantage of this book is that it gives an historical introduction to dimension theory and develops the intuition of the reader in the conceptual foundations of the subject. The concept of dimension that the authors develop in the book is an inductive one, and is based on the work of  the mathematicians Menger and Urysohn. In this formulation the empty set has dimension -1, and the dimension of a space is the least integer for which every point in the space has arbitrarily small neighborhoods with boundaries having dimension less than this integer. The authors restrict the topological spaces to being separable metric spaces, and so the reader who needs dimension theory in more general spaces will have to consult more modern treatments.<br /> In chapter 2, the authors concern themselves with spaces having dimension 0. They first define dimension 0 at a point, which means that every point has arbitrarily small neighborhoods with empty boundaries. A 0-dimensional space is thus 0-dimensional at every one of its points. Several examples are given (which the reader is to prove), such as the rational numbers and the Cantor set. It is shown, as expected intuitively, that a 0-dimensional space is totally disconnected. The authors also show that a space which is the countable sum of 0-dimensional closed subsets is 0-dimensional. The closed assumption is necessary here, as consideration of the rational and irrational subsets of the real line will bring out.<br /> Chapter 3 considers spaces of dimension n, the notion of dimension n being defined inductively. Their definition of course allows the existence of spaces of infinite dimension, and the authors are quick to point out that dimension, although a topological invariant, is not an invariant under continuous transformations. The famous Peano dimension-raising function is given as an example. The authors prove an equivalent definition of dimension, by showing that a space has dimension less than or equal to n if every point in the space can be separated by a closed set of dimension less than or equal to n-1 from any closed set not containing the point. The `sum theorem' for dimension n is proven, which says that a space which is the countable union of closed sets of dimension less than or equal to n also has dimension less than or equal to n.<br /> A successful theory of dimension would have to show that ordinary Euclidean n-space has dimension n, in terms of the inductive definition of dimension given. The authors show this in Chapter 4, with the proof boiling down to showing that the dimension of Euclidean n-space is greater than or equal to n. (The reverse inequality follows from chapter 3).  The proof  of  this involves showing that the mappings of the n-sphere to itself which have different degree cannot be homotopic. The authors give an elementary proof of this fact. This chapter also introduces the study of infinite-dimensional spaces, and as expected, Hilbert spaces play a role here.<br /> The Lebesgue covering theorem, which was also proved in chapter 4, is used in chapter 5 to formulate a covering definition of dimension. The author also proves in this chapter that every separable metric space of dimension less than or equal to n can be topologically imbedded in Euclidean space of dimension 2n + 1. The author quotes, but unfortunately does not prove, the counterexample due to Antonio Flores, showing that the number 2n + 1 is the best possible. These considerations motivate the concept of a universal n-dimensional space, into which every space of dimension less than or equal to n can be topologically imbedded. The author also proves a result of Alexandroff on the approximation of compact spaces by polytopes, and a consequent definition of dimension in terms of polytopes.<br /> Chapter 6 has the flair of differential topology, wherein the author discusses mappings into spheres. This brings up of course the notion of a homotopy, and the author uses homotopy to discuss the nature of essential mappings into the n-sphere. The author motivates the idea of an essential mapping quite nicely, viewing them as mappings that cover a point so well that the point remains covered under small perturbations of the mapping. This chapter also introduces extensions of mappings and proves Tietze's extension theorem. This allows a characterization of dimension in terms of  the extensions of mappings into spheres, namely that a space has dimension less than or equal to n if and only if for every closed set and mapping from this closed set into the n-sphere, there is an extension of this mapping to the whole space.<br /> In chapter 7 the author relates dimension theory to measure theory, and proves that a space has dimension less than or equal to n if and only if it is homeomorphic to a subset of the (2n+1)-dimensional cube whose (n+1)-dimensional measure is zero. As a sign of the book's age, only a short paragraph is devoted to the concept of Hausdorff dimension. Hausdorff dimension is of enormous importance today due to the interest in fractal geometry.<br /> Chapter 8 is the longest of the book, and is a study of dimension from the standpoint of algebraic topology. The treatment is relatively self-contained, which is why the chapter is so large, and the author treats both homology and cohomology.  The author proves that a compact space has dimension less than or equal to n if and only if given any closed subset, the zero element of the n-th homology group of this subset is a boundary in the space. A similar (dual) result is proven using cohomology.o proves a result of Alexandroff on the approximation of compact spaces by polytopes, and a consequent definition of dimension in terms of polytopes. <br /> Chapter 6 has the flair of differential topology, wherein the author discusses mappings into spheres. This brings up of course the notion of a homotopy, and the author uses homotopy to discuss the nature of essential mappings into the n-sphere. The author motivates the idea of an essential mapping quite nicely, viewing them as mappings that cover a point so well that the point remains covered under small perturbations of the mapping. This chapter also introduces extensions of mappings and proves Tietze's extension theorem. This allows a characterization of dimension in terms of  the extensions of mappings into spheres, namely that a space has dimension less than or equal to n if and only if for every closed set and mapping from this closed set into the n-sphere, there is an extension of this mapping to the whole space. <br /> In chapter 7 the author relates dimension theory to measure theory, and proves that a space has dimension less than or equal to n if and only if it is homeomorphic to a subset of the (2n+1)-dimensional cube whose (n+1)-dimensional measure is zero. As a sign of the book's age, only a short paragraph is devoted to the concept of Hausdorff dimension. Hausdorff dimension is of enormous importance today due to the interest in fractal geometry. <br /> Chapter 8 is the longest of the book, and is a study of dimension from the standpoint of algebraic topology. The treatment is relatively self-contained, which is why the chapter is so large, and the author treats both homology and cohomology.  The author proves that a compact space has dimension less than or equal to n if and only if given any closed subset, the zero element of the n-th homology group of this subset is a boundary in the space. A similar (dual) result is proven using cohomology.	2002-11-06
1352109:US	50702879	R23Z2L514FMCU7	0394703693	922733443	The Birth of Tragedy and The Case of Wagner	Books	5	18	25	N	N	Excellent	The ideas of Friedrich Nietzsche has had considerable influence on much of twentieth century philosophy and other areas as well. Indeed, the modern dance technique of Doris Humphrey is one of the many, and was taken to be based on his distinction between the Apollinian and Dionysian duality. Walter Kaufmann, the translator and commentator of this book, has given the reader a distinct view of Nietzsche in two of his works, the &quot;Birth of Tragedy&quot; being his first, and one of his last, &quot;The Case of Wagner&quot;.<br /> Nietzsche was one of the few philosophers who engaged in self-criticism, and is the most honest of all philosophers who took to the pen. This is indeed manifest in his &quot;Attempt at a Self-Criticism&quot;, which was added to the 1886 edition of &quot;The Birth of Tragedy&quot;. Nietzsche attempted to view the nature of truth without any masks, and his need to do this resulted in his works perhaps being more of a dialog with himself than with his readers. With every line written, Nietzsche was making sure that he himself was convinced of what was put down on paper. But this must at all times be done without &quot;arresting the play&quot; and negating the &quot;terrors of existence&quot;.<br /> Kaufmann represents &quot;The Birth of Tragedy&quot; as a work that allowed Nietzsche to justify his appointment to a full chair of philology at the young age of 25, but also a book that would not appeal to anyone in German academic circles. It would appear that Nietzsche was determined to remain independent, and not become intoxicated with the &quot;prestige&quot; of being appointed to such a position at such an early age. Nietzsche's later criticism of his own work would seem to justify this interpretation. This total intellectual honesty of Nietzsche is unique in the history of philosophy.<br /> What is most valuable about &quot;The Birth of Tragedy&quot; is its restatement of Greek life and culture, which up to Nietzsche's time was conceived in terms of the &quot;Winckelmann view&quot; according to Kaufmann. The &quot;noble simplicity, calm grandeur&quot; of Goethe and the &quot;sweetness and light&quot; of Matthew Arnold were the appropriate adjectives for Greek culture. But Nietzsche brought in the Dionysian festivals, as another aspect of it, and its longing, in the words of Kaufmann, to &quot;exceed all norms&quot;. This insight of Nietzsche has wide-ranging applications, for it points to the need of all cultures, and thus all individuals, to at times attend the Dionysian festival and get out of equilibrium, remain for awhile off-balance, and get intoxicated with the dance of unreason.<br /> But with intellectual honesty towards oneself comes the same for others, and Nietzsche did not hesitate to depart with friends when there was conflict with this honesty. Thus Nietzsche wrote &quot;The Case of Wagner&quot;, a very damning indictment against his former friend Richard Wagner, and a book which Nietzsche subtitled &quot;A Musician's Problem&quot;. Nietzsche describes his reasons for writing at it as a consequence of a &quot;special self-discipline: to take sides against everything sick in me&quot;. This included Wagner, Schopenhauer, and all of what Nietzsche called &quot;modern humaneness&quot;.  According to Nietzsche, Wagner was just one of his sicknesses. But sickness can be a stimulant to life, he says, but only if one is healthy enough for this stimulant.<br /> So what about Wagner bothered Nietzsche? It was the fact in Nietzsche's view, Wagner's music was nongenuine. Wagner was an &quot;actor in music&quot;, according to Nietzsche, and a lack of honesty or genuineness was intolerable to Nietzsche. The integrity and &quot;authenticity&quot; of musicians has never been put to the test so dangerously, he says. Wagner's music is a sign of a declining culture, and in such a culture, believed Nietzsche, authenticity becomes superfluous and a liability. Thus the passion that Wagner's music instilled in people, and the boredom it alleviated in orchestra musicians, was more of a sign of decadence, rather than achievement. It was an attempt to &quot;arrest the flow&quot;, to negate the original &quot;difficulty of life&quot;, and this, in Nietzsche's view, was its essential crime, a crime that Christianity and other forms of decadence also committed. The ninth part of the book ends with the following lines which make Nietzsche's Wagnerian complaint particularly manifest: &quot;That the theatre should not lord it over the arts. That the actor should not seduce those who are authentic. That music should not become an art of lying. &quot;in people, and the boredom it alleviated in orchestra musicians, was more of a sign of decadence, rather than achievement. It was an attempt to &quot;arrest the flow&quot;, to negate the original &quot;difficulty of life&quot;, and this, in Nietzsche's view, was its essential crime, a crime that Christianity and other forms of decadence also committed. The ninth part of the book ends with the following lines which make Nietzsche's Wagnerian complaint particularly manifest: &quot;That the theatre should not lord it over the arts. That the actor should not seduce those who are authentic. That music should not become an art of lying. &quot;	2002-11-04
1352979:US	50702879	R36IYVN0M0MZ2Q	0679748199	79113792	Voltaire's Bastards: The Dictatorship of Reason in the West	Books	3	11	26	N	N	Is the author ruled by the dictatorship of anger?	The author clearly has an axe to grind, and his anger against the bureaucracies is only matched by today's libertarians. One could argue maybe that his anger is somewhat justified, as the policies of some bureaucracies has led to more unintended pain than perhaps any other group of individuals. The bureaucracies though of the author are ones that he says are following the dictates of \\"reason\\", which he claims \\"is a narrow system swollen into an ideology\\", and \\"presents itself as the solution to the problems it has created\\". He asserts that the philosophers of Europe, England, and America \\"threw themselves into the arms of reason\\" with the conviction that it would result, thanks to the \\"rational elites\\" that control it, to a new civilization.<br /> The philosopher Voltaire was the one who began this path to perdition, says the author, and his followers, \\"the bastards of Voltaire\\", have, unwittingly perhaps, created a complex array of coercive social structures, divorced from ethical considerations, and possessing no redeeming virtue. The academy, the military, the educational system, and the government bureaucracies have all played a part in this negation of common sense and morality, and society has become a \\"self-justifying system which generates its own logic\\". The author therefore advises the reader of the \\"virtue of doubt\\", and to eschew the disease called \\"the desire to answer\\", which he says \\"runs through our veins like rats scurrying for truth in the endless corridors of expertise\\". The goal should be to unify the individual through questions, and not divide him through answers, he says.<br /> Well, the author's thesis is an interesting one, but also somewhat troubling, since if a reader were to believe it in its entirety, then it follows that there are two people who have escaped the \\"rigidity of reason\\" and its sterile and sometimes dangerous consequences: the reader and the author. If a reader is open enough to understand the author's complaints, then certainly such a reader has been spared the cruelty and dogmatism of the \\"dictatorship of reason\\". The author too, by his very act of writing things differently than the controlling bureaucracies, has found safe haven outside of their influence. What existing institutions educated the author? If there were none, and he discovered his ideas on his own, that is even more proof that the soul can be saved from the \\"tyranny of reason\\". Of course, if there is no such reader, then the author is alone, comfortable maybe to immerse himself in apodictic certainty.<br /> The late Allan Bloom said that anger requires an unshakable conviction that one is right in order to sustain itself. The author's own dogmatism is to be compared maybe with the agencies he speaks out against. Reason is not a force of nature though, nor an abstract Hegelian menacing principle that forces itself upon the scene, taking no prisoners. It begins with the mind of the individual and is always the result of free choice. Intelligence is time dependent, and does not necessarily have a correlation with the past. Wisdom and folly can proceed from the same person(s), and its consequences are sometimes unpredictable at short time scales. Errors, false leads, irrational beliefs, unethical conduct, and blind allegiance to ideology are perhaps some of the downsides of being human. These can always be corrected, but again only by choice. But if the author is correct, then he himself is the best example maybe of someone who was not been swayed by the idols of the bureaucracies. He should therefore be guided by the person he observes daily in the mirror, take up the (very light) sword called optimism, and remember the words of Melville, that \\"hope prove a man deathless\\".rtainly such a reader has been spared the cruelty and dogmatism of the \\"dictatorship of reason\\". The author too, by his very act of writing things differently than the controlling bureaucracies, has found safe haven outside of their influence. What existing institutions educated the author? If there were none, and he discovered his ideas on his own, that is even more proof that the soul can be saved from the \\"tyranny of reason\\". Of course, if there is no such reader, then the author is alone, comfortable maybe to immerse himself in apodictic certainty. <br /> The late Allan Bloom said that anger requires an unshakable conviction that one is right in order to sustain itself. The author's own dogmatism is to be compared maybe with the agencies he speaks out against. Reason is not a force of nature though, nor an abstract Hegelian menacing principle that forces itself upon the scene, taking no prisoners. It begins with the mind of the individual and is always the result of free choice. Intelligence is time dependent, and does not necessarily have a correlation with the past. Wisdom and folly can proceed from the same person(s), and its consequences are sometimes unpredictable at short time scales. Errors, false leads, irrational beliefs, unethical conduct, and blind allegiance to ideology are perhaps some of the downsides of being human. These can always be corrected, but again only by choice. But if the author is correct, then he himself is the best example maybe of someone who was not been swayed by the idols of the bureaucracies. He should therefore be guided by the person he observes daily in the mirror, take up the (very light) sword called optimism, and remember the words of Melville, that \\"hope prove a man deathless\\".	2002-11-03
1354758:US	50702879	RT9H8YU5XVD9H	0262530740	277567517	Matter and Consciousness: A Contemporary Introduction to the Philosophy of Mind	Books	4	17	20	N	N	Pretty good introduction to a vexing problem	The mind-body problem, as it is called in Western philosophy, still has the attention of philosophers, despite centuries of debate. It will no doubt occupy more of philosophers time in the upcoming decades due to the resurging interest (and advances) in artificial intelligence. But the goal of most research in A.I. is now geared towards computational algorithms that are able to learn and can discover new knowledge or data patterns. The &quot;hard A.I.&quot; problem, that of creating conscious machines, is not top priority it seems.<br /> But philosophers will continue with the analysis of the nature of conscious intelligence, and the author is one of these. Interestingly though, and correctly, he asserts that progress in this analysis has been made, and he notes that philosophy has joined hands with psychology, artificial intelligence, neuroscience, ethology, and evolutionary theory in making this progress. And this will no doubt continue as advances in these fields are made, and the 21st century will see the advent of the &quot;industrial philosopher&quot;. Once thought to be a purely academic profession, the ethical considerations behind genetic engineering and the legal rights of thinking machines will require the presence of philosophers in the rank and file of engineers, technicians, and managers. And because of this, these philosophers, and their coworkers will themselves have considerable knowledge outside their own field.<br /> Again, the refreshing feature of this book is that the author believes that philosophy has made considerable process on the nature of mind. This was done, he says, by understanding the mind's self-knowledge, by providing a much clearer idea of the nature of the different theories of mind, and by clarifying the sorts of evidence that must be acquired in order to distinguish between these different theories. Empirical evidence, he states, has enabled the making of these distinctions much more rational and scientific. But he is careful to note that the evidence is still ambigious, and much work still needs to be done before the these ideas can be differentiated with more clarity. He discusses in detail the different theories of dualism and materialism. An entire chapter is devoted to discussing substance dualism, property dualism, philosophical behaviorism, reductive materialism, functionalism, and eliminative materialism. The author asks readers to start anew and throw away their convictions while analyzing these conceptions of mind and matter.<br /> For the author, the mind-body problem cannot be solved without considering three problems: 1. Semantical: The meaning of ordinary common-sense terms for mental states. 2. Epistemological: The problem of other minds and the capacity for introspection. 3. Methodological: The proper methodology to use in constructing a theory of mind. Entire chapters are devoted to these, and after reading them the reader entering the debate on the mind-body problem for the first time will have an over-abundance of food for thought.<br /> An entire chapter is spent on the topic of artificial intelligence. If this book were updated, this chapter would probably have to be considerably expanded, in that many advances have been made in A.I. since this book was first published. Research in A.I. has been rocky, and many promises that were unfullfilled were made in the past about it. But now it seems a more rational and realistic attitude is taken about the claims of A.I. Most everyone involved in it understands that it is an enormously complex problem, and have concentrated their efforts on building intelligent machines from a piece-meal, microscopic approach, i.e. from solving the simplest problems first before tackling the more difficult ones.<br /> A chapter is also devoted to neuroscience. Thanks to imaging technologies and other approaches to mapping the brain, this field has mushroomed in recent years. The author only gives a cursory overview of the brain and the nervoussystem in this chapter, due no doubt to lack of space. The reverse engineering of the human brain has been pointed to by some researchers in artificial intelligence as being the best hope for building intelligent machines. The dramatic increases in chip technology and bus design have made this belief certainly more feasible. It remains to be seen, via actual empirical research, whether the reverse engineering of the human brain, and then its subsequent implementation in electronic devices, will indeed result in the rise of intelligent machines.<br /> Whatever the future of artificial intelligence and neuroscience, the mind-body problem will no doubt be of interest to philosophers for decades to come. It will be fascinating to see what kinds of conceptual frameworks and methodologies will be employed in attempts to solve this problem. Without doubt some new ideas would be welcome in this regard, as proposals for solutions to the mind-body problem seem to be stuck in a local minimum. But, as the author argues well for, the solution will bring in many areas and possibly some radical ideas, all supported by painstaking experimentation.rvous system in this chapter, due no doubt to lack of space. The reverse engineering of the human brain has been pointed to by some researchers in artificial intelligence as being the best hope for building intelligent machines. The dramatic increases in chip technology and bus design have made this belief certainly more feasible. It remains to be seen, via actual empirical research, whether the reverse engineering of the human brain, and then its subsequent implementation in electronic devices, will indeed result in the rise of intelligent machines. <br /> Whatever the future of artificial intelligence and neuroscience, the mind-body problem will no doubt be of interest to philosophers for decades to come. It will be fascinating to see what kinds of conceptual frameworks and methodologies will be employed in attempts to solve this problem. Without doubt some new ideas would be welcome in this regard, as proposals for solutions to the mind-body problem seem to be stuck in a local minimum. But, as the author argues well for, the solution will bring in many areas and possibly some radical ideas, all supported by painstaking experimentation.	2002-11-02
1355194:US	50702879	R3KEIAO1X6U5K0	0385483368	495318696	The Last Apocalypse: Europe at the Year 1000 A.D.	Books	4	4	8	N	N	A time full of heros...just like today	So what was it like to live in Europe in the year 1000 A.D.? The author gives a brief glimpse of it at the turn of  the millennium, and the picture he gives is one of an existence that is partly brutal and partly poetic. Certainly the people who lived in that century had an abundance of courage and, judged by the many standards of the 21st century, their lifestyle may seem very primitive. But many of their beliefs and ideologies survive to this day, and, they are held by greater numbers. If one criticizes the people of this time as being barbaric, perhaps a lesson in statistics would be in order. Most of the people of this time, by an overwhelming majority, never killed anyone. A lesser number perhaps, but still a vast majority, never hurt anyone physically. Human brutality is rare, back then as it is now. Those who believe in an inherent murderous nature of humankind are poor statisticians. Very poor ones indeed.<br /> The author gives the reader details of the Viking raids, their kings, and their family life. Maps are drawn to delineate the pagan influences and control of Europe. It is perhaps not a surprise to see Christianity, Judaism, and Islam coexisting with, and mixing with, these earthly doctrines. Ideas, no matter how disjoint, can always eventually find an intersection. \\"To mix ones's faith was the fashion\\" says the author. This time had its share of genius, both scientific and literary. Most perhaps lived their lives as preparation for an afterlife, but their visions, some bold, some timid, and some violent, gave a continuity to history. Learning from example is a most powerful technique, and we can backpropagate to that time to make sure what was good about their culture is also good about ours. What is bad about it we can shelf and label: \\"For Reference Only\\".<br /> Did cold climate rear cold personalities? Can we blame the Viking conduct on the weather in Greenland? Not really, since, as the author states the world's climate in 1000 A.D. was more moderate than today. Greenland and Iceland were a full degree Centigrade hotter. Perhaps this made Leif Eriksson's trip to Greenland, in particular on an island just off its shores and close to the American continent, much easier. His voyage tells the reader that the New World is a lot older than is sometimes taught. The pagan blonde beat the Catholic merchant by almost five centuries.<br /> And those Viking women! A thousand year headstart on the women's movement of today, they hesitated not in their ambition. Could the men of today handle them? Queen Sigrid could drink the typical 21st century man under the table. Wife abuse was therefore uncommon, and was \\"a dangerous game\\", and \\"to strike her in the face could be suicide\\", says the author. And the empress Theophano is not to be forgotten, a counterexample against the preconception that beauty and brutality cannot exist in one person.<br /> The reader learns of Spain under the Moors, captured centuries before from remnants of the Visigoths. But under the Islamic Moors, \\"tolerance was deep\\", says the author. Christians were taxed via the \\"jizya\\", but were allowed to worship freely and \\"ring the bell on Sundays\\".  Spain under the Moors had seventeen universities, but Christian Europe only two. No public libraries in Christian Europe, but seventy in Moorish Spain. Without a doubt, modern science owes a lot to Islam. The Moors were defeated four centuries later, and instead of obtaining more places of learning, Spain was blessed with The Inquisition.<br /> Europe was beginning to draw its boundaries, at least the ones familiar today. Al Mansor, Little Sancho, Sancho the Great, Otto the Great,  Vajk the Saint, Gerbet the Wizard, and Theophano are discussed as the predominant figures doing this typically violent European redistricting. But should we really label history by the names of these individuals? Those outside of this small collection were the true movers of the time. Unknown perhaps, their contributions made lifepossible, then and now. They \\"walked silently through life\\" as the European philosopher Friederich Nietzsche would say of true heros over eight centuries later.<br /> The author ends the book with a recapitulation of the events, spanning over about forty years, that transformed the first millennium into the second. He calls it a \\"miraculous transformation\\" and says that as the new millennium began, there was a mood of \\"hope and excitement\\". If so, the similarity to the current time is uncanny. The world today is dramatically different, but the optimism remains, albeit amplified beyond measure. Regions of conflict still exist, some of these being identical to the ones of 1000 A.D. Some ideas have a long decay time. But in this millennium humans have learned to make copies of themselves, to create new lifeforms,  make thinking machines out of grains of sand, and hurl themselves into space. If the humans of 1000 A.D. could see 21st century technology they would perhaps find it shocking, even alien. But they would find our optimism familiar. Very familiar.life possible, then and now. They \\"walked silently through life\\" as the European philosopher Friederich Nietzsche would say of true heros over eight centuries later. <br /> The author ends the book with a recapitulation of the events, spanning over about forty years, that transformed the first millennium into the second. He calls it a \\"miraculous transformation\\" and says that as the new millennium began, there was a mood of \\"hope and excitement\\". If so, the similarity to the current time is uncanny. The world today is dramatically different, but the optimism remains, albeit amplified beyond measure. Regions of conflict still exist, some of these being identical to the ones of 1000 A.D. Some ideas have a long decay time. But in this millennium humans have learned to make copies of themselves, to create new lifeforms,  make thinking machines out of grains of sand, and hurl themselves into space. If the humans of 1000 A.D. could see 21st century technology they would perhaps find it shocking, even alien. But they would find our optimism familiar. Very familiar.	2002-11-01
1356665:US	50702879	R1S9UWU0PF9VKL	0060655186	602904794	Who Wrote the New Testament?: The Making of the Christian Myth	Books	4	65	89	N	N	Some interesting hypotheses here	Biblical studies can be both interesting and boring depending on the  reasons for doing it. It is interesting in that it requires meticulous analysis and a greater measure of objectivity. Too often personal beliefs and prejudices sway the researcher into making statements that are not relevant or are scientifically unsound. But Bible study can also be boring if one is forced to do it because of parental or societal pressures. Anyone engaged in the latter deserves much sympathy of course, but hopefully some good ideas will come out of such a scenario. If one is to do a scientific study of the Bible, it must be done without masks, and one must be prepared to accept the consequences, regardless of how they may be at odds with one's religious (or secular) convictions.<br /> The author of this book clearly has a negative attitude about the New Testament and Christianity in general, but it is interesting reading if one forgets this. The author speaks of the &quot;Catch-22&quot; that he was confronted with when deciding to write a book about the New Testament. He does not view the New Testament as one in which the authors were all collaborating together to write the gospels and to found the Christian church. The &quot;catch&quot; he says is that most people do believe that this is the case, i.e. the the New Testament is an eye-witness account of how Jesus came into the world, preached the gospels, was crucified, and then resurrected. The conversion of Paul and the works of the apostles came subsequently and was documented accurately by the writers of the New Testament.<br /> The New Testament, according to the author, has very different views of Jesus, Judaism, salvation, the Kingdom of God, etc. It is thus misleading, in the eyes of the author, to view the literary status of New Testament as being the work of authors who bore witness to a set of events that inaugurated the Christian religion. Christian literature was written anonymously and the names given to the authors was done in ways that show it was not considered dishonest to do so. It was considered normal practice in that period of time to credit others with literary works, speeches, letters, etc. that represented individuals that were deemed important for the particular area discussed.<br /> In order to understand the origins of Christianity and why individuals came to hold to it, the author believes that one needs to dismantle the New Testament and attempt to isolate just where and when each writing arose. The conventional picture of Christian origins must be set aside and the New Testament analyzed anew. The author makes use of what some Biblical scholars call the &quot;Q source&quot;, which arose from their view that Matthew and Luke had used a collection of sayings of Jesus as one their sources, the other being the gospel of Mark. A major portion of the early part of the book is the author's justification for using the Q document. Some historians and readers will no doubt be troubled by the use of Q, but it could perhaps be viewed as a &quot;working hypothesis&quot; to explain the disparities between the gospels.<br /> Those who believe in the divine authenticity of the New Testament may not be swayed by this book and may in fact believe that the author is being unfair in demanding that the New Testament satisfy criteria for authenticity that other documents of the time are not subjected to. But the claims of the New Testament are very extraordinary. The virgin birth, the miracles of Jesus, the resurrection, are all events that take place completely out of history. To experience or witness any of these would be most interesting and perhaps traumatic. If the New Testament has been scrutinized more than other books of the time, then it is for this reason. If the New Testament is divinely inspired and true, then God, in the personage of Jesus, is clearly working &quot;into&quot; history (vertically), and not &quot;through&quot; it (horizontally). Thus, an apologist of theNew Testament must be able to show that it documents accurately these monumental singular events in history, and distinguish them from similar stories in other religions that came before Christianity (and there are many of these). Still, one could perhaps view the workings of God in history as &quot;horizontal&quot;, accept the author's arguments, and still remain a devout Christian. Such individuals would be very different than the &quot;standard&quot; Christians of today, but perhaps such a stance would be one that is most appropriate from the standpoint of intellectual honesty and from scientific evidence.the New Testament must be able to show that it documents accurately these monumental singular events in history, and distinguish them from similar stories in other religions that came before Christianity (and there are many of these). Still, one could perhaps view the workings of God in history as &quot;horizontal&quot;, accept the author's arguments, and still remain a devout Christian. Such individuals would be very different than the &quot;standard&quot; Christians of today, but perhaps such a stance would be one that is most appropriate from the standpoint of intellectual honesty and from scientific evidence.	2002-10-31
1356740:US	50702879	R2J6XHAWGRAXOB	0387076034	900915507	Algebraic Geometry I: Complex Projective Varieties	Books	5	5	5	N	N	Excellent	The author of this book is well known in algebraic geometry, and, as of late in the field of computer graphics. In this book, he summarizes beautifully various results in algebraic geometry that were known at the time of publication. Most importantly, the author believes that in order to properly understand algebraic geometry, one must delve into the works of `Italian' algebraic geometry, as well as the works of Zariski, Weil, and Grothendieck. The former assists in building intuition, while the latter gives a unified algebraic framework in which to work in and relates the subject to number theory. Every student of algebraic geometry has perhaps been overwhelmed by the sheer volume of results in the subject, and the increasing level of abstraction in the form of the theory of schemes, that is encountered when learning algebraic geometry. This book introduces the `classical' point of view, with the modern scheme-theoretic approach left to a future work, says the author. Since its publication, many new interesting approaches have been taken toward algebraic geometry, one being that use is being made of the computer and various symbolic programming languages in order to deal with the geometric objects from a computational point of view. Another has been the role of physics, particularly that of `mirror symmetry' and superstring and M-theory. In fact, one might expand the words of the author in the introduction to this book, and now say that a proper understanding of algebraic geometry should also involve an understanding of quantum field theory, integrable systems, and superstring and membrane theory.<br /> Some of the more interesting and well-motivated discussions in the book include:1. The author uses an `analytic' version of the implicit function theorem to show that the Zariski open set of smooth points on an affine variety has the structure of a complex manifold. The Zariski topology has been viewed as somewhat \\"mysterious\\" by some beginning students, so this characterization clears this up to some degree. 2. The need for the group of divisors and the resulting Picard group. This is done to make up for the fact that for a smooth variety X, the affine coordinate ring R(X) is not a unique factorization domain (UFD). The author describes this situation as being analogous to the one in algebraic number fields where the UFD property must be weakened to that of decomposing principal ideals into products of prime ideals. The Picard group is then the group of divisors modulo the principal divisors, and then R(X) is a UFD if and only if the Picard group is zero. 3. The discussion on Chow's theorem. The author motivates this famous result by asking to what extent the general theory of complex analytic spaces parallels the theory of algebraic varieties. The difficulty, he explains, is that in algebraic geometry one deals with rational functions, which do not have essential singularities like analytic functions do. The author discusses a case where no essential singularities occur, his example dealing with `analytic' and `*-analytic' subsets of complex n-space. Loosely speaking, analytic sets are essentially zero sets of analytic functions, whereas *-analytic sets can be represented as the union of complex submanifolds.  He shows that a set is *-analytic if and only if it is analytic, and from this result follows Chow's theorem, which states that the only complex analytic subsets of n-dimensional projective space are algebraic varieties. Chow's theorem is a generalization of the result in complex variable theory that says that the only meromorphic functions on the extended complex plane are rational functions. 4. A natural question to ask when studying algebraic varieties is whether they have a \\"size\\", i.e. a volume or area of some sort. For r-dimensional subvarieties of n-dimensional projective space, the author proves that one can define the 2r-dimensional volume of the variety, and this is accomplished via a Riemannian metric on n-dimensional projective space. This metric only depends on r and the degree of the variety, and is in fact the famous Kahler metric. The author goes on to characterize algebraic varieties as minimal submanifolds of n-dimensional projective space, using the tools of DeRham cohomology. The volume result is then generalized to that of compact oriented submanifolds of n-dimensional projective space, with the first result holding when the submanifold is an algebraic subvariety. 5. The treatment of the Hilbert polynomial. The author motivates this in the context of the calculation of the dimension of the vector space of functions with poles at most a given divisor. He proves an explicit formula for the Hilbert polynomial for r-dimensional subvarieties of n-dimensional projective space. He also shows how the constant term of the Hilbert polynomial is related to the `arithmetic genus' of a projective variety. The arithmetic genus is then shown to be equal to the topological genus for smooth curves, this being the famous Hirzebruch-Riemann-Roch theorem in dimension one. His proof of this result is very detailed and actually quite fun to work through and read, as it does not depend on the theory of harmonic forms. 6. For those who are interested in the theory of elliptic curves, the author gives an elementary overview of their properties.imensional projective space. This metric only depends on r and the degree of the variety, and is in fact the famous Kahler metric. The author goes on to characterize algebraic varieties as minimal submanifolds of n-dimensional projective space, using the tools of DeRham cohomology. The volume result is then generalized to that of compact oriented submanifolds of n-dimensional projective space, with the first result holding when the submanifold is an algebraic subvariety. 5. The treatment of the Hilbert polynomial. The author motivates this in the context of the calculation of the dimension of the vector space of functions with poles at most a given divisor. He proves an explicit formula for the Hilbert polynomial for r-dimensional subvarieties of n-dimensional projective space. He also shows how the constant term of the Hilbert polynomial is related to the `arithmetic genus' of a projective variety. The arithmetic genus is then shown to be equal to the topological genus for smooth curves, this being the famous Hirzebruch-Riemann-Roch theorem in dimension one. His proof of this result is very detailed and actually quite fun to work through and read, as it does not depend on the theory of harmonic forms. 6. For those who are interested in the theory of elliptic curves, the author gives an elementary overview of their properties.	2002-10-31
1360153:US	50702879	R28YL8EOFKKB2T	0253202353	405014515	Anthropology of Dance	Books	4	13	13	N	N	Very interesting reading	That dance is universal in human culture is both expected and appreciated. Life without dance is akin to eating without tasting the food. But dance can take many forms, and one can make conclusions about a culture after examining its dances, and also study its function in going against cultural norms. Dance in every culture can be a celebration, an expression of ideology, or a rebellion against the same. The author in this book has given the reader an introduction to the anthropology of dance, and a appreciation of the wide variability of cultural attitudes towards dance.<br /> The author calls dance the oldest of the arts and then addresses the natural question which arises when studying dance: how is it, as a pattern of movement in time and space, to be distinguished from other patterns of movement in time and space (a parade for example, or swimming, or playing tennis)? Also, can there be nonhuman dance? She gives as an example the movement of certain bird species. Any scientific/anthropological study of dance must of course find a working definition of dance that is mutually agreed upon, as the author states explicitly in this chapter. She eventually gives such a definition, namely that it is &quot;patterned movement performed as an end in itself&quot;, but is also careful to note that cultural biases must be taken into consideration when analyzing dance from an anthropological perspective. Indeed, a too narrow definition of dance may result in the conclusion that there are some societies or cultures that do not have any forms of dance, even though they engage in organized events where &quot;patterns of movement&quot; are regularly done. The author gives several interesting examples that illustrate the difference between a scholarly definition of dance and what constitutes dance from the standpoint of the participants in a given culture.<br /> The author's discussion on dance from the anthropological perspective is interesting, for she gives examples of how the influence of certain philosophical and psychological frameworks have influenced the study of dance. Some anthropologists for example only paid attention to dance since the neglecting of it would make their cultural studies incomplete. Others mentioned it only if it was relevant to the psychological state of the people within the studied culture. Thus some anthropologists viewed dance as being merely an extraneous activity for the society in question.<br /> The author though is perhaps too cautious in the appraisal of the methodological techniques used to study cultures. Stating correctly that research must begin with observation, she laments the (supposed) fact that the use of concepts distorts what one does observe: &quot;We draw parallels where perhaps there are none, and we categorize phenomena on the basis of perhaps misleading superficial characteristics&quot;. But scientific study is a certain well-defined activity, and studying cultures scientifically already assumes that a given set of rules and concepts is to be applied. The author should not feel guilty about the use of these methodologies. If one indeed is &quot;distorting the facts&quot;, this will be brought out by further more in-depth studies, which could go on for quite some time.<br /> An entire chapter of the book is devoted to methods and techniques, some of these being the dance notation that was developed by Rudolph Laban, Rauol Feuillet, and Joan and Rudolph Banesh. Mere syntactical systems are not enough though, as movement quality must be protrayed. The author is careful to note that the &quot;Effort-Shape&quot; strategy employed by Laban was in fact designed to do this. She comments on the use of film and video for capturing dance movement, and she clearly believes that the use of film and notation complement each other. But the author again here seems over-cautious when she mentions &quot;the difficulty of shedding one's own cultural biases long enough to record others who are operating onthe basis of different cultural biases&quot;. Field guides are also discussed as a method for studying dance.<br /> The author also describes five potential areas for performing what she calls &quot;structural analysis&quot; of dance. This is a methodology that combines the &quot;structural&quot; and &quot;functional&quot; points of view. The former emphasizes the grammar of dance styles, while the latter is concerned with the contribution that dance makes to the well-being of a culture. One could then concentrate on the study of how dances change in a particular culture, as a gauge as to how the culture itself is changing. Or, secondly, one could study the &quot;survival potential&quot; of dances. As an example of this, the author discusses the work of Adrienne Kaeppler, who used the concept of a 'allomorphokine', which is essentially a particular dance movement that can be substituted for another with no change of &quot;meaning&quot;. A dance with few allomorphokines will be rigid and less adaptable (to an eventual stage performance for example). A third area of investigation for structural analysis might be what the author calls 'native categories' for dance. This is a kind of linguistic analysis, and discovers and gives information on units or patterns that are significant to the &quot;native speakers&quot; of a particular dance movement. The fourth possible avenue of approach for structural analysis is what the author calls 'ethnochoreography', which involves the study of native conceptions of movement segmentation. Differences between cultures of a particular dance segment can then be studied, with these variations shedding light on the variations in the cultures themselves. The last approach she discusses for structural analysis is the examination of cultural norms regarding creativity. This in my opinion is probably the most important, for it is by creative ingenuity that a culture expands and grows. Dance is an excellent estimator and barometer of the creative vitality of a culture, and the first thing to examine when evaluating cultural health. If indeed individual creativity is stymied, that particular culture suffers. It remains to be shown whether dance is essential to a culture, but this book is a great help in answering that question. My prejudices and biases are that the answer to this question will be an overwhelming YES.on the basis of different cultural biases&quot;. Field guides are also discussed as a method for studying dance. <br /> The author also describes five potential areas for performing what she calls &quot;structural analysis&quot; of dance. This is a methodology that combines the &quot;structural&quot; and &quot;functional&quot; points of view. The former emphasizes the grammar of dance styles, while the latter is concerned with the contribution that dance makes to the well-being of a culture. One could then concentrate on the study of how dances change in a particular culture, as a gauge as to how the culture itself is changing. Or, secondly, one could study the &quot;survival potential&quot; of dances. As an example of this, the author discusses the work of Adrienne Kaeppler, who used the concept of a 'allomorphokine', which is essentially a particular dance movement that can be substituted for another with no change of &quot;meaning&quot;. A dance with few allomorphokines will be rigid and less adaptable (to an eventual stage performance for example). A third area of investigation for structural analysis might be what the author calls 'native categories' for dance. This is a kind of linguistic analysis, and discovers and gives information on units or patterns that are significant to the &quot;native speakers&quot; of a particular dance movement. The fourth possible avenue of approach for structural analysis is what the author calls 'ethnochoreography', which involves the study of native conceptions of movement segmentation. Differences between cultures of a particular dance segment can then be studied, with these variations shedding light on the variations in the cultures themselves. The last approach she discusses for structural analysis is the examination of cultural norms regarding creativity. This in my opinion is probably the most important, for it is by creative ingenuity that a culture expands and grows. Dance is an excellent estimator and barometer of thecreative vitality of a culture, and the first thing to examine when evaluating cultural health. If indeed individual creativity is stymied, that particular culture suffers. It remains to be shown whether dance is essential to a culture, but this book is a great help in answering that question. My prejudices and biases are that the answer to this question will be an overwhelming YES.	2002-10-28
1362025:US	50702879	R1GEMGGMSSACE4	0452011019	118162393	Objectivism: The Philosophy of Ayn Rand (Ayn Rand Library)	Books	4	43	50	N	N	Some interesting ideas here	The philosophy called Objectivism, which is expounded in this book, is both an interesting one and, if judged by comparison with what was developed in philosophy in the 20th century, very original. In addition, it is one of the last attempts to build a full-scale \\"system\\" of philosophy, integrating epistemology, ethics, aesthetics, ontology, and politics. This is to be contrasted with the \\"microscopic\\" approach to philosophical problem solving, which was, one can argue with some confidence, the dominant strategy in mainstream 20th century philosophy. This is not to say of course that this strategy is not an effective one. After all, specialization in any field has the advantage of being thorough, whereas comprehensive system building is both time-consuming and exhausting for the investigator. Objectivism was constructed outside the academy and its elaboration was not reported in the accepted academic journals. This being the case, its statements and positions on philosophical matters may take a considerable amount of time to be accepted by academic circles. Even if Objectivism does not gain respect in such circles, it still could serve as an alternative to the accepted ideas and concepts that are entrenched in the academic journals. The advent of the Internet and more accessible methods of publication will no doubt encourage more thinking outside the academy. It remains to be seen if this strategy results in philosophical theories that are both non-trivial and interesting.<br /> Space does not permit a detailed review of this book, but some of the more interesting ideas that are elaborated on include: 1. The \\"stolen concept fallacy\\". Although not really original, this notion is interesting from the standpoint of artificial intelligence and learning theory, as it asserts the existence of \\"levels of abstraction\\" and hierarchical organization of knowledge. The author describes the stolen concept fallacy as an error in how a concept is integrated into this hierarchy. Concepts higher in the hierarchy must be shown to be connected to lower level ones, this being called \\"conceptual reduction\\" by the author. The process of reduction must end at the level of the raw data of perception. This of course does not settle the issue of whether the perceptual data uniquely determines this conceptual and hierarchical structure. Such uniqueness seems not to be required by the Objectivist system, only that once a conceptual structure is chosen, consistency requires that the hierarchy must be fixed for all time. The idea of a stolen concept fallacy, if coded in the data structures of artificial intelligence, would formalize the notion of what it means for an intelligent machine to make a mistake. Of course, the search algorithms needed for the conceptual reduction and the consequent identification of the stolen concept may be computationally complex. At any rate, the notion of the stolen concept as elucidated briefly by the author deserves further investigation in this regard. 2. The notion of self-interest in ethics. The concept of self-interest has typically been a negative one in the history of ethical thought, meaning that it has been taken as almost axiomatic that individuals engaged in self-interest will always work to the detriment of another. What the author asks the reader to consider is that self-interest not only might not work against the well-being of another, but more than that: self-interest may in fact never work to the detriment of another. This is a fascinating move, and one that has not been done that I am aware of in the history of philosophy. A game theory interpretation and study of this assertion would be interesting both for ethical and political philosophy, as well as economics. The political philosophy of Objectivism is based on this notion of self-interest and its consequences. The author has moved the question of self-interest as to what effect a particular behavior will have on the individual involved, and not on the effect on another person. Traditional notions of self-interest hold to the essential tension between two individuals, and ask each individual to refrain from self-interested behavior in order to not violate another's rights. But in Objectivism, at least as I understand it, the reason that one does not engage in aggressive conduct towards another is that it acts to the detriment of oneself. One is always better off if one pursues a path that requires one to think through every situation, and not to initiate aggressive behavior, the latter only to be used in circumstances of self-defense (the latter could be difficult to define however in a given situation). This concept of self-interest in Objectivism is a refreshingly optimistic one and has tremendous consequences. And again, it would be very interesting to model this notion in a game-theoretic framework.<br /> New ideas usually meet considerable opposition when first proposed. Some of the ideas in this book are original, even radical, and some are mainstream. The negative reaction to some ideas or their standing in the mainstream does not of course determine their truth value. That is to be determined by painstaking analysis and research. And again, the ever-increasing use of alternative methods for publication of philosophical research will no doubt encourage a neutral stance to new ideas as they are proposed. Their consequent value will be determined by how resilient they are to criticism and how useful they are for philosophy. Even if one does not agree with every idea proposed by the author and the school of Objectivism, it is the best apology for doing philosophy that philosophy has ever had. And also, the optimism implicit in this philosophy is unequaled. It celebrates the efficacy and power of the human mind, and in that respect it is pure 21st century....effect on another person. Traditional notions of self-interest hold to the essential tension between two individuals, and ask each individual to refrain from self-interested behavior in order to not violate another's rights. But in Objectivism, at least as I understand it, the reason that one does not engage in aggressive conduct towards another is that it acts to the detriment of oneself. One is always better off if one pursues a path that requires one to think through every situation, and not to initiate aggressive behavior, the latter only to be used in circumstances of self-defense (the latter could be difficult to define however in a given situation). This concept of self-interest in Objectivism is a refreshingly optimistic one and has tremendous consequences. And again, it would be very interesting to model this notion in a game-theoretic framework. <br /> New ideas usually meet considerable opposition when first proposed. Some of the ideas in this book are original, even radical, and some are mainstream. The negative reaction to some ideas or their standing in the mainstream does not of course determine their truth value. That is to be determined by painstaking analysis and research. And again, the ever-increasing use of alternative methods for publication of philosophical research will no doubt encourage a neutral stance to new ideas as they are proposed. Their consequent value will be determined by how resilient they are to criticism and how useful they are for philosophy. Even if one does not agree with every idea proposed by the author and the school of Objectivism, it is the best apology for doing philosophy that philosophy has ever had. And also, the optimism implicit in this philosophy is unequaled. It celebrates the efficacy and power of the human mind, and in that respect it is pure 21st century....	2002-10-27
1362382:US	50702879	R26ODLS0ZP7KTP	0691079986	103222694	Lectures on Vector Bundles over Riemann Surfaces. (MN-6)	Books	4	0	0	N	N	A fine overview	Following up on the prior book &quot;Lectures on Riemann Surfaces&quot;, the author, in this book, makes heavy use of sheaf theory to study complex analytic vector bundles over Riemann surfaces. The use of sheaf theory will seem quite natural to the reader who has read the first book, and even those who have not but have a background in complex function theory will recognize sheaf theory as a generalization of the concept of analytic continuation. The power of sheaf theory is made very apparent in this book, and the reader can see clearly some notions from the 'classical' theory, such as the Riemann-Roch theorem, generalized to the case of vector bundles over Riemann surfaces.<br /> In the first chapter, the author first considers sheaves over a commutative ring R with an identity element and sheaves of modules over these kinds of rings. A 'free sheaf' of rank m is defined as being one isomorphic to the direct sum of m R-modules. A 'locally free sheaf' of R-modules or rank m over a topological space M is defined, naturally, as one that is free when restricted to the open sets of a covering of M. The author then discusses carefully the notion of how to get a cohomology 'set' via the sheaf of (non-Abelian) groups defined by the presheaf of the general linear group. This discussion leads to a fiber bundle that represents the locally free sheaf. This is then used to obtain 'analytic sheaves', which are sheaves of modules over the sheaf of rings of germs of holomorphic functions. The elements of the cohomology set are called 'complex analytic vector bundles of rank m' over the Riemann surface M. Coherent analytic sheaves are then brought in order to make up for the fact that analytic sheaves are generally not locally free.<br /> The local structure of coherent analytic sheaves is studied in chapter two, wherein it is proved first that every coherent analytic sheaf of a locally free sheaf is locally free. The author then show how to construct exact sequences of coherent analytic sheaves and shows explicitly how they are described in terms of locally free analytic sheaves for the case of the complex projective line. He then proves that every vector bundle over the projective line admits non-trivial meromorphic sections.<br /> Given a sheaf over one Riemann surface M, an analytic mapping from M to another Riemann surface induces a sheaf on the other, and the author studies these induced sheaves in chapter 3. The author then generalizes the projective line results from chapter 2 to the case of a coherent analytic sheaf over an arbitary compact Riemann surface.<br /> In chapter 4 the author proves the famous Riemann-Roch theorem for the case of vector bundles over compact Riemann surfaces of genus g. This leads straightforwardly, as the author shows, to a form of the Riemann-Roch theorem for coherent analytic sheaves. Then, after defining the notion of a dual bundle to a complex vector bundle, the author proves a version of Serre duality for vector bundles.<br /> After a lengthy discussion of how to extend a complex analytic line bundle to a complex analytic vector bundle of rank 2, the author in chapter 5 discusses how to determine which line bundles can be subbundles of a given vector bundle. This leads to an extension of the notion of a divisor, and the author then gives a classification of rank 2 vector bundles.<br /> For line bundles, the vanishing of its Chern class guarantees that it has a 'flat' representative. The situation for higher rank complex vector bundles is more complicated, due to the general linear group not being abelian. The author shows how to find conditions for the admission of flat representatives in these bundles in chapter 6. This is followed naturally by a discussion of flat vector bundles in chapter 7, wherein a notion of a 'flat sheaf' of rank n is formulated. Flat vector bundles are shown to have a 'characteristic representation', which is viewed as the fundamental group of the Riemann surface acting as operators on complex n-space. This is then used to obtain a &quot;sheafified&quot; deRham complex for a flat vector bundle. The notion of a 'period' of a differential form makes its first appearance here.<br /> Chapter 8 covers basically the same subject as chapter 7, but from an analytic viewpoint. The DeRham sequence in this viewpoint involves, as expected, the sheaf of germs of flat sections of the bundle and the sheaf of germs of holomorphic sections of the bundle. The author shows how the 'Prym differentials' arise as differential forms that generalize the Abelian differentials on a compact Riemann surface. He also discusses how the analytic properties of flat sheaves can be studied by considering an exact sequence involving instead the sheaf of germs of meromorphic functions on the Riemann surface. Sections of the flat vector bundle in this case give rise to the meromorphic Prym differentials, which intuitively can be thought of as meromorphic differential forms which have zero residues at each point of the Riemann surface.<br /> By considering for a Riemann surface the mapping which associates to a flat vector bundle its characteristic representation, the author studies families of flat vector bundles in chapter 9. He shows how to obtain a complex analytic structure associated to this family. Techniques from the theory of several complex variables are utilized without review to study the complex analytic equivalence of flat vector bundles, and he shows that every flat vector bundle is analytically equivalent to an 'irreducible' flat vector bundle. Here 'irreducible' is an algebraic geometry notion, and refers to the fact that the homomorphisms from the fundamental group of the Riemann surface to the complex general linear group has the structure of a complex analytic variety. The subset of irreducible representations then is a complex analytic manifold.as operators on complex n-space. This is then used to obtain a &quot;sheafified&quot; deRham complex for a flat vector bundle. The notion of a 'period' of a differential form makes its first appearance here. <br /> Chapter 8 covers basically the same subject as chapter 7, but from an analytic viewpoint. The DeRham sequence in this viewpoint involves, as expected, the sheaf of germs of flat sections of the bundle and the sheaf of germs of holomorphic sections of the bundle. The author shows how the 'Prym differentials' arise as differential forms that generalize the Abelian differentials on a compact Riemann surface. He also discusses how the analytic properties of flat sheaves can be studied by considering an exact sequence involving instead the sheaf of germs of meromorphic functions on the Riemann surface. Sections of the flat vector bundle in this case give rise to the meromorphic Prym differentials, which intuitively can be thought of as meromorphic differential forms which have zero residues at each point of the Riemann surface. <br /> By considering for a Riemann surface the mapping which associates to a flat vector bundle its characteristic representation, the author studies families of flat vector bundles in chapter 9. He shows how to obtain a complex analytic structure associated to this family. Techniques from the theory of several complex variables are utilized without review to study the complex analytic equivalence of flat vector bundles, and he shows that every flat vector bundle is analytically equivalent to an 'irreducible' flat vector bundle. Here 'irreducible' is an algebraic geometry notion, and refers to the fact that the homomorphisms from the fundamental group of the Riemann surface to the complex general linear group has the structure of a complex analytic variety. The subset of irreducible representations then is a complex analytic manifold.	2002-10-26
1362816:US	50702879	R24FSJ3NJVLR7Z	0471439584	953493860	The Philosophy of Quantum Mechanics: The Interpretations of Quantum Mechanics in Historical Perspective	Books	5	49	49	N	N	A first class job	Everyone who has studied quantum physics and is interested in its &quot;philosophical foundations&quot; has no doubt picked up this book, if not to study it in detail, certainly to at least briefly peruse its contents. It is the most widely cited of all books on the philosophy of quantum physics, and apart from discussing the issues most effectively, it also could be used as an introduction to graduate-level quantum physics and the mathematical structure of quantum mechanics.<br /> With the advent of theories of quantum computation and quantum information theory, the philosophy of quantum mechanics seems to have taken a back seat. The phenomenon of entanglement, considered one of the most exotic of topics in quantum mechanics, is now taken to be one of the cornerstones of quantum information theory and is also considered experimentally verified, despite considerable objections from some &quot;realist&quot; circles. It would seem that philosophical discussion would play a  major role in discussion of quantum information theory, but this has not occured at any substantial level. This may also be a sign of the movement toward viewing science as being in some sense &quot;fundamental&quot;, and not needing philosophical &quot;justification&quot;.<br /> But whatever one's view on these matters is, this book will give a detailed historical overview of the controversy surrounding quantum physics, from a philosophical perspective. It indeed sheds considerable light on the historical context in which quantum mechanics arose, and how its formalism evolved throughout the 20th century. The EPR controversy, the Bohr-Einstein debate, and the rise of many-worlds theories are all fascinating topics, and one can find ample discussion of these by the author. The author is also careful to include a substantial bibliography for serious scholars of quantum physics.	2002-10-26
1363155:US	50702879	R3SA49N51BHUM2	0945466242	347077241	Human Action Scholars Edition	Books	2	69	186	N	N	Purely descriptive...	This book is a non-quantitative, non-analytical, purely descriptive overview of economics as given by one of the main figures in the 'Austrian' school of economics. The author does not hesitate to denounce those who would seek to bring in mathematics and statistics in to the study of economics, and he makes it clear that introducing these tools is a meaningless endeavor. It is interesting to think about the author's statements in the context of the Nobel prizes in economics this year, as they were given to honor the use of psychological modeling and empirical studies in economics. What these individuals have shown is that one can indeed quantity the subjective factors behind economic behavior. The author of this book would be find their contributions completely vacuous, based on  his statements in this book.<br /> Indeed, the author holds that &quot;identical events result sometimes in different human responses, and different external events produce sometimes the same human response. We do not know why&quot;. This is a particularly odd statement, as the author is asserting implicitly that he has an ability or a tool for distinguishing one event from another, and for judging when they are the same. Is the author asserting the existence of a metric, a purely quantitative notion, for distinguishing between events? This would go against another statement he makes elsewhere, namely that &quot;no such constant  relations exist in the field of human action&quot;. And later, he states that &quot;in the field of economics, no constant relations, and consequently no measurement is possible.&quot; If what he is saying is true, then it would definitely be impossible to label one event as being identical to another, nor in a &quot;quantitative&quot; nor &quot;qualitative&quot; sense. Identical events would definitely stand in a constant relation to one another.<br /> The author attempts to categorize his approach to economics, which he labels as a &quot;praxeological system&quot;, as different from a &quot;logical system&quot;, the latter of which does not include notions of time and causality. But logical systems that contain these notions have been constructed and have been studied by a number of individuals, going by the name of deontic logic. And just because &quot;events are irreversible&quot;, as the author (only partially) correctly observes, does not mean that historical or economic events cannot be categorized and studied to the extent that future events can be predicted (albeit within a certain tolerance) using this information. In fact, it is sometimes astounding to the degree that one can do this, particulary in the the use of artificial intelligence for economic time series prediction. Irreversibility can be dealt with, given the patience and sound mathematical tools.<br /> The notions of probability that the author holds to in the book are also interesting (and somewhat troubling). One is called &quot;class probability&quot; and is the familiar frequentist notion. The other is called &quot;case probability&quot;, and is apparently the one that the author favors in the study of economics. I thought when reading the book that case probability would perhaps be a Bayesian notion, since he states that it deals with the incompleteness of our knowledge. But alas, the author states that &quot;it is not open to any kind of numerical evaluation&quot;. His notion of case probability could perhaps however be compared with the field of inductive logic programming in artificial intelligence, wherein one is given a certain amount of &quot;background knowledge&quot; and positive examples and attempts to find the reasons or &quot;hypotheses&quot; for obtaining this knowledge without generating any &quot;negative examples&quot;. All of this is done in a purely qualitative framework.<br /> Game theory has generated much research in economics, and there are  fine examples of just how fruitful this approach can be. The author however does not hold any place for game theory in economics, stating that &quot;there is not the slightest analogy between playing games and the conduct of business within a market society&quot;. This is an outstanding statement, given the many examples of just how game theory can in some instances exactly model the business arrangements among a certain group of individuals. Examples of this include QoS provisioning in telecommunication networks and wireless bandwidth allocation. The theory of noncooperative games has in this case been extremely helpful in bargaining and allocation strategies in the business environment. Noncooperation does not by result automatically in the &quot;social disintegration&quot; of the participants, as claimed by the author. With the proper mathematical tools they can instead reach a level mutually satisfactory to all.<br /> &quot;Human Action&quot; should be read as perhaps a warm-up to the study of economics. Anyone genuinely interested in the dynamics of a capitalist economy however will not find a sound and scientific study of such in this book.old any place for game theory in economics, stating that &quot;there is not the slightest analogy between playing games and the conduct of business within a market society&quot;. This is an outstanding statement, given the many examples of just how game theory can in some instances exactly model the business arrangements among a certain group of individuals. Examples of this include QoS provisioning in telecommunication networks and wireless bandwidth allocation. The theory of noncooperative games has in this case been extremely helpful in bargaining and allocation strategies in the business environment. Noncooperation does not by result automatically in the &quot;social disintegration&quot; of the participants, as claimed by the author. With the proper mathematical tools they can instead reach a level mutually satisfactory to all. <br /> &quot;Human Action&quot; should be read as perhaps a warm-up to the study of economics. Anyone genuinely interested in the dynamics of a capitalist economy however will not find a sound and scientific study of such in this book.	2002-10-26
1363180:US	50702879	R2K10KJLEMC33	0691020612	274084783	Friedrich Nietzsche and the Politics of the Soul: A Study of Heroic Individualism	Books	5	5	9	N	N	A book about a hero's philosophy	Could Friedrich Nietzsche actually have a hero? For those familiar with his works, the answer to this question would not be an easy one, for the reason that Nietzsche's writings are so honest as to be almost obscure. It is not common in literature or philosophy to find an author so willingly  an exhibitionist. It is as though Nietzsche were himself trying to figure out who he was in his writings, and he never hesitates to reveal his thoughts. But maybe exhibitionist is not the right term to describe Nietzsche, as such a characterization would imply that he needed another's look to justify himself. But it seems as though Nietzsche was not writing for another, but for himself, feeling perhaps that his self-analysis was best done on paper.<br /> The author addresses this book to the readers of Nietzsche's works who are \\"victims\\" and have swallowed the bait, and consequently \\"carried along by the flights of his thought\\". She makes sure immediately to caution the reader that the expression \\"heroic individualism\\" is not found in any of Nietzsche's writings. But the equation \\"individual = hero\\" holds throughout his works. The author does a fine job of extracting this mathematics of individuation from the the writings of Nietzsche. One finishing the book, one carries away a deeper appreciation of the playful seriousness of Nietzsche's philosophy and his admonition to do philosophy while always looking in the mirror, and seeing one's own reflection, not someone else's.<br /> Nietzsche was always celebrating, according to the author, the death of gods, and his project was to inspire a passion for greatness in a world without gods. But idols are to be smashed, and the grandeur of man is not to be found in a divine origin. It is making use of the dynamism of the flux, and the achieving of fame, and not its achievement, that is true heroism. The hero is a \\"dragon-slayer\\" who must achieve in life the highest value, and it (life) is never to be squandered. Caution though must be ever present, lest one use heroism not as a stimulus to self-development but as a means of avoiding it. \\"Sentimental dirge\\" and Wagnerian romanticism must be rejected.<br /> The great man does not seek the admiration of the many, as the author again characterizes Nietzschean heroism: \\"go silently through the world and out of the world\\". The temptation for recognition must be avoided; one must not succoumb to the illusion of fame. The golden calf is not to replace the true self as the object of worship. Glory is always self-administered.<br /> So how rare or common today is the hero of the Nietzschean type? Well, quite common...thousands...maybe hundreds of thousands. They are to be found in dance, in science, in literature, on the battlefield, behind the counter, sitting in the classroom and also standing in front of it, in the laboratory....indeed everywhere....the 21st century has no paucity of heroism.e ever present, lest one use heroism not as a stimulus to self-development but as a means of avoiding it. \\"Sentimental dirge\\" and Wagnerian romanticism must be rejected. <br /> The great man does not seek the admiration of the many, as the author again characterizes Nietzschean heroism: \\"go silently through the world and out of the world\\". The temptation for recognition must be avoided; one must not succoumb to the illusion of fame. The golden calf is not to replace the true self as the object of worship. Glory is always self-administered. <br /> So how rare or common today is the hero of the Nietzschean type? Well, quite common...thousands...maybe hundreds of thousands. They are to be found in dance, in science, in literature, on the battlefield, behind the counter, sitting in the classroom and also standing in front of it, in the laboratory....indeed everywhere....the 21st century has no paucity of heroism.	2002-10-26
1370891:US	50702879	RWCAT94KY6ZQ9	0844223972	778237521	Your First 100 Words in Chinese	Books	4	0	0	N	N	A good start	My seven year old son and I began learning Chinese together only three weeks ago, and we started with this book. It was a great help in that regard, and we got help with the pronunciation from on-line resources. The flash cards and the test at the end assisted both of us in trying to remember the Chinese words.  I would definitely recommend this book to those who are beginning to learn Chinese but have chosen to teach themselves.	2002-10-19
1373876:US	50702879	R1G3VOSIYQ9BNT	1578701163	379619906	IP Quality of Service	Books	4	8	12	N	N	A good start	For those who need a general overview of how QoS is implemented in Cisco devices and software, this book would serve as a pretty good introduction. Some of the discussion is generic enough to be useful to those who are interested in QoS, but not necessarily implemented in a Cisco environment. Naturally then the reader is assumed to have a good background in Cisco network architectures. The author implements case studies in the book, with it being assumed that the reader is also comfortable with the actual administration of Cisco network devices. Therefore the book is really useful for those readers who are involved in the practical implementation of QoS schemes. Those interested in developing new approaches to QoS may still find the book helpful as an introduction to what is known. There are more specialized treatments that can be found online if one is willing to spend the time finding and downloading the documents (from the Cisco website). I only read the first six chapters of the book, which deal with IP QoS, and so my review will be restricted to these.<br /> Remembering that the Internet is a best-effort service only, the author introduces the IP QoS functions in chapter 1. The advent of voice and video traffic over IP for example, requires the need for QoS in modern networks. QoS services are divided into levels: best-effort, which does not guarantee traffic delivery; differentiated service, which groups traffic into classes but does not guarantee its delivery; and guaranteed service, which allocates network resources to ensure specific service requirements. Bandwidth, packet latency, and packet loss are measures used to characterize connection performance.<br /> Chapter 2 gives a more detailed overview of the differentiated services architecture for delivering QoS on the Internet. Called `diffserv' by the IETF, the author discusses the historical origins of it, and how it provides traffic differentiation by breaking traffic up into a small number of classes, with relative service priority existing among these classes. The presentation is straightforward to follow, once one gets used to remembering all of the many acronyms that are employed, such as PHB (per-hop behavior), DSCP (Differentiated Services Code Point), etc. The traffic conditioners, which are QoS functions that set the DSCP field and monitor traffic for profile compliance, and discussed in detail. Network provisioning, signaled QoS, and QoS policy manager are all discussed as resource provisioning policies.<br /> In chapter 3, the author overviews the use of traffic conditioning functions at the network boundary as a tool for providing differentiated services. In one, called `packet classification', the packets are identified using one or more fields in a packet. This could be the MAC address, URL, IP Precedence, etc. Then `packet marking' is used to mark classified packets according to their traffic class. Traffic rate management, another conditioning function, is discussed via the token bucket scheme, along with the CAR traffic policing function. The strategy of borrowing of tokens for token buckets with extended burst capability is very interesting and is a good candidate for improvement using techniques and concepts from financial engineering and artificial intelligence. The token bucket scheme is also discussed in the context of traffic shaping.<br /> In the next chapter on resource allocation, the author discusses how weighted fair queuing can be employed as a scheduling discipline in which flow differentiation occurs. The author makes some interesting and somewhat controversial remarks in this chapter, one being that after stating that some flows are delayed to offer a particular bandwidth to other flows, he concludes to the effect that a preferential treatment will result in another suffering. This is not really true as one can show using techniques from game theory. In fact, the max-min fair-share allocation scheme that he discusses next is a step in this direction. This is true also for the weighted max-min fair share allocation, in which each user is assigned a weight, with the fair-share being proportional to this weight. Generalized processing sharing (GPS) is discussed as an ideal scheduling mechanism that services an infinitesimally small amount of data from each nonempty queue via round-robin. This unrealistic requirement is then ameliorated by using fair queuing, a strategy that takes all flows to have the same weight, and simulates GPS by computing a sequence number for each arriving packet. Flow-based weighted fair queuing is also discussed in detail in this chapter. For those readers worrying about QoS for interactive voice traffic, the author is careful to point out that WFQ maybe unable to achieve the low-jitter requirements. Therefore, he includes a discussion of WFQ with priority queue in this chapter. A short overview of flow-based distributed WFQ is also included. The latter does not make use of the CPU, unlike ordinary WFQ. The author then outlines the class-based WFQ, which can be implemented in both distributed and nondistributed modes. Priority queuing, which divides queues into subqueues of decreasing order of priority, is also treated. The author also gives an overview of custom queuing, which is a strategy for guaranteeing a minimum bandwidth for each traffic classification.<br /> Chapter 5 is an overview of the scheduling algorithms on routers that employ a switching architecture that is not bus-based. In this regard, the author gives a very detailed discussion of the use of Modified Weighted Round Robin and Modified Deficit Round Robin algorithms.<br /> The TCP congestion control mechanism and how it deals with packet drops is the topic of chapter 6. Those who are familiar with TCP/IP will find the reading very straightforward, but the author also introduces Weighted Random Early Detection (WRED) and Flow WRED, which permit different RED parameters based on packet precedence, and a scheme for penalizing flows that attempt to utilize more than their allocated queue lengths. The author also discusses Selective Packet Discard (SPD), which assists in the differentiation of `priority' traffic from `normal' traffic. An interesting case study in how to prevent `smurf attacks' by using SPD is included in this chapter.ep in this direction. This is true also for the weighted max-min fair share allocation, in which each user is assigned a weight, with the fair-share being proportional to this weight. Generalized processing sharing (GPS) is discussed as an ideal scheduling mechanism that services an infinitesimally small amount of data from each nonempty queue via round-robin. This unrealistic requirement is then ameliorated by using fair queuing, a strategy that takes all flows to have the same weight, and simulates GPS by computing a sequence number for each arriving packet. Flow-based weighted fair queuing is also discussed in detail in this chapter. For those readers worrying about QoS for interactive voice traffic, the author is careful to point out that WFQ maybe unable to achieve the low-jitter requirements. Therefore, he includes a discussion of WFQ with priority queue in this chapter. A short overview of flow-based distributed WFQ is also included. The latter does not make use of the CPU, unlike ordinary WFQ. The author then outlines the class-based WFQ, which can be implemented in both distributed and nondistributed modes. Priority queuing, which divides queues into subqueues of decreasing order of priority, is also treated. The author also gives an overview of custom queuing, which is a strategy for guaranteeing a minimum bandwidth for each traffic classification. <br /> Chapter 5 is an overview of the scheduling algorithms on routers that employ a switching architecture that is not bus-based. In this regard, the author gives a very detailed discussion of the use of Modified Weighted Round Robin and Modified Deficit Round Robin algorithms. <br /> The TCP congestion control mechanism and how it deals with packet drops is the topic of chapter 6. Those who are familiar with TCP/IP will find the reading very straightforward, but the author also introduces Weighted Random Early Detection (WRED) and Flow WRED, which permit different RED parameters based on packet precedence, and a scheme for penalizing flows that attempt to utilize more than their allocated queue lengths. The author also discusses Selective Packet Discard (SPD), which assists in the differentiation of `priority' traffic from `normal' traffic. An interesting case study in how to prevent `smurf attacks' by using SPD is included in this chapter.	2002-10-17
1374500:US	50702879	R1823GBY38712S	0691082766	457627436	Exact Sequences in the Algebraic Theory of Surgery. (MN-26): (Mathematical Notes)	Books	4	0	0	N	N	An in-depth overview of the author's work at the time	One of the principal aims of surgery theory is to classify the homotopy types of manifolds using tools from algebra and topology. The algebraic approach is emphasized in this book, and it gives the reader a good overview of the subject, as it was known at the time of publication.<br /> If one is given a closed topological manifold of dimension N, then for a given integer k, the N-k cohomology is isomorphic to the k-homology of the manifold. This isomorphism is called Poincare duality. A space X will be homotopy equivalent to an N-dimensional manifold if X is a N-dimensional Poincare duality space, i.e. the N-k cohomology of the space is isomorphic to the k homology of the space. The author defines the 'topological structure set' to be the set of equivalence classes of pairs (N-dimensional manifold M, homotopy equivalence h: M -&gt; X), where two pairs  (M, h) and (M, h') are equivalent if one can find a homeomorphism F from M to M' such that h'F is equivalent to h. Surgery theory then attempts to find out if a Poincare complex X is homotopy equivalent to a manifold, by computing the topological structure set in terms of the algebraic topology of X.<br /> One approach to deciding if a Poincare complex is homotopy equivalent to a manifold is due to the mathematicians Felix Browder, S.P. Novikov, C.T.C Wall, and Dennis Sullivan. This is now known as obstruction theory, and involves the use of two concepts: the primary topological K-theory obstruction, and a secondary algebraic L-theory obstruction. The latter is defined if the primary obstruction vanishes. These are reviewed in the book, and the author shows how, for dimensions greater than or equal to 5, that the non-emptiness of the topological structure set is necessary and sufficient for the primary surgery obstruction to be zero.<br /> The author also discusses the use of the algebraic L-groups, due to the mathematicians Kervaire and John Milnor, in the surgery classification of exotic spheres. Their work could essentially be thought of as the origin of surgery theory. The author elaborates on just what is involved in making their ideas applicable to a purely algebraic setting, which is now classified as 'algebraic L-theory'. The author does this in the context of rings that possess an involution operation (thus the theory is sometimes called hermitian K-theory), and defines an n-dimensional algebraic Poincare complex over these rings (in topology the ring is the group ring of the fundamental group). In zero dimensions, these complexes reduce to non-singular quadratic forms over the ring. He then generalizes Poincare-Lefschetz duality to obtain an n-dimensional algebraic Poincare pair over the ring, which is essentially a pair of chain complexes together with a self-dual chain equivalence. This gives a kind of abstract cobordism theory, in which one can speak of n-dimensional algebraic Poincare complexes as cobordant if their difference is the boundary of an (n+1)-dimensional algebraic Poincare pair.<br /> The author's primary aim in the book then is to generalize the topological setting to a purely algebraic one. In the topological setting, the symmetric and quadratic L-groups generalize the K-groups in the sense that these L-groups are related to the Witt groups in the same way that the K-groups are related to the projective class group. In algebraic L-theory then, the goal is to prove that the symmetric and quadratic forms are hyperbolic and determine how many ways this can be done. This is to be compared with the situation in algebraic K-theory, wherein one must determine how many ways a finitely generated projective module is free.essentially be thought of as the origin of surgery theory. The author elaborates on just what is involved in making their ideas applicable to a purely algebraic setting, which is now classified as 'algebraic L-theory'. The author does this in the context of rings that possess an involution operation (thus the theory is sometimes called hermitian K-theory), and defines an n-dimensional algebraic Poincare complex over these rings (in topology the ring is the group ring of the fundamental group). In zero dimensions, these complexes reduce to non-singular quadratic forms over the ring. He then generalizes Poincare-Lefschetz duality to obtain an n-dimensional algebraic Poincare pair over the ring, which is essentially a pair of chain complexes together with a self-dual chain equivalence. This gives a kind of abstract cobordism theory, in which one can speak of n-dimensional algebraic Poincare complexes as cobordant if their difference is the boundary of an (n+1)-dimensional algebraic Poincare pair. <br /> The author's primary aim in the book then is to generalize the topological setting to a purely algebraic one. In the topological setting, the symmetric and quadratic L-groups generalize the K-groups in the sense that these L-groups are related to the Witt groups in the same way that the K-groups are related to the projective class group. In algebraic L-theory then, the goal is to prove that the symmetric and quadratic forms are hyperbolic and determine how many ways this can be done. This is to be compared with the situation in algebraic K-theory, wherein one must determine how many ways a finitely generated projective module is free.	2002-10-16
1377926:US	50702879	R1MID70PHIHFOF	0122960505	975613327	Homotopy theory: an introduction to algebraic topology, Volume 64 (Pure and Applied Mathematics)	Books	4	8	8	N	N	A fine introduction	Homotopy theory is one of the hardcore topics in algebraic topology that usually takes a formidable amount of technical machinery in order to progress in its development. This is somewhat paradoxical considering that defining homotopy groups is very straightforward. The author has given the reader a fine introduction to homotopy theory in this book, and one that still could be read even now, in spite of the developments in homotopy theory that have taken place since the book was published (1975). The book emphasizes how homotopy theory fits in with the rest of algebraic topology, and so less emphasis is placed on the actual calculation of homotopy groups, although there is enough of the latter to satisfy the reader's curiosity in this regard. In the book the author states that \\"the deeper one gets into mathematics, the closer one sees the connections\\". This is readily apparent in his coverage, as he gives a good general view of how algebra and topology are intertwined in the study of homotopy theory.<br /> The calculation of the fundamental group in homotopy theory is done by first considering covering spaces. Noting that this approach is useless in proving that a space is simply connected, the author moves on to the van Kampen theorem, and he uses it to show that the n-dimensional sphere is simply-connected. The calculation of the nth homotopy group for n > 1 is done using locally trivial bundles, which are the simplest generalizations of covering spaces. These bundles have the homotopy lifting property, and one can use this to relate the homotopy on the fibers to that of the base of the bundle. The author also shows how to get homotopy information from projective space fiberings.<br /> That the n-th homotopy group can be given a group structure is done in the context of compactly generated Hausdorff spaces by first using the reduced suspension as the domain. The group structure is alternately defined using an H-space structure on the range. The duality between these points of view is then proved by the author.<br /> In the simplicial category, the author proves the Blakers-Massey Theorem. The homotopy groups of spheres in certain selections of dimensions are then calculated. The homotopy theory of spaces more general than simplicial complexes, the CW complexes, is treated in detail by the author. The notion of weak homotopy equivalence is introduced, and a proof of the Whitehead theorem, showing that weak homotopy equivalence between CW complexes is the same as homotopy equivalence, is proven.<br /> The author does a fine job of discussing K(pi,n)'s and Postnikov systems, which are introduced as tools to find a space that will realize a sequence of homotopy groups. Geometric intuition takes its leave here, the reader now being properly embedded in the true abstraction of algebraic topology. Obstruction theory makes its first appearance here.<br /> Spectra, one of the most esoteric of topics in homotopy theory, also makes its appearance in this book. Its relation to homology and cohomology is brought about via the suspension functor. The homology of CW complexes is discussed, along with the generalization to more general spaces, using singular homology, which is defined in terms of spectra. This approach is different than what is usually done in books on algebraic topology. Homotopy theory is related to ordinary homology in 0 and higher dimensions and the Whitehead theorem, giving a homotopy equivalence if the homology of simply connected CW complexes is an isomorphism, is proven.<br /> The multiplicative properties of cohomology is discussed in detail, and the author brings in the heavy guns from homological algebra. These tools are all used to analyze orientation and duality issues in paracompact topological manifolds. The author introduces duality as a generalization of that in Euclidean n-space, wherein one can find an (n-k)-dimensional subspace for each k-dimensional subspace.<br /> Cohomology operations, which are the modern tour-de-force of algebraic topology, are discussed first as coefficient transformations, and then as natural transformations between spectra. The cup and cap products, and their generalizations in the Steenrod squaring operations , are discussed in fair detail. Spectral sequences are not used in the book, and so they are only assumed in order to study the algebra of stable operations over the integers modulo 2. This is done with the assistance also of Adem relations, which are relations among the Steenrod squares.<br /> K-theories, which are introduced as examples of 'extraordinary' cohomology theories, are discussed briefly, in the context of vector bundles, but the Bott periodicity theorem is not proven. Instead, the author uses it to solve the Hopf invariant and vector field problems. The Gauss map is defined and then used to give the classification theorem for vector bundles. The Whitney sum of vector bundles, along with the Grothendieck construction, give the K-theory functor. Applications of K-theory to Lie groups are delegated to the exercises.<br /> The author also includes a brief discussion of cobordism, which is done with the assistance of some notions from differential topology, such as the normal bundle and the concept of a tubulur neighborhood. The cobordism ring is shown to be graded, and assuming the Whitney embedding theorem, the Thom isomorphism between the cobordism ring and the homotopy of MO, where MO(k) is the tangent bundle over the universal k-plane bundle over BO(k). The homotopy of MO is calculated by first calculating the cohomology of BO and MO over the integers modulo 2. The Stiefel-Whitney classes are introduced here, and used to show that real projective 2n-space  can be viewed as a ring generator of the cobordism ring. A most interesting discussion, as it shows to what extent the homology and cohomology derived from unoriented cobordism is different from ordinary homology and cohomology over the integers modulo 2. As is shown, every homology class over the integers modulo 2 is represented by a map from a manifold.the modern tour-de-force of algebraic topology, are discussed first as coefficient transformations, and then as natural transformations between spectra. The cup and cap products, and their generalizations in the Steenrod squaring operations , are discussed in fair detail. Spectral sequences are not used in the book, and so they are only assumed in order to study the algebra of stable operations over the integers modulo 2. This is done with the assistance also of Adem relations, which are relations among the Steenrod squares. <br /> K-theories, which are introduced as examples of 'extraordinary' cohomology theories, are discussed briefly, in the context of vector bundles, but the Bott periodicity theorem is not proven. Instead, the author uses it to solve the Hopf invariant and vector field problems. The Gauss map is defined and then used to give the classification theorem for vector bundles. The Whitney sum of vector bundles, along with the Grothendieck construction, give the K-theory functor. Applications of K-theory to Lie groups are delegated to the exercises. <br /> The author also includes a brief discussion of cobordism, which is done with the assistance of some notions from differential topology, such as the normal bundle and the concept of a tubulur neighborhood. The cobordism ring is shown to be graded, and assuming the Whitney embedding theorem, the Thom isomorphism between the cobordism ring and the homotopy of MO, where MO(k) is the tangent bundle over the universal k-plane bundle over BO(k). The homotopy of MO is calculated by first calculating the cohomology of BO and MO over the integers modulo 2. The Stiefel-Whitney classes are introduced here, and used to show that real projective 2n-space  can be viewed as a ring generator of the cobordism ring. A most interesting discussion, as it shows to what extent the homology and cohomology derived from unoriented cobordism is different from ordinary homology and cohomology over the integers modulo 2. As isshown, every homology class over the integers modulo 2 is represented by a map from a manifold.	2002-10-13
1384555:US	50702879	R5C6BWR6JB117	0253204429	55424283	Radical Hermeneutics: Repetition, Deconstruction, and the Hermeneutic Project (Studies in Phenomenology and Existential Philosophy)	Books	4	15	19	N	N	So what next, after this 'book' has 'ended'?	The philosophical systems of Western philosophy are a 'fast way out of the difficulties of life', the author argues. Metaphysics is a betrayal of this fact, as it seeks to 'put the best face on existence', and make things look easy. Hermeneutics, via the deconstructive project, on the contrary, seeks to 'recapture the hardness of life' and therefore not seek 'the fast way out of the back door of the flux'. The author wants to carry through Heidegger's project in Being and Time and 'restore the original difficulty of 'Being'. It is a hermeneutic project that begins with Heidegger as 'radical thinking' and follows the process of its radicalization, keeping faith to the 'philosophers of the flux': Nietzsche, Heidegger, Kierkegaard, Husserl, and Meister Eckhart.<br /> Regardless if one is in agreement with the author, his utterances have become fashionable as of late, and not just in hideaway cafes in Europe, but in professional circles of philosophy. However alien the ideas may seem in this book, it is an undeniable fact they grew out of Western philosophy. They are not a 'logical' consequence, but a consequence of the rebellion against rational 'system building', this rebellion beginning in the nineteenth century. The system builders of Western philosophy, such as Plato, Aquinas, Kant, and Hegel, sought a comprehensive view of existence, a view that holds to the idea that reality is understandable, and meaningful, and can be expressed via a rational framework.<br /> But ideas when entrenched encourage playful and sometimes radical antithesis. The mistake that the system builders made was that they assumed the systems they constructed were closed, comprehensive in their scope, and not needing further development. Settling into a local minimum, their ideas were jostled from without by those who caution against their sterility. Delighting in the use of philosophical wrecking balls, these new philosophers were all too willing to demolish the huge edifices built by the philosophers of old. Dancing with ecstacy after the damage was done, they then proposed a new viewpoint, one that attempts to accept the dynamism of Being, and not assume the existence of any epistemic or ontological fixed points.<br /> Thus the author wallows in this new (anti?)structure. To paraphrase a line from the book, his ideas (organize?) themselves into ferocious animals and then descend upon (philosophy), devouring everything in their path. The author holds up the Heidegger primordial 'Verstehen' as that which allows knowledge to work itself out in the process of existence. Reality for the author is a collection of torrential currents, extreme perturbations, and circumstances that shape the situation, and which consequently 'Verstehen' provides interpretive insight.<br /> Metaphysics, says the author, must be kept in check, so that it does not dominate the text, arrest the play, recenter the system, and stabilize the flux. This will break the code, and reintroduce the nostalgiac longing for the origin. Thus metaphysics must undergo a 'radical hermeneutics', somewhat along the lines of Jacques Derrida in holding to the 'uselessness of signs' and a rejection of 'a priori grammar'. We need our fictions, the author argues, for we cannot function 'without the wildness of play'. Imposing normality is a measure of stilling the flux. Authority must always be interrogated, and our fixation on repetition, those temporary stabilizations of the flow must not be mistaken for a grounding of normality in principle.<br /> Reason, for the author, is a central power, held by the military, industrial, and scientific authorities of administered society. What 'should' we do then? The author's answer is an 'ethics of dissemination', which arises precisely from the foundering of metaphysics. The morality of the author is be one of a 'community of mortals', which is held together by common fears and lack of metaphysical foundation. Huddling together in the face of the chilling hermeneutics, humility and compassion are the (natural?) consequences, according to the author. After all, 'we do not know who we are', he concludes.<br /> After reading this book, one might ask: so what next in the history of philosophy? Deconstruction has reacted with enthusiasm against metaphysics, but it has also now been codified and transformed itself into an ethic. Once dancing freestyle, it has now a precise set of choreographic principles, not to be deviated from. Once intoxicated with recklessness and shaking a stick, it has now become static doctrine, with all the 'rigidities' of the metaphysics it felt the need to rebel against.<br /> Philosophy has not ended, nor should it. But what form will it take next in this, the most dynamic of all centuries? The technological flux of the 21st century is so far unequaled. Perhaps we can take a hint from both metaphysics and the radical hermeneutics of the author: we can drench ourselves with the overwhelming torrential flood of change, knowing full well that, using our signs, our symbols, our logic, it is we ourselves that create these changes.ermeneutics, humility and compassion are the (natural?) consequences, according to the author. After all, 'we do not know who we are', he concludes. <br /> After reading this book, one might ask: so what next in the history of philosophy? Deconstruction has reacted with enthusiasm against metaphysics, but it has also now been codified and transformed itself into an ethic. Once dancing freestyle, it has now a precise set of choreographic principles, not to be deviated from. Once intoxicated with recklessness and shaking a stick, it has now become static doctrine, with all the 'rigidities' of the metaphysics it felt the need to rebel against. <br /> Philosophy has not ended, nor should it. But what form will it take next in this, the most dynamic of all centuries? The technological flux of the 21st century is so far unequaled. Perhaps we can take a hint from both metaphysics and the radical hermeneutics of the author: we can drench ourselves with the overwhelming torrential flood of change, knowing full well that, using our signs, our symbols, our logic, it is we ourselves that create these changes.	2002-10-07
1384641:US	50702879	R2GVYVMTMXGRCC	0201067102	117790086	Advanced Quantum Mechanics	Books	3	22	28	N	N	Out of date, but still could be useful	This book represents to a large degree an approach to quantum field theory that is now viewed as somewhat out of date. Modern textbooks and monographs in quantum field theory emphasize functional methods, the renormalization group, the operator product expansion, and topological field configurations. In addition, this book was published before the advent of the electroweak theory, and so readers will not get an introduction to this theory, nor to quantum chromodynamics, the gauge theory of the strong interactions. The only gauge theory actually treated in the book is quantum electrodynamics, although the author does not exploit the gauge invariance of this theory to its fullest potential in the book.<br /> For those readers who want learn quantum field theory, this book would probably not suffice, due to the above omissions. However, the book might still be used as a reference, and one that, as stated by the author, emphasizes the physics of quantum field theory. Covariant perturbation theory and Feynmam diagrams are given ample treatment. In addition, the author does not hesitate to employ symmetry considerations in the discussion of the transformation properties of the Dirac wave function and the quantized Dirac field. The spin-statistics theorem is not proven, but some plausible arguments as to its validity are given, dealing with the difficulty in constructing a quantum field theory for the electron that does not obey the Pauli exclusion principle. And, as another example of the avoidance of complicated mathematics, the author chooses to discuss the Moller interaction between two electrons using the (noncovariant) Coulomb gauge. In this strategy, the transverse part of the vector potential is treated dynamically, and the electron interaction consists of the interaction of the transverse electromagnetic field with the Dirac current and the instantaneous Coulomb interaction between charge densities. Only the transverse part of the vector potential is quantized, but interestingly, the nonphysical, longitudinal parts cancell out in the calculation of the amplitude. This approach may be distasteful from a modern gauge-invariant point of view, but it does suffice to bring out the physics of the problem, and it does serve to motivate the modern approach to the calculation of the Moller cross-section.<br /> Thus, this might still serve to build insight into the physics of quantum field theory. Too often modern texts emphasize the mathematical formalism, the latter becoming more and more formidable as the years go on. The chapter on covariant perturbation theory is definitely worth some amount of time because of this. The reader can then move on to the magnificent fortresses built by the theoreticians of quantum field theory since this book was published. Quantum field theory is definitely still a very active subject, and there are lots of things in the theory that remain unsolved to this day.ut interestingly, the nonphysical, longitudinal parts cancell out in the calculation of the amplitude. This approach may be distasteful from a modern gauge-invariant point of view, but it does suffice to bring out the physics of the problem, and it does serve to motivate the modern approach to the calculation of the Moller cross-section. <br /> Thus, this might still serve to build insight into the physics of quantum field theory. Too often modern texts emphasize the mathematical formalism, the latter becoming more and more formidable as the years go on. The chapter on covariant perturbation theory is definitely worth some amount of time because of this. The reader can then move on to the magnificent fortresses built by the theoreticians of quantum field theory since this book was published. Quantum field theory is definitely still a very active subject, and there are lots of things in the theory that remain unsolved to this day.	2002-10-07
1387497:US	50702879	R2G0ASQUUN539J	0691082065	579737005	Infinite Loop Spaces (AM-90), Volume 90: Hermann Weyl Lectures, The Institute for Advanced Study. (AM-90) (Annals of Mathematics Studies)	Books	5	3	4	N	N	Rigorous, but very understandable	Although published in 1978, this book could be used as an introduction to the theory of operads and other recent work on homotopy theory and vertex operators. Vertex operators are not discussed in this book, but the theory elucidated herein is good background material for their study.<br /> The author does a great job in motivating the subject in chapter 1. Loop spaces are function spaces of maps from the unit interval to a space with a chosen basepoint, with the property that each map sends 0 and 1 to the base point. The mathematician Jean Pierre Serre introduced the path space in order to study loop spaces, resulting in the famous Serre fibering. The nth homotopy group of the loop space can be shown to be equivalent to the (n+1)-th homotopy group of the original space. The homology of loop spaces can be calculated for some types of spaces, such as wedges of spheres. Infinite loop spaces are essentially sequences of spaces such that the nth element of this sequence is equivalent to the loop space of the (n+1)-th element. This sequence is also known as an &quot;Omega-spectrum&quot; and has the infinite loop space as its zeroth term. The name &quot;spectrum&quot; comes from general considerations involving sequences of spaces where the nth term is equivalent to the loop space of the (n+1)-th term; equivalently, where the suspension of the nth term is equal to the (n+1)-th term. The author reviews how a generalized cohomology theory yields an Omega-spectrum, giving two examples involving Eilenberg-Maclane spaces and complex and real K-theory. One can also start with a spectrum and construct a generalized homology and cohomology theory. Spectra and cohomology theory are thus essentially equivalent.<br /> Chapter 2 is an overview of techniques needed to construct a category of spaces with enough structure so that the infinite loop space functor yields an equivalence from the category of spectra to the category of certain spaces. An example of the latter is given by the Stasheff A-infinity space, and its now ubiquitous property of having a product which is strictly associative. This property allows one to prove that a space is equivalent to a loop space if and only if the space is a Stasheff A-infinity space and that the zeroth homotopy of the space is a group. The Stasheff A-infinity spaces are also used to motivate the construction of 'operads'.<br /> The next chapter the author is concerned with the concept of a space being like another one without being equivalent to it. He discusses the use of 'localization' in homotopy theory, an idea that is analogous to the one in algebra. The use of localization in homotopy theory is due to D. Sullivan, and involves use of the notion of a space being 'A-local', where A is a subring of the rationals. Remembering that a Z-module is A-local if it has the structure of an A-module, a space is A-local if its homotopy groups are A-local. Examples of the use of localization in constructing certain spaces are given. The author also discusses the use of the 'plus construction' that allows the alteration of fundamental groups without affecting the cohomology groups. Then after the construction of the Quillen higher algebraic K-theory groups in this regard, the author describes the relation between a topological monoid and the loop space of the classifying space of this monoid. This involves the notion of 'group completion', which is essentially an isomorphism between the homology of the path components of the monoid and the homology of the loop space of the classifying space of the monoid, but in the (infinite) direct limit.<br /> Chapter 4 introduces the concept of a transfer map. A very elusive idea at first glance, the transfer map is motivated via the n-sheeted covering map of a space on another. The (singular) simplices of each then get matched up by the covering, and the transfer map between the spaces is then defined so that it is equal to the sum of the singular simplices of the covering space. It is in fact a chain map as shown by the author. The transfer maps are related to homotopy classes of the 'structure' maps of chapter 2, and the author gives a few examples of how they are used.<br /> Chapter 5 is a quick overview of the Adams conjecture, which is essentially an assertion that the image of KO(X) in KF(X) can be characterized explicitly. Detailed proofs are omitted but references are given for the interested reader.<br /> In chapter 6, the author restricts his attention to the K-theory of spectra. The treatment is concerned in large degree with the question of the existence of infinite loop map between infinite loop structures, and finding such a map, checking whether it is unique. This question is answered for particular types of spectra, via the Madsen, Snaith, and Tornehave theorem. Also, the Adams-Priddy theorem is proved, showing that one can construct on a space a unique infinite loop space structure. The reader gets more examples of the use of localization, in that some spaces can become equivalent as infinite loop spaces upon localization. The origin of K-theory in this chapter comes from the replacing of spectra that are not known by ones that are (namely the ones in classical K-theory). The author shows how the Madsen-Snaith-Tornehave theorem works in the context of both complex and real (periodic) K-theory. Detailed proofs are given for all of these results.pace. It is in fact a chain map as shown by the author. The transfer maps are related to homotopy classes of the 'structure' maps of chapter 2, and the author gives a few examples of how they are used. <br /> Chapter 5 is a quick overview of the Adams conjecture, which is essentially an assertion that the image of KO(X) in KF(X) can be characterized explicitly. Detailed proofs are omitted but references are given for the interested reader. <br /> In chapter 6, the author restricts his attention to the K-theory of spectra. The treatment is concerned in large degree with the question of the existence of infinite loop map between infinite loop structures, and finding such a map, checking whether it is unique. This question is answered for particular types of spectra, via the Madsen, Snaith, and Tornehave theorem. Also, the Adams-Priddy theorem is proved, showing that one can construct on a space a unique infinite loop space structure. The reader gets more examples of the use of localization, in that some spaces can become equivalent as infinite loop spaces upon localization. The origin of K-theory in this chapter comes from the replacing of spectra that are not known by ones that are (namely the ones in classical K-theory). The author shows how the Madsen-Snaith-Tornehave theorem works in the context of both complex and real (periodic) K-theory. Detailed proofs are given for all of these results.	2002-10-05
1390768:US	50702879	R3917Q2L8NMC8N	0451147952	325358008	Capitalism: The Unknown Ideal	Books	2	16	32	N	N	Not the ideal book for the study of capitalist economics	It is sometimes difficult in public to be objective about the ideas of Rand, for the reason that the hatred of her detractors and the devotion of her followers borders on the hysterical. It is best to contemplate her philosophy in private, and then communicate to those who perhaps are still open enough to consider sometimes very radical ideas. Rand's thinking on ethics is brilliant, and the best in the history of philosophy, but this book, summarizing her thoughts on the political ramifications of her ethics, is very flawed, and there are some very outlandish claims that are made if one views them from a scientific perspective.<br /> Economics is a difficult subject, and some might say not a science. But the financial interactions of humans can be studied scientifically, given the patience and the mathematical tools. Rand, and the other contributors of this book, do not do this anywhere in the articles. They are at best a loose, qualitative description of capitalist economics, and as such are not useful to those who really want to understand the dynamics of the capitalist economy. Rand calls capitalism \\"an unknown ideal\\" and laments the state of society (at that time), in that its not fairly represented in education or the popular media. The evidence she gives however is purely anecdotal, and she makes no attempt to cite empirical or historical studies. It is one thing to argue for the ethical foundations of capitalism, which she does so with incredible originality and skill. It is quite another to describe the inner workings of the economy and to prove causal connections between historical economic events.<br /> For example, Rand states in the first article 'What is Capitalism\\"  that depressions and mass unemployment are not caused by the free market but by government interference into the economy. What evidence of this is there? Rand does not cite any empirical or historical data for this assertion, and even lacking such data, does not attempt even to construct a quantitative model that would lend some plausibility to her argument. In economic studies, mathematical modeling sometimes serves to shed light on a particular phenomenon when empirical data is lacking. Such a model can then be altered as the data is collected. Attempting to find the causes of depressions is a nontrivial affair, and something that economists and mathematicians have wrestled with for decades (if not centuries). Rand is very cavalier in her assertion here, and again, makes no attempt to prove it using a calm, rational, and scientific framework.<br /> In another article, written by her former collaborator, Nathaniel Brandon, and entitled 'Common Fallacies about Capitalism\\", he argues that free markets make monopolies impossible. His arguments utilize a sort of 'principal of arbitrage' (my words here), in that he argues that a monopoly that attempts to set prices will result in a competitor entering the field to take advantage of the high profits, thus closing the artificially high prices set by the monopoly. This is certainly plausible, but the time scales involved for the competitor may be too long to take advantage of the profitability. Getting into a highly technological business, such as chip manufacturing or drug discovery, may be too difficult and time-consuming for a competitor. And, Brandon still needs to justify his assertions with either an economic model or with an empirical study. He does not cite any historical evidence to support his claim.<br /> Capitalism as discussed in this book may not currently exist by the standards and definitions held by the authors of this book, and indeed one might believe that it has received an unfair and distorted hearing in academia and other circles. But human ingenuity has exploded in the last two decades, and shows no sign of abatement, despite the actions of the government and the existing tax structure. Perhaps maybe it is time to stop fixating on government inefficiencies and ineptitudes and continueto innovate. A society smart enough to invent and use genetic engineering, to create thinking machines, and to travel in space, will perhaps find dealing with the government mundane and rather trivial in the whole scheme of things, and perhaps not want to waste intellectual energy on tirades against government bureaucracies.<br />  One can only speculate what Rand would think of the dizzying pace of technological development in the 21st century, but I think it would be fair to say, judging by the utterances of the characters of her novels, she would forget her moral outrage, and would find life in the 21st century exhilirating...nue to innovate. A society smart enough to invent and use genetic engineering, to create thinking machines, and to travel in space, will perhaps find dealing with the government mundane and rather trivial in the whole scheme of things, and perhaps not want to waste intellectual energy on tirades against government bureaucracies.<br />  One can only speculate what Rand would think of the dizzying pace of technological development in the 21st century, but I think it would be fair to say, judging by the utterances of the characters of her novels, she would forget her moral outrage, and would find life in the 21st century exhilirating...	2002-10-02
1393344:US	50702879	R1S20J7WRRLIMO	0821803239	415112695	Metrics, Connections and Gluing Theorems (Cbms Regional Conference Series in Mathematics)	Books	3	0	3	N	N	Out of date, but still could be useful	The results in this book have been superseded by the results of Nathan Seiberg and Edward Witten that appeared a short time after this book was published. The Seiberg-Witten theory caused great excitement among the mathematical community who do research in differential geometry and differential topology, particularly in the area of the differential toplogy of 4-dimensional manifolds. Proclaiming the &quot;end of the Donaldson theory&quot;, mathematicians moved on to study the properties of the Seiberg-Witten equation, which is still nonlinear enough to be interesting.<br /> Thus the discussions in this book are somewhat dated, but still could be of interest from a mathematical history standpoint or with the goal perhaps of motivating the Seiberg-Witten theory, although the self-dual Yang-Mills equations, a cornerstone of the Donaldson theory, are not discussed in the book. Instead the author studies the anti-self dual equations. These arise uniquely in four dimensions due to the fact that  the Lie algebra so(4) of the special orthogonal group SO(4) is not simple, but instead decomposes as the direct sum of two copies of the Lie algebra so(3) of SO(3). This enables one to decompose the tangent bundle of the manifold into a direct sum of two oriented 3-plane bundles. The curvature of the Levi-Civita connection then splits with respect to this decomposition, the decomposition having entries involving the scalar curvature, the traceless Ricci tensor, and the self-dual and anti-self dual Weyl curvature tensors. The question of the existence of metrics on the manifold for which the anti-self dual part vanishes is the subject of the book, with particular attention paid to complex vector bundles over the manifold. The anti-self dual equations are consequently a set of algebraic equations for the curvature, which are equivalent, over an open set in the manifold, to a first-order differential equation involving a 1-form over this open set and taking values in the Lie algebra of complex 2-space.  The main strategy the author employs for studying these equations is to show  that they linearize to Fredholm equations. Thus a kind of generalization of the Fredholm property holds here in the context of (infinite-dimensional) vector bundles. A section of an infinite-dimensional vector bundle which linearizes to a Fredholm operator acts essentially like a section of a finite dimensional bundle over a finite dimensional manifold.<br />The book could also be used to motivate a study of the connection between the Donaldson and Seiberg-Witten invariants of smooth four-manifolds. That there is such a connection was recently conjectured and some promising work in proving this conjecture has appeared lately. There has also been recent interest in examining the anti-self dual equations on noncommutative four-dimensional Euclidean space, because of its connection with string theory.of complex 2-space.  The main strategy the author employs for studying these equations is to show  that they linearize to Fredholm equations. Thus a kind of generalization of the Fredholm property holds here in the context of (infinite-dimensional) vector bundles. A section of an infinite-dimensional vector bundle which linearizes to a Fredholm operator acts essentially like a section of a finite dimensional bundle over a finite dimensional manifold.      <br />The book could also be used to motivate a study of the connection between the Donaldson and Seiberg-Witten invariants of smooth four-manifolds. That there is such a connection was recently conjectured and some promising work in proving this conjecture has appeared lately. There has also been recent interest in examining the anti-self dual equations on noncommutative four-dimensional Euclidean space, because of its connection with string theory.	2002-09-30
1393929:US	50702879	RMUOCQI8R7AR0	0691095272	605465026	The Essential John Nash	Books	5	76	88	N	Y	An excellent compilation	Having written about the life of the mathematician John Nash in the excellent biography \\"A Beautiful Mind\\", Sylvia Nasar teams up with the mathematician Harold W. Kuhn to produce a book that introduces the mathematical contributions of Nash, something that was done only from a \\"popular\\" point of view in Nasar's biography. For those who have the background, this book is a fine overview of just what won Nash acclaim in the mathematical community, and won him a Nobel Prize in economics.<br /> It is always easy to dismiss ideas as trivial after they have been discovered and have been put into print. This is apparently what John von Neumann did after discussing with Nash his ideas on noncooperative games, dismissing his ideas as a mere \\"fixed point theorem\\". At the time of course, the only game-theoretic ideas that had any influence were those of von Neumann and his collaborator, the Princeton economist Oskar Morgenstern. The rejection of ideas by those whose who hold different ones is not uncommon in science and mathematics, and, from von Neumann's point of view at the time, he did not have the advantage that we do of examining the impact that Nash's ideas would have on economics and many other fields of endeavor. Therefore, von Neumann was somewhat justified, although not by a large measure, in dismissing what Nash was proposing. Nash's thesis was relatively short compared to the size on the average of Phd theses, but it has been applied to many areas, a lot of these listed in this book, and others that are not, such as QoS provisioning in telecommunication and packet networks. The thesis is very readable, and employs a few ideas from algebraic topology, such as the Brouwer fixed point theorem.<br /> The paper on real algebraic manifolds though is more formidable, and will require a solid background in differential geometry and algebraic geometry. However, from a modern point of view the paper is very readable, and is far from the sheaf and scheme-theoretic points of view that now dominate algebraic geometry. It is interesting that Nash was able to prove what he did with the concepts he used. The result could be characterized loosely as a representation theory employing algebraic analytic functions. These functions are defined on a closed analytic manifold and serve as well-behaved imbedding functions for the manifold, which is itself analytic and closed. These manifolds have been called 'Nash manifolds' in the literature, and have been studied extensively by a number of mathematicians.<br /> I first heard about John Nash by taking a course in algebraic topology and characteristic classes in graduate school. The instructor was discussing the imbedding problem for Riemannian manifolds, and mentioned that Nash was responsible for one of the major results in this area. His contribution is included in this book, and is the longest chapter therein. Here again, the language and flow of Nash's proof is very understandable. This is another example of the difference in the way mathematicians wrote back then versus the way they do now. Nash and other mathematicians of his time were more 'wordy' in their presentations, and this makes the reading of their works much more palatable. This is to be contrasted with the concisness and economy of thought expressed in modern papers on mathematics. These papers frequently employ a considerable amount of technical machinery, and thus the underlying conceptual foundations are masked. Nash explains what he is going to do before he does it, and this serves to motivate the constructions that he employs. His presentation is so good that one can read it and not have to ask anyone for assistance in the understanding of it. This is the way all mathematical papers should be written, so as to alleviate any dependence on an 'oral tradition' in mathematical developments.<br />  Nash's proof illuminates nicely just what happens to the derivatives of a function when the smoothing operation is applied. The smoothing operator consists of essentially of extending a function to Euclidean n-space, applying a convolution operator to the extended function, and then restricting the result to the given manifold. Nash gives an intuitive picture of this smoothing operator as a frequency filter, passing without attenuation all frequencies below a certain parameter, omitting all frequencies above twice this parameter, and acting as a variable attenuator between these two, resulting in infinitely smooth function of frequency.<br /> The next stage of the proof of the imbedding theorem is more tedious, and consists of using the smoothing operator and what Nash calls 'feed-back' to construct a 'perturbation device' in order to study the rate of change of the metric induced by the imbedding. Nash's description of the perturbation process is excellent, again for its clarity in motivating what he is going to do. The feed-back mechanism allows him to get a handle of the error term in the infinitesimal perturbation, isolating the smoother parts first, and handling the more difficult parts later. Nash reduces the perturbation process to a collection of integral equations, and then proves the existence of solutions to these equations. A covariant symmetric tensor results from these endeavors, which is CK-smooth for k greater than or equal to 3, and which represents the change in the metric induced by the imbedding of the manifold. The imbedding problem is then solved for compact manifolds by proving that only infinitesimal changes in the metric are needed. The non-compact case is treated by reducing it to the compact case. The price paid for this strategy is a weakening of the bound on the required dimension of the Eucliden imbedding space.<br /> The last chapter concerns Nash's contribution to nonlinear partial differential equations. I did not read this chapter, so I will omit its review.thing operator consists of essentially of extending a function to Euclidean n-space, applying a convolution operator to the extended function, and then restricting the result to the given manifold. Nash gives an intuitive picture of this smoothing operator as a frequency filter, passing without attenuation all frequencies below a certain parameter, omitting all frequencies above twice this parameter, and acting as a variable attenuator between these two, resulting in infinitely smooth function of frequency. <br /> The next stage of the proof of the imbedding theorem is more tedious, and consists of using the smoothing operator and what Nash calls 'feed-back' to construct a 'perturbation device' in order to study the rate of change of the metric induced by the imbedding. Nash's description of the perturbation process is excellent, again for its clarity in motivating what he is going to do. The feed-back mechanism allows him to get a handle of the error term in the infinitesimal perturbation, isolating the smoother parts first, and handling the more difficult parts later. Nash reduces the perturbation process to a collection of integral equations, and then proves the existence of solutions to these equations. A covariant symmetric tensor results from these endeavors, which is CK-smooth for k greater than or equal to 3, and which represents the change in the metric induced by the imbedding of the manifold. The imbedding problem is then solved for compact manifolds by proving that only infinitesimal changes in the metric are needed. The non-compact case is treated by reducing it to the compact case. The price paid for this strategy is a weakening of the bound on the required dimension of the Eucliden imbedding space. <br /> The last chapter concerns Nash's contribution to nonlinear partial differential equations. I did not read this chapter, so I will omit its review.	2002-09-29
1398328:US	50702879	R3MUEGXO5W0V51	091514459X	663050811	Possible Worlds: An Introduction to Logic and Its Philosophy (English and German Edition)	Books	5	14	14	N	N	An excellent introduction to logic (in all possible worlds)	It is too bad this book is out of print, for the authors do a fine job of introducing the student of philosophy or mathematics to the essentials of modern logic. Their approach, as the title implies, is via the framework of possible worlds, a framework first proposed by the philosopher J. Hintikka. Their approach is unique at this level of textbook. &quot;Possible worlds semantics&quot;, as it is now called, is a highly sophisticated and subtle branch of mathematical logic, but the authors give a very elementary introduction in this book, employing symbols very sparingly, and then only in the last two chapters. The goal, as stated by the authors, is to reach the reader who has difficulty with symbols. The book succeeds well in giving the reader an appreciation of logical reasoning and prepares well the reader for more advanced topics in symbolic and mathematical logic. Modal logic is also treated, and again, this is unique at this level. Useful exercises accompany the end of each section of the book.<br /> One of the main virtues of the book is it distinguishes between conceivability (what we can imagine), and what is possible. The ability to conceive a state of affairs does not imply the possibility of that state of affairs, they argue (correctly). Conceivability is neither a necessary nor sufficient condition for possibility. Psychologism is to be avoided at all costs, along with collapsing into circularity, and the authors accomplish this by the use of examples, i.e. examples of possible worlds and examples of impossible worlds. These examples are generated using ostension, naming, description, etc.<br /> Most interesting is the author's discussion on the properties of propositions. Propositions are classified as being possibly true or false, contingent, noncontingent, and necessarily true and false. Such distinctions are necessary given the framework in which the authors work, and its subsequent definition of truth and falsity. Objects and things, for the authors, are to be distinguished from properties and relations, and both of these concepts may be instanced in possible worlds other than the actual one. It is &quot;true&quot; that an object has an attribute if and only if the object has the attribute. It is &quot;false&quot; that the object has an attribute if and only if it is not the case that the object has the attribute. These considerations may at first seem trivial at first glance, but they are, again, a direct consequence of the &quot;possible worlds&quot;, non-nominalist framework that the authors have chosen to work in. All of the discussions in the book are a fine example of the price that must always be paid in the selection of a particular framework in which to analyze or think philosophically.<br /> There are many other interesting discussions in the book, such as the the one of the product/process ambiguity and the paradox of analysis. Particularly interesting is the discussion on the counterexamples of the philosopher Edmund Gettier to the idea that a justified belief in a true proposition constitutes knowledge. The authors illuminate his arguments in their possible worlds context. The authors exhibit a clever example of a possible world in which a person justifiably believes a proposition which is true and yet does not know it.<br /> Without a doubt the authors do hold that knowledge of the truth of some propositions really is possible. This leads them to address the question as to the limits of knowledge, and they conclude that there is a limit, a boundary between the class of humanly knowable true propositions and the class of (true) propostions which are not known to be true neither in the actual world or in any other possible worlds. Their justification for this leads to a consideration of &quot;experiential&quot; vs. &quot;ratiocinative&quot; knowledge and a fascinating discussion of the contributions of Immanuel Kant in this regard.ors, are to be distinguished from properties and relations, and both of these concepts may be instanced in possible worlds other than the actual one. It is &quot;true&quot; that an object has an attribute if and only if the object has the attribute. It is &quot;false&quot; that the object has an attribute if and only if it is not the case that the object has the attribute. These considerations may at first seem trivial at first glance, but they are, again, a direct consequence of the &quot;possible worlds&quot;, non-nominalist framework that the authors have chosen to work in. All of the discussions in the book are a fine example of the price that must always be paid in the selection of a particular framework in which to analyze or think philosophically. <br /> There are many other interesting discussions in the book, such as the the one of the product/process ambiguity and the paradox of analysis. Particularly interesting is the discussion on the counterexamples of the philosopher Edmund Gettier to the idea that a justified belief in a true proposition constitutes knowledge. The authors illuminate his arguments in their possible worlds context. The authors exhibit a clever example of a possible world in which a person justifiably believes a proposition which is true and yet does not know it. <br /> Without a doubt the authors do hold that knowledge of the truth of some propositions really is possible. This leads them to address the question as to the limits of knowledge, and they conclude that there is a limit, a boundary between the class of humanly knowable true propositions and the class of (true) propostions which are not known to be true neither in the actual world or in any other possible worlds. Their justification for this leads to a consideration of &quot;experiential&quot; vs. &quot;ratiocinative&quot; knowledge and a fascinating discussion of the contributions of Immanuel Kant in this regard.	2002-09-25
1402538:US	50702879	R4TJZG3RV58OZ	0387906851	277396548	A Hilbert Space Problem Book (Graduate Texts in Mathematics)	Books	5	50	50	N	N	Deserves 10 stars	This book should have been titled &quot;A Hilbert Space Idea/Problem Book&quot; as it not only challenges the reader to work out interesting problems in operator theory and the geometry of Hilbert space, but also motivates the essential ideas behind these fields. It is definitely a book that, even though out-of-print, will be referred to by many newcomers to operator theory and quantum physics. The insight one gains by the reading of this book is unequaled in any other books in existence on operator theory. It is becoming more rare as mathematics advances, to find books that attempt to explain the intuition behind the abstractions that are manifested in any area of mathematics. The problems in the book deal with both concrete examples and general theorems, and the reader should attempt to try and solve them without looking at the hints. The solutions found by the reader can then be compared with the author's, and some interesting differences will occur.<br /> There are so many interesting discussions in this book that to list them all would probably entail listing everything in the book. The reader will find excellent discussions of the origin of normal operators on infinite dimensional Hilbert spaces as analogs to matrices on finite dimensional spaces; why the weak topology in infinite dimensions is not metrizable; the non-emptiness of the spectrum and why the spectral radius can be computed even though the spectrum cannot; the impossibility of isolated singular operators; the non-continuity of the spectrum: the existence of an operator with a large spectrum and the existence of operators with small spectra in every neighborhood of the large spectrum. The author then goes on to show that the spectrum is an upper semicontinuous function, thus preventing the existence of small spectra arbitrarily close to large spectra. This is an excellent discussion on the meaning and intuition behind semicontinuity; the result that every normal operator is unitarily equivalent to a multiplication and its equivalance to the spectral theorem. The author goes on to explain how one gives up the sigma-finiteness of the measure when doing this, and the origin of functional calculus; the difference between infinite and finite dimensions when attempting a polar decomposition for operators and its connection with partial isometries; the origin of compact operators and their connection with integral equations. The author shows how even the identity operator is not an integral operator on the space of square-integrable functions with Lebesgue measure.<br /> In discussing the spectral theorem in chapter 13 the author states  most profoundly: &quot;In some contexts some authors choose to avoid a proof that uses the spectral theorem even if the alternative is longer and more involved. This sort of ritual circumlocution is common to many parts of mathematics; it is the fate of many big theorems to be more honored in evasion than in use. The reason is not just mathematical mischievousness. Often a long but 'elementary' proof gives more insight, and leads to more fruitful generalizations, than a short proof whose brevity is made possible by a powerful but overly specialized tool.&quot; In these few sentences the author has characterized the problem with current methods of teaching advanced mathematics. Too often the formalism masks the true meaning and intuitive motivation behind the mathematics. And even though mathematics is being applied to many different areas at an unprecedented rate, pure mathematics seems to be trapped in a local minimum, and I beleive this is due to the reluctance of authors to explain in detail the essentials of their ideas. This book is a perfect example of how mathematics can be taught that requires much thought and creativity on the part of students, without spoon-feeding them and thus encouraging a passive attitude to the learning of mathematics. I salute the author in his achievements in research and in teaching...one can onlyhope that his approach will be followed in all future works of mathematics.y hope that his approach will be followed in all future works of mathematics.	2002-09-21
1403889:US	50702879	RM3ABP8Q3TYEA	0387952292	892639957	Statistical Methods in Bioinformatics (Statistics for Biology and Health)	Books	4	64	66	N	N	Pretty good overview	This book is a timely introduction to the mathematical statistics used in computational biology and bioinformatics. The authors have done a superb job in the overview of a subject that students of biology and bioinformatics can rely on for study and for reference. The mathematics is done at an advanced undergraduate level, but the authors are pragmatic in their approach, and interlace the discussion with biological applications immediately after the appropriate mathematical background has been developed. It thus seems appropriate  to discuss the quality of the presentation with these applications in mind.<br />Chapter one begins, appropriately, with an introduction to probability theory, with a consideration of discrete probability distributions of one variable beginning the chapter. The Bernoulli, binomial, uniform, geometric, generalized geometric, and Poisson distributions are discussed. The authors point out the use of geometric-like distributions in the BLAST application. The also caution the reader as to the difference between the mean and the average of a random variable. They then move on to consider continuous distributions, discussing briefly the uniform, Normal, exponential, gamma, and beta distributions. Moment-generating functions are also introduced, and they prove a &quot;convexity&quot; theorem for these functions that is important in the BLAST application. The authors also introduce the relative entropy and generalized support statistics, the later also being used in BLAST.<br />The next chapter is an overview of probability theory in many random variables. The results in chapter one are discussed in this context, and the authors give an interesting application to the sequencing of EST libraries. The authors also point out that the variance of the maximum of a collection random variables is finite as the number of variables increases, a fact that is used quite often in bioinformatics. Transformations of random variables are also discussed, with the goal of showing how these can be used to find the density function of a single random variable, this also being important in BLAST.<br />The most important subject of the book begins in chapter 3, wherein the authors introduce statistical inference. They begin with a very brief discussion of the differences between the frequentist and Bayesian approaches to statistical inference and then move on to classical hypothesis testing and nonparametric tests. This chapter is of great value to those readers, for example biologists/would-be bioinformaticists who are approaching statistics for the first time.<br />Chapter 4 introduces concepts that are of upmost importance in probabilistic computational biology, namely Markov chains. The discussion in this chapter sets up the strategies used in the next chapter on analyzing a single DNA sequence and a latter chapter on hidden Markov models. Shotgun sequencing is discussed as a tool to determine the an actual DNA sequence, and the authors discuss the probabilistic issues that arise in the reconstruction of long DNA sequences from shorter sequences. Missing in this chapter is a mathematical analysis of the advantages/disadvantages between shotgun and whole genome sequencing strategies.<br />Chapter 6 then generalizes the analysis of chapter 5 to multiple DNA and protein sequences. It is here that one begins to talk about alignments between sequences, which bring about some very subtle mathematical problems in computational biology. The computational complexity of the (global) alignment problem entails the use of softer techniques, such as dynamic programming, which is discussed in this chapter. The (local) alignment problem is also discussed in some detail, using the linear gap model. The alignment problem and the issues with scoring for protein sequences are also discussed in detail. The reader first encounters the famous PAM and BLOSUM matrices in this chapter. The authors do not discuss any connections with the protein folding problem, unfortunately.<br />The next chapter introduces the basic probability theory behind the BLAST algorithm, namely random walks. They do so with emphasis on moment generating functions, which might be a little abstract for the biologist reader.<br />The authors return to tatistical estimation and hypothesis testing in chapter 8, with maximum liklihood and fixed sample size tests discussed in some detail. Again connecting with the BLAST algorithm, the sequential probability ratio test is treated.<br />The authors finally get down to the BLAST algorithm in chapter 9, using an older version of the software (1.4). The connection of the algorithm with random walks and how to assign scores is immediately apparent, as is the ability of BLAST to do database queries against a chosen sequence. The algorithm is compared with the sequential analysis discussed in the last chapter.<br />The authors return to Markov chains in chapter 10, and give some numerical examples. In addition, they treat the important topic of Markov chain Monte Carlo via the Hastings-Metropolis algorithm, Gibbs sampling, and simulated annealing. An application of simulated annealing to the double digest problem is described. The authors also spend a litte time discussing continuous-time Markov chains.<br />Hidden Markov models are finally discussed in chapter 11. These have been the most effective tools in sequence analysis and the authors give a nice overview of their construction and properties in this chapter. The Pfam package is discussed as a software implementation of HMMs for determining protein domains. Unfortunately, they do not discuss the excellent package HMMER for implementing HMMs in sequence analysis.<br />Chapter 12 discusses computationally intensive methods in classical inference. One of these methods, the bootstrap procedure, which is used for large sample sizes, is described. Used to estimate confidence intervals in situations where there is not enough information to employ classical methods, the authors detail a method using quantiles to estimate the confidence interval for the standard deviation of the expression intensity of a gene. This is followed by a return to the multiple testing problem of chapter 3 in the context of the data analysis of expression arrays.<br />I did not read the last two chapters on evolutionary models and phylogenetic tree estimation so I will omit their review.n folding problem, unfortunately. <br />The next chapter introduces the basic probability theory behind the BLAST algorithm, namely random walks. They do so with emphasis on moment generating functions, which might be a little abstract for the biologist reader. <br />The authors return to tatistical estimation and hypothesis testing in chapter 8, with maximum liklihood and fixed sample size tests discussed in some detail. Again connecting with the BLAST algorithm, the sequential probability ratio test is treated. <br />The authors finally get down to the BLAST algorithm in chapter 9, using an older version of the software (1.4). The connection of the algorithm with random walks and how to assign scores is immediately apparent, as is the ability of BLAST to do database queries against a chosen sequence. The algorithm is compared with the sequential analysis discussed in the last chapter. <br />The authors return to Markov chains in chapter 10, and give some numerical examples. In addition, they treat the important topic of Markov chain Monte Carlo via the Hastings-Metropolis algorithm, Gibbs sampling, and simulated annealing. An application of simulated annealing to the double digest problem is described. The authors also spend a litte time discussing continuous-time Markov chains. <br />Hidden Markov models are finally discussed in chapter 11. These have been the most effective tools in sequence analysis and the authors give a nice overview of their construction and properties in this chapter. The Pfam package is discussed as a software implementation of HMMs for determining protein domains. Unfortunately, they do not discuss the excellent package HMMER for implementing HMMs in sequence analysis. <br />Chapter 12 discusses computationally intensive methods in classical inference. One of these methods, the bootstrap procedure, which is used for large sample sizes, is described. Used to estimate confidence intervals in situations where there is not enough informationto employ classical methods, the authors detail a method using quantiles to estimate the confidence interval for the standard deviation of the expression intensity of a gene. This is followed by a return to the multiple testing problem of chapter 3 in the context of the data analysis of expression arrays. <br />I did not read the last two chapters on evolutionary models and phylogenetic tree estimation so I will omit their review.	2002-09-19
1406960:US	50702879	RRXENWFXG9ETO	0805052534	123190073	If Aristotle Ran General Motors	Books	5	20	25	N	N	Brilliant	When you ask business people what they think about ethics and morality, they usually answer that these are important things in today's business environment. When you ask them what they REALLY think about ethics and morality, most of them don't want to answer you in any detail. A few will reply that morality is \\"idealistic\\" and that one must be \\"pragmatic\\" in everyday business practice. The belief that \\"morality is a topic to be debated after the bills are paid\\" seems to be the dominant belief in business (and other) circles.<br /> This book, brilliant in every way, attempts, and succeeds, in arguing that wisdom and its concrete manifestation in ethics, should be the cornerstone of business life. The author is a philosopher, and not a business owner, but with his insight into the dynamics of the marketplace and its optimization, his ideas are clearly thinking \\"out of the box\\". One can only hope that business leaders (and others) will discover the ideas in this book or some other like it. With today's headlines in corporate fraud and other scandals (some justified and some not), business people need to start believing in the efficacy of ethics in optimizing their business ventures.<br /> The preface to the book concerns \\"reinventing corporate spirit\\", the author drawing on the thoughts of the ancient Greek philosopher Aristotle to set up the foundation for his arguments in the book. He recognizes correctly that it is ideas that fundamentally move the world.<br /> Throughout the book are many interesting insights into the psychology of business practices. When speaking of happiness for example, in relation to Aristotle's notion of eudaemonia, one of these is the recognition that money is frequently not the end goal for business people, the real goal being to achieve admiration in the eyes of others. The resulting ostentatious lifestyle is primarily done to impress, this being a transient and ultimately unsatisfying motivation in the eyes of the author.<br /> The book is divided up into four parts: Truth, Beauty, Goodness, and Unity. Each of these stand for respectively, the intellectual, aesthetic, moral, and spirtual necessities for achieving true happiness.<br />In \\"Truth\\" the discussion is interesting in that it emphasizes the importance of telling the truth not just from the standpoint of what it will do in relation to others, but what it will do for the individual involved. Telling a lie damages one's self confidence. Individuals who practice the telling of falsehoods are intimidated by truth and do not have any confidence in the efficacy of their own minds. In addition, the author discusses the importance of \\"open-book management\\": that the sharing of knowledge results in greater productivity among the employees. This is to be contrasted with the nervous attitude among some managers who feel threatened by information, again lacking self-confidence and are in a perpetual state of worry that the dissemination of knowledge among employees or co-workers will result in their comptetitive demise. These  views on truth are most refreshing. \\"Lying is the most dangerously corrosive and subtly destabilizing activities to be found in human life\\" he says. He's right.<br /> Quoting the Hindu proverb \\"The true nobility is in being superior to your precious self\\", the author encourages the view of competition as being one in which individuals surpass their former abilities, instead of worrying about their status in relation to others. He's right.<br /> Even more important is that the author addresses the influence of philosophy in the development of ethical attitudes in business. Ethical relativism and nihilism have wreaked havoc in society as a whole, not just in business, and the author emphasizes the need for coming to grips with these beliefs, and replacing them with sound philosophical systems that are both rational and meshed with common sense. \\"Ideas rock the world\\" he states. He's right.<br /> Most refreshingly, the author does not shy away from addressing the issue of self-interest. Confronting the \\"What's in it for me?\\" question that is asked by some, he clearly believes that self-interest is not something to be swept under the rug in discussions on ethics and morality in business. \\"The view that ethics requires total personal disinterestedness is a dangerous distortion of the truly moral point of view\\", he states. He's right.<br /> Peer pressure and \\"going with the flow\\" are always issues that everyone has to deal with in the business environment. Not being labeled as a \\"team player\\" can be detrimental to one's growth in a particular organization. The author asks the reader to count the costs of conformity and not to \\"associate with evil men, lest you increase their number\\", quoting George Herbert. He's right.<br /> But ethics is not merely a collection of arbitrary rules to follow, the author argues. The right course of action is built into the nature of reality and meshes with human nature and human needs. Since this is the case, the practice of true ethical norms is not only productive, but pleasureful to the individual, and instead of causing boredom as some might believe, alleviates it, argues the author. He's right.<br /> Some might label, and the author does unashamedly, the framework outlined in the book as \\"spiritual\\". Goal-oriented, truth-valuing, truth-loving conduct results in a productive, life-loving spiritual individual, in complete antithesis to that of a sterile, non-creative, cynical one who views life as a burden with crosses to bear.<br /> Some of course might view this book, and one on ethics in general, as being \\"idealistic\\" or \\"naive\\". Such individuals may not wish to even pick it up, let alone read it. But individuals who practice these ideas, or ones very similar, haved moved the world, and will continue to do so.oes not shy away from addressing the issue of self-interest. Confronting the \\"What's in it for me?\\" question that is asked by some, he clearly believes that self-interest is not something to be swept under the rug in discussions on ethics and morality in business. \\"The view that ethics requires total personal disinterestedness is a dangerous distortion of the truly moral point of view\\", he states. He's right. <br /> Peer pressure and \\"going with the flow\\" are always issues that everyone has to deal with in the business environment. Not being labeled as a \\"team player\\" can be detrimental to one's growth in a particular organization. The author asks the reader to count the costs of conformity and not to \\"associate with evil men, lest you increase their number\\", quoting George Herbert. He's right. <br /> But ethics is not merely a collection of arbitrary rules to follow, the author argues. The right course of action is built into the nature of reality and meshes with human nature and human needs. Since this is the case, the practice of true ethical norms is not only productive, but pleasureful to the individual, and instead of causing boredom as some might believe, alleviates it, argues the author. He's right. <br /> Some might label, and the author does unashamedly, the framework outlined in the book as \\"spiritual\\". Goal-oriented, truth-valuing, truth-loving conduct results in a productive, life-loving spiritual individual, in complete antithesis to that of a sterile, non-creative, cynical one who views life as a burden with crosses to bear. <br /> Some of course might view this book, and one on ethics in general, as being \\"idealistic\\" or \\"naive\\". Such individuals may not wish to even pick it up, let alone read it. But individuals who practice these ideas, or ones very similar, haved moved the world, and will continue to do so.	2002-09-16
1409147:US	50702879	R32CO7ESHERWD2	081299180X	839690737	Arguing A.I.: The Battle for Twenty-first-Century Science	Books	4	8	8	N	Y	An elementary but interesting introduction to A.I.	Is research and thinking on artificial intelligence stuck in a local minimum? Those in the field have attested to major advances in the last decade, but are these advances merely a renaming of approaches that were taken decades ago?<br /> This book does not address these questions as its major goal, but instead attempts to give a broad overview of how A.I. got started and where it is now, and where it might be going. The reader is lead to ask the questions above though after reading the book, for the author seems to ask them implicitly. Its validity as a science are questioned, and the future of A.I. is addressed in detail. The author though is fair in his representation of both sides of the A.I. debate.<br /> After a short introduction and a brief &quot;A.I. debate timeline&quot;, the author begins chapter 1 with what could be considered to be the mathematical origins of the subject, due to the mathematicians David Hilbert and Alan Turing. Hilbert was essentially the originator of the formalist school of mathematics and proof theory, but his ideas were countered by Turing, and the mathematicians Kurt Godel and Alzono Church. These counterarguments are taken to be final by the author, and he follows the lead of many others in asserting this. But the &quot;unprovability&quot; results of Godel do not show up in the normal practice of mathematical research though, with the self-referential statements having to be artificially constructed. There are no examples in the everyday practice of mathematical research where these kinds of statements arise when engaging in the activity of making definitions and proving theorems. Empirically and practically speaking therefore, the Godel counter to the Hilbert formalism is weak. As far as any negative ramifications to A.I. are concerned, the author does mention the assertion of Douglas Hofstadter that Godel self-referential statements would be a (positive) sign of machine intelligence and self-awareness.<br /> The next chapter discusses the A.I. contributions of the LISP pioneer John McCarthy. A brief biography is given of McCarthy and how he got started in A.I. This chapter gives much insight into the &quot;giddy&quot; optimisim that surrounded the A.I. community in the 1950's, an optimism that has grown beyond all bounds at the present time. McCarthy's time scale for having machine intelligence is on the order of 500 years, but, as the author reports him saying: &quot;The breakthrough could come this or next year.&quot; In addition, and I think correctly, McCarthy believes that computational power is not enough for advances in A.I., but some new ideas. When viewing the status of A.I. research, with fairness one could say that it is trapped in a local minimum, and some radically new ideas are needed to force it out of equilibrium. Computational power will certainly help in testing out these new ideas of course.<br /> In chapter 3, the author overviews the contributions and attitudes of Ray Kurzweil to A.I. Called the &quot;optimist&quot; by the author, and this is indeed an understatement. Kurzweil predicts the onset of thinking machines way beyond the capabilities of human intelligence by the year 2030. His contributions to A.I. and his technological ingenuity justify though this optimism. His attitude that computational power is the sole issue is not really justified, at least from current levels of knowledge. But increased computer performance may result in more innovative ideas to be developed, resulting in a kind of self-fulfilled prophecy for the rise of intelligent machines by the year predicted.<br /> Chapter 4 discusses an idea that you don't hear much about anymore: virtual reality. The author overviews the work of Jaron Lanier, the leading innovator of virtual reality software. Critical of the claims of A.I. researchers, Lanier has much to say about the future of both A.I. and software development. As reported by the author, his motivation for developing virtual reality is very intriguing, as he wanted to build an interactive computer-graphics program that would give mathematicians the power to express their ideas in graphical form. Software development though, according to Lanier, has taken a turn for the worse, with bug-ridden progams the norm rather than the exception, all written, he says, to take advantage of increasing microprocessor speeds. The future in 2030 is one where software maintenance is the predominant activity, according to Lanier. Lanier though omits the fact that software engineering is one of the main applications of A.I. at present, and shows every sign of increasing. Intelligent debugging, intelligent software maintenance, and even intelligent software development are acting as testing grounds and financial justification for A.I.<br /> In chapter 5, the (pessimistic) ideas of Bill Joy are discussed by the author. Joy is clearly very concerned that the future may result in a terrifying one for all of humanity, if indeed A.I. is realized to the point of autonomous, thinking machines. He believes that A.I. will reach such a status, but he is not optimistic as to its consequences. It is interesting to compare his ideas on software development with those of Lanier. Joy, as reported by the author, believes that it will not be like anything we currently understand. In addition, strong A.I., or a conscious thinking machine, does not have to be realized in order for it to be dangerous, Joy argues.<br /> The last chapter, entitled &quot;Fact Versus Fiction&quot; is an attempt by the author to wrap things up and assess just where we all are in A.I. research. As in most books of this kind, the arch-villan HAL of 2001: A Space Odyssey makes its appearance. HAL has turned into a sort of benchmark for A.I., in both popular and professional circles. And, interestingly, the movie &quot;A.I.&quot; is mentioned also, it being held as an example of the current thinking in many A.I. circles that a machine must interact with the environment in order for it to become intelligent.<br /> But more A.I. is coming....ry intriguing, as he wanted to build an interactive computer-graphics program that would give mathematicians the power to express their ideas in graphical form. Software development though, according to Lanier, has taken a turn for the worse, with bug-ridden progams the norm rather than the exception, all written, he says, to take advantage of increasing microprocessor speeds. The future in 2030 is one where software maintenance is the predominant activity, according to Lanier. Lanier though omits the fact that software engineering is one of the main applications of A.I. at present, and shows every sign of increasing. Intelligent debugging, intelligent software maintenance, and even intelligent software development are acting as testing grounds and financial justification for A.I.<br /> In chapter 5, the (pessimistic) ideas of Bill Joy are discussed by the author. Joy is clearly very concerned that the future may result in a terrifying one for all of humanity, if indeed A.I. is realized to the point of autonomous, thinking machines. He believes that A.I. will reach such a status, but he is not optimistic as to its consequences. It is interesting to compare his ideas on software development with those of Lanier. Joy, as reported by the author, believes that it will not be like anything we currently understand. In addition, strong A.I., or a conscious thinking machine, does not have to be realized in order for it to be dangerous, Joy argues.<br /> The last chapter, entitled &quot;Fact Versus Fiction&quot; is an attempt by the author to wrap things up and assess just where we all are in A.I. research. As in most books of this kind, the arch-villan HAL of 2001: A Space Odyssey makes its appearance. HAL has turned into a sort of benchmark for A.I., in both popular and professional circles. And, interestingly, the movie &quot;A.I.&quot; is mentioned also, it being held as an example of the current thinking in many A.I. circles that a machine must interact with the environment in order for it to become intelligent. <br /> But more A.I. is coming....	2002-09-14
1411265:US	50702879	R38WW0CCXVZYWI	0486678504	834701362	A Geometric Introduction to Topology (Dover Books on Mathematics)	Books	4	6	7	N	N	Good introduction for undergraduates	This book is a brief introduction to algebraic topology and is written by one of the major contributors to the subject. Written for undergraduates, it does not presuppose any background in topology, and the author concentrates strictly on subsets of Euclidean space. And, interestingly, the author does not introduce homology and cohomology using simplicial complexes, but instead uses the Cech theory and singular homology. Also, and somewhat disappointingly, the fundamental group is not discussed at all. The author is very concrete in his presentation, and he includes effective sets of exercises at the end of each chapter. He also introduces the necessary algebra at various places in the book.<br /> Some of the highlights in the book include: 1. The discussion of the zeroth cohomology group of a topological space, which is introduced as the collection of continuous maps from the space into the integers. This of course is what is called singular cohomology, and the author shows how it is related to the path components of the space, one consequence being that if there is only one path component, then the zeroth cohomology group has only constant maps. The singular homology group is then defined as the free group on the path component space. 2. The treatment of homotopy, and how it is related to the first singular cohomology group, the latter being the collection of maps from a space to the unit circle. The author also gives an interesting exercise dealing with quaternions. 3. The study of the algebraic topology of the unit circle. This discussion introduces the important concept of the degree of a map, and this is used to prove the fundamental theorem of algebra and the Brouwer fixed point theorem in the plane. 4. The treatment of the Mayer-Vietoris theorem. This is a fundamental result in algebraic topology, and the author computes the first singular cohomology group of a product as an example of this result. 5. The discussion on duality, which, at this level, is a very original presentation that essentially relies on extending Eilenberg's criterion on separation of points by compact plane sets.ry original presentation that essentially relies on extending Eilenberg's criterion on separation of points by compact plane sets.	2002-09-12
1414158:US	50702879	R1X17DOELNZQSE	0125113609	659667677	C*-Algebras and Operator Theory	Books	5	24	25	N	N	Excellent, modern introduction to C*-algebras	The use of C*-algebras in operator theory is known as a \\"soft\\" technique, in contrast to the \\"hard\\" techniques that use deep results from analysis. The blending of algebra, topology, measure theory, and analysis to study operators has resulting in breathtaking advances, and this trend continues. Applications to physics, especially quantum field theory, has also resulted in fruitful collaborations between mathematicians and physicists. The author has given an introduction to C*-algebras in this book from the purely mathematical standpoint, but those interested in applications can gain much from the reading of this book.<br /> Spectral theory is introduced in chapter 1, with a definition of Banach algebras immediately given on the first page. There are many advantages is presenting spectral theory in this general context, and the author illustrates these advantages throughout the chapter. For Banach algebras with a unit, Gelfand's theorem, giving the non-emptiness of the spectrum, is proven. The author also discusses the Gelfand representation, that says essentially that abelian Banach algebras act like continuous functions. He then restricts his attention to compact and Fredholm operators, and discusses their index theory. It is here that the reader can see the origin of the idea of a compact operator acting as a \\"zero element\\" in algebras of operators. This is readily apparent in the definition of the Calkin algebra, which is the quotient algebra modulo the compact operators.<br /> By defining an involution on a Banach algebra, the author introduces C*-algebras in chapters 2 and 3, and proves the famous Gelfand-Naimark theorem. The latter allows one to view any C*-algebra as a collection of bounded operators on a separable Hilbert space. In addition, the spectral theorem for normal operators is proven. These two theorems give one confidence in the power of the theory of C*-algebras to study operators, but their nonconstructive nature sometimes is not of much use for calculating explicitly the spectra or to find the Hilbert space that serves as a representative example in the Gelfand-Naimark result.The author also introduces the concept of a hereditary C*-subalgebras, which is a generalization of the concept of an idea, and, like the algebra of compact operators, are always simple if they are subalgebras of simple C*-algebras. Also, the author introduces the important class of Toeplitz operators. These are intimately connected with \\"hard analysis\\" and have important applications in physics and cryptography. The author also uses them, via the consideration of the Toeplitz algebra, to introduce concepts in K-theory.<br /> The theory of von Neumann algebras, or W*-algebras as they are sometimes called, is discussed in chapter 4. His viewpoint of them is characteristically modern, as essentially a noncommutative measure theory. This viewpoint meshes will with current research in the field of noncommutative geometry. Proofs of the double commutant theorem and the Kaplansky density theorem are given. The presence of the weak operator topology makes these objects of primary interest to applications in quantum physics, as it is this topology which is physically relevant. The famous \\"type\\" characterization of projections in von Neumann algebras is given in an addendum to the chapter.<br /> The representation theory of C*-algebras is considered in chapter 5. The author shows that topological irreducibility is equivalent to algebraic irreducibility for C*-algebras. The reader can see the role that ideals, especially the \\"primitive\\" ideals, play in the representation theory. The author also discusses CCR algebras, but he calls them \\"liminal\\" algebras. The theory of liminal algebras is of upmost importance in applications to quantum physics (physicists still call them CCR algebras).<br /> Chapter 6 is an introduction to the construction of C*-algebras using direct limits and tensor products of given C*-algebras. And here again, the physicist reader will find a useful class of algebras, namely the AF-algebras, which are used heavily in mathematical statistical mechanics. Nuclear C*-algebras, which are the most well-behaved class under the operation of tensor product, are discussed briefly.<br /> The last chapter of the book is the most interesting, for it deals with the K-theory of C*-algebras. The Brown-Douglas-Fillmore theory was briefly mentioned in an addendum to chapter 2. This theory could be considered a precursor to latter work on K-theory of operator algebras. The author explains the origin of the K-groups K0(A) and K1(A) assigned to a C*-algebra, and how they can be used to study some properties of A. The K-groups are constructed by first forming the set P(A) consisting of the union of all projections in the collection of n by n matrices over an arbitrary *-algebra A. Then for a unital *-algebra A, a notion of stable equivalance is defined for elements of P(A). The reader familiar with the K-theory of vector bundles will see the similarity in this definition. Here the two projections are stably equivalent if they are equivalent under the direct sum of the n x n identity operator. The equivalance classes under stability are then enveloped via the Grothendieck group, giving the K-group K0(A). Then the K0-group shown to be a complete isomorphism invariant for unital AF-algebras, i.e. two unital AF-algebras are *-isomorphic iff there is a unital order isomorphism between their K0-groups. Three fundamental results in K-theory are then discussed: \\"weak exactness\\", which gives an exact sequence of K0-groups given an exact sequence of C*-algebras; \\"homotopy invariance\\", which shows that mappings between the K0-groups of two C*-algebras are equal if the mappings between the C*-algebras are homotopic; \\"continuity\\": which gives a notion of continuity for the K0-functor. Then after defining a notion of stability for the K0-functor, the author proves an analog of Bott periodicity. This involves of course the construction of the K1-group, which is done in terms of the suspension of the C*-algebra, in complete analogy with the vector bundle case.cist reader will find a useful class of algebras, namely the AF-algebras, which are used heavily in mathematical statistical mechanics. Nuclear C*-algebras, which are the most well-behaved class under the operation of tensor product, are discussed briefly. <br /> The last chapter of the book is the most interesting, for it deals with the K-theory of C*-algebras. The Brown-Douglas-Fillmore theory was briefly mentioned in an addendum to chapter 2. This theory could be considered a precursor to latter work on K-theory of operator algebras. The author explains the origin of the K-groups K0(A) and K1(A) assigned to a C*-algebra, and how they can be used to study some properties of A. The K-groups are constructed by first forming the set P(A) consisting of the union of all projections in the collection of n by n matrices over an arbitrary *-algebra A. Then for a unital *-algebra A, a notion of stable equivalance is defined for elements of P(A). The reader familiar with the K-theory of vector bundles will see the similarity in this definition. Here the two projections are stably equivalent if they are equivalent under the direct sum of the n x n identity operator. The equivalance classes under stability are then enveloped via the Grothendieck group, giving the K-group K0(A). Then the K0-group shown to be a complete isomorphism invariant for unital AF-algebras, i.e. two unital AF-algebras are *-isomorphic iff there is a unital order isomorphism between their K0-groups. Three fundamental results in K-theory are then discussed: \\"weak exactness\\", which gives an exact sequence of K0-groups given an exact sequence of C*-algebras; \\"homotopy invariance\\", which shows that mappings between the K0-groups of two C*-algebras are equal if the mappings between the C*-algebras are homotopic; \\"continuity\\": which gives a notion of continuity for the K0-functor. Then after defining a notion of stability for the K0-functor, the author proves an analog of Bott periodicity. This involves of course the construction of the K1-group, which is done in terms of the suspension of the C*-algebra, in complete analogy with the vector bundle case.	2002-09-09
1416249:US	50702879	R3M2JZDV4HRTZX	0821816705	464578463	Introduction to Some Methods of Algebraic $K$-Theory (CBMS Regional Conference Series in Mathematics)	Books	4	3	3	N	N	Short but adequate	Written for those who are not familiar to the subject, the author gives a brief but fairly effective overview of the subject of algebraic K-theory. Once thought to be of interest only to pure mathematicians, K-theory has now found applications to high energy physics and cryptography. Higher algebraic K-theory is not covered, the author realizing that very advanced technical machinery is needed for such material. The notes could be used though as an introduction to higher K-theory and Quillen's construction of K-groups for categories with exact sequences.<br /> The author begins the lectures with stating the main goal of the book, namely for proving that for the polynomial ring A in N variables over the integers or integers modulo p, the general linear group of n by n matrices GL(n,A) over this ring is finitely generated for n greater than or equal to N + 3. To meet this goal he reviews the properties of elementary matrices in lecture 1. For a ring A, by considering the elementary subgroups E(n,A) of GL(n,A), these subgroups consisting of matrices satisfying certain relations, the author shows that for a surjective ring homomorphism between rings A and A', the homomorphism from E(n,A) to E(n,A') is surjective, even though it is not for GL(n,A) to GL(n,A'). E(n,A) is shown to be stable under transposition and shown to be commutator subgroup of GL(n,A) for large n. This is the origin of the stability issues in K-theory, and these are discussed in lecture 2. The author shows just why it is advantageous to consider taking the union GL(A) of GL(n,A) (and E(n,A)) for all n and why stability is important in the proof of the above result.<br /><br /> The \\"Whitehead group\\" K(1,A) is defined as GL(A)/E(A), and its use in the proof of the theorem results from the map GL(n,A)/E(n,A) to K(1,A) being a bijection for large n and that K(1,A) is finitely generated. Following this matrix characterization of K(1,A), the author reduces the proof of the theorem to showing that for a \\"regular\\" ring A, every unipotent element in GL(A) represents 0 in K(1,A), and that the rings in the theorem are indeed regular. Noting the analogy between determinants of matrices and determinants of endomorphisms of vector spaces, the author begins the proof of these assertions with a different description of K(1,A). This description involves the consideration of Grothendieck and Whitehead groups of categories with exact sequences.<br /> The Whitehead group is now defined as the quotient of the Grothendieck group, the latter being the abelian group whose generators are essentially isomorphism classes of objects from an admissible Abelian category. The Whitehead group K(1,A) for a ring A is then related to the Whitehead group K(1,M) for an admissible category M. This definition is due to Grothendieck and involves showing that their is an isomorphism between K(1,A) and K(1, P(A)) where P(A) is the category of finitely generated projective A-modules. P(A) is not abelian, and therefore must be enlarged, without changing K(1,A), to one that is. The author shows that P(A) must be abelian in order to kill unipotents K(1,A). The enlarged P(A) is abelian as long as A is regular, the latter meaning that A is right Noetherian and that any finitely generated A-module has finite homological dimension. As the name implies, homological dimensions involves some discussion of homology theory, and is defined to the least n for which there is a projective resolution of the A-module of length n. The proof of the above theorem then follows, as the author shows, from Hilbert's syzygy theorem.ar\\" ring A, every unipotent element in GL(A) represents 0 in K(1,A), and that the rings in the theorem are indeed regular. Noting the analogy between determinants of matrices and determinants of endomorphisms of vector spaces, the author begins the proof of these assertions with a different description of K(1,A). This description involves the consideration of Grothendieck and Whitehead groups of categories with exact sequences. <br /> The Whitehead group is now defined as the quotient of the Grothendieck group, the latter being the abelian group whose generators are essentially isomorphism classes of objects from an admissible Abelian category. The Whitehead group K(1,A) for a ring A is then related to the Whitehead group K(1,M) for an admissible category M. This definition is due to Grothendieck and involves showing that their is an isomorphism between K(1,A) and K(1, P(A)) where P(A) is the category of finitely generated projective A-modules. P(A) is not abelian, and therefore must be enlarged, without changing K(1,A), to one that is. The author shows that P(A) must be abelian in order to kill unipotents K(1,A). The enlarged P(A) is abelian as long as A is regular, the latter meaning that A is right Noetherian and that any finitely generated A-module has finite homological dimension. As the name implies, homological dimensions involves some discussion of homology theory, and is defined to the least n for which there is a projective resolution of the A-module of length n. The proof of the above theorem then follows, as the author shows, from Hilbert's syzygy theorem.	2002-09-07
1421386:US	50702879	R23MW4S145Z7T7	1573929921	824389633	Our Molecular Future: How Nanotechnology, Robotics, Genetics and Artificial Intelligence Will Transform Our World	Books	5	39	44	N	Y	The 21st century will not frighten the horses.	For optimists and those who find life in the 21st century a complete source of exhiliration, and for those who are indulging themselves in the dizzying pace of technological advancement, this book is sheer delight. Speculative in some points, and gaurded in others, the author has written a book that takes the reader through a future that is not far distant, and a future that is now. Genetic engineering, artificial intelligence, nanoscale computing, and robotics are here, right now, and advances in these areas show every sign of being explosive.<br /> The author asks us to imagine a conversation between a farmer in the year 1899 and a person who rolls up in an early automobile. The driver tells the farmer what is ahead in the next decades, such as playing golf on the moon, his children being able to drive themselves faster than a locomotive, his cows milked using machines, etc. The author then replays the same conversation but with a farmer of the year 2001, he automobile is replaced by a flying car:  golf will be played on Mars, and egg hatcheries will be designed by computers that do a better job then humans, agriculture will be replaced by food synthesizers, etc. With these hypothetical conversations, the author asks us to take stock in our skepticism that the future he outlines in the book it too far-fetched.<br /><br />  He is certainly correct in his reasoning. There are too many instances of \\"famous last words\\" when it comes to the future of a particular technological development. If one takes cognizance of the many developments that are now occuring simultaneously, it would be hard to tell exactly which ones are going to prevail. For example, when it comes to the enhancement of human capabilities, I see a competition between genetic engineering and artificial intelligence arising in the future. Both are strategies to improve human mental and physical capabilities, but are essentially different ways of course to meet these ends. The marketplace, and not government, will hopefully determine the outcome of this competition, but it, may disappear entirely if new methodologies, up to this time unknown, dilute the efficacy of these approaches.<br /> In addition, human factors engineering, which is not really emphasized in the book, may determine the outcome of particular technologies. Voice recognition and command in computers for example, may be too annoying to actually employ in the workplace, if open cubicle environments are still in place. The resulting noise level of everyone talking to their computers might be too irritating. Federal and state health requirements also have a repressive influence on the employing of new technology. With the growing hostility towards genetic engineering, governments will be stepping up their regulations and this might dampen the ever-growing amplitude of 21st century development.<br /> The author is aware of these attitudes towards technology, and so he attempts to offer a different sort of justification for employing them, particularly nanotechnology. Much space in the book is devoted to the use of this to combat natural disasters, such as asteroids, earthquakes, tornadoes, tsunamies, and radical climate changes. Many of his proposals for using nanotechnology to do this are interesting, such as \\"utility fog\\", which allows material objects to change shape at arbitrary time scales, food fabrication using molecular biosynthesis and robotic replenishment, and the intelligent product system (IPS), which allows maximal compatibility with the environment. In addition, the author envisions the deployment of millions of nanosatellites that will probe the solar system in order to find rogue asteroids that threaten our planet. Once found, the asteroid will be dissassembled layer by layer to a size that nullifies its threat. The residue will then be used as raw materials for space-based colonies.<br /> The author is also realistic in his appraisal of just what it is going to take from a financial perspective to develop the technology which he envisions. Such developments can be accomplished, and the financial and time scales involved, coupled with the physical dimensions of the technology, are the justification for his optimism. He does not use \\"inevitability\\" arguments to justify future technology developments, but instead realizes, correctly, that such developments are subject to human volition. We can halt or move forward, the choice being completely our own.<br /> Robo sapiens, Robo servers, and Homo provectus, may be on the way the author states. He asks us if we are ready, and he asks us to consider the answers to the employment of new technologies ourselves, and not leave it up to our government or religious leaders, who themselves are explaining it to us inadequately, he argues. Religious institutions are centuries behind, companies are selling products and services but are not structured to serve our interests, and scientists are too involved in their projects to consider how their discoveries will impact human life on Earth.<br /> The author encourages the reader to get involved, or invent, institutions or strategies that will mesh with the technological advances that are confronting each one of us. I cannot speak for the author here, but he seems to be incredibly optimisitic. This is refreshing, for this indeed is the most exciting time to be alive. We should all constantly attempt to improve ourselves and others with the knowledge we have available. With genetic engineering, artificial intelligence, highly sophisticated mathematics, robotics, and nanotechnology, we have precisely the right instruments, at precisely the right time, to participate in and build the greatest century yet for the human species...al perspective to develop the technology which he envisions. Such developments can be accomplished, and the financial and time scales involved, coupled with the physical dimensions of the technology, are the justification for his optimism. He does not use \\"inevitability\\" arguments to justify future technology developments, but instead realizes, correctly, that such developments are subject to human volition. We can halt or move forward, the choice being completely our own. <br /> Robo sapiens, Robo servers, and Homo provectus, may be on the way the author states. He asks us if we are ready, and he asks us to consider the answers to the employment of new technologies ourselves, and not leave it up to our government or religious leaders, who themselves are explaining it to us inadequately, he argues. Religious institutions are centuries behind, companies are selling products and services but are not structured to serve our interests, and scientists are too involved in their projects to consider how their discoveries will impact human life on Earth.<br /> The author encourages the reader to get involved, or invent, institutions or strategies that will mesh with the technological advances that are confronting each one of us. I cannot speak for the author here, but he seems to be incredibly optimisitic. This is refreshing, for this indeed is the most exciting time to be alive. We should all constantly attempt to improve ourselves and others with the knowledge we have available. With genetic engineering, artificial intelligence, highly sophisticated mathematics, robotics, and nanotechnology, we have precisely the right instruments, at precisely the right time, to participate in and build the greatest century yet for the human species...	2002-09-03
1421728:US	50702879	RMLFVXCRD7UZA	0691048150	936640505	Cycles, Transfers, and Motivic Homology Theories. Annals of Mathematics Studies, No. 143	Books	5	14	14	N	Y	Algebraic topology can be done in algebraic geometry	Beginning with the work of Grothendiek, the theory of motives is, very loosely speaking, an attempt at a &quot;unified theory&quot; of number theory and algebraic geometry. This years Fields Medals reflect the interest in motives, as one of the authors in this book (Voevodsky) was awarded for his research in this area. In a gist, this book tries to see how much of (standard) algebraic topology can be carried over to the study of algebraic varieties and schemes. By defining a new topology on algebraic cycles, the &quot;qfh topology&quot;, Voevodsky showed that the techniques of sheaf theory can be used to study them from the standpoint of algebraic topology. This topology is finer than the etale topology and allows one to use sheaf cohomology to study algebraic cycles. The reader will be expected to have a substantial background in the theory of schemes, higher K-theory, algebraic topology, and sheaf theory. Reading this book will give one a deep appreciation of how difficult it is to do algebraic topology in algebraic geometry, requiring formidable technical machinery.<br /> The use of K-theory in topology and algebra goes back half a century, beginning with the K-theory of CW-complexes and the construction of Atiyah and Hirzebruch of spectral sequences relating singular cohomology  to topological K-theory. The K-theory of algebraic varieties is a little more subtle, and involves looking at the isomorphism classes of algebraic vector bundles on the variety. These form an abelian group with the group operation being defined via the existence of an exact sequence between the isomorphism classes.<br /> As a warm-up to the scheme-theoretic setting, the K-theory of an arbitrary ring proceeds by analogy with the simplicial setting, the latter of which involves the classifying space of homotopy maps of the complex and the notion of stable equivalence. But for a general ring, the unit interval used in the definition of homotopy is replaced by the affine line. The work of Karoubi and Villamayor, and Quillen defined precisely higher algebraic K-theory for rings, the former using this simplicial motivation, the latter using what is called a &quot;Q-construction&quot;. The definitions coincide for regular schemes but not for singular ones.<br /> Motivic cohomology, which is an algebraic analog of singular cohomology, arose in the setting of the Chow ring of algebraic cycles modulo rational equivalence. A homology theory of the free abelian group of algebraic cycles of a variety, with the replacement of the unit interval with the affine line, was developed. The products existing in cohomology arise from the consideration of the intersection of subvarieties, leading to the familiar Chow ring. The Chow ring is functorial under pull-backs, and can be related to the zeroth K-group via the use of the Chern class and the Riemann-Roch theorem. The higher K-groups of Quillen give the desired long exact sequence of K-groups.<br /> Bloch then defined motivic cohomology via the construction of higher Chow groups, again by analogy to the simplicial theory, and with a careful definition of intersection product, so as to insure the algebraic cycles intersect the faces in the correct codimension. It was then shown that the higher Chow groups are related to the the higher K-groups for a variety which is smooth over a field.<br /> One of the authors (Frielander) and Dwyer, using the etale cohomology of Grothendieck, gave a mod-n topological K-theory, called etale K-theory, which led to the work of Suslin and Voevodsky on the motivic homology of algebraic cycles, which is the main focus of this book.<br /> After a brief introduction to motivic cohomology in chapter 1 and an historical introduction, the second chapter deals with relative cycles on schemes and Chow sheaves. Relative cycles are defined for schemes of finite type over a Noetherian (base) scheme and are well-behaved for morphisms of of the base scheme. The authors concentrate most of their attention not to general schemes but to varieties over a field. The cdh-topology is introduced here as one which allows the construction of long exact sequences for sheaves of relative cycles.<br /> Chapter 3 overviews the cohomological theory of presheaves and defines the notion of a transfer map. For smooth schemes over a field, these maps are used to define a &quot;pretheory&quot; over the field, and homotopy invariance of pretheories can then be defined. Examples of pretheories include etale cohomology, algebraic K-theory, and algebraic de Rham cohomology. The Mayer-Vietoris exact sequence for the Suslin homology is proven, giving another analogue of ordinary algebraic topology.<br /> In chapter 4 the authors consider the generalization of the duality  property of homology and cohomology in algebraic topology using bivariant cycle cohomology. The bivariant cycle cohomology groups are defined for schemes of finite type over a field in terms of the higher Chow groups. They have the origin in the generalization of the simplicial theory to the algebraic geometry setting. Homotopy invariance, suspension maps, and the Gysin sequence find their place here also. The authors detail to what extent the higher Chow groups can be considered to be a motivic cohomology theory. Motivic homology, motivic cohomology, and Borel-Moore motivic cohomology are shown to be related to the bivariant cycle cohomology and their algebraic topological properties discussed briefly.<br /> Chapter 5 studies algebraic cycle cohomology theories categorically via the construction of triangulated categories of motives. This is the key step in allowing the techniques of (ordinary) sheaf cohomology to be applied to the category of motives. The discussion is done in the context of smooth schemes, but it would be interesting if the authors would have given some concrete examples, possibly with elliptic curves, showing how these constructions come into play for elementary algebraic varieties.<br /> The book ends with a discussion of the higher Chow groups and how they relate to etale cohomology. A relatively concrete presentation, the author proves the equality between the higher Chow groups and etale cohomology with compact supports for quasiprojective schemes over algebraically closed fields of characteristic zero.attention not to general schemes but to varieties over a field. The cdh-topology is introduced here as one which allows the construction of long exact sequences for sheaves of relative cycles. <br /> Chapter 3 overviews the cohomological theory of presheaves and defines the notion of a transfer map. For smooth schemes over a field, these maps are used to define a &quot;pretheory&quot; over the field, and homotopy invariance of pretheories can then be defined. Examples of pretheories include etale cohomology, algebraic K-theory, and algebraic de Rham cohomology. The Mayer-Vietoris exact sequence for the Suslin homology is proven, giving another analogue of ordinary algebraic topology. <br /> In chapter 4 the authors consider the generalization of the duality  property of homology and cohomology in algebraic topology using bivariant cycle cohomology. The bivariant cycle cohomology groups are defined for schemes of finite type over a field in terms of the higher Chow groups. They have the origin in the generalization of the simplicial theory to the algebraic geometry setting. Homotopy invariance, suspension maps, and the Gysin sequence find their place here also. The authors detail to what extent the higher Chow groups can be considered to be a motivic cohomology theory. Motivic homology, motivic cohomology, and Borel-Moore motivic cohomology are shown to be related to the bivariant cycle cohomology and their algebraic topological properties discussed briefly. <br /> Chapter 5 studies algebraic cycle cohomology theories categorically via the construction of triangulated categories of motives. This is the key step in allowing the techniques of (ordinary) sheaf cohomology to be applied to the category of motives. The discussion is done in the context of smooth schemes, but it would be interesting if the authors would have given some concrete examples, possibly with elliptic curves, showing how these constructions come into play for elementary algebraic varieties.<br />The book ends with a discussion of the higher Chow groups and how they relate to etale cohomology. A relatively concrete presentation, the author proves the equality between the higher Chow groups and etale cohomology with compact supports for quasiprojective schemes over algebraically closed fields of characteristic zero.	2002-09-02
1424903:US	50702879	RFJRV3S2NFCLK	0195093445	927835421	How Is Quantum Field Theory Possible?	Books	5	14	15	N	N	A refreshing alternative to the usual philosophical doctrine	This book, very insightful into the intricacies of quantum field theory, is not based on what one might call the &quot;standard assumption&quot; of the philosophy of science, namely that science has an underlying foundation, that it is in a sense a derived collection of knowledge that needs &quot;justification&quot; philosophically. Indeed, the usual attitude in the philosophy of science is that a theory is only &quot;possible&quot; if its formalism is laid bare and shown to satisfy some essential philosophical assumptions. The predictions of a theory are not by themselves its justification, as this would presuppose too much of a &quot;commonsense&quot; attitude, and such an attitude is eschewed by philosophers of science.<br /> But of course there is another outlook on science that is not held by any of the modern doctrines in the philosophy of science. This is one in which science is not assumed to need an underlying philosophical justification, that it is its own justification, and the goal of philosophy should be in discovering what this assumption says about philosophy. For example, what theories of mind and reality are entailed by quantum field theory? Do the invariance principles used in quantum field theory say anything about epistemology? Quantum field theory is rich in concepts and uses very sophisticated mathematical constructions, and it has, via the ingenuity of experimentalists, resulted in real predictions that are as of yet unrivaled by any other physical theory. Can one build an interesting philosophical structure, complete with a metaphysics and a nontrivial epistemology, using the assumptions and structure of quantum field theory?<br /> In large measure, the author of this book does take this approach, and she is clearly not attempting to justify quantum field theory from the standpoint of the standard assumption. This is a unique and refreshing approach, and the book is a highly interesting one, as one can gain, as a bare minimum, a siginificant amount of understanding into the subtleties of quantum field theory. In addition, the analysis that the author has given is a positive one for quantum field theory. She assumes the existence of what could be characterized as 'epistemic fixed points' (my words here) in our ability to categorize phenomena in the microrealm. Also, she argues,  a philosophical foundation for quantum field theory must deal with their success in actual practice. The author assumes from the start that quantum field theory gives us knowledge of the microrealm, and answers to the questions of the meaning of objects in this realm can be found within the theory of quantum fields itself. And, even more refreshing, she states that quantum field theory still requires the assistance of common sense, in order to apply the theory and derive meaning from experimental data.<br /> The author has indeed done a fine job here, and has given the scientific and philosophical community a book that is an alternative to the usual philosophical standards. She describes and justifies a reality that humans can indeed understand via the framework of quantum field theory. This understanding takes place with concepts and constructions that might at first seem alien from a 'classical' perspective, but when one puts on the right epistemic glasses, things become clearer and the seemingly odd behavior in the microrealm becomes very natural and philosophically sound.amount of understanding into the subtleties of quantum field theory. In addition, the analysis that the author has given is a positive one for quantum field theory. She assumes the existence of what could be characterized as 'epistemic fixed points' (my words here) in our ability to categorize phenomena in the microrealm. Also, she argues,  a philosophical foundation for quantum field theory must deal with their success in actual practice. The author assumes from the start that quantum field theory gives us knowledge of the microrealm, and answers to the questions of the meaning of objects in this realm can be found within the theory of quantum fields itself. And, even more refreshing, she states that quantum field theory still requires the assistance of common sense, in order to apply the theory and derive meaning from experimental data. <br /> The author has indeed done a fine job here, and has given the scientific and philosophical community a book that is an alternative to the usual philosophical standards. She describes and justifies a reality that humans can indeed understand via the framework of quantum field theory. This understanding takes place with concepts and constructions that might at first seem alien from a 'classical' perspective, but when one puts on the right epistemic glasses, things become clearer and the seemingly odd behavior in the microrealm becomes very natural and philosophically sound.	2002-08-30
1428438:US	50702879	R2U5P88WWQET2C	0486656764	317863691	Topology (Dover Books on Mathematics)	Books	4	13	19	N	N	A good start	Very clearly written, full of examples and counterexamples, making use of pictures but never sacrificing rigor, the authors of this book have given students of topology a superb introduction to the field. Many students have been educated in topology by using this book, and it is sure to remain a classic in the field. It builds a solid understanding of the basic rudiments and intuition behind point-set, geometric, and algebraic topology. There is a lot of material covered in the book, and some very specialized subjects, such as Cech and Vietoris homology and some dimension theory, but with some preserverance and concentration, the entire book can be grasped within reasonable time constraints. Probably the only minus to the book is the lack of exercises. This is a quite serious omission, for the only way to master a subject is to work problems that require careful thought for their solution.<br /> The beginning student of topology should probably read this book with the following mindset: try to think of ways and techniques that you would devise to study the structure of a topological space. Homotopy and homology (in various forms) are the standard techniques for doing this. These strategies have varying degrees of success, but their use in topology now seems to be reaching a saturation limit, even though the explicit calculation of homotopy groups is still a very active area. New techniques and concepts, representing sort of a &quot;large deviation&quot; from the standard ones discussed in this book, will be needed to make further progress in the study of complicated topological spaces. Something more is needed now, that is completely different than homology and homotopy theory, that will make more transparent the properties of these spaces. These new techniques will be somewhat radical from the standpoint of current ones, but they will be more effective from a conceptual (and computational) point of view.	2002-08-27
1435249:US	50702879	R3WB0N0A4OIT1	0486670473	879699644	A Guide to Feynman Diagrams in the Many-Body Problem: Second Edition (Dover Books on Physics)	Books	5	25	27	N	N	Who says QFT is not fun to teach?	This book is a counterexample to the idea that one cannot write a book on quantum field theory and keep a sense of humour. Quantum field theory of course is notoriously difficult, both in terms of its conceptual foundations and in calculating meaningful answers from its formalism. Perturbation theory has been the most succesful of the methods of calculation in quantum field theory, and the visualization of the terms of the perturbation series is greatly assisted by the use of Feynman diagrams. The author has done a great job in the elucidation of these diagrams, and readers will not only have fun reading this book but will also take away needed expertise in moving on to more advanced presentations of quantum field theory. Some readers may object to the pictorial, playful way in which the author explains some of the concepts, but he does not depart from the essential physics. Mathematicians who want to understand quantum field theory can also gain much from the reading of this book. Although not rigorous from a mathematical standpoint, the presentation will given them sorely needed intuition. Quantum field theory has resulted in an explosion of very interesting results in mathematics, particularly in the field of differential topology, and mathematicians need this kind of a presentation to assist them in the understanding of quantum field theory and how to apply it to mathematics (and the other way around). In addition, readers intending to enter the field of condensed matter physics will appreciate the clarity of the author's treatment, drawing as it does on many examples from that field. This includes a brief introduction to finite temperature quantum field theory.<br /> The use of mnemonics, pictures, and hand-waving arguments may be frowned upon by some, but as long as their use is supported by solid science, their didactic power is formidable. Arguments by analogy, and by appeals to common-sense objects are of great utility in explaining the intricacies of a subject as abtruse as quantum field theory. The author for example uses a pin-ball game, with its many scatterings, as a tool for introducing the quantum propagator, even though paths of a (classical) pin-ball are not really meaningful in the quantum realm. Once done though, he proceeds to derive the perturbation series, and as an example computes the energy and lifetime of an electron in an impure metal.<br /> The concept of a quasi-particle is exploited fully in this book to illustrate just how one can do calculations in quantum many-body theory. The reader will find ample discussion of Dyson's equation, the random phase approximation, phase transitions in Fermi systems, the Kondo problem, and the renormalization group in this book.<br /> Happy reading.....(and teaching).....bject as abtruse as quantum field theory. The author for example uses a pin-ball game, with its many scatterings, as a tool for introducing the quantum propagator, even though paths of a (classical) pin-ball are not really meaningful in the quantum realm. Once done though, he proceeds to derive the perturbation series, and as an example computes the energy and lifetime of an electron in an impure metal. <br /> The concept of a quasi-particle is exploited fully in this book to illustrate just how one can do calculations in quantum many-body theory. The reader will find ample discussion of Dyson's equation, the random phase approximation, phase transitions in Fermi systems, the Kondo problem, and the renormalization group in this book. <br /> Happy reading.....(and teaching).....	2002-08-20
1437235:US	50702879	R1H5AL80CEFBWK	0914351087	718391766	Aspects of Topology	Books	5	10	10	N	N	Excellent for first-year graduate students	Emphasizing geometric topology, the authors have written an excellent introduction that is suitable for students of topology at the beginning graduate level. It would take two semesters to cover all of the material in the book, and there are lots of exercises and problems to challenge the reader's understanding. The main virtue of the book is that the authors do not hesitate to use pictures and diagrams to illustrate the concepts in topology.<br /> The first two chapters are an overview of elementary set theory and  beginning notions in topology, such as metric spaces, the product topology, etc. The authors assume that the reader has encountered these ideas before, and so they do not spend a lot of time explaining them. Calling one section a &quot;potpourri of fundamental concepts&quot; the authors define accumulation points, closure, etc. There are some interesting insights though that the authors give the reader, particularly in the discussion on homeomorphisms. They caution the reader, giving a pictorial example, that thinking of a homeomorphism as a stretching or deformation is a somewhat limited view. The example shows two objects that are homeomorphic but that cannot be deformed into each other in Euclidean 3-dimensional space.<br /> The next two chapters cover connectedness, compactness, and metric spaces. The authors show what pathologies can arise in the consideration of connectedness, challenging the reader to find an example of a space with an explosion point. They also define the notion of a chain, a concept that proves to be very useful in geometric topology. The authors motivate its eventual application very well, their construction beginning with an arbitrary &quot;entangled&quot; collection of open sets, out of which the chain is systematically selected. The famous Knaster-Kuratowski example is discussed. For readers interested in moving on to dimension theory, this example is important, in that it is a one dimensional set that is not totally disconnected. Separation properties are discussed in Chapter 4, and again reflecting their prejudice for geometric topology, the authors define and discuss absolute retracts and absolute neighborhood retracts.<br /> Things get very geometric in chapter 5, wherein topology of the Euclidean plane is discussed. The Jordan curve theorem is proved in detail, along with the Schoenflies theorem. The latter has to rank as one of the more amusing results in geometric topology, and its proof is a joy to construct. Then, in chapter 6, the authors return to the consideration of product spaces, and they also define and discuss inverse systems. An understanding of inverse systems is a must for readers intending to move on to algebraic topology. The dyadic solenoid, an important construction in the field of dynamical systems, is discussed geometrically and then shown to arise as an inverse limit.<br /> Considerations of a more analytic nature appear in chapter 7, which deals with function spaces, weak topologies, and Hilbert spaces. The compact-open topology, important in many area of application, is discussed as a topology that guarantees that a sequence of continuous functions converges to a continuous limit. The weak topology is introduced as a generalization of the free union topology, and its importance in the study of cell complexes is pointed out.<br /> The glueing and identification operations, so familiar from popular or more elementary expositions of topology, are discussed in chapter 8. These are the quotient spaces, and the authors discuss the cone and suspension of a space as examples. CW-complexes are then introduced and discussed in detail. This is followed in chapter 9 by a discussion of one of the most important of all topological spaces: continua. The Peano continua in the light of the Hahn-Mazurkiewicz are overviewed.<br /> If the reader has studied differential geometry, then chapter 10 will be somewhat familiar, as it deals with paracompactness and partitions of unity, the later of which are used extensively to perform some very standard constructions in the theory of differentiable manifolds. Metrizability is also discussed, and the authors give an example of a Moore space that is not metrizable.<br /> Chapter 11 gives an alternative view of convergence, wherein the authors discuss nets and filters. The pathologies that can arise for sequences in non-metric spaces are emphasized. Filters may be familiar for the reader who has studied mathematical logic, where they are used extensively.<br /> Things heat up in chapter 12, wherein readers get to indulge in the intricacies of algebraic topology, a topic that has been hinted at in a few places in the first eleven chapters. Homotopy theory and the fundamental group make their appearance, as well as the notion of a direct limit. The higher homotopy groups are introduced in the problem sets. The reader versed in algebra will certainly appreciate this chapter, as well as the next one, which deals with covering spaces, which the authors mention is a topological analog of Galois coverings. Covering spaces allow the computation of the fundamental group, as well as being useful in many other applications.<br /> Simplicial topology is introduced in chapter 14 as objects that have a local linear structure, and can thus be studied much more easily than more general types  of spaces. Most readers will catch on very quickly to this category of spaces, due to its connection with notions from plane and solid geometry, and linear algebra. The simplicial approximation of maps is emphasized, with an elementary example of a continuous map that cannot be simplicially approximated given. A hint of the field of simple homotopy theory is given in the problem section, with the famous Bing's house with two rooms discussed.<br /> The last 3 chapters of the book discuss applications of homotopy theory, a brief introduction to knot theory, wild sets, the classification theorem for 2-manifolds (which is proven in detail), and a brief introduction to n-dimensional manifolds. The authors discuss briefly the attempts to generalize the 2-D classification to 3-D, one being finding a proper generalization of the normal form, another being the removal of a maximal open 3-cell from the 3-manifold to obtain the \\"spine\\". The famous Poincare conjecture is related to these issues.f unity, the later of which are used extensively to perform some very standard constructions in the theory of differentiable manifolds. Metrizability is also discussed, and the authors give an example of a Moore space that is not metrizable. <br /> Chapter 11 gives an alternative view of convergence, wherein the authors discuss nets and filters. The pathologies that can arise for sequences in non-metric spaces are emphasized. Filters may be familiar for the reader who has studied mathematical logic, where they are used extensively. <br /> Things heat up in chapter 12, wherein readers get to indulge in the intricacies of algebraic topology, a topic that has been hinted at in a few places in the first eleven chapters. Homotopy theory and the fundamental group make their appearance, as well as the notion of a direct limit. The higher homotopy groups are introduced in the problem sets. The reader versed in algebra will certainly appreciate this chapter, as well as the next one, which deals with covering spaces, which the authors mention is a topological analog of Galois coverings. Covering spaces allow the computation of the fundamental group, as well as being useful in many other applications. <br /> Simplicial topology is introduced in chapter 14 as objects that have a local linear structure, and can thus be studied much more easily than more general types  of spaces. Most readers will catch on very quickly to this category of spaces, due to its connection with notions from plane and solid geometry, and linear algebra. The simplicial approximation of maps is emphasized, with an elementary example of a continuous map that cannot be simplicially approximated given. A hint of the field of simple homotopy theory is given in the problem section, with the famous Bing's house with two rooms discussed. <br /> The last 3 chapters of the book discuss applications of homotopy theory, a brief introduction to knot theory, wild sets, the classification theorem for 2-manifolds (which is proven in detail), and a brief introduction to n-dimensional manifolds. The authors discuss briefly the attempts to generalize the 2-D classification to 3-D, one being finding a proper generalization of the normal form, another being the removal of a maximal open 3-cell from the 3-manifold to obtain the \\"spine\\". The famous Poincare conjecture is related to these issues.	2002-08-18
1439618:US	50702879	R37FWL9OAPAY4N	0486679667	350078283	A Combinatorial Introduction to Topology (Dover Books on Mathematics)	Books	5	30	30	N	N	A good start	Historically, combinatorial topology was a precursor to what is now the field of algebraic topology, and this book gives an elementary introduction to the subject, directed towards the beginning student of topology or geometry. Due to its importance in applications, the physicist reader who is intending eventually to specialize in elementary particle physics will gain much in the perusal of this book.<br /> Combinatorial topology can be viewed first as an attempt to study the properties of polyhedra and how they fit together to form more complicated objects. Conversely, one can view it as a way of studying complicated objects by breaking them up into elementary polyhedral pieces. The author takes the former view in this book, and he restricts his attention to the study of objects that are built up from polygons, with the proviso that vertices are joined to vertices and (whole) edges are joined to (whole) edges.<br /> He begins the book with a consideration of the Euler formula, and as one example considers the Euler number of the Platonic solids, resulting in a Diophantine equation. This equation only has five solutions, the Platonic solids. The author then motivates the concept of a homeomorphism (he calls them &quot;topological equivalences&quot;) by considering topological transformations in the plane. Using the notion of topological equivalence he defines the notions of cell, path, and Jordan curve. Compactness and connectedness are then defined, along with the general notion of a topological space.<br /> Elementary notions from differential topology are then considered in chapter 2, with the reader encountering for the first time the connections between analysis and topology, via the consideration of the phase portraits of differential equations. Brouwer's fixed point theorem is proved via Sperner's lemma, the latter being a combinatorial result which deals with the labeling of vertices in a triangulation of the cell. Gradient vector fields, the Poincare index theorem, and dual vector fields,  which are some elementary notions in Morse theory, are treated here briefly.<br /> An excellent introduction to some elementary notions from algebraic topology is done in chapter 3. The author treats the case of plane homology (mod 2), which is discussed via the use of polygonal chains on a grating in the plane. Beginning students will find the presentation very understandable, and the formalism that is developed is used to give a proof of the Jordan curve theorem. Then in chapter 4, the author proves the classification theorem for surfaces, using a combinatorial definition of a surface.<br /> The author raises the level of complication in chapter 5, wherein he studies the (mod 2) homology of complexes. A complex is defined somewhat loosely as a topological space that is constructed out of vertices, edges, and polygons via topological identification. He proves the invariance theorem for triangulations of surfaces by showing that the homology groups of the triangulation are same as the homology groups of the plane model of the surface. This is an example of the invariance principle, and the author briefly details some of the history of invariance principles, such as the Hauptvermutung, its counterexample due to the mathematician John Milnor, and Heawood's conjecture, the latter of which deals with the minimum number of colors needed to color all maps on a surface with a given Euler characteristic. Integral homology is also introduced by the author, and he shows the origin of torsion in the consideration of the &quot;twist&quot; in a surface.<br /> In the last part of the book, the author returns to the consideration of continuous transformations, tackling first the idea of a universal covering space. Algebraic topology again makes its appearance via the consideration of transformations of triangulated topological spaces, i.e. simplicial transformations. He shows how these transformations induce transformations in the homology groups,thus introducing the reader to some notions from category theory. The elaboration of the invariance theorem for homology leads the author to studying the properties of the group homomorphisms via matrix algebra, and then to a proof of the Lefschetz fixed point theorem. The book ends with a brief discussion of homotopy, topological dynamics, and alternative homology theories.<br />  The beginning student of topology will thus be well prepared to move on to more rigorous and advanced treatments of differential, algebraic, and geometric topology after the reading of this book. There are still many unsolved problems in these areas, and each one of these will require a deep understanding and intuition of the underlying concepts in topology. This book is a good start.thus introducing the reader to some notions from category theory. The elaboration of the invariance theorem for homology leads the author to studying the properties of the group homomorphisms via matrix algebra, and then to a proof of the Lefschetz fixed point theorem. The book ends with a brief discussion of homotopy, topological dynamics, and alternative homology theories.<br />  The beginning student of topology will thus be well prepared to move on to more rigorous and advanced treatments of differential, algebraic, and geometric topology after the reading of this book. There are still many unsolved problems in these areas, and each one of these will require a deep understanding and intuition of the underlying concepts in topology. This book is a good start.	2002-08-16
1445850:US	50702879	R2AWLY9ORWN0NX	3540570179	56600024	Deterministic Chaos in Infinite Quantum Systems (Trieste Notes in Physics)	Books	5	2	2	N	N	Excellent job	The theory of C*- and W*-algebras is an extensive one, and some of its results are applied here to study the properties of infinite quantum systems, with particular attention paid to the ergodicity of such systems. The author attempts to take notions from the ordinary measure-theoretic, &quot;classical&quot; theory of ergodicity and apply them to the case of quantum systems. The occurrence of chaos in classical systems is of course well-defined from a mathematical standpoint, and a natural question to ask is whether chaos can occur in quantum systems. At first thought, one might be tempted to assert that it cannot, due to the linearity and unitary of the time evolution in quantum physics. In addition, the non-commutativity of the observables in quantum systems makes a straightforward generalization  of the commutative classical situation nontrivial.<br /> There are a few ways of viewing chaos in the classical context, one being the notion of &quot;differentiable&quot; dynamics, and one being &quot;topological&quot; dynamics. The former is more related to the accepted physical notion of chaos, while the latter is more atune to the interest of the mathematician. Another one is measure-theoretic, and fits the needs of both the physicist and the mathematician, the former in the realm of statistical mechanics, and the latter in the study of measure-preserving transformations. All of these viewpoints do have an intersection however, and all are necessary to form a more complete viewpoint of what it means for a time evolution of a system to be chaotic or random in some way. The field of quantum chaos is still an active one, and there is as of this date no definition of it that is acceptable to everyone, both physicists and mathematicians.<br /> This book is a helpful guide to the research in this area, and is fairly up-to-date, in spite of being almost ten years old. The first couple of chapters concentrate on casting classical ergodic theory in the C*- and W*-algebra frameworks. The treatment though is physically motivated, and the author is careful in his definitions and mathematical proofs. He also gives the reader insight as to why infinite systems are needed in the study of chaos, such as the case of a harmonic oscillator in a heat bath. Quasi-periodicity, characteristic of finite systems without a continuous spectrum, would destroy the exponential decay of the correlation functions if the heat bath were not infinite. The author also points out the difference between Bernoulli and K-systems, showing that the Kolomogorov-Sinai entropy is not a complete invariant for K-systems but it is for Bernoulli systems. Topological entropy, not so useful for the physicist but of great use for the mathematician, is discussed in detail. Classical dynamical systems are thought of as abelian C*-algebras with the time evolution modeled by the Z-action of a *automorphism of the algebra. To study the ergodic properties in this context requires the use a normalized state that is invariant under the *automorphism. The author also gives an interesting motivation for the need for W*-algebras. He starts with the Baker map, views it as a 2-dimensional Ising model, its index functions arising from a chessboard lattice. Taking finer and finer chessboard lattices gives an abelian C*-algebra, but using the norm topology results in the C*-algebra being too small. Representing this C*-algebra as a multiplication operators on the Hilbert space of square-integrable functions results in an algebra that is strongly and weakly closed on this Hilbert space, i.e. a W*-algebra.<br /> The remainder of the book deals with the problem of ergodicity and chaos in infinite quantum systems and the corresponding mathematical problems that arise in this context. Some of the more important of these include the generalization to infinite dimensions of the fact that in finite dimensions the algebra of observables always has a representation equivalent to the Fock representation.This generalizes to the Gelfand-Naimark-Segal construction in infinite dimensions, which is unique modulo a unitary map. Another notion that breaks down in infinite dimensions is the Gibbs state, which must be replaced by that of a KMS state. In addition, states on (finite-dimensional) matrix algebras, which satisfy the modular relations at inverse temperature ( = 1), have their generalization to the (infinite-dimensional) W*-algebra case via the Tomita-Takesaki theorem. The author studies some toy models and bosonic and fermionic systems, one interesting one being the non-commutative 2-torus, which gives an algebraic formulation of the quantum Hall effect. For fermionic systems, one sees clearly the effects of noncommutativity in preventing strong topological mixing: they induce correlations that cannot be suppressed in the time evolution of the system.<br /> In addition, the author investigates whether Kolmogorov entropy is meaningful in the noncommutative context. The role of quantum K-systems is particularly interesting here, as they are defined so as to not have quasi-periodicity in their dynamics. The noncommutative Arnold cat map is given as an example of a quantum K-system. The Connes-Narnhofer-Thirring entropy is offered as a generalization of Kolmogorov entropy. The author discusses the problem as a consequence of the difficulty in generalizing the ordinary classical probabilistic notions to this case, since states can be changed when the observable is measured. And as everyone who has to work with the time evolution of operators in say, the Heisenberg picture, noncommutativity can generate more operators. This aggravates the situation considerably in the attempt to carry over classical ergodic theory to the noncommutative case. The existence of quantum correlations causes even more headaches. The solution due to CNT is to start with finite collections of finite dimensional algebras, and construct an entropy functional on them that respects as many of the properties of the classical entropy as possible. This functional is defined in terms of \\"Abelian models\\" of these algebras, these being finite dimensional Abelian algebras along with a state and a positive map that when composed with the state gives the state of the original algebra. The resulting CNT-entropy is applied to the case of quasi-free automorphisms and the author then ends the book with a proposal for a noncommutative topological entropy.n. This generalizes to the Gelfand-Naimark-Segal construction in infinite dimensions, which is unique modulo a unitary map. Another notion that breaks down in infinite dimensions is the Gibbs state, which must be replaced by that of a KMS state. In addition, states on (finite-dimensional) matrix algebras, which satisfy the modular relations at inverse temperature ( = 1), have their generalization to the (infinite-dimensional) W*-algebra case via the Tomita-Takesaki theorem. The author studies some toy models and bosonic and fermionic systems, one interesting one being the non-commutative 2-torus, which gives an algebraic formulation of the quantum Hall effect. For fermionic systems, one sees clearly the effects of noncommutativity in preventing strong topological mixing: they induce correlations that cannot be suppressed in the time evolution of the system.<br /> In addition, the author investigates whether Kolmogorov entropy is meaningful in the noncommutative context. The role of quantum K-systems is particularly interesting here, as they are defined so as to not have quasi-periodicity in their dynamics. The noncommutative Arnold cat map is given as an example of a quantum K-system. The Connes-Narnhofer-Thirring entropy is offered as a generalization of Kolmogorov entropy. The author discusses the problem as a consequence of the difficulty in generalizing the ordinary classical probabilistic notions to this case, since states can be changed when the observable is measured. And as everyone who has to work with the time evolution of operators in say, the Heisenberg picture, noncommutativity can generate more operators. This aggravates the situation considerably in the attempt to carry over classical ergodic theory to the noncommutative case. The existence of quantum correlations causes even more headaches. The solution due to CNT is to start with finite collections of finite dimensional algebras, and construct an entropy functional on them that respects as many of the properties of the classical entropy as possible. This functional is defined in terms of \\"Abelian models\\" of these algebras, these being finite dimensional Abelian algebras along with a state and a positive map that when composed with the state gives the state of the original algebra. The resulting CNT-entropy is applied to the case of quasi-free automorphisms and the author then ends the book with a proposal for a noncommutative topological entropy.	2002-08-10
1446142:US	50702879	RKM1UFTH2OELG	9971950839	314747766	Elementary Primer For Gauge Theory, An	Books	3	34	43	N	N	Pre W- and Z-boson book	Although published in 1983, this book predates the discoveries made at CERN of the intermediate vector bosons. This discovery coupled with the discovery of weak neutral currents more than a decade before, solidified the role of gauge theories in providing a unified theory of elementary particle interactions. The author does a fine job of introducing the history of gauge theory, and also its conceptual foundations, emphasizing the physics, and not the mathematical formalism.<br /> In the book, the Einstein theory of gravitation is explained, naturally, as the first successful gauge theory, the local coordinates of which can be defined as the gravitational field. This, the author explains, movtivated H. Weyl to generalize this to one of the other forces of nature, namely electromagnetism. Weyl needed a quantity that would transform like the electromagnetic potential under changes of position. For this he chose to assert that the norm of a physical vector should depend on position (i.e. a change of \\"scale\\"), and thus to compare lengths at different places in space-time one needs a connection. This connection did transform like a vector potential and thus gave Weyl what he needed. His theory was rejected however by Einstein and Bergmann, and many others. The soundest of their objections was based on an argument from quantum theory, namely that a natural scale involving the particle's wavelength is characteristic of the quantum theory, and the wavelength is dependent on mass, which cannot depend on position.<br /> The author also overviews the role of gauge invariance in the Hamilton-Jacobi formulation of electromagnetic theory. The inclusion of this discussion is rare in books and articles written on gauge theory at the time of this one (or before), but it does serve to motivate nicely the place that gauge invariance holds in the quantum theory of electromagnetism. In this context, the Aharonov-Bohm effect is discussed, and asserted to be proven experimentally. This is a controversial assertion however, and the one can say without any mental reservations that after a thorough study of the literature on the experiments studying this effect, that they are inconclusive as of this date.<br /> In addition, the author discusses the reasons that gauge invariance took so long to be accepted by the physical community. In the quantum realm, one of these reasons, he argues, is due to the fact that gauge transformations were related to the phase of the wavefunction, and not to coordinates in space-time. The latter geometric view was thus missing from the concept of gauge invariance in quantum physics. In addition, the gauge group did not seem to play a role in the dynamics of the quantum theory, it merely being a sort of ancillary property that had no predictive power.<br /> Such beliefs ended of course with the rise of Yang-Mills theories, but the road to acceptance of Yang-Mills gauge theories was not a smooth one. It took many years before the non-renormalizability of these theories was worked out. In the meantime, mathematicians were becoming more attracted to the study of gauge theories, and the formulation of gauge theories from a mathematically rigorous point of view was gaining major advances, excluding the path integral quantization of these theories, which to this date, has defied a mathematically rigorous treatment. The author details well the development of gauge theories from the paper of Yang-Mills, up until the time of the book's publication. The Weinberg-Salam theory and its triumph in the prediction of neutral currents is oultined, and a brief introduction is given to quantum chromodynamics, the gauge theory of the strong interaction. The Weinberg-Salam theory was further solidified in the early eighties due to the experimental evidence for intermediate vector bosons.<br /> That gauge theores are successful in predicting elementary particle phenomena has now become a cliche. There is still of course an enormous amount of workto be done, particularly from the standpoint of the calculation of quantities in low-energy strong-interaction physics, and the prediction of bound states using quantum gauge field theories. Superstring and M-theories have supplanted a lot of the research in gauge theories, this research also involving the mathematical community to a large degree. Indeed, Weyl, Einstein, Yang, and Mills would no doubt be astonished at the level of mathematics now being used in these theories. The mathematical constructions used in their theories was considered esoteric at the time, but it pales in comparison to the dizzying heights that mathematics has been taking in superstring and M-theories. These developments are very exciting and one can probably say with a fair degree of confidence that the role of gauge theory will remain in research in high energy physics in the 21st century.work to be done, particularly from the standpoint of the calculation of quantities in low-energy strong-interaction physics, and the prediction of bound states using quantum gauge field theories. Superstring and M-theories have supplanted a lot of the research in gauge theories, this research also involving the mathematical community to a large degree. Indeed, Weyl, Einstein, Yang, and Mills would no doubt be astonished at the level of mathematics now being used in these theories. The mathematical constructions used in their theories was considered esoteric at the time, but it pales in comparison to the dizzying heights that mathematics has been taking in superstring and M-theories. These developments are very exciting and one can probably say with a fair degree of confidence that the role of gauge theory will remain in research in high energy physics in the 21st century.	2002-08-10
1446556:US	50702879	R3KPOZD6BY2EZ3	0387908927	856013487	Topology (Undergraduate Texts in Mathematics)	Books	5	29	30	N	N	Students: BUY THIS BOOK!!!	It is not too often that a book about topology is written with the goal of actually explaining in detail what is going on behind the formalism. The author does a brilliant job of teaching the reader the essential concepts of point set topology, and the book is very fun to read. The reader will walk away with an appreciation of the idea that topology is just not abstract formalism, but has an underlying intuition that is rich in imagery. The author has a knack for allowing readers to \\"see into the future\\" of what kind of mathematics is waiting for them and how topology is indispensable in its study.<br /> At the end of chapter three, which deals with the quotient topology, the author writes the following paragraph: \\"If is often said against intuitive, spatial argumentation that it is not really argumentation but just so much gesticulation - just 'handwaving'. Shall we then abandon all intuitive arguments? Certainly not. As long as it is backed by the gold standard of rigorous proofs, the paper money of gestures is an invaluable aid for quick communication and fast circulation of ideas. Long live handwaving!\\". This has to rank as one of the best paragraphs that has every appeared in a mathematics book, for it nicely summarizes the need for developing a feel for the concepts behind mathematics before moving on to the rigorous proofs. Physicists in particular, who must assimilate mathematics very quickly in order to apply it to real problems must have a pictorial, \\"playful\\" understanding of the mathematical constructions.<br /> Thus the language that the author employs is informal, and a listing of the best discussions in the book would really entail a listing of every one in the book. There is not one part of the book that is not helpful or interesting, and the author delves into many different areas that involve the use of topology.<br /> If you are a beginning student in mathematics, BUY AND STUDY THIS BOOK...BUY AND STUDY THIS BOOK. You will take away so much for the price paid.the price paid.	2002-08-09
1446637:US	50702879	R13C7ZDC44C9F7	0486670201	617679159	Mathematical Methods and Theory in Games, Programming, and Economics: Vol 1 : Matrix Games, Programming, and Mathematical Economics/Vol 2 : The Theo	Books	3	7	7	N	N	Considerably out of date but still can be useful	This book was first published in 1959, and as such does not reflect the large number of significant results in game theory that have taken place since then. At the time of publication, the theory of Nash equilibria was known but had not yet taken hold, the role of artificial intelligence in the theory of games was yet to unfold, and computer simulations were just beginning to be used to understand optimal strategies in games. These concepts and the computer now play a major role in game theory, and a modern book would reflect these developments more than this one.<br /> That being said, one still might peruse this book to get an idea of the history of game theory and possibly to appreciate the conceptual situation that existed at the time of publication. Frequently older books in mathematics stress more of the underlying intuition behind a subject than modern ones. Thus one could justify a reading of this book with this in mind, and possibly use it also as a reference and as a source of problem sets for those individuals teaching game theory in the classroom.<br /> The book treats what is now called &quot;classical&quot; game theory, which is taken to be the time before the contributions of John Nash circa 1950-1953. The research in game theory in the classical period was dominated by the results of J. Von Neumann, O. Morgenstern, H.Kuhn, A. Tucker, and many researchers in the Rand Corporation. The mathematical techniques used were primarily drawn from linear algebra, analysis, and linear and nonlinear programming. Economic modeling, military strategies, and management problems provided the stimulus to this research. Indeed, mathematical economics has one of its roots in game theory. The very early work in game theory by James Waldegrave in the 1700s and Augustin Cournot in the 1800s is not discussed by the author. The work by Cournot on duopolies could be considered to be a version of Nash equilibrium.<br /> The book is divided into two parts, with the first one treating matrix games, linear and nonlinear programming and mathematical economics, and the second the theory of infinite games. My interest in the book stemmed from being asked to look at a mathematical formulation of poker. The game of poker is considered by the author in a few places in the book, both in the context of discrete games and in infinite games. The case of infinite games is particularly interesting in that it involves the use of integral equations and fixed-point theorems.<br /> Some of the more esoteric techniques from mathematics used in the book include a few from algebraic topology: the Brouwer and Kakutani fixed-point theorems; from real analysis: the Haar measure, which comes into play when considering the invariance of optimal strategies under the action of a compact transformation group (the idea of weak* convergence also is used here), and the Fourier transform, which appears in the consideration of bell-shaped kernels for infinite games.<br /> Some of the major results in classical game theory that are proved in the book are: the Kuhn-Tucker theorem of nonlinear (concave) programming (and an example dealing with portfolio selection), the duality theorem for both linear and nonlinear programming (a connection with the law of supply and demand is discussed), the von Neumann model of an expanding economy (this gives an excellent introduction to dynamical modeling in economics),and a fairly lengthy overview of equilibrium in economics and its stability. In modern treatments this is best done using the techniques of differential topology. The author's treatment can be viewed as an elementary introduction to the more modern treatments.e treating matrix games, linear and nonlinear programming and mathematical economics, and the second the theory of infinite games. My interest in the book stemmed from being asked to look at a mathematical formulation of poker. The game of poker is considered by the author in a few places in the book, both in the context of discrete games and in infinite games. The case of infinite games is particularly interesting in that it involves the use of integral equations and fixed-point theorems.   <br /> Some of the more esoteric techniques from mathematics used in the book include a few from algebraic topology: the Brouwer and Kakutani fixed-point theorems; from real analysis: the Haar measure, which comes into play when considering the invariance of optimal strategies under the action of a compact transformation group (the idea of weak* convergence also is used here), and the Fourier transform, which appears in the consideration of bell-shaped kernels for infinite games. <br /> Some of the major results in classical game theory that are proved in the book are: the Kuhn-Tucker theorem of nonlinear (concave) programming (and an example dealing with portfolio selection), the duality theorem for both linear and nonlinear programming (a connection with the law of supply and demand is discussed), the von Neumann model of an expanding economy (this gives an excellent introduction to dynamical modeling in economics),and a fairly lengthy overview of equilibrium in economics and its stability. In modern treatments this is best done using the techniques of differential topology. The author's treatment can be viewed as an elementary introduction to the more modern treatments.	2002-08-09
1456673:US	50702879	R31M2NJ0T3JFU6	0471569526	212903835	Quantum Mechanics (2 vol. set)	Books	5	53	57	N	N	The best out there	The authors, well-known contributors to the field of quantum optics, have given in these 2 volumes probably the best overview of quantum mechanics at the first-year graduate level. Having used these books both as a graduate student and as a lecturer, I have found that there are not too many things in the book that I find in any way troubling. The only minus might be the number of exercises: there are really not enough that are representative of the concepts covered in the book. Also, there is no discussion of entanglement of states, this reflecting more than anything the date of publication. Entanglement has grown in importance in recent years due to the intense research in quantum computation. The inclusion of a discussion of entanglement would still be justified even though it was not an immensely popular topic at the time of writing.<br /> The first volume covers in detail the mathematical formalism of quantum mechanics along with its physical motivation, the latter given in the first chapter. And, both in this volume and the second, the authors include a large set of &quot;complements&quot; to each chapter. All of them are very well-written and instructors can fine tune the course using them as needed or as time permits. The treatment of the tensor product of state spaces is especially well done, and the authors give a physical example of its use via the two-dimensional infinite well. Chapter 3 is a very long and absorbing overview of the physical foundations of quantum mechanics. The authors introduce the concept of an 'insufficiently selective measurement device', not found in other textbooks on quantum mechanics, and one that can be integrated easily into discussions of the foundations of quantum mechanics. In the complements to this chapter, the reader will find a sound presentation of gauge invariance in quantum mechanics and a brief overview of the path integral approach to quantization. Due to its importance in quantum field theory, the latter could perhaps be expanded into an entire chapter if a future edition of this book is written. The authors also include a discussion of the physics of a particle in a periodic potential, paving the way for a later course in condensed matter physics. A thorough presentation of the harmonic oscillator is included in Chapter 5 of this volume, and the authors include an elementary discussion of the quantization of the electromagnetic field in a complement to this chapter. And, again anticipating a later study of condensed matter physics, the reader is introduced to the physics of an infinite set of coupled harmonic oscillators, i.e. the physics of phonons. Atomic physics of course is not forgotten by the authors, as they spend an entire chapter on the central potential, and include several excellent complements on atomic orbitals and diatomic molecules. The physics and mathematics of angular momenta in quantum physics is discussed in chapter six, as preparation for the more detailed treatment of spin systems in volume 2.<br /> The authors begin volume 2 with a brief treatment of scattering theory, concentrating mostly on the scattering off a central potential. The authors continue the discussion of angular momenta begun in volume 1 and here show the reader how to deal with the addition of angular momenta. Clebsch-Gordon coefficients, spherical harmonics, and the Wigner-Eckhart theorem are treated in detail.<br /> No doubt the most important topic that the authors treat in these two volumes is on perturbation theory, for it is the calculation of cross sections and other physically relevant quantities and their comparison with experiment that give quantum mechanics its ultimate validity as a physical theory. Chapters 11 and 12 on stationary perturbation theory and the fine and hyperfine structure of the hydrogen atom serve as a good introduction to the methods of perturbation theory. The use of numerical methods and the computer is of course the favored method of calculation these days, and will remain throughout the 21st century. As more powerful machines are built and more sophisticated algorithms are developed, more problems in quantum physics of a nonperturbative nature will be tackled, allowing greater insight into and perhaps changes to quantum mechanics.days, and will remain throughout the 21st century. As more powerful machines are built and more sophisticated algorithms are developed, more problems in quantum physics of a nonperturbative nature will be tackled, allowing greater insight into and perhaps changes to quantum mechanics.	2002-07-31
1460540:US	50702879	R1UNTHY41XDIXD	0691029776	892636044	The Dawning of Gauge Theory	Books	5	5	5	N	N	A sorely needed book	Once thought of as merely a mathematical curiosity, the concept of gauge invariance now plays the dominant role in theoretical particle physics. Gauge invariance is not a really difficult concept in which to understand, but it does have some hidden subtleties that can seem rather obscure in the context of modern quantum field theories. The reader of this book will walk away with a deeper appreciation of the history of gauge invariance, due to the inclusion of original articles written by some of the early contributors to the theory. These contributions were attempts to generalize Einstein's theory of gravitation, and, just as in that theory, made use of concepts from differential geometry. Ideas from the mathematical theory of groups were also used, setting the stage for later developments in particle physics. One can only wonder of course what these individuals would have thought about modern theories of gravitation and particle interactions, making use of highly esoteric and complex mathematical constructions. Their thinking at the time was itself thought of as very exotic, but it pales in comparison with the level of abstraction that now permeates elementary particle physics in the language of superstring and M-theory.<br /> The author has written additional papers on the history of gauge theory,which can easily be found via an online search, and this book could be considered an excellent introduction to them. He addresses more modern developments in gauge theories as they relate to the early history, such as superstring theory. Readers who study this book, will not only come away with a deeper appreciation of the underlying concepts in gauge theory, but will be prepared to appreciate in greater detail these modern developments, being as they are the best current hope for understanding the nonperturbative region in quantum field theories and string theories.	2002-07-28
1461108:US	50702879	R1FDPCM1AXC05P	0818672005	910897466	Mathematical Methods in Artificial Intelligence	Books	5	20	20	N	N	Excellent	Although using only elementary mathematics, and not at all addressing new areas of artificial intelligence, such as inductive logic programming, this book gives an excellent overview of how mathematics is used in artificial intelligence. Mathematics at all levels is used in this field, both in the algorithms and in discussing its foundations, and this book serves as a good introduction to its application in A.I. Only elementary algebra and calculus are used in the book, making it very accessible to the beginning student in computer science. Readers with more sophisticated background in mathematics can then extend the results in the book to more advanced mathematical contexts. The author's writing style is very informal, and in many places in the book he encourages the reader to &quot;stop and think&quot; before continuing in the reading. Exercises, some simple and some very challenging, are found at the end of most chapter sections.<br /> The author gives a brief overview of the history of A.I. in chapter one, including a discussion of the issues of computational complexity in A.I. algorithms, a discussion of expert systems (with examples), and a few biographical sketches.<br /> Chapter 2 is a fairly detailed overview of search algorithms, and the author introduces some notions from the mathematical field of combinatorics, namely directed graphs and ordered trees. Induction and recursion are then reviewed as tools for search algorithms. The recursive formulation of algorithms in A.I. is of course very powerful, and one that students need to master early on. Fields such as bioinformatics and data mining are becoming increasingly dependent on search algorithms from A.I., and the author reviews these in detail, including 'simple' search methods such as breadth-first, depth-first, and iterative-deepening, along with 'heuristic' methods.<br /> The reader gets introduced to first-order predicate calculus in chapter 3. This topic could be said to be one of the most important ones in A.I., and it is discussed in this chapter using the (declarative) programming language Prolog. One could easily use the language Lisp, but Prolog makes more apparent the head/body clause structure of predicate logic. In addition, if a reader wants to move on to more modern developments in A.I., such as inductive logic programming, which can be viewed essentially as predicate logic but with inductive reasoning, a mastery of the content of this chapter is essential.<br /> Chapter 4 introduces the reader to the proof theory, namely the technique of resolution, which is discussed for propositional calculus, where it is very simple, and for predicate logic, in the latter wherein some specialized techniques must be brought in, such as Skolemization. The author also discussed proof in the context of Prolog, and introduces the cut operator, which inhibits Prolog from fully implementing resolution. He also gives an interesting discussion on the problem of negation in Prolog and the closed-world assumption.<br /> The author has been careful to not write a purely theoretical book in computer science, and evidence of this is given in chapter 5, which discusses how to implement first-order logic (FOL) into real-world applications. It is one thing to discuss the properties of logic, quite another to actually use it productively to solve problems of interest. The author discusses the limitations of FOL in these applications, and how they can be resolved through alternative reasoning tools, such as nonmonotonic logics, Bayesian networks, and fuzzy sets.<br /> One of these alternatives, nonmonotonic reasoning, is discussed in the next chapter, wherein the author gives a fairly detailed overview of default reasoning and how it is implemented in Prolog. Rule sets and semantic nets are also discussed, along with defeasible reasoning. Applications of these techniques are stymied by their computational complexity, and the author gives references for discussions of this.<br />After a review of probability theory in chapter 7, the author discusses Bayesian networks in chapter 8. These have been extremely important in recent applications of A.I., and the author gives a fine review of their properties, especially their ability to incorporate causality by imposing a directed graph structure on the event space. The author gives a few examples of Bayesian networks, including a medical diagnosis, wherein he introduces a very important concept in A.I., namely that of abductive inference. Detailed discussion (with proofs) is given for the Kim-Pearl algorithm for singly connected networks.<br /> Chapter 9 is an introduction to fuzzy logic and belief theory. The author motivates nicely the reasons for considering fuzzy reasoning instead of probabilistic methods. The Dempster-Shafer belief theory, which has become popular in recent years, is also discussed in some detail.<br /> So as to motivate the discussion of neural networks, the next chapter overviews automatic pattern classification. Contrasting between supervised and unsupervised learning of patterns, the author then outlines the types of automatic classifiers, such as decision trees and neural networks. The chapter on neural networks is a good introduction considering the vastness of the subject. Indeed, an enormous amount of research has been done on neural networks, and their use in applications of A.I. has finally been achieving success in recent years.<br /> Concepts from information theory are of course very important in A.I. and these are discussed in chapter 12, along with more advanced topics in probability and statistics that were not treated earlier in the book. These ideas are used in the next chapter wherein neural networks and decisions trees are discussed in more detail. The most interesting part of this discussion is the idea that noise can improve the generalization capabilities of neural networks. This strategy will be obvious to the physicist reader who has studied the effects of noise on dynamical systems governed by potentials with local minima.<br /> The last chapter of the book discusses some additional topics that should be included in a study of A.I., such as genetic algorithms and more discussion of optimization, such as simulated annealing. Hidden Markov models are also briefly discussed, and this is somewhat disappointing given their importance in current applications. The reader is also introduced to robotics, certainly the most exciting of all topics in 21st century A.I.<br /> After a review of probability theory in chapter 7, the author discusses Bayesian networks in chapter 8. These have been extremely important in recent applications of A.I., and the author gives a fine review of their properties, especially their ability to incorporate causality by imposing a directed graph structure on the event space. The author gives a few examples of Bayesian networks, including a medical diagnosis, wherein he introduces a very important concept in A.I., namely that of abductive inference. Detailed discussion (with proofs) is given for the Kim-Pearl algorithm for singly connected networks. <br /> Chapter 9 is an introduction to fuzzy logic and belief theory. The author motivates nicely the reasons for considering fuzzy reasoning instead of probabilistic methods. The Dempster-Shafer belief theory, which has become popular in recent years, is also discussed in some detail. <br /> So as to motivate the discussion of neural networks, the next chapter overviews automatic pattern classification. Contrasting between supervised and unsupervised learning of patterns, the author then outlines the types of automatic classifiers, such as decision trees and neural networks. The chapter on neural networks is a good introduction considering the vastness of the subject. Indeed, an enormous amount of research has been done on neural networks, and their use in applications of A.I. has finally been achieving success in recent years. <br /> Concepts from information theory are of course very important in A.I. and these are discussed in chapter 12, along with more advanced topics in probability and statistics that were not treated earlier in the book. These ideas are used in the next chapter wherein neural networks and decisions trees are discussed in more detail. The most interesting part of this discussion is the idea that noise can improve the generalization capabilities of neural networks. This strategy will be obvious to the physicist reader who has studied the effects of noise on dynamical systems governed by potentials with local minima. <br /> The last chapter of the book discusses some additional topics that should be included in a study of A.I., such as genetic algorithms and more discussion of optimization, such as simulated annealing. Hidden Markov models are also briefly discussed, and this is somewhat disappointing given their importance in current applications. The reader is also introduced to robotics, certainly the most exciting of all topics in 21st century A.I.	2002-07-27
1468729:US	50702879	R19LFAXLO9DR4R	0132641437	207304337	Elements of Differential Geometry	Books	5	19	22	N	N	A solid introduction	It is hard to disagree with the idea that one must pursue the learning of mathematics in way that might be at odds with its axiomatic structure. One can pursue the study of differentiable manifolds without ever looking at a book on classical differential geometry, but it is doubtful that one could appreciate the underlying ideas if such a strategy were taken. Some background in linear algebra, topology, and vector calculus would allow one to understand the abstract definition of a differentiable manifold. However, to push forward the frontiers of the subject, or to apply it, one must have a solid understanding of its underlying intuition.<br /> Thus a study of classical differential geometry is warranted for someone who wants to do original research in the area as well as use it in applications, which are very extensive. Differential geometry is pervasive in physics and engineering, and has made its presence known in areas such as computer graphics and robotics. In this regard, the authors of this book have given students a fine book, and they emphasize right at the beginning that an undergraduate introduction to differential geometry is necessary in today's curriculum, and that such a course can be given for students with a background in calculus and linear algebra. They also do not hesitate to use diagrams, without sacrificing mathematical rigour. Too often books in differential geometry omit the use of diagrams, holding to the opinion that to do so would be a detriment to mathematical rigour. Much is to be gained by the reading and studying of this book, and after finishing it one will be on the right track to begin a study of modern differential geometry.	2002-07-20
1468801:US	50702879	R223FTR3DL2KOO	0226742024	416984459	Unstable Modules over the Steenrod Algebra and Sullivan's Fixed Point Set Conjecture (Chicago Lectures in Mathematics)	Books	5	0	0	N	N	Very interesting mathematics	Fixed points of mappings are of course of enormous interested in the fields of dynamical systems and differential equations. This book however is interested in fixed points from the standpoint of algebraic topology, namely with the study of the homotopy type of the fixed point set of a group action. This motivates the consideration of a homotopy fixed point set, and the author studies specifically the homotopy fixed point set of a finite group acting on a finite complex. From an equivariant point of view, a homotopy fixed point is a set of maps equivariant under the integers modulo 2 (Z/2) from the &quot;antipodal&quot; sphere (i.e the ordinary sphere provided with the antipodal action) to a finite Z/2-CW-complex. A homotopy fixed point is such a map, and ordinary fixed points determine homotopy fixed points. The Sullivan fixed point conjecture asserts that the mapping of ordinary fixed points to homotopy fixed points is a homotopy equivalence, and this conjecture is one of the main topics of the book. The resolution of this conjecture was accomplished by Haynes Miller, with other contributions made by Gunnar Carlsson and J. Lannes. As a point of historical fact, Miller first proved the Sullivan conjecture in the context of pointed maps from the classifying space of a finite group to a finite CW-complex. With the compact-open topology, he showed that this space of maps is weakly contractible. Another line of thought on this topic and considered in this book is that of the fixed point set of a G-space localized at a prime p. The question of whether this fixed point set is weakly homotopy equivalent to the homotopy fixed point set of G acting on the p-localization of a finite CW-complex was solved by Carlsson via a consideration of the Segal conjecture.<br /> The author gives a nice overview of these results, and does so by first considering background material from the theory of unstable modules over the Steenrod algebra. The reader is expected to have a solid background in algebraic topology, particularly in the homotopy theory of CW-complexes, Eilenberg-Maclane spaces, Postnikov systems, the theory of spectral reduced and unreduced cohomology, cohomology operations, and K-theory. The Steenrod algebra has its origins in the consideration of stable Z/2 cohomology operations, where these operations can all be written in terms of Steenrod operations. Consideration of relations among the Steenrod squares result in a family of relations called the Adem relations. This construction can be generalized to a prime p by considering generators other than the Steenrod squares, and dividing out the Adem relations (these are more complex than for the case p = 2). The calculation of the cohomology of Eilenberg-Maclane spaces leads to a characterization of the Steenrod algebra as the algebra of all transformations of mod p cohomology that commute with suspension. Such transformations are called 'stable'.<br /> The mod p cohomology of a space as a module over the Steenrod algebra is unstable, meaning that it is trivial in negative degrees. The author then characterizes the category of unstable modules over the Steenrod algebra (designated U by the author), and shows that is has enough projectives and that it is (locally) Noetherian. That this category has enough injectives is shown using Brown-Gitler technology. This involves the construction of the Brown-Gitler modules, which are related to the Milnor algebra (the dual of the Steenrod algebra, familiar from the elementary theory), and the Carlsson modules. The later are related to Carlsson's work on the Segal conjecture, and their description involves some interesting use of the combinatorics of binary trees. The Lannes functor is introduced as a generalization of this tensor product that still gives an injective category, and its properties are outlined in detail. Modular representation theory is used in the book to study  indecomposable reduced U-injectives, and their graded vector space structure is studied using the familiar Poincare series. Then the quotient category of U by its subcategory of nilpotents is studied via a filtration on it, the quotient categories of this filtration being identified with the modular representations of the symmetric groups.<br />  The last part of the book finally gets down to the Sullivan conjecture, beginning with a discussion of the Andre-Quillen cohomology of unstable algebras over the Steenrod algebra. All of the familiar tools from algebraic topology, such as Eilenberg-Moore spectral sequences and the Borel construction are used to prove Miller's version of the Sullivan conjecture and also a generalized version of it.ructure is studied using the familiar Poincare series. Then the quotient category of U by its subcategory of nilpotents is studied via a filtration on it, the quotient categories of this filtration being identified with the modular representations of the symmetric groups. <BR>         The last part of the book finally gets down to the Sullivan conjecture, beginning with a discussion of the Andre-Quillen cohomology of unstable algebras over the Steenrod algebra. All of the familiar tools from algebraic topology, such as Eilenberg-Moore spectral sequences and the Borel construction are used to prove Miller's version of the Sullivan conjecture and also a generalized version of it.	2002-07-20
1476161:US	50702879	R266YO57PVTOAY	0688092551	148548307	Enola Prudhomme's Low-Calorie Cajun Cooking	Books	5	2	2	N	N	Good eating with no love handles	For those who love the aroma, taste, and challenge of cajun cuisine but want to eliminate its correlation with the human waistline, this book will be a welcome addition to the culinary library. It is packed full of hints for preparation and of course many excellent recipes. It is quite common in low-cal cookbooks that the flavor and texture get sacrificed in the quest to maintain the hourglass shape, and to some extent this is true here. But the author/chef has done a good job of preserving the bare essentials of the Cajun cooking experience. Recipe recommendations: 1. Seafood gumbo. 2. Shrimp Salad 3. Crabmeat Casserole 4. Shrimp and Crabmet Jambalaya 5. Shrimp Creole 6. Blackened Catfish 7. Cajun Catfish 8. Chicken and Sausage Jambalaya. 9. Blackened Chicken Breast 10. Cajun-Style Chili 11. Blackened Pork Chop 12. Blackened Lamb Chop 13. Sweet Potatoes with Orange 14. Dirty Rice 15. Cajun Couche-Couche 16. Jalapeno Cornbread	2002-07-14
1480003:US	50702879	R1T7WE773RDX5	0879696087	973145252	Bioinformatics: Sequence and Genome Analysis	Books	4	37	38	N	N	Good introduction, but somewhat qualitative	The field of bioinformatics has exploded in the last five years, and several monographs and textbooks have appeared to assist in the elucidation of the concepts involved. Bioinformatics is a field that grew hand-in-hand with the rise of the Internet, and anyone going into it will need expertise in the PERL and JAVA programming languages, as well as a fairly strong mathematical background. In this book, the author gives a very good overview of bioinformatics from mostly a qualitative and descriptive point of view, although some elementary mathematical discussions are inserted in various places. Because of the level of mathematics used, this might not be the book to use for the mathematician who desires to go into bioinformatics or computational biology. On the other hand, for the student of biology or mathematics who intends to pursue bioinformatics as a profession, this book would be an excellent choice. One cannot read the book however without visiting its accompanying Website, for the author extends some of the results of the book there.<br /> The book begins with an historical introduction to the subject, and a newcomer to the subject will get a brief overview of some of the first sequence analysis programs and some of the first DNA sequence databases developed long before bioinformatics was recognized as a real discipline. The author introduces some of the techniques that will be discussed in the book, such as global and local sequence alignment, dynamic programming, RNA structure prediction, and protein structure prediction. This is followed in chapter 2 by an overview of the procedures used to collect and store sequences in the laboratory. To the reader not familiar with these techniques, the discussion may be too brief. The different sequence formats used are outlined, as well as techniques used to convert from one sequence format to another.<br /> Chapter 3 takes a closer look at the pairwise alignment of sequences, and the author also outlines the reasons behind examining sequence alignment in the first place, namely that of finding the functional, structural, and phylogenetic information. The view of sequence alignment as an optimization problem is emphasized via the dynamic programming algorithm for sequence alignment. Dot matrix analysis is discussed a sequence alignment strategy that allows all possible matches of residues between two sequences. The author is careful to note that local alignment algorithms might give global alignments, and vice versa, because of small changes in the scoring system. The PAM and BLOSUM substitution matrices are compared as to their relative merits and pitfalls. A very detailed discussion of gap penalties is given, along with the role of the Gumbel extreme value distribution in the determination of the statistical significance of a local alignment score between two sequences. And, after a brief introduction to Bayesian statistics, the author shows how to to use it produce alignments between pairs of sequences and to calculate distances between sequences. The Bayes block aligner software package is discussed in detail as a tool for Bayesian sequence alignment.<br /> In chapter 4, the author gives an extensive discussion of multiple sequence alignment algorithms, the most important of these by contemporary standards being hidden Markov models. The author though does treat the &quot;progressive&quot; methods, as well as the use of genetic algorithms in doing multiple sequence alignment. The former include the classic CLUSTALW package and the PILEUP program for doing msa. Although the discussion of hidden Markov models makes sparing use of mathematics, is does serve to explain how they work and should assist readers who need a solid understanding of them.<br /> I did not read chapters 5 and 6 so I will omit their review. Chapter 7 is an introduction to database searches in order to find similar sequences. The algorithms developed in chapters 3 and 4 again make their appearance, and the reader is confronted with various user interfaces for performing genetic database searching online. The FASTA and BLAST tools are introduced as fast methods to do database searching. As computer performance increases in the years ahead, these and other currently existing tools will no doubt be replaced by more powerful search routines. While perusing this chapter, one cannot help but be fascinated by the current situation in the biological/genetic sciences. Once thought of as a purely descriptive science, it is now dominated by a reductionist philosophy, involving huge amounts of data, and sophisticated mathematics for the analysis of this data.<br /> The author moves on to the methods for detecting protein-encoding regions of DNA sequences in chapter 8. The simplest method according to the author for doing this is to search for ORFs, and he discusses the reliability of methods for accomplishing this. Hidden Markov models again make their appearance as a tool to study eukaryotic internal exons and in gene prediction in microbial genomes. And, neural networks are introduced as tools for finding complex patterns and relationships among sequence positions, and Grail II is discussed as a system for exon finding in eukaryotic genes. Promotor prediction in E. Coli is also briefly overviewed.<br /> I did not read chapter 9 so I will omit its review. Chapter 10 though is an introduction to one of most interesting parts of bioinformatics, namely that of analyzing the entire genomes of organisms. Due to rapid experimental advances in genetics, several genomes are now available, and this allows a more global, dynamical view of the role of genes and how their expression correlates to result in a fully-developed functioning organism. The techniques discussed in earlier chapters come into play in genomic analysis, and many other more novel techniques will have to be invented if sense is to be made of the enormous amount of genomic data currently available.he reader is confronted with various user interfaces for performing genetic database searching online. The FASTA and BLAST tools are introduced as fast methods to do database searching. As computer performance increases in the years ahead, these and other currently existing tools will no doubt be replaced by more powerful search routines. While perusing this chapter, one cannot help but be fascinated by the current situation in the biological/genetic sciences. Once thought of as a purely descriptive science, it is now dominated by a reductionist philosophy, involving huge amounts of data, and sophisticated mathematics for the analysis of this data. <br /> The author moves on to the methods for detecting protein-encoding regions of DNA sequences in chapter 8. The simplest method according to the author for doing this is to search for ORFs, and he discusses the reliability of methods for accomplishing this. Hidden Markov models again make their appearance as a tool to study eukaryotic internal exons and in gene prediction in microbial genomes. And, neural networks are introduced as tools for finding complex patterns and relationships among sequence positions, and Grail II is discussed as a system for exon finding in eukaryotic genes. Promotor prediction in E. Coli is also briefly overviewed.<br /> I did not read chapter 9 so I will omit its review. Chapter 10 though is an introduction to one of most interesting parts of bioinformatics, namely that of analyzing the entire genomes of organisms. Due to rapid experimental advances in genetics, several genomes are now available, and this allows a more global, dynamical view of the role of genes and how their expression correlates to result in a fully-developed functioning organism. The techniques discussed in earlier chapters come into play in genomic analysis, and many other more novel techniques will have to be invented if sense is to be made of the enormous amount of genomic data currently available.	2002-07-10
1480064:US	50702879	RN35HBKEHK2WL	0471050598	35249214	Principles of Algebraic Geometry	Books	5	36	39	N	N	Will never collect dust	Once thought to be highly esoteric and useless by those interested in applications, algebraic geometry has literally taken the world by storm. Indeed, coding theory, cryptography, steganography, computer graphics, control theory, and artificial intelligence are just a few of the areas that are now making heavy use of algebraic geometry.<br /> This book would probably be the most useful one for those interested in applications, for it is an overview of algebraic geometry from the complex analytic point of view, and complex analysis is a subject that most engineers and scientists have had to learn at some point in their careers. But one must not think that this book is entirely concrete in its content. There are many places where the authors discuss concepts that are very abstract, particularly the discussion of sheaf theory, and this might make its reading difficult. The complex analytic point of view however is the  best way of learning the material from a practical point of view, and mastery of this book will pave the way for indulging oneself in its many applications.<br /> Algebraic geometry is an exciting subject, but one must master some background material before beginning a study of it. This is done in the initial part of the book (Part 0), wherein the reader will find an overview of harmonic analysis (potential theory) and Kahler geometry in the context of compact complex manifolds. Readers first encountering Kahler geometry should just view it as a generalization of Euclidean geometry in a complex setting. Indeed, the so-called Kahler condition is nothing other than an approximation of the Euclidean metric to order 2 at each point.<br /> The authors choose to introduce algebraic varieties in a projective space setting in chapter 1, i.e. they are the set of complex zeros of homogeneous polynomials in projective space. The absence of a global holomorphic function for a compact complex manifold motivates a study of meromorphic functions and divisors. Divisors are introduced as formal sums of irreducible analytic hypersurfaces, but they are related to the defining functions for these hypersurfaces also, via the poles and zeros of meromorphic functions. For the mathematical purist, a \\"sheafified\\" version of divisors is also outlined. Divisors and line bundles are basically \\"linear\\" tools used to investigate complex varieties through their representation as complex submanifolds of projective space. In addition, various approaches are used to study codimension-one subvarieties, such as the results of Kodaira and Spencer. Although the famous Kodaira vanishing theorem is clothed in the language of Cech cohomology, this cohomology is represented by harmonic forms, thus making its understanding more accessible. The authors also show explicitly to what extent an algebraic variety can be thought of as a compact complex manifold via the Kodaira embedding theorem. Projective space of course is not the most complicated of constructions, as readers familiar with the theory of vector bundles will know. Grassmannians are an example of this, and they are introduced and discussed in the book as generalizations of projective space. And, just as in the ordinary theory of vector bundles, the authors show how to use Grassmannians to act as universal bundles for holomorphic vector bundles.<br /> The presence of meromorphic functions will alert the astute reader as to the role of Riemann surfaces in the study of complex algebraic varieties. Indeed, in chapter 2, the authors cast many classical complex analytic results to modern ones, and they prove the famous Riemann-Roch theorem, which essentially counts the number of meromorphic functions on a Riemann surface of genus g. The theory of Abelian varieties is outlined, and the reader gets a taste of \\"Italian\\" algebraic geometry but done in the rigorous setting of Plucker formulas and coordinates.<br /> Chapter 3 is a summary of some of the other methodologies and techniques used to study generalanalytic varieties, the first of these being the theory of currents, i.e differential forms with distribution coefficients. It is perhaps not surprising to see this applied here, given that it can handle both the smooth and piecewise smooth chains simultaneously. The currents are associated to analytic varieties and allow a definition of their intersection numbers and a proof that they are positive. The all-important Chern classes are introduced here, and it is shown that the Chern classes of a holomorphic vector bundle over an algebraic variety are fundamental classes of algebraic cycles. Most importantly the authors introduce spectral sequences, a topic that is usually formidable for newcomers to algebraic geometry.<br /> The study of surfaces is studied in chapter 4, with the differences between its study and the theory of curves (Riemann surfaces) emphasized. The reader gets a first crack at the notion of a rational map, and the birational classification of surfaces is shown. Intuitively, one expects that the classification of surfaces would be easy if it were not for \\"singular points\\", and this is born out in the use of blowing up singularities in this chapter. Rational surfaces are characterized using Noether's lemma, and a rather detailed discussion is given of surfaces that are not rational, giving the reader more examples of rigorous \\"Italian\\" geometry.analytic varieties, the first of these being the theory of currents, i.e differential forms with distribution coefficients. It is perhaps not surprising to see this applied here, given that it can handle both the smooth and piecewise smooth chains simultaneously. The currents are associated to analytic varieties and allow a definition of their intersection numbers and a proof that they are positive. The all-important Chern classes are introduced here, and it is shown that the Chern classes of a holomorphic vector bundle over an algebraic variety are fundamental classes of algebraic cycles. Most importantly the authors introduce spectral sequences, a topic that is usually formidable for newcomers to algebraic geometry.<br /> The study of surfaces is studied in chapter 4, with the differences between its study and the theory of curves (Riemann surfaces) emphasized. The reader gets a first crack at the notion of a rational map, and the birational classification of surfaces is shown. Intuitively, one expects that the classification of surfaces would be easy if it were not for \\"singular points\\", and this is born out in the use of blowing up singularities in this chapter. Rational surfaces are characterized using Noether's lemma, and a rather detailed discussion is given of surfaces that are not rational, giving the reader more examples of rigorous \\"Italian\\" geometry.	2002-07-10
1480212:US	50702879	R3I45HXXSNHQ85	0125140819	153573014	Topology and Geometry for Physicists	Books	3	26	30	N	N	Good attempt	When reading this book one can both admire these authors and feel sympathy with them. They have made an honest effort to explain the concepts  of differential geometry and topology in a way that is understandable and appreciated by the physicist reader. But the book falls short in many places, although there are some places where they do a fine job. They have taken on a very difficult project in this book, for it is quite straightforward to expound on the formalism of mathematics, but explaining it in a way that grants insight into its conceptual meaning is another matter altogether. Many physicists complain, with justification, that the way mathematics is presented in textbooks is not sufficient for giving them a deep appreciation of the underlying ideas involved. This, they argue, is what is needed for devising new physical theories and results based on these ideas. Physicists must assimilate very complex mathematical ideas very quickly in order to formulate these theories in a reasonable time frame. This is especially true in high energy physics, which in the last two decades has used mathematics like it has never been used before. Indeed, the mathematical complexity of high energy physics is dizzying, and if progress is going to be made in this field by the students of the 21st century, they are going to need mathematics books and documents that are more than just formal expositions. But, again, writing these kinds of books is very hard to do, and has yet to be done in a book to this date, although there are helpful discussions scattered throughout the mathematical literature.<br /> Some of the concepts that need more in-depth explanation include: the theory of characteristic classes, sheaf theory, the theory of schemes in algebraic geometry, and spectral sequences in algebraic topology. There are of course many others, and some of the ones that the authors do a fairly good job of explaining in this book include: 1. the reason that the continuity of a function is defined in terms of inverses of open sets; 2. The orientability of a manifold; 3. The fundamental group and its relation with the first homology group. 4. The discussion on Morse theory.is defined in terms of inverses of open sets; 2. The orientability of a manifold; 3. The fundamental group and its relation with the first homology group. 4. The discussion on Morse theory.	2002-07-10
1480227:US	50702879	R3OM7ER42NJ1AZ	0697059723	957547565	Introduction to Topology	Books	4	7	9	N	N	Good introduction	Written for undergraduate students of mathematics, this book serves as a fine introduction to topology from an abstract set-theoretic point of view. The approach of the author is also to have the reader do most of the proofs of the theorems in the book, and thus the book can be thought of as the student's second course in proof theory, the first being maybe Euclidean geometry.<br /> Basic concepts in set theory are outlined in chapter 1, and in detail. This paves the way for a discussion of topological spaces in chapter 2. The author could have begun this discussion with a general definition of a topological space, but instead chooses (thankfully) to motivate the definition via the definition of an open set in the real line. The abstract definition is thus better appreciated, which the author then does immediately. He then moves on to the consideration of subspaces and continuity in chapter 3. The discussion here is pretty standard, as there are not any examples that cannot be found in the literature. The most important concept introduced here is that of a homeomorphism, and readers will get a taste of the intuitive &quot;coffee cup = donut&quot; definition of topological equivalance that they have no doubt heard about from popular discussions of topology.<br /> Product spaces are introduced in chapter 4, with a brief peek at topological groups given. Infinite products are introduced but the reading is labeled as supplementary by the author. Chapter 5 is then an introduction to the topological concept of connectedness. The beginner may be troubled as to the way connectedness is defined, since it is defined as the negation of disconnectedness, but the examples given should alleviate any skepticism as to this nonconstructive definition of connectedness. The famous example of a connected space that becomes totally disconnected after the removal of one point is unfortunately not discussed in this book.<br /> Another important concept in topology, that of compactness, is discussed in chapter 6. It is introduced via the concept of coverings, and it is shown that the use of this concept, and not one that is based on a generalization of closed and bounded sets, is the one that gives the best definition for general topological spaces. Then, in chapter 7, the separation properties of topological spaces are discussed. Regular and normal spaces are defined here also, along with the concept of a T5 space. The latter is usually not discussed in elementary books in topology. Metric spaces are finally introduced in the last chapter of the book, giving the reader some of the tools needed for a future study of analysis.is discussed in chapter 6. It is introduced via the concept of coverings, and it is shown that the use of this concept, and not one that is based on a generalization of closed and bounded sets, is the one that gives the best definition for general topological spaces. Then, in chapter 7, the separation properties of topological spaces are discussed. Regular and normal spaces are defined here also, along with the concept of a T5 space. The latter is usually not discussed in elementary books in topology. Metric spaces are finally introduced in the last chapter of the book, giving the reader some of the tools needed for a future study of analysis.	2002-07-10
1480730:US	50702879	R3CM18UUSE5YWG	0828402663	85952725	The Theory of Rings	Books	4	5	5	N	N	Good introduction	The theory of rings is not only important in mathematics but in also in applications of algebra, such as cryptography, coding theory, and theoretical physics. The theory of rings has advanced considerably since this book was published, but the book emphasizes the fundamentals, which have not changed, and so could still be used as an introduction to these modern developments. The book is written for undergraduates who have had prior exposure to modern algebra.There are many exercises at the end of each chapter, and hints of some of their solutions in the back of the book.  Ring theory used to be viewed as an abstract, esoteric subject, but this attitude has changed due to its many applications. Commutative rings are the emphasis in the book, and this reflects somewhat its time of publication. Noncommutative rings have been the subject of intense investigation in the last decade, going by the name of quantum algebra. Quantum algebra has its origins in theory of exactly solved models in statistical mechanics, but has now established itself as a rigorous subfield of modern algebra. Readers interested in this area of research will be well prepared after a study of this book. Some of the highlights of the book, a few of which are usually not included in a beginning course in ring theory include the discussions on ideals in complete metric rings, dense rings, and modular ideals.	2002-07-10
1485554:US	50702879	R31P9C0LNVHLEJ	0898745519	405153076	Introduction to Topology and Modern Analysis	Books	5	65	67	N	N	Didactic perfection	In the author's words in the preface, the dominant theme of this book is continuity and linearity, and its goal is to illuminate the meanings of these words and their relations to each other. The book, he says, belongs to the type of pure mathematics that is concerned with form and structure, and such a body of mathematics must be judged by its high aesthetic quality, and should exalt the mind of the reader.<br /> The author's attitude can only be characterized as magnificent, and, if one is to judge his utterances in the preface by what is found after it, one will indeed find perfect evidence of his delight in mathematics and his high competence in elucidating very abstract concepts in topology and real analysis. Indeed, this has to be the best book ever written for mathematics at this level. It is a book that should be read by everyone that desires deep insights into modern real and functional analysis.<br /> After a brief and informal overview of set theory, the author moves on to the theory of metric spaces in chapter 2. His emphasis is on the idea that metric spaces are easy to find, since every non-empty set has the discrete metric, and that metric spaces are good motivation for the more general idea of a topological space. The Cantor set, ubiquitous in measure theory, dynamical systems, and fractal geometry, is constructed as the most general closed set on the real line, i.e. one obtained by removing from the real line a countable disjoint class of open intervals. Continuity of mappings between metric spaces is defined, and also the concept of uniform continuity, the latter of which is motivated very nicely by the author. Then, the author takes the reader to a higher level of abstraction, wherein he asks the reader to consider all of the continuous functions on a metric space, and turn this collection into a metric space of a special type called a normed linear space, and, more specifically, a Banach space. Thus the author introduces the reader to the field of functional analysis.<br /> A lengthy introduction to topological spaces follows in chapter 3. The author motivates well the idea of an open set, and shows that one could just as easily use closed sets as the fundamental concept in topology. And, most important for functional analysis, he introduces the weak topology, and shows how to obtain the weakest topology for a collection of mappings from a topological space to a collection of other topological spaces. The reader can see clearly that the weaker the topology on a space the harder it is for mappings to be continuous on the space.<br /> Compactness, so essential in all areas of mathematics that make use of topology, is discussed in chapter 4. It is motivated by an abstraction of the Heine-Borel theorem from elementary real analysis, and the author shows how well-behaved things are on compact topological spaces. Some important theorems are proved in this chapter, namely Tychonoff's theorem, the Lebesgue covering lemma, and Ascoli's theorem.<br /> Recognizing that the only functions able to be continuous on a space with the indiscrete topology are the constants, and that a space with the discrete topology has continuous functions in abundance, the author asks the reader to consider topologies that fall between these extremes, and this motivates the separation properties of topological spaces. Chapter 5 is an in-depth discussion of separation, and the reader again confronts function spaces, and their ability (or non-ability) to separate the points of a topological space. Spaces that allow such separation to occur are called completely regular, and this property has far-reaching consequences in analysis and other areas of mathematics. The Stone-Cech compactification is discussed as an imbedding theorem for completely regular spaces, analogous to one for normal spaces.<br /> The intuitive idea of a space being connected is given rigorous treatment in chapter 6. Certain pathologies can of course arise when discussingconnectedness, and the author shows this by discussing totally disconnected spaces, remarking that such spaces are very important in dimension theory and representation theory. Indeed, computational and fractal geometry is much harder to study because of the existence of these spaces.<br /> Chapter 7 is important to all working in numerical analysis, wherein the author discusses approximation theory. The Weierstrass approximation and the Stone-Weierstrass theorems are discussed in detail.<br /> A slight detour through algebra is given in chapter 8. Groups, rings, and fields are given a minimal treatment by the author, discussing only the basic rudiments that are needed to get through the rest of the book.<br /> Banach spaces make their appearance in chapter 9, with the three pillars of the theory proven: the Hahn-Banach, the open mapping, and the uniform boundedness theorems. These theorems guarantee that the study of Banach spaces is worth doing, and that there are analogs of the finite dimensional theory in the (infinite)-dimensional context of Banach spaces. The theory of Banach spaces is very extensive, but this chapter gives a peek at this very interesting area of mathematics.<br /> Banach spaces with an inner product are considered in chapter 10. These of course are the familiar Hilbert spaces, so important in physics and the subject of a huge amount of research in mathematics. The presence of the inner product allows constructions familiar from ordinary finite-dimensional vector spaces to carry over to the inifinite-dimensional setting, one example being the transpose of a matrix, which is replaced in the Hilbert space setting by a self-adjoint operator.<br /> As a warm-up to the infinite-dimensional theory, finite-dimensional spectral theory is considered in chapter 11. The famous spectral theorem is proven. Then in chapter 12, the reader enters the world of &quot;soft&quot; analysis, wherein topological and algebraic constructions are used to study linear operators on spaces of infinite dimensions. Putting an algebraic structure on a Banach space gives a Banach algebra, and then the trick is deal with the spectrum of an element of this algebra. The reader can see the interplay between algebra, topology, and analysis in this chapter and the next one on commutative Banach algebras. Indeed, the Gelfand-Naimark theorem, that essentially states that elements of a commutative Banach *-algebra act like the functions on its maximal ideal space, has to rank as one of the most interesting results in the book, and indeed in all of mathematics.scussing connectedness, and the author shows this by discussing totally disconnected spaces, remarking that such spaces are very important in dimension theory and representation theory. Indeed, computational and fractal geometry is much harder to study because of the existence of these spaces. <br /> Chapter 7 is important to all working in numerical analysis, wherein the author discusses approximation theory. The Weierstrass approximation and the Stone-Weierstrass theorems are discussed in detail. <br /> A slight detour through algebra is given in chapter 8. Groups, rings, and fields are given a minimal treatment by the author, discussing only the basic rudiments that are needed to get through the rest of the book. <br /> Banach spaces make their appearance in chapter 9, with the three pillars of the theory proven: the Hahn-Banach, the open mapping, and the uniform boundedness theorems. These theorems guarantee that the study of Banach spaces is worth doing, and that there are analogs of the finite dimensional theory in the (infinite)-dimensional context of Banach spaces. The theory of Banach spaces is very extensive, but this chapter gives a peek at this very interesting area of mathematics. <br /> Banach spaces with an inner product are considered in chapter 10. These of course are the familiar Hilbert spaces, so important in physics and the subject of a huge amount of research in mathematics. The presence of the inner product allows constructions familiar from ordinary finite-dimensional vector spaces to carry over to the inifinite-dimensional setting, one example being the transpose of a matrix, which is replaced in the Hilbert space setting by a self-adjoint operator. <br /> As a warm-up to the infinite-dimensional theory, finite-dimensional spectral theory is considered in chapter 11. The famous spectral theorem is proven. Then in chapter 12, the reader enters the world of &quot;soft&quot; analysis, wherein topological and algebraic constructions are used tostudy linear operators on spaces of infinite dimensions. Putting an algebraic structure on a Banach space gives a Banach algebra, and then the trick is deal with the spectrum of an element of this algebra. The reader can see the interplay between algebra, topology, and analysis in this chapter and the next one on commutative Banach algebras. Indeed, the Gelfand-Naimark theorem, that essentially states that elements of a commutative Banach *-algebra act like the functions on its maximal ideal space, has to rank as one of the most interesting results in the book, and indeed in all of mathematics.	2002-07-06
1489164:US	50702879	R2G3PZLOXDRHDJ	0521589568	889227038	From Calculus to Cohomology: De Rham Cohomology and Characteristic Classes	Books	3	25	26	N	N	Too advanced for the targeted audience	De Rham cohomology and the theory of characteristic classes are not only two of the most important topics in mathematics, but also in theoretical physics. Indeed, an understanding of the geometry and topology of fiber bundles requires a mastery of these topics, and, if one is to make sense of topological phenomena in quantum field theory, one must understand how to perform the calculation of characteristic classes. This book gives a fairly good start in meeting these goals, and, the authors say, is written for upper-level undergraduates with no background in topology or differential geometry. However topological spaces are not defined in the book, but the authors use them as though the reader has had prior exposure.<br /> De Rham cohomology is introduced very early in the book (p. 15), with a differential p-form defined as a smooth map from an open set in n-dimensional Euclidean space to the space of alternating forms. The authors do motivate the definition through the consideration of ordinary vector calculus, which serves to ease the transition to the more formal theory. Concepts from algebraic topology immediately follow, these being chain complexes and their corresponding homological algebra. The foremost strategy for the calculation of the De Rham cohomology, the Mayer-Vietoris sequence is given, the treatment emphasizing the role of the Poincare lemma. Considerations from homotopy are used to calculate the de Rham cohomology of punctured Euclidean space. The De Rham theory is then used to prove the Brouwer fixed point theorem. The famous theorem of J.F. Adams on the maximal number of linearly independent vector fields on the n-dimensional sphere is stated but not proved. No doubt the proof was omitted due to the advanced techniques that must be used to prove it.<br /> Differential forms on smooth manifolds are discussed also, along with the accompanying topics of curvature and integration on smooth manifolds. Stokes' theorem is proved in detail. A very detailed study of the concept of degree, linking numbers, and indexes of vector fields is given, as preparation for later discussions on Morse theory and the Poincare-Hopf theorem. The physicist reader will definitely want to pay attention to this discussion because of its importance in applications.This discussion also marks the beginning of the more advanced topics in the book, which continues to its end. Readers will definitely have to pay attention to more of the details here, and the authors replace geometric intuition by more formal, algebraic considerations.<br /> The theory of fiber bundles and vector bundles are given fair treatment in the book too, but the authors should have motivated the subject with some examples of elementary bundles, such as the Mobius strip. They do however prove that a vector bundle over a compact base space has an inner product and they do this with the help of partitions of unity. Partitions of unity are one of most useful concepts to illustrate how the different fibers of a bundle can be joined together. Also, they show how vector bundles over a compact base can be trivialized by taking the direct sum with a suitable bundle, called its complement. This motivates the definition of an Abelian semigroup of isomorphism classes of vector bundles over compact bases. This semigroup can, and the authors show this, be completed to an Abelian group via the Grothendieck construction. These considerations are the origin of the famous K-theory of vector bundles. Along these same lines the authors show that there is a homotopy classification of vector bundles by using the notion of a \\"pull-back\\" of vector bundles (the pull-back of a vector bundle \\"dilutes\\" the bundle, i.e. makes it less \\"twisted\\").<br /> The way the authors present the theory of characteristic classes is much too formal, and does not give the reader an appreciation of their origins and why they work as well as they do. Readers at this level need to be given a lot more motivation to the underlying intuition behind characteristic classes. Physicists in particular, who are faced with these objects in many applications, need a more in-depth discussion. Indeed, the authors really take off in their proof of the Thom isomorphism theorem. They do not discuss why this result is so important nor give concrete examples of its utilization.<br /> A fairly long list of exercises is given in the back of the book, and the reader should work most of these in order to be able to understand the results in the book. It will also help to go back to some of the original papers on vector and fiber bundles, even ones published in the 1930s, to gain more of an appreciation of the concepts in the book.<br /> Rigor is of upmost importance in mathematics, but so is understanding.o the underlying intuition behind characteristic classes. Physicists in particular, who are faced with these objects in many applications, need a more in-depth discussion. Indeed, the authors really take off in their proof of the Thom isomorphism theorem. They do not discuss why this result is so important nor give concrete examples of its utilization. <br /> A fairly long list of exercises is given in the back of the book, and the reader should work most of these in order to be able to understand the results in the book. It will also help to go back to some of the original papers on vector and fiber bundles, even ones published in the 1930s, to gain more of an appreciation of the concepts in the book. <br /> Rigor is of upmost importance in mathematics, but so is understanding.	2002-07-03
1492221:US	50702879	R2USUOMRM5SVY8	0486630692	551109171	Calculus of Variations: with Applications to Physics and Engineering	Books	5	27	32	N	N	Will never collect dust	The importance of variational calculus cannot be overstated, as it now is being applied to myriads of different areas, these going way beyond the routine applications in physics and engineering. Indeed, it has been found to be useful in economics, network engineering, financial modeling, computational radiology, and in the new field of constraint programming. This book is now a classic, and has been the standard reference and textbook for variational calculus since its first date of publication. There have been many excellent books on variational calculus that have appeared since this one first did, but they do not provide the needed intuition in learning the subject. The clarity of the author's presentation in this book is outstanding, and, most importantly, he assigns challenging exercises to test the readers understanding of the subject. When the book was first published, computers were not being used as they are today, and the current strategy in solving variational problems is usually to use some sort of numerical software packages. In addition, the use of symbolic programming languages, such as Mathematica and Maple, have made the derivations in variational calculus almost trivial, and this is a promising trend since it allows the user to concentrate more on the concepts involved in applying it. Also, very efficient numerical routines exist in Fortran, C, and C++ that are designed and optimized for variational problems.<br /> All of the beginning material on the calculus of variations is covered in the book, and its application to Lagrangian and Hamiltonian mechanics, elasticity, quantum mechanics, and electrostatics. Isoperimetric problems are treated, the vibrating string and membrane, and the Sturm-Liouville system and its origin as an eigenvalue problem in variational calculus. In the latter, the reader can see the origing of some of special function solutions, such as the Bessel functions and Laguerre polynomials. The reading of this book will amply prepare the reader for applying it to problems in quantum field theory, economics, radiology, financial engineering, logistics, optimization theory, computational geometry, control theory, and the theory of evolutionary strategies. In addition, the book will allow the reader to move on to more advanced areas of mathematics, such as the theory of minimal surfaces, Morse theory, and geometric measure theory.are the reader for applying it to problems in quantum field theory, economics, radiology, financial engineering, logistics, optimization theory, computational geometry, control theory, and the theory of evolutionary strategies. In addition, the book will allow the reader to move on to more advanced areas of mathematics, such as the theory of minimal surfaces, Morse theory, and geometric measure theory.	2002-06-30
1492688:US	50702879	R22GCFW7Q2J0ZF	3110137046	52171803	Quantum Invariants of Knots and 3-Manifolds (Degruyter Studies in Mathematics)	Books	5	5	6	N	N	Excellent overview of what was known at the time	Some quite amazing results have appeared in the last two decades that connect two seemingly different fields of knowledge, namely topology and quantum field theory. Topological considerations have played a role in quantum field theory for quite some time, due to the role of instantons, but quantum field theory did not shed any light on topological questions until Edward Witten, Vaughan Jones, and other physicists and mathematicians showed that it can be a powerful tool of investigation in 3-dimensional and 4-dimensional topology.<br /> This book, written for the mathematician, does not follow the physical line of reasoning that has been employed to obtain invariants of knots and 3-manifolds. Instead, it endeavors to remain as rigorous as possible, and thus the approaches using conformal field theory or Chern-Simons field theory are not developed by the author (this is not to say that one cannot see the influence of these areas in the book). The author incorporates not only the developments from the current research literature up to the date the book was written, but also interjects some original results of his own. The book could also be viewed as a textbook, as there are exercises put in at various places in the book.<br /> Topological quantum field theory is defined rigorously in this book, but is put in the context of what are called modular categories and modular functors by the author.Modular categories are finite dimensional modules over a Hopf algebra. Hence, one should think of the designation 'quantum field theory' in the book as being one that indicates only its historical roots. A fully operational quantum field theory always needs infinite dimensions to gain its predictive power. These modular categories are constructed from modular functors, the latter arising from closed oriented surfaces with a distinguished Lagrangian subspace and a finite set of marked points, or &quot;colors&quot; (the reader versed in conformal field theory will see the origins of these ideas). Choosing a particular modular category and set of colors will give the familiar Jones polynomial.<br /> After defining an isotopy invariant for colored frame oriented links in Euclidean space, topological invariants for closed oriented 3-manifolds are defined by doing surgery on the standard 3-sphere along a framed link. The dependence on the link is removed by employing Kirby calculus, which gives the sequence of moves needed to relate one link to another. The resulting quantum invariant is thus dependent on the link diagrams, but an intrinsic definition computed from the manifold is via a state sum on a triangulation of the manifold. Most interesting is that this state sum is computed using the 6j-symbols, familiar to physicists in the quantum theory of angular momentum. The actual invariant requires the computation of a product over the manifold and one equal to it except taking the opposite orientation. In addition, the computation is done inside an arbitrary compact oriented piecewise-linear 4-manifold bounded by the manifold. This computation utilizes the concept of a &quot;shadow&quot; of a 4-manifold, which are topological objects related to 6j-symbols.The illumination (no pun intended) by the author of the theory of shadows is done in great detail and occupies most of the space in the book.<br /> The existence of modular categories is related to the theory of representations of quantum groups at roots of unity, these quantum groups being Hopf algebras over the complex numbers which are constructed via 1-parameter deformations of the universal enveloping algebra of simple Lie algebras. The author though sticks with the general language of categories, and algebraic and geometric constructions of them are discussed in detail by the author.<br />  All of the results in this book are interesting, but the author admits that their connection with low-dimensional topology and the classical invariants of 3-manifolds is not readily apparent, especiallytheir connection with homotopy via the fundamental group. Such a connection would possibly shed light on the one of the most nagging questions in 3-dimensional topology: the Poincare conjecture.pecially their connection with homotopy via the fundamental group. Such a connection would possibly shed light on the one of the most nagging questions in 3-dimensional topology: the Poincare conjecture.	2002-06-30
1493422:US	50702879	R1NS7DN9RZ7VF	3110140284	529851432	The Link Invariants of the Chern-Simons Field Theory (Degruyter Expositions in Mathematics)	Books	4	3	3	N	N	Out of date but still can be useful	Recognized as a distinct branch of mathematical physics, this book treats the subject of topological quantum field theory from the standpoint of finding invariants for knots using the pure Chern-Simons gauge theory. The Chern-Simons field theory has its beginnings in the construction of instantons in quantum field theory, but it took the work of Edward Witten and others to see the connection between it and knot theory. This connection was accomplished using the non-rigorous methods of path integrals, and these are used in this book in the initial stages to motivate the later developments. And, most importantly, the author does not hesitate to use physical arguments in place of rigorous mathematical arguments to illuminate a particular result.<br />  As an introduction, the Abelian Chern-Simons theory is considered, the (classical) action of which is metric independent and is the integral of a 3-form on a 3-manifold. Gauge invariance and general covariance are discussed as the key side-constraints for the properties of the expectation value taken over (linked) paths. In the corresponding non-Abelian theory, framings must be chosen on the knots to preserve general covariance. The goal of the book is then to calculate the expectation values of the Wilson line operators and show they define link invariants. These link invariants are polynomials, and are then shown to be associated with those defined by braid group representations on the quasi-tensor category of quasi-triangular Hopf algebras. These algebras are a &quot;quantum&quot; deformation of a Lie algebra, and the corresponding polynomials are called (Drinfeld) universal link polynomials. What is interesting about this connection is that with the algebraic interpretation one need not worry about doing computations in quantum field theory. This is definitely the approach taken in recent years, and mathematicians, with their insistence on rigour, are anxious to remove the subject from its quantum field theory roots.<br />  The use of quantum field theory does however have its advantages as a source of new ideas and strategies in defining link invariants, and invariants of 3-manifolds, and I believe strongly that the use of quantum field theory will lead to a resolution of the 3-dimensional Poincare conjecture. The author does not discuss this conjecture, but he does give an excellent overview of surgery on 3-manifolds via the Dehn surgery operations and some discussion of Kirby calculus. The surgery rules are then interpreted in terms of topological quantum Chern-Simons field theory. Specifically, the surgery is interpreted physically in terms of symmetries, and, via the Likorish theorem, the surgeries are thought of as being combinations of elementary surgery operations. The elementary surgery operations are then understood as twist homoeomorphisms of the complement of a tubulur neighborhood of the unknot in the standard 3-sphere. The field theory rules corresponding to the surgery operations are then formulated as symmetries in quantum field theory. The Kirby calculus then appears when the author considers the so-called &quot;honest&quot; surgeries, which are surgeries in which the surgery coefficients are integers. The most important part of these considerations is that one need only concentrate on Chern-Simons field theory on the standard 3-sphere.The coupling constant then only takes integer values, and hence, the author shows, the space of gauge-invariant states is then a reduced tensor algebra, which has finite dimension. The calculation of the resulting path integrals are then fairly straightforward, since one does not have to consider the difficult problem of functional integration in infinite dimensions. The case of a generic 3-manifold is handled by viewing it as the result of surgery on the standard 3-sphere. The problem in using Chern-Simons field theory in this case comes from the interpretation of the partition function, i.e. the normalization problem has to beconsidered since one is dealing with fields defined on different 3-manifolds (each related via surgery). But since it has been established that surgery operations are symmetry transformations, these are used to give meaning to the normalization, which, for the physicist, is nothing other than the calculation of the zero-point energy.<br />  The invariants defined by the author are not fine enough to distinguish one 3-manifold from each other, in particular, manifolds with different homotopy groups. Such invariants would be of value in resolving the 3-dimensional Poincare conjecture. A modification of the approach of topological quantum field theory, wherein genuine quantum effects, such as superposition and entanglement of states, are incorporated into the transition amplitudes between 3-manifolds, may be the way to resolve this conjecture.o be considered since one is dealing with fields defined on different 3-manifolds (each related via surgery). But since it has been established that surgery operations are symmetry transformations, these are used to give meaning to the normalization, which, for the physicist, is nothing other than the calculation of the zero-point energy. <br />   The invariants defined by the author are not fine enough to distinguish one 3-manifold from each other, in particular, manifolds with different homotopy groups. Such invariants would be of value in resolving the 3-dimensional Poincare conjecture. A modification of the approach of topological quantum field theory, wherein genuine quantum effects, such as superposition and entanglement of states, are incorporated into the transition amplitudes between 3-manifolds, may be the way to resolve this conjecture.	2002-06-29
1495973:US	50702879	R3R8JQBOB6ZJCH	0716742195	851933933	The Knot Book: An Elementary Introduction to the Mathematical Theory of Knots	Books	5	43	45	N	N	Excellent motivation for knot theory	Knot theory has been a branch of mathematics that has been around for over a century, and now is finding applications in mnay areas, some of these being electrical circuit analysis, genetics, dynamical systems, and cryptography. This book, written for the layman or the beginning student of mathematics, is an excellent overview of what is known (and not known) in knot theory. Because of the pictorial nature of the subject, knot theory is an excellent way to get people interested in mathematics. Knot theory now is an established branch of mathematics, and it involves the use of tools from topology, analysis, and algebra. The problem of distinguishing one knot from another is one of the major questions in knot theory, and its partial resolution has been assisted by concepts from physics, namely statistical mechanics and quantum field theory. The author discusses the knot recognition problem, and other unsolved problems in the book, and he points out that in knot theory the unsolved problems can be approached by someone with very little background in advanced mathematical techniques. The author does an excellent job of introducing these problems and letting the reader experience, in his words, the joy of doing mathematics.<br />  Chapter 1 is an introduction to the basic terminology of knot theory, and the author gives examples of the most popular elementary knots. He points out the historical origins of the theory, one of these being the attempt by Lord Kelvin to explain the origins of the elements, interestingly. The basic operations on knots are defined, such as composition and factoring, and the famous Reidemeister moves. The proof that planar isotopies and Reidemeister moves suffices to map one projection of a knot to another is omitted. After defining links and linking numbers, the author then discusses tricolorability, and uses this to prove that there are nontrivial knots.<br />  Chapter 2 then overviews the strategies used in the tabulation of knots.The Dowker notation, used to describe a projection of a knot, is discussed as a tool for listing knots with 13 or less crossings. The author also discusses the Conway notation, and how it is used to study tangles and mutants. Graph theory is also introduced as a technique to study knot projections. The author discusses the unsolved problem of finding an elementary integer function that gives the prime knots with given crossing number, a problem that has important ramifications for cryptography (but the author does not discuss this application).<br />  Since knots are complicated objects, then like many other areas in topology, the strategy is to assign a quantity to a knot that will distinguish it from all other knots. Such a quantity is called an invariant, and as one might guess, no one has yet found an invariant to distinguish all nontrivial knots from each other. In the last two decades though, new powerful knot invariants have been discovered, many of these being based on concepts from theoretical physics. In chapter 3, the author discusses the unknotting number, the bridge number, and the crossing number as elementary examples of knot invariants.<br />  Chapter 4 is more complicated, in that the author shows how to use surfaces to assist in the understanding of knots. After discussing how to triangulate an surface and the concept of a homoeomorphism between surfaces, he introduces the Euler characteristic as an invariant of surfaces. Surfaces appear in knot theory as the space in the knot's complement, and the author introduces the concept of the compressibility of a surface, also very important in three-dimensional topology. Particular attention is paid to Seifert surfaces, which, given a particular knot, are orientable surfaces with one boundary component such that the boundary component is the knot in question.<br />  Several different types of knots are considered in chapter 5, such as torus, satellite and hyperbolic knots. The latter are particularly interesting, since their study is part of the field of hyperbolic geometry, a subject that is now undergoing intense study. The author also introduces the theory of braids and the braid group. Not only are braids very important in the study of knots, but they have taken on major importance in cryptography and dynamical systems.<br />  Chapter 6 is very interesting, and introduces some of the more contemporary topics in knot theory. The assignment of polynomials to knots goes back to the early 20th century, but it took the work of Vaughan Jones and his use of ideas from operator theory and statistical mechanics to provide polynomial invariants of knots that were much finer than the Alexander polynomial of the 1930s. The Jones polynomial however is not introduced the way Jones did, but instead via the Kaufmann bracket polynomial. The HOMFLY polynomial is introduced as a polynomial that generalizes the Jones and Alexander polynomials.<br />  A few applications of knot theory are discussed in Chapter 7, such as the DNA molecule and topological stereoisomers. The author also discusses the applications of knot theory to the theory of exactly solvable models in statistical mechanics, a topic that has mushroomed in the past decade. This is followed by a brief overview of applications of knot theory to graph theory in chapter 8.<br />  Chapters 9 and 10 are an introduction to knot theory as it relates to research in the topology of 3-dimensional manifolds and the existence of knots in dimensions higher than 3. The concepts introduced, particulary the idea of a Heegaard diagram, are used extensively in the study of 3-manifolds. In addition, the author mentions the famous Poincare conjecture, albeit in non-rigorous terms. The Kirby calculus, which is a kind of generalization of the Reidemeister moves, but instead models the sequence of operations that allow one to change from one Dehn surgery description of a 3-manifold to another is briefly discussed. The author also gives a few elementary, intuitive hints about how to visualize knotted objects in high dimensions.interesting, since their study is part of the field of hyperbolic geometry, a subject that is now undergoing intense study. The author also introduces the theory of braids and the braid group. Not only are braids very important in the study of knots, but they have taken on major importance in cryptography and dynamical systems. <br />    Chapter 6 is very interesting, and introduces some of the more contemporary topics in knot theory. The assignment of polynomials to knots goes back to the early 20th century, but it took the work of Vaughan Jones and his use of ideas from operator theory and statistical mechanics to provide polynomial invariants of knots that were much finer than the Alexander polynomial of the 1930s. The Jones polynomial however is not introduced the way Jones did, but instead via the Kaufmann bracket polynomial. The HOMFLY polynomial is introduced as a polynomial that generalizes the Jones and Alexander polynomials. <br />  A few applications of knot theory are discussed in Chapter 7, such as the DNA molecule and topological stereoisomers. The author also discusses the applications of knot theory to the theory of exactly solvable models in statistical mechanics, a topic that has mushroomed in the past decade. This is followed by a brief overview of applications of knot theory to graph theory in chapter 8. <br />   Chapters 9 and 10 are an introduction to knot theory as it relates to research in the topology of 3-dimensional manifolds and the existence of knots in dimensions higher than 3. The concepts introduced, particulary the idea of a Heegaard diagram, are used extensively in the study of 3-manifolds. In addition, the author mentions the famous Poincare conjecture, albeit in non-rigorous terms. The Kirby calculus, which is a kind of generalization of the Reidemeister moves, but instead models the sequence of operations that allow one to change from one Dehn surgery description of a 3-manifold to another is briefly discussed. The author also gives a few elementary, intuitive hints about how to visualize knotted objects in high dimensions.	2002-06-27
1496509:US	50702879	R2NHR2LF2DGR2T	0691005486	675908909	The Topology of Fibre Bundles. (PMS-14)	Books	5	12	12	N	N	This is where it started	For those individuals who want an in-depth, insightful, and solid understanding of fiber bundles this book must be read. In spite of its date of publication, it still is of considerable value in this regard. Modern treatments of fiber bundles are very formal and the underlying motivation gets swept away in the thirst for rigor. Fiber bundles are now ubiquitous in differential topology, algebraic topology, differential geometry, and algebraic geometry, and have also found a place in theoretical physics, thanks to the success of gauge field theories. Therefore a mastery of fiber bundles is essential for entering any of these fields. But fiber bundles are fascinating objects in and of themselves, and studying them for their own sake needs no apology.<br />  The author does use some antiquated notation, but that is not really a hindrance to the study of the book. The reader will no doubt have some background in differential geometry and topology before attempting this book, so the appropriate translation to more modern notation should be straightforward. Once started, and with a little thought adjustment to the idiosyncracies of the author's writing style, the reader will find a plethora of neat examples and insights into the subject. In particular, part 3 on the cohomology theory of bundles is exceptionally valuable in that it gives the reader a detailed overview of the origin of what are not called Stiefel-Whitney classes. The theory of characteristic classes has of course advanced and matured extensively since this book first appeared, but all of the modern treatments are lacking in that they do not give the reader an appreciation of the fundamentals of the subject. Indeed, the construction of the obstruction to the construction of a cross-section to a bundle is the starting point for many of the ideas in obstruction theory that one finds in differential topology. And yes, the procedures the author uses can be &quot;cleaned-up&quot; and made more concise, but the price one pays in such an endeavor is the loss of an appreciation of the concepts behind the scene.<br />  Since the book is a monograph, there are no exercises, and this is probably the only minus to the book. Also, some knowledge of the German language would be useful to a reader who has it, since the author makes references to papers written in German and much of the terminology in the book shows its roots in the German language. One good example of this is the Reidemeister theory of cohomology groups based on a bundle of coefficients, called Uberdeckung by Reidemeister.<br />  There is no question as to why this book remains in print, and it will no doubt continue to be well into the 21st century. IT is a good example of the idea that something new may not be something better. After finishing it, the reader will be amply prepared to enter into the continually-evolving theory of fiber bundles and their applications, all of which are interesting and important.price one pays in such an endeavor is the loss of an appreciation of the concepts behind the scene. <br />   Since the book is a monograph, there are no exercises, and this is probably the only minus to the book. Also, some knowledge of the German language would be useful to a reader who has it, since the author makes references to papers written in German and much of the terminology in the book shows its roots in the German language. One good example of this is the Reidemeister theory of cohomology groups based on a bundle of coefficients, called Uberdeckung by Reidemeister. <br />     There is no question as to why this book remains in print, and it will no doubt continue to be well into the 21st century. IT is a good example of the idea that something new may not be something better. After finishing it, the reader will be amply prepared to enter into the continually-evolving theory of fiber bundles and their applications, all of which are interesting and important.	2002-06-26
1497278:US	50702879	R25VRDB9Z19YQ5	019879276X	678010221	Genes VII	Books	4	10	12	N	N	A definite improvement over Genes VI	In this edition, the author dramatically departs from the last one, both in content and order of presentation, and in the author's enthusiasm. He is clearly very excited about the developments in genetics that have taken place in the last decade, and this shows up everywhere in his writing. The book would be of interest to anyone interested in genetics, whether they are students, curious laymen, or mathematicians or physicists interested in the molecular biology behind genetics. The only minus to the book is the lack of exercises, the absence of which makes the understanding of the material more time consuming. A good background in biochemistry would be very helpful in the reading of the book.<br /> The book is a sizable one, and space does not permit a detailed review, but there are some areas in the book that stand out as being exceptionally well-written, thought-provoking, or helpful. As someone interested in bioinformatics, mathematical genetics, and mathematical modeling of metabolic processes, I read this book from the standpoint of these interests. With this in mind, some of the more interesting discussions in the book include: 1. The author constantly asks questions throughout the book, which help to clarify the issues and motivate the concepts in the book. He also points out the questions that are unanswered up to the date of publication, giving the research-oriented reader opportunities for further investigation. 2. The discussion on mutations, with the author pointing out the difference between point mutations and insertions/deletions, the role of revertants, and the occurrence of silent mutations. I wish he would have elaborated in more detail on the experiments that identified the mutations responsible for Mendel's famous wrinkled-pea mutants, i.e. the inactivation of the gene for a starch branching enzyme. 3. The discussion on the C-value paradox and the presence of large amounts of noncoding DNA in the larger genomes. This is an interesting problem for optimization theory. 4. The discussion on the mechanisms for gene reorganization. Again, this is an interesting question in optimization theory, especially the divergence between introns as a stabilizing factor that suppresses the occurrence of unequal crossing-over. The author gives examples of the effects of unequal crossing-over, such as human globin gene clusters. 5. The crossover fixation model and the time scales needed relative to mutation. 6. Satellite DNAs and their role in DNA fingerprinting. From an information theory standpoint, satellite DNAs are interesting since they are essentially long strings of DNA of low complexity. 7. The life cycle of mRNA and the neat electron micrograph illustrating beautifully the dynamics of gene expression. 8. The accuracy of translation; the author outlining the critical stages at which errors can be made. 9. The discussion on phage strategies. The dynamics of phages is very amenable to mathematical modeling. 10. They topological manipulation of DNA. Some results from the mathematical theory of knots, such as the writhing and twisting numbers, are playing a role here. 11. The discussion on transposons. The author speaks of the mobility of transposons, and the physical mechanisms employed for their transfer are elaborated on in detail. The theory of transposons has to rank as one of the most fascinating in all of genetics. 12. DNA rearrangements and their consequence, such as the creation of new genes and the switching of expression of one gene to another. The discussion on Crown gall disease is particularly interesting. 13. The discussion on the visualization of genes during transcription and the differences in the experimental results. 14. The regulation of transcription and the control mechanisms for eukaryotes. 15. RNA editing and how information is extracted from various sources. 16. The discussion on the development process in Drosophila. This chapter should begin to satisfy the reader who is curious about the molecular basis of development.<br /> Because of its high quality, this book will no doubt continue to be one of the canonical texts in genetics to be used now and in the future to prepare students and researchers in genetics. The career opportunities opening up in bioinformatics and genetic engineering have mushroomed in recent years, a lot of this driven by the needs of drug discovery and development. In this connection, the author asks the following question in the book: \\"If we could read out the entire sequence of DNA comprising the genome of some organism and interpret it in terms of proteins and regulatory regions, could we then construct an organism by controlled expression of the proper genes?\\" One can only hope that the answer to this question will be yes, as this will create one of the most exciting of all professions in the 21st century: the genetic designer.cular basis of development. <br /> Because of its high quality, this book will no doubt continue to be one of the canonical texts in genetics to be used now and in the future to prepare students and researchers in genetics. The career opportunities opening up in bioinformatics and genetic engineering have mushroomed in recent years, a lot of this driven by the needs of drug discovery and development. In this connection, the author asks the following question in the book: \\"If we could read out the entire sequence of DNA comprising the genome of some organism and interpret it in terms of proteins and regulatory regions, could we then construct an organism by controlled expression of the proper genes?\\" One can only hope that the answer to this question will be yes, as this will create one of the most exciting of all professions in the 21st century: the genetic designer.	2002-06-26
1501750:US	50702879	R28R16TEPMEJH	0716782014	606486187	Truth, Deduction, and Computation: Logic and Semantics for Computer Science (Principles of Computer Science Series)	Books	4	4	6	N	N	Good introduction	Having used this book to teach courses in elementary model theory, I can attest to its utility. It serves this purpose well, and the book is short enough to allow covering most of the material in the span of a semester. After finishing it, readers will be well prepared to tackle more advanced books in mathematical logic and model theory, or move into areas of artificial intelligence or logic programming. The most popular languages in artificial intelligence, namely LISP and PROLOG are based on the concepts in this book. Some of the areas that are not treated but can be accessed after reading the book include nonmonotonic logics, inductive logic programming, formal learning theory, higher-order languages, automated deduction, and the theory of object-oriented languages.<br />  The author discusses four languages in the book, namely propositional logic, predicate calculus, elementary number theory, and lambda calculus. The author's strategy in discussing each of these languages is to first discuss the syntax, and then move on to treat the truth, deduction, and computational aspects of them. As expected, propositional logic is the &quot;cleanest&quot; of the four languages, for its model theory is constructed via the use of truth tables. The computation, ground resolution is used, which gives a decision procedure for the language. The author shows that truth tables can be generated effectivey for a given well-formed formula, and thus the truth of the language is established. Completeness then implies the language is provable. Thus for propositional logic, the notions of truth, deduction, and computation are equivalent.<br />  For predicate calculus the situation is more complicated, requiring the use of general resolution. The author's treatment is very contemporary, in that it makes use of Horn clauses to implement the computation scheme. She again shows that truth, deduction, and computation are equivalent for predicate calculus, but that one cannot decide if a computation will yield a result. Given a sentence in the language, if it is provable, then the computation will terminate. Conversely, if the computation terminates successfully, then the sentence is provable. One cannot however put an upper bound on the computation, and so there is no gaurantee a priori that the program will terminate. The author tightens this situation even further by showing that the predicate calculus is undecidable.<br />  In the language of elementary number theory, the author clarifies the notion of an algorithm, and shows that this language is undecidable. She also overviews the famous Godel incompleteness theorems, which show the existence of a sentence that is true under the standard interpretation but which is not provable. Thus elementary number theory is not complete.<br />  In the language of lambda calculus, the author shows, interestingly, that expressions involving normal forms are not semantically distinguishable from expressions without normal forms. This forces a redefinition of normal form to that of a head normal form. The lambda calculus is then shown to be incomplete, except for the case where only normal forms are considered, wherein truth, deduction, and computation are shown to be equivalent. Even more interesting is the author's use of a concept of approximation between expressions which allows one to formulate the notion of limits. Topological notions are not used here, but instead the lambda calculus is extended by adding a special constant symbol (omega) to represent undetermined parts of normal forms. This allows the author to construct a partial normal form, and as a result define the notion of &quot;completeness in the limit&quot;.if a computation will yield a result. Given a sentence in the language, if it is provable, then the computation will terminate. Conversely, if the computation terminates successfully, then the sentence is provable. One cannot however put an upper bound on the computation, and so there is no gaurantee a priori that the program will terminate. The author tightens this situation even further by showing that the predicate calculus is undecidable. <br />      In the language of elementary number theory, the author clarifies the notion of an algorithm, and shows that this language is undecidable. She also overviews the famous Godel incompleteness theorems, which show the existence of a sentence that is true under the standard interpretation but which is not provable. Thus elementary number theory is not complete. <br />      In the language of lambda calculus, the author shows, interestingly, that expressions involving normal forms are not semantically distinguishable from expressions without normal forms. This forces a redefinition of normal form to that of a head normal form. The lambda calculus is then shown to be incomplete, except for the case where only normal forms are considered, wherein truth, deduction, and computation are shown to be equivalent. Even more interesting is the author's use of a concept of approximation between expressions which allows one to formulate the notion of limits. Topological notions are not used here, but instead the lambda calculus is extended by adding a special constant symbol (omega) to represent undetermined parts of normal forms. This allows the author to construct a partial normal form, and as a result define the notion of &quot;completeness in the limit&quot;.	2002-06-21
1508967:US	50702879	R2ACGHHGXBKA3S	0849331668	501961366	Statistical Genomics: Linkage, Mapping, and QTL Analysis	Books	5	6	9	N	N	Beautiful job	The author of this book defines genomics as the study of whole genomes via the integration of cytology, Mendelian-quantitative-population-molecular genetics with bioinformatics and automated sequencing. It attempts to answer, the author states, such questions as to the physical and chemical requirements of genomes, the possible necessity that genes be located at certain sites to function normally, that particular DNA sequences and structures needed for gene functions, the total number of functional genes necessary for a biological system, and the homology between the DNA sequences of different species. He addresses the book to biologists interested in statistical issues in genomics, for mathematicians in genomics, and for students of genetics.<br /> To satisfy these three classes of readers, she lists three different &quot;tracks&quot; for them consisting of a sequence of chapters recommended. Another good feature of the book is the inclusion of exercises at the end of each chapter, an absolute necessity for the understanding of this field. For those interested specifically in the efficacy of transgenic strategies in the design of viable breeds of plants and animals, this book will be helpful, for the author emphasizes in the book that the major application of genomics will be in finding optimal breeding strategies in agriculture and forestry.<br /> After a brief introduction in chapter 1, the author outlines briefly Mendelian, population, quantitative, and molecular genetics in chapter 2, each presented as a separate discipline. The author never really defines what a gene &quot;is&quot; in the context of molecular genetics, as he does in the disciplines, but instead views it as a sequence of base pairs in the DNA strands, which has the potential of being expressed via transcription, RNA splicing, and translation, to a particular protein. Fortunately, in one of the exercises at the end of the chapter, the reader finds a connection between molecular and classical genetics by examining a trait (viewed as a simple compound) of a hypothetical plant.<br /> Genomics as a discipline is introduced in chapter 3, and defined as the analysis of data from nuclear genomes, with the intent of learning about their structure, function, and evolution. Genome structure and sources of genome variation are discussed. Biological techniques in genomics are briefly discussed for interested readers. The author is careful to point out that complex traits cannot be related to the DNA sequences available currently as little is known about the molecular identity of most genes controlling these traits. Helpful diagrams are used to illustrate the important concepts, such as mating schemes, chromosome rearrangements, &quot;natural&quot; populations used in genomic research, RAPD, AFLP, and a diagram outlining the history of genetic markers.<br /> Chapter 4 is a summary of the mathematical statistics needed in the book, but the author does give an example of the methods, dealing with mapping a gene for resistance to fusiform rust disease.<br /> The statistical modeling of a single locus is carried out in chapter 5, as an example of what can be done, and as a warm-up for multiple locus models which follow later in the book. The author outlines how to detect segregation distortion using chi-square and log likelihood tests, and methods for determining sample size for marking screening using controlled crosses. The reader can get an idea of the importance of using PCR and RFLP to screen polymorphic genetic markers. A disequilibrium coefficient is defined and log likelihood methods are used to estimate it. Heterozygosity is defined in terms of allelic frequencies and estimated statistically. The author also details the use of Monte Carlo simulation to screen polymorphic markers.<br /> In chapter 6, the author uses goodness of fit, likelihood ratio tests, and recombination fraction estimation to perform two-locus linkage analysis. Newton-Rhapson methods are used to solve the (non-linear) likelihood equations for obtaining maximum likelihood estimates. The author answers the question as to how large the sample size should be for detecting linkage, with the expected log likelihood ratio test statistic being the tool for the determination of this. This analysis is generalized to the more difficult case of natural populations in chapter 7. Linkage disequilibrium is then used in chapter 8 to also study two-locus models. The transmission/disequilibrium test and other tests are discussed in the light of finding markers linked to disease genes.<br /> Linkage groups, defined as groups of loci inherited together according to statistical criteria, are studied in chapter 9. Locus ordering is considered and studied as a case, interestingly, of the traveling salesman problem, and some algorithms are proposed for its solution, such as seriation, simulated annealing, and branch-and-bound. But likelihood and bootstrap approaches are also discussed.<br /> Multi-locus models and the important concept of map distance are considered in chapter 10. This chapter is the most interesting and helpful in the book, for it discusses in detail the relationship between multi-point map distance and physical distance. Morgan's, Haldane's, Kosambi's, and other map functions are discussed. Also, and most importantly, the quality of a genomic map is quantified, using the confidence of estimated locus order and locus distribution on the map.<br /> The pooling or merging of linkage maps are considered in chapter 11, followed by the study of QTLs in chapter 12. Regression techniques are used for single-marker analysis and interval mappings are used to locate QTLs. QTL mappings for natural populations are discussed and the author considers the &quot;statistical power&quot; of QTL detection experiments. The question as to what QTLs really are is addressed, particularly the role of molecular biology and genomic mapping, and the limitations of QTL mapping. The author ends his discussion of QTLs by asking what would be the best approach for modeling a quantitative trait. A brief discussion of computer methods ends the book.<br /> After finishing the book and noting the explosive influence of molecular biology, it is natural to ask: Will statistical methods in genomics fade away and be replaced by deterministic methods based on molecular and metabolic models?used to solve the (non-linear) likelihood equations for obtaining maximum likelihood estimates. The author answers the question as to how large the sample size should be for detecting linkage, with the expected log likelihood ratio test statistic being the tool for the determination of this. This analysis is generalized to the more difficult case of natural populations in chapter 7. Linkage disequilibrium is then used in chapter 8 to also study two-locus models. The transmission/disequilibrium test and other tests are discussed in the light of finding markers linked to disease genes. <br /> Linkage groups, defined as groups of loci inherited together according to statistical criteria, are studied in chapter 9. Locus ordering is considered and studied as a case, interestingly, of the traveling salesman problem, and some algorithms are proposed for its solution, such as seriation, simulated annealing, and branch-and-bound. But likelihood and bootstrap approaches are also discussed. <br /> Multi-locus models and the important concept of map distance are considered in chapter 10. This chapter is the most interesting and helpful in the book, for it discusses in detail the relationship between multi-point map distance and physical distance. Morgan's, Haldane's, Kosambi's, and other map functions are discussed. Also, and most importantly, the quality of a genomic map is quantified, using the confidence of estimated locus order and locus distribution on the map. <br /> The pooling or merging of linkage maps are considered in chapter 11, followed by the study of QTLs in chapter 12. Regression techniques are used for single-marker analysis and interval mappings are used to locate QTLs. QTL mappings for natural populations are discussed and the author considers the &quot;statistical power&quot; of QTL detection experiments. The question as to what QTLs really are is addressed, particularly the role of molecular biology and genomic mapping, and the limitations of QTL mapping. The author ends his discussion of QTLs by asking what would be the best approach for modeling a quantitative trait. A brief discussion of computer methods ends the book. <br /> After finishing the book and noting the explosive influence of molecular biology, it is natural to ask: Will statistical methods in genomics fade away and be replaced by deterministic methods based on molecular and metabolic models?	2002-06-15
1515098:US	50702879	RPK9XYW0UL52L	0878934812	263948088	Genetics and Analysis of Quantitative Traits	Books	4	22	33	N	N	Comprehensive in scope	I read this book with the expectation that it would give me an idea of the extent to which organism traits or phenotypes are determined optimally. Discussions on evolution frequently regard the functioning and attributes of an organism as being optimal at the particular time in its evolutionary history. A successful theory of evolution as a theory of mathematical optimization would entail a thorough understanding of the evidence for this hypothesis of optimality of phenotypes.<br /> Another interesting question as to what effect a certain mixing of genetic factors, each one of these factors determining a phenotype separately (and optimally), would determine an optimal phenotype. An answer to this question would be important from the standpoint of transgenic strategies.<br /> But this book is not about optimization theory in genetics, but one that introduces the reader to an analysis, in the authors view, of how evolution happens, and not a predictive tool of what ought to evolve. And, as the authors correctly point out, the time scales needed to evolve an optimal phenotype are not usually dealt with in discussion on optimization strategies. The authors also argue that optimization theories do not consider the expected phenotypic variance or the influence of random drift or mutation. Quantitative genetics does this, they state, and they define it as a mechanistic theory of the evolutionary process.<br /> What is also interesting about quantitative genetics is that it was responsible directly or indirectly for a large body of statistical theory, many of these results being standard material in modern classes in statistics. It is also beginning to find an intersection with the theory of molecular genetics. The authors remark that eventually both quantitative and molecular genetics will have to answer to each other, and they give a taste of this in the chapter on marked-based analysis and QTLs.<br /> There is no question that the reading of this book will give the reader a comprehensive overview of quantitative genetics. But, it takes an very long time to get through, and there are no exercises to test the understanding. Readers will need a fair knowledge of statistics to read the book, but there are three chapters and appendices in the back of the book outlining some of the necessary statistical concepts. The level of mathematics is the most sophisticated in the last chapter, which uses techniques such as maximum likelihood, expectation maximization, and restricted maximum likelihood. Readers with a background in bioinformatics will be very familiar with these techniques. Newton-Rhapson methods and Fisher's scoring method are discusses as derivative-based methods for solving the ML/REML equations and compared with the EM methods for doing the same. The authors are very convincing in informing the reader of the difficulty in estimating genetic variance components in real populations. Also, and most importantly, there are myriads or real-world examples given to illustrate the theory.<br /> For molecular geneticists, and for those very curious about the connection between molecular biology and quantitative genetics, chapter 14, covering the principles of marker-based analysis, would probably be the most interesting in the book. The treatment is both historical, discussing the effects of entire chromosomes, and modern, discussing topics such as using markers or the construction of nearly isogenic lines and cloning individual QTLs. In the 'classical' approach to marker-based methods the authors discuss chromosomal assays, wherein a chromosome from one line is substituted into a standard genetic background chosen to have minimum variance. Since a chromosomal segment may contain a large position of the total genome, the authors take what could be called a 'coarse-grained' approach that utilizes genetic factors rather than a 'microscopic' one emphasizing individual genes. Such a strategy requires large sample sizes if one is to detect factors that result in extremely small effects. Examples of this approach are given, and the authors discuss its weaknesses, one being that a large chromosomal section can have QTLs that have effects in opposite directions, resulting in a net effect close to zero. Thoday's method is also discussed in order to point out the limitations of using flanking-marker mapping methods. The genetics of Drosophila bristle number is also briefly treated, but many references are given.<br /> Recoginizing that direct sequencing of DNA gives a measure of genetic variation, the authors point out though that restriction fragment length polymorphisms are suitable for most purposes, assuming that these are detectable. The advantages and disadvantages of other techniques, such as randomly amplified polymorphic DNAs, are also discussed. The arithmetic involved in genetic mapping is treated in fair detail, the authors overviewing what is involved mathematically in map distances, recombination frequencies, and in the estimation of how many randomly distributed markers are needed to gaurantee that a portion of the genome is within a given number of map units of a marker. The strategies for mapping and cloning of QTLs are the main emphasis in the rest of the chapter. Some of the more interesting discussions here include: 1. The phenomena of 'linkage drag', wherein linked undesirable geness can be dragged along with the marker; 2. Candidate loci and their use in the study of genetic disorders. The authors outline in great detail the problems with this approach, such as linkage disequilibrium; 3. Gene cloning and its use in the study of QTLs. The authors discuss two different cloning strategies, namely that of transposon tagging and positional cloning. The authors emphasize the need for inbred lines for the detection of QTLs by transposon tagging to reduce variance from segregation at other loci. Because of this need, they seem skeptical of the general use of this technique, but give a brief argument as to its possible success using homologies in sequence data between species. The authors also emphasize the complexity involved in the use of positional cloning and comparative mapping and then outline an algorithm as to how to use NILs to do positional cloning of a QTL.ct factors that result in extremely small effects. Examples of this approach are given, and the authors discuss its weaknesses, one being that a large chromosomal section can have QTLs that have effects in opposite directions, resulting in a net effect close to zero. Thoday's method is also discussed in order to point out the limitations of using flanking-marker mapping methods. The genetics of Drosophila bristle number is also briefly treated, but many references are given. <br /> Recoginizing that direct sequencing of DNA gives a measure of genetic variation, the authors point out though that restriction fragment length polymorphisms are suitable for most purposes, assuming that these are detectable. The advantages and disadvantages of other techniques, such as randomly amplified polymorphic DNAs, are also discussed. The arithmetic involved in genetic mapping is treated in fair detail, the authors overviewing what is involved mathematically in map distances, recombination frequencies, and in the estimation of how many randomly distributed markers are needed to gaurantee that a portion of the genome is within a given number of map units of a marker. The strategies for mapping and cloning of QTLs are the main emphasis in the rest of the chapter. Some of the more interesting discussions here include: 1. The phenomena of 'linkage drag', wherein linked undesirable geness can be dragged along with the marker; 2. Candidate loci and their use in the study of genetic disorders. The authors outline in great detail the problems with this approach, such as linkage disequilibrium; 3. Gene cloning and its use in the study of QTLs. The authors discuss two different cloning strategies, namely that of transposon tagging and positional cloning. The authors emphasize the need for inbred lines for the detection of QTLs by transposon tagging to reduce variance from segregation at other loci. Because of this need, they seem skeptical of the general use of this technique, but give a brief argument as to its possible success using homologies in sequence data between species. The authors also emphasize the complexity involved in the use of positional cloning and comparative mapping and then outline an algorithm as to how to use NILs to do positional cloning of a QTL.	2002-06-09
1515396:US	50702879	R1PABJ50EXLRE1	0471316180	103272497	Genomes	Books	4	3	4	N	N	Good overview of modern genetics	Because of the explosion of genetics research and technology in today's world, many textbooks and monographs on the subject have appeared. This book is certainly one of the finest of these, and emphasizes, as stated in the the preface, the major research issues in genetics, rather than issues that were important two decades ago. Genomes, not genes, the author states, should be the topic of primary focus. The more fundamental 'microscopic' processes such as DNA replication and mutation are studied in terms of their effects on the genome. This reflects the current move in genetics to find common ground between classical genetics and modern molecular genetics. Clearly the author is very excited about the developments in genetics that have taken place in the last decade, and this shows in his writing. The only major omission in the book is the lack of exercises; these are of upmost importance in the learning process. The book, written for beginning graduate students, could also be useful to mathematicians, physicists, or computer scientists who are moving into bioinformatics or computational biology.<br /> Some of the more interesting discussions in the book include: 1. The C-value paradox: The correlation between the complexity of an organism and the size of its genome is explained by a space optimization argument, i.e. the genomes of simpler organisms conserve space by packing the genes closer together. 2. Using DNA markers versus gene markers for genetic mapping. 3. Single nucleotide polymorphisms, oligonucleotide hybridization analysis, and their use in DNA chip technology and dynamic allele-specific hybridization. 4. The need for physical mapping techniques and the discussion on the discrepancies between genetic and physical maps of S. cerevisiae chromosome III. 5. The use of orthogonal field alternation gel electrophoresis to separate  molecules of more than 50kb in length. 6. Rapid sequence acquisition strategies, such as expressed sequence tags and sequence skimming. 7. The ethicial ramifications of the Human Genome Project. 8. The difficulty of existing software programs to assist in the location of exon-intron boundaries. 9. Homology searching and analysis. 10. The telomere and the  role of telomeric proteins in capping chromosome ends. 11. The location of genes and the isochore model of genome organization. 12. The role of extra chromosomal genes in explaining inheritance patterns of some phenotypes in fungi, yeasts, and algae. 13. The (unanswered) questions as to why organelle genomes cannot be transported through the membranes that surround mitochondira and chloroplasts. 14. The discovery in the 1980s that DNA transfer from organelle to nucleus still occurs and the role of promiscuous DNA. 15. The experimental evidence that genes are made of DNA. 16. The role of bacterial RNA polymerase as a 'sliding clamp'. 17. The three-dimensional structure of tRNA. 18. Ribosome frameshifting. 19. Transient changes in genome activity. 20. Rearrangements of genomes 21. Genome regulation by feedback loops. 22. The genetic basis of flower development. 23. Mutations and recombination. Readers interested in genetic algorithms will appreciate this discussion. 24. The experimental detection of mutations. 25. Adapative mutations in E. coli. Because of its challenge to the current paradigm of evolution, this discussion was particularly interesting. 26. Evidence for ancient genome duplication and molecular phylogenetics.mming. 7. The ethicial ramifications of the Human Genome Project. 8. The difficulty of existing software programs to assist in the location of exon-intron boundaries. 9. Homology searching and analysis. 10. The telomere and the  role of telomeric proteins in capping chromosome ends. 11. The location of genes and the isochore model of genome organization. 12. The role of extra chromosomal genes in explaining inheritance patterns of some phenotypes in fungi, yeasts, and algae. 13. The (unanswered) questions as to why organelle genomes cannot be transported through the membranes that surround mitochondira and chloroplasts. 14. The discovery in the 1980s that DNA transfer from organelle to nucleus still occurs and the role of promiscuous DNA. 15. The experimental evidence that genes are made of DNA. 16. The role of bacterial RNA polymerase as a 'sliding clamp'. 17. The three-dimensional structure of tRNA. 18. Ribosome frameshifting. 19. Transient changes in genome activity. 20. Rearrangements of genomes 21. Genome regulation by feedback loops. 22. The genetic basis of flower development. 23. Mutations and recombination. Readers interested in genetic algorithms will appreciate this discussion. 24. The experimental detection of mutations. 25. Adapative mutations in E. coli. Because of its challenge to the current paradigm of evolution, this discussion was particularly interesting. 26. Evidence for ancient genome duplication and molecular phylogenetics.	2002-06-09
1523390:US	50702879	R38X18ZH3FIIJ4	0684843285	809832535	On Food and Cooking	Books	5	23	26	N	N	Excellent	For those who are interested in the physics and chemistry of cooking, this book is one of the few in existence that gives a fairly detailed overview. The author's account is purely descriptive, and does not involve any mathematics, but it is very interesting reading and is accessible to all who want to approach cooking in a more in-depth fashion. My review will cover the 1984 edition of this book.<br /><br />A lot of my questions regarding utensils, baking and frying temperatures, and food preparation were answered by the author. Specifically, the following questions, some of which I wondered about while musing in the kitchen over the years, are answered by the author (and other readers will no doubt find many more of their own answered also): 1. What are the role of casein particles in giving milk the appearance it has? 2. How does the homogenization of milk prevent milk from separating and forming a layer of cream at the top? 3. Why do some people prefer acidophilus milk? 4. Why should milk be kept out of high intensity light? 5. Why is it best to chill the bowl and beaters before whipping cream? 6. What is the basic structure of butter? 7. What is the difference between \\"ghee\\" and clarified butter? 8. How is cheese made? 9. What factors contribute to the degradation in flavor of eggs after being laid? 10. What is the role of water loss in the effective cooking of eggs? 11. What is the occasional greenish-gray appearance on hard-boiled eggs? 12. What is the optimum temperature range for frying eggs? 13. Why does the egg yolk degrade the volume of egg foams? 14. What keeps the egg foam from collapsing in the actual cooking phase? 15. What role does cream of tarter have in the volume of egg foams? 16. Why do you whip egg whites at room temperature? 17. Is there really an advantage in using copper bowls to whip egg whites? 18. Why is fish flaky rather than firm like birds and mammals? 19. Does the way an animal is slaughtered play any role in the flavor of the resulting meat? 20. What is the role of aging on the flavor of meat? 21. Why do meat leftovers typically taste different than the freshly cooked? 22. Does the searing of meat really retain the inner moisture? 23. Why is it best to cut off the green tuber portions of potatoes before preparing the potatoes for consumption? 24. Why should one refrain from eating apple seeds? 25. What is the role of ethylene in speeding up ripening? 26. What is the optimum temperature range to cook french fries? 27. How does okra thicken soups and sauces? 28. Why is saffron so expensive? 29. What is converted rice? 30. Why does popcorn pop? (The author gives an \\"educated guess\\"). 31. Why is a diet dominant in corn dangerous? 32. What are the historical origins behind the names Kellogg and Post? 33. How is soy sauce made? 34. Why do legumes cause gas after consumption? 35. What is the role of gluten in the kneading of bread dough? 36. Why does bread go stale in storage? 37. How does starch thicken a sauce? 37.What is the best way to make fudge? 38. How is beer made and what are the most critical factors in the process? 39. How long in human history have additives been put into food?<br /> The author also inserts many interesting photographs into the book, such as photographs of a yolk granule and the ripening bacteria in Gouda chesse, both taken through a scanning electron microscope. In addition, detailed discussions are given of general nutrition and body chemistry. The book ends with a helpful summary of the general principles behind cooking.<br /> This is an excellent book and should be on the shelf of all who are seriously into cooking. It has been very helpful in my own musings in the kitchen. But alas, despite the advice given in this book, and many others, I have have never been able to make buttercream frosting without it curdling. Life is hard.ng meat? 20. What is the role of aging on the flavor of meat? 21. Why do meat leftovers typically taste different than the freshly cooked? 22. Does the searing of meat really retain the inner moisture? 23. Why is it best to cut off the green tuber portions of potatoes before preparing the potatoes for consumption? 24. Why should one refrain from eating apple seeds? 25. What is the role of ethylene in speeding up ripening? 26. What is the optimum temperature range to cook french fries? 27. How does okra thicken soups and sauces? 28. Why is saffron so expensive? 29. What is converted rice? 30. Why does popcorn pop? (The author gives an \\"educated guess\\"). 31. Why is a diet dominant in corn dangerous? 32. What are the historical origins behind the names Kellogg and Post? 33. How is soy sauce made? 34. Why do legumes cause gas after consumption? 35. What is the role of gluten in the kneading of bread dough? 36. Why does bread go stale in storage? 37. How does starch thicken a sauce? 37.What is the best way to make fudge? 38. How is beer made and what are the most critical factors in the process? 39. How long in human history have additives been put into food? <br /> The author also inserts many interesting photographs into the book, such as photographs of a yolk granule and the ripening bacteria in Gouda chesse, both taken through a scanning electron microscope. In addition, detailed discussions are given of general nutrition and body chemistry. The book ends with a helpful summary of the general principles behind cooking. <br /> This is an excellent book and should be on the shelf of all who are seriously into cooking. It has been very helpful in my own musings in the kitchen. But alas, despite the advice given in this book, and many others, I have have never been able to make buttercream frosting without it curdling. Life is hard.	2002-06-02
1525770:US	50702879	R1JBR4DOF12MPK	0080428002	778873617	Neural Networks and Genome Informatics, Volume 1 (Methods in Computational Biology and Biochemistry)	Books	3	4	6	N	N	Good as a literature survey	This book serves well to introduce the reader to the literature on the applications of neural networks to bioinformatics. It falls short however in giving an in-depth view of how neural networks operate and does not include any source code. Performance issues with the use of neural networks in genome informatics should have been given a more careful treatment.  Considering its price, this is disappointing. A reader could obtain the required reading material on this subject from an online search. An instructor in a course in bioinformatics might use this book as a reference source however. Those who have used neural networks in other fields might be able to use the book as a guide to applying them to genome informatics. Thus the book could be viewed as a (very expensive) literature review article, but it does include some interesting remarks at various places: 1. Amino acid groupings that are found automatically by a Kohonen self-organizing map. 2. Feature representation and input encoding. 3. The discussion on cross-validation. 4. The discussion on protein secondary structure prediction. Genetic algorithms are mentioned here, so readers not familiar with these will have to gain the background elsewhere.	2002-05-30
1526040:US	50702879	RXJ2Q7SUJWADC	0226474089	690100742	An Introduction to Legal Reasoning (Phoenix Books)	Books	4	74	85	N	N	A fine introduction to the subject	For those going into the legal profession, and for those curious about the logic of legal procedures, this book offers and excellent introduction. Its length will suit those readers who want a quick but accurate overview of this topic. It might also satisfy the needs of a reader in a field of endeavor somewhat removed from the legal profession, namely, that of artificial intelligence. Artificial and computational intelligence has been applied to the legal profession with the goal of creating automated legal reasoning machines. My interest in the book was somewhat different when I first read it years ago, but now has been reactivated from the standpoint of artificial intelligence.<br /> The author describes his book as an attempt to give a general description of the process of legal reasoning in case law and in statutorial and constitutional interpretation. He emphasizes right at the beginning that the law should not be viewed as a known system of rules that are applied by a judge, that legal rules are never clear, and that a requirement for such clarity would make society impossible. Ambiguity in the rules he says, allows collective participation to resolve the ambiguity. Such a characterization of legal rules by Levi prohibits an axiomatic or formal approach to legal reasoning, and this will make the problem of creating automated legal reasoners much more difficult.<br /> Interestingly, Levi quotes Aristotle in asserting that the pattern of legal reasoning consists of reasoning by example, and that it follows a three-step process: With the doctrine of precedent assumed throughout, a proposition describing a particular case is made into law and then this rule is applied to a situation that is similar to these. Thus: 1. The cases are shown to be similar. 2. The rule of law in the first case is announced 3. This rule is then applied to the second case. It is the finding of similarity in both cases that would entail, in the context of a legal reasoning machine, the use of data mining techniques coupled with a formalization of the Aristotelian \\"reasoning by example\\" that is discussed by Levi.<br /> An interesting part of Levi's discussion on the determination of similarity (or difference) is that this determination is dependent on the judge. When a statute does not exist, and case law is being considered, the judge is free to dismiss teh facts that the prior judge may have considered important. The doctrine of \\"ratio decidendi\\" in legal philosophy, and has been the subject of intense investigation. A formal or computational model of ratio decidendi must come to terms with this tension between precedent and judicial discretion.<br /> In addition, Levi argues, the rules are discovered in the process of determining the similarities (or differences). This dynamism in legal reasoning is not too different from what happens in scientific research, for in the latter new laws (rules) are discovered in the process of interpreting new data that has been acquired by new experiments. The data may then have to be re-interpreted in the light of the new laws (rules) that are formulated. Future data that is similar to this data will then be interepreted under these new rules. Future data that is very different from this may entail a new set of rules be invented (discovered) to deal with this difference.<br /> The issue then, Levi explains, is to when one must view different cases as the same. An intersection of the set of facts of two cases entails a general rule be applied. This \\"reasoning\\" is imperfect, Levi argues, since the conclusions were arrived at by a process that was not transparent. Levi summarizes this as a process in which the classification changes as the classification is made, i.e., the rules change as they are applied. This might seem troubling to some, but Levi explains that such a situation is desirable since without it, new ideas could not enter into the legal process. Thus a static view of the legal process where consequencesare derived from a closed system of rules is not useful in legal reasoning. In addition, Levi argues, fairness to the parties involved in litigation is served best by this ambiguity in legal categories. The commonality of the ideas of society coupled with the contributions made by legal experts both serve to shape the law.<br /> Levi also discusses the role that reasoning by example has in the interpretation of case law, statutes, and the Constitution. The intent of the legislature enters into the consideration of the statute by subsequent judges, and so these judges have less flexibility in applying a statute than they would in the consideration of case law. Interestingly, Levi argues that the case for constitutional law is different, in that the judge has more freedom than was the case for statutorial or case law. The court can be inconsistent in this case, says Levi, but this freedom is masked under the guise of a search for the intent of the framers of the Constitution or as a characterization of the Constitution as a \\"living document\\".nces are derived from a closed system of rules is not useful in legal reasoning. In addition, Levi argues, fairness to the parties involved in litigation is served best by this ambiguity in legal categories. The commonality of the ideas of society coupled with the contributions made by legal experts both serve to shape the law. <br /> Levi also discusses the role that reasoning by example has in the interpretation of case law, statutes, and the Constitution. The intent of the legislature enters into the consideration of the statute by subsequent judges, and so these judges have less flexibility in applying a statute than they would in the consideration of case law. Interestingly, Levi argues that the case for constitutional law is different, in that the judge has more freedom than was the case for statutorial or case law. The court can be inconsistent in this case, says Levi, but this freedom is masked under the guise of a search for the intent of the framers of the Constitution or as a characterization of the Constitution as a \\"living document\\".	2002-05-30
1527321:US	50702879	RQ0MYBF3RV39C	0805016058	830951462	You Shall Be As Gods: A Radical Interpretation of the Old Testament and Its Tradition	Books	5	56	60	N	N	Highly interesting and very original	Erich Fromm is not only an interesting thinker but a fine writer, and in this book, one of many that he has written and all of which I have read, he outlines what he calls a radical humanist interpretation of the Old Testament and its history and traditions. In this interpretation, the concept of God evolved from that of a jealous, vengeful spirit to that of a constitutional monarch, and ultimately to a nameless God who is bound by the same morals and principles that govern humankind. Fromm is convincing in his arguments, and even for those readers who will remain unconvinced after the reading of the book, all will no doubt take away an appreciation of the depth of his scholarship.<br /> All of the three major Western religions: Islam, Christianity, and Judaism, owe their origins to the Old Testament, whether this is acknowledged or not, and all have to this day a powerful influence on the lives of millions of people. And yes, as Fromm states in the book, the world's populations do hold a materialistic philosophy that is coupled with ever-increasing globalization and technology, but the acquisition of material goods and the indulgence of their pleasures coexists with a commitment to spirtual values and religion. This superposition of religious and materialistic philosophy shows no sign of abatement.<br /> The radical humanism of Fromm is a philosophy that is delightfully optimistic, and emphasizes the capacity of humans to develop their intellectual powers, to become fully independent, to understand reality as it  is, and a renunciation of the initiation of force, the latter of which, Fromm argues, results in intellectual disintegration and emotional dependence. Eschewing a static allegiance to doctrines and concepts that therefore become divorced from experience, Fromm encourages the thinking of concepts as dynamic objects, and cautious that \\"they have their own lives\\", and can be aliented from the experiences by which they were invented (discovered). Forgetting the roots of a conceptual structure in experience will transform it to ideology, argues Fromm, and this ideology will usurp the underlying reality of human experience. History will become a history of ideologies, rather than a history of concrete, real individuals who produce ideas. Conceptual structures according to Fromm can never adequately express the experience from which they refer to, and the symbols used allow communication of experiences. But, this also allows an alienation of their use, since such structures are incomplete, and a rush to fill in the gaps, to pad the system, results in one that appears complete, but in reality is still fragmented. It then tends to a state of stagnation and sterility, making it inert and useless. Such is the history of religious concepts in particular, asserts Fromm.<br /> Fromm's interpretation of the Old Testament is essentially as follows: Stage 1: A dictatorial God as absolute ruler, jealous of the human potential to be God's rival. The use of force and brutality characterizes such a God, who expels Adam and Eve from Paradise and limits human lifetime to 120 years. Stage 2: God establishes a covenant with Noah and his descendants, promising to never again flood the Earth. For Fromm, the concept of the covenant is one of the most decisive steps in the evolution of Judaism, in that it leads to a conception of complete freedom for humankind, in particular freedom from God. God and human beings become partners in a treaty, this transforming God from an absolute ruler into a constitutional monarch. God then has less freedom to be brutal, to disrepect human life and other living creatures. Abraham's numerical challenge to God at Sodom and Gommorrah is offered in evidence. Abraham's confidence in the principle of universal justice is a departure from the concept of human beings as meek supplicants, fearful of God's reprisals. Stage 3: The rejection of idols and the subsequent concept of God as a nameless God. One must talk to God, not about him, the latter results in idolatry. The philosophy of Moses Maimonides is offered as evidence of this. The \\"negative theology\\" of Maimonides allows only the employment of attributes of actions of God. Both God and humans in this stage become subjected to the same universal principles of truth and justice, and their relationships is no longer confrontational . Conceptions of God then evolve to the more abstract, with God working through history (\\"horizontally\\"), and not into it (\\"vertically\\").<br /> Fromm's viewpoints on sin and repentance are also very interesting. He points out that in the story of Adam's fall, no mention is made of Adam having committed a sin. Fromm also gives interesting arguments that support his notion that the Old Testament scriptures do not state that humans are intrinsically evil. Humans can choose good with the same potential as their choice for evil, is his reading of these scriptures. The Biblical view, at least from the standpoint of the Old Testament, argues Fromm, is that humans can choose between life and death, good versus evil, and their does not exist any compulsion to choose one rather than the other. God points out the alternatives and asks us to choose life and the good.<br /> Erich Fromm has been away from us for 22 years now, but his writings are to this day still studied diligently by many individuals and they still have a lot to say about human beings, their beliefs, and their relationship to reality. With the complexity of life and knowledge increasing at an accelerating rate, humans now can make copies of themselves, can create thinking machines from mere sand, can travel in space, and can live their lives in ways that the ancient writers of the Old Testament never envisioned. Fromm translates Deuteronomy 30:19:  \\"....I have set before you life and death, choose life....\\". I think if Fromm were alive, being the optimist he is, he would be proud of what humans now stand for, despite some areas of conflict in the world.<br /> Humans have indeed chosen life, and have become as gods.......God, not about him, the latter results in idolatry. The philosophy of Moses Maimonides is offered as evidence of this. The \\"negative theology\\" of Maimonides allows only the employment of attributes of actions of God. Both God and humans in this stage become subjected to the same universal principles of truth and justice, and their relationships is no longer confrontational . Conceptions of God then evolve to the more abstract, with God working through history (\\"horizontally\\"), and not into it (\\"vertically\\"). <br /> Fromm's viewpoints on sin and repentance are also very interesting. He points out that in the story of Adam's fall, no mention is made of Adam having committed a sin. Fromm also gives interesting arguments that support his notion that the Old Testament scriptures do not state that humans are intrinsically evil. Humans can choose good with the same potential as their choice for evil, is his reading of these scriptures. The Biblical view, at least from the standpoint of the Old Testament, argues Fromm, is that humans can choose between life and death, good versus evil, and their does not exist any compulsion to choose one rather than the other. God points out the alternatives and asks us to choose life and the good. <br /> Erich Fromm has been away from us for 22 years now, but his writings are to this day still studied diligently by many individuals and they still have a lot to say about human beings, their beliefs, and their relationship to reality. With the complexity of life and knowledge increasing at an accelerating rate, humans now can make copies of themselves, can create thinking machines from mere sand, can travel in space, and can live their lives in ways that the ancient writers of the Old Testament never envisioned. Fromm translates Deuteronomy 30:19:  \\"....I have set before you life and death, choose life....\\". I think if Fromm were alive, being the optimist he is, he would be proud of what humans now stand for, despite some areas of conflictin the world. <br /> Humans have indeed chosen life, and have become as gods.......	2002-05-29
1531584:US	50702879	R1VUC0ORCCECWC	1579550088	20378952	A New Kind of Science	Books	3	28	34	N	Y	A good introduction to cellular automata	In this gargantuan treatise, which has appreciable gravitational pull, the author introduces the reader to the tools and science of cellular automata. Some of the proposals in the book are radical (such as the Principle of Computational Equivalence), some fairly conservative, and some unjustifield,  but it does serve to introduce cellular automata from the standpoint of an individual who has been very active in their study and development. The book is long, and space does not permit a detailed review here, but one can read the book in its entirety in a fairly short time frame since the margins are large and there are an abundance of diagrams in the book which take up page space. Also a very large (338 pages) part is devoted to notes in the back of the book.<br /><br /> Different viewpoints on science and mathematics require both formal and empirical justification. The author does this in some areas of the book, but not all, and the ones left open are left to the reader to speculate on. Because of this it is not clear the book will have a major influence on scientific research. One would want more examples of the power of cellular automata in solving difficult problems in mathematics and science before deciding to use them in the everyday practice of scientific research.<br />  Throughout the book, the author repeatedly suggests that simple rules in cellular automata can result in complex or &quot;random&quot; behavior, but never really quantifies what he means by randomness. The patterns generated &quot;seem&quot; random to him, as he says repeatedly, but other readers may disagree. He attempts to define it more precisely in his discussions on the processes of perception and analysis, but again the discussion is purely qualitative. In addition, the rule for generating the patterns is known in advance. In actual research however, one is given a collection or pattern of data and attempts to discover the rules behind it. Thus all of the patterns in the book are really quite simple, since the rules are known for generating them. If one is given one of these patterns without knowing the rules, it might be very difficult to find these rules. Such is the headache of modern science. Also, randomness is a concept that depends on the time scale chosen. Transient behavior of physical systems may appear random on short time scales, but for long time scales the system approaches periodic or quasiperiodic behavior. Also, sometimes one can &quot;quench&quot; apparent randomness in a system by a transformation of coordinates, which says that behavior that looked random was only due to a particular coordinate system chosen to characterize the system.<br /> The author does distinguish three mechanisms for randomness, one being an explicit introduction of randomness into the rules of the system; another being randomness in the initial conditions; and the third being randomness from the environment. The discussion is purely qualitative and leaves the reader wanting as to what tools are needed to detect or distinguish these forms of randomness from each other in the time evolution of the system under study. The detection and use of noise in physical systems is of course of paramount importance to applied science and engineering, and practitioners in these areas will need a more quantitative presentation than what is given by the author. It is clear that the author considers &quot;randomness&quot; as being in some sense fundamental or ontological, since the seemingly random behavior of discrete systems can produce for example, interesting behavior, such as mathematical continuity.<br /> Even the characterization of systems or rules as &quot;simple&quot; can be quite difficult to define from a fundamental point of view. The concept of Kolmogorov complexity has shown some headway in defining simplicity, but its elucidation has been omitted from the book, no doubt because of its use of &quot;traditional&quot; mathematics, which the author has steadfastly avoided in the book. There are many examples in &quot;traditional&quot; mathematics however that give the kinds of behavior the author finds fascinating, many of these found in the area of dynamical systems. And here again, the complexity of a problem or system may be dependent on the vantage point of an observer. The inability of &quot;Eve&quot; to decipher the elliptic curve factorization choices of &quot;Bob&quot; and &quot;Alice&quot;, makes Eve's situation very complex from her standpoint. Bob and Alice however have chosen a procedure based on a &quot;simple&quot; group operation on elliptic curves.<br /> Interestingly, the author has not chosen to discuss quantum computation in this book, in spite of its current importance. His claim that that the Principle of Computational Equivalence is a law of nature that will prohibit systems from carrying out computations more sophisticated than cellular automata and Turing machines suggests that quantum computers can be reduced to these systems, a claim that is profound but difficult to prove. Quantum mechanics and quantum field theory are discussed briefly in the book, but no in-depth suggestions are given as to how to apply cellular automata to resolving difficult and nagging problems in these areas, unfortunately.<br /> Speaking now independently of the content of the book, it was written and then delivered to its readers outside the confines of peer-reviewed academic journals. The author is to be applauded for this move, for it shows an independence of spirit and follows a trend that hopefully will increase in the decades ahead. With electronic publishing and Internet postings of scientific results, this leaves readers the privilege of making up their own minds as to the scientific worth of a particular document. Thus one can read this book as the author intended it, and free from the influence of anonymous referees. The author has written it, marketed it, and put his name on it, and he clearly is, and should be, proud of his many achievements to this date. One can disagree with the content of this book, but it is an attempt to view things from a different point of view, and 21st century science needs more of this, not lessstly avoided in the book. There are many examples in &quot;traditional&quot; mathematics however that give the kinds of behavior the author finds fascinating, many of these found in the area of dynamical systems. And here again, the complexity of a problem or system may be dependent on the vantage point of an observer. The inability of &quot;Eve&quot; to decipher the elliptic curve factorization choices of &quot;Bob&quot; and &quot;Alice&quot;, makes Eve's situation very complex from her standpoint. Bob and Alice however have chosen a procedure based on a &quot;simple&quot; group operation on elliptic curves. <br /> Interestingly, the author has not chosen to discuss quantum computation in this book, in spite of its current importance. His claim that that the Principle of Computational Equivalence is a law of nature that will prohibit systems from carrying out computations more sophisticated than cellular automata and Turing machines suggests that quantum computers can be reduced to these systems, a claim that is profound but difficult to prove. Quantum mechanics and quantum field theory are discussed briefly in the book, but no in-depth suggestions are given as to how to apply cellular automata to resolving difficult and nagging problems in these areas, unfortunately. <br /> Speaking now independently of the content of the book, it was written and then delivered to its readers outside the confines of peer-reviewed academic journals. The author is to be applauded for this move, for it shows an independence of spirit and follows a trend that hopefully will increase in the decades ahead. With electronic publishing and Internet postings of scientific results, this leaves readers the privilege of making up their own minds as to the scientific worth of a particular document. Thus one can read this book as the author intended it, and free from the influence of anonymous referees. The author has written it, marketed it, and put his name on it, and he clearly is, and shouldbe, proud of his many achievements to this date. One can disagree with the content of this book, but it is an attempt to view things from a different point of view, and 21st century science needs more of this, not less	2002-05-25
1532138:US	50702879	R3HIDUJ9ZTKAMK	3822870315	725972234	Masterpieces of Western Art: A History of Art in 900 Individual Studies	Books	4	12	16	N	N	A fine overview	A book thorough in its presentation of Western art from the Gothic period on through the period of Neoclassicism, the authors of the chapters in it have given the reader a fine overview of the art techniques used in this time period. They also attempt to explain the various rationale and motivations of the artists themselves in creating the artforms that they did. These attempts will of course remain points of controversy, for it is difficult, and the authors cannot claim with certainty, any correlation between the artforms and the political, personal, and social philosophies of the time periods discussed. But the author's speculations on these reasons entice readers to form their own, and this enhances the didactic quality of the book.<br /> In the discussion of the Gothic era, for example, the author (Robert Suckale) claims that the art of this period was to be contrasted with that of the Middle Ages, which exclusively produced works that protrayed life in the hereafter. A sharp boundary would be difficult to draw between the Gothic and Middle Ages though, so it should be concluded that his statement is one that could be characterized as dealing with \\"averages\\" over the works produced. Certainly some exceptions or deviations could be found in the works of the Gothic era as well as the Middle Ages. It might be perhaps more precise to classify time periods in art relative to the techniques used rather than the content, especially when comparing two points in history that are separated by a relatively short time scale. Therefore it is easier to accept that art at the end of the Gothic period was very different in content than the beginning of the Middle Ages, but as one shrinks the time scale separating these endpoints, the distinction becomes more difficult.<br /> in addition, Suckale emphasizes the role of the artist as architect in the Gothic period, with geometrical considerations viewed as \\"natural\\" and therefore subject to the dynamism displayed by nature. This lead to complex mathematical configurations coupled with intricate non-geometric components. The \\"fresco\\" technique had its origin in this time period, and Suckale takes the reader through the process of how this was done, it requiring the artist to work very quickly. The ramifications of the Black Death on commerce at the time influenced art dramatically, Suckale argues, and resulted, interestingly, with an explosion of both religious and secular works of art. The survivors of the Black Death were those of the repentant and those who felt life was short and must be enjoyed to the fullest. Suckale also explains the switching by artists from the pattern book to the sketch book, resulting in more originality by the artists.<br /> Manfred Wundram follows in the next article with a discussion of the early Renaissance period, which can be characterized he says by emphasis on portraiture and landscape painting. He claims that fine art is a means of expression of humankinds general cultural and intellectual history, and that religious and political conditions play a major role in shaping the art forms of a particular era. Art intepretation, he says, cannot happen without visual evidence. Any attempt to do so is mere speculation. These comments are to some extent convincing, but the interpretation of all art, regardless of the time period in which it was produced, should be left to the mind of the observer, in whatever framework such an observer chooses, be it a modern viewpoint or one that is actually attempting to relate the artwork to the time period in which it was produced. Pure speculation in the appreciation of art is thus permissible and is to be encouraged.<br /> Wundrum continues his analysis in the next article on the Renaissance and Mannerism, in which he argues, painting reached an absolute zenith. Readers preferences may prohibit an agreement with this characterization of the Renaissance however. In the artworks displayed in this article, a good example beingthe Virgin and Child with St Anne and St John the Baptist, one can see what Wundrum describes as color modulation, as the gradual dissolving of outlines. Wundrum also discusses in detail the origins of the term Mannerism and its problematic use in describing some of the art in this time period, and as being a transition between Renaissance and Baroque. And interestingly from a modern perspective is the exaggeration and deformation of the ideal human figure which took place under the category of Mannerism, supposedly according to the author to make more of an expressive impact.<br /> In the next article, Andreas Prater takes the reader through the Baroque period, the art in this period reflecting the ostentation and exuberance of the times. He argues that the art of this period is very difficult to define and characterize, and he summarizes the attempts to do so in detail. Illusionism and distortion of reality he says, are characteristics of the Baroque period. This is not readily apparent in the artworks displayed in this section however, unless one view angels, unicorns, etc as a distortion of reality, and not merely a flight of fancy on the part of the artist. In fact a certain degree of optimisim is present, a good example being \\"Seaport at Sunrise' by Claude Lorrain.<br /> Hermann Bauer continues with the Baroque period but from the standpoint of the Netherlands in the next article. The paintings seem more naturalistic in this case, the landscapes more serene, with an overabundance of earth tones. The \\"Honeysuckle Bower\\" of Peter Paul Rubens has to rank as one of the most impressive studies in detail ever put on canvas. Rembrandt's \\"Slaughtered Ox\\" is characteristically post-Modern.<br /> Eva-Gresine Baur ends the book with an article on Rococo and Neoclassicism. The use of pastels characterizes this period, argues Baur, and she describes these methods in detail. She characterizes the art of this period as a repression of fear, and without agreeing with this statement, the artworks listed do seem to exemplify a certain degree of escapism.eing the Virgin and Child with St Anne and St John the Baptist, one can see what Wundrum describes as color modulation, as the gradual dissolving of outlines. Wundrum also discusses in detail the origins of the term Mannerism and its problematic use in describing some of the art in this time period, and as being a transition between Renaissance and Baroque. And interestingly from a modern perspective is the exaggeration and deformation of the ideal human figure which took place under the category of Mannerism, supposedly according to the author to make more of an expressive impact. <br /> In the next article, Andreas Prater takes the reader through the Baroque period, the art in this period reflecting the ostentation and exuberance of the times. He argues that the art of this period is very difficult to define and characterize, and he summarizes the attempts to do so in detail. Illusionism and distortion of reality he says, are characteristics of the Baroque period. This is not readily apparent in the artworks displayed in this section however, unless one view angels, unicorns, etc as a distortion of reality, and not merely a flight of fancy on the part of the artist. In fact a certain degree of optimisim is present, a good example being \\"Seaport at Sunrise' by Claude Lorrain. <br /> Hermann Bauer continues with the Baroque period but from the standpoint of the Netherlands in the next article. The paintings seem more naturalistic in this case, the landscapes more serene, with an overabundance of earth tones. The \\"Honeysuckle Bower\\" of Peter Paul Rubens has to rank as one of the most impressive studies in detail ever put on canvas. Rembrandt's \\"Slaughtered Ox\\" is characteristically post-Modern. <br /> Eva-Gresine Baur ends the book with an article on Rococo and Neoclassicism. The use of pastels characterizes this period, argues Baur, and she describes these methods in detail. She characterizes the art of this period as a repression of fear, and without agreeing withthis statement, the artworks listed do seem to exemplify a certain degree of escapism.	2002-05-25
1538242:US	50702879	R1KPDS7S8YPLHI	0134578708	734555455	Inductive Logic Programming: Techniques and Applications (Ellis Horwood Series in Artificial Intelligence)	Books	4	1	1	N	N	Out of date, but still can be useful	Interest in inductive logic programming has waxed and waned over the last decade, but never fallen to zero. This book is a summary of what was known in the field in 1994, and much has changed since then. It can however still serve as an introduction to the field of inductive logic programming, in spite of its publication date. Most of the current research and applications of inductive logic programming has concentrated on introducing stochasticity into logic programming and on how to incorporate reasoning with numerics into the framework.<br /> The authors emphasize the empirical aspects of inductive logic programming and its applications, but do spend the first few chapters detailing the theoretical foundations of the subject. The characterize machine learning paradigms as inductive, deductive, learning with genetic algorithms, and learning with neural nets. They rule out neural net learning as being a true learning system since it does not pass the \\"Michie strong criterion\\", i.e. learning must acquire new knowledge which must be understandable by humans. They do not elaborate on why neural nets fail to meet this criterion. Inductive learning of course is what they consider exclusively in the book, with inductive concept learning essentially consisting of the learning of how to recognize objects in the concept, the concept being a subset of objects in universal set of objects or observations. To define inductive concept learning more rigorously the authors employ the concept of a covering of an object, which means essentially that the description of the object satisfies the description of the concept. The object description is thus \\"covered\\" by the concept description. Notions of completeness and consistency of hypotheses are then introduced, with completeness being the requirement that the hypothesis cover all positive examples and no negative ones, while consistency meaning that it does not cover any of the negative examples. These ideas are then generalized to the case where background knowledge is present. Inductive logic programming systems are then defined as those that induce hypotheses in the form of logic programs. These systems are partitioned into those that learn predicates from scratch, called empirical ILP systems, and those that learn multiple predicates, called interactive ILP systems. The authors then discuss briefly the systems that were available at the time of writing. Only empirical ILP systems are considered by the authors in the book, with emphasis on the systems LINUS and FOIL, which were the dominant ones at the time of writing.<br /> Because of its popularity and effectiveness in logic programming, the authors employ Prolog to introduce the basic theory of logic programming. Other languages have been developed since then with ILP applications in mind, one of these being Progol. Symbolic programming languages, such as Mathematica and Maple, can also be used, and very effectively.  The essentials of logic programming discussed in the book have no doubt been seen by the reader, and some familiar concepts such as Horn clauses and resolution are discussed by the authors. The goal of empirical ILP then is to find a complete and consistent definition for an unknown predicate given a set of examples and background knowledge. Concept learning is viewed as a search problem, with states in the search space being concept descriptions. The goal is to find states that satisfy a quality criterion, and a learning algorithm is characterized in terms of the structure of its search space, its search strategy, and the search heuristics. The structure of the search space is characterized by a \\"theta-subsumption lattice\\", which gives the structure of the search space of program clauses, and which can be searched blindly or heuristically. Theta-subsumption provides the basis for a \\"bottom-up\\" ILP technique, namely that of the building of least general generalizations from training examples relative to background knowledge,and a \\"top-down\\" technique of the searching of refinement graphs. These techniques and the technique of inverse resolution are discussed in detail by the authors. The idea of inverse resolution will seem natural to the reader familiar with the related (but inverted) procedure in deductive (propositional) logic. Inverse resolution inverts the SLD-resolution proof procedure for definite programs.<br /> Most of the book is devoted to an overview of the FOIL system and how it can be implemented to do practical inductive logic programming. The search routines used by FOIL are hill-climbing strategies, and the authors discuss ways that have been used to improve on these. Since this book was written, an ILP system called SFOIL has appeared that takes advantage of the view of induction of hypotheses as an optimization problem. Interestingly, SFOIL uses a generalization of simulated annealing to do this, based on Markovian neural networks. The authors also review the GOLEM ILP programming language, which is based on the notion of relative least general generalization, again a bottom-up search of the theta-subsumption lattice. Other ILP languages, such as MOBAL and MPL are also reviewed. In addition, the LINUS IPL system is reviewed, which exploits background knowledge in learning both propositional and relational descriptions. Deduction plays a major role in the LINUS system, as well as the transformation of relational descriptions to a propositional learning task. Both the FOIL and the LINUS systems are characterized with respect to refinement operators and refinement graphs, which allows a comparison of the expressiveness of their hypothesis languages and the search costs associated with these systems.<br /> The authors also discuss how to handle imperfect data in ILP, and show the role of heuristics in doing this. Random errors in training examples and background knowledge, sparse training examples, inexact description of target concepts, and missing values in training examples all need to be dealt with when using ILP, and various techniques are oultined by the authors to do this. Several interesting applications of ILP are given in the book, including medical diagnostics, finite element methods, qualitative modeling of dynamical systems, and predicting protein secondary structure. The role of ILP in bioinformatics has taken on more importance in recent years, and this trend will no doubt continue.e, and a \\"top-down\\" technique of the searching of refinement graphs. These techniques and the technique of inverse resolution are discussed in detail by the authors. The idea of inverse resolution will seem natural to the reader familiar with the related (but inverted) procedure in deductive (propositional) logic. Inverse resolution inverts the SLD-resolution proof procedure for definite programs. <br /> Most of the book is devoted to an overview of the FOIL system and how it can be implemented to do practical inductive logic programming. The search routines used by FOIL are hill-climbing strategies, and the authors discuss ways that have been used to improve on these. Since this book was written, an ILP system called SFOIL has appeared that takes advantage of the view of induction of hypotheses as an optimization problem. Interestingly, SFOIL uses a generalization of simulated annealing to do this, based on Markovian neural networks. The authors also review the GOLEM ILP programming language, which is based on the notion of relative least general generalization, again a bottom-up search of the theta-subsumption lattice. Other ILP languages, such as MOBAL and MPL are also reviewed. In addition, the LINUS IPL system is reviewed, which exploits background knowledge in learning both propositional and relational descriptions. Deduction plays a major role in the LINUS system, as well as the transformation of relational descriptions to a propositional learning task. Both the FOIL and the LINUS systems are characterized with respect to refinement operators and refinement graphs, which allows a comparison of the expressiveness of their hypothesis languages and the search costs associated with these systems. <br /> The authors also discuss how to handle imperfect data in ILP, and show the role of heuristics in doing this. Random errors in training examples and background knowledge, sparse training examples, inexact description of target concepts, and missing values in training examples all need to be dealt with when using ILP, and various techniques are oultined by the authors to do this. Several interesting applications of ILP are given in the book, including medical diagnostics, finite element methods, qualitative modeling of dynamical systems, and predicting protein secondary structure. The role of ILP in bioinformatics has taken on more importance in recent years, and this trend will no doubt continue.	2002-05-20
1538462:US	50702879	RUVZ0UA7U4AHZ	0134578708	734555455	Inductive Logic Programming: Techniques and Applications (Ellis Horwood Series in Artificial Intelligence)	Books	4	0	0	N	N	Out of date, but still can be useful	Interest in inductive logic programming has waxed and waned over the last decade, but never fallen to zero. This book is a summary of what was known in the field in 1994, and much has changed since then. It can however still serve as an introduction to the field of inductive logic programming, in spite of its publication date. Most of the current research and applications of inductive logic programming has concentrated on introducing stochasticity into logic programming and on how to incorporate reasoning with numerics into the framework. <br /> The authors emphasize the empirical aspects of inductive logic programming and its applications, but do spend the first few chapters detailing the theoretical foundations of the subject. The characterize machine learning paradigms as inductive, deductive, learning with genetic algorithms, and learning with neural nets. They rule out neural net learning as being a true learning system since it does not pass the \\"Michie strong criterion\\", i.e. learning must acquire new knowledge which must be understandable by humans. They do not elaborate on why neural nets fail to meet this criterion. Inductive learning of course is what they consider exclusively in the book, with inductive concept learning essentially consisting of the learning of how to recognize objects in the concept, the concept being a subset of objects in universal set of objects or observations. To define inductive concept learning more rigorously the authors employ the concept of a covering of an object, which means essentially that the description of the object satisfies the description of the concept. The object description is thus \\"covered\\" by the concept description. Notions of completeness and consistency of hypotheses are then introduced, with completeness being the requirement that the hypothesis cover all positive examples and no negative ones, while consistency meaning that it does not cover any of the negative examples. These ideas are then generalized tothe case where background knowledge is present. Inductive logic programming systems are then defined as those that induce hypotheses in the form of logic programs. These systems are partitioned into those that learn predicates from scratch, called empirical ILP systems, and those that learn multiple predicates, called interactive ILP systems. The authors then discuss briefly the systems that were available at the time of writing. Only empirical ILP systems are considered by the authors in the book, with emphasis on the systems LINUS and FOIL, which were the dominant ones at the time of writing. <br /> Because of its popularity and effectiveness in logic programming, the authors employ Prolog to introduce the basic theory of logic programming. Other languages have been developed since then with ILP applications in mind, one of these being Progol. Symbolic programming languages, such as Mathematica and Maple, can also be used, and very effectively.  The essentials of logic programming discussed in the book have no doubt been seen by the reader, and some familiar concepts such as Horn clauses and resolution are discussed by the authors. The goal of empirical ILP then is to find a complete and consistent definition for an unknown predicate given a set of examples and background knowledge. Concept learning is viewed as a search problem, with states in the search space being concept descriptions. The goal is to find states that satisfy a quality criterion, and a learning algorithm is characterized in terms of the structure of its search space, its search strategy, and the search heuristics. The structure of the search space is characterized by a \\"theta-subsumption lattice\\", which gives the structure of the search space of program clauses, and which can be searched blindly or heuristically. Theta-subsumption provides the basis for a \\"bottom-up\\" ILP technique, namely that of the building of least general generalizations from training examples relative to background knowledge, and a \\"top-down\\" technique of the searching of refinement graphs. These techniques and the technique of inverse resolution are discussed in detail by the authors. The idea of inverse resolution will seem natural to the reader familiar with the related (but inverted) procedure in deductive (propositional) logic. Inverse resolution inverts the SLD-resolution proof procedure for definite programs. <br /> Most of the book is devoted to an overview of the FOIL system and how it can be implemented to do practical inductive logic programming. The search routines used by FOIL are hill-climbing strategies, and the authors discuss ways that have been used to improve on these. Since this book was written, an ILP system called SFOIL has appeared that takes advantage of the view of induction of hypotheses as an optimization problem. Interestingly, SFOIL uses a generalization of simulated annealing to do this, based on Markovian neural networks. The authors also review the GOLEM ILP programming language, which is based on the notion of relative least general generalization, again a bottom-up search of the theta-subsumption lattice. Other ILP languages, such as MOBAL and MPL are also reviewed. In addition, the LINUS IPL system is reviewed, which exploits background knowledge in learning both propositional and relational descriptions. Deduction plays a major role in the LINUS system, as well as the transformation of relational descriptions to a propositional learning task. Both the FOIL and the LINUS systems are characterized with respect to refinement operators and refinement graphs, which allows a comparison of the expressiveness of their hypothesis languages and the search costs associated with these systems. <br /> The authors also discuss how to handle imperfect data in ILP, and show the role of heuristics in doing this. Random errors in training examples and background knowledge, sparse training examples, inexact description of target concepts, and missing values in training examples all need to be dealt with when using ILP, and various techniques are oultined by the authors to do this. Several interesting applications of ILP are given in the book, including medical diagnostics, finite element methods, qualitative modeling of dynamical systems, and predicting protein secondary structure. The role of ILP in bioinformatics has taken on more importance in recent years, and this trend will no doubt continue.	2002-05-20
1539572:US	50702879	R2WMP3RPED0H5F	0811201880	942112163	Nausea (New Directions Paperbook)	Books	5	15	20	N	N	Post-war malaise or our ontological status?	The author of this book has now been gone from us for twenty years, existence now longer penetrates him anywhere, but his essence is preserved eloquently in this short novel via the character of Roquentien. Sartre believed that we define ourselves by the instant; we choose who we are to be continuously in time. Thus it is for our interpretation of this novel. Without taking a position on the validity of Sartre's grand system of Existentialism, one can still interpret the novel as we choose. Roquentien can be a character engaging in excessive introspection, embedded in a European post-war  malaise, or a philosophical anti-hero struggling for the raw, naked truth as to our ontological status.<br /><br />His inquisitiveness entails that he notices everything; the roots and bark of the chestnet tree, the dry mud, the laurel, and also, and most importantly, he notices the absence of things; he experiences their negation. For Roquentien, a caricature of early 20th century phenomonalist philosophy, experiencing the negation is a central element of Sartre's philosophy. But Roquentien, terrified of his existence, should really not have been too surprised at his experience in the park, his confrontation with existence \\"with the veil torn away\\". The human mind, especially a mind like Roquentien's, who is very involved in life and his surroundings, will grant access to phenomena that one chooses. Roquentian wanted to experience the bare nakedness of existence; to see things stripped of labels.<br /><br />Goal-directed consciousness will allow such access, with an intensity that is equal to that of any other problem-solving activity. Mental focus grants an awareness of the Roquentien kind, but it is spontaneous, and sometimes delayed in its action. The time scales involved do not always meet the expectations of the person involved. The veil was lifted for Roquentien without his volition at that instant, but it was a consequence of his earlier musings and longings. Interestingly, Roquentien feels adventerous after this experience, and makes the decision to leave for Paris. His goal was satisfied with the experiencing-of-the-park...time to move on to others.els adventerous after this experience, and makes the decision to leave for Paris. His goal was satisfied with the experiencing-of-the-park...time to move on to others.	2002-05-18
1539871:US	50702879	R3TLMTTU61EAYS	0632059540	589843399	Principles of Gene Manipulation	Books	5	7	7	N	Y	Excellent overview of a very exciting field	Certainly one of the most exciting developments in the last quarter century, genetic engineering is also one of the most controversial, and discussions of it are typically accompanied by vehemence and exaggerations. An objective study of genetic engineering is thus mandatory for everyone in the 21st century. This book is one of the best treatments of genetic engineering that I have read, and I am speaking not as a biologist but as someone actively involved in bioinformatics and computational biology. The explanations of the techniques of genetic engineering are excellent and the reader with a fairly good background in biochemistry should have no problem following the presentation. Readers without such a background will find the reading a little more demanding. One can only admire the ingenuity of the many researchers and technicians who have developed these techniques. The only thing missing in the book are exercises at the end of each chapter to test the readers understanding of the relevant concepts.<br /> The last five chapters of the book are the most interesting ,for it is in these chapters that the authors discuss the genetic manipulation of animals, transgenic strategies, and biotechnology. We are all priveleged to be witnessing the development of new breeds of plants and animals, and hopefully this trend will continue in the 21st century. The impact of genetic engineering for medicine and agriculture will be immense, but even more mundance activities such as gardening and horticulture will be even more interesting with the development of new kinds of plants via transgenic strategies. In addition, genetic engineering is finding applications to areas outside of biology. It was recently reported that genetically engineered viruses are being used to assist in the development of quantum dots in microelectronics.<br /> Some of the features of the book I found particularly helpful or interesting were: 1. The numerous diagrams employed in the book that tie concepts together or give flow charts for laboratory procedures. 2. The discussion on the physics of gel electrophoresis. Apparently the dynamics of stained molecules undergoing electrophoresis is poorly understood. 3. The historical and anecdotal information that the authors include at various places in the book. 4. The discussion on optimizing translation. The degeneracy of the genetic code might lead one to believe that the choice of codons by genes is essentially a random process. The authors argue this is not the case and give excellent references for further reading on this. Apparently protein translation is a tight scheme, and again, this is surprising given the degeneracy of the genetic code. 5. The box on express sequence tags. The most interesting part of this discussion was on the legal issues involving the patenting of ESTs. The patent applications were rejected because ESTs were viewed as incomplete sequences. This rejection might serve as a precedent to future attempts to patent genes or complete genomes. Will some of these patents be rejected on the grounds that genes do not completely determine the protein(s) or phenotype(s)? Whatever the outcome, the legal profession in the 21st century will have to deal with information-theoretic criteria when addressing patent issues in genetic engineering. 6. The listing of the Internet tools available for gene sequencing and protein structure. 7. The discussion on the quantitative effect of sequence accuracy on gene accuracy, assuming the random occurence of sequencing errors. The diagram shown of average sequence-error rate versus the fraction of error-free genes shows clearly the importance of robust and precise sequence-similarity search algorithms. Interestingly, the authors argue that, in spite of the success of statistical methods in these algorithms, the use of these methods will decrease as new sequences are accumulated and sequence conservation is used as the criterion for gene identification. They do however state that these methods will still remain useful for localizing frame shifts and for the choice of the initiation codon. 8. The box on the modes of replication of circular DNA molecules. The biophysicist reader will appreciate the discussion on the two types of replication: by theta-like structures or the rolling-circle type of mechanism. 9. The discussion on applications of transgenic mice, position effects, and transgene silencing. The authors discussion of the efficacy of transgenic strategies in mice progeny is fascinating in that some mice progeny has expression that was very different from that of the parents, or even absent. The authors give a brief discussion of boundary elements and matrix attachment regions with references for further reading. 10. The short discussion on transgenic fish. 11. The box on control of transgene expression in plants. 12. The discussion on the use of immunosuppressant drugs as chemical inducers of dimerization. The side effects of these drugs has prompted research into finding transgene induction strategies that do not have these side-effects. 13. The discussion on post-translational inducible protein activity. 13. The discussion on visible marker genes, especially the discussion on green flourescent protein. 15. The discussion on the use of antisense RNA to regulate gene expression in prokaryotes. 16. The discussion on the use of cosuppression in increasing the amount of pigment synthesized by petunia flowers. The application of transgenic strategies to horticulture is indeed exciting and one that will hopefully result in new varieties of houseplants and garden fruits and vegetables. 17. The discussion on the role of functional genomics. 18. Transgenic animals and plants as bioreactors: Tracy and her progeny in producing AAT. 19. Xenotransplantation. This is no doubt one of the most controversial techniques used in genetic engineering today.state that these methods will still remain useful for localizing frame shifts and for the choice of the initiation codon. 8. The box on the modes of replication of circular DNA molecules. The biophysicist reader will appreciate the discussion on the two types of replication: by theta-like structures or the rolling-circle type of mechanism. 9. The discussion on applications of transgenic mice, position effects, and transgene silencing. The authors discussion of the efficacy of transgenic strategies in mice progeny is fascinating in that some mice progeny has expression that was very different from that of the parents, or even absent. The authors give a brief discussion of boundary elements and matrix attachment regions with references for further reading. 10. The short discussion on transgenic fish. 11. The box on control of transgene expression in plants. 12. The discussion on the use of immunosuppressant drugs as chemical inducers of dimerization. The side effects of these drugs has prompted research into finding transgene induction strategies that do not have these side-effects. 13. The discussion on post-translational inducible protein activity. 13. The discussion on visible marker genes, especially the discussion on green flourescent protein. 15. The discussion on the use of antisense RNA to regulate gene expression in prokaryotes. 16. The discussion on the use of cosuppression in increasing the amount of pigment synthesized by petunia flowers. The application of transgenic strategies to horticulture is indeed exciting and one that will hopefully result in new varieties of houseplants and garden fruits and vegetables. 17. The discussion on the role of functional genomics. 18. Transgenic animals and plants as bioreactors: Tracy and her progeny in producing AAT. 19. Xenotransplantation. This is no doubt one of the most controversial techniques used in genetic engineering today.	2002-05-18
1550652:US	50702879	R12RRNZU11COV0	0521649765	872804272	Computational Geometry in C (Cambridge Tracts in Theoretical Computer Science (Paperback))	Books	4	15	15	N	N	Very hepful	Anyone who is involved in areas such as computer graphics, computational radiology, robot vision, or visualization software should have a copy of this book. The author has done a fine job of introducing the most important algorithms in computational geometry, choosing the C language for their implementation. The choice of C might be somewhat dated now, since C++ is now beginning to dominate computational geometry, but readers who are actually programming these algorithms using C++ can easily extend the ones in the book to C++. Not all of the algorithms in the book are implemented into C, unfortunately, but the clarity of presentation is done well enough to make this implementation a fairly straightforward task. My interest in the book came from a need to design and implement algorithms for polyhedra in VRML and toric varieties in algebraic geometry. This book, along with others, was a great help in that regard. The running time of these algorithms was not really an issue with me, so the detail the author spends on discussing the complexity of the algorithms was not a concern. Readers who need to pay attention to running-time issues will appreciate his discussion of them for the algorithms that are presented.<br /> The ability to visualize objects in an abstract subject like algebraic geometry boils down to, in the case of toric varieties, to a consideration of how to manipulate polytopes geometrically. A major portion of the book, if not all of it, is devoted to the computational geometry of polyhedra. Because it is an introductory book, some more advanced topics, such as Bayesian methods to find similarities between polyhedra, and neural network approaches to classifying polyhedral objects are not treated. Readers who need to do such things will be well-prepared for them after a study of this book. In addition, there are good exercises assigned at the end of each chapter, so the book could be used in the classroom. Some readers will however choose to use it as a reference source, and it would be a good one, for the author gives references to topics that he only touched upon in the book.<br /> Some particular areas that were treated especially well were: 1. The discussion on data structures for surfaces of polyhedra. Although not very general, since he choose to deal with only triangulated polytopes, readers who need to be more general will have a good start in this discussion. 2. The discussion on volume overflow and how to deal with it using robust computation. 3. The discussion, albeit short, of the randomized incremental algorithm. 4. The treatment on the minimum spanning tree and Kruskal's algorithm. Communication network performance optimization is now a major application of this algorithm and others in graph theory, including the author's later discussion of Dijkstra's algorithm.eference source, and it would be a good one, for the author gives references to topics that he only touched upon in the book. <br /> Some particular areas that were treated especially well were: 1. The discussion on data structures for surfaces of polyhedra. Although not very general, since he choose to deal with only triangulated polytopes, readers who need to be more general will have a good start in this discussion. 2. The discussion on volume overflow and how to deal with it using robust computation. 3. The discussion, albeit short, of the randomized incremental algorithm. 4. The treatment on the minimum spanning tree and Kruskal's algorithm. Communication network performance optimization is now a major application of this algorithm and others in graph theory, including the author's later discussion of Dijkstra's algorithm.	2002-05-09
1550812:US	50702879	R1P8CT1B28O3RS	086622601X	242583655	The Mini-Atlas of Snakes of the World	Books	4	1	1	N	N	Beautiful photos	Some of the most beautiful lifeforms on this planet are illustrated in this book, and when reading it, one can only feel more amazement and respect for this order of reptiles. The colors, patterns, and life styles of snakes are varied enough to keep a serious student of herpetology busy for a long time. One can only envy the photographer who took the pictures in this book.<br />  The book is not just a photo collection however, for the author also includes a discussion of their taxonomy, natural history, biology, eating habits, diseases, reproduction, and how to care for them in captivity. The most interesting discussion in the book was on taxonomy, for it is very controversial. The binomial system is employed in the book, but the author explains that a trinomial classificiation becomes appropriate when certain characteristics are unable to justify a separate classification as a species. The North American Common Kingsnake is offered as an example of this, having at it were seven subspecies.<br />  The top 10 most beautiful snakes in the book:<br />1. Trimeresurus wagleri p. 569<br />2. Chondropython viridis p.41<br />3. Diadophis punctatus punctatus p. 257<br />4. Oxybelis fulgidus p. 356<br />5. Ahaetulla prasina p. 312<br />6. Dendraapsis augusticeps p. 412<br />7. Bitis nasicornis p. 476<br />8. Naja nigricollis p. 429<br />9. Drymarchon corais couperi p. 111<br />10. Lampropeltis zonata p. 164	2002-05-08
1551821:US	50702879	RX46894DB5VKU	156731015X	303922714	The Age of Faith: A History of Medieval Civilization-Christian, Islamic, and Judaic-From Constantine to Dante : A.D. 325-1300 (The Story of Civilization, 4) (Vol 4)	Books	5	29	32	N	N	Was it solely the age of faith?	History and its study has always been a daunting task, both in terms of the length of time it takes a reader to assimilate the knowledge of a particular period of history, and also the painstaking attention to detail that the historian must engage in. The gravitational pull on this book is appreciable, as is the case for most books on history, but for the person curious about the events of 300-1300, events that still have a major influence on the present, it is well worth the time needed for its perusual. The authors are sometimes cynical in their appraisal of these times, and one can detect a measure of hostility towards religion in their writing, but their style of writing is both interesting and at times very entertaining, and it certainly keeps the readers attention.<br /><br /> One can disagree of course in labeling a particular period in history as \\"The Dark Ages\\" solely on the basis of a personal belief that the ideas of that time do not meet certain criteria of \\"enlightenment\\". The authors do label the period AD 566 - 1095 as the Dark Ages, but they do so not only from the standpoint of the intellectual climate of the time, but also from an economic one. That progress was not occurring during that time at a rate that it was capable of, is the message implicitly given by the authors.<br /><br /> The book takes on through a time period that saw the rise of figures whose ideas are held by most of today's populations. The rapid rise of Islam via the personage of Mohammed, the struggles of the Jewish people, and the rise of the Holy Roman Empire are brilliantly detailed by the authors. The Koran, the Talmud, and the Bible all coexisted, the beliefs expressed in these books had considerable overlap, and the tension between them has endured till now. One should not however conclude that this tension has always been a detriment to humankind. Most of the readers of these books, a considerable majority in fact, have never engaged in violence or deliberate conflict. The wars brought about by a small minority, who claim special status in their interpretation of the contents of these books, should not lead to a hasty conclusion that the rare perturbations that wars make to history are in fact all of history itself.<br /><br /> All peoples in the present time owe much to the efforts of those in the period discussed in the book. Modern science has its roots of course in ancient Greece, but it took Islamic scholars, with their efforts to translate the works of the Greeks, particularly Aristotle, to set the stage for science. The authors introduce us to Averroes, the 12 century \\"Stagrite\\" and scholar; to Muhammed ibn Musa of the 8th century, one of the great mathematicians of his time , giving us algebra, the latter term coined by the Arabs; to Abu Hanifa, a 9th century botanist/pharmacologist, and to many other Arabic/Islamic seekers and purveyors of wisdom. An entire chapter is devoted to the brilliant Christian scholar/philosopher/rationalist Abelard, who set the stage for the Scholastic philosophy of Lombard and Thomas Aquinas. The reader also is introduced to the Jewish scholar Maimonides, his philosophy and his \\"Glossary on Drugs\\". Clearly, the age of faith had its share of brilliance.<br /><br /> The age of faith should thus be seen as an age of discovery as well as prayer. Jewish, Christian, and Islamic scholars were laying the foundations of knowledge as well as propagating their faith. This superposition of faith and reason continues in our day, and shows no sign of being abated. In this regard, this book is almost like a chronicle of our own time. We now have computers, genetic engineering, robotics, and space travel; but we also have churches, synagogues, tabernacles, temples, and mosques. The history of our own time, and that described in this book, could thus be viewed as a mere change of names and dates. The goals in both time periods are the same: the unrelenting quest for new knowledge and the reaching out for something intangible and beyond ourselves.g intangible and beyond ourselves.	2002-05-08
1551860:US	50702879	R2E5QTKPW56R6P	0849371643	291578212	Modern Differential Geometry of Curves and Surfaces with Mathematica, Second Edition	Books	4	18	18	N	N	Good introduction to differential geometry	The visualization of complicated geometrical objects<br />is now routine thanks to the excellent software that<br />has been developed over the past two decades. Now<br />students and professionals can have a better<br />appreciation of the geometrical properties of these<br />objects thanks to these software packages. In this<br />book the author has done a great job of doing this,<br />having chosen one of the best tools for this purpose:<br />Mathematica. The book is a hefty one, totaling almost<br />1100 pages, but its perusal is worth the effort for<br />those who want a more intuitive appreciation behind<br />the concepts of differential geometry. Physicists in<br />particular, who usually need a pictorial approach to<br />complement the learning of a subject, should really<br />enjoy this book. It could definitely be used as a<br />textbook in a beginning course in differential<br />geometry since there are problems at the end of each<br />chapter and most of the results in the book are proven<br />with the required mathematical rigor, I.e. this book<br />is not just code and pictures, and a substantial<br />portion of it is devoted to definitions and rigorous<br />proofs. This is especially true for the discussion on<br />differentiable manifolds and Riemannian geometry. The<br />author also includes a brief biography of the<br />mathematicians who have been involved in differential<br />geometry at various places in the book. The<br />Mathematica code in the book though can be revised to<br />make it look more like standard mathematical notation,<br />thanks to the new features of Mathematica that have<br />appeared since this book was published (1997). The use<br />of color shading is not done in the book, except for a<br />short insert with pictures of several surfaces, but<br />the reader can easily experiment with the color<br />functions available in Mathematica if needed. A very<br />lengthy appendix that lists the functions and code<br />used in the book is included.<br />Some of the concepts that are usually<br />difficult to grasp intuitively for those approaching<br />differential geometry for the first time but are here<br />illustrated nicely include: 1. The computation of the<br />curvature of plane curves and the plotting of this<br />curvature. The curvature of the famous Lissajous<br />curves, very familiar from oscilloscope traces, is<br />computed. The author might have spent a little more<br />time explaining why the curvature plots have the shape<br />they do however. 2. The treatment of osculating curves<br />to plane curves. 3. The finding of curves whose<br />curvature is equal to the arc length times a Bessel<br />function. The resulting plots are very entertaining.<br />4. The computation of the torsion of a curve in space.<br />The discussion on torus knots is particularly well-<br />done. 5. The author's discussion on surfaces in<br />Euclidean space motivates well the concept of a<br />differentiable manifold. He plots a few surfaces with<br />coordinate patches that have a singularity, and shows<br />how to plot surfaces that defined nonparametrically.<br />Kummer's surface, of particular importance in<br />algebraic geometry, is plotted here. Even more useful<br />is the author's treatment of nonorientable surfaces,<br />wherein he shows the reader how to plot the Moebius<br />strip, the Klein bottle, and two realizations of the<br />projective plane using Mathematica. Several examples<br />of the Gaussian curvature of surfaces are plotted. The<br />Gauss map, one of the most important tools for the<br />physicist, is given detailed treatment. 6. Rare in<br />textbooks at this level of differential geometry is a<br />discussion of minimal surfaces, but the author gives a<br />very nice treatment in this book. The Enneper's,<br />Scherk's Henneberg's and Catalan's minimal surfaces<br />are plotted along with the Gauss map of Enneper's<br />surface. Minimal surfaces are extremely importantin<br />theoretical physics, such as superstring and membrane<br />theories, and are also very important in optimization<br />theory, so it was nice to see a discussion of them<br />included in the book. In recent years galleries of<br />minimal surfaces have appeared on the Web, and this<br />book allows one to plot these without too much effort.<br />The author even introduces the use of complex analysis<br />in the study of minimal surfaces. Readers interested<br />in understanding the mathematics of string theory will<br />appreciate this discussion. In addition, the<br />Weierstrass representation, which allows generation of<br />new minimal surfaces, is introduced. Readers familiar<br />with the Weierstrass function for elliptic curves will<br />see it used here for this generation.ries, and are also very important in optimization <BR>theory, so it was nice to see a discussion of them <BR>included in the book. In recent years galleries of <BR>minimal surfaces have appeared on the Web, and this <BR>book allows one to plot these without too much effort. <BR>The author even introduces the use of complex analysis <BR>in the study of minimal surfaces. Readers interested <BR>in understanding the mathematics of string theory will <BR>appreciate this discussion. In addition, the <BR>Weierstrass representation, which allows generation of <BR>new minimal surfaces, is introduced. Readers familiar <BR>with the Weierstrass function for elliptic curves will <BR>see it used here for this generation.	2002-05-08
1553124:US	50702879	RQ2QQ5RQ7D8AQ	0521645980	62074098	MathLink &#174; Paperback with CD-ROM: Network Programming with MATHEMATICA &#174;	Books	4	15	15	N	N	Good introduction	For those who know Mathematica well, and who also want<br />to call Mathematica programs either remotely or from<br />programs not written in Mathematica, this book is the<br />canonical reference; in fact the only one that I am<br />aware of other than the documentation that comes with<br />Mathematica. The material in tbe book goes far beyond<br />what can be found in the documentation however. As the<br />authors observe, writing programs from scratch using<br />the TCP/IP protocol can be formidable, and so MathLink<br />was invented to ease the process for those who do not<br />want to become expert in TCP/IP. Readers will also<br />have to have a working knowledge of the C programming<br />language.<br />The book covers the Windows. Macintosh, and<br />Unix platforms, with LINUX emphasized for the latter.<br />Since all three of these operating systems are covered<br />in the book, this makes navigation in it a little<br />annoying at times. It does expand on the actual<br />evaluation process when executing a Mathlink program,<br />and how Mathlink does type conversion. Latency issues<br />in the network will of course have to be dealt with in<br />using Mathlink. The authors devote a chapter of the<br />book in dealing with data transfer times across a<br />network. They are also wise enough to know that the<br />data transfer is best done with functions written in C<br />for situations that are time-intensive. Readers just<br />need to remember to call the Install function after<br />each change they make to the .c and .tm files, as this<br />fact is not emphasized by the authors.<br />A chapter is devoted to the debugging of<br />programs written in MathLink. The ability to debug<br />these programs is really because of the underlying C<br />code rather than Mathematica, for the latter does not<br />of course have a debugger. The authors also illustrate<br />real-time graphics with TurtleGraphics, which is based<br />on the graphics primitives of Logo. Although somewhat<br />antiquated, it was put in to allow simulations of<br />cellular automata that are done in the next chapter.<br />Transfer times in the performing of real-time graphics<br />are reduced by employing color tables. For those<br />working on MAC OS or Windows machines, a discussion of<br />the digitizing of movies is given using the QuickTime<br />movie player. These discussions of real-time graphics<br />are generalized to interactive graphics in the next<br />chapter. This discussion is particularly enlightening,<br />since it deals with how to implement object-oriented<br />programming in Mathematica. Interestingly, objects are<br />thought of as function names when sending messages to<br />them. This is an illustration of the classic \\"message-<br />passing\\" paradigm in object-oriented programming, with<br />the messages being send to objects as their function<br />arguments. The authors discuss the class method and<br />instance method; the latter being the collection of<br />definitions that make up the class. Single and<br />multiple inheritance, a very important feature of<br />object-oriented programming, are discussed, and the<br />authors show how to create an event-driven mechanism<br />using Mathlink. Most interestingly, they show how to<br />create a window object, and this leads to a detailed<br />discussion on how to write a real-time interactive<br />graphics system. The latter is not supported by the<br />Mathematica front-end, and so for readers interested<br />in creating these for purposes such as curve-fitting<br />to data, their discussion is very helpful.<br />In addition, for those involved in large-scale<br />team efforts in writing Mathematica applications, or<br />programs calling Mathematica, the authors show how to<br />use Mathlink to communicate between different<br />Mathematica sessions. They discuss briefly the use of<br />J/Link to enable users to write Java programs to call<br />Mathematica programs, thus exploitingJava's<br />portability capabilities.	2002-05-07
1555576:US	50702879	R7760A05WR2QZ	0871271540	210667715	Dance Technique of Doris Humphrey and Its Creative Potential	Books	5	6	6	N	N	Exquisite	It is unfortunate that this book is out of print, for it is one of the few written that gives insight into the dance technique of one of the pioneers of modern dance in the 20the century. Known to many students of modern dance as Humphrey-Weidman technique, with reference to Humphrey's collaborator Charles Weidman, it is a dance form that has taken root not only in the dance classroom, but in rythymic studies and dance notation.<br /> The author had known Doris Humphrey personally, taken her classes, and has given dance enthusiasts a fine book here, comprehensive in content, and one that also gives insight into Humphrey's influence of the philosopher Frederich Neitzsche. The book offers a study of Humphrey's dance technique that is based on Neitzsche's philosophy of aesthetics, namely his thinking on the dual nature of humankind: the Dionysion and the Appollonian.<br /> When reading the book, one is led to the conclusion that Humphrey was one of the more analytical of the 20th century choreographers. Following Nietzsche, her technique emphasized the individual need for adventure, to \\"get out of equilibrium\\". But a sustained attempt to remain like this, for the dancer to be always off-balance, implies for Humphrey a \\"dynamic death\\"; but the opposite, a sustained attempt at symmetry and order, implies a \\"static death\\". A dancer must oscillate between these two extremes, explains the author in dicussing the Humphrey philosophy of dance. This is the origin of Humphrey's famous principle of falling and recovering, and the author outlines in detail the exercises and movements that reflect this principle.<br /> Not only is this work a book on dance theory, but it also can be used in the classroom. The author uses stick figures in the book, but they are clear enough for an instructor to interpret and implement. The exercises are discussed in detail along with the counts and phrasing for each. Some of the more interesting ones that illustrate nicely the Humphrey-Weidman technique are: 1. Change of weight with falling motion. The dancer \\"rebounds\\" after succoumbing momentarily to gravity. 2. Full body swings. These are an example of the famous \\"fall and recovery\\" principles of the Humphrey-Weidman technique. 3. The floor exercises. In modern dance, and especially Humphrey-Weidman technique, the floor is equal partners with the other levels. The famous \\"Weidman pushup\\" is described here in detail by the author. The \\"thigh stretch\\" exercises is one of the best floor exercises for developing control in the sitting position and requires tremendous strength in the quadriceps. 4. The falls and their consequent recovery. The author is very detailed here and thus the discussion is very useful for those teaching these. The circular fall is certainly the most exquisite to watch in this technique.echnique are: 1. Change of weight with falling motion. The dancer \\"rebounds\\" after succoumbing momentarily to gravity. 2. Full body swings. These are an example of the famous \\"fall and recovery\\" principles of the Humphrey-Weidman technique. 3. The floor exercises. In modern dance, and especially Humphrey-Weidman technique, the floor is equal partners with the other levels. The famous \\"Weidman pushup\\" is described here in detail by the author. The \\"thigh stretch\\" exercises is one of the best floor exercises for developing control in the sitting position and requires tremendous strength in the quadriceps. 4. The falls and their consequent recovery. The author is very detailed here and thus the discussion is very useful for those teaching these. The circular fall is certainly the most exquisite to watch in this technique.	2002-05-04
1560070:US	50702879	R13HUKPP3VBWFE	1558603298	924235055	Computer Architecture: A Quantitative Approach, Second Edition	Books	4	7	10	N	N	A little outdated...but still a great book	Anyone who is interested in computer architecture or computer performance benchmarking should have a copy of this book. It is well organized, packed full of information, and has many challenging exercises at the end of each chapter that reinforce and extend the concepts outlined. Also, the inside jacket gives a list of useful formula for quick reference. For those interested in vector processors, the authors have included an overview of these in the appendix. Do to new hardware and updated versions of operating systems, the book is of course somewhat out-of-date since it first appeared. It takes a long time to get through the book, but the time spent is well worth it. My interest in the book was mostly in performance aspects of computer architecture, and how to relate the material in the book to the SPEC benchmarking studies. For this reason, and for lack of space, my comments will briefly summarize the parts of the book that I found exceptionally well-written in this area.<br /> The discussion on the measuring and reporting of computer performance begins early in the book, wherein the authors attempt to quantify what it means for one computer to be faster than then another. They take the position that the best measure of performance is the execution time of real programs. They of course mention benchmarks as a way of doing this, and discuss briefly the SPEC92 benchmark suites. The SPEC standards have changed considerably since this book was written however. After a discussion of the methods to calculate performance, and their drawbacks, the authors discuss Amdahl's Law and how to use it correctly. This is followed by a discussion of the CPU performance equation with several interesting examples given. There is a \\"fallacies and pitfalls\\" section at the end of chapter one, as there is at the end of every chapter, that discusses the problems with approaches taken in benchmarking performance. These arguments are considerably important if one is to step away from marketing claims when developing commercial software packages, especially for scientific applications. Customer satisfaction in using these packages is dictated by the actual performance, not what might be accomplished in an isolated test environment. The author's honest approach to these issues is extremely helpful to those involved in developing these kinds of programs and applications.<br />One of the more common fallacies that they discuss in this regard are: The MIPS value as being indicative of performance among computers. They argue that this is not the case since MIPS is dependent on the instruction set, the program being run, and it can vary inversely to performance. For the later, they give the well-known example of machines with optional floating-point hardware. The MIPS rating can be misleading since floating-point programs using the hardware take less time but have a lower MIPS rating. If software floating point routines are used, they result in a higher MIPS rating but the execution time is longer. The issues with instruction sets are given a very detailed treatment by the authors, along with the role of compilers in designing an efficient instruction set. They discuss how variables are allocated and addressed and how many registers are needed to allocate the variables appropriately. They use a hypothetical load-store architecture, which they call DLX to illustrate the points they are attempting to make. The DLX is generic enough so as to be convincing in its didactic quality, based as it is on the computer hardware that was available at the time of writing.<br />The authors give a thorough discussion of pipelining, including performance issues and potential pitfalls in using it. They also describe the use of dynamic scheduling to avoid stalling when data dependencies are present. The scoreboard and Tomasulo approaches to dynamic scheduling are discussed. In addition, the authors spend a lot of time discussing cache memory design and cache optimization, andvirtual memory. The chapter on storage media is excellent and the authors employ some queuing theory to estimate the reponse time and throughput of an I/O system, assuming that the system is in equilibrium. The authors then discuss in detail different ways to benchmark I/O performance. This discussion is extremely important for those involved in Web server performance modeling and benchmarking. An excellent example is given dealing with the performance of a UNIX file system.<br />Chapter 7 is very important for those who need to study the performance of networked computers. The authors begin by considering a simple network consisting of two machines containing FIFO queues. They then design a simple protocol, similar to UDP for transferring data between these machines, and calculate the total latency of this network. Interconnection media are considered, although the presentation is somewhat out-of-date due to improvements and costs since the book was written. Performance issues with switched (ATM) versus shared medium (Ethernet) are discussed. The authors also treat connectionless networks with a brief overview of the TCP/IP protocol, and mention the role of the Internet, but do not discuss, disappointingly, performance issues with TCP/IP over the Internet, which is a formidable mathematical problem.<br />The treatment of multiprocessor architectures is excellent and the authors discuss two application kernels that are frequently used in scientific applications: the Fast Fourier Transform and the LU factorization from linear algebra. The parallel implementation of these algorithms is extremely important in scientific programming. They consider the Barnes-Hut n-body algorithm and the Ocean application to study scaling and performance issues in parallel programs.<br />Some excellent appendices appear in the book, particularly the ones on vector architectures. For those interested in scientific applications, vector processing is a popular methodology for performance enhancement. But the authors point out that the popularity of vector processing seems to becoming to an end, due to advances in microprocessor technology. Scientific progammers have realized this, and have devoted much of their time in writing code that will run on these processors, which is frequently a challenging proposition.nd virtual memory. The chapter on storage media is excellent and the authors employ some queuing theory to estimate the reponse time and throughput of an I/O system, assuming that the system is in equilibrium. The authors then discuss in detail different ways to benchmark I/O performance. This discussion is extremely important for those involved in Web server performance modeling and benchmarking. An excellent example is given dealing with the performance of a UNIX file system. <br />Chapter 7 is very important for those who need to study the performance of networked computers. The authors begin by considering a simple network consisting of two machines containing FIFO queues. They then design a simple protocol, similar to UDP for transferring data between these machines, and calculate the total latency of this network. Interconnection media are considered, although the presentation is somewhat out-of-date due to improvements and costs since the book was written. Performance issues with switched (ATM) versus shared medium (Ethernet) are discussed. The authors also treat connectionless networks with a brief overview of the TCP/IP protocol, and mention the role of the Internet, but do not discuss, disappointingly, performance issues with TCP/IP over the Internet, which is a formidable mathematical problem. <br />The treatment of multiprocessor architectures is excellent and the authors discuss two application kernels that are frequently used in scientific applications: the Fast Fourier Transform and the LU factorization from linear algebra. The parallel implementation of these algorithms is extremely important in scientific programming. They consider the Barnes-Hut n-body algorithm and the Ocean application to study scaling and performance issues in parallel programs. <br />Some excellent appendices appear in the book, particularly the ones on vector architectures. For those interested in scientific applications, vector processing is a popular methodology for performance enhancement. But the authors point out that the popularity of vector processing seems to becoming to an end, due to advances in microprocessor technology. Scientific progammers have realized this, and have devoted much of their time in writing code that will run on these processors, which is frequently a challenging proposition.	2002-04-30
1563034:US	50702879	R1258SBKCNSX2J	061806026X	438852329	Redesigning Humans: Our Inevitable Genetic Future	Books	5	41	43	N	Y	A breath of fresh air	Genetic engineering of humans: we can do it; we should do it; and we will do it.<br /> The author of this book is one of tbe best apologists for genetic engineering alive today, and this book is a fine example of his sound argumentation and comoon sense. He is unashamed of his position, delightfully unabashed, and one gets the impression while reading the book that he is very excited to be alive and be witness to the incredible advances in genetic engineering now taking place. Those who support the genetic engineering of humans should read the book, along with those that don't.<br /> As of this date, human cloning is being debated not only in the United States but all over the world, and a cloned embryo is now gestating inside of a woman somewhere in the world. This is indeed an exciting development, but the author says that the fuss over human cloning is unwarranted, but for different reasons than those opposed to it. Copying a human being is insignificant, he argues, compared to what can be done with engineering the human germline. The focus should be, the author argues, on how we are to proceed with this technology, a technology that he clearly supports. He is one of the few that does, oddly, out of the collection who themselves are responsible for the major advances in genetic engineering.<br /> But what of other ways of engineering improvements to human beings? Artificial intelligence and robotics have shown every indication of finally taking off, after decades of promises to that effect. Will humans, already inserting pacemakers, computer chips, and othe devices into their bodies, use this technology to enhance their vision, auditory capabilities, intelligence, etc? Who needs germline modification when this type of technology is available for enhancing human performance? The author argues that this will not be the case, that the human biological organism is too complex for this to happen. Also, the current level of knowledge on biological/electronic interaction is too primitive for such things as direct brain linkage. In addition, human beings will be reluctant to allow surgical implants such as these to be inserted into their brains.<br /> Although his arguments against the occurence of electronic enhancement are good, the author, with his advocacy of germline enhancement, may be expressing a worry that artificial intelligence and cyberelectronics may \\"win out\\" over biological approaches to human enhancement. Will there be competition between biotechnology and cybertronic technology for the enhancement of human capabilities in the decades ahead? A silicon-vs-carbon-race for this purpose could prove to be a very interesting one.<br /> The author is very honest and very frank is his discussions in the book, and such honesty is greatly appreciated in this time where genetic engineering is a frightening possibility to some. This omission of \\"tact and prudence\\" in discussions of genetic engineering serves better the purposes of rational debate and eases suspicions on the use of germline enhancement.<br /> The accelerating field of bioninformatics and its role in germline manipulation is emphasized many times by the author. Faster computers, cheaper DNA chips, and sophisticated sequence matching algorithms will increase the enticement to perform reliable and safe genetic engineering. One can extend the author's logic to future scenarios where each individual's genome will be sequenced and digitized in a database. Combinatorial mathematics will then allow a pair of humans to determine with confidence the genetic make-up of their offspring. Subjective preferences of the parents, always a factor in the selection of mates, and this translating of course into their children, will become much more sophisticated using 21st century genetic engineering. The freedom to choose is the basic premise and right here, its results will just occur at a faster time scale than evolution has done.<br /> The author is also an advocate of the freemarket when it comes to the inevitable choices involved in genetic engineering of humans. Considerations of cost and practicality will determine the prevelance of use of genetic technologies. What can be corrected by simple technology will eliminate the need for genetic engineering to do the same. A pair of glasses to correct for nearsightedness is a simpler and more economical approach than germline enhancement for better vision in our future children.<br /> The author has successfully countered the current most popular arguments against genetic engineering in this book. He has done it with fairness and confidence, and with a command of the ethical and scientific issues involved. It remains to be seen of course whether wide-scale genetic engineering of humans will indeed occur in the next decades. One can say with confidence that it will occur in at least a few cases. But one thing is certain: this is indeed an exciting time to be alive, that the contemplation of the technology of genetic engineering is  exhilirating, and its actual use even more so......free market when it comes to the inevitable choices involved in genetic engineering of humans. Considerations of cost and practicality will determine the prevelance of use of genetic technologies. What can be corrected by simple technology will eliminate the need for genetic engineering to do the same. A pair of glasses to correct for nearsightedness is a simpler and more economical approach than germline enhancement for better vision in our future children. <br /> The author has successfully countered the current most popular arguments against genetic engineering in this book. He has done it with fairness and confidence, and with a command of the ethical and scientific issues involved. It remains to be seen of course whether wide-scale genetic engineering of humans will indeed occur in the next decades. One can say with confidence that it will occur in at least a few cases. But one thing is certain: this is indeed an exciting time to be alive, that the contemplation of the technology of genetic engineering is  exhilirating, and its actual use even more so......	2002-04-28
1563378:US	50702879	RXR38F8CLL3AY	0070049084	801959221	002: Electricity and Magnetism (Berkeley Physics Course, Vol. 2)	Books	4	8	8	N	N	Still a good book after all this time	That this book is still in print is a testament to its popularity in the teaching of electromagnetic theory at the undergraduate level. Not only being popular, it is also a book of high quality and is packed full of the insights that are needed for students at this level. The only thing missing from the book, because of its age, is the inclusion of computer algorithms and code to solve problems in this subject. All physics textbooks in the 21st century should include the use of the computer so as to introduce the student to what is now the predominant way of solving problems in physics. The use of numerical methods in physics will continue to increase in the decades ahead, and students need to be exposed to these methods as early as possible.<br /> The author gives good descriptions of the vector calculus needed for a study of electromagnetism. The divergence of a vector function, Gauss's theorem, the curl of a vector function, and Stoke's theorem are all treated in detail, with diagrams employed at every step to reinforce the student's intuition. It is very important at this level to make sure the student understand these concepts in depth, as it will make the learning and appreciation of differential forms much easier in later courses in physics. Too often, vector calculus is presented to physics students as a formal construction, and the use of pictures is eschewed. Thankfully this author has not chosen this approach.<br /> In addition, in his discussion of the fields of moving charges, the author prepares the student for the special theory of relativity. An interesting thought experiment is given for illustrating the invariance of charge. A description is also given of the experiment of Henry Rowland, which in the 19th century detected the magnetic field of a charged rotating disk, thus supporting the theory of Maxwell. The Hall effect, of tremendous importance technologically, is described in detail. The famous &quot;jumping ring&quot; demonstration of Lenz's law is discussed also.law is discussed also.	2002-04-28
1564088:US	50702879	R2PTV3GFYYGHWP	0486409244	213354069	Quantum Mechanics (2 Volumes in 1)	Books	4	89	91	N	N	Still suitable as a reference/historical introduction	Published in 1958, this book is still used as a reference in graduate classes in quantum mechanics. One property of older books on quantum theory that is missing in more modern treatments is the inclusion of the history behind the subject. A discussion of the historical origins of a physical theory is of great importance in the learning and the appreciation of the subject. The first chapter of the first volume of this work does that very well, for the author gives a detailed discussion of the issues and experiments that were arising in classical physics in the early years of the 20th century that gave birth to quantum theory. This is followed in chapter two by an introduction (with history) to matter waves and the Schroedinger equation. Both of these chapters are very effective in developing the physical intution behind the quantum theory, beset as it is with problems of interpretation and mathematical inconsistencies.<br /> To develop this intuition further, the author discusses one-dimensional quantum systems in the next chapter. His remarks that these kinds of problems serve to develop the student's understanding and he also refers to the fact that several problems can be reduced to ones that resemble the one-dimensional Schroedinger equation. With the advent of exactly solved many-particle systems in one-dimension that were discovered after this book was published, the consideration of one-dimensional problems such as are included in this chapter is of even more importance. Most of the \\"standard problems\\" are discussed here, such as the potential step, the square well potential, and the square potential barrier. The author also does not hesitate to discuss the mathematical properties of the one-dimensional Schroedinger equation.<br /> Chapter 4 is an overview of the statistical interpretation of quantum mechanics. The most interesting (and controversial) part of this chapter is the statistical interpretation of the Heisenberg uncertainly relations. The root-mean-square deviations are defined precisely, but the author does not want to take a stand on the consequences that this move can entail, namely that the product of the root-mean-square deviations of position and momentum must be greater than Planck's constant is a statistical statement only. It does not say what could happen in principle to individual measurements of the position and momentum.<br /> The next four chapter discuss both the rigorous mathematical formalism behind quantum mechanics and its physical interpretation. The author's approach is pretty standard, but at times he feels the need to relax mathematical rigor, such as in the treatment of the Dirac delta \\"function\\". A proper treatment of this would entail bringing in some heavy guns from functional analysis, and the author is evidently hesitant to do this in a book at this level. His treatment of pure states and mixtures, namely that of quantum statistical mechanics is too short and could be excluded without detracting from the main points in these chapters. A connection with the classical is given via a discussion of Ehrenfest's theorem. Becuase chaos in classical mechanics was not known at the time of writing, the discussion here is now very out of date. Proving a version of Ehrenfest's theorem for such systems has to this date eluded researchers and has prohibited a sound formulation of \\"quantum chaos\\". The author does discuss the WKB approximation and shows how it can be used to study tunneling through a potential barrier. Path integral methods, known at the time of writing, but not very popular then, are not considered. And, in this treatment of the tensor product, he does not deal with the issue of entanglement of states, the latter being of enormous importance in current attempts to realize \\"quantum computation\\".<br /> The last three chapters of volume 1 cover exact solution methods for the Schroedinger equation, such as the scattering of a central potential, the harmonic oscillator, and Coulomb scattering. Such problems are now dealt with much more efficiently with symbolic computer languages such as Mathematica and Maple. The properties of the special functions that arise in these solutions are easily understood with the use of these packages.<br /> Volume 2 begins with a consideration of angular momentum in qunatum mechanics. The considerations of symmetry and conservation principles in this discussion are very important from a modern standpoint, permeating as they do in high energy physics and the goals of unification. The author does discuss briefly the issue of time reversibility in quantum mechanics. This issue has occupied the minds of hundreds of theorists, in attempting to elucidate the connection between statistical mechanics, with its \\"arrow of time\\", and quantum mechanics, which is invariant under time-reversal.<br /> Perturbation methods are discussed extensively in this volume. But here again, from a modern standpoint these methods can be treated best by the use of symbolic programming languages. In addition, since the use of a computer in physics was somewhat limited at the time this book was written, there is no inclusion of numerical methods. Any textbook on quantum mechanics at this level in the 21st century should include a very detailed introduction to numerical methods so as to prepare the student early on to techniques that will be used more and more in the decades ahead. The use of the computer, with dramatically enhanced computational power, will be the tool that will bring about more fundamental discoveries in the quantum realm in this century, particularly in quantum many-body physics and condensed matter.<br /> The last two chapters consider relativistic quantum mechanics and quantum field theory. Although the discussion is completely out-dated now, because of the current emphasis on functional methods, rather than canonical quantization as is done here, the discussion might be helpful as to gain insight as to why the canonical approach fell into disfavor.mb scattering. Such problems are now dealt with much more efficiently with symbolic computer languages such as Mathematica and Maple. The properties of the special functions that arise in these solutions are easily understood with the use of these packages. <br /> Volume 2 begins with a consideration of angular momentum in qunatum mechanics. The considerations of symmetry and conservation principles in this discussion are very important from a modern standpoint, permeating as they do in high energy physics and the goals of unification. The author does discuss briefly the issue of time reversibility in quantum mechanics. This issue has occupied the minds of hundreds of theorists, in attempting to elucidate the connection between statistical mechanics, with its \\"arrow of time\\", and quantum mechanics, which is invariant under time-reversal. <br /> Perturbation methods are discussed extensively in this volume. But here again, from a modern standpoint these methods can be treated best by the use of symbolic programming languages. In addition, since the use of a computer in physics was somewhat limited at the time this book was written, there is no inclusion of numerical methods. Any textbook on quantum mechanics at this level in the 21st century should include a very detailed introduction to numerical methods so as to prepare the student early on to techniques that will be used more and more in the decades ahead. The use of the computer, with dramatically enhanced computational power, will be the tool that will bring about more fundamental discoveries in the quantum realm in this century, particularly in quantum many-body physics and condensed matter. <br /> The last two chapters consider relativistic quantum mechanics and quantum field theory. Although the discussion is completely out-dated now, because of the current emphasis on functional methods, rather than canonical quantization as is done here, the discussion might be helpful as to gain insight as to why the canonical approach fell into disfavor.	2002-04-27
1565967:US	50702879	R2VO3HF2Y2FPFI	0486656322	451786890	A History of Mechanics (Dover Books on Physics)	Books	5	17	19	N	N	Excellent book	This book is a fascinating overview of the history of mechanics. One learns just how much was known about mechanics before the time of Galileo, and the facts are surprising. The work of Galileo and Newton was not a sudden leap in knowledge of mechanics, but grew out of work done in the middle ages and in ancient times. Here are just a few of the highly interesting historical facts that are expounded on in the book: 1. The work of Plato, who held that the weight of an object was the result of a force that was pushing it downwards. 2. The approach of Aristotle to mechanics: he was much more elaborate than Plato, and he made an intensive effort to understand the origin of motion fundamentally. The Aristotelian conception of motion and dynamics can be summarized as follows. There are two kinds of motion, natural and violent. Aristotle gives the falling body as an example of natural motion, whereas projectile motion is an example of violent motion. Violent motion has the property of being temporary, and objects undergoing violent motion will eventually undergo natural motion. Natural motion is in turn divided up into two classes: celestial motion and terrestrial motion. Objects that undergo celestial motion are characterized by what is now called uniform circular motion. On the other hand, terrestrial motion is rectilinear, and for Aristotle rectilinear motion is either straight up or straight down.  An object needs a force and a resistance acting on it if it is to be in motion. Heavy bodies fall faster than light ones. Aristotle refused to admit the existence of a vacuum since such a void would not sustain the motion of an object. In addition, a total vacuum would offer no resistance to the motion of an object, and thus the object would, according to Aristotle, move off with increasing speed. In a vacuum he concluded that heavy bodies would move with the same speed as light ones, again unacceptable he argued. 3.In the sixth century, the philosopher John Philoponus gave what is probably the first systematic attack on the Aristotelian ideas of motion. He argued that the planetary motions, as confirmed by observation, are much more complex than the simple circular motion that Aristotle imputed to them. Philoponus also proposed the so-called &quot;impetus theory&quot; to explain projectile motion. As the name implies, according to this theory the thrower imparts an impressed force or impetus to the projectile which keeps it moving until the &quot;natural&quot; motion and the resistance of the medium takes over. The projectile then falls straight down. The power given to the projectile by the impetus will gradually damp out because of the resistance of the medium and these &quot;natural tendencies&quot; of the projectile. 4. A somewhat more axiomatic and mathematical approach to mechanics in the thirteenth century was proposed by Jordanus of Nemore. His work is interesting in that it contains a notion of virtual work, a concept that was really not developed extensively (and proven to be practically useful) until the nineteenth century. Jordanus also attempted to quantify the idea of acceleration, and in his writings he deduced that an object accelerates when, in a fixed interval of time,  a greater amount of space is covered by the object, and so when the speed of the object increases. Jordanus discussed this in the context of falling objects, but he did not in his writings relate the distance the object falls in terms of the time it took the object to fall. As for the cause of the acceleration of the object, Jordanus held to the view that as the object descended, the object caused the air surrounding it to be less resistive, thereby causing the body to accelerate. Lastly, and most interestingly from the standpoint that it occured during the thirteenth century, an anomynous author of a work entitled Liber Jordani de ratione ponderis solved correctly the problem of the equilibrium of a heavy body on an inclined plane. 5. John I. Buridanof Bethune (1300 - 1358) developed a theory of the impetus which rejected the idea that air is the motive power for projectiles, Buridan took the impetus to reside permanently in the projectile, until the object is acted upon by some other forces. This belief of Buridan regarding the impetus is very important from a modern standpoint, because it is somewhat similar to the idea of inertia that was developed in the sixteenth and seventeenth centuries. In Buridan's view a heavy body would receive more of the impetus than a lighter one. Buridan gave as an example the difference in impetus gained from a heavy iron versus that of light wood. If two objects, one of wood and one of iron have the same volume and the same shape, then the iron object will be moved farther because it will have a greater impetus imparted to it.  6. The ideas of Buridan were discussed by Albert of Saxony (1316 - 1390). He held basically the same beliefs as Buridan about impetus and projectile motion, free fall, etc. Albert concluded that the speed of a falling object increases as the distance of the fall.  Most interesting is that he used the idea of impetus to treat the problem of a stone dropped through a hole in the Earth, and concluded that the motion of the stone would oscillate about the center of the Earth until the impetus in the stone was exhausted. 7. Noted work on mechanics in the fourteenth century was performed by logicians at Merton College. One individual of this school was William Heytesbury, who distinguished between the velocity of an object and the measure of how much the velocity is changing: the acceleration of the object. Heytesbury gave definitions of uniform velocity, uniform acceleration, and instantaneous velocity, but these were not correct from the standpoint of modern mechanics. He rejected the Aristotelian ideas on free fall, noting that a falling body travels three times as far in the second second of its fall as in the first.of Bethune (1300 - 1358) developed a theory of the impetus which rejected the idea that air is the motive power for projectiles, Buridan took the impetus to reside permanently in the projectile, until the object is acted upon by some other forces. This belief of Buridan regarding the impetus is very important from a modern standpoint, because it is somewhat similar to the idea of inertia that was developed in the sixteenth and seventeenth centuries. In Buridan's view a heavy body would receive more of the impetus than a lighter one. Buridan gave as an example the difference in impetus gained from a heavy iron versus that of light wood. If two objects, one of wood and one of iron have the same volume and the same shape, then the iron object will be moved farther because it will have a greater impetus imparted to it.  6. The ideas of Buridan were discussed by Albert of Saxony (1316 - 1390). He held basically the same beliefs as Buridan about impetus and projectile motion, free fall, etc. Albert concluded that the speed of a falling object increases as the distance of the fall.  Most interesting is that he used the idea of impetus to treat the problem of a stone dropped through a hole in the Earth, and concluded that the motion of the stone would oscillate about the center of the Earth until the impetus in the stone was exhausted. 7. Noted work on mechanics in the fourteenth century was performed by logicians at Merton College. One individual of this school was William Heytesbury, who distinguished between the velocity of an object and the measure of how much the velocity is changing: the acceleration of the object. Heytesbury gave definitions of uniform velocity, uniform acceleration, and instantaneous velocity, but these were not correct from the standpoint of modern mechanics. He rejected the Aristotelian ideas on free fall, noting that a falling body travels three times as far in the second second of its fall as in the first.	2002-04-25
1566773:US	50702879	R1Q9DWVR3SADQ0	0070335869	833662397	Introduction To Computer System Performance Evaluation	Books	4	3	3	N	N	Somewhat dated...but still has much to offer	This book is now ten years old but it still has much to say regarding the mathematical and simulation modeling of computer systems. In addition, many of the results in the book are directly relevant to computer network modeling and simulation, the latter taking on enormous importance due to the explosion of the Internet and of ever-changing WAN technologies. Also, the author devotes a lot of time to the validation and calibration of performance models. This is a topic that is usually glossed over in other books on the subject.<br /> Chapter 1 is an introduction to performance measures and evaluation techniques. It is out of date in some places, due to the hardware and operating systems the author discusses at various places in the book, these being available at the time at which the book was written. The SPEC benchmarking standard is discussed, but this benchmark has changed considerably since the book was written, and now has its own website. The author is careful to note the difficulties in applying performance evaluation measures used for single processor machines to those with highly parallel architectures.<br /> In chapter 2 the author discusses hardware, software, and hybrid measurement techniques for measuring computer system performance. \\"Primitive\\" measurements are defined, and he explains how a condition for measurement can be recognized as sampled or trace monitoring. The pitfalls involved in performing measurements in these three techniques are discussed, along with other issues that effect measurement. One of the most interesting points the author makes here regards the use of the performance index and its connection with the control parameter.<br /> The next chapter is very useful for those who need to do simulation modeling. Since such modeling is dependent on random number generation, the author discusses this along with the statistical data analysis techniques that must be used when analyzing the results of these simulations. He describes three different ways to organize simulation runs,  and how to choose the input factors to make the simulations less time-consuming. And, regression analysis, so important to performance modeling, is treated in great detail, along with variance reduction techniques.<br /> Queuing theory, of upmost importance in computer and network modeling, is discussed in chapter 4. The open and closed models are treated in detail, and the performance parameters of queues delineated. The throughput, utilization, and arrival laws, along with the famous Little's law are derived. The reader involved in Web server performance modeling will benefit greatly from the reading of this chapter. And, most importantly, the author discusses techniques for validating queuing models, a rare undertaking in books on this subject.<br /> The dialog gets much more mathematical in chapter 5, which discusses the stochastic processes of isolated X/Y/c queues, for X the interarrival-time distribution, Y the service-time distribution, and c the number of servers. Steady-state analysis of several different queues is accomplished, and the response-time distribution is calculated for an M/M type of queuing system. Transform techniques are used to solve batch systems via the method of stages.<br /> Product-form solutions are the subject of chapter 6, wherein the author considers both open and closed product-form queuing network models. The mean value analysi algorithm and a few others are discussed as exact algorithms for these kinds of queuing networks. Mean value analysis has arisen reently as an important algorithm for the study of wide-area network models. This and other algorithms for product-from networks are considered in much more detail in chapter 7, where convolution and the LBANC algorithms are also treated.<br /> Approximation techniques for solving complex queuing network models are discussed in chapter 8. Flow-equivalent aggregation techniques, which allow one to collapse a subnetwork of a queuing networkto a single station with a particular rate function are detailed. These techniques however, as the author points out, are very difficult to validate, and he does not discuss methods to do this. In addition, the author defines an interesting notion of a \\"conditional response time\\" for non-product-form scheduling disciplines.<br /> Even more advanced mathematical techniques are brought in beginning in chapter 9, wherein the author first tackles the E(k)/M/1 queuing system using generating functions. Readers will need some background in complex variables to follow the treatment here. The all-important M/G/1 queuing system is discussed and the author calculates the response-time distribution and busy period for it. The latter is important in the modeling of token ring networks. Matrix analytic techniques are then used to analyze nonexponential queuing systems and queues in random environments. The author also introduces Markov modulated Poisson processes in this context. These have become very important recently in the modeling of the Internet.<br /> Chapter 10 is more specialized, in that the author discusses techniques for find product-form solutions for networks with chain-dependent capacities, variable chain populations, rejection blocking, etc. The convolution and mean-value analysis algorithms are generalized to deal with these kinds of networks. Rejection blocking networks are interesting from the standpoint of TCP/IP networks, as they model a dropped packet that must be retransmitted by the client. Asymptotic expansions are used to analyze the behavior of normal usage networks. One example of this of current interest is a satellite network.<br /> Chapter 11 moves away from solution methods and concentrates on performance bounds for queuing networks. This is done for both load-independent and load-dependent stations, and for multiple-chain networks.<br /> In chapter 12, the author considers a very popular method for modeling the behavior of concurrent systems: Petri net techniques. These are briefly reviewed and then generalized to the stochastic case, followed by a discussion on how to apply them to the modeling of multiprocessor systems.<br /> The last chapter of the book outlines various applications of the methods developed in the book, one of these being token-ring networks. Although these networks are becoming rare these days, some large businesses are still employing them and so an understanding of their behavior is still important. Performance optimization problems and the of modeling fault-tolerant systems are also considered.etwork to a single station with a particular rate function are detailed. These techniques however, as the author points out, are very difficult to validate, and he does not discuss methods to do this. In addition, the author defines an interesting notion of a \\"conditional response time\\" for non-product-form scheduling disciplines. <br /> Even more advanced mathematical techniques are brought in beginning in chapter 9, wherein the author first tackles the E(k)/M/1 queuing system using generating functions. Readers will need some background in complex variables to follow the treatment here. The all-important M/G/1 queuing system is discussed and the author calculates the response-time distribution and busy period for it. The latter is important in the modeling of token ring networks. Matrix analytic techniques are then used to analyze nonexponential queuing systems and queues in random environments. The author also introduces Markov modulated Poisson processes in this context. These have become very important recently in the modeling of the Internet. <br /> Chapter 10 is more specialized, in that the author discusses techniques for find product-form solutions for networks with chain-dependent capacities, variable chain populations, rejection blocking, etc. The convolution and mean-value analysis algorithms are generalized to deal with these kinds of networks. Rejection blocking networks are interesting from the standpoint of TCP/IP networks, as they model a dropped packet that must be retransmitted by the client. Asymptotic expansions are used to analyze the behavior of normal usage networks. One example of this of current interest is a satellite network. <br /> Chapter 11 moves away from solution methods and concentrates on performance bounds for queuing networks. This is done for both load-independent and load-dependent stations, and for multiple-chain networks. <br /> In chapter 12, the author considers a very popular method for modeling the behavior of concurrentsystems: Petri net techniques. These are briefly reviewed and then generalized to the stochastic case, followed by a discussion on how to apply them to the modeling of multiprocessor systems. <br /> The last chapter of the book outlines various applications of the methods developed in the book, one of these being token-ring networks. Although these networks are becoming rare these days, some large businesses are still employing them and so an understanding of their behavior is still important. Performance optimization problems and the of modeling fault-tolerant systems are also considered.	2002-04-25
1568472:US	50702879	R1EDC5HO21USZP	0071353461	69235723	Schaum's Outline of Programming with C++	Books	3	19	20	N	N	Good introduction	The number of books on C++ on the market has exploded in recent years, no doubt due to the growing popularity of this language and the accompanying object-oriented paradigm. With code reusability and software engineering becoming crucial elements of both business and scientific programming, C++ has become the language of choice for many developments in these areas. The author has written a pretty good book on C++ here, but readers will need to know a lot more about programming than what the author assumes, namely that one could be a beginner to programming. There is an element of abstraction in object-oriented programming that might at first seem alien to a newcomer to programming, so it is best that this kind of programming be introduced after one has gained some experience in programming. That being said, an ambitious reader who needs to jump right into programming without any prior experience will find the book helpful in this regard. And, like all books in the Schaum's Outline series, many examples and problems are given to test the reader's understanding of how to program in C++.<br /> Most of the important concepts in C++ are introduced in this book, and there are really no surprises or idionsyncracies in the author's approach to teaching C++. Naturally one will have to run some of the programs developed in the book, and the author has inserted warnings in various places in the book that alert the reader to possible conflicts with different C++ compilers. In addition, he tries to adhere to current standards in software engineering regarding comments and code design. Readers who have programmed in C will notice right away its legacy in the language constructs of C++. Performance issues that arise between the choice of C and C++ are not discussed in the book, due no doubt to its goal of being an elementary introduction. The author does include a discussion of the notorius and antiquated \\"goto\\" statement in C++, but warns, thankfully, that use of these may result in code that is very difficult to debug. For those readers intending to do scientific programming in C++, brief discussions with code examples of roundoff error, random number generation, and linear regression, Monte Carlo simulation, are given. For the reader astute in mathematics, the author discusses, again with code examples, the Euclidean and Babylonian algorithms, the game of craps, the Sieve of Eratosthenes. In addition, a good discussion is given of the difference between passing by value and passing by reference. A nice example is given of how to use a function as an array subscript.<br />The author shows effectively how to use pointers to functions to define functions of functions by passing a function pointer as a parameter to another function. Friend functions are also introduced. These are considered by some to be a violation of  the object-oriented paradigm, but they can be powerful in practice, particularly with the use of operator overloading. In addition, a very effective discussion is given of virtual functions and polymorphism, and templates and iterators. For the scientific programmer in particular, this is a very powerful feature of C++.t in code that is very difficult to debug. For those readers intending to do scientific programming in C++, brief discussions with code examples of roundoff error, random number generation, and linear regression, Monte Carlo simulation, are given. For the reader astute in mathematics, the author discusses, again with code examples, the Euclidean and Babylonian algorithms, the game of craps, the Sieve of Eratosthenes. In addition, a good discussion is given of the difference between passing by value and passing by reference. A nice example is given of how to use a function as an array subscript. <br />The author shows effectively how to use pointers to functions to define functions of functions by passing a function pointer as a parameter to another function. Friend functions are also introduced. These are considered by some to be a violation of  the object-oriented paradigm, but they can be powerful in practice, particularly with the use of operator overloading. In addition, a very effective discussion is given of virtual functions and polymorphism, and templates and iterators. For the scientific programmer in particular, this is a very powerful feature of C++.	2002-04-24
1570878:US	50702879	R865FF1PTH37C	1572319658	790446852	Learn Microsoft Visual C++ 6.0 Now	Books	3	7	8	N	N	Pretty good introduction to Visual C++	For those who have had exposure to C++ but are not experts, and who need to learn Visual C++, this book would be a good choice. The book emphasizes the Microsoft Foundation Classes, since it is a Microsoft Press book, and the author includes more background material in C++ for those who need it. But lest the reader get bogged down in the intricacies of C++ , the author includes an introduction to Visual C++ in the first chapter of the book. It is assumed, naturally, that the reader will be in front of a computer with Visual Studio open while reading the book, and inputing code or navigating in it as the author requests in the book. Readers who intend to program business applications in C++  will find the book very useful. At the present time, scientific programming in C++ is on the rise, and even though Visual C++ and its GUI environment may be overkill for these applications, this situation is changing, especially in areas such as computational biology and financial engineering. Readers in these fields are frequently faced with creating GUI environments for their applications, and so Visual C++ can be of help in this regard.<br />Chapters 2-5 are an overview of C++ and object-oriented programming and can be skipped by readers who already have the necessary background. The material is pretty standard, and the author gives suggestions on how to program more efficiently in C++. Readers without any knowledge at all of C++ might find the reading somewhat difficult, as the author does not give an in-depth presentation of the relevant concepts in C++. A fairly good discussion of the scoping rules in C++ is given,  along with pointers, MFC pointer conventions, classes, etc.<br />The author begins in chapter 6 to discuss the main goal of the book, which is to introduce the reader to Windows programming using the Microsoft Foundation Class Library. He emphasizes first the role of message passing via the message handlers, and the use of the MFC to write handler functions instead of window procedures to process window messages. The author is aware of the difficulty in learning the MFC and its consequent applications to Windows programming, and so he spends a fair amount of time looking at the MFC class hierarchy. The AppWizard is used early on to perform elementary coding examples. The author discusses the document/view architecture in terms of the separation of the data from how it is used; this being done with the class Cdocument for holding the data, and CView for viewing the data. This is an approach that characterizes the object-oriented origins of the MFC. Those readers who have programmed Windows applications using C will notice the absence of the WinMain function, this being done automatically by the MFC. The author summarizes the relationships between the MFC and the Win32 API for this kind of reader. this being done automatically by the MFC. The author summarizes the relationships between the MFC and the Win32 API for this kind of reader.<br />The next several chapters consider the use of the AppWizard and the MFC to a drawing application. Those interested in developing sophisticated scientific or financial applications might find this dull reading, but with some amount of patience one can get through it. In addition, the author introduces the Visual C++ debugger, and so for this reason alone the reading of these chapters might be profitable for such a reader. Also, the design of a Visual C++ application that contains a large amount of graphs will require knowledge of the tools discussed here.<br />The last part of the book concentrates on various ancillary topics in MFC that the author felt were necessary to use it more proficiently. The author includes a useful diagram of the MFC view class hierarchy in this regard. He also discusses the serialization of objects, of crucial importance to those who are needing persistence in their applications, particulary in Web-based applications and database programming. The most useful discussions for me in this part were the chapters on dialog boxes, controls, and toolbarsdiscussions for me in this part were the chapters on dialog boxes, controls, and toolbars	2002-04-22
1572946:US	50702879	RQTSLWPH6BCZ4	0521589894	799398827	Quantum Field Theory in Condensed Matter Physics	Books	5	15	16	N	N	Modern overview that emphasizes the physics	Quantum field theory has been applied to many different areas of physics, and has done a fairly good job of explaining the phenomena in these areas. When applying quantum field theory to a physical problem one usually takes a pragmatic attitude, and ignores the many existing difficulties in its formalism. Quantum field theory has yet to be put on a rigorous mathematical foundation, but this has not deterred its use in a myriad of applications, with condensed matter physics, the subject of this book, being one of them. The author has done a superb job here, since he emphasizes the physics behind quantum field theory, and not just the formalism. Anyone interested in quantum field theory, and especially those outside the &quot;oral tradition&quot;, will definitely benefit from its perusal.<br /> That quantum field theory is similar to statistical mechanics is used extensively in this book. Loosely speaking, one can view the quantum field theory of a system in a certain dimension as a statistical mechanical system in one dimension more. This simplifies calculations considerably, and in condensed matter physics things get even easier since a lattice is present, thus allowing one to deal more transparently with the problems with infinities that will always appear in quantum field theory.<br /> The author gives an overview of quantum field theory in the first part of the book, it being assumed that the reader already has a strong background in it. The calculation of correlation functions is the main goal of the book, and to facilitate this, the author introduces the path integral formalism. Wick's theorem, the tour-de-force of calculations in quantum field theory is then derived. Explicit calculations are done for a bosonic field in an external field using the now ubiquitous mathematical identity that &quot;the determinant of an operator is the exponential of the trace of the logarithm of the operator. One should remember when reading these pages that the considerations are purely formal since no mathematical justification has been given for the path integral measure. Perturbation theory and Feynman diagrams are discussed (of course) and the infinities that arise in perturbation series are dealt with using regularization procedures. Since the author is dealing with problems in condensed matter, where a lattice is present, he labels quantum field theories as &quot;universal&quot; if there is no dependence of the correlation functions in the lattice. Since regularization procedures are obviously dependent on the lattice spacing (the &quot;ultraviolet&quot; and &quot;infrared&quot; divergences), physical quantities that depend on this are called &quot;non-universal&quot; by the author. The standard characterization of a theory as being &quot;renormalizable&quot; is reserved for those where the perturbation expansion can be reformulated so that non-universal quantities appear as a finite number of parameters. This leads to a formulation of the &quot;universality hypothesis&quot; and the renormalization group. The author states the Gellman-Low equation, and shows that the behavior of the Gellman-Low function graphically. The properties of this function in predicting asymptotic freedom and phase transitions are discussed in detail. The O(N) model is used to illustrate some of the phenomena exhibited by quantum field theories, such as symmetry breaking and the origin of Goldstone bosons.<br /> All of these considerations involve only bosonic quantum field theories, but the inclusion of fermions is done in the second part of the book. The discussion here is also more physical, as the author discusses electrodynamics in metals, the treatment however being non-relativistic. This is remedied though later as the author treats quantum electrodynamics. The Schwinger model, and the origin of anomalies as a screening of the electromagnetic field is discussed, and this discussion is more physically motivated and better appreciated intuitively than the one based on path integral measures. The famous Boson-Fermion equivalence in (2+1) dimensions is discussed in terms of the Aharonov-Bohm effect. This is an interesting discussion and one that is somewhat unorhodox, as it is usually not presented in this way. It clearly shows the physical meaning of adding the Chern-Simons term to the Lagrangian, presented in most books as being merely a mathematical device.<br /> Spin systems are the subject of part 3 of the book, with the author noting at the beginning that such systems are complicated to study due to the commutation relations of the spin operators. The emphasis is on disordered magnetic systems, and the presentation is crystal clear from a physical standpoint. The role of continuous symmetry in the nonlinear sigma model, and the breaking of discrete symmetry by short range quantum fluctuations is discussed in detail. The reader is also briefly introduced to the physics of doped antiferromagnets.<br /> The last part of the book is the most exotic, and one that is better understood from a mathematical standpoint. The physics of (1+1)-dimensional quantum systems has turned out to be more of a mathematical playground however, as it turns out to have many experimental manifestations, as the author points out many times. In addition, his treatment of the quantum field theory of the free massless bosonic scalar field shows that even a seemingly trivial action can have non-trivial properties in terms of its correlation functions. Perturbing this action by a cosine term gives the sine-Gordon model, which is exactly solvable, and its connection with conformal field theory is shown by the author. The famous Kosterlitz-Thouless transition is also treated in fair detail. The Ising and spin 1/2 Heisenberg models are discussed in terms of conformal field theories and bosonization. The reader thus gets a physical motivation for the consideration of conformal field theories that have resulted in an enormous amount of research in the past decade. And, also, the reader can see clearly the origin of Kac-Moody algebras and non-Abelian bosonization in these and latter discussions on current operators. The Kondo problem, dealing with a magnetic impurity in a metal, and one of the most difficult problems in condensed matter physics, is treated here in detail in one dimension at half-filling.the one based on path integral measures. The famous Boson-Fermion equivalence in (2+1) dimensions is discussed in terms of the Aharonov-Bohm effect. This is an interesting discussion and one that is somewhat unorhodox, as it is usually not presented in this way. It clearly shows the physical meaning of adding the Chern-Simons term to the Lagrangian, presented in most books as being merely a mathematical device. <br /> Spin systems are the subject of part 3 of the book, with the author noting at the beginning that such systems are complicated to study due to the commutation relations of the spin operators. The emphasis is on disordered magnetic systems, and the presentation is crystal clear from a physical standpoint. The role of continuous symmetry in the nonlinear sigma model, and the breaking of discrete symmetry by short range quantum fluctuations is discussed in detail. The reader is also briefly introduced to the physics of doped antiferromagnets.<br /> The last part of the book is the most exotic, and one that is better understood from a mathematical standpoint. The physics of (1+1)-dimensional quantum systems has turned out to be more of a mathematical playground however, as it turns out to have many experimental manifestations, as the author points out many times. In addition, his treatment of the quantum field theory of the free massless bosonic scalar field shows that even a seemingly trivial action can have non-trivial properties in terms of its correlation functions. Perturbing this action by a cosine term gives the sine-Gordon model, which is exactly solvable, and its connection with conformal field theory is shown by the author. The famous Kosterlitz-Thouless transition is also treated in fair detail. The Ising and spin 1/2 Heisenberg models are discussed in terms of conformal field theories and bosonization. The reader thus gets a physical motivation for the consideration of conformal field theories that have resulted in an enormous amount of research in the past decade. And, also, the reader can see clearly the origin of Kac-Moody algebras and non-Abelian bosonization in these and latter discussions on current operators. The Kondo problem, dealing with a magnetic impurity in a metal, and one of the most difficult problems in condensed matter physics, is treated here in detail in one dimension at half-filling.	2002-04-20
1574949:US	50702879	R25L0SK4TRBF9Y	0471941867	936526069	Quantum Field Theory, Rev.Ed.	Books	3	19	25	N	N	Quick overview of quantum field theory	When this book was first written, the intermediate vector bosons had only recently been (indirectly) observed, giving more weight to the gauge theory of electroweak interactions. The first edition did not treat the electroweak theory at all, but this, the revised edition, does, albeit using a formalism that is now considered to be somewhat antiquated. In particular, the methods of functional integration are not used at all. Canonical methods are used instead in the quantization procedures. The reader interested in a fast overview of quantum field theory could benefit from a perusal of the book. There are no fresh insights on quantum field theory in the book, and so it should really be considered as more of a bread-and-butter overview of the subject, with emphasis on the calculations of cross-sections rather than on a deep understanding of quantum field theory. The latter is very difficult both to explain and to research, and readers will have to look elsewhere to obtain this level of knowledge, or, better yet, figure it out for themselves and propose new approaches to quantum field theory, that not only predicts the results coming from scattering experiments, but also solves the major unsolved problem of quantum field theory: the existence of a bound state.	2002-04-18
1578111:US	50702879	R27U78U3EZ8YY1	0672312409	847555097	Sams Teach Yourself Visual C++ 6 in 21 Days	Books	3	4	5	N	N	Pretty good	For those programming in C++, Microsoft Visual Studio can be both a blessing and a curse. There are many instances in program and project development where the package can be very helpful and save hours in development time. This is usually the case for commercial applications. For technical or scientific applications written in C++ though, Visual Studio can be very painful, as it does given the developer a view of what is going on behind the scenes. Individuals who are doing scientific applications usually want to have control of most of code, and so templating and the Application Wizard can be more of an annoyance rather than of help. For this reason, scientific programmers will probably not want to read this book at all. But frequently these days, scientific programmers are involved in developing applications in areas such as finance and bioinformatics, and so a study of this book would then be appropriate. Readers of the book are expected to have a thorough knowledge of C++, but the author gives a short (36 page) review in an appendix to the book for those who need such a review.<br />For readers who are writing Windows applications using Visual C++, the author has done a pretty good job of overviewing how to develop with Visual Studio. He begins with the simplest features of Visual Studio, and builds up to more advanced features, to the extent possible in Visual Studio. Some features of Visual Studio are so entrenched at all levels of the package that it is difficult to separate them out, being themselves advanced features, at early stages in the book. This is readily apparent in the author's use of the \\"WinExec' function instead of the \\"CreateProcess\\" function, since the latter is deemed to complicated for the beginning reader. The Class Wizard and AppWizard are brought in early on, no doubt to encourage the reader to become adept at using them as soon as possible. The major goal of the book then is to get the reader to create a Windows application as soon as possible.<br />Some helpful and useful discussions in the book include: 1. The Q&amp;A section at the end of the chapter, wherein the author attempts to anticipate a typical reader's questions after they have finished the chapter. 2. The review sections at the end of each week, detailing to readers just what they are expected to know before moving on. 3.  Binary attribute flags,  for memory-senstive applications that need window and control capabilities. 4. The creation of custom dialog windows; the author is very detailed here and he also shows the role of the MFC class library in creating these. 5. ActiveX controls are introduced fairly early, and this is good considering their importance and pervasiveness in current applications. 6. How to make application objects serializable using the CArchive class and Serialize function. Performance and legacy issues with serialization dictate that particular attention be made to this discussion. 7. Database access and updating. Performance issues involved in database access again make this discussion mandatory reading for those who are involved in these kinds of applications, particularly for database applications that are used in a client/server configuration with a database server that is accessed over a wide-area network. The author does not discuss these issues unfortunately, but ADO, which is used to build a database application in the book, has had performance problems in the past. 8. The creation of library modules and dynamic link libraries. For creating software for scientific purposes where classes should be used from one application to another, this discussion is particularly appropriate. The author also spends a small amount of time on how to create test applications to test these modules. In addition, he shows how to convert a regular DLL so that it can be used by applications not created with Visual Studio. The author mentions that in the design of DLLs one must insure that they be \\"threadsafe\\". Multithreading in C++ however is not a subject that is usually encountered in a course on C++, so this inclusion may cause difficulty for some readers. This is alleviated somewhat in a later discussion on threads. 9. How to add multitasking to applications. Multithreading again makes its appearance here, but in this case the author spends more time on explaining the origin and need for it. The author details a fun example of multithreading that involves four spinning color wheels. 10. The discussion on creating Internet applications. Although the author does not dicuss performance issues in creating these, he does give some basic background on how actually to program them.in C++ however is not a subject that is usually encountered in a course on C++, so this inclusion may cause difficulty for some readers. This is alleviated somewhat in a later discussion on threads. 9. How to add multitasking to applications. Multithreading again makes its appearance here, but in this case the author spends more time on explaining the origin and need for it. The author details a fun example of multithreading that involves four spinning color wheels. 10. The discussion on creating Internet applications. Although the author does not dicuss performance issues in creating these, he does give some basic background on how actually to program them.	2002-04-16
1578126:US	50702879	R38E4QY5Y3UZZ0	0387536108	449262534	Local Quantum Physics: Fields, Particles, Algebras (Texts & Monographs in Physics)	Books	5	13	14	N	N	Deserves 10 stars	Quantum field theory is a subject that has occupied the time of an enormous number of researchers, both in physics and in mathematics. Those who have studied perturbation methods in quantum field theory have no doubt run acroos &quot;Haag's theorem&quot; that is usually loosely stated as saying that &quot;the interactive representation does not exist&quot;. The statement of this theorem, and many other results in quantum field theory, particularly the procedure of renormalization, have been viewed by many as unsound from a mathematical standpoint, and so efforts were begun to put quantum field theory on a rigorous mathematical foundation. Going by the names of axiomatic or constructive quantum field theory, these approaches are interesting, but also a little troubling from a scientific perspective. Axiomitization is usually appropriate in mathematics when a subject has matured to the point where it can be &quot;closed off&quot;, and this usually happens when the theory is very well understood and so its essence can be codified in a few well-forumlated axioms. But quantum field theory is no where near that stage; indeed one can say that it continues to be a theory that, oddly, has immense predictive power but whose rigorous mathematical formulation remains elusive. Not only that, quantum field theory is still in a course of evolution, and any attempt at axiomitization might become obsolete as soon as it is put down on paper. In addition, physical insight, as much as mathematical understanding, must not be sacrificed in any resulting axiomatization of quantum field theory. Frequently, the result of axiomatization is to divorce a physical theory from its physical roots, and beginning students of the theory then have difficulty in acquiring intuition of the essential physics of the theory.<br /> One of the best attributes of this book is that the author realizes this, and early on he refers to &quot;general&quot;, rather than &quot;axiomatic&quot; QFT as being more appropriate since it allows flexibility in relation to future discoveries. Not only that, the author endeavors to explain the formalism that he is expousing in the book, and he succeeds brilliantly. Anyone interested in the mathematical physics behind quantum field theory, and not just doing bread-and-butter perturbation calculations, will gain a lot from the reading of this book. It is packed full of insight, a rare occurence in books that employ the heavy mathematical formalism that this one does. One will need a strong background in operator theory, abstract theory, and several complex variables to read the book, but a lot of this is developed impromptu as the text unfolds. When it is not, the author gives references for those readers who need more in-depth discussion.<br /> There are so many ineresting discussions in this book that space does not permit an evaluation of all of them, but the following is a short list of points in the book that I found particularly well-written: 1. The Wigner analysis of irreducible unitary representations of the Poincare group. This is not a mathematically rigorous discussion, but the author points out the physical relevance of the fact that the spectrum of the 4-momentum operator must be concentrated on a single orbit. This fact ensures the stability of matter. And, as frequently happens in physics, several mathematical consequences of a particular physical theory are discarded as not being relevant; in this case the other three classes of the irreducible representations. That being said, the author does include as of possible physical relevance the idea of parastatistics. He points out his reasons for this, namely that a strict adherence to the Bose-Fermi alternative is not operationally justified. 2. The role of fields in implementing the principle of locality and not as observable particles. This fact is usually not emphasized in books on quantum field theory. 3. The author clarifies the distinction between the notion of localitythat deals with the commutation of two observables that are space-like separated, and the one dealing with the Einstein-Podolsky-Rosen paradox and Bell's inequality. 4. The discussion on the Bose-Einstein alternative, in particular the suggestion that parastatistics can be replaced by Bose or Fermi statistics in the presence of a non-Abelian unbroken global gauge group. 5. The discussion on topological charges and their prohibition by the Doplicher-Haag-Roberts selection criterion. The Doplicher-Haag-Roberts criterion was used in scattering theory and thought to be reasonable, but the author shows that its use is problematic in this case also, as well as in prohibiting topological charge. Purely massive fields can, it turns out, have measurable correlations at large distances, and Borcher's selection criterion, also discussed along these lines, gives topological charges. 6. The treatment of the Tomita-Takesaki theorem, modular automorphisms, and their connection to the KMS-condition. 7. The discussion on the need for type III-1 von Neumann algebras in relativistic quantum field theory versus type I in ordinary quantum mechanics. Such a von Neumann algebra is hyperfinite and is unique. 8. The discussion on the impossibility of coherent wave packets of one-electron states in quantum field theory, as contrasted with the usual practice in quantum mechanics. This is dues to superselection rules and the &quot;infraparticle&quot; nature of electrically charged particles, which are not associated with discrete eigenvalues of the mass operator. The author asks the reader to justify electron interference experiments in quantum field theory.ty that deals with the commutation of two observables that are space-like separated, and the one dealing with the Einstein-Podolsky-Rosen paradox and Bell's inequality. 4. The discussion on the Bose-Einstein alternative, in particular the suggestion that parastatistics can be replaced by Bose or Fermi statistics in the presence of a non-Abelian unbroken global gauge group. 5. The discussion on topological charges and their prohibition by the Doplicher-Haag-Roberts selection criterion. The Doplicher-Haag-Roberts criterion was used in scattering theory and thought to be reasonable, but the author shows that its use is problematic in this case also, as well as in prohibiting topological charge. Purely massive fields can, it turns out, have measurable correlations at large distances, and Borcher's selection criterion, also discussed along these lines, gives topological charges. 6. The treatment of the Tomita-Takesaki theorem, modular automorphisms, and their connection to the KMS-condition. 7. The discussion on the need for type III-1 von Neumann algebras in relativistic quantum field theory versus type I in ordinary quantum mechanics. Such a von Neumann algebra is hyperfinite and is unique. 8. The discussion on the impossibility of coherent wave packets of one-electron states in quantum field theory, as contrasted with the usual practice in quantum mechanics. This is dues to superselection rules and the &quot;infraparticle&quot; nature of electrically charged particles, which are not associated with discrete eigenvalues of the mass operator. The author asks the reader to justify electron interference experiments in quantum field theory.	2002-04-16
1582243:US	50702879	R35RD1O6UQR7PR	0262133822	566705154	Robo sapiens: Evolution of a New Species	Books	5	7	8	N	Y	The robots are coming...	In view of the news last week that Kevin Warwick, one of the roboticists talked about in this book, had a chip imbedded permanently under his skin, this book takes on a profound significance. The book includes interviews with some of the major researchers in robotics and artificial intelligence, and has many beautiful photographs. In addition to the news of Warwick's operation, other news of exciting advances in robotics have been reported in the technicial journals and in the news media in recent months. And with the advent of robot toys and a Hollywood movie about artificial intelligence, it seems that robotics has taken us by storm. These developments are indeed exciting, for those working in the field of artificial intelligence, and those that are not, and even though there is perhaps a long way to go before we are priveleged to be among autonomous thinking machines working and playing among us, we are witnessing a good beginning. Indeed we are very lucky to be in a time when the dreams of the researchers in artificial intelligence are finally beginning to be realized, even at a modest level. This book is, thankfully, optimistic in its appraisal of robotics, and as the name of it implies, it has a somewhat different viewpoint on its future. Robots, it contends, will not necessarily be separate independent entities possessing superior intelligence and physical capabilities. By taking on chips underneath their skin, by using hearing aids, by employing heart defibrillators, by reverse engineering the human brain, and by immersing other devices in their bodies, humans will (slowly?) evolve into a superposition of the biological and mechanical. The robots....<br />......will be us......	2002-04-12
1582559:US	50702879	R1A8OS27AO2OXO	0673999866	266744558	Pointers on C	Books	5	43	44	N	N	The best book on C in print	For those who need an up-to-date ANSI overview of the C programming language, this book would be an excellent introduction. Pointers are usually a stumbling block for those programming C initially, but the author does an excellent job of detailing the use of pointers in this book. The use of pointers dominates the entire book, and after studying it, readers will have a thorough, practical knowledge of how to take advantage of the performance power of C language, due mostly to its use of pointers. For those programming in a commercial/business environment, where coding practices are strictly enforced, this book would be a good desk reference, as the author includes discussion of sound programming practices throughout the book. The book would also serve well those involved in teaching C in the classroom, as it contains many exercises, ranging from very easy to highly advanced. And for those readers frequently facing legacy code in C, such as scientific programmers, the author cites the differences between the older \\"Kernighan-Ritchie\\" C, and the more modern ANSI C, the latter being used in the book. These differences are indicated in the margin of the book, and are of an enormous help for those who must take older code and get it to run on more up-to-date compilers.<br />The author also endeavors to organize the C code for those who are going on to study C++ and the accompanying object-oriented approach to programming. In addition, he emphasizes how to write C code so as to make it more portable. For those writing commercial applications in C that must be used on different platforms, this is a very important issue of course. Particularly well-written is the author's discussion on the storage class of a variable, noting, for those such as I who are pre-disposed to using recursion, that the formal parameters to a function cannot be static if recursion is to be supported. The book is full of examples such as this that give readers insight on the workings of C that fit their particular programming style.  He does discuss `goto' statements in relation to function scope and in C statement structures, but, thankfully, recommends such statements never be used. He gives an interesting counterexample to those who say that goto statements must be used to break out of nested loops. Also, the author discusses the difference between L- and R-values, and this is not usually included in beginning books on C. Dynamic memory allocation has  been at times a somewhat painful aspect of programming in C, but the author shows how to do straightforwardly in the book.<br />Having a book like this that is predominantly about pointers is quite a blessing for those who are inexperienced with them or for more experienced programmers who are still uncomfortable with their use. It is not uncommon these days to have to write programs in one's professional work that involve triple pointers or even quadruple pointers. In addition, for embedded systems programming, the use of pointer arithmetic is almost mandatory. This also is true for writing applications in cryptography using C. The author does pay careful attention to pointer arithmetic in the book.  The performance pay-off for using pointers is undeniable, and so a thorough knowledge of their use and pit-falls is of upmost importance for those C programmers who are involved in writing performance-sensitive applications. The author discusses in detail what can happen when pointers are misused and gives many examples of what to avoid and good hints for the proper use of pointers. He recommends against the use of the `null' pointer in array searching, and recommends a strategy for circumventing them. Some very helpful diagrams are given for explaining pointer expressions. In addition, the author gives helpful hints on when to use pointers and not subscripts when manipulating arrays in C.  The performance issues involved in this are extremely important in scientific programming using C. The author gives a very interesting example of the differences in performance using pointers involving a program to copy the contents of one array into another. Arrays of pointers, useful in data mining applications, are also given ample treatment in this book, and the author addresses the issue of when to use a matrix instead of an array of pointers.<br />The author also gives an effective presentation of functions in C, particularly the construction of recursive functions, and he employs some useful diagrams to illustrate how the variables in a recursive function call change on the stack. The performance hit experienced by using recursion versus iterative loops is discussed in a standard way via the Fibonacci series. Those readers raised in the functional programming paradigm will want to pay notice these performance issues when using C to do recursion. Along the same lines, the author shows how to implement functions with variable argument lists in C. This is another topic that is frequently passed over in beginning books on C.<br />The author's treatment of data structures in C is also very nicely done, and he includes again a topic not usually treated in beginning books on C, namely the concept of a self-referential data structure. These are very important in applications in artificial intelligence, and the author shows how to implement them in C using a data structure that points to itself. This leads to a discussion of incomplete declarations. Very helpful diagrams are used again to discuss how to access members of data structures and how to point to data structures. Bit fields, so often used in embedded system applications, are also given a detailed treatment.interesting example of the differences in performance using pointers involving a program to copy the contents of one array into another. Arrays of pointers, useful in data mining applications, are also given ample treatment in this book, and the author addresses the issue of when to use a matrix instead of an array of pointers. <br />The author also gives an effective presentation of functions in C, particularly the construction of recursive functions, and he employs some useful diagrams to illustrate how the variables in a recursive function call change on the stack. The performance hit experienced by using recursion versus iterative loops is discussed in a standard way via the Fibonacci series. Those readers raised in the functional programming paradigm will want to pay notice these performance issues when using C to do recursion. Along the same lines, the author shows how to implement functions with variable argument lists in C. This is another topic that is frequently passed over in beginning books on C.   <br />The author's treatment of data structures in C is also very nicely done, and he includes again a topic not usually treated in beginning books on C, namely the concept of a self-referential data structure. These are very important in applications in artificial intelligence, and the author shows how to implement them in C using a data structure that points to itself. This leads to a discussion of incomplete declarations. Very helpful diagrams are used again to discuss how to access members of data structures and how to point to data structures. Bit fields, so often used in embedded system applications, are also given a detailed treatment.	2002-04-12
1584955:US	50702879	R2HEAWGGZRPXWF	0387540628	247706755	Numerical Solution of Stochastic Differential Equations (Applications of Mathematics)	Books	5	49	50	N	N	Excellent	This book is one of the finest written on the subject and is suitable for readers in a wide variety of fields, including mathematical finance, random dynamical systems, constructive quantum field theory, and mathematical biology. It is certainly well-suited for classroom use, and it includes computer exercises what are definitely helpful for those who need to develop actual computer code to solve the relevant equations of interest. Since it emphasizes the numerical solution of stochastic differential equations, the authors do not give the details behind the theory, but references are given for the interested reader.<br />As preparation for the study of SDEs, the authors detail some preliminary background on probability, statistics, and stochastic processes in Part 1 of the book. Particularly well-written is the discussion on random number generators and efficient methods for generating random numbers, such as the Box-Muller and Polar Marsaglia methods. Both discrete and continuous Markov processes are discussed, and the authors review the connection between Weiner processes (Brownian motion for the physicist reader) and white noise. The measure-theory foundations of the subject are outlined briefly for the interested reader.<br />Part 2 begins naturally with an overview of stochastic calculus, with the Ito calculus chosen to show how to generalize ordinary calculus to the stochastic realm. The authors motivate the subject as one in which the functional form of stochastic processes was emphasized, with Ito attempting to find out just when local properties such as the drift and diffusion coefficients can characterize the stochastic process. The Ito formula is shown to be a generalization of the chain rule of ordinary calculus to the case where stochasticity is present. The authors are also careful to distinguish between \\"random\\" differential equations and \\"stochastic\\" differential equations. The former can be solved by integrating over differentiable sample paths, but in the latter one has to face the nondifferentiability of the sample paths, and hence solutions are more difficult to obtain. The authors give many examples of SDEs that can be solved explicitly, and prove existence and uniqueness theorems for strong solutions of the SDEs. And since ordinary differential equations are usually tackled by Taylor series expansions, it is perhaps not surprising that this technique would be generalized to SDEs, which the authors do in detail in this part. They also outline the differences between the Ito and Stratonovich interpretations of stochastic integrals and SDEs.<br />Part 3 is definitely of great interest to those who must develop mathematical models using SDEs. The authors carefully outline the reasons where Ito versus the Stratonovich formulations are used, this being largely dependent on the degree of autocorrelation in the processes at hand. The Stratonovich SDE is recommended for cases when the white noise is used as an idealization of a (smooth) real noise process. The authors also show how to approximate Markov chain problems with diffusion processes, which are the solutions of Ito SDEs. Several very interesting examples are given of the applications of stochastic differential equations; the particular ones of direct interest to me were the ones on population dynamics, protein kinetics, and genetics; option pricing, and blood clotting dynamics/cellular energetics.<br />After a review of discrete time approzimations in ordinary deterministic differential equations, in part 4 the authors show to solve SDEs using this approximation. The familiar Euler approximation is considered, with a simple example having an explicit solution compared with its Euler approximate solution. They also show how to use simulations when an explicit solution is lacking. The importance notions of strong and weak convergence of  the approximate solutions are discussed in detail. Strong convergence is basically a convergence in norm (absolute value), while weak convergence is taken with respect to a collection of test functions. Both of these types of convergence reduce to the ordinary deterministic sense of convergence when the random elements are removed.<br />The discussion of convergence in part 4 leads to a very extensive discussion of strongly convergent approximations in part 5, and weakly convergent approximations in part 6. Stochastic Taylor expansions done with respect to the strong convergence criterion are discussed, beginning with the Euler approximation. More complicated strongly convergent stochastic approximation schemes are also considered, such as the Milstein scheme, which reduces to the Euler scheme when the diffusion coefficients only depend on time. The strong Taylor schemes of all orders are treated in detail. Since Taylor approximations make evaluations of the derivatives necessary, which is computational intensive, the authors discuss strong approximation schemes that do not require this, much like the Runge-Kutta methods in the deterministic case , but the authors are careful to point out that the Runge-Kutta analogy is problematic in the stochastic case. Several of  these \\"derivative-free\\" schemes are considered by the authors. The authors also consider implicit strong approximation schemes for stiff SDEs, wherein numerical instabilities are problematic. Interesting applications are given for strong approximations for SDEs, such as the Duffing-Van der Pol oscillator, which is very important system in engineering mechanics and phyics, and has been subjected to an incredible amount of research.<br />More detailed consideration of weak Taylor approximations is given in part 6. The Euler scheme is examined first in the weak approximation, with the higher-order schemes following. Since weak convergence is more stringent than strong convergence, it should come as no surprise that fewer terms are required to obtain convergence, as compared with strong convergence at the same order. This intuition is indeed verified in the discussion, and the authors treat both explicit and implicit weak approximations, along with extrapolation and predictor-corrector methods. And most importantly, the authors give an introduction to the Girsanov methods for variance reduction of weak approximations to Ito diffusions, along with other techniques for doing the same. Those readers involved in constructive quantum field theory will value the treatment on using weak approximations to calculate functional integrals. The approximation of Lyapunov exponents for stochastic dynamical systems is also treated, along with the approximation of invariant measures.ue), while weak convergence is taken with respect to a collection of test functions. Both of these types of convergence reduce to the ordinary deterministic sense of convergence when the random elements are removed. <br />The discussion of convergence in part 4 leads to a very extensive discussion of strongly convergent approximations in part 5, and weakly convergent approximations in part 6. Stochastic Taylor expansions done with respect to the strong convergence criterion are discussed, beginning with the Euler approximation. More complicated strongly convergent stochastic approximation schemes are also considered, such as the Milstein scheme, which reduces to the Euler scheme when the diffusion coefficients only depend on time. The strong Taylor schemes of all orders are treated in detail. Since Taylor approximations make evaluations of the derivatives necessary, which is computational intensive, the authors discuss strong approximation schemes that do not require this, much like the Runge-Kutta methods in the deterministic case , but the authors are careful to point out that the Runge-Kutta analogy is problematic in the stochastic case. Several of  these \\"derivative-free\\" schemes are considered by the authors. The authors also consider implicit strong approximation schemes for stiff SDEs, wherein numerical instabilities are problematic. Interesting applications are given for strong approximations for SDEs, such as the Duffing-Van der Pol oscillator, which is very important system in engineering mechanics and phyics, and has been subjected to an incredible amount of research. <br />More detailed consideration of weak Taylor approximations is given in part 6. The Euler scheme is examined first in the weak approximation, with the higher-order schemes following. Since weak convergence is more stringent than strong convergence, it should come as no surprise that fewer terms are required to obtain convergence, as compared with strong convergence at the same order. This intuition is indeed verified in the discussion, and the authors treat both explicit and implicit weak approximations, along with extrapolation and predictor-corrector methods. And most importantly, the authors give an introduction to the Girsanov methods for variance reduction of weak approximations to Ito diffusions, along with other techniques for doing the same. Those readers involved in constructive quantum field theory will value the treatment on using weak approximations to calculate functional integrals. The approximation of Lyapunov exponents for stochastic dynamical systems is also treated, along with the approximation of invariant measures.	2002-04-10
1586648:US	50702879	R2IYBH8D6L9A4W	0691003920	850850373	Cycles and Chaos in Economic Equilibrium	Books	4	3	3	N	N	Good introduction to the theory	It was perhaps inevitable that the theory of chaotic dynamical systems would be applied to economics. In an intuitive, everyday sense, economic phenomena is usually perceived as being &quot;chaotic&quot;, this notion being equated with a random behavior of sorts. Whether or not economic systems are really random (from a rigorous mathematical standpoint) is the subject of other books. This one addresses the question as to whether chaos does indeed exist in economic systems. Chaos and randomness are of course distinct concepts, and this is brought out clearly by the authors of the articles in the book, the specific theme of which is to shed light on the role of oscillatory dynamics in economic fluctuations. The oscillations are put in the context of chaotic dynamical systems, which, as is well known, have a very rich orbit structure. The emphasis is on theory, but there are some articles that discuss empirical validation of chaotic dynamical system models of time series. What is most interesting about the results in the book is that chaos is a deterministic explanation of the erratic behavior of economic behavior. This is to be contrasted with the situation in financial modeling, where randonmess is thought to be essential because of arbitrage opportunities. It is fascinating to compare the ideas in this book with the ones that are very entrenched in financial modeling. The authors of the articles have been heavily involved in the research of chaotic dynamical systems in economics. Space here permits only a limited review of the contents of the book.<br /> . Before the advent of research in chaos in economics, the complexity of economic phenomena was modeled by linear equations subjected to exogenous shocks. The approach taken in one of the articles discusses to what extent aggregate fluctuations represent endogenous phenomena that are persistent even when there are no random shocks to the economy. Recognizing that chaotic dynamical systems can generate time series that appear irregular or random, discussion is given on the models based on chaos that exhibit the persistence phenomena. Since chaotic systems have countably many periodic orbits, it is natural to ask to what extent these orbits play in models of economic phenomena. One of these considered is the overlapping generations model. A class of robust utility functions, assumed to be constant from one generation to another, are shown to give the existence of bounded trajectories that do not converge to periodic orbits or fixed points, but are also, because of the time scales involved, indistinguishable from periodic orbits of arbitrarily long period, the latter also existing in the model. The existence of these trajectories is interesting, particularly when considering the mechanism by which the trades between generations occur. This mechanism involves the introduction of a central credit authority, and even when the nominal credit expands at a constant rate, the model still exhibits erratic trajectories in the real value of credit. These trajectories appear qualitatively to be very similar to trajectories generated from random processes, and so it is no surprise that statistical techniques and ergodic theory are employed to study their properties.<br /> Another economic model considered in the book is a two-sector growth model that consists of an industry producing consumption goods and another producing capital goods. A dynamical system parametrized by the capital depreciation rate is used to describe the time evolution of the aggregate capital stock over time, and is shown to have chaotic orbits for certain values of the capital depreciation rate. These chaotic orbits exist, interestingly, when capital, but not labor, is very productive in both sectors. An analysis of the relative capital-labor intensities is done to shed light on the oscillatory behavior of the model, this behavior contrary to the expected one of following a smooth averaged path. The latter is expectedbecause of the choice of a concave function for the consumption and investment processes. The model is not shown to be one that could reflect phenomena that exist in the real world. In particular, the time scales needed to observe the chaotic behavior are not discussed.<br /> Another issue taken up in the book deals with the question as to why economic activity exhibits fluctuations, and subsequent attempts to stabilize this activity via fiscal policy. The Judd model, which deals with technical innovation, is adapted to study the economic instabilities that arise from investment activity in such innovation, and the value of fiscal policy in dampening these instabilities. The model is shown to exhibit chaotic dynamics, with this being a consequence of the noncompetitive nature of a market immediately after a new good is introduced into the market. The discussion is reminiscent of arbitrage arguments in finance, since the monopolistic prices charged by the patent holder are wiped out by new innovations. Interestingly, the model shows examples of situations where stabilizing policies are undesirable, and in particular a waste of resources would result.d because of the choice of a concave function for the consumption and investment processes. The model is not shown to be one that could reflect phenomena that exist in the real world. In particular, the time scales needed to observe the chaotic behavior are not discussed. <br /> Another issue taken up in the book deals with the question as to why economic activity exhibits fluctuations, and subsequent attempts to stabilize this activity via fiscal policy. The Judd model, which deals with technical innovation, is adapted to study the economic instabilities that arise from investment activity in such innovation, and the value of fiscal policy in dampening these instabilities. The model is shown to exhibit chaotic dynamics, with this being a consequence of the noncompetitive nature of a market immediately after a new good is introduced into the market. The discussion is reminiscent of arbitrage arguments in finance, since the monopolistic prices charged by the patent holder are wiped out by new innovations. Interestingly, the model shows examples of situations where stabilizing policies are undesirable, and in particular a waste of resources would result.	2002-04-09
1590902:US	50702879	R1WT1AD1B137HB	0262631857	297264162	An Introduction to Genetic Algorithms (Complex Adaptive Systems)	Books	4	88	90	N	N	Good introduction for such a short book	Although short, this book gives a good introduction to genetic algorithms for those who are first entering the field and are looking for insight into the underlying mechanisms behind them. It was first published in 1995, and considerable work has been done in genetic algorithms since then, but it could still serve as an adequate introduction.  Emphasizing the scientific and machine learning applications of genetic algorithms instead of applications to optimization and engineering, the book could serve well in an actual course on adaptive algorithms. The author includes excellent problem sets at the end of each chapter, these being divided up into \\"thought exercises\\" and \\"computer exercises\\", and in the latter she includes some challenge problems for the ambitious reader.<br /> Chapter 1 is an overview of the main properties of genetic algorithms, along with a brief discussion of their history. The role of fitness landscapes and fitness functions is clearly outlined, and the author defines genetic algorithms as methods for searching fitness landscapes for highly fit strings. An elementary example of a genetic algorithm is given, and the author compares genetic algorithms with more traditional search methods. The author emphasizes the unique features of genetic algorithms that distinguish them from other search algorithms, namely the roles of parallel population-based search with stochastic selection of individuals, and crossover and mutation. A list of applications is given, and two explicit examples of applications are given that deal with the Prisoner's Dilemna and sorting networks. The author also gives a brief discussion as to how genetic algorithms work from a more mathematical standpoint, emphasizing the role of Holland schemas. The reader more prepared in mathematics can consult the references for more in-depth discussion.<br /> The next chapter stresses the role of genetic algorithms in problem solving, beginning with a discussion of genetic programming. Automatic programming has long been a goal of computer scientists, and the author discusses the role of genetic programming in this area, particularly the work of John Koza on evolving LISP programs. In addition, she discusses the current work on evolving cellular automata and its role in automatic programming. The latter discussion is more detailed, this resulting from the author's personal involvement in artificial life research. Those interested in time series prediction tools will appreciate the discussion on the use of genetic algorithms to predict the behavior of dynamical systems, with an example given on predicting the behavior of the (chaotic) Mackey-Glass dynamical system. The author also gives applications of genetic algorithms in predicting protein structure, an area of application that has exploded in recent years, due to the importance of the proteome projects. The area of neural networks has also been influenced by genetic algorithms, and the author discusses how they have replaced the familiar back-propagation algorithm as a method to find the optimal weights.<br /> Chapter 3 is more in line with what the author intended in the book, namely a discussion of the relevance of genetic algorithms to study the mechanisms behind natural selection. She discusses the \\"Baldwin effect\\", which gives a connection between what an organism has learned (a small time-scale process) to the evolutionary history of the Earth (a long time-scale process). A simple model of the Baldwin effect is given using a genetic algorithm, along with a discussion of the Ackley-Littman evolutionary reinforcement learning model, which involves the use of neural networks, and which is another computational demonstration of the Baldwin effect. In addition, the author discusses models for sexual selection and ecosystems based on genetic algorithms. These are the \\"artificial life\\" models that the author has been involved in, and she gives a very understandable overview of their properties.<br /> Chapter 4 should suit the curiosity of the mathematician or computer scientist who wants to understand the theoretical justification behind the use of genetic algorithms. Again employing the Holland notion of schemas and adaptation as a \\"tension between exploration and exploitation\\", the author formulates a mathematical model, called the Two-Armed Bandit Problem, of how genetic algorithms are used to study the tradeoffs in this tension. The level of mathematics used here is very elementary with the emphasis placed on the intuition behind this model, with only a sketch of the model's solution given. To address the role of crossover in genetic algorithms, the author discusses in detail a class of fitness landscapes, called \\"Royal Road functions\\" that she and others have developed. The performance of the genetic algorithm employed is then compared against the three different hill-climbing methods. Formal mathematical models of genetic algorithms are also discussed, one of which involves dynamical systems, another using Markov chains,  and one using the tools of statistical mechanics. The latter is very interesting from a physics standpoint but is only briefly sketched. The interested physicist reader can consult the references given by the author for further details.<br /> Practical use of genetic algorithms demands an understanding of how to implement them, and the author does so in the last chapter of the book. She outlines some ideas on just when genetic algorithms should be used, and this is useful since a newcomer to the field may be tempted to view a genetic algorithm as merely a fancy Monte Carlo simulation. The most difficult part of using a genetic algorithm is how to encode the population, and the author discusses various ways to do this. She also details various \\"exotic\\" approaches to improving the performance of genetic algorithms, such as the \\"messy\\" genetic algorithms. One must also choose a selection method when employing genetic algorithms, and the author shows how to do this using various techniques, such as roulette wheel and stochastic universal sampling. In addition, genetic operators must also be chosen in implementing genetic algorithms, and the author emphasizes crossover and mutation for this purpose. Lastly, the values of the parameters of the genetic algorithm, such as population size, crossover rate, and mutation rate must be chosen. The author discusses various approaches to this. Although brief, she does give a large set of references for further reading.<br /> Chapter 4 should suit the curiosity of the mathematician or computer scientist who wants to understand the theoretical justification behind the use of genetic algorithms. Again employing the Holland notion of schemas and adaptation as a \\"tension between exploration and exploitation\\", the author formulates a mathematical model, called the Two-Armed Bandit Problem, of how genetic algorithms are used to study the tradeoffs in this tension. The level of mathematics used here is very elementary with the emphasis placed on the intuition behind this model, with only a sketch of the model's solution given. To address the role of crossover in genetic algorithms, the author discusses in detail a class of fitness landscapes, called \\"Royal Road functions\\" that she and others have developed. The performance of the genetic algorithm employed is then compared against the three different hill-climbing methods. Formal mathematical models of genetic algorithms are also discussed, one of which involves dynamical systems, another using Markov chains,  and one using the tools of statistical mechanics. The latter is very interesting from a physics standpoint but is only briefly sketched. The interested physicist reader can consult the references given by the author for further details. <br /> Practical use of genetic algorithms demands an understanding of how to implement them, and the author does so in the last chapter of the book. She outlines some ideas on just when genetic algorithms should be used, and this is useful since a newcomer to the field may be tempted to view a genetic algorithm as merely a fancy Monte Carlo simulation. The most difficult part of using a genetic algorithm is how to encode the population, and the author discusses various ways to do this. She also details various \\"exotic\\" approaches to improving the performance of genetic algorithms, such as the \\"messy\\" genetic algorithms. One must also choose a selection method when employing genetic algorithms, andthe author shows how to do this using various techniques, such as roulette wheel and stochastic universal sampling. In addition, genetic operators must also be chosen in implementing genetic algorithms, and the author emphasizes crossover and mutation for this purpose. Lastly, the values of the parameters of the genetic algorithm, such as population size, crossover rate, and mutation rate must be chosen. The author discusses various approaches to this. Although brief, she does give a large set of references for further reading.	2002-04-06
1591536:US	50702879	R1FWQLS080Q579	0696025566	774371739	Better Homes and Gardens Complete Guide to Gardening	Books	4	5	5	N	N	Very helpful and extremely detailed	This book is a very technical and detailed overview of gardening practices. All issues of interest to gardeners are addressed, and a thorough reading of the book will amply prepare the newcomer to  gardening. Seasoned gardeners can view the book as an excellent reference source.<br />Particularly well-written are: 1. The sections on landscaping and how to grade slopes for correct drainage. 2. How to provide proper drainage and air circulation when planting trees on a grade. 3. The discussion on lawn grass diseases and their control. 4. The very detailed overview of ground covers, shrubs, vines, and trees. 5. The proper method to prune trees and shrubs.6. A long listing of perennials and the proper methods for care. 7. The entire section on roses. Being a rose fanatic, I paid particular attention to the discussion. For winter care, the book recommmends covering at locations where temperatures fall below 20 degrees F. Some rose experts recommend against this, except for climbers. A brief discussion of rose pests and diseases is given. For rose lovers of the Midwest, who face severe humidity, not enough attention is paid to black spot. It would have been helpful to have specific recommendations on the best commercial applicant to use.<br />This is a fascinating time to be involved in horticulture with the advent of genetic engineering. Techniques from genetic engineering will allow more robust varieties of trees and plants, with resistance to many of the diseases and pests discussed in the book. Gardening will indeed become even more exciting in the 21st century......	2002-04-05
1595167:US	50702879	R1QRCMT2DK6KUQ	0824786432	741271572	An Introduction to Functional Analysis (Chapman & Hall/CRC Pure and Applied Mathematics)	Books	5	6	6	N	N	Highly original introduction to functional analysis	Functional analysis is now required background for anyone in mathematical physics and numerical analysis. In addition, the strategy of this field, namely of studying collections of objects to find out properties they  have in common, and that of studying spaces by the functions defined on them, is now pervasive in most areas of pure mathematics. The author gives an overview of both functional analysis and operator theory, and as such it is a useful book for students going into these fields, as well as those interested in mathematical physics or constructive quantum field theory.<br /> Part one of the book details standard material in topological vector spaces. These spaces are of course essential if one is to discuss vector operations as being continuous. Banach spaces, the bread-and-butter of functional analysis are defined here. Linear operators and linear functionals are defined, along with the notion of a dual space. Measure-theoretic examples are given for the later, but it is assumed that the reader has had exposure to dual spaces before reading this book.<br /> Part two, entitled &quot;Three Basic Principles&quot; is just that, a thorough discussion of the Hahn-Banach theorem, the Uniform-Boundedness Principle, and the Open Mapping and Closed Graph Theorems. Qualitatively speaking, the Hahn-Banach theorem gaurantees there are a lot of linear functionals available on a vector space. The author proves the theorem for the real case, and then for the complex case using a result due to Bohnenblust-Sobczyk. An interesting application of the theorem is given to the moment problem in probability theory. The chapter on the uniform-boundedness principle is highly original, employing some results on infinite matrices, and not requiring, interestingly, the assumption that the domain be complete. Schauder bases are employed in the chapter on the open mapping theorem, but the famous Per Enflo example of a separable reflexive Banach space that has no Schauder basis in not discussed, dissappointingly.<br /> Locally convex topological vector spaces are discussed in part 3. Those physicists working on formulations of quantum physics will appreciate the discussion on separation in this part. The Krein-Milman theorem and the continuity of linear operators with respect to weak topologies are proven. And, the author again is very original in his treatment of the Banach-Alaoglu theorem and a generalization of the Stone-Weierstrass theorem. Bornological spaces, which are not usually discussed in texts at this level, are given a detailed treatment.<br /> The constructions in part 3 are generalized in part 4 to deal with linear operators between topological vector spaces. The treatment gives the &quot;classical&quot; examples dealing with Volterra and Fredholm integral equations but is clearly &quot;soft&quot; in its approach, and contains, again, some concepts not usually included in introductory texts, such as infra-Ptak spaces. Those interested in applications will appreciate the discussion of Schwartz distributions. Compact operators, also of paramount importance in applications, are treated thoroughly.<br /> The last part of the book deals with the generalization of eigenvalue problems to infinite dimensions. Since operators on infinite-dimensional spaces can fail to have eigenvalues, more careful attention must be paid to definitions. This part introduces operators on Hilbert spaces and the all-important spectral theorem for normal operators is proven. In addition, the author gives an interesting alternative proof of Lomonosov's theorem that proves the existence of a non-trivial invariant subspace for any operator that commutes with a compact operator. The general invariant subspace problem is still open to this day. The reader is also introduced, albeit briefly, to the &quot;ultrasoft&quot; techniques of Banach algebras, the reading of which will amply prepare the reader for the next step in operator theory: the theory of C*- and W*-algebras.algebras.	2002-04-03
1598959:US	50702879	R34PS56466BQ0N	0671867806	794137195	Being and Nothingness	Books	5	69	78	N	N	Sartre: one of the last of the system builders....	One of the most influential books of 20th-century philosophy, Being and Nothingness, and others by Sartre, has probably been read by more beginning students of philosophy than any other. Sartre's approach to philosophy is eclectic, but he has unique solutions to some of the problems he is attempting to solve, particularly his treatment of the problem of how to handle the negation, a problem of great interest to Hegel, and carried over to a phenomenological setting by Sartre. His discussion of the &quot;experiencing&quot; of negation has to rank as one of the most interesting in contemporary philosophy. It is a topic also that Sartre apparently thought so important that he included it in the first chapter of the book. He does however prepare the reader for the analysis in an introduction to the book. Therein, he argues for the dissolving of the distinction between being and appearance, and to reject (in Nietzschean terms), &quot;the illusion of worlds-behind-the-scene&quot;. This discussion also shows Satre's training in the phenomenology of Husserl and Heidegger. The move away from the dualism of appearance and essence, and appearance and being has its consequences of course, and it is these consequences that Sartre expounds upon briliantly in the rest of the book. One of these, interestingly, is the existence of an infinite series. The dualism of being and appearance is replaced by Sartre with the new dualism of finite and infinite. The appearance is finite, but to be grasped as an appearance of that which appears, says Sartre, it requires the series of appearances as infinite.<br />In addition, Sartre also discusses his reasoning behind his rejection of the idealism of Berkeley. Having reduced reality to the phenomenon, namely that the phenomenon is at is appears, he discusses why the Berkeley move to equate being with appearance is not a tenable one, in spite of the simplicity of such a move. His discussion expands on the famous Husserlian axiom that consciousness is always directed toward something. But Sartre goes beyond Husserl, and this is because he feels he needs to answer those who state that the requirement of consciouusness does not imply that the requirement is satisfied. He takes Husserl's notion of intentionality, and asserts that consciousness of consciousness of something is equated with intentionality, but that the object is what he terms a &quot;revealed-revelation&quot;: it reveals itself as already existing when consciousness reveals it.<br />  It is very interesting that for students of philosophy, this book is one of the first large treatises they read on philosophy, interesting because the hyphenated definitions that Sartre employs throughout the book can be opaque at times. But Sartre was one of the last &quot;system-builders&quot; of philosophy, and also one of the few philosophers who permitted himself to propagate his philosophy into novels and short stories. One can disagree with his politics, his anti-Americanism, and his Marxism, but he was a brilliant thinker and novelist, and philosophy in the 21st century is definitely experiencing-his-absence......ss is always directed toward something. But Sartre goes beyond Husserl, and this is because he feels he needs to answer those who state that the requirement of consciouusness does not imply that the requirement is satisfied. He takes Husserl's notion of intentionality, and asserts that consciousness of consciousness of something is equated with intentionality, but that the object is what he terms a &quot;revealed-revelation&quot;: it reveals itself as already existing when consciousness reveals it. <br />   It is very interesting that for students of philosophy, this book is one of the first large treatises they read on philosophy, interesting because the hyphenated definitions that Sartre employs throughout the book can be opaque at times. But Sartre was one of the last &quot;system-builders&quot; of philosophy, and also one of the few philosophers who permitted himself to propagate his philosophy into novels and short stories. One can disagree with his politics, his anti-Americanism, and his Marxism, but he was a brilliant thinker and novelist, and philosophy in the 21st century is definitely experiencing-his-absence......	2002-03-31
1602625:US	50702879	R2WXPNH78DC7UY	0802113974	669431314	The Mansion on Turtle Creek Cookbook	Books	5	9	11	N	N	Culinary artistry from Dallas	For those who have dined at the Mansion on Turtle Creek in Dallas, or for anyone who is deeply involved in the craft of gourmet cooking, this book is culinary heaven. The photographs of some of the dishes in the book are indeed fine art, and they entice the reader to make permanent residence in the kitchen studio, with spatula-paintbrush in hand, and mimic or alter at will the recipes in the book. Having cooked all the main dishes in the book, with varying degress of success, I can vouch for the idea that one must depart frequently from strict adherence to the recipes. Definitely try the creme brulee, but use a cooking torch instead of broiling. Can't find quail? Use Cornish hens instead of course.	2002-03-28
1604125:US	50702879	R1CJOGGYVF749O	1566198720	17170433	History of Art	Books	4	3	5	N	N	Needs more...but then gravity might prohibit its reading	There are three ways of viewing art; namely, the way it has been, the way it could be, and the way it should be. This book of course follows the first, with the other two being delegated to art techniques and the philosophy of aesthetics. It is very difficult to say whether one can gain insight into a culture via the artistic relics that have been left over from it, but a rational and organized discussion of how humans have expressed themselves in the past can only inspire a deeper appreciation of art. That being said, an author must be careful in the decision as to what goes into a book on art history. Subjective preferences can seduce an author into including artworks that are representative only of the author's view, or, possibly even worse, the views of the majority of the people in the era that is studied. A work of art need not be popular before it is classified as art, but frequently it is the popular works that are chosen to be included in a work on art history. Art is a continuous source of surprise, it beckons the viewers to consider alternatives, and to formulate, sometimes with concentration and at other times with reckless abandonment, an estimate of themselves. A book on the history of art should be no different than the art which it delineates: it should also be original, and give readers a slight push off balance, get them out of equilibrium, and entice them to reconsider their preconceptions.<br /> This book does not do this, and instead focuses its attention on the artwork that would be classified as popular or familiar. It does however give an academic and very comprehensive view of the history of art from a culturally global point of view. It is democratic in its selection of geographies and the cultures in which the art originated. For that reason it could be read profitably by someone interested in the facts of art, with the goal perhaps of finding out the values and motivations of the culture in which the art was produced. Not much time is spent on the methodologies and reasons for the art taking the form that it did in past cultures. It would have been interesting to encounter more discussion on the mediums chosen by the artists, and why they chose these particular mediums, with more detailed discussion maybe of the connection of these mediums with the available technology of the time. Or, maybe more discussion on the connection of the art with the particular philosophies of the culture.<br /> Popular or not, the art pieces chosen in the book are still fascinating to look at. They are a delightful mixture of the symmetrical and the chaotic, the familiar and the fantastical, and they reinforce the belief that to live life, one must also draw it, paint it, and sculpt it.....ent on the methodologies and reasons for the art taking the form that it did in past cultures. It would have been interesting to encounter more discussion on the mediums chosen by the artists, and why they chose these particular mediums, with more detailed discussion maybe of the connection of these mediums with the available technology of the time. Or, maybe more discussion on the connection of the art with the particular philosophies of the culture. <br /> Popular or not, the art pieces chosen in the book are still fascinating to look at. They are a delightful mixture of the symmetrical and the chaotic, the familiar and the fantastical, and they reinforce the belief that to live life, one must also draw it, paint it, and sculpt it.....	2002-03-27
1605238:US	50702879	R37WA5TZEYSBE5	0262193787	334013551	HAL's Legacy: 2001's Computer as Dream and Reality	Books	5	11	11	N	Y	Gradually, HAL is coming....	There are few films that have had the influence of Kubrick's 2001: A Space Odyssey. It is difficult to say how many A.I. researchers were inspired to go into the field by the viewing of the film, but this book is good evidence that research in A.I. has undergone a sort of &quot;public benchmarking&quot; via a comparison with HAL, the arch computer-villan in the movie, and whose name is now ubiquitous in debates on robotics and artificial intelligence. This excellent book is a summary of just how far A.I. has come, as compared to the abilities of HAL.  All of the authors acknowledge that the present level of A.I. is not what it is in HAL, but that progress is being made, in spite of, as one author remarked, the fact that A.I. is one of the most profoundly difficult problems in science.<br /> Marvin Minsky is interviewed in the book, and he  believes it is the problem of knowledge representation that has slowed down the progress in A.I. Too much time has been spent on chess programs and character recognition, and not on fundamentals, Minsky argues. Minsky also believes that emotions are absolutely essential in intelligent problem solving, and this is interesting in light of recent work on computational models of emotion.<br /> The large physical size of HAL is compared with present sizes of computers in the article of David Kuck. But, the author argues, the human brain is also much smaller than HAL, but such a marvelous computing machine has yet to be emulated by even the best of present-day supercomputers. Size does not matter in matters of intelligence.<br /> The article on error correction by R. Iyer is particularly insightful, for he argues, quite correctly, that making mistakes is a characteristic of true intelligence. HAL's brag that it is &quot;incapable of error&quot; is a sign of stupidity, rather than intelligence. False leads, uncompleted strategies and goals, and inconsistent reasoning are all part of genuine problem-solving.<br /> M.S. Campbell discusses the efforts in machine chess, with Deep Blue of course being the focal point. Comparisons of how HAL plays chess compared to Deep Blue illustrate Campbell's belief that a mere combinatorial approach to playing chess should not be considered an intelligent one. HAL is intelligent because it plays intelligence like a human does, but Deep Blue does not. Campbell also gives an interesting historical summary of computer chess. He cites that example of a &quot;fortress&quot; position as one that chess computers have severe difficulty with.<br /> The ability of computers to speak, and not sound &quot;machine-like&quot; is the subject of the article by J.P. Olive. His discussion  gives the reader both an historical and technical overview of the difficulties involved in computer speech. And yes, the song &quot;Daisy, Daisy&quot; is real, and was the first song ever sung by a computer.<br /> R. Kurzweil gives an optimistic overview of computer speech recognition. He details the &quot;lessons&quot; one needs to perform speech recognition and repeats his well-known desire to &quot;reverse-engineer&quot; the human brain, once the computational ability becomes available.<br /> R.C. Schank discusses why he thinks A.I. must be able to understand more than just words, if natural language processing is to become a reality. And, interestingly, he believes that intelligence and problem solving are not necessarily the same thing and gives the reader insight into the difficulties involved in language acquisition by a computer.<br /> This book was first printed in 1997, but given the recent news of a common sense reasoning computer developed by the company that D.B. Lenat heads, his article is particularly interesting. The ability of computers to exercise common sense is considered a fundamental requirement for machine intelligence, and Lenat outlines &quot;3 easy steps&quot; for the building of a HAL-like computer. It remains to be seen whether Lenat has indeed achieved this.<br /> The ability of HAL to recognize images is discussed in the article by A. Rosenfeld. In light of the recent need for face recognition software for security enhancement, this discussion is particularly interesting. Rosenfeld details just what is difficult and what is easy to do in this area.<br /> The capability of a computer to perform speechreading is the topic of D.Stork's article. Noting that speech has both auditory and visual aspects, Stork argues that HAL's ability to perform speechreading is far advanced in comparison to the real computers of today. He discusses interestingly, some of the tools used in current research on speechreading, such as hidden Markov models and neural networks.<br /> The article of D. Norman addresses the human factors involved in living with intelligent machines. Norman contends that 2001 is too optimistic a projection of the future, and, in addition, that its technology is too large and bulky to be of much use to humans.<br /> Computational models of emotion have been a subject of intense interest of late, and R. Picard addresses the issue of emotion and computers in his article. The discussion is fascinating, and Picard clearly believes that emotional states can be recoginized and mimicked by a computer. &quot;Emotional&quot; intelligence is something that must be part of any notion of artificial intelligence.<br /> The ability of HAL to manipulate circumstances and trick the crew members is addressed in D.Wilkin's article. The ability to plan is based on common sense issues,  and this is no where near being realized, he argues.<br /> D.Stork interviews Stephen Wolfram in another article, and the reader learns of Wolfram's opinions on A.I. and related issues. Wolfram believes that its the nature of intelligence that must be understood to develop thinking machines, and not just processing power.<br /> When thinking machines are built, legal issues of responsibility will naturally arise. D. Dennett addresses this in the last article of the book. Dennet puts HALs behavior in the context of what a human might do when faced with the mission priorities given to him. Turning off HAL was justified, but so was HALs response to it./> The ability of HAL to recognize images is discussed in the article by A. Rosenfeld. In light of the recent need for face recognition software for security enhancement, this discussion is particularly interesting. Rosenfeld details just what is difficult and what is easy to do in this area. <br /> The capability of a computer to perform speechreading is the topic of D.Stork's article. Noting that speech has both auditory and visual aspects, Stork argues that HAL's ability to perform speechreading is far advanced in comparison to the real computers of today. He discusses interestingly, some of the tools used in current research on speechreading, such as hidden Markov models and neural networks. <br /> The article of D. Norman addresses the human factors involved in living with intelligent machines. Norman contends that 2001 is too optimistic a projection of the future, and, in addition, that its technology is too large and bulky to be of much use to humans. <br /> Computational models of emotion have been a subject of intense interest of late, and R. Picard addresses the issue of emotion and computers in his article. The discussion is fascinating, and Picard clearly believes that emotional states can be recoginized and mimicked by a computer. &quot;Emotional&quot; intelligence is something that must be part of any notion of artificial intelligence. <br /> The ability of HAL to manipulate circumstances and trick the crew members is addressed in D.Wilkin's article. The ability to plan is based on common sense issues,  and this is no where near being realized, he argues. <br /> D.Stork interviews Stephen Wolfram in another article, and the reader learns of Wolfram's opinions on A.I. and related issues. Wolfram believes that its the nature of intelligence that must be understood to develop thinking machines, and not just processing power. <br /> When thinking machines are built, legal issues of responsibility will naturally arise. D. Dennett addresses this in the lastarticle of the book. Dennet puts HALs behavior in the context of what a human might do when faced with the mission priorities given to him. Turning off HAL was justified, but so was HALs response to it.	2002-03-26
1608000:US	50702879	R7XBDJXYZ12V6	1883463483	633847947	Green Iguana: The Ultimate Owner's Manual	Books	3	5	6	N	Y	Fairly good job	Given the size of this book, one would have expected a comprehensive overview of the biology of green igauanas along with their care as pets. But the book is too anecdotal in its content, and so important topics are treated in a cursory fashion, especially the discussion on diseases and ailments of green igaunas. I have lost two iganuas because of black spot, but the author does not give a useful discussion of the origins and cures for black spot. The book is not without its virtues though, and some of the more interesting discussions include: 1. The scientific classification for iguanas. 2. How to differentiate betweeen the sexes. 3. The ability of iguanas to detect ultraviolet light. 4. An explanation os to why iguanas close their eye when an object is brought close to it. 5. The existence of a parietal eyes on iguanas, a fact that took me completely by surprise. The functioning of this eye is apparantly to act as a sensor for sunlight, enabling the iguana to move to the shade and avoid overheating. 6. The internal anatomy of iguanas. 7. The existence of a Jacobson's organ. 8. The importance of heat for adequate digestion. 9. The entire chapter on the feeding of iguanas. 10. The presence of salmonella in iguana feces. This has been reported in the press as a concern for iguana owners, particularly pregnant women. 11. The plans for the construction of an iguana habitat.<br />  With more in-depth discussion on important topics, and with the omission of anecdotal insertions, this book would become the bible of iguana care and biology. The author is quite correct when he asserts that iguanas are difficult to take care of. That is why he needs to spend more time on treating the topics in more depth.	2002-03-24
1608007:US	50702879	R1W82JISFJY39H	0451517938	691474875	The Red and the Black (Signet classics)	Books	5	3	4	N	N	One of the best novels for its time	Was Julien Sorel an ambitious, unprincipaled rogue? A womanizing playboy with no direction? A victum of circumstances and only acting according to the constraints he found himself in? Purely naive and innocent, and mamipulated by the women he encountered? Any of these interpretations (and many more) would be valid of the character of Julian Sorel, and readers of this novel will no doubt find their own unique views of a character that is quite complex from the standpoint of 19th century literature.<br /><br />  As an author, Stendahl, like other authors, lived his fantasies of life through his characters, and giving of course the same opportunity to his readers. Literature allows both author and reader to participate in an adventure of their own making. The author's adventure may not equal the reader's, luckily. The possible separation between the author's intent and the reader's reaction speaks well of the beauty and power of literature. Reader's need only concern themselves with the author's purposes if they choose, for historical appreciation, or some other reasons. One cannot, and should not, consult Stendahl for his interpretation; this is the reader's privelege and right, and such a wide dispersion of interpretations among the readers is the best evidence of success in Stendahl's work, a success he evidently craved for during his short life, and possibly taking a form that he could not imagine.<br /><br />  Julien was beheaded at the end of the book, but this was merely a physical decapitation. He lost his head, his mind, long before this, when he chose a path in life of manipulation and social climbing. Such behavior he deemed practical, given the circumstances that he found himself in. But Julian was too quick to act and too cynical in his estimation of history. He concluded that the society in which he was immersed was corrupt, and therefore that the optimal strategy was to corrupt himself. Not confident in the efficacy of his own mind, and therefore not giving consideration to any other strategy other than the one he chose, it is not surprising that he met the end which he did, this occurring, again, not at the end of the book, but at the beginning.....ation to any other strategy other than the one he chose, it is not surprising that he met the end which he did, this occurring, again, not at the end of the book, but at the beginning.....	2002-03-24
1614173:US	50702879	R17SQYCQR03I04	0716750449	894904913	Life Processes of Plants (Scientific American Library)	Books	5	13	14	N	N	Excellent	The reader will find in this book an excellent overview of the biophysical and metabolic processes that occur in plants, and, refreshingly, the author seems very much involved in his writing. He is clearly fascinated by the biology of plants, and this enthusiasm comes out in the book. The reader is exposed to a lot in this book, and takes away an appreciation of just what plants are capable of from a physical and biochemical standpoint. In addition, the author does not hesitate to interject discussions of the genetic engineering of plants in the book, making its reading even more interesting. It is written for the &quot;popular audience&quot;, but anyone with an interest in plants, students or amateur horticulturists, should enjoy the book.<br /> Some of the more interesting discussions in the book include: 1. The rising of the carbon dioxide content of the Earth's atmosphere, particularly since the beginning of the industrial revolution, and the need therefore to retain as much as possible the forests on the planet. 2. The 2/5 phyllotaxic leaf arrangement of the tobacco plant, the goal of which is to optimize the amount of light falling on the leaves. The author throughout the book emphasizes the clever evolutionary strategies of plants. 3. The Priestley experiment showing the opposite effects of animals and plants on enclosed atmospheres. 4. The use of electron-spin-resonance spectroscopy to decipher the sequence of events in photosynthesis. 5. The efficiency of photosynthesis in the creation of a molecule of oxygen: eight photons to release one oxygen molecule, a doubling of the number needed from the theoretical value. 6. The ability of chloroplasts to change their orientation to obtain maximum exposure to light. 7. The overwintering strategies of plants. 8. The ability of the cocklebur to flower if the photoperiod is less than 15.5 hours per day, but not if it exceeds that value by more than a few minutes. 9. The absorption spectra of phytochrome. 10. The measurement of the circadian rhythms. 11. The use of transgenic plants to study the control mechanisms of phytochrome. 12. Growth hormones in plants, particularly the discussion of gibberellins. 13. The phototropism of plants. 14. The mechanism by which plants form chemical toxins in response to injury. 15. The production of ethylene after damage to the plant, activating cell division. 16. The reaction of plants to excessive salinity of the soil. This discussion is very important in the context of recent attempts to develop salt-resistant tomatoes. 17. The ability of a single protoplast to produce an entire plant. 18. Recombinant DNA technology and the production of transgenic plants. This discussion is by far the most fascinating in the book. The recent developments in the genetic engineering of plants has to rank as the most interesting in all of scientific endeavor. 19. The ethical considerations involved in modern biotechnology.<br /> In the last sentence of the book the author states that &quot;Plant science has matured, and the age of innocence is over&quot;. Indeed his words are a modest reflection of the importance of botany in the world today. Botanists, through the use of genetic engineering, have made incredible discoveries in the last two decades, and will no doubt make many more in years to come, especially in the agricultural sector. But horticulturists, professional and otherwise, also have many things to look forward to in botanical research. As a lover of plants and as an owner of hundreds in my home, I look forward to the new varieties of plants that will be developed in the future using the techniques of genetic engineering.....urement of the circadian rhythms. 11. The use of transgenic plants to study the control mechanisms of phytochrome. 12. Growth hormones in plants, particularly the discussion of gibberellins. 13. The phototropism of plants. 14. The mechanism by which plants form chemical toxins in response to injury. 15. The production of ethylene after damage to the plant, activating cell division. 16. The reaction of plants to excessive salinity of the soil. This discussion is very important in the context of recent attempts to develop salt-resistant tomatoes. 17. The ability of a single protoplast to produce an entire plant. 18. Recombinant DNA technology and the production of transgenic plants. This discussion is by far the most fascinating in the book. The recent developments in the genetic engineering of plants has to rank as the most interesting in all of scientific endeavor. 19. The ethical considerations involved in modern biotechnology. <br /> In the last sentence of the book the author states that &quot;Plant science has matured, and the age of innocence is over&quot;. Indeed his words are a modest reflection of the importance of botany in the world today. Botanists, through the use of genetic engineering, have made incredible discoveries in the last two decades, and will no doubt make many more in years to come, especially in the agricultural sector. But horticulturists, professional and otherwise, also have many things to look forward to in botanical research. As a lover of plants and as an owner of hundreds in my home, I look forward to the new varieties of plants that will be developed in the future using the techniques of genetic engineering.....	2002-03-19
1614627:US	50702879	RP28U3L7FOUFT	0394556437	625332625	Martha: The Life and Work of Martha Graham- A Biography	Books	5	6	7	N	N	Brilliant overview of a dance genius	It is unfortunate that this book is out of print, for it gives a  overview of one of the most brilliant choreographers of the twentieth century. The mind and values of Martha Graham are exposed in detail by the author, and it serves its purpose in giving the curious reader insight into the life and dance technique of a woman who single-handedly developed one of the most original forms of movement to this date. Anyone who is overcome by watching the dances of Graham will definitely appreciate this book, written by a person who had known Graham for fifty-eight years. Included in the book are an excellent collection of black-and-white photographs, both of Graham and some of the people she worked closely with. Indeed, Graham was a beautiful woman, and her personality, as well as her physical beauty, are exemplified nicely in these photographs.<br /> The knowledge one can gain from the reading of this book makes it well worth the time, for by reading it one can understand how Graham developed her technique, interestingly without any government aid; there was no National Endowment of the Arts to assist in her endeavors. Graham viewed dance as a celebration, and eschewed the attitude of those who danced for monetary gain. One  reads of Graham's relationship with Louis Horst, and of the popularity of the writings of the philosopher Frederich Nietzsche among Horst, Graham, Doris Humphrey, and Isadora Duncan.<br /> Graham's father told her that &quot;bodies never lie&quot;, and this statment apparently had a major influence on her resulting &quot;philosophy of dance&quot;, as well as the influence of Ruth St. Denis and Erick Hawkins. The author discusses the differences between the dance technique of Graham and Humphrey, the latter being characterized as mathematical by the author, the former emotional. But I find the Graham technique straightforward to view from a mathematical standpoint, if one is so inclined.<br /> The technical aspects of the Graham technique are brought out nicely in the book, one example being the marvelous description of the &quot;spiral fall&quot; and its recovery. One also learns of the use of &quot;plastiques&quot;, i.e, the posing and moving in scarves and costumes by the dancers. Also, it is interesting to learn of the omission of mirrors in the early Graham studios; lest the student, in the author's words, &quot;drown in his own image&quot;. The class routine for the Graham dancers, particularly the floor exerices, along with the spasm of the the diaphragm, are the most well-known manifestation of the Graham technique, and are discussed nicely in this book.<br /> It is fortunate that Graham was able to find such dedicated students for her classes. Forcing to live a frugal existence, these students found her dances a &quot;religion that they served&quot;, according to the author. Indeed, if one has ever viewed modern dance performances of the Graham technique, one can see this attitude in the dancers, as though they were priveleged, and moving to a unique traceform in space never before executed.<br /> The Graham technique is brilliant, and it forces one to rethink preconceived notions of what movement must be, and instead speculate on what it could be. Graham in her works made it readily apparent that gravity is real, but that it need not be a total master. Even on the floor the Graham dancers are in control, at least momentarily, interpolating brilliantly between order and bodily dissonance. Martha Graham, as protrayed by the author, was an innovator and a determined individualist, and has given us a unique collection of traceforms, both in our memories and in books and videos, that will embolden us and refresh us always.....ht out nicely in the book, one example being the marvelous description of the &quot;spiral fall&quot; and its recovery. One also learns of the use of &quot;plastiques&quot;, i.e, the posing and moving in scarves and costumes by the dancers. Also, it is interesting to learn of the omission of mirrors in the early Graham studios; lest the student, in the author's words, &quot;drown in his own image&quot;. The class routine for the Graham dancers, particularly the floor exerices, along with the spasm of the the diaphragm, are the most well-known manifestation of the Graham technique, and are discussed nicely in this book. <br /> It is fortunate that Graham was able to find such dedicated students for her classes. Forcing to live a frugal existence, these students found her dances a &quot;religion that they served&quot;, according to the author. Indeed, if one has ever viewed modern dance performances of the Graham technique, one can see this attitude in the dancers, as though they were priveleged, and moving to a unique traceform in space never before executed. <br /> The Graham technique is brilliant, and it forces one to rethink preconceived notions of what movement must be, and instead speculate on what it could be. Graham in her works made it readily apparent that gravity is real, but that it need not be a total master. Even on the floor the Graham dancers are in control, at least momentarily, interpolating brilliantly between order and bodily dissonance. Martha Graham, as protrayed by the author, was an innovator and a determined individualist, and has given us a unique collection of traceforms, both in our memories and in books and videos, that will embolden us and refresh us always.....	2002-03-18
1614763:US	50702879	R2E2VF5Q39J2K9	0716710889	272227989	Thermal Physics (2nd Edition)	Books	5	26	34	N	N	Beautiful job	After so many years in print, and being used by so many students, this book has become a classic in undergraduate statistical mechanics. It is indeed a fine book, and one that will no doubt remain as a standard text in statistical mechanics in years to come. The authors motivate the subject well, and they at all times explain the physics behind the mathematics. So often in textbooks, even at the undergraduate level, the physical intuition gets lost behind the mathematical formalism. Although the book is addressed to an audience of undergraduate physics majors, it could be read profitably by those in other fields, particularly in the biological sciences.<br /><br /> Some of the parts I found particularly well-writtten include the discussions on: 1. The sharpness of the multiplicity function and its connection with the stability of physical properties. 2. The zipper problem as a model of the unwinding of the DNA molecule ( an assigned problem). 3. The ascent of sap in trees (an assigned problem). 4. Bose-Einstein distribution function and the Einstein condensation temperature. Given the exciting developments in this area, this discussion is particularly enlightening. 5. Quasiparticles and superfluidity. This is a nice job here, given the level of the text. 6. The Landau theory of phase transitions. 7. Semiconductor statistics. 8. The Boltzmann transport equation. Because of its immense importance, it is great that the authors have chosen to include a discussion of this in a book at this level. The treatment is very understandable and prepares the reader for more advanced reading on the subject. 9. The heat conduction equation. The diffusive solutions of the equation are discussed in terms of the time development of a temperature pulse, giving the reader a first glimpse of the &quot;Green's function&quot; methods.	2002-03-18
1615748:US	50702879	R2QOSL0GG560ET	0785214275	580137710	Josephus Complete Works	Books	4	13	13	N	N	Captivating reading	Anyone interested in the modern view of the Jewish faith and the Jewish people must start in the past, and this book is the canonical reference. In addition, anyone who is interested in Biblical history and apologetics will be interested in the reading of this book, as well as those involved in the study of the ancient Greek language. The translator includes passages in original Greek for these readers, and as one who was learning ancient Greek at the time I read it, it was helpful to have these included in the book. It would take an established expert however to judge whether the translation of Whiston, who lived in the time of Isaac Newton, is in any sense an adequate one.<br /> One also learns briefly of the life of Josephus, and gains an insight as to why Josephus chose to write this lengthy history of the Jewish people. What is most interesting about the reading of Josephus is his reliance on Jewish scriptures for delineating the history of the Jewish people before his time. He departs from this however when discussing the events of his own time. In addition, the reader obtains a discussion of the famous passages in Josephus on the historical authenticity of John the Baptist and Jesus Christ, these being questioned by some scholars of Josephus.	2002-03-18
1617376:US	50702879	R11ZATWBWURXIU	0471353868	852900406	Relativistic Quantum Mechanics and Field Theory	Books	4	17	17	N	N	Bread-and-butter introduction to quantum field theory	This book is a fine one, and it emphasizes the practical aspects of quantum field theory rather than the abstract formalism. The author has written a book that would be of use to the graduate student in physics who is intending to specialize in quantum field theory or experimental particle physics. <br /> The book is divided into four parts. The author begins in part one with an overview of the quantization of the vibrating string via canonical quantization. This method involves finding the normal modes of the string, and then replacing the canonical variables with operators that satisfy particular non-commutation relations. The resulting structure is interpreted as a phonon field (in the particle picture). The author gives an interesting and detailed discussion of field-particle duality by taking the classical limit, and one can see clearly the origin of the famous coherent states. <br /> Part one is also an introduction to quantum electrodynamics. The author discusses the quantization of the electromagnetic field as a quantization problem with constraints, the latter being gauge and Lorentz invariance. The conflict between these two requirements is illustrated by the choice of different gauges, such as the Coulomb gauge (which is not manifestly covariant). The interaction picture also makes its appearance, wherein the S-matrix is derived, and the Lamb shift is calculated and compared with experiment. The famous mass renormalization problem is discussed, and the cross section for deuteron photodisintegration is calculated. This calculation is interesting in that detailed knowledge of the strong interaction is not necessary to obtain the correct answer. <br />Part two of the book is an overview, with historical emphasis, of the Klein-Gordon and Dirac equations. The reader can see the origin here of the concept of a quantum field, but a full understanding of these fields is not yet available in modern physics, particularly in the utility of these fields in predictingbound states. The Klein-Gordon equation is interpreted as a description of a charged particle, with its norm the charge density, and a solution of the Klein-Gordon equation equation is given, involving pair creation from a high Coulomb barrier. This example is interesting in that it predicts negative energy states in the context of the Klein-Gordon equation, and is not done in any other textbooks in quantum field theory. The non-relativistic limits of both of these equations is discussed, and applications given, such as the Zeeman effect. The author also shows that the homogeneous Lorentz group is not simply-connected, and proves the covariance of the Dirac equation by constructing a representation of the Lorentz group on (four-dimensional) Dirac space, i.e. the space of spinors. The author also gives an introduction to hadron physics, via the MIT bag model. All of these discussions are interesting but they leave the reader wanting for an explanation of how bound states can form in a fully relativistic quantum field theory. <br />In part three, the author delves more deeply into the theoretical aspects of quantum field theory, and proves the famous PCT theorem. Such a discussion will prepare the reader for an understanding of the current theories regarding mirror matter. Interactions in quantum field theory are introduced via the phi-3 field theory, and the reader gets a first taste of the famous Feynman rules. One topic noticeably missing in this part is that of effective field theories. This is a topic of enormous importance in current formulations of quantum field theories and their connection with other theories of fundamental interactions, such as string theories. Such a discussion would be appropriate in this part, particularly in the sections on pion-nucleon interactions. An entire chapter is spent on renormalization, wherein Wick's theorem is proved. A mathematically-astute reader will find the idea of renormalization troubling from a mathematical point ofview, but a more rigorous foundation for renormalization does currently exist in the literature. The problem of bound states in quantum field theory is dealt with in this part by the partial summing of particular Feynman diagrams, the so-called ladder and crossed ladder sums of Feynman diagrams. This leads to the famous Bethe-Salpeter equation and the author's &quot;spectator&quot; equation. The author shows the equivalence of these approaches in dealing with the (two-body) bound state problem. In addition, he also introduces briefly the Blackenbecler-Sugar equation as another relativistic two-body equation, but does not compare this equation to the other approaches at all. The Schwinger-Dyson equations would be the natural thing to discuss in this part, and how one might derive the relativistic two-body equations from them, but the author does not do so, unfortunately. <br />The last part is on overview of quantum gauge theories. Gauge symmetry is introduced as a &quot;dynamical&quot; symmetry, which, the author argues is strong enough to be able to determine the structure of the Lagrangian of the theory. This strategy is one of the most pervasive in all modern attempts at building unified theories of particle interactions. He also does give an introduction to chiral symmetry, in the context of the strong interaction. The discussion of chirality is unfortunately the only example of an effective field theory in the book. The method of functional integration is introduced to deal with the quantization of gauge theories, and the reader can see the origin of the famous Faddeev-Popov ghosts. The electroweak model, the most successful of the Non-abelian gauge theories to this date, is also discussed in fair detail. Examples of the calculation of cross sections for the intermediate vector bosons are not included though, surprisingly. The book ends with a fairly detailed discussion of the renormalization group and asymptotic freedom. The later property of the gauge theoryof the strong interaction is definitely a confidence builder in one's belief that gauge theories contain a hint of the correct physics for the strong interaction.	2002-03-16
1617735:US	50702879	R1NUMVGDNGG6M1	0070037345	583186895	Classical Mechanics: A Modern Perspective, 2nd Edition	Books	4	23	27	N	N	Short but has some interesting examples	This book, although short, is a fairly good overview of classical mechanics, which emphasizes more recent developments in the theory, such as chaotic dynamical systems. The authors do however remain concrete in their treatment, with real-world examples permeating the text. The details behind the theory of classical mechanics are presented very quickly in the book, and this might make the book difficult to read for students first exposed to mechanics at this level.<br /> Chapter one is an introduction to motion in one dimension. After a brief review of Newton's laws, the authors solve some neat problems  dealing with damping forces, one being the frictional force on a drag racer, and the other with aerodynamic drag on a parachute. They also treat the undamped and damped harmonic oscillator, and the discussion is very standard. The authors are careful to point out that some force laws are too complicated to be solved analytically, but that computing methods can be used to solve the cases that are not. Computational approaches are now the rule rather than the exception in problems in mechanics, and this trend will continue in the future.<br />  After a short discussion of energy conservation, the authors introduce motion in three dimensions and give a fairly detailed overview of vector notation. Their approach to tensors though is kind of antiquated, for it motivates them via the outer product, which is reminiscent of the dyadic approach that is currently &quot;out of fashion&quot;. The authors also discuss the simple pendulum, but do not of course introduce the elliptic curve solutions that accompany this problem. Such a treatment, however fascinating, would drive this book to a height that would make it inaccessible to the audience of students it addresses. Coupled harmonic oscillators are solved using the normal mode approach.<br /> Lagrangian mechanics is introduced in chapter 3, but not from the standpoint of variational calculus at first. Instead the authors choose to present this formulation via generalized forces. They include a discussion of constraints, and give as an example the simple pendulum with a moving support. Only later do they give the Lagrangian formulation via variational calculus, and do so rather hurriedly. Hamilton's equations are derived, and it is shown (again briefly) how Legendre transformations enter into the formalism of Hamiltonian mechanics.<br /> Conservation principles are then thought of as fundamental in the rest of the book, and the authors use momentum conservation to discuss elastic and inelastic collisions in chapter 4. Angular momentum conservation is then used in chapter 5 to discuss central forces and planetary motion. Kepler's laws are also discussed, and Rutherford scattering is discussed. All of the discussion is pretty standard and can be found in most textbooks on classical mechanics.<br /> Rigid body mechanics makes its appearance in chapter 6, wherein the authors discuss the rotational equations of motion of many-particle systems and rigid bodies. A very brief discussion of gyroscopic mechanics is given, but the authors make up for this by explaining the motion of boomerangs. The discussion is fun to read and should satisfy the curious reader as to why a boomerang returns. And, after a discussion of how to calculate the moment of inertia, the authors give a neat introduction to the physics of billiards and the superball. The latter is a popular physics demonstration and the authors show how its motion differs from an ordinary smooth ball.<br /> The difficult (and controversial) topic of accelerated coordinate systems is treated in chapter 7. The four famous &quot;fictitious&quot; forces are introduced, and to develop the reader's intution on these, the authors give a nice example dealing with the manufacture of telescope mirrors. The casting of the mirrors is a neat illustration of the famous Newtonian water pail experiment. The motion of the Foucault pendulum is also discussed briefly. Then after a discussion of principal axes and Euler's equations, the authors give another neat example, this time dealing with the motion of tennis rackets, which illustrates the motion of a rigid body with unequal principal moments of inertia. The physics of tops is then discussed, and in a manner which makes the underlying physics more intuitive for the reader. The authors make an attempt to understand the motion of the famous tippie-top, but don't really do so. The tippie-top is another popular demonstration in the classroom but its physics has eluded the best attempts, and this treatment is no exception. The flip times that are calculated are not in agreement at all with what is observed in the demonstration.<br /> Chapter 8 is an overview of gravitational physics, and the authors show the effects of a body moving in a non-uniform gravitational field, with an example dealing with the tides. Interestingly, the authors attempt to introduce the general theory of relativity, and do so more at a level of elementary mathematics and arm-waving arguments, but the treatment is suitable at this level.  The authors show the difference between the orbits predicted by general relativity and the Newtonian theory, i.e. the famous perihelion advance.<br /> A brief overview of Newtonian cosmology is given in chapter 9, wherein the authors discuss the expansion of the universe and the cosmic redshift. After proving the virial theorem, they discuss the effects of dark matter on the rotations of spiral galaxies and groups of galaxies, which is currently a very hot topic in astrophysics.<br /> The special theory of relativity is treated in chapter 10, and the discussion is very standard. Readers are introduced to relativistic mechanics and some of the counterintuitive physics of the theory.<br /> The last chapter of the book is an introduction to non-linear dynamics and chaos. It is defined as sensitive dependence on initial conditions, although this is not a strong enough condition. The Duffing oscillator is offered as an example of chaotic behavior and the transition to chaos is studied as a function of the driving frequency. This brings up concepts from bifurcation theory, such as the idea of a strange attractor. Numerical analysis plays the dominant role in these theories.sed briefly. Then after a discussion of principal axes and Euler's equations, the authors give another neat example, this time dealing with the motion of tennis rackets, which illustrates the motion of a rigid body with unequal principal moments of inertia. The physics of tops is then discussed, and in a manner which makes the underlying physics more intuitive for the reader. The authors make an attempt to understand the motion of the famous tippie-top, but don't really do so. The tippie-top is another popular demonstration in the classroom but its physics has eluded the best attempts, and this treatment is no exception. The flip times that are calculated are not in agreement at all with what is observed in the demonstration. <br /> Chapter 8 is an overview of gravitational physics, and the authors show the effects of a body moving in a non-uniform gravitational field, with an example dealing with the tides. Interestingly, the authors attempt to introduce the general theory of relativity, and do so more at a level of elementary mathematics and arm-waving arguments, but the treatment is suitable at this level.  The authors show the difference between the orbits predicted by general relativity and the Newtonian theory, i.e. the famous perihelion advance. <br /> A brief overview of Newtonian cosmology is given in chapter 9, wherein the authors discuss the expansion of the universe and the cosmic redshift. After proving the virial theorem, they discuss the effects of dark matter on the rotations of spiral galaxies and groups of galaxies, which is currently a very hot topic in astrophysics. <br /> The special theory of relativity is treated in chapter 10, and the discussion is very standard. Readers are introduced to relativistic mechanics and some of the counterintuitive physics of the theory. <br /> The last chapter of the book is an introduction to non-linear dynamics and chaos. It is defined as sensitive dependence on initial conditions, although this is not a strongenough condition. The Duffing oscillator is offered as an example of chaotic behavior and the transition to chaos is studied as a function of the driving frequency. This brings up concepts from bifurcation theory, such as the idea of a strange attractor. Numerical analysis plays the dominant role in these theories.	2002-03-16
1617769:US	50702879	R1JMV8F2GY9KZG	0521297338	401591830	Principles of the Theory of Solids	Books	5	5	6	N	N	No doubt as good as the first edition	I used heavily the first edition of this book, and have not seen the second, but it is no doubt as good as the first, which was packed full of insights into the many rich phenomena that exists in solids. It has served, and will serve, future generations of students in the 21st century in their development of new ideas and technologies based on condensed matter physics.<br />Writers of physics texts should follow the strategy that this author does, in his statement that &quot;a treatise expounds; a textbook explains&quot;. The emphasis of any book in physics should be in developing the reader's intuition; the mathematics sometimes takes hold and moves the reader away from the essential ideas. The author is one of the few who has not done this, and that is no doubt the reason for this book's popularity.	2002-03-16
1626038:US	50702879	R94U9HEB0MCHC	0879695773	725045295	Molecular Cloning: A Laboratory Manual, Third Edition (3 volume set)	Books	5	28	28	N	N	Excellent reference for all	In this 3 volume set of books the authors summarize the most important laboratory protocols for DNA analysis and cloning. As someone involved in computational biology and mathematical gene sequence analysis, I was needing such a summary to get an idea of just how genetic engineering is actually practiced in the laboratory. The book is definitely written for those readers that are very experienced in these \\"wet\\" techniques, but it still could be perused profitably by anyone who is curious about genetic engineering. There is also an excellent website that owners of the books can go to and search for protocols and obtain updates and additions to the protocols.<br />At the beginning of each chapter, the authors give an introduction to the protocols and this is of an enormous help to those readers with only rudimentary acquaintance with the laboratory procedures. Typically, this introduction contains an historical summary of the procedures as they were developed or discovered. One can only marvel at the ingenuity of the discoverers of these techniques. These introductions are fairly straightforward to read, even for those that are not experts in biochemistry.<br />At the end of each chapter, the authors include an \\"information panel\\" that gives a more in-depth view of the biochemistry or genetics behind the procedures. These are summaries and are highly specialized, and are again meant for experienced readers. A very lengthy list of references is also included at the end of each chapter.<br />Becuase of the size of this collection, space here does not permit a detailed review, so I will list some of the areas that I thought were particularly interesting or well-written (these coming from the introduction or the information panels only): 1. The DNA synthesis at the colE1 replicon and the interaction between RNAI and RNAII. 2. The discussion of electroporation and the physics behind this technique to introduce DNA into eukaryotic cells. 3. The discussion on the discovery of bacteriophage lambda. 4. The discussion (with diagram), of the assembly pathway of bacteriophage lambda. 5. The summary of the early analysis of DNA using electrophoresis and the different pulsed-field configurations used. 6. The anecdote on the discovery of the polymerase chain reaction. 7. The short discussion on computer-assisted design of oligonucleotide primers. 8. The discussion of oligonucleotide synthesis. 9. The flowchart detailing the preparing and screening of a cDNA library. 10. The history of the development of the methods to synthesize and clone cDNAs. 11. The detailed discussion of the molecular cloning of double-stranded cDNA. 12. The discussion on the methods to validate clones of cDNA. 13. The discussion on magnetic beads for affinity purification. 14. The discussion on the history of DNA sequencing and the different techniques to accomplish it, particularly the information panel on automated DNA sequencing. 15. The discussion of the different types of mutagenesis and the different methods for accomplishing it. 18. The fascinating discussion of how to introduce cloned genes into mammalian cells. 19. The discussion on the steps involved in DNA footprinting. 20 The discussion on green flourescent protein and its use as a fusion tag. 21. The discussion on the use of surface plasmon resonance spectroscopy.of bacteriophage lambda. 4. The discussion (with diagram), of the assembly pathway of bacteriophage lambda. 5. The summary of the early analysis of DNA using electrophoresis and the different pulsed-field configurations used. 6. The anecdote on the discovery of the polymerase chain reaction. 7. The short discussion on computer-assisted design of oligonucleotide primers. 8. The discussion of oligonucleotide synthesis. 9. The flowchart detailing the preparing and screening of a cDNA library. 10. The history of the development of the methods to synthesize and clone cDNAs. 11. The detailed discussion of the molecular cloning of double-stranded cDNA. 12. The discussion on the methods to validate clones of cDNA. 13. The discussion on magnetic beads for affinity purification. 14. The discussion on the history of DNA sequencing and the different techniques to accomplish it, particularly the information panel on automated DNA sequencing. 15. The discussion of the different types of mutagenesis and the different methods for accomplishing it. 18. The fascinating discussion of how to introduce cloned genes into mammalian cells. 19. The discussion on the steps involved in DNA footprinting. 20 The discussion on green flourescent protein and its use as a fusion tag. 21. The discussion on the use of surface plasmon resonance spectroscopy.	2002-03-09
1626603:US	50702879	RLIZP6TAOAPSP	0521635039	766086721	Quantum Computation and Quantum Information (Cambridge Series on Information and the Natural Sciences)	Books	3	19	38	N	Y	Not enough consideration of the experimental situation...	There is great excitement currently about quantum computing and its laboratory realization. Recent press releases have indicated successes in implementing quantum computation and this no doubt has encouraged the excitement. The authors of this book have been directly involved in the experimental and theoretical developments behind quantum computing and have written a fair summary of the subject as was known at the time it was first published (2000).<br /><br /> The theory behind quantum computing is outlined in some detail in the book, but the experimental situation is not, and this is disappointing since it is the laboratory realization of quantum computing that is most interesting. Most implementations of quantum computing theoretically are dependent on the notion of entanglement of states, and in my opinion there is no convincing experimental evidence of entanglement. Theoretical constructions that employ entanglement have grown considerably in recent years, but the experimental situation is far behind these developments. This book unfortunately does not look critically at the experimental justification for entanglement, but uses concepts of entanglement throughout to lay the groundwork for a theory of quantum computation. Indeed one could say that the entire book rests on the notion of entangled states and being able to manipulate these states via various transformations, called 'entanglement transformations' by the authors.<br /><br /> The authors do however devote an entire chapter to the physical realization of quantum computers , although again no real experimental data is given. The role of the decoherence time is emphasized in the discussion, and a chart is given listing rough estimates for decoherence times for various candidate realizations of quantum computers. Several different scenarios for quantum computers are outlined in the chapter, and the discussion gives some credence to the view that the theory of quantum computation has some physical meaning to it, rather than just a theory of computation based on the properties and geometry of Hilbert space. Indeed, one could easily take this later viewpoint, as it is one thing to call a mathematical construction 'quantum' and another to really find a physical (quantum) system that actually behaves in a manner compatible with these constructions. If one is to speak of 'quantum' computation and not just 'Hilbert space' computation, one must show beyond doubt that the system executing the computation is indeed a physical and quantum one. A mere statement that 'physics is computation' is not enough. Indeed, there are a few examples of using Hilbert space properties to enhance the performance of various algorithms. For example, one can speed up the training portion in neural networks by complexifying the weights. In addition, one can employ a tunneling scheme to alleviate the problems of local minima in these networks, and in gradient algorithms in general. These approaches all take advantage of Hilbert space geometry and the ability to do superposition of states, but none of them correspond at all to physical systems, let alone quantum ones. They are merely mathematical tools used to speed up (dramatically in some cases) a particular algorithm.<br /><br /> There has also been a great deal of very exciting research in the employment of the 'quantum' point of view in pure mathematics. New methodologies have been developed for handling difficult mathematical results using such a viewpoint and these have resulted in brilliant developments, especially in differential topology and algebraic geometry. The chapter on distance measures for quantum information in this book could be viewed as part of these developments and strategies. The definition of the fidelity between two quantum states is purely a mathematical convenience that is used (albeit productively) to derive quantities that behave as one would want them to (viewing from a classical standpoint). No physical relevance isgiven for this metric in the chapter, although it is interesting from a mathematical standpoint. The authors are honest to admit this though, for they state that notions of quantum information are in a state of infancy and no solid (physical) definitions have been given as of yet.<br /><br /> If more time were spent on the analysis of the raw experimental data behind the efforts to build quantum computers, and less on purely theoretical considerations, this book would have been a lot more helpful. The literature is bursting with papers on entanglement and its relation to quantum computing and quantum information, but unfortunately, not enough critical analysis of the experimental situation. This book is no different in this regard, but the authors are still enthusiastic about the prospects for quantum computing, difficult as they are. One can only hope that their efforts are successful, that such machines will be built soon, as the consequences are awesome.given for this metric in the chapter, although it is interesting from a mathematical standpoint. The authors are honest to admit this though, for they state that notions of quantum information are in a state of infancy and no solid (physical) definitions have been given as of yet.<br /><br /> If more time were spent on the analysis of the raw experimental data behind the efforts to build quantum computers, and less on purely theoretical considerations, this book would have been a lot more helpful. The literature is bursting with papers on entanglement and its relation to quantum computing and quantum information, but unfortunately, not enough critical analysis of the experimental situation. This book is no different in this regard, but the authors are still enthusiastic about the prospects for quantum computing, difficult as they are. One can only hope that their efforts are successful, that such machines will be built soon, as the consequences are awesome.	2002-03-09
1629552:US	50702879	RPGI0HLS3XPYH	0071348492	278573227	Schaum's Outline of Investments	Books	4	15	15	N	N	Good introduction to the beginning student of investment	This book gives an excellent elementary introduction to investment techniques and concepts for the beginning student of business or economics. It is full of useful examples and solved problems as is characteristic of all books in this series, and it also gives adequate explanation of the terms and results in most areas of investment activity. Some of the parts of the book which are particularly well-written or helpful include: 1. The diagram of the corporate bond rating process . 2. The flowchart detailing a primary offering made through a syndicate of investment bankers. 3. The summary of the different security market indices. 4. The discussion of the &quot;naive buy-and-hold strategy&quot; and their use as benchmarks against which other investment strategies may be compared. 5. The discussion of the Dupont framework for analyzing equity returns and growth to reveal the sources of the growth of the firm. 6. The discussion of time-series comparisons for the ratios of a firm. 7. The discussion of the various problems involved when doing financial statement analysis. 8. The discussion on arbitrage. 9. The treatment of moving averages and the accompanying illustration of different moving averages. 10. The discussion of the random walk theory in the context of the efficient markets theory. The random walk theory has been been taken to be axiomatic by most financial analysts but has recently been challenged recently by empirical studies of financial data. 11. The treatment of the different levels of market efficiency, including the weakly efficient, the semistrong efficient, and the strongly efficient market hypotheses. 12. The discussion of the anomalies in market data that point to deviations from the efficient market hypothesis. 13. The chapter on portfolio analysis via the use of covariance and the treatment of the efficient frontier. 14. The treatment of the capital asset pricing model.	2002-03-06
1631119:US	50702879	R17LSYXDER1M28	0816608679	300602951	Thought, Fact, and Reference: The Origins and Ontology of Logical Atomism	Books	5	7	7	N	N	Five stars is not enough	It is unfortunate that this book is out of print, for it is one of the best written books on the origins and explanations of logical atomism. I had the distinct pleasure of sitting in a class on realism and idealism that was given by the author, wherein this book was used, and it was probably one of the best overviews of these two schools of thought that I have experienced. The author explains the history behind the linguistic turn that began early in the twentieth centuryand discusses in detail the attempts by Moore and Russell to refute idealism with their arguments evolving into the theory of logical atomism. The author does not hesitate to use the logical symbolism of first order predicate calculus when needed to clarify the issues. Such symbolism appears in the book in many places, and serves the reader well in the statement of the problems that Moore and others were attempting to solve. Some examples of this include the discussion of the argument of Moore on the existence of objects of direct apprehension. These are to occur, contrary to the idealist position, independently of any act of apprehension. The way the author constructs the logical proposition to elaborate Moore's position differentiates it from the idealist position with great clarity.<br /> Moore has been known as the &quot;common sense&quot; philosopher, and the author in his discussion brings this labeling to light in the book in detail. It is also interesting, when reading the book, to reflect on positions taken by philosophers in later decades, particularly by Jean Paul Sartre. The issue of negation for example, is discussed in the book, and Sartre's view is that one &quot;experiences&quot; the negation. This move by Sartre of how to handle the negation is expoused in great detail in Sartre's works, and this book gives a greater appreciation of just why the problem of negation was so important to Sartre.<br /> The issues in this book are, interestingly enough, very important in fields such as artificial intelligence and are currently hotly debated in the attempts to build thinking machines. A field called &quot;ontological engineering&quot; has been evolving over the past two decades, and the logical and programming issues that arise in this field are ones that are similar to or identical to the ones addressed in this book. We are lucky to be in age where one can speak of &quot;applied philosophy&quot;, in the attempts to bring artificial intelligence to reality. The excellent elucidation by the author in this book of these issues is, unintended by the author no doubt at the time of writing, of great assistance to those working to develop machines that can think, that can gather facts, and that can reference. These machines, when they are developed, will put forward their own unique arguments about their abilities to do this.......as artificial intelligence and are currently hotly debated in the attempts to build thinking machines. A field called &quot;ontological engineering&quot; has been evolving over the past two decades, and the logical and programming issues that arise in this field are ones that are similar to or identical to the ones addressed in this book. We are lucky to be in age where one can speak of &quot;applied philosophy&quot;, in the attempts to bring artificial intelligence to reality. The excellent elucidation by the author in this book of these issues is, unintended by the author no doubt at the time of writing, of great assistance to those working to develop machines that can think, that can gather facts, and that can reference. These machines, when they are developed, will put forward their own unique arguments about their abilities to do this.......	2002-03-05
1634934:US	50702879	R3KOZ7RVQRSBXG	0070240353	311929222	Schaum's Outline of Programming with C	Books	4	14	15	N	N	Straightforward overview of C	With their low cost and their wide availability in college bookstores, the Schaum's Outline Series has helped many students in the past decades. In technical areas, the books in the Series are noted for being example wizards, and therefore are also of assistance to instructors. In this book on C programming, the author has continued this tradition, and has produced a book that turns out to be one of the best ways to learn this language. C can be difficult and abtruse at times, particularly in the use of pointer arithmetic, in string manipulation, and in memory management, but the author, again through many examples, clears up nicely any nagging issues in writing programs in C. C is still heavily used in applications, particularly when performance is an issue, and only in recent years has it been seriously replaced by its descendant, C++. The material in the book is pretty standard, and no really imaginative uses of C are outlined, such as how to use C to do self-reference function calling or how to emulate functional programming using C. However, for one needing an introduction to C, or for one who is teaching C in the classroom, this book would be a good supplement if cognizance is taken of current programming standards in C.	2002-03-02
1635498:US	50702879	RQHDX7GF654W1	0963502700	642424419	Data Analysis for Scientists and Engineers	Books	4	13	13	N	N	Still useful	I have used heavily the first edition of this book, published in 1975, and have found it an excellent source of reference and a good teaching aid in the subject. With the proliferation of software packages in statistics, some of  these now using artificial intelligence, it is imperative that students still have a good training in the foundations of probability and statistics. I am glad to know that the book has been reprinted and is now available to be of assistance in this regard.<br />The author does a fine job of explaining the nature of data collection and scientific investigation, and also proves rigorously the properties of the most common probability distributions, such as the binomial, hypergeometric, Poisson, Gaussian, Student's t, negative binomial, multinomial, exponential, Weibull, and log-normal distributions. Noticeably missing is the Pareto distribution, which has become very important in network modeling and computational biology. Also included is a brief introduction to Monte Carlo experiments. There has been an explosion in the last decade in the use of Monte Carlo simulations, particularly in financial engineering, and this will no doubt continue in years to come.<br />Statistical inference is also treated very adequately in this book, and should prepare the beginning reader for using the statistical packages currently available. Missing of course are discussions of time series and nonlinear regression using neural networks, but reader who need exposure to these areas will be prepared after reading this book.<br />Computational and artificial intelligence are quickly overtaking the world of statistical estimation and modeling, and future books in data analysis will no doubt be considerably different than this one. But programming and designing these intelligent programs or machines will still require a thorough understanding of statistical concepts, and this book still serves well in that goal.	2002-03-02
1635926:US	50702879	R3973K81MWLNNT	0387944346	902877943	An Introduction to Programming With Mathematica	Books	3	6	7	N	N	Out of date...but still can be useful	Mathematica is now in version 4.1, and this book was written in the time of Version 2.2, but it still could be read profitably if cognizance is made of the significant additions made to Mathematica since 2.2. The \\"Lispy\\" nature of Mathematica is still the same, and it still ranks as one of the easiest and most powerful of languages to program in. The authors have done a good job of introducing the reader to the subtleties of Mathematica, and they are honest in their explanations, pointing out the areas where using Mathematica might be problematic. A person getting started in Mathematica will no doubt want to read something that is more up-to-date, but this book is designed for such a reader and it has a lot of interesting ideas of how to apply the language.<br />  One of the better features of the book includes the discussion on functions. The functional programming paradigm is one that I favor the most, and which is most transparently used in Mathematica. The authors do a good job of explaining anonymous functions in Mathematica and how to create the famous \\"one-liners\\" that Mathematica is famous for.<br />  Another topic that is treated very well by the authors is recursion. Mathematica is mostly easily programmed using recursion, and the authors show, starting with the Fibonacci numbers, how to \\"think recursively\\". Readers who know Lisp will of course find the discussion very easy to follow.<br />  A third edition of this book is in order, again since Mathematica has changed considerably since this book was written. More discussion on performance issues in Mathematica would be welcome, and also more examples and applications, along with more discussion on how to link Mathematica to external programs.	2002-03-01
1637404:US	50702879	R1OMBV05DIGSW9	0079136966	525686732	Java Algorithms	Books	3	3	3	N	N	Fair treatment	In this book, written at the time of JDK 1.1.1, the author attempts to convey to the reader that the Java programming language is not just for creating applets, but can be used for networking, interprocess communications, scientific programming, and for creating portable graphic interfaces. It is reasonably well-written, but the author should have spent more time on the performance issues in writing stand-alone code in Java. He makes the claim that a Java program can outperform an equivalent program in C++, but he offers no benchmark comparisons to substantiate his claim. This is particularly for his discussion of matrix algebra in Java. His general discussion of algorithms to do various tasks is pretty well-written, and a reader could gain insight into the workings of these algorithms by the perusal of this book.<br />The author also gives hints on how to improve the performance of Java programs. In the discussion of sorting for example, he explains how to remove recursion in order to implement an iterative scheme for sorting, thus enhancing performance. He is also careful to point out that the presence of primitive types in Java, which cannot be derived from the Object class. Thus it is often required, as the author explains, to create methods to convert arrays of primitive types to arrays of wrapper classes.<br />The author's discussion of numerical applications in Java is fairly well-written, as he discusses the various numeric data types in Java, and how it does conversions between numeric types. And he points out some of the virtues that Java has in manipulating arrays, one example being that manual range checking need not be done. He does give Java code for the Fast Fourier Transform, but it is too slow to be of practical interest in serious real-world applications.<br />A reader with background in computational biology and genome sequence analysis might find the author's discussion on Java strings of interest. Java has been used in biological applications, but the software language PERL continues to be dominant in these applications. The author develops explicitly algorithms for string searching in chapter 3, and these could be adapted to biological applications if one is so inclined.<br />Another topic of interest in the book is the one on high-performance containers. The author recognizes that Java does not provide for the standard data structures like queues and linked lists, so he spends a fair amount of time developing various types of containers.<br />The author also introduces evolutionary programming and its implementation in Java. This is done via the construction of finite state machines, and the evolutionary algorithm calculates a fitness value for each finite state machine based on its performance. A fun example dealing with robot examples is provided in Java. In addition, a very interesting discussion (with Java source code) is given for random number generation.<br />The discussions on serialization and serialization in random access files might be useful to the reader who is attempting to write network and database applications in Java or writing JavaBeans applications. There is also an entire chapter devoted to implementing (in Java) the BTree data structure. I was not aware of this data structure before reading the book, so this chapter was interesting reading.<br />By far the most pleasureful part of the book was the discussion on stellar cartography and star map plotting, from both a personal and educational standpoint. Instructors of astronomy or earth science could easily use the Java implementation in the classroom to illustrate the relevant concepts to students., but the software language PERL continues to be dominant in these applications. The author develops explicitly algorithms for string searching in chapter 3, and these could be adapted to biological applications if one is so inclined. <br />Another topic of interest in the book is the one on high-performance containers. The author recognizes that Java does not provide for the standard data structures like queues and linked lists, so he spends a fair amount of time developing various types of containers. <br />The author also introduces evolutionary programming and its implementation in Java. This is done via the construction of finite state machines, and the evolutionary algorithm calculates a fitness value for each finite state machine based on its performance. A fun example dealing with robot examples is provided in Java. In addition, a very interesting discussion (with Java source code) is given for random number generation. <br />The discussions on serialization and serialization in random access files might be useful to the reader who is attempting to write network and database applications in Java or writing JavaBeans applications. There is also an entire chapter devoted to implementing (in Java) the BTree data structure. I was not aware of this data structure before reading the book, so this chapter was interesting reading. <br />By far the most pleasureful part of the book was the discussion on stellar cartography and star map plotting, from both a personal and educational standpoint. Instructors of astronomy or earth science could easily use the Java implementation in the classroom to illustrate the relevant concepts to students.	2002-02-28
1638353:US	50702879	RKVS5WQHC0W98	0226568164	73243940	Several complex variables (Chicago lectures in mathematics)	Books	4	10	11	N	N	Good overview	This book is a short overview of the theory of several complex variables that emphasized the elementary aspects of the subject, such as Hartogs' theory, and domains of holomorphy. The price quoted here for the book is surely a mistake, and even though it is out of print, if obtained it could still be of use for self-study. Readers should have a background of course in the theory of one complex variable, and when reading it will clearly see the differences in the theory of complex variables when raising the dimension.<br />In chapter 1, the author defines the basic concepts needed for a study of this subject, such as the polydisc and the definition of real analyticity. As expected, the Cauchy integral formula holds in several dimensions, with the proof easily generalized from the case of one dimension. In fact, most of the results in one dimension, such as Montel's and Weierstrass theorems, are shown by the author to hold in several dimensions. After defining what is means for a function of several complex variables to be holomorphic, he shows that such a function is not dependent on the complex conjugate of its dependent variables, just like in the one variable case. He proves the converse, namely that the vanishing of the partial derivative with respect to the conjugate variables implies the function is holomorphic, in chapter three.<br />In chapter two, the author immediately shows where the things begin to change in several variables, the first result being Hartogs' theorem. This theorem states that one can always find an analytic continuation of a holomorphic function defined on an open disc to the boundary of the disk. One can clearly see the origins of sheaf theory in this chapter, when the author discusses the construction of domains of existence for one or more holomorphic functions. The author proves that two holomorphic functions on a domain that agree on a nonempty open subset of this domain are identical.<br />Chapter three is an introduction to the study of subharmonic functions in several complex variables. The author proves the theorem of Hartogs, that shows the converse of the holomorphicity result in chapter 1. The reader familiar with elementary harmonic analysis will see it here in the context of several complex variables.<br />In chapter four, the author introduces analytic sets, these being essentially subsets of an open set in complex n-space on which a finite collection of holomorphic functions vanish. He shows to what extent the singularities of a holomorphic function are an analytic set.<br />The author studies the collection of automorphisms on bounded domains in complex n-space in chapter five. An automorphism from an open connected set in complex n-space to itself is a holomorphic map if there exists another holomorphic map whose composition with the automorphism is the identity. After putting a topology on the group of automorphisms, he characterizes all automorphisms of a polydisc. In addition, he again illustrates the differences between complex 1-space and complex n-space for n greater than 2. In complex 2-space for example, he shows that there is no analytic isomorphism from the open square onto the open disk. This is not the case in complex 1-space, where all simply connected domains are analytically equivalent. He also shows that there are no proper holomorphic maps of domains in complex n-space into any ball, and that there are &quot;flat&quot; directions for holomorphic maps from domains in complex n-space to products of bounded domains in complex 1-space. The latter in particular is a radical departure from the behavior in complex 1-space.<br />The author considers families of holomorphic functions in chapter six, generalizing the results in chapter two. Sheaf theory again makes its presence known, and the key concept introduced is that of envelopes of holomorphy. This is essentially the maximal domain such that each function holomorphic on a domain can be analytically continued to the envelope of holomorphy. Envelopes of holomorphy are shown to exist and to be unique. And, this is one of the few places in the book where the author gives examples, i.e. he details examples of envelopes of holomorphy that are not in complex n-space. The theory in this chapter is of considerable importance in some formulations of axiomatic quantum field theory.<br />Holomorphic convexity and domains of holomorphy are the subject of chapter seven. A domain of holomorphy is essentially the &quot;natural&quot; domain for at least one function. If a given domain is not a domain of holomorphy, then any function holomorphic in this domain is holomorphic in some larger domain. Any domain in complex 1-space is a domain of holomorphy, but in complex n-space this need not be the case. One can construct domains in complex n-space so that every holomorphic function on this domain extends holomorphically to a strictly larger domain containing the original. The author shows the role of holomorphic convexity in the consideration of functions that are bounded by their supremum norm.  Every convex open set in complex n-space is a domain of holomorphy.<br />Hadamard's three domains theorem and one part of Oka's theorem are proved in chapter eight. The former is essentially an inequality (in the sup norm) for a function defined on a connected domain that has two others as successive proper subsets.  Oka's theorem as stated gives that a domain of holomorphicially is holomorphically convex. The author does not prove the converse, explaining that such a proof would take an excursion into global ideal theory.<br />The last chapter of the book deals with automorphisms of bounded domains, wherein the author details the proof of Henri Cartan that the collection of analytic automorphisms of a bounded domain is a Lie group.e envelope of holomorphy. Envelopes of holomorphy are shown to exist and to be unique. And, this is one of the few places in the book where the author gives examples, i.e. he details examples of envelopes of holomorphy that are not in complex n-space. The theory in this chapter is of considerable importance in some formulations of axiomatic quantum field theory. <br />Holomorphic convexity and domains of holomorphy are the subject of chapter seven. A domain of holomorphy is essentially the &quot;natural&quot; domain for at least one function. If a given domain is not a domain of holomorphy, then any function holomorphic in this domain is holomorphic in some larger domain. Any domain in complex 1-space is a domain of holomorphy, but in complex n-space this need not be the case. One can construct domains in complex n-space so that every holomorphic function on this domain extends holomorphically to a strictly larger domain containing the original. The author shows the role of holomorphic convexity in the consideration of functions that are bounded by their supremum norm.  Every convex open set in complex n-space is a domain of holomorphy. <br />Hadamard's three domains theorem and one part of Oka's theorem are proved in chapter eight. The former is essentially an inequality (in the sup norm) for a function defined on a connected domain that has two others as successive proper subsets.  Oka's theorem as stated gives that a domain of holomorphicially is holomorphically convex. The author does not prove the converse, explaining that such a proof would take an excursion into global ideal theory. <br />The last chapter of the book deals with automorphisms of bounded domains, wherein the author details the proof of Henri Cartan that the collection of analytic automorphisms of a bounded domain is a Lie group.	2002-02-27
1644415:US	50702879	R1DKA9DUOCOO0L	0471096849	148188001	Seventeen Simple Lectures on General Relativity Theory	Books	3	5	5	N	N	Fair job	Foundational studies of a physical theory are usually thought of as philosophy, and not really part of physics. But if clarification of a physical theory is considered philosophical, then one must engage in it, as it sheds more light on the intrinsic difficulties of the theory.<br />In this book, a collection of seventeen lectures, the author attempts to examine what he calls the uncertainties and perplexities that he encountered when studying the general theory of relativity. He states in the preface that he is not a philosopher of science, but his approach in the lectures could be classified as philosophical. I only read the first five lectures, so my review will be limited to these. Considering the importance of the topics in the lectures, the author was too quick in his summary of them. A full treatment of these topics will swell a book to an enormous size, as one can tell from a perusal of the literature on the foundations of the theory of relativity. One could view the book as an introduction to this literature.<br />In the first lecture, the author attempts to clarify just what a theory is, and whether the special theory of relativity is in fact a theory. He concludes that it is not, but merely a &quot;meta-theory&quot;, since the postulates of the special theory do not have physical content, i.e. no physical laws are embedded in it. The principles of the special theory that inertial frames are equivalent and the constancy of the speed of light, are in the author's view, merely regulative principles that govern the correct form of a theory. He does not elaborate in much detail though, and leaves the reader wanting for more discussion.<br />In lecture two, he begins an analysis of general relativity. He briefly addresses the issue of time but abandons an in-depth analysis of it, stating instead that it is impossible to define it, and any attempt to do so results in circularity. Eschewing a rigorous, philosophical definition of time, the author instead takes the modern operational, prescriptive notion of time. His approach to the notion of space is similar: he backs away from any philosophical discussion, taking instead a definition of space as the set of all spatial relations.<br />The author's goal in lecture three is to define a free particle, which he states is one not in contact with any material substances, is not subject to any incident particles or radiation, and is not influenced by electric or magnetic moments,  or electric currents. This allows him to define an inertial frame, which he takes to be a set of four particles, each having a &quot;standard&quot; clock, such that a beam of light leaving any one of them meets only one of the others. Coordinate systems for a particle are established by means of light pulses emitted from the particle and then reflected by these four, giving the four coordinates of the particle. A consideration of measuring rods leads him to the concept of a local inertial frame, and this is extended to a discussion of the geometry of space, and the notion of space being &quot;locally Euclidean&quot;. He prefers to view geometry as &quot;physical&quot; and not in an abstract sense, the latter he claims to be non-empirical and not relevant for physics.<br />In lecture four, the author recognizes that the four particles that were used to define an inertial frame have no special status. This is the &quot;special principle of relativity&quot;. Transformations between inertial frames are constructed to preserve the shape of light pulses and to insure that a free particle moves with constant speed in a straight line in all inertial frames. These are the famous Lorentz transformations, and Maxwell's equations are shown to be invariant under these.<br />The invariance of equations under coordinate transformations is an issue considered important by the author, and he spends the next lecture on its discussion, the gist of which is to attempt to differentiate between what he calls &quot;proper&quot; and &quot;improper&quot; form invariance of equations between coordinate systems. An equation is improperly form invariant if both the equation and the equation in another coordinate system can be written as the same function of the variables and the metric. The metric does not have to be the same function of the coordinates in both coordinate systems. When it is, the equation is properly form invariant. Proper form invariance is usually called covariance in the literature, and he argues that it does have physical consequences, in that it may determine teh form of the equations uniquely. His discussion is similar to those that are given in gauge theories when imposing gauge invariance of the proposed equations. The author also gives consideration of &quot;nonlocal&quot; systems of coordinates. With the constraint that the coordinate transformations must be locally Euclidean, the author is led to the introduction of normal coordinates, which he shows can always be introduced. A typical coordinate transformation will involve linear and quadratic terms, and these, the author shows, can be eliminated if their coefficients satisfy certain relations involving the famous Christoffel symbols. This allows the author to discuss meaningfully spatiotemporal relationships between events referred to a nonlocal system which are local with respect to the system where the aforementioned linear and quadratic terms are absent.r&quot; and &quot;improper&quot; form invariance of equations between coordinate systems. An equation is improperly form invariant if both the equation and the equation in another coordinate system can be written as the same function of the variables and the metric. The metric does not have to be the same function of the coordinates in both coordinate systems. When it is, the equation is properly form invariant. Proper form invariance is usually called covariance in the literature, and he argues that it does have physical consequences, in that it may determine teh form of the equations uniquely. His discussion is similar to those that are given in gauge theories when imposing gauge invariance of the proposed equations. The author also gives consideration of &quot;nonlocal&quot; systems of coordinates. With the constraint that the coordinate transformations must be locally Euclidean, the author is led to the introduction of normal coordinates, which he shows can always be introduced. A typical coordinate transformation will involve linear and quadratic terms, and these, the author shows, can be eliminated if their coefficients satisfy certain relations involving the famous Christoffel symbols. This allows the author to discuss meaningfully spatiotemporal relationships between events referred to a nonlocal system which are local with respect to the system where the aforementioned linear and quadratic terms are absent.	2002-02-23
1652059:US	50702879	R3BJ7LZRVRV19C	0517881705	204569267	Unveiling the Edge of Time: Black Holes, White Holes, Worm Holes	Books	4	13	13	N	N	Nice job	Written for the &quot;popular audience&quot;, this book has no doubt inspired many who have read it to further their studies in science or even to specialize in gravitational physics. The book is easy to follow, and the author injects a lot of history, making the book even more interesting. Examples of this include the Cavendish torsion-balance experiments, the 1670 measurement of the speed of light, and the discussions in 1796 of &quot;dark-stars&quot;. And, considering there is no mathematics used in the book, the author does a good job of explaining curvature of spacetime and geodesics. The physics of neutron stars, pulsars, and white dwarfs, is also given adequate explanation, and the author emphasizes the use of computers in determining their dynamics. Penrose diagrams are used effectively to illustrate the properties of black holes, a fairly lengthy discussion, the result of which is to make what use to be the playful fantasies of science fiction writers become accepted science. Wormhole engineering and time machine constructions are unshamedly expounded upon, with careful caution by the author that such ideas are not yet practical......not yet.	2002-02-16
1652191:US	50702879	R354R1E54WWSKS	1581120419	766707568	Contributions to the Theory of Monte Carlo and Quasi-Monte Carlo Methods	Books	3	2	2	N	N	Needs some more examples	In this work, the author's Phd dissertation, he attempts to show that quasi-Monte Carlo methods can indeed be useful in high dimensional problems and that there is a methodology for estimating the error in a quasi-Monte Carlo simulation. The thesis is divided up into three sections, with the first two covering a hybrid Monte Carlo method, and third to a quasi-Monte Carlo integration rule. Readers interested in performance issues in Monte Carlo and quasi-Monte Carlo will be interested in this work, although much more could be done in way of examples. Quasi-Monte Carlo techniques have been used in mathematical finance and in computational biology to improve convergence and performance in problems traditional Monte Carlo, but the improvements have not been very dramatic. It still remains to be seen whether quasi-Monte Carlo will be a viable replacement to Monte Carlo, and really an honest assessement of both techniques points to using a hybrid of each to tackle most problems of interest.<br />Strictly speaking, Monte Carlo techniques are just as \\"deterministic\\" as quasi-Monte Carlo ones, because of the inability to generate totally random numbers on a computer. For this reason, the author is careful to use a notion of randomness that is based on a uniform distribution, so that randomness or lack thereof  becomes a problem dealing with the uniformity of a sequence of numbers. And, as in Monte Carlo, the numerical evaluation of integrals is the goal initially.<br />The author does a fair job of explaining and proving the properties of mixed sequences, and in comparing their efficiency in calculating integrals versus ordinary low-discrepany sequences. He concludes based on the few examples he treats that mixed sequences outperform the others, such as Sobol, Niederreiter, and Faure sequences. He did not consider though integrands that are rapidly oscillating, which would have been an interesting test for mixed sequences. The author also compares the use of mixed sequences in the option valuation problem in mathematical finance, namely Asian and European options with stochastic volatility. In the one example he examines, he shows that the conventional methods are comparible to mixed sequences for 40 prices, but at 70 prices the mixed sequences are superior. More examples should have been done however to validate the author's bias towards the use of mixed sequences.<br />In addition, the author explains in some detail the error bounds in using quasi-Monte Carlo methods versus Monte Carlo. In the former, one can give deterministic error bounds, while in the latter the error bounds are probabilistic. However, the error bounds for quasi-Monte Carlo require numerical estimation of the variation and the star discrepancy, while in Monte Carlo only the standard deviations of the estimates need be obtained. The author discusses interesting an interesting method, which he calls the RS-estimate, for obtaining estimates that is still deterministic, but can also be analyzed statistically. This method is then applied to a European call option problem and to a problem in particle transport, and compared with pseudorandom, square root, and Halton sequences. Although the RS-method is shown to be competetive with these other sequences in the problems considered, it would have been better if the author had considered additional problems, particularly from transport theory. Indeed a consideration of the difficult dose deposition problem in radiation therapy, which is one that has been tackled with ordinary Monte Carlo, would have been an interesting problem in which to test his techniques.<br />The author also considers the mathematical issues in error reduction in quasi-Monte Carlo integration, formulating what he calls weighted non-uniform quasi-Monte Carlo integration rules, and proves a Koksma-Hlawka type inequality for these. He shows, via an example, that these weight sequences improve by a factor of 2 the upper bound of the Koksma-Hlawka inequality, but points out that the error reduction depends on the integrand. He does not however give examples of this.ality, but points out that the error reduction depends on the integrand. He does not however give examples of this.	2002-02-16
1652402:US	50702879	R1DA3XR8HXG1LF	3540100903	37356482	Essential Relativity: Special, General, and Cosmological  (Texts and Monographs in Physics)	Books	4	20	22	N	N	Very well written	As a modern textbook in the theory of relativity, this book is rare, in that its goal is to give the reader a conceptual introduction to the theory, and not just mathematical formalism. The author also does not hesitate to include some philosophical argumentation wherever needed. It is written for the advanced undergraduate, and will prepare such a reader for more advanced reading in the subject.<br />The first chapter of the book is the best, for it is a comprehensive discussion of the origins of the theory of relativity as one that rejected the assertion that space and time were absolute. The author also gives an interesting historical discussion of Lorentz's ether theory, wherein Lorentz hypothesized that bodies moving through the ether undergo a contraction, and he discovered a time transformation that implied that clocks moving through the ether run slow. As the author points out, Lorentz thought such considerations were purely mathematical, and not important physically. In addition, in the section on Mach's principle, the author discusses briefly the work of Dennis Sciama who showed that the 1872 gravitational theory of F. Tisserand included Mach's principle. I was not aware of this work, and it motivated me to do further reading on the subject. The author also gives several examples to show that Mach's principle is not physically vacuous, but has observational consequences.<br />Chapter two overviews the kinematic consequences of the special theory of relativity. The most interesting part of this discussion was the section on the formulation of special relativity without assuming the invariance of the speed of light. The author shows that the principle of relativity implies that either all inertial frames are related by Galilean transformations, or all are related by Lorentz transformations with the same (postive) velocity (squared).<br />A discussion of optical effects follows in chapter 3. One unexpected and interesting result in this chapter is that a moving sphere has a circular outline to all observers because of length contraction.<br />Some of the mathematical formalism needed in special relativity is overviewed in chapter four. The class of four-vectors and four-tensors is defined, and the light cone geometry discussed in detail.<br />The relativistic mechanics of point particles is covered in chapter five. Such a theory is cast in the language of four-vectors, and the author explains nicely the mass-energy equivalence, analyzes scattering from a relativistic standpoint in the center of momentum frame, and shows how Newtonian mechanics is altered in the relativistic realm. He also spends a little time on relativistic continuum mechanics, via the energy tensor of the simplest continua: dust.<br />The connection between relativity and electrodynamics is outlined in chapter six. The material is standard and found in most books on relativity.<br />The author begins the study of general relativity in chapter seven with some elementary considerations of the differential geometry of curved surfaces and also Riemannian spaces. The author endeavors, rightfully, to explain the mathematics in a way that is intuitive as possible, rather than hitting the reader with highly abstract formalism.<br />He then presents the mathematica foundations of general relativity in chapter eight. After a brief review of tensor calculus, the author considers the gravitational field equations in a vacuum, emphasizing their nonlinearity. This is followed by a detailed discussion of the famous Schwarzschild solution. In addition, he considers a particular exact solution of the Einstein field equations in a vacuum, namely a plane-fronted gravitational wave. Although not physical, this solution illustrates some important properties of general gravitational radiation.<br />The author ends the book with a fairly detailed overview of cosmology. The difficulties in the pre-relativistic cosmology are discussed, one of the more interesting being the consideration of the Newtonian gravitational field inside a cavity resulting from the removal of a finite sphere from a static universe. Recognizing that Poisson's equation does not have a constant solution led to the alteration of the Newtonian potential and thus a modification of the Poisson equation. As the author observes, this move to get a static Newtonian universe is formally the same as what Einstein did via the introduction of the cosmological constant in his field equations (also to get a static universe). The author also considers the Robertson-Walker, Milne, and Friedman universe, and compares these to what is known observationally.ng the consideration of the Newtonian gravitational field inside a cavity resulting from the removal of a finite sphere from a static universe. Recognizing that Poisson's equation does not have a constant solution led to the alteration of the Newtonian potential and thus a modification of the Poisson equation. As the author observes, this move to get a static Newtonian universe is formally the same as what Einstein did via the introduction of the cosmological constant in his field equations (also to get a static universe). The author also considers the Robertson-Walker, Milne, and Friedman universe, and compares these to what is known observationally.	2002-02-16
1659419:US	50702879	R11LY68DGU9OYR	0844654876	371141189	Introduction to the Theory of Relativity	Books	4	10	11	N	N	Buy a used copy	This book is one of the first introductions to the theory of relativity that has the endorsement of the discoverer of the theory. Albert Einstein was alive when the book was first published, and writes the foreward to the book. Individuals who want to learn relativity should still take a look at this book, in spite of the somewhat outdated mathematical notation. In more contemporary textbooks and monographs the physical intuition is usually sacrificed and replaced with mathematical formalism. But here the author puts the main emphasis on the physics behind the subject. It is one of the few books still in print that discusses the relativistic mechanics of mass points and continuous matter.<br />The reader will also get an overview of early approaches to unified field theories. Historians of science will be interested in particular with this discussion. It is amazing how much has changed in this area since this book was published in 1942. The advent of superstring and M-theory has given physicists a view of reality that is set on a mathematical structure that is quite formidable. It now takes years for a student to obtain the necessary mathematical background to reach the frontiers of unified theories. In this book, it only takes the reading of the first two parts to be able to understand the author's overview of unified field theories. Particular attention should be paid to the treatment of the gauge-invariant geometry of Hermann Weyl, because of its relevance to the construction of gauge theories in elementary particle physics. The geometry of Weyl is constructed using a symmetric tensor representing the gravitational field and a pseudovector that represents the vector potential. When a gauge transformation is applied to this vector potential, it changes by a gradient, which, as the author remarks, is the historical reason for calling the addition of a gradient to the electromagnetic vector potential a gauge transformation. In addition, variational principles play a role in this discussion, and these principles have wide applicability to the quantization of gauge theories in modern developments. The role played by adding extra dimensions to formulate a field theory is summarized here by the author in his discussion of five-dimensional field theories and Kaluza-Klein theories. Ten- and eleven-dimensional theories now dominate modern unified theories. It would be very interesting to know what the author and Einstein would have thought about the theories of today, entrenched as they are in the most complex mathematical constructions ever applied to physical theory.a role in this discussion, and these principles have wide applicability to the quantization of gauge theories in modern developments. The role played by adding extra dimensions to formulate a field theory is summarized here by the author in his discussion of five-dimensional field theories and Kaluza-Klein theories. Ten- and eleven-dimensional theories now dominate modern unified theories. It would be very interesting to know what the author and Einstein would have thought about the theories of today, entrenched as they are in the most complex mathematical constructions ever applied to physical theory.	2002-02-10
1660578:US	50702879	R19E03CG66O0GO	0132276127	551439612	Mathematica for Scientists and Engineers: Using Mathematica to Do Science	Books	4	8	9	N	N	Somewhat dated....but still useful	Since this book was published, Mathematica has come out with version 4.1, which makes the book somewhat dated, since it is written in 3.0. However, it could still be of benefit to someone who wants to use Mathematica for more specialized tasks in science and enginnering. Some of the Mathematica code in the book is given for problems that are not usually discussed in books on Mathematica. It could serve as a supplement to a course in Mathematica if one is willing to put up with its being out of date, since there are many interesting exercises assigned at the end of each chapter. It would not be too difficult to update the book to Mathematica 4.1. Practicing scientists interested in using Mathematica for visualization could use the book as a handy reference.<br />Chapter 1 begins with a short review of how to use Mathematica and then the author jumps right into the Riemann zeta function. He gives a fairly lengthy discussion of this function, complete with graphics and Mathematica code. He uses both his own code for the function as well as the built-in function Zeta to illustrate the properties of the Riemann zeta function, particularly its zeros. He shows how the choice of grid spacing can hide the singularity structure of this function, if not chosen finely enough.<br />Chapter 2 is an overview of numerical methods in Mathematica. He begins with the problem of numerical integration by calculating the specific heat of a crystalline lattice using Nintegrate. The ability of Mathematica to integrate numerically nasty integrands, such as sin(1/x), is then investigated, with the problems with the singularity and convergence discussed in some detail. He also discusses numerical contour integration, which is not usually done in Mathematica books. The Duffing oscillator is treated as an example of solving differential equations numerically using Mathematica. Most importantly though the author shows how to solve partial differential equations numerically using Mathematica. Although performance issues in solving PDEs will appear in using Mathematica to do this, the author uses the built-in function NDSolve to show how one might gain insight into the behavior of solutions. He treats the case of sound waves in a pipe and the elastic string with fixed ends subjected to a constant transverse force. Then after a brief look at numerical sums and products, he treats the quantum mechanical problem of a particle in a one-dimensional well. The chapter ends with a consideration of the 3-body problem, including the restricted 3-body problem. The author's treatment is pretty good but he fails to discuss in detail the numerical instability of the orbits at large times.<br />Symbolic manipulation, the tour-de-force in Mathematica, is treated in detail in chapter 3. He gives as an example a very interesting simulation of a cyclotron, and shows how Mathematica can be used to efficiently do the algebra in this problem. He then illustrates how to use Mathematica to manipulate series, with series solutions of ordinary differential equations given the emphasis. Most helpful is his discussion on how to treat residues in complex analysis using Mathematica. The author also shows how a cavilier use of symbolic integration can cause problems with some integrands. Such a discussion is very useful in it flags the first-user of Mathematica or to the mathematics student who might be careless in using the built-in function Integrate. This is followed by a fairly detailed discussion of how to differentiate symbolically using Mathematica and how to do vector calculus. Anyone who has done the calculations in the solution of the Schroedinger equation for the hydrogen atom will appreciate the ability of Mathematica to make the arithmetic less painful, and the author shows this in this chapter. Then after a brief discussion of matrix algebra and simplification using Mathematica, the author moves on to a topic that is usually not treated at all in Mathematica books, namely integral transforms. He shows briefly how to deal with the Laplace and Fourier transforms. He also introduces the ability to do local scoping of variables using the Module command.<br />Chapter 4 covers Mathematica's powerful graphics capability. Most of this material can be found in other books, and in fact the absence of color in the book is somewhat disappointing given the author's heavy use of color directives when plotting functions in this chapter. He does however give a useful short discussion on how Mathematica samples a function to be plotted. A fun example of how to create a Smith chart using Mathematica is detailed by the author. In addition, he treats a physical problem of the spinning top. This is a problem that cries out for visualization when learning about it for the first time, and the author does a fine job of explaining its motion, including the Mathematica code for doing an animation. Unfortunately he does not discuss the solution of the spinning top using elliptic curves nor the case of the spinning top without a fixed point, which involves the use of hyperelliptic curves. Mathematica can be used effectively I have found to deal with these cases.<br />The last chapter is oriented more to matters in computer science, as the author treats data structures, namely lists, in Mathematica. He gives the reader hints on how to program in Mathematica efficiently, and how to use the built-in function Compile to improve program performance in Mathematica. He also illustrates the very powerful ability of Mathematica to do rule-based programming via an example of generating fractal images. Most importantly, he shows how to use Mathematica to solve partial differential equations using finite differences, another topic usually not done in other Mathematica books. A brief discussion of how to do tensor manipulation ends the chapter.integral transforms. He shows briefly how to deal with the Laplace and Fourier transforms. He also introduces the ability to do local scoping of variables using the Module command. <br />Chapter 4 covers Mathematica's powerful graphics capability. Most of this material can be found in other books, and in fact the absence of color in the book is somewhat disappointing given the author's heavy use of color directives when plotting functions in this chapter. He does however give a useful short discussion on how Mathematica samples a function to be plotted. A fun example of how to create a Smith chart using Mathematica is detailed by the author. In addition, he treats a physical problem of the spinning top. This is a problem that cries out for visualization when learning about it for the first time, and the author does a fine job of explaining its motion, including the Mathematica code for doing an animation. Unfortunately he does not discuss the solution of the spinning top using elliptic curves nor the case of the spinning top without a fixed point, which involves the use of hyperelliptic curves. Mathematica can be used effectively I have found to deal with these cases. <br />The last chapter is oriented more to matters in computer science, as the author treats data structures, namely lists, in Mathematica. He gives the reader hints on how to program in Mathematica efficiently, and how to use the built-in function Compile to improve program performance in Mathematica. He also illustrates the very powerful ability of Mathematica to do rule-based programming via an example of generating fractal images. Most importantly, he shows how to use Mathematica to solve partial differential equations using finite differences, another topic usually not done in other Mathematica books. A brief discussion of how to do tensor manipulation ends the chapter.	2002-02-09
1665531:US	50702879	R2Z5BPVF849MUP	007003575X	561387684	Schaum's Outline of Theory and Problems of Combinatorics including concepts of Graph Theory	Books	4	57	58	N	N	Nice job	Combinatorics is an area of mathematics that is frequently looked on as one that is reserved for a small minority of mathematicians: die-hard individualists who shun the limelight and take on problems that most would find boring. In addition, it has been viewed as a part of mathematics that has not followed the trend toward axiomatization that has dominated mathematics in the last 150 years. It is however also a field that has taken on enormous importance in recent years do its applicability in network engineering, combinatorial optimization, coding theory, cryptography, integer programming, constraint satisfaction, and computational biology. In the study of toric varieties in algebraic geometry, combinatorics has had a tremendous influence. Indeed combinatorial constructions have helped give a wide variety of concrete examples of algebraic varieties in algebraic geometry, giving beginning students in this area much needed intuition and understanding.  It is the the advent of the computer though that has had the greatest influence on combinatorics, and vice versa.The consideration of NP complete problems typically involves enumerative problems in graph theory, one example being the existance of a Hamiltonian cycle in a graph. The use of the computer as a tool for proof in combinatorics, such as the 4-color problem, is now legendary.  In addition, several good software packages, such as GAP and Combinatorica, have recently appeared that are explicitly designed to do combinatorics. One fact that is most interesting to me about combinatorics is that it gave the first explicit example of a mathematical statement that is unprovable in Peano arithmetic. Before coming across this, I used to think the unprovable statements of Godel had no direct relevance for mathematics, but were only interesting from the standpoint of its foundations.<br />This book is an introduction to combinatorics for the undergraduate mathematics student and for those working in applications of combinatorics. As with all the other guides in the Schaums series on mathematics, this one has a plethora of many interesting examples and serves its purpose well. Readers who need a more in-depth view can move on to more advanced works after reading this one. The author dedicates this book to the famous mathematician Paul Erdos, who is considered the father of modern combinatorics, and is considered one of most prolific of modern mathematicians, with over 1500 papers to his credit.<br />The author defines combinatorics as the branch of mathematics that attempts to answer enumeration questions without considering all possible cases. The latter is possible by the use of two fundamental rules, namely the sum rule and the product rule. The practical implementation of these rules involves the determination of permutations and combinations, which are discussed in the first chapter, along with the famous pigeonhole principle. Most of this chapter can be read by someone with a background in a typical college algebra course. The author considers some interesting problems in the \\"Solved Problems\\" section, for example one- and two-dimensional binomial random walks, and problems dealing with Ramsey, Catalan, and Stirling numbers. The consideration of Ramsey numbers will lead the reader to several very difficult open problems in combinatorics involving their explicit values.<br />Generalized permutations and combinations are considered in chapter two, along with selections and the inclusion-exclusion principle. The author proves the Sieve formula and the Phillip Hall Marriage Theorem. In the \\"Solved Problems\\" section, the duality principle of distribution, familiar from integer programming is proved, and the author works several problems in combinatorial number theory. A reader working in the field of dynamical systems will appreciate the discussion of the Moebius function in this section. Particularly interesting in this section is the discussion on rook and hit polynomials.<br />The consideration of generating functions and recurrence relations dominates chapter 3, wherein the author considers the partition problem for positive integers. The first and second identities of Euler are proved in the \\"Solved Problems\\" section, and Bernoulli numbers, so important in physics, are discussed in terms of their exponential generating functions. The physicist reader working in statistical physics will appreciate the discussion on Vandermonde determinants. Applications to group theory appear in the discussion on the Young tableaux, preparing the reader for the next chapter.<br />A more detailed discussion of group theory in combinatorics is given in chapter 4, the last chapter of the book. The author proves the Burnside-Frobenius, the Polya enumeration theorems, and Cayley's theorem in the \\"Solved Problems\\" section. Readers without a background in group theory can still read this chapter since the author reviews in detail the basic constructions in group theory, both in the main text and in the \\"Solved Problems\\" section. Combinatorial techniques had a large role to play in the problem of the classification of finite simple groups, the eventual classification proof taking over 15,000 journal pages and involving a large collaboration of mathematicians. Combinatorics also made its presence known in the work of Richard Borchers on the \\"monstrous moonshine\\" that brought together ideas from mathematical physics and the largest simple group, called the monster simple group.<br />The author devotes an appendix to graph theory, which is good considering the enormous power of combinatorics to problems in graph theory and computational geometry. Even though the discussion is brief, he does a good job of summarizing the main results, including a graph-theoretic version of Dilworth's theorem. Combinatorial/graph-theoretic considerations are extremely important in network routing design and many of the techniques discussed in this appendix find their way into these kinds of applications. The author asks the reader to prove that Dilworths' theorem, the Ford-Fulkerson theorem, Hall's marriage theorem, Konig's theorem, and Menger's theorem are equivalent. A very useful glossary of the important definitions and concepts used in the book is inserted at the end of the book.he consideration of generating functions and recurrence relations dominates chapter 3, wherein the author considers the partition problem for positive integers. The first and second identities of Euler are proved in the \\"Solved Problems\\" section, and Bernoulli numbers, so important in physics, are discussed in terms of their exponential generating functions. The physicist reader working in statistical physics will appreciate the discussion on Vandermonde determinants. Applications to group theory appear in the discussion on the Young tableaux, preparing the reader for the next chapter.<br />A more detailed discussion of group theory in combinatorics is given in chapter 4, the last chapter of the book. The author proves the Burnside-Frobenius, the Polya enumeration theorems, and Cayley's theorem in the \\"Solved Problems\\" section. Readers without a background in group theory can still read this chapter since the author reviews in detail the basic constructions in group theory, both in the main text and in the \\"Solved Problems\\" section. Combinatorial techniques had a large role to play in the problem of the classification of finite simple groups, the eventual classification proof taking over 15,000 journal pages and involving a large collaboration of mathematicians. Combinatorics also made its presence known in the work of Richard Borchers on the \\"monstrous moonshine\\" that brought together ideas from mathematical physics and the largest simple group, called the monster simple group.<br />The author devotes an appendix to graph theory, which is good considering the enormous power of combinatorics to problems in graph theory and computational geometry. Even though the discussion is brief, he does a good job of summarizing the main results, including a graph-theoretic version of Dilworth's theorem. Combinatorial/graph-theoretic considerations are extremely important in network routing design and many of the techniques discussed in this appendix find their way into these kinds of applications. The author asks the reader to prove that Dilworths' theorem, the Ford-Fulkerson theorem, Hall's marriage theorem, Konig's theorem, and Menger's theorem are equivalent. A very useful glossary of the important definitions and concepts used in the book is inserted at the end of the book.	2002-02-05
1668485:US	50702879	R1NJ4K9T0U3XYT	0716760347	190572905	A Journey into Gravity and Spacetime ("Scientific American" Library)	Books	5	34	38	N	N	The author's mind has no boundary....	This author is one of the most briliant, the most optimistic, and the most enthusiastic writer in all of physics, and in this book, his competence as a physicist and his deep fascination with the physical world is brought out dramatically.  He is clearly a man who is feeling a powerful sense of exhiliration of the discoveries now taking place in all areas of knowledge. His foundation and his theme in the book is a simple geometric principle, namely that the boundary of a boundary is zero. He then guides the reader, assumed to have a rudimentary knowledge of mathematics, in a splendid presentation of the power of this principle in gravitational physics.<br />The first chapter is an overview of the history behind the subject, via the work of people who contributed to our current understanding of gravity. And then, with a masterfull use of diagrams he gives the reader a taste of the simplicity of the equivalence principle and the need to tack on an additional dimension (time) to the 3-dimensional space of everyday experience. The Pound-Rebka experiment is discussed as one that illustrates the idea of the spacetime interval, and the role of time dilation is discussed via the possibility of practical space travel.  And such enthusiasm in his dialog: &quot;the universe will grow ever more exciting&quot;, he says, and looking at the developments now taking place in today's science, he is indeed correct.<br />Chapter 4 gives a fascinating overview of what the author calls the boomerang, which illustrates the action of curvature on nearby test masses. This thought experiment involves the motion of a spacecraft through an imaginary tunnel through the Earth. The author analyzes the motion from the standpoint of Newtonian physics and general relativity. Curvature as the &quot;grammar of gravity&quot; is the topic of the next chapter, with illustrations of the paths of ants on spaces of zero, positive, and negative curvature. A very intuitive treatment of parallel transport around a closed path on a curved surface is given. The tides are discussed as a natural manifestation of the gravitational influence of the Moon on Earth.<br />Must difficult for a layman to understand is how spacetime acts on masive objects, but the author explains it brilliantly in the next chapter, taught via the concept of &quot;momenergy&quot;.  This entity is a 4-vector, and the author uses it to show how its creation in a spacetime region can be written as the sum of 8 terms, reflecting the fact that the &quot;boundary&quot; of a four-dimensional block in spacetime consists of eight three-dimensional cubes. That the contents of these cubes sum to zero is the famous &quot;boundary of a boundary is zero&quot;, which is discussed in the next chapter. This chapter is one of the best explanations ever given (at this level) of the physics behind  spacetime curvature and massive objects. The actual mathematical quantification of curvature is detailed in chapters 8 and 9, using elementary mathematics. The author discusses nicely the famous Scharwzschild geometry.<br />Concepts of a more concrete nature are discussed in chapter 10, wherein the author discusses the famous Pound-Rebka experiment and planetary motion.  This is followed by a discussion of the elusive gravitational waves in chapter 11. Again with a clever use of illustrations, the author explains the transverse property of gravitational waves, and compares gravitational waves with electromagnetic waves. The role of the quadrupole moment in the creation of gravitational waves is brought out briliantly by the author. He discusses briefly various attempts to detect gravitational waves.<br />Black holes are the topic of chapter 12, wherein the famous Penrose process for extracting energy from a black hole is discussed, and the &quot;no-hair&quot; theorem for black holes. A neat symbolic representation of the Bekenstein number of a black hole is given. The role of the Hawking process, connection quantum processes with the physics of black holes is briefly discussed. The author ends the book with a look at the expansion of the universe, the missing mass problem, and another very interesting topic that has gained much attention recently: the concept of gravitomagnetism. This is a &quot;weak-field&quot; prediction of general relativity, and predicts that the rotation of the Earth should influence the motion of orbiting satellites. This topic is currently bringing together ideas such as the quantum Zeno effect, Mach's principle, and the notorious &quot;frame dragging&quot; effect in general relativity. Experiments do measure it are currently in play and in the proposal stage, namely the LAGEOS and LAGEOS II experiments, which measure the gravitomagnetic orbital perturbation, which is known as the Lense-Thirring effect.sses with the physics of black holes is briefly discussed. The author ends the book with a look at the expansion of the universe, the missing mass problem, and another very interesting topic that has gained much attention recently: the concept of gravitomagnetism. This is a &quot;weak-field&quot; prediction of general relativity, and predicts that the rotation of the Earth should influence the motion of orbiting satellites. This topic is currently bringing together ideas such as the quantum Zeno effect, Mach's principle, and the notorious &quot;frame dragging&quot; effect in general relativity. Experiments do measure it are currently in play and in the proposal stage, namely the LAGEOS and LAGEOS II experiments, which measure the gravitomagnetic orbital perturbation, which is known as the Lense-Thirring effect.	2002-02-03
1670026:US	50702879	R3UMTOKBB7K47Z	0691023522	511015403	The Meaning of Relativity	Books	5	46	50	N	N	Will never collect dust....	There are numerous books on general relativity currently on the market, and these range in difficulty from those written for the beginner or the layman, those written for graduate students in physics, and research monographs covering specialized topics. It is always refreshing to go back to the originator of the subject, and take part in his special insights on the topic. Philosophers and historians of science can definitely benefit from a perusal of this book.<br />The author begins this book with a discussion of the origin of the concepts of space-time, the emphasis being partly philosophical and partly psychological, and the reader can see the origin of the author's operationalism in reading this introduction. He is clearly against the philosophers who attempt to remove concepts from experience and put them in his words &quot;in the intangible heights of the a priori&quot;. The motion of rigid bodies is used to set up a discussion of Euclidean geometry and linear orthogonal transformations. The author emphasizes the role of the physicist in discerning whether a system of geometry is true or not, contrary to the pure mathematician. Examples of geometrical invariants, such as the Cartesian line element and the volume element are discussed, along with the role of vectors and tensors. Both of these are used as means by which one can give expression to the independence of Cartesian coordinates. Maxwell's equations are put in tensor notation as an example of covariance with respect to Cartesian coordinate transformations. All of this is done to motivate the theories of special and general relativity.<br />The theory of spectial relativity is treated in chapter 2, the author introducing his famous principle of special relativity. The author poses the problem of calculating the coordinates and time in an inertial system moving with uniform translation relative to another. He shows how this problem is solved by assuming that time and space are absolute, and if the coordinate axes of the systems are parallel to one another, the Galilean transformations result. Newton's equations of motion are covariant under these transformations, but Maxwell equations are not (but the author chooses not to show this explicitly). He then gives an in-depth discussion of how the Lorentz transformations arise as being those that guarantee the covariance of the Maxwell equations. The author also discusses the signature of the Lorentz metric and how it is related to the light cone. He ends the chapter by developing the energy tensor of the electromagnetic field and matter.<br />The author's rejection of inertial frames as being priveleged leads him in the beginning of the next chapter to a short philosophical critique of the principle of inertia. This leads to a discussion of the principle of equivalence and to the origin of the general theory of relativity, a theory which the author developed, amazingly, single-handedly, and which he clearly believes is very much superior to classical mechanics. The intuition to be gained by reading this chapter is invaluable for serious students of general relativity. One can see the simplicity and power of the author's arguments, relying on keen physical intuition and sound use of mathematics. In particular, the author's heuristic derivation of the gravitational field equations from Poisson's equation is briliant. In addition, he is not ashamed to interject philosophical argumentation into his writing, particularly in his discussion of Mach's principle. Such discussions are becoming more rare among physicists at the present time.dinate axes of the systems are parallel to one another, the Galilean transformations result. Newton's equations of motion are covariant under these transformations, but Maxwell equations are not (but the author chooses not to show this explicitly). He then gives an in-depth discussion of how the Lorentz transformations arise as being those that guarantee the covariance of the Maxwell equations. The author also discusses the signature of the Lorentz metric and how it is related to the light cone. He ends the chapter by developing the energy tensor of the electromagnetic field and matter. <br />The author's rejection of inertial frames as being priveleged leads him in the beginning of the next chapter to a short philosophical critique of the principle of inertia. This leads to a discussion of the principle of equivalence and to the origin of the general theory of relativity, a theory which the author developed, amazingly, single-handedly, and which he clearly believes is very much superior to classical mechanics. The intuition to be gained by reading this chapter is invaluable for serious students of general relativity. One can see the simplicity and power of the author's arguments, relying on keen physical intuition and sound use of mathematics. In particular, the author's heuristic derivation of the gravitational field equations from Poisson's equation is briliant. In addition, he is not ashamed to interject philosophical argumentation into his writing, particularly in his discussion of Mach's principle. Such discussions are becoming more rare among physicists at the present time.	2002-02-02
1674750:US	50702879	R3F36B3VQ4URPA	0521663954	496826361	Computer Science with MATHEMATICA &#174;: Theory and Practice for Science, Mathematics, and Engineering	Books	4	29	32	N	N	A good overview	As a symbolic programming language, and as one that can effectively emulate most programming paradigms, Mathematica is unequaled. In this book, the author makes this abundantly clear as he takes the reader through a sampling of the power of Mathematica, with the target reader being a computer scientist without a knowledge of Mathematica.<br />After a very brief review of computer concepts and architectures in chapter 1, the author begins chapter 2 with an overview of the syntax of Mathematica. The most helpful points in this chapter were: 1. How to implement piecewise-defined functions. 2. Pure functions. 3. The ability of Mathematica to do functional programming via functional operations. 4. Normal expressions and atoms.<br />Chapter 3 is an introduction to iteration and recursion. The author begins the chapter by showing how to use rule-based or recursive programs to construct a program to calculate the greatest common divisor of two integers. He is careful to note however that the use of recursion may be inefficient and so he shows how to convert the program to one that uses loop iteration. The contrast in inefficiency between iterative and recursive programs is illustrated again in the next section which deals with the Collatz problem. An iterative computation of the Collatz sequence is given, and the author encourages the use of loops and not recursion, to obtain efficient programs. The author shows how to use loop invariants to test program correctness for loops. The engineer/physicist reader will appreciate the application of iterative methods to the solution of ordinary differential equations.<br />In chapter 4, the author shows how to build packages in Mathematica, via an example in complex variables. The role of contexts in Mathematica is made very clear, as well as how to handle options in the package.<br />A discussion of abstract data types follows in chapter 5. The author defines these in the usual sense of being independent of implementation and he introduces the concept of a model. The ring of modular numbers is chosen as an example of how to design and implement data types in Mathematica, and he shows how to make the data type for this ring independent of implementation by using constructors and selectors. The discussion in this chapter is not found in the usual Mathematica books, so it is invaluable for a more in-depth view of the capabilities of Mathematica to handle abstract data types.<br />Topics of a more applied nature are discussed in chapter 6, wherein the author gives Mathematica algorithms for sorting and searching. The graphics capability of Mathematica is used to illustrate the properties of these algorithms and the author shows how to design a binary search algorithm that is polymorphic, i.e. one that can be used to search collections of data of different types. Dynamic data structures are illustrated via the binary tree.<br />The computational complexity of algorithms is discussed in chapter 7. The author uses the computation of the nth Fibonacci number to compare the complexity of different algorithms. A recursive algorithm is given for this computation, and shown to be of exponential complexity. This algorithm is improved upon (given a quadratic dependence in the number of steps) by using a technique from dynamic programming, wherein each computed Fibonacci number is stored as a rule. For those involved in encryption algorithms, the discussion on long-integer arithmetic and fast multiplication should be helpful. The Karatsuba method for multiplying two integers is implemented in Mathematica.<br />Chapter 8 is devoted to linear algebra, wherein the author shows how to implement basic matrix multiplication and inner and outer products in Mathematica. In addition, he shows how to do vector calculus using Mathematica, and defines the divergence operator, the gradient, the Jacobian, and Laplacian. Most importantly, the author shows how to program with dynamic data structures in Mathematica, this being relatively straightforward since Mathematica does garbage collection. The heap data structure is analyzed in detail as an example.<br />Chapter 9 is a more detailed overview of lists and recursion in Mathematica. Readers interested in artificial intelligence will appreciate the discussion because of the connection with the LISP programming language. Although short, the author does give a convincing treatment of how to operate on data structures via their selectors and constructors.<br />The discussion in chapter 9 on rule-based programming was the most important to me, as it was helpful in bringing out the pattern matching capabilities of Mathematica. If one is attempting to implement such as inductive logic programming or stochastic logic programming in Mathematica, this chapter is a good start in that regard.<br />Chapter 11 could be viewed as a discussion of how the lambda calculus from mathematical logic is implemented in Mathematica. The ability of Mathematica to emulate functional programming is one of its most powerful features, and this is illustrated nicely here.<br />The topics in chapter 12 are more theoretical in nature, and those interested in this facet of computer science will find the discussion on primitive recursive functions fairly convincing. In addition, the author gives the Mathematica code for simulating a Turing machine. He shows via Mathematica, that recursive functions are Turing computable.<br />The author gives an introduction to databases in chapter 13. He shows how to perform the relational algebra in relational databases using Mathematica. Although the practical value of this chapter is limited since one would probably not want to access databases using Mathematica, the treatment does allow an understanding of how databases are constructed.<br />The last chapter of the book is a very interesting discussion on how to implement object oriented programming in Mathematica. The author shows how to implement containers using Mathematica and gives the class hierarchy associated with the collections. The interval, list, and set are given as implementations of collections, and the array and dictionary is given as an implementation of an indexed collection.his being relatively straightforward since Mathematica does garbage collection. The heap data structure is analyzed in detail as an example. <br />Chapter 9 is a more detailed overview of lists and recursion in Mathematica. Readers interested in artificial intelligence will appreciate the discussion because of the connection with the LISP programming language. Although short, the author does give a convincing treatment of how to operate on data structures via their selectors and constructors. <br />The discussion in chapter 9 on rule-based programming was the most important to me, as it was helpful in bringing out the pattern matching capabilities of Mathematica. If one is attempting to implement such as inductive logic programming or stochastic logic programming in Mathematica, this chapter is a good start in that regard. <br />Chapter 11 could be viewed as a discussion of how the lambda calculus from mathematical logic is implemented in Mathematica. The ability of Mathematica to emulate functional programming is one of its most powerful features, and this is illustrated nicely here. <br />The topics in chapter 12 are more theoretical in nature, and those interested in this facet of computer science will find the discussion on primitive recursive functions fairly convincing. In addition, the author gives the Mathematica code for simulating a Turing machine. He shows via Mathematica, that recursive functions are Turing computable. <br />The author gives an introduction to databases in chapter 13. He shows how to perform the relational algebra in relational databases using Mathematica. Although the practical value of this chapter is limited since one would probably not want to access databases using Mathematica, the treatment does allow an understanding of how databases are constructed. <br />The last chapter of the book is a very interesting discussion on how to implement object oriented programming in Mathematica. The author shows how to implement containers usingMathematica and gives the class hierarchy associated with the collections. The interval, list, and set are given as implementations of collections, and the array and dictionary is given as an implementation of an indexed collection.	2002-01-29
1678392:US	50702879	R1QKXHX40PYOKZ	038790218X	957485180	General Relativity for Mathematicians (Graduate Texts in Mathematics)	Books	4	13	15	N	N	As the title says....	It is too bad this book is out of print, as it is nicely written and addresses a mathematically sophisticated reader with a solid background in differential geometry. It is written by two very competent mathematicians, and still could be read as background for more modern developments in general relativity, particularly singularity theorems and as mathematical preparation to the current research in quantization of gravity. It could serve as a textbook in a class the mathematical foundations of general relativity at the graduate level.	2002-01-26
1686080:US	50702879	RPZO76ZTCJSPF	1563963949	297567897	Lorentzian Wormholes: From Einstein to Hawking (Aip Series in Computational and Applied Mathematical Physics)	Books	5	21	22	N	N	Buy a used copy	Some of the words in this book have appeared in movies and science fiction stories, but in this book they take on a mathematical/scientific meaning, thanks to the efforts of the author. Although the concepts in the book are still far-removed from experimental verification, one must credit the author with writing of a book that may be standard reading in centuries to come. When reading the book, one can only hope that its ideas, or some similar to them, will eventually allow humans to traverse time and space routinely. The reader will need a strong background in general relativity and quantum field theory to really appreciate the book, but after reading it will obtain a solid understanding of what might be calle, in the words of the author, &quot;non-boring&quot; physics.<br />After a brief overview of general relativity and quantum field theory, the author devotes the first part of the book to the history of wormhole physics. I was surprised to learn that the study of wormholes goes as far back as 1916 in paper by the physicist L.Flamm. But it was the desire of A. Einstein and N. Rosen to build a geometrical model of an elementary particle that is finite and singularity-free that set the tone for the research that continues to this day. Their ideas are reviewed in detail, and the author shows that viewing elementary particles as they did predicts they have internal structure, contrary to experiment. The contributions of J.A. Wheeler, namely his interest in topological issues in general relativity, and his geon/spacetime foam ideas are discussed also. The role of wormhole physics in developing a quantum theory of gravity, via the quantization of weak field gravity and the subsequent appearance of gravitons is treated also. The author lists the things that be done with quantized linearized gravity and gives references for research that counters the idea of spacetime foam. &quot;Back-of-the-envelope&quot; calculations are given for the importance of quantum fluctuations in the gravitational field at Planckian scales. A very interesting, and critical discussion is given of topology changes of spacetime via quantum fluctuations. The author states (but does not prove) various theorems regarding the topology of spacetime if a Lorentz metric is put on it. These results are pretty restrictive in limiting the existence of certain topology changes, but as the author remarks, one can abandon the idea of spacetime being everywhere-Lorentzian if one gives up the strong equivalence principle, an idea he clearly is not comfortable with. Given his remarks, it is interesting to ask whether quantum fluctuations could force a violation of the strong equivalence principle. The author does consider the role of quantum tunneling in changing spacetime topology, but concludes that it is not a meaningful question. However, he does devote a brief paragraph to the consideration of an energy-dependent effective topology which is the one of relevance to physics. Based on the &quot;quantum claustrophobia&quot; effect arising from the tendency of a particle to avoid small regions (i.e Heisenberg uncertainty), some regions of spacetime may thus not be visible from a quantum point of view. The author gives one example of this, but this idea has far-reaching consequences: not just for physics but for mathematics. If viewed from a quantum perspective, many of the usual mathematical structures in topology and other areas of mathematics are changed considerably. One can then perform a kind of interpolation between &quot;quantum&quot; and &quot;classical&quot; mathematical constructions.<br />The author switches to more modern developments in part 3, with the idea of a traversable wormhole due to M. S. Morris and K.S. Thorne leading off the discussion. These wormholes are shown to violate the weak, strong, and dominant energy conditions, implying the existence of negative energy density near the throat of the wormhole. The existence of this energy will remind the reader of the Casimir effect, and the author does discuss this effect in detail. In addition, the thin shell formalism is discussed as a tool to analyze traversable wormholes without spherical geometry. Global techniques and the topological censorship are used to give a mathematically precise definition of a traversable wormhole, although the censorship theorem is not proven.<br />Part 4 attempts to remove the idea of time travel from pure fantasy science fiction and give it more of a scientific foundation. The author is convincing in his efforts, via his thorough analysis of causality conditions in spacetime, and the explicit constructions of simple time machines, which in the author's words are a consequence of general relativity being &quot;infested&quot; with geometries that produce them. The van Stockum, Godel, Kerr, and Gott tiem machines are discussed in detail, and the author shows explicitly how to construct time machines via wormholes. He also addresses the problems that arise in the actual construction of these time machines, such as the possibility of a non-Hausdorff topology, the problem of unique histories (Novikov conjecture), the breakdown of unitarity in the quantum realm, and the Hawking chronology protection conjecture.<br />Section 5 is an overview of the quantum field theory needed for a study of wormhole physics. The author shows that time- and space-orientable spacetimes are incompatible with the Standard model. He discusses in detail the result that the ANEC condition can be violated by scale anomalies. Readers will have to have a very detailed knowledge of quantum field theory in curved spacetime to follow the discussion. The calculation of van Vleck determinants, familiar as Green function techniques, are done also. The stress-energy tensor is calculated explictly for traversable wormhole spacetimes. The Wheeler-DeWitt minisuperspace formalism is used to shed light on the quantum aspects of Lorentzian wormholes, and the Wheeler-DeWitt equation for Einstein gravity on minisuperspace is solved exactly.<br />The last part of the book is more of a send off to the reader and an encouragement for further reading on the issues in the book A list of research problems in given for the ambitious and curious reader.reader of the Casimir effect, and the author does discuss this effect in detail. In addition, the thin shell formalism is discussed as a tool to analyze traversable wormholes without spherical geometry. Global techniques and the topological censorship are used to give a mathematically precise definition of a traversable wormhole, although the censorship theorem is not proven. <br />Part 4 attempts to remove the idea of time travel from pure fantasy science fiction and give it more of a scientific foundation. The author is convincing in his efforts, via his thorough analysis of causality conditions in spacetime, and the explicit constructions of simple time machines, which in the author's words are a consequence of general relativity being &quot;infested&quot; with geometries that produce them. The van Stockum, Godel, Kerr, and Gott tiem machines are discussed in detail, and the author shows explicitly how to construct time machines via wormholes. He also addresses the problems that arise in the actual construction of these time machines, such as the possibility of a non-Hausdorff topology, the problem of unique histories (Novikov conjecture), the breakdown of unitarity in the quantum realm, and the Hawking chronology protection conjecture. <br />Section 5 is an overview of the quantum field theory needed for a study of wormhole physics. The author shows that time- and space-orientable spacetimes are incompatible with the Standard model. He discusses in detail the result that the ANEC condition can be violated by scale anomalies. Readers will have to have a very detailed knowledge of quantum field theory in curved spacetime to follow the discussion. The calculation of van Vleck determinants, familiar as Green function techniques, are done also. The stress-energy tensor is calculated explictly for traversable wormhole spacetimes. The Wheeler-DeWitt minisuperspace formalism is used to shed light on the quantum aspects of Lorentzian wormholes, and the Wheeler-DeWitt equation for Einstein gravity on minisuperspace is solved exactly. <br />The last part of the book is more of a send off to the reader and an encouragement for further reading on the issues in the book A list of research problems in given for the ambitious and curious reader.	2002-01-21
1686893:US	50702879	RN7BTAE8QJRV8	0716703440	914376472	Gravitation	Books	5	45	51	N	N	The Bible of gravitational physics	By size and content, this book ranks as one of the largest in physics . Not only does it give an excellent discussion of all of the concepts in gravitational physics, but it gives clear presentations of the relevant mathematics, not hesitating at all to employ useful diagrams and pictures. Truly a classic, it is a work that is sure to be read by future generations of students in gravitational physics. I can still remember the excitement I felt when picking the book up for the first time. The authors are giants in the field, and it is great that they chose to take the time to write such an excellent book. It is readily apparent that they care a great deal about what the reader will take away after reading such a large book, as the presentation is always crystal clear and a great joy to read.<br />Space prohibits a thorough review, so I will instead highlight the parts of the book that I found particularly exceptional: 1. The example of how coordinate singularities arise: the &quot;cells of the egg crate&quot; squashed to zero volume. 2. The beautiful illustration of the Roll-Krotkov-Dicke experiment. 3. The &quot;physics demo&quot; of a local inertial frame of reference (it is not very difficult to construct this demonstration for actual use in a classroom). 4. The presentation of a 2-form as a honeycomb of tubes with a sense of circulation. Such an explanation is lacking in the general mathematical literature. 5. The flying ring demonstration illustrating Faraday stresses. This demonstration is done very often in physics classes, and is simple to set up. 6. The excellent discussion (with illustrations) of the covariant derivative and the Schild ladder construction. 7. The presentation of parallel transport around a closed curve. 8. The treatment of Riemann normal coordinates. These are typically presented in a purely formal way in most texts on general relativity, ignoring their status as providing a local inertial frame in curved spacetime. 9. The (philosophical) discussion on the principal of general covariance in the context of Newtonian gravity in tensorial form. 10. The illustration, with accompanying discussion, on a situation where two events can be connected by more than one geodesic. The authors mention the relation of this example to the Morse theory of critical points. 11. The discussion of the Bianchi identities and the topological result on the boundary of a boundary being empty. 12. The discussion on the gravity gradiometer. 13. The exceptional discussion on six routes to the Einstein field equation. 14. The variational principle and the initial value problem in the Einstein equation. 15. The connection between the Gauss-Weingarten equations and extrinsic curvature. 16. The ADm formulation of the dynamics of geometry. 17. The discussion on Mach's principle. 18. The radial oscillations of a Newtonian star. 19. The Hamilton-Jacobi description of motion and its employment in analyzing the central force problem. 20. The effect of the value of the cosmological constant on cosmological models and evolution of the universe. 21. The cosmological redshift and its explanation via the expansion of the universe. 22. The mathematics of the Mixmaster cosmology. 23. The dynamics of the Schwarzschild geometry. 24. The discussion on the global properties of spacetime and singularity theorems. 25. The short biographies of Hawking and Penrose. 26. The quadrupole nature of gravitational radiation. 27. The experimental justification of general relativity, particularly the description of Pound-Rebka experiment on the gravitational redshift.discussion on the principal of general covariance in the context of Newtonian gravity in tensorial form. 10. The illustration, with accompanying discussion, on a situation where two events can be connected by more than one geodesic. The authors mention the relation of this example to the Morse theory of critical points. 11. The discussion of the Bianchi identities and the topological result on the boundary of a boundary being empty. 12. The discussion on the gravity gradiometer. 13. The exceptional discussion on six routes to the Einstein field equation. 14. The variational principle and the initial value problem in the Einstein equation. 15. The connection between the Gauss-Weingarten equations and extrinsic curvature. 16. The ADm formulation of the dynamics of geometry. 17. The discussion on Mach's principle. 18. The radial oscillations of a Newtonian star. 19. The Hamilton-Jacobi description of motion and its employment in analyzing the central force problem. 20. The effect of the value of the cosmological constant on cosmological models and evolution of the universe. 21. The cosmological redshift and its explanation via the expansion of the universe. 22. The mathematics of the Mixmaster cosmology. 23. The dynamics of the Schwarzschild geometry. 24. The discussion on the global properties of spacetime and singularity theorems. 25. The short biographies of Hawking and Penrose. 26. The quadrupole nature of gravitational radiation. 27. The experimental justification of general relativity, particularly the description of Pound-Rebka experiment on the gravitational redshift.	2002-01-20
1687646:US	50702879	R1ITKV33OZTCSQ	0387978828	476261701	Economic and Financial Modeling with Mathematica	Books	3	27	27	N	N	Somewhat dated...but still helpful	For the reader well-versed in Mathematica and in economic theory, this book gives a fairly good overview of how Mathematica can be used to study mathematical economics and finance. It is also assumed in the articles in the book that the reader has a strong background in mathematics. Since the book was published in 1993, Mathematica has considerably expanded, with many new features that make some of the accompanying code in the book somewhat dated, but the notebooks can still be used beneficially.In addition, economic theory is currently making more use of symbolic programming, and financial analysis has exploded as an area which is now making heavy use of high-performance computing. Although Mathematica cannot compete from a performance standpoint with the needs of financial engineering, it still has an advantage from a didactic standpoint. I did not read all of the articles in the book, so my comments will be limited to the ones that I did.<br />The article on &quot;Mathematica and Diffusions&quot; is an overview of how to use Mathematica to do stochastic calculus. The Ito calculus is reviewed briefly, and the authors begin with constructing a Weiner process. The Mathematica package they employ and on the disk accompanying the book is not discussed in detail, but is merely used to simulate realizations of the process. Readers who want a more in-depth view will have to go over the code themselves. The authors use the package to generate realizations of Weiner processes that are correlated with each other, and show this correlation via Mathematica graphics. The Black-Scholes formula is derived using the standard self-financing trading strategy and ignoring transaction costs and dividends. The algebraic manipulations are done with Mathematica, and this obscures (a little) the underlying concepts behind the derivation of this important formula. Since data structures in Mathematica are essentially lists, the authors outline the construction of the data structure that could be used to represent a diffusion, namely a list consisting of five terms: the diffusion, Weiner process name, expression for the drift and dispersion, and the initial value. For the reader familiar with OO-programming, accessor functions are used to extract the components of this data structure. This is a nice move by the authors, for it is an example of how Mathematica can be used to emulate OO-programming.<br />The article &quot;Itovsn3: Doing Stochastic Calculus with Mathematica&quot; is an overview of how to use the Itovsn3 package that is on the disk to implement Ito calculus. It is assumed that the reader has a background in stochastic calculus, since the author does not give a review. However, semimartingales, so important to those working in financial engineering, are discussed and their statistical behavior described using Mathematica. The Ito formula is presented as a semimartingale-type decomposition for smooth function of Brownian motion and the author shows using Mathematica plots how the higher order terms in the second-order Taylor expansion vanish asymptotically. This article is not merely Mathematica code for Ito calculus, for the author gives an example of how to use the package in a hedging problem.<br />The article &quot;Option Valuation&quot; is a more detailed overview of how to use Mathematica in the context of the Black-Scholes model to perform options valuation and risk management. Heavy use is made of the graphics capability of Mathematica to illustrate how option values change as a function of stock price and time of expiration. The author also shows how Mathematica can be used as a OO-language to treat options as self-contained objects with accessor functions. He does however state that Mathematica does not live up to the OO toolkits available elsewhere, contrary to my experience. He closes the article with a consideration of how to use Mathematica to value options that can be exercised before expiry, the binomial model playing the central role in the discussion. It is here in particular that the performance of Mathematica is readily felt. The numerical number-crunching needed to do the calculations in these types of models cannot be done in Mathematica efficiently and profitably.<br />The article &quot;Time Series Models and Mathematica&quot; gives a general treatment on how Mathematica can be used to study ARIMA models for time series. Mathematica is used more interactively than the other articles and the visualization obtained is quite nice in giving the reader insight into such concepts as the moving average and the spectral density function. The author shows how to estimate the spectral density function and why periodogram techniques fall short in this estimation. I would have liked to see other techniques for studying time series discussed, such as neural networks and hidden Markov models, but the author does do a fairly good job with the ARIMA models.ntral role in the discussion. It is here in particular that the performance of Mathematica is readily felt. The numerical number-crunching needed to do the calculations in these types of models cannot be done in Mathematica efficiently and profitably.<br />The article &quot;Time Series Models and Mathematica&quot; gives a general treatment on how Mathematica can be used to study ARIMA models for time series. Mathematica is used more interactively than the other articles and the visualization obtained is quite nice in giving the reader insight into such concepts as the moving average and the spectral density function. The author shows how to estimate the spectral density function and why periodogram techniques fall short in this estimation. I would have liked to see other techniques for studying time series discussed, such as neural networks and hidden Markov models, but the author does do a fairly good job with the ARIMA models.	2002-01-19
1689691:US	50702879	R17E8CPTCA2LR8	0521099064	419597976	The Large Scale Structure of Space-Time (Cambridge Monographs on Mathematical Physics)	Books	5	44	45	N	N	A classic in mathematical general relativity	This book is now a classic and is written by two giants in mathematics and physics. It wil be used for many years to come and is certainly one of the most widely quoted in the subject.<br />The authors begin the book by a discussion of the role of gravity in physics and its role as determining the causal structure of the universe. They introduce the idea of a closed trapped surface, setting the stage for the goal of the book, namely the study of the conditions under which a space-time singularity must occur. Black holes and the beginning of the universe are cited as examples of these singularities. The authors also outline briefly the content of each chapter. A neat argument is given for the significance of focal points via the use of Raychaudhari's equation.<br />The second chapter is an overview of the background in differential geometry needed in the rest of the book. Although complete from an axiomatic point of view, the approach is much too formal for readers who do not have a knowledge of differential geometry. Such a reader should gain the necessary background elsewhere.<br />General relativity as a theory of gravitation is discussed in chapter 3. Spacetime is assumed to be a connected 4-dimensional smooth  manifold on which is defined a Lorentz metric. The topology  is assumed to be Hausdorff. Some of the more interesting or well-written parts of this chapter include the example of a spacetime that is not inextendible, the determination of the conformal factor for the spacetime metric, and the discussion of alternative field equations.<br />The authors discuss the physicial significance of curvature in chapter 4, namely its effect on families of timelike and null curves. The most important part of this chapter is the discussion on certain inequalities tht the energy-momentum tensor should satisfy from a physical viewpoint. These inequalities, called the weak energy condition and the dominant energy condition, allow the authors to prove the existence of singularities in  a later chapter. The reader can see clearly the role of the Jacobi equation, and its solution, the Jacobi field, in measuring the separation of nearby geodesics. The existence of conjugate points is proven, and shown to imply the existence of self-intersections in families of geodesics. As a warm-up to showing the non-existence of geodesics of maximal length, the authors employ variational calculus to study how to vary non-spacelike curves connecting points in convex normal neighborhoods in spacetime, and between points and hypersurfaces. In particular, it is shown that a timelike geodesic curve from a hypersurface to a point is maximal iff there is no conjugate point to the hypersurface along the curve. In addition, the authors prove that two points joined by a non-spacelike curve which is not a null geodesic can be joined by a timelike curve.<br />The authors consider the exact solutions of the Einstein field equations in chapter 5. Most of the &quot;usual&quot; spacetimes are considered, including Minkowski, De Sitter, Anti-de-Sitter, Robertson-Walker, Schwarzschild, Reissner-Nordstrom, Kerr, Taub-Nut, and Godel. The emphasis in on the global properties of the spacetimes and the existence of singularities in them. The famous Penrose diagrams are used to &quot;compactify&quot; spacetimes in order to study their behavior at infinity and their conformal properties. The authors first introduce the concept of a future (past) Cauchy development here, so important in later developments in the book. The reader can see the tools developed in chapter 4 in play here; for example, the existence of a singularity in a spatially homogeneous cosmology is shown to follow directly from the Raychaudhuri equation. The existence of the singularity is proved to be independent of any acceleration or rotation of matter in such cosmologies.<br />In chapter 5, the authors consider the causal structure of spacetime, namely the study of its conformal geometry. The considerationof the set of all metrics conformal to the physical metric allows one to discuss &quot;geodesic completeness&quot; of spacetime, this concept forming the basis of a later definition of a singularity in spacetime. The more interesting topics discussed in this chapter include the causality conditions (there are no closed non-spacelike curves), and the Alexandrov topology and its connection with the strong causality condition (every neighborhood of a point contains a neighborhood of the point no non-separable curve of which intersects it more than once). When strong causality does hold, the Alexandrov topology is equivalent to the usual manifold topology, and thus the topology of spacetime can be determined by the observation of causal relationships. The discussion on the role of global hyperbolicity in showing the existence of a maximal geodesic is also very well-written.<br />The next chapter is pretty much independent of the rest, and was put in no doubt for the mathematician who desires to understand the Einstein equations as a set of nonlinear second-order hyperbolic partial differential equations with initial data on a 3-dimensional manifold, the famous Cauchy problem in general relativity.<br />Chapter 8 is the most important in the book, for its uses the constructions of earlier chapters to define the notion of a singularity in spacetime. The authors argue that singularities are points where physical laws break down and thus to characterize them one attempts to find out whether any such points have been removed, making spacetime &quot;incomplete&quot; in some sense. Such a notion of incompleteness is very meaningful in topological spaces with a positive definite metric, since in that case one can define completeness in terms of the convergence of Cauchy sequences. In spacetimes with a Lorentz metric, the authors discuss the notion of geodesic completeness for null and timelike geodesics. A very detailed treatment of the now famous singularity theorems is given, these theorems involving an inequality of the Ricci tensor. The last two chapters of the book are more physical in nature wherein the singularity problem is shown to have physical relevance via the occurence of black holes at the endpoint of evolution of massive stars.eration of the set of all metrics conformal to the physical metric allows one to discuss &quot;geodesic completeness&quot; of spacetime, this concept forming the basis of a later definition of a singularity in spacetime. The more interesting topics discussed in this chapter include the causality conditions (there are no closed non-spacelike curves), and the Alexandrov topology and its connection with the strong causality condition (every neighborhood of a point contains a neighborhood of the point no non-separable curve of which intersects it more than once). When strong causality does hold, the Alexandrov topology is equivalent to the usual manifold topology, and thus the topology of spacetime can be determined by the observation of causal relationships. The discussion on the role of global hyperbolicity in showing the existence of a maximal geodesic is also very well-written. <br />The next chapter is pretty much independent of the rest, and was put in no doubt for the mathematician who desires to understand the Einstein equations as a set of nonlinear second-order hyperbolic partial differential equations with initial data on a 3-dimensional manifold, the famous Cauchy problem in general relativity. <br />Chapter 8 is the most important in the book, for its uses the constructions of earlier chapters to define the notion of a singularity in spacetime. The authors argue that singularities are points where physical laws break down and thus to characterize them one attempts to find out whether any such points have been removed, making spacetime &quot;incomplete&quot; in some sense. Such a notion of incompleteness is very meaningful in topological spaces with a positive definite metric, since in that case one can define completeness in terms of the convergence of Cauchy sequences. In spacetimes with a Lorentz metric, the authors discuss the notion of geodesic completeness for null and timelike geodesics. A very detailed treatment of the now famous singularity theoremsis given, these theorems involving an inequality of the Ricci tensor. The last two chapters of the book are more physical in nature wherein the singularity problem is shown to have physical relevance via the occurence of black holes at the endpoint of evolution of massive stars.	2002-01-18
1697266:US	50702879	R2X1LWPIA6K9C2	0898710057	993482980	Techniques of Differential Topology in Relativity (CBMS-NSF Regional Conference Series in Applied Mathematics)	Books	5	12	13	N	N	Still a useful overview	First published in 1972, it is remarkable that this book is still in print, and this fact attests to the current interest in singularity theorems in general relativity. The author of course is well-known for his contributions in this area, and he has written these series of lectures primarily for the mathematician whose speciality is differential topology, and who is curious about its applications to general relativity. The author thinks in pictures in this book, and so it is well-suited for the physicist reader also. Detailed proofs are omitted for the singularity theorems, but references are given. Much work and discussion has taken place since this book was published, but it can still serve as an introduction to modern developments.<br />Section 1 sets the mathematical definitions and conventions used in the later sections. Spacetime is defined as a real, four-dimensional connected smooth Hausdorff manifold on which is defined a global smooth nondegenerate Lorentzian metric. In addition, it is assumed that spacetime is time-orientable, which is not too big a restriction since as the author remarks, one can always find a time-orientable twofold covering of spacetime. Jacobi fields are introduced also, with the goal of eventually using them to study maximal geodesics. Known to physicists as the equation of geodesic deviation, the author derives the Jacobi equation, the solutions of which form an 8-dimensional vector space of Jacobi fields.<br />In section 2, the author gives definitions that allow one to discuss causality and time ordering for curves on spacetime. Special types of non-smooth curves, called trips, which (piecewise) are future-oriented timelike geodesics, are used to define a chronological ordering of points on spacetime. Causal trips are more restrictive, in that the curves are causal geodesics. The chronological ordering is shown to imply causal ordering, and both orderings are shown to be transitive. This allows the partitioning of spacetime into chronological future and past, and causal future and past. The topological properties of these sets are studied, and conditions are given in terms of null geodesics and timelike curves for causal and chronological ordering.<br />The next section considers the properties of future and past sets. A future (past) set is one that is equal to the chronological future (past) of some set in spacetime. In addition, subsets of spacetime that do not contain any points that are chronologically related, called achronal sets, and subsets that are boundaries are considered. It is shown that spacetime can be written as the disjoint union of an achronal boundary, and a unique past and future set. It is also shown that achronal boundaries are fairly well-behaved objects: they are 3-dimensional topological manifolds.<br />In order to rule out &quot;pathological&quot; spacetimes that contain closed trips or closed causal trips, the author studies global causality conditions in section 4. Thus the author defines a spacetime to be future (past)-distinguishing if for any two distinct points, their chronological future (past) sets are unequal. He then defines a spacetime to be strongly causal if every point in it has arbitrarily small causally convex neighborhoods (causally convex meaning that it does not intersect a trip in a disconnected set). The author offers examples to show that local violations of causal convexity can be avoided, and so violations of strong causality at a point are due to the global structure of the spacetime. He shows that a spacetime which is strongly causal at a point must be future and past distinguishing at the point. The converse is not true, and the author gives a counterexample. The Alexandrov topology for spacetime is defined in this section also. Given two points in spacetime, a basis for the open sets for this topology is given by the intersection of the chronological future set of one point with the chronological past set of the other. The author showsthat spacetime is strongly causal iff the Alexandrov topology equals the manifold topology iff the Alexandrov topology is Hausdorff. Defining a vicious point to be one through which passes a closed trip, and concentrating attention on the set of all vicious points, the author gives five conditions for strong causality to fail at a point, these conditions involving the boundary of the set of vicious points. He concludes the section by showing that if spacetime is compact, it must contain a closed trip.<br />Motivated by the notion of an initial value set from physicial considerations, the author defines in the next section domains of dependence for achronal subsets of spacetime, along with the future, past, or total Cauchy horizon for closed achronal subsets. These are related to the familiar Cauchy hypersurfaces from the theory of partial differential equations. It is proven that spacetime is globally hyperbolic iff a Cauchy hypersurface exists for it.<br />The space of causal curves is defined in the next section, on which is defined the C0-topology. It is shown to be compact under certain conditions. The study of geodesics as curves of maximal length is taken up in section 7. This entails matters of a more purely differential geometric point of view. The important inequality involving the Ricci curvature and an element of volume (or area) on a hypersurface. The author discusses briefly the importance of this inequality in the singularity theorems.<br />The last section is (unfortunately) very brief, wherein the author discusses the applications of the preceeding sections in singularity theorems. Referring to S. Hawking for the full proof, he gives a general argument and discusses the conditions as to when spacetime will have a past-endless geodesic in M which has a finite length.  He defines a future-trapped set as one where the &quot;future horizon&quot; of the set, defined as the difference between its causal and chronological future, is compact. He then outlines a proof of the result that no spacetime can have the property that it contain no closed trips, have endless causal geodesics containing a pair of conjugate points, and contain a future-trapped set.ows that spacetime is strongly causal iff the Alexandrov topology equals the manifold topology iff the Alexandrov topology is Hausdorff. Defining a vicious point to be one through which passes a closed trip, and concentrating attention on the set of all vicious points, the author gives five conditions for strong causality to fail at a point, these conditions involving the boundary of the set of vicious points. He concludes the section by showing that if spacetime is compact, it must contain a closed trip. <br />Motivated by the notion of an initial value set from physicial considerations, the author defines in the next section domains of dependence for achronal subsets of spacetime, along with the future, past, or total Cauchy horizon for closed achronal subsets. These are related to the familiar Cauchy hypersurfaces from the theory of partial differential equations. It is proven that spacetime is globally hyperbolic iff a Cauchy hypersurface exists for it. <br />The space of causal curves is defined in the next section, on which is defined the C0-topology. It is shown to be compact under certain conditions. The study of geodesics as curves of maximal length is taken up in section 7. This entails matters of a more purely differential geometric point of view. The important inequality involving the Ricci curvature and an element of volume (or area) on a hypersurface. The author discusses briefly the importance of this inequality in the singularity theorems. <br />The last section is (unfortunately) very brief, wherein the author discusses the applications of the preceeding sections in singularity theorems. Referring to S. Hawking for the full proof, he gives a general argument and discusses the conditions as to when spacetime will have a past-endless geodesic in M which has a finite length.  He defines a future-trapped set as one where the &quot;future horizon&quot; of the set, defined as the difference between its causal and chronological future, is compact. He thenoutlines a proof of the result that no spacetime can have the property that it contain no closed trips, have endless causal geodesics containing a pair of conjugate points, and contain a future-trapped set.	2002-01-12
1703447:US	50702879	R13V0ZDRMNRH78	038001159X	687487462	Einstein:: The Life and Times	Books	5	24	25	N	N	Gives you keen insight into a remarkable man	This is probably the most widely read biography on Einstein and with good reason: the author does a fine job of detailing the life of the man who pretty much dominated 20th century physics. It is a cliche now to say that his theories changed the way physicists think about the natural world, and his demeanor and politics continue to be the rage in so-called popular culture. Young students of physics usually get their first taste of advanced mathematical formalism when being introduced to his general theory of relativity, and the author, even though he is not a physics educator, actually does a decent job of explaining the concepts that Einstein was responsible for in his life work. The author does not leave out the politics of the man who continues to be known for his Zionism, and the reader will finish the book with an appreciation of the complexity of his thinking and his personal adherences to this point of view. Some readers may be perplexed on his associaton with the mustard gas researchers Walther Nernst and Fritz Haber, but put in context, as the author does with clarity, readers will see the reasons for this along with Einstein's commitment to the development of atomic weapons.<br /><br />The author also conveys the excitement surrounding the experimental confirmation of some of Einstein's theories, particularly the photoelectric effect and the bending of the light around the Sun. In addition, the reader can appreciate more the concern among many physicists  at the time of Einstein's use of &quot;high-brow&quot; mathematics in general theory of relativity. Now of course, such concern has definitely subsided, for today's theories of gravitation are laden with highly estoric constructions from mathematics. Einstein, as the author notes, was very young when he developed his theories. Modern theories of gravitation, such as superstring and M-theories require such a high level of mathematics that physicists who make contributions in these theories generally spend many years obtaining this background. It is interesting to reflect on how Einstein would have reacted to these theories and elementary particles physics. It is also interesting to ask whether Einstein's politics would be the same if he were alive today, given the current situation in the Middle East. In addition, computers were not available to Einstein in the way there are now to all physicists. Would Einstein have taken to computers? To computational physics? His general theory of relativity is now one of the main applications of high performance computing and symbolic programming.many years obtaining this background. It is interesting to reflect on how Einstein would have reacted to these theories and elementary particles physics. It is also interesting to ask whether Einstein's politics would be the same if he were alive today, given the current situation in the Middle East. In addition, computers were not available to Einstein in the way there are now to all physicists. Would Einstein have taken to computers? To computational physics? His general theory of relativity is now one of the main applications of high performance computing and symbolic programming.	2002-01-07
1704214:US	50702879	RD428EOY3VPLO	0226870332	821236234	General Relativity	Books	4	74	80	N	N	Helpful	There have been many books written on general relativity from both a physical and mathematical viewpoint, but this one stands out as one that is a hybrid between mathematical rigor and physical insight. It is certainly written for the physics student, but mathematicians interested in general relativity can certainly benefit from its perusal. I only read the first nine chapters of the book, so my review will be limited to these.<br />The first chapter is a short introduction to special relativity put in by the author for motivation. And, instead of introducing the mathematical formalism &quot;as needed&quot; in the book, the author chooses to outline it in detail in chapters two and three. The approach taken is a &quot;modern&quot; coordinate-free one, at least from the standpoint of differential geometry, but he delegates to an appendix the relevant background in topology. Since he is targeting the physicist reader, he does not hesitate to use diagrams to explain the concepts. The author introduces the idea of a dual vector using the example of a magnetic field. Tensors are then defined with great clarity from the standpoint of mathematical rigor. The physicist reader may have trouble digesting this if seeing tensors defined this way for the first time, instead of via their transformations properties, as is typically done. The abstract index notation is introduced to deal with the plethora of indices involved in manipulating tensors. In the treatment of geodesics, the author shows that it is sufficient to consider curves that are affinely parametrized, and the geodesic equation is derived in a coordinate basis. Riemannian and Gaussian normal coordinates are discussed as consequences of the unique solution of the geodesic equation. Curvature is also characterized in terms of the geodesic equation and two methods for calculating it are discussed: the coordinate component and tetrad methods, with the Newman-Penrose method briefly discussed. The existence of symbolic programming languages such as Mathematica and Maple make tensor manipulation much less laborius than the author contends in the book.<br />In the next chapter, the principle of general covariance is introduced as one that prohibits the existence of perferred vector fields in the laws of physics. The metric is the only quantity permitted to be related to space in the laws of physics. Thus quantities such as the Christoffel symbols, cannot appear in these laws. The author discusses in detail how general relativity views gravitation in terms of curved spacetime geometry and how Mach's principle is incorporated, the later forcing the spacetime metric to be a  dynamical variable. The author discusses the difficulty in solving the Einstein equation, namely that a simultaneous solution for the spacetime metric and matter distribution is required (since the stress-energy tensor, the &quot;source&quot;, requires knowledge of the spacetime metric for its interpretation). The linearized theory is discussed in detail along with the Newtonian limit. Gravitational waves are shown to follow from the linearized Einstein equation. The effect of energy loss on the orbital period of the Taylor-McCulloch binary star system is discussed as an experimental verification of general relativity.<br />Applications to cosmology are given in chapter 5, which is restricted to the case of homogeneous, isotropic cosmologies. The reader gets introduced to the famous Hubble constant, along with Robertson-Walker and Friedman solutions. A fairly lengthy overview of the evolution of the universe is given.<br />The next chapter is devoted entirely to the Schwarzschild solution, which is used to discuss the four experimental verifications of general relativity, namely the gravitational redshift, the precession of Mercury's orbit, bending of light by the Sun, and the time delay of radar signals. The singularities in the Schwarzschild solution are treated via the Kruskal extension.<br />Methods for obtainingphysically realistic solutions are discussed in chapter 7, most of these being obtained by exploiting stationarity and symmetry properties. Perturbation theory is discussed very briefly with no explicit examples given.<br />Topics of a more mathematical nature appear in chapter 8, wherein the causal structure of spacetime is discussed. The discussion is qualitative and not based on Einsteins equation, and so is applicable to general spacetimes. One wonders when reading it if the obtained framework can be based on an analytical (or possibly numerical) treatment of the Einstein equation, instead of pure differential geometry. It is shown that null geodesics are The discussion here sets the tone for the next chapter on singularities, wherein the author derives criteria for determining when a timelike geodesic is not a local maximum in proper time between two points, and for when a null geodesic fails to remain on the boundary of the future of a point or two-dimensional surface. By using the local positivity of the stress-energy tensor (this is the only place the Einstein equation gets used) to get an inequality on the Ricci tensor,  the author shows that timelike geodesics cannot be maximal length curves and null geodesics cannot remain on past or future boundaries. However, using compactness properties of the space of causal curves allows one to prove the existence of timelike and nullike curves of maximal length in globally hyperbolic spacetimes. The singularity theorems are shown to follow from this contraction, giving the result that spacetime is timelike or nulllike incomplete. A very detailed discussion of the definition of a singularity in physics is given. In all of the author's discussion, it is very interesting to note that the Einstein equation is only used once in obtaining the bound on the Ricci tensor. One naturally wonders if this framework is more general than what is available via general relativity, namely a question to ask is whether the Einstein notion of gravity can be derived from a consideration of singularities. Enforcing the presence (or absence) of singularities may allow the derivation of gravitational theories that are not the same as Einsteins, and yet have the same experimental success.ining physically realistic solutions are discussed in chapter 7, most of these being obtained by exploiting stationarity and symmetry properties. Perturbation theory is discussed very briefly with no explicit examples given. <br />Topics of a more mathematical nature appear in chapter 8, wherein the causal structure of spacetime is discussed. The discussion is qualitative and not based on Einsteins equation, and so is applicable to general spacetimes. One wonders when reading it if the obtained framework can be based on an analytical (or possibly numerical) treatment of the Einstein equation, instead of pure differential geometry. It is shown that null geodesics are The discussion here sets the tone for the next chapter on singularities, wherein the author derives criteria for determining when a timelike geodesic is not a local maximum in proper time between two points, and for when a null geodesic fails to remain on the boundary of the future of a point or two-dimensional surface. By using the local positivity of the stress-energy tensor (this is the only place the Einstein equation gets used) to get an inequality on the Ricci tensor,  the author shows that timelike geodesics cannot be maximal length curves and null geodesics cannot remain on past or future boundaries. However, using compactness properties of the space of causal curves allows one to prove the existence of timelike and nullike curves of maximal length in globally hyperbolic spacetimes. The singularity theorems are shown to follow from this contraction, giving the result that spacetime is timelike or nulllike incomplete. A very detailed discussion of the definition of a singularity in physics is given. In all of the author's discussion, it is very interesting to note that the Einstein equation is only used once in obtaining the bound on the Ricci tensor. One naturally wonders if this framework is more general than what is available via general relativity, namely a question to ask is whether the Einstein notion of gravity can be derived from a consideration of singularities. Enforcing the presence (or absence) of singularities may allow the derivation of gravitational theories that are not the same as Einsteins, and yet have the same experimental success.	2002-01-07
1706334:US	50702879	R1X8WJJ7XTM32F	155521651X	918583833	Illustrated Book of Insects: A Comprehensive Color Guide to the Lives and Habitats of the Insects of the World	Books	5	2	2	N	N	Buy a used copy	With the illustrations and the descriptions of the insects, this book is a sheer delight. It conveys to the reader the wide variability of insects and their unique adaptations. It is certainly a book for the insect collector and for students of entemology. The anatomical structure of insects is discussed, along with some of their incredible abilities in locomotion, such as the ability of the nostril fly to reach a speed of over 100 kilometers per hour. The inter-sex differences in form and coloring and the variation in morphological types is also outlined. The phylogenetic relationships of insects is also delineated, which is helpful for those beginning the study of the classification of insects.<br /> Most of my favorites are discussed here, including the praying mantis, the migratory locust, the firebug, bed-bug, water stick, water scorpion, spittle bug, mountain cicada, great diving beetle, stag beetle, dung beetle, rhinoceros beetle, timberman beetle, velvet ant, hornet, honeybee, giant peacock moth, emperor moth, swallowtail, and horsefly.	2002-01-05
1706622:US	50702879	R2KOW1JDFC8JSE	0674040759	911185139	The Ants	Books	5	49	54	N	N	Excellent	This is a book that makes you want to drop everything and dedicate all your time to the study of ants. There are not too many books out there that are so well-written that they induce such emotions. It is a sizable book, and for those outside the field of myrmecology, it probably would not be read cover-to-cover. But every page of this book is fascinating, and considering the time and effort the authors put into it, it is no surprise that it has been the target of numerous awards. The authors dedicate the book to the &quot;next generation of myrmecologists&quot;, and no doubt they have convinced many individuals to take up the field. The authors convey to the reader that the study of ants is a thriving field, and there are lots of research questions unanswered in their study.<br />  Space prohibits a detailed review, so I will list instead the parts of the book that I consider most interesting: 1. The variation in the mode of colony founding among the different species of ants. 2. The mating habits of ants, in particular the female-calling and aggregation syndromes. 3. The description of the experiment showing the role of male pheromones in carpenter ants. 4. The statistical analysis of the time of swarming. 5. The comparison between different hypotheses for polyandry. 6. The universal occurence across species of 'nanitics' or 'minims' in the first brood and their ergonomic advantages. 7. The parental manipulation and offspring consent hypotheses for the origin of worker castes. 8. Eusociality and chromosome number as a strategy for reducing genetic variance. 9. The role of learning in colony-level recognition. 10. The presence of conflict between queens and workers in the management of new queens and males. 11. The existence of modulatory communication in ants (this was definitely the most interesting discussion in the book ). 12. The steps in the evolution of physical castes. 13. The result that colony-level selection is the opposite of what one  would expect from individual-level selection, the later tending to improving phenotypes. 14. The use of allometric space to model evolutionary optimization. 15. The capability of associative learning in ants. 16. Ant-termite warfare. 17. The entire chapter on army ants.individual-level selection, the later tending to improving phenotypes. 14. The use of allometric space to model evolutionary optimization. 15. The capability of associative learning in ants. 16. Ant-termite warfare. 17. The entire chapter on army ants.	2002-01-05
1712608:US	50702879	RSMCRP4VPRSI4	0915463733	84388854	Capitalism: A Treatise on Economics	Books	2	41	97	N	N	The utility of this book is marginal	This book is a massive treatise on economics that attempts to do what von Mises, Ayn Rand, and other well-known apologists for capitalism left incomplete: namely a comprehensive foundation  and justification for laissez-faire capitalism.<br />The book is a grand attempt, but falls short in many places, the most important being the author's aversion for what he calls 'mathematical economics'. Arguing that this field is dominated by the use of calculus and differential equations, the author rejects this approach is invalid because it fails to take into account the inherent discrete nature of goods and services. The author fails though to realize that a large body of economic theory and econometrics uses discrete mathematics and computer algorithms to model economic behavior. Not only that, economic models based on calculus are not necessarily unable to capture the discrete nature of economic phenomena. Such approaches are always considered by mathematicians an idealization, and one that needs to be compared with empirical data for validation. Indeed, an enormous effort has been undertaken in the last decade in financial engineering to apply advanced mathematical techniques to option trading, portfolio optimization, and risk analysis. These efforts are based in part on partial differential equations, and have had great successes in modeling trading in the marketplace. The author also argues, incorrectly, that too much emphasis is placed on states of final equilibrium in mathematical economics. He does not however give evidence for this claim. The behavior at long time of course is of interest for those modeling economic phenomena using dynamical systems, but the transient short-time behavior is also of great practical interest, and one that much of the literature is devoted to. The author also takes a swipe at the mathematical economics community, referring to them as 'snobs&quot; for their insistence on using what he calls 'esoteric' methods for studying economics. What he fails to note though is that mathematical systemization in economics was strongly resisted at first by the academic community; mathematical economics had a long and horrendous fight for recognition. And mathematics has indeed served the study of economics well, and even more importance now is placed on the validation of the algorithms for economic models, thanks to the growth of computing power.<br />The second major objection to the book is the lack of empirical and statistical analysis for the claims made. It is one thing to argue against the claims of socialists and others hostile to capitalism; it is quite another thing to put forth a theory of capitalism that meshes with known facts about what is observed in the real world. The author needs to spend more time on the validation of his theories using real data. Such an activity is difficult, but it is crucial to building a successful defense of laissez-faire capitalism, which from an ethical point of view, the author argues well for.<br />The book however is not all bad. The author is briliiant in his argumentation of the moral justification for capitalism, as he generalizes and clarifies the arguments of von Mises, Rand, and others who are sympathetic with capitalism. He encourages the reader to sharpen their critical thinking skills and to dispense with pre-conceived notions about capitalism as a morally-justifiable system. In particular, his analysis of the environmental movement is very well-written.<br />Even more troubling, is that this book will probably not be read by the most important audience of all: the worlds business people. The sheer size of the book will dissuade such individuals from reading it. This is unfortunate, since actually, modern business people view capitalism as somewhat 'evil'; they just don't mind being 'evil'. The accept the capitalist system as being 'realistic' and that those who don't are 'naive' and not atune to the real nature of humans. They really don't believe, or careto articulate on, the need for a moral justification of capitalism.<br />If this book were revised to include more statistical and empirical analysis, it would be a tour-de-force in economic theory. As it reads now though, it is more of a book on the ethics of capitalism and not a  scientific description. As a scientific theory of economics, it fails to deliver......care to articulate on, the need for a moral justification of capitalism. <br />If this book were revised to include more statistical and empirical analysis, it would be a tour-de-force in economic theory. As it reads now though, it is more of a book on the ethics of capitalism and not a  scientific description. As a scientific theory of economics, it fails to deliver......	2002-01-01
1712934:US	50702879	R3XR6GYC6MRJT	0521585171	763448608	Mathematics of Genome Analysis (Cambridge Studies in Mathematical Biology)	Books	5	27	29	N	N	Short but helpful	This book is a short overview of some of the important mathematical techniques used to study genome sequences. In spite of the length of the book, the author does a fine job of introducing these techniques. Students of computational biology will especially benefit from its perusal.<br />The first section is a brief overview of the structure of DNA, m-RNA, and t-RNA. Recognizing that DNA is two large for direct analysis, restriction fragments are discussed in the second section, with emphasis on the restriction-enzyme fingerprint. The author's goal is to find the probability of occurences of a 6-letter word in a strand and the mean distance between occurrences of this word (assuming no overlap between the words or the occurences and equal probabilities for the bases). The effect of successive pair correlation (Markov chain effect) is considered briefly. This is followed by a calculation of the probability that a base pair is contained in a given clone. The author omits any discussion of algorithms for optical mapping, but does give a brief discussion of restriction maps.<br />The mathematics becomes more rigorous in chapter two, wherein the author analyzes a chain that exists as a set of cloned subchains with unknown overlap. This is the 'fingerprint assembly' problem the object of which is to produce a physical map of the full sequence. The fingerprint of the clone is a collection of lengths of a particular restriction fragments. This algorithm involves a sequence of contiguous clones called 'islands'; and 'contigs', which are two or more clones. The average number and size of islands are calculated assuming that the clones have equal length and identical overlap threshold. The method of anchoring is also discussed as a second method for obtaining the physical map of the genome. The author then considers the problem of covering the whole sequence by first placing n markers on a genome and covering by intervals centered at these markers. This is the restriction-fragment-length polymorphism analysis, the combinatorics of which the author solves by using Laplace and Fourier transforms. He also considers adaptive and non-adaptive pooling, in order to find a particular set of proteins on a large fragment.<br />The third chapter addresses sequence statistics, with the author addressing the nonhomogeneity of sequences and the correlation dependence in the bases. The chi-square test is discussed is some detail and the author discusses the accuracy of the Markov chain assumption. Noting that very long chains would be needed to determine the parameters for the expressions for the conditional correlations, he uses the maximum likelihood method to find the intrinsic correlation length, and then estimates the parameters by modeling the parameter set.<br />The author then studies the isochore regions and discusses their detection via the Jensen-Shannon entropy. Asking whether there are correlations between these long regions and within them motivates him to consider the long-range properties of DNA. This leads to the examination of a long fragment of a single strand of DNA, and with the assumption that strand-symmetry holds, the correlation coefficients are studied, with the decay properties of the auto- and cross-correlation discussed. Then, distinguishing only dual pairs, the author considers the probability that a pair is separated by an integer after an integral number of steps, a calculation that reduces to finding the largest eigenvalue of a 'transfer matrix', a procedure well-known in statistical physics.<br />Next, a consideration of simple sequence repeats leads to a difference equation that is solved by the method of moments. Windows of bases are then discussed, in order to improve on the statistics. Correlations within and between windows are calculated. Interestingly, the consideration of long-range correlations gives a power-law dependence for the correlations, which is related to the Hurst index for self-similar patterns. Readers get their first taste of hidden Markov models in this chapter, which are currently very popular in sequence analysis. Even more interesting is the discussion of walking Markov models, wherein a first-order base-to-base Markov chain is chosen to depend on a hidden parameter, and the time evolution is shown to satisfy a Fokker-Planck (diffusion) equation. Spectral analysis and information theoretic criteria are also discussed.<br />In the next chapter of the book, the author considers the most important part of sequence analysis, namely the comparison between sequences according to their linear ordering. The problem is to find the probability of a common subsequence of two linear chains with a given length. The first calculation assumes that the matches are mutually exclusive, and the result is an upper bound on the probability. The author then considers the matches to be independent events, and again bounds are given for the probability, the so-called Chen-Stein estimate). He also gives an estimate of the probability in terms of an asymptotic series. Extreme value methods are then used to calculate the expectation value and the variance of the length of the longest match. An interesting exercise is assigned for the reader; namely of finding the effect on the Fourier and Walsh power spectrum with the assumption that the base correlations are fractal in form. The alignment problem is then generalized to include replication errors, mutations, etc. The chapter ends, appropriately, with a discussion of multisequence comparison. The author poses the problem as one of finding the best match of a word to an n-tuple of words, which he tackles first using 'information content'. The category analysis of separating subsequence configurations into clusters is briefly discussed via simulated annealing, discriminant analysis, Bayesian analysis, and neural networks.<br />The last chapter is a short introduction to the biophysics of DNA. The Hamiltonian for the dynamics of DNA is given, thermal equilibrium is assumed, and the partition function is calculated. This is followed by a discussion of the dynamics at low temperature when the energy is given by RNA polymerase instead of the heat bath, and the dynamics is solved via the Lagrangian using Bessel functions.Readers get their first taste of hidden Markov models in this chapter, which are currently very popular in sequence analysis. Even more interesting is the discussion of walking Markov models, wherein a first-order base-to-base Markov chain is chosen to depend on a hidden parameter, and the time evolution is shown to satisfy a Fokker-Planck (diffusion) equation. Spectral analysis and information theoretic criteria are also discussed. <br />In the next chapter of the book, the author considers the most important part of sequence analysis, namely the comparison between sequences according to their linear ordering. The problem is to find the probability of a common subsequence of two linear chains with a given length. The first calculation assumes that the matches are mutually exclusive, and the result is an upper bound on the probability. The author then considers the matches to be independent events, and again bounds are given for the probability, the so-called Chen-Stein estimate). He also gives an estimate of the probability in terms of an asymptotic series. Extreme value methods are then used to calculate the expectation value and the variance of the length of the longest match. An interesting exercise is assigned for the reader; namely of finding the effect on the Fourier and Walsh power spectrum with the assumption that the base correlations are fractal in form. The alignment problem is then generalized to include replication errors, mutations, etc. The chapter ends, appropriately, with a discussion of multisequence comparison. The author poses the problem as one of finding the best match of a word to an n-tuple of words, which he tackles first using 'information content'. The category analysis of separating subsequence configurations into clusters is briefly discussed via simulated annealing, discriminant analysis, Bayesian analysis, and neural networks. <br />The last chapter is a short introduction to the biophysics of DNA. The Hamiltonian for the dynamics ofDNA is given, thermal equilibrium is assumed, and the partition function is calculated. This is followed by a discussion of the dynamics at low temperature when the energy is given by RNA polymerase instead of the heat bath, and the dynamics is solved via the Lagrangian using Bessel functions.	2002-01-01
1720959:US	50702879	RGIUCR2ZHI7DN	0804708630	687882679	Cacti of the United States and Canada	Books	5	12	12	N	N	A masterpiece	After 1044 pages, 813 black and white photographs, 194 color photographs, 165 line drawings, and 135 distribution maps, cacti lovers will have no problems finding their favorite cacti in the wild or getting background on their systematics. This is a wonderful book, and one can never tire of perusing its contents. It is rich with information and an excellent introduction for those readers first entering the exotic world of cacti. Some of the most interesting parts of the book include: 1. The use of the scanning electron microscope to study surface patterns of cacti. Students of botany will realize that correlating the fine structure of cacti with taxonomy would be an interesting research project. 2. The root system of the Opuntia echinocarpa cholla. 3. The metabolism of cacti: the Craseulacean acid metabolism which allows closing of the stomata during the day. 4. The chemical chracters of cacti, particularly the use of two-dimensional chromatograms. 5. The evolutionary relationships within the family of cacti. 6. The role of asexual reproduction in promoting the survival of hybrids in chollas and prickly pears.<br />The book will no doubt serve as an excellent reference book in many years to come.	2001-12-25
1721134:US	50702879	R1GJQRYXCYCO8Y	0838577016	30371604	Principles of Neural Science	Books	4	14	25	N	N	Comprehensive in scope	This book, a collection of 65 articles written by leading experts in the different areas of neurology and brain biology, could draw a large audience of readers, including those interested in brain modeling and artificial intelligence. Space prohibits a comprehensive review, but some of the more interesting discussions include: 1. The evidence for localization of the emotional aspects of behavior in the brain. 2. The role of myelin basic proteins in producing allergic encephalomyelitis and the consequent discussion of a model for multiple sclerosis. 3. The dynamics of polymerization and dynamic instability. 4. The Hodgkin-Huxley model of excitability. 5. The regulation of gene expression by second messengers, the difference in time scales between these and directly gated synaptic actions is particularly interesting. 6. Calculating the probability of transmitter release, release being random and done in quanta. 7. The transplantation of embryonic neurons into an adult brain to promote recovery from brain damage. 8. the experimental techniques used to image the human brain: computerized tomography, positron emission tomography, magnetic resonance imaging. 9. The The hierarchical and parallel organization of sensory systems and motor control. 10. The diagrams of the major ascending somatic sensory systems. 11. The role of rhodopsin in the human visual system. 12. The physics of human hearing. 13. The role of the olfactory receptors in human smell and taste. 14. The skeletal muscles as being low-pass filters of neural input. 15. Genetic markers and Huntington's disease. 16. Sexual differentiation in the nervous system. 17. The model for the induction of LTP.	2001-12-25
1721539:US	50702879	R3P099W297N6VE	0195136306	141996927	Robot: Mere Machine to Transcendent Mind	Books	4	10	10	N	N	Very optimistic but realistic	Robots are now pervasive in all areas of human activity, and they are still primitive compared to what was envisioned two decades ago, at which time independent thinking machines and military-capable robots were predicted by the late 1990s.These predictions were very optimistic and way off their mark, but this book aims to set the record straight on A.I. and to make accurate predictions on the future of robotics. The author is very convincing in his arguments that artificial intelligence will accelerate rapidly in the next few decades. He backs up his predictions with empirical evidence from activities and research currently being done in A.I. and robotics, and extrapolates these into the future. Such predictions of course have been made before, and so the author inserts an elment of caution in his analysis, but he does, in his own words, consider intelligent machines an inevitability.<br />The tone of the book is optimistic, and this is good since many books and movies display an attitude that is threatened by robotics and artificial intelligence. The author does however predict the end of the dominance of biological humans, such beings to be replaced by highly intelligent robots. He is probably wrong here in the sense that humans will not be mere passive spectators in the upcoming age of robots. They will hybridize themselves with the chips invented for the robots, enabling them to stand toe-to-toe with these metal/silicon geniuses. Ever-growing technology implies ever-growing enhancement for the human, visual, muscular, and auditory capabilities.<br />Karl Marx would raise an eyebrow to the author's prediction of the end of private ownership of the means of production. Hypercompetitiveness, the author argues, will eliminate owners, replacing them by better robot decision makers. But to hold Switzerland up as an example of things to come? Hardly.<br />The end resulof the robotic evolution, will, the author argues, be the &quot;Exes&quot;, beings with awesome intelligence that are able to arrange spacetime and energy for computation. The physics of time trave; os discussed in the context of general relativity, with its nonlinear field equations being solved by &quot;Instant NP&quot; machines, and winning chess games in the process. Some metaphysical speculation is of course included: after all, the strong AI problem is one of the most provocative in philosophical circles. Conscious robots are indeed possible in the author's eyes, or at best possible given our current understanding of it. The robots themselves, with their enhanced capabilities, will have their own arguments about this......telligence that are able to arrange spacetime and energy for computation. The physics of time trave; os discussed in the context of general relativity, with its nonlinear field equations being solved by &quot;Instant NP&quot; machines, and winning chess games in the process. Some metaphysical speculation is of course included: after all, the strong AI problem is one of the most provocative in philosophical circles. Conscious robots are indeed possible in the author's eyes, or at best possible given our current understanding of it. The robots themselves, with their enhanced capabilities, will have their own arguments about this......	2001-12-24
1721786:US	50702879	RN9HVI2M35VR6	0763710660	830571097	Evolution	Books	5	10	11	N	N	Excellent	I used the second edition of this book and have not had a chance to view the third, but it no doubt is an excellent and comprehensive overview of the theory of evolution, just as in the second. In the edition I used, there are many fine diagrams illustrating the main points and also exercises at the end of each chapter to reinforce the concepts presented. Space probibits a detailed review so I will list only the areas in the book that I found exceptionally well-written: 1. The philosophical and religious issues in evolution theory. 2. The history of biology before Darwin. 3. The comparison between the pangenesis and germ plasm theories in the formation of a human. 4. The table on the comparison of views on variation and heredity. 5. The clarification by the author that evolution is primarily a historical process, and not arising by a lucky combination of events. 6. The general scheme of protein synthesis in Escherchia coli. 7. The schematic diagram outlining the mutual dependence of information carried by nucleotide sequences and function governed by proteins. 8. The dicussion on the &quot;RNA world&quot;. 9. The universality of the genetic code. 10. The evolution of the genetic code. 11. The discussion on exceptions to Mendelism. 12. The highly interesting discussion on the evolution of sex-determining systems. 13. The discussion on sickle cell mutation. 14. Evolutionary solutions to problems of locomotion. 15. The evolution of the human brain. 15. Conservation of gene frequencies and Hardy-Weinberg equilibrium. 16. The treatment of adaptive landscapes showing adaptive heights of different possible genotypes.	2001-12-24
1722318:US	50702879	R3PU28EFXU36Y	0817638687	620113745	Clifford (Geometric) Algebras With Applications in Physics, Mathematics, and Engineering	Books	4	22	22	N	N	Good compilation	This book, a compilation of 33 articles covering many different aspects and applications of Clifford algebras, can be read profitably by anyone desiring an overview of their history, theory, and applications. I did not read every article, and space also prohibits such a comprehensive review, so I will comment only on the ones that I actually studied.<br />Chapter introduces Clifford algebras as an extension of the real numbers to include vectors and vector products. The familiar representation in Euclidean space is outlined, with emphasis on the exterior product of two vectors, which, the author points out, is associative (unlike the ordinary cross product). The connection with rotations, reflections, and volume elements is pointed out, and the complex numbers and the Pauli algebra are shown to be Clifford algebras.<br />A short history of Clifford algebras is given in chapter 2. The reader not familiar with Clifford algebras should have no trouble following the ensuing discussion where some elementary geometric constructions are given of the Clifford algebra on the Euclidean plane. In addition, the operator approach to Weyl, Majorana, and Dirac operators is given, illustrating in detail their connection to physics. Recognizing that the Fierz identities do not by themselves give the Weyl and Majorana spinors, the author introduces what he calls the boomerang method for their construction. The boomerang is essentially a linear combination of bilinear covariants for a spinor, and the author details the conditions under which the spinor can be reconstructed. Interestingly, and unknown to me at the time of reading this chapter, the author constructs a new class of spinors, the &quot;flag-dipole&quot; spinors, that are different from the Weyl, Majorana, and Dirac spinors.<br />The author of chapter 3 considers the construction of Clifford algebras from a more geometric viewpoint, calling them geometric algebras, which he motivates by the consideration of extending the reals by a unipotent ( a number not equal to +1 or -1 but whose square is 1). The resulting unipodal numbers are isomorphic to the diagonal 2 x 2 matrices. The extension of the unipodal numbers so as to make this isomorphism to the full 2 x 2 matrix algebra leads to Clifford algebras.<br />In Chapter 9, the spacetime algebra is brought in to study electron physics. The &quot;space-time algebra&quot; or STA is used to characterize the observables associated with Pauli and Dirac spinors. The material presented is standard in physics, wherein the Green's function (propagator) for the Dirac equation is given, along with scattering theory. The typical problem of scattering off a potential barrier of finite width is discussed, along with the Klein paradox.<br />The space-time algebra is also discussed in the context of the interpretation of quantum mechanics in Chapter 11. The authors really do not add anything new here (in  terms of what one might consider &quot;strange&quot; behavior in quantum physics). They interpret Dirac currents as measurable quantities, avoiding seemingly any notion of wave packet collapse and difficulties with defining tunneling time(s), but not answering at all how to measure these currents. In addition, the Pauli principle is interepreted in the context of space-time algebra, without any quantum field theory. Howerver, it is not shown that such an approach satisfies cluster decomposition, casting suspicion on its utility.<br />In Chapters 21, 22, and 23 the author shows how spinors fit into the framework of the Lorentz group, their relationship to the Clifford algebra, and in general relativity. It is shown how the Dirac spinor can be defined in three different ways, namely as an element of the representation space of the Clifford algebra of spacetime, an element of the representation space of the fundamental representation of the Dirac spinor metric-preserving automorphism group of the Clifford algebra, and as an element of the representation space of the fundamental representation of the covering group of the conformal group.<br />The most interesting discussion in the book is chapter 28 on extending the Grassmann algebra. Dispensing with any scalar product on a vector space, the author shows how to obtain the relative magnitude between two vectors and this leads to the notion of a multivector. The duals to these are called outer forms, and are the familiar differential forms when depending on spatial position. Many helpful diagrams are used to illustrate the properties of multivectors and pseudomultivectors, the linear span of which is called the extended Grassmann algebra of multivectors. Adding a scalar product reduces the number of directed quantities to four, and electrodynamics can be formulated in a way that is independent of the scalar product.ace of the fundamental representation of the covering group of the conformal group.<br />The most interesting discussion in the book is chapter 28 on extending the Grassmann algebra. Dispensing with any scalar product on a vector space, the author shows how to obtain the relative magnitude between two vectors and this leads to the notion of a multivector. The duals to these are called outer forms, and are the familiar differential forms when depending on spatial position. Many helpful diagrams are used to illustrate the properties of multivectors and pseudomultivectors, the linear span of which is called the extended Grassmann algebra of multivectors. Adding a scalar product reduces the number of directed quantities to four, and electrodynamics can be formulated in a way that is independent of the scalar product.	2001-12-23
1723364:US	50702879	R3MH6ZS3JTOIEH	0691085420	427996762	Spin Geometry. (PMS-38)	Books	5	12	12	N	N	Excellent	Who would have known that the equation discovered by P.A.M. Dirac in the 1920's would have the enormous appllications to mathematics that it currently has. This book is an excellent overview of these applications, written by two individuals who are responsible for the development of many of these. Dirac's theory of course had its origins in physics, and physicists, particularly those working in high energy physics, will find this book interesting and helpful.<br />The authors give a brief introduction and then move on to the representation theory of Clifford algebras and spin groups in chapter 1. The reader can see the origin of Clifford algebras and an introduction to the Pin and Spin groups. Clifford algebras are classified as matrix algebras over the real or complex numbers, and the quaternions. It is the representation theory of Clifford algebras however that has resulted in the impressive results outlined in the book Noting that the tensor product of Clifford algebras is not necessarily a Clifford algebra, the authors introduce a Z(2)-grading on a Clifford algebra, which results in a multiplicative structure in the representations of Clifford algebras. The Lie algebras of the Pin and Spin groups are discussed along with applications to geometry and Lie groups. By far the most interesting discussion though is on K-theory, which allows one to define a ring structure on vector bundles. Distinguishing a base point in the base space, relative K-groups are defined, and shown to be equal for the base space and its i-fold suspension. Bott periodicity results are stated but their proof is delayed until chapter 3. A detailed discussion is given of the Atiyah-Bott-Shapiro isomorphism and KR-theory.<br />The connection between spin and differential geometry is discussed in chapter 2. The first few sections is a review of standard results in the spin structure of vector bundles, such as Stiefel-Whitney classes and spin cobordism. For Riemannian vector bundles, each fiber has a quadratic form that gives rise to a Clifford algebra on the fiber. The question as to when a vector bundle over the Riemannian base space can be found that has fibers each an irreducible module over this Clifford algebra leads to a consideration of spin manifolds and spin cobordism, when the total space is chosen to be the tangent bundle. The Dirac operator acting on a bundle over this Clifford bundle allows the construction of all the standard elliptic operators such as the signature, Atiyah-Singer, and the Euler characteristic. The authors discuss these constructions in detail along with the notion of of Cl(k)-linear operators.<br />The Dirac operator can be viewed in Euclidean space as the square root of a Laplace operator, but over general manifolds it is the Laplacian with a correction term dependent on the curvature and Clifford multiplication. The Bochner vanishing theorems are discussed in great detail, along with the results on the existence of exotic spheres.<br />An entire chapter is spent on index theorems, wherein the authors present the results in terms of the approach used by Atiyah and Singer, instead of the heat kernel methods of Gilkey and Patodi. Physicists might prefer the later approach, due to its connections with applications, but the abstract K-theory approach undertaken by the authors is elegant and their presentation is excellent. The role of physics in index theorems is a fascinating one though, especially the use of supersymmetry to simplify the proofs of some of the results. The authors do not discuss this approach, but point out, interestingly, that it does not work when one is dealing with torsion elements in K-theory. These cannot be detected using cohomology nor can the modulo-two invariants appearing in the index theorems be computed from local densities.<br />The last chapter is a long one and discusses applications in differential topology and geometry, emphasizing index thoerems and Riemannian manifolds of positive scalar curvature. The authors outline just when the indexes are integers (the integrality theorems) and use spin geometry to discuss the immersion problem for manifolds and the vector field problem. Exotic n-spheres again make their appearance, wherein it is shown that some of these have very few symmetries and are very asymmetric objects. A short introduction to elliptic genera is given. Interestingly, C*-algebras are briefly mentioned as tools to decide whether for every compact spin manifold with positive scalar curvature all higher A-genera must be zero. Spin-c manifolds are not treated, the authors instead concentrating their attention to Kahlerian geometry. In this context the Clifford algebra multiplication has a beautiful relationship with the complex structure. A brief discussion is given of the pure spinors of Cartan and twistor spaces. The theory of holonomy and calibrations, the later due to one of the authors, is discussed in great detail. The discussion begins in the consideration of when universal covering spaces are not Riemannian manifolds and their holonomy groups have been classified. The idea of a calibration arises from the consideration of submanifolds that are homologically volume-minimizing. These become calibrations when the integrals of p-forms on them are the volumes, and these p-forms have vanishing differentials on oriented tangent p-planes on the manifold. The authors give an interesting discussion of the relation between spinors and calibrations.curvature. The authors outline just when the indexes are integers (the integrality theorems) and use spin geometry to discuss the immersion problem for manifolds and the vector field problem. Exotic n-spheres again make their appearance, wherein it is shown that some of these have very few symmetries and are very asymmetric objects. A short introduction to elliptic genera is given. Interestingly, C*-algebras are briefly mentioned as tools to decide whether for every compact spin manifold with positive scalar curvature all higher A-genera must be zero. Spin-c manifolds are not treated, the authors instead concentrating their attention to Kahlerian geometry. In this context the Clifford algebra multiplication has a beautiful relationship with the complex structure. A brief discussion is given of the pure spinors of Cartan and twistor spaces. The theory of holonomy and calibrations, the later due to one of the authors, is discussed in great detail. The discussion begins in the consideration of when universal covering spaces are not Riemannian manifolds and their holonomy groups have been classified. The idea of a calibration arises from the consideration of submanifolds that are homologically volume-minimizing. These become calibrations when the integrals of p-forms on them are the volumes, and these p-forms have vanishing differentials on oriented tangent p-planes on the manifold. The authors give an interesting discussion of the relation between spinors and calibrations.	2001-12-22
1732144:US	50702879	RTGNXJU1DATPT	012185860X	48912268	Noncommutative Geometry	Books	4	12	14	N	N	A beautiful subject	Even though detailed proofs are omitted for most of the major results, the book is an excellent overview of a beautiful subject that the author has made substantial contributions to. The subject of noncommutative geometry has recently made its way into theoretical physics, and so a perusal of this book would be of interest to individuals working in string theory or quantum field theory.<br />  The main idea of this book is to generalize measure and operator theory to non-commutative situations. In the usual operator theory, von Neumann algebras serve as a generalization of &quot;classical&quot; measure theory. Commutative von Neumann algebras, or W*-algebras as they are sometimes called, are essentially bounded meausurable functions, and have measure spaces as their dual. These facts and a fine movtivation for the subject appear in the introduction to the book. The author shows with great clarity what is involved in extending measure theory to the non-commutative case. What is most interesting about the extensions is that they involve ideas from quantum physics. In addition, readers familiar with K-theory will see some brilliant uses of it in the book, particularly in the extension of BDF-theory to noncommutative situations, namely the KK-theory of Kasparov. The author also gives a taste of physics applications in the very last section of the book. He shows, interestingly, that when space-time is replaced by a product with a certain finite space, the Lagrangian of quantum electrodynamics becomes that of the Standard Model. Although such &quot;add-ons&quot; to space-time are not uncommon in physics (Kaluza-Klein theories being one example), the author's strategy is unique in its use of bimodules, and gives the three lepton generations.<br />  There are also many other interesting topics as well in the book, such as how to deal with non-Hausdorff quotient spaces using noncommutative C*-algebras, deformation theory and the Kasparov group, the notion of Morita equivalence, leaf spaces of foliations, the E-theory of morphisms of separable C*-algebras, the extension of de Rham cohomology to a noncommutative framework (cyclic cohomology) and its relation to K-theory, the noncommutative torus and the quantum Hall effect.<br />  The book is an excellent source of information on noncommutative geoemtry and with the many references given one can find more detailed proofs. It is a subject that will no doubt continue to make its presence known in mathematics (and physics) in years to come.ence, leaf spaces of foliations, the E-theory of morphisms of separable C*-algebras, the extension of de Rham cohomology to a noncommutative framework (cyclic cohomology) and its relation to K-theory, the noncommutative torus and the quantum Hall effect. <br />  The book is an excellent source of information on noncommutative geoemtry and with the many references given one can find more detailed proofs. It is a subject that will no doubt continue to make its presence known in mathematics (and physics) in years to come.	2001-12-15
1766274:US	50702879	R3SWLK23WONL32	0195102703	555876735	Computational Intelligence: A Logical Approach	Books	4	14	18	N	Y	Serves well as an introduction	Everything in this book used to be classified as artificial intelligence, but the authors have chosen to call it computational intelligence, arguing that it is the computational aspects of the subject that they want to emphasize. The book is very well written, and students and those interested in A.I. research and development will find it a helpful step to more involved studies.<br />The emphasis in the book is on intelligent agents, which the authors characterize in chapter one. Agents are viewed as black boxes that take in knowledge, past experiences, goals/values, and observations and output actions. They define what they call a representation and reasoning system consisting of a language to communicate to a computer, a methodology for giving meaning to this language, and a collection of procedures for computation. They also outline the three applications domains they will be developing in the book: an autonomous delivery robot, a diagnostic assistant, and an infobot.<br />The authors expand upon the representation and reasoning system in chapter 2 in terms that are familiar from mathematical logic and computer science. A formal language, a semantics, and a proof procedure are the three essentials of an RRS. All of these elements are discussed in great detail, and concrete examples are given for all the main concepts. Readers without any background in logic may find the reading difficult, but with some effort it could be read profitably. The authors do a good job of presenting material that is usually delegated to texts on formal computer science.<br />In chapter three, the authors show how representational knowledge can be used for domain representation, querying, and problem solving. This is done via an example of electrical house wiring and the PROLOG-astute reader will find the presentation very straightforward. But LISP programmers will also see its influence and the discussion on lists. An application is given in computational linguistics, namely that of definite clauses for context-free grammars.<br />A discussion of searching is given in chapter 4, in the context of potential partial solutions to a problem, with the hope that these will truly be real solutions for the problem at hand. Graph searching, blind search strategies, heuristic searching, and refinements of these are all discussed with great clarity. And, because of their importance in applications, dynamic programming and constraint classification problems are overviewed, albeit very briefly.<br />Chapter 5 turns to the topic of how to choose a representation langauge for knowledge. The authors detail the criteria for comparing different languages or logics in terms of expressiveness, worse-case complexity, and naturalness. Most important in this chapter is the discussion on qualitative versus quantitative representations.<br />This is followed in chapter 6 by a discussion of the user interactions to a knowledge-based system in terms of a meta-interpreter that produces knowledge acquistion, debugging, etc.<br />The next chapter shows how definite clause representation and reasoning systems can be extended to include the relation of equality and negation, and quantification of variables. This sets up naturally a discussion of first-order predicate calculus, but only a brief overview is given. A very short treatment of modal logic is given.<br />Chapter 8 considers agents that act and reason in time, with three representations given for reasoning about time. These are the STRIPS representation (developed at Stanford University), the situation calculus, and the event calculus. It is then shown how these can be used to reason and produce plans to achieve goals. Although brief, the discussion is very interesting, and the authors give good references for further reading.<br />The authors generalize their discussions to assumption-based reasoning in chapter 9, which up until this chapter has been restricted to reasoning from knowledge bases. Nonmonotonic reasoningis defined, along with abduction, which is a form of reasoning different from both deduction and induction, and which emphasizes hypothesis formation.<br />Chapter 10 considers the more realistic situation whre the agents have incomplete or uncertain knowledge. This naturally brings up a discussion of probability, which the authors define as the study of how knowledge affects belief. They distinguish between evidence and background knowledge, the latter which is stated in terms of conditional probabilities, the former characterized by what is true in the situation being studied. Belief networks are introduced as a graphical representation of conditional independence, these graphs being directed and also acyclic (the latter for reasons of causality). An algorithm for determining the posterior distribution of belief networks is given, and is based on the idea that a belief network specifies a factorization of the joint probability distribution. A brief overview of decision networks is also given.<br />The important topic of learning theory is overviewed in chapter 11. And, naturally, neural networks make their appearance here, although the discussion is very brief. PAC learning is also treated, as well as Bayesian learning. Unfortunately, the important field of inductive logic programming is not discussed, but some references are given.<br />The last chapter covers artificial purposive agents, otherwise known as robots. This is a vast subject, and only a general overview is given here, but the authors do a good job of showing how robots can be characterized within the concepts outlined in the book. Dynamical systems are used to represent the agent function for a robot. Readers familiar with the theory of dynamical systems will see the state transition function appear here in a more general context. The states of an agent at time t encode all of the information about its history. The state transition functions acts on the states and percepts, with the percepts playing the role of time in the usual dynamical system.<br />The appendices include a terminology list and a short introduction to PROLOG, along with a few examples of PROLOG code applied to some of the concepts in the book. Although very general, the inclusion of these examples are of further help in understanding the material in the book.reasoning is defined, along with abduction, which is a form of reasoning different from both deduction and induction, and which emphasizes hypothesis formation. <br />Chapter 10 considers the more realistic situation whre the agents have incomplete or uncertain knowledge. This naturally brings up a discussion of probability, which the authors define as the study of how knowledge affects belief. They distinguish between evidence and background knowledge, the latter which is stated in terms of conditional probabilities, the former characterized by what is true in the situation being studied. Belief networks are introduced as a graphical representation of conditional independence, these graphs being directed and also acyclic (the latter for reasons of causality). An algorithm for determining the posterior distribution of belief networks is given, and is based on the idea that a belief network specifies a factorization of the joint probability distribution. A brief overview of decision networks is also given. <br />The important topic of learning theory is overviewed in chapter 11. And, naturally, neural networks make their appearance here, although the discussion is very brief. PAC learning is also treated, as well as Bayesian learning. Unfortunately, the important field of inductive logic programming is not discussed, but some references are given. <br />The last chapter covers artificial purposive agents, otherwise known as robots. This is a vast subject, and only a general overview is given here, but the authors do a good job of showing how robots can be characterized within the concepts outlined in the book. Dynamical systems are used to represent the agent function for a robot. Readers familiar with the theory of dynamical systems will see the state transition function appear here in a more general context. The states of an agent at time t encode all of the information about its history. The state transition functions acts on the states and percepts, with the percepts playing the role of time in the usual dynamical system. <br />The appendices include a terminology list and a short introduction to PROLOG, along with a few examples of PROLOG code applied to some of the concepts in the book. Although very general, the inclusion of these examples are of further help in understanding the material in the book.	2001-11-18
1766334:US	50702879	RD8X4U1AU12XD	1560251328	973385185	Information Warfare: Second Edition	Books	4	7	8	N	N	Very important book	The importance of the contents of this book cannot be overstated. It is a collection of articles written by various experts in the field, which works well as it gives the reader a balanced view. Space prohibits a thorough review, so a list of some important highlights in the book is in order: 1. The discussion on applications of biotronics: bacteria that can detect single molecules of chemical and biological agents. 2. High-power radio frequency (HERF) weapons and their effects on biological systems. 3. The use of superconducting quantum interference devices (SQUIDS) to measure the magnetic neural activity of the brain. 4. The discussion on &quot;assassination politics&quot;. 5. Cognitive maps used to visualize belief systems about information warfare. 6. The afterward of the book, which is the best part actually, for the reason that the author embraces an optimistic view of the future of the information age. He lists the &quot;Ten Commandments&quot; of computer ethics which should be followed by all individuals.	2001-11-18
1767862:US	50702879	R29GO9VZG3MZPA	0125931158	408521076	Object-Oriented Neural Networks in C++	Books	4	6	7	N	N	Organized and helpful	Neural networks are pervasive in the modern business and research environment. The applications of neural networks are enormous and include fields such as financial engineering, network modeling, computational radiology, medicine, and brain modeling.<br />For readers who know C++, this book gives a thorough overview of neural networks from the standpoint of the source code used to represent them. It is expected that the reader has had some exposure to neural networks, for no detailed discussion is given of their history or properties. The author attempts to stick to a purely object-oriented framework, and refrains from giving what he calls a &quot;coarse-grained&quot; approach to an object-oriented implementation of neural networks. The later according to him is merely a collection of C++ wrappers around existing C code. The base objects are the nodes and links of the neural networks, called the Base-Node and Base-Link classes in the book. The author admits this approach degrades performance, but design and development of complicated neural net architectures is enhanced, he argues.<br />After a brief review of object-oriented programming in chapter 2, the author treats the neural network base classes in chapter 3. He defines a neural net as a 3-tuple consisting of a pattern set, parameters, and topology. The ADALINE, backpropagation, Kohonen self-organizing, and BAM neural-network architectures are treated throughout the book in chapters 4, 5, 6, and 7 respectively. The XOR problem is discussed as an example of learning with a backpropagation neural network, along with an example from lithology. Also, for those readers who are using compilers that do not support template classes, the author creates a generic backpropagation neural-network class. This class is constructed to make the creation of a back-propagation class more transparent.<br />The only major problem with the book is the lack of examples illusrating the Kohonen and BAM neural networks and the lack of in-depth discussion of neural networks. For readers very familiar with neural networks and C++, this book should work well.f in-depth discussion of neural networks. For readers very familiar with neural networks and C++, this book should work well.	2001-11-17
1776427:US	50702879	R2WFR5R3CFUAWQ	0596000804	808495392	Beginning Perl for Bioinformatics	Books	5	48	49	N	Y	Very timely introduction to PERL	Finally someone has written a beginning book on PERL for biologists, and has also done an excellent job of doing so. This book assumes no prior programming experience, and therefore suits the biologist who needs to concentrate on using computers to solve biological problems, and not have to become a computer scientist in the process. PERL can be a very cryptic language, but it is also extremely concise, and PERL programmers frequently and rightfully boast about their &quot;one-liners&quot; that accomplish complicated tasks with only one line of code.<br />Since it is addressed to readers with no programming experience, the author introduces some elementary concepts of programming in the first three chapters. These include what text editor to use, how to install PERL, how run PERL programs, and other relevant elementary topics.<br />The author then gets down to writing a program to store a DNA sequence in chapter 4. Very basic, it merely reads in a string and prints it out, but serves to start readers on their way to developing more useful programs. Later a program for the transcription of DNA to RNA is given, which illustrates nicely the binding, substitution and trace operators. Block diagrams are used here, and throughout the book, to illustrate basic PERL operators. The author shows in detail how to read protein sequence data from a file and how to use it in a PERL program. The reader is also introduced to the most ubiquitous data structure in all of computing: the array. Already the reader gets a taste of the power of PERL to manipulate arrays, using operations such as 'unshift', 'push', 'splice', etc.<br />The next chapter introduces conditional statements in PERL, as a warm-up for the discussion on finding motifs in sequences. The reader can see why PERL is the language of choice in bioinformatics, with its ability to find substrings or patterns in strings. Things do become more cryptic in the discussion of regular expressions, but the reader can get through it with some effort. Interesting programs are given for determining the frequency of nucleotides.<br />Since the programs have become more complicated to this point, a discussion of subroutines follows in the next chapter. And, for the same reason, the reader is introduced to debugging in PERL in this chapter also. The greater the complexity of the program, the harder it becomes to avoid making mistakes, and even more difficult to find them. The very important concepts of pass by value versus pass be reference are discussed briefly in this chapter.<br />Random number generators, so important in any consideration of mutations, are discussed in chapter 7. It is shown, via some straightforward programs, how to select a random location in DNA and mutate it with some other nucleotide. In addition, the author shows how to use random numbers to generate DNA sequences and mutate them in order to study the effect of mutations over time.<br />The next chapter is the most interesting in the book, for it shows how PERL can be used to simulate how the genetic code directs the translation of DNA into protein, the hash data structure being used extensively for this purpose. The author shows how to read DNA from files in FASTA format, and discusses in detail reading frames. He gives a useful subroutine to translate reading frames.<br />The author returns to regular expressions in chapter 9, wherein they are used as 'wildcards' to search for a particular string in a collection of strings. In addition, the range operator is used to find restriction sites. Regular expressions are also used in the next chapter to manipulate GenBank 'flat files'. The author does however give URLs for more sophisticated bioinformatics software. This is followed in chapter 11 by a discussion of the use of PERL to work with files in the Protein Data Bank. Recursion, one of the most powerful techniques in programming, is introduced here.<br />Chapter 12 covers the Basic Local Alignment Search Tool (BLAST), wherein readers get a taste of the field of computational biology. This extremely popular software package is used to find similarity between a given sequence and a library of known sequences. The author does discuss some of the basic rudiments of string matching and homology, and encourages the reader to consult the BLAST documentation for further details. In addition, the author briefly discusses the Bioperl project in this chapter, and shows the reader how to run some elementary computations using it.<br />This book definitely is a timely one and it will serve the needs of biologists who need to obtain some programming expertise in PERL. There are helpful exercises at the end of each chapter that serve to solidify the understanding of the concepts introduced in the chapter. After a thorough study of it, readers will be well-equipped to use PERL in bioinformatics. With more mathematical background, readers after finishing it will be able to enter the exciting field of computational biology, a field that is exploding, and one in which will require imaginative programming skill in the future.AST), wherein readers get a taste of the field of computational biology. This extremely popular software package is used to find similarity between a given sequence and a library of known sequences. The author does discuss some of the basic rudiments of string matching and homology, and encourages the reader to consult the BLAST documentation for further details. In addition, the author briefly discusses the Bioperl project in this chapter, and shows the reader how to run some elementary computations using it. <br />This book definitely is a timely one and it will serve the needs of biologists who need to obtain some programming expertise in PERL. There are helpful exercises at the end of each chapter that serve to solidify the understanding of the concepts introduced in the chapter. After a thorough study of it, readers will be well-equipped to use PERL in bioinformatics. With more mathematical background, readers after finishing it will be able to enter the exciting field of computational biology, a field that is exploding, and one in which will require imaginative programming skill in the future.	2001-11-10
1793807:US	50702879	ROUVE3WCCSM1X	0821809946	596698716	4-Manifolds and Kirby Calculus (Graduate Studies in Mathematics)	Books	5	10	10	N	N	Extremely detailed overview of Kirby calculus	Readers familiar with the proof of Stephen Smale's proof of the high-dimensional Poincare conjecture will know that handle calculus was employed in the proof. This book is an overview of Kirby calculus, which is essentially handle calculus in dimensions less than or equal to four.<br />  Kirby calculus can be used to describe four-dimensional manifolds such as elliptic surfaces, and gives a pictorial description of its handle decomposition. Its utility lies further than this however, as Kirby calculus has been used to answer questions that would have been very difficult otherwise.<br />  The book begins with a very quick overview of the algebraic topology and gauge theory of four-dimensional manifolds. Readers not familiar with this material will have to consult other books or papers on the subject.<br />  Part two takes up Kirby calculus, and handle decompositions are described with examples given for disk bundles over surfaces and tori. Handle moves are employed as processes that allow one to go from one description of a manifold to another. Handlebody descriptions are given for spin manifolds, and more exotic topics, such as Casson handles and branched covers are treated.<br />  Part 3 of the book uses techniques from algebraic geometry to describe branched covers of algebraic surfaces. Handle decompositions of Lefschetz fibrations are given, and its is shown that a Stein structure on a manifold is completely described by a handle diagram. There is also a thorough discussion of exotic structures on Euclidean 4-space. In spite of the non-constructive nature of these results, namely that no explicit example of an exotic structure is given, the discussion is a fascinating one and has recently been shown to be important in physics.<br />The reader will no doubt attempt many of the exercises; the solutions of some of these given in the back of the book. The book serves well the needs of those dedicated individuals who are interested in specializing in low-dimensional topology. In addition, physicists interested in these ideas couuld benefit from its reading, although some of the results may seem a little heavy-handed and abtruse at times.ensional topology. In addition, physicists interested in these ideas couuld benefit from its reading, although some of the results may seem a little heavy-handed and abtruse at times.	2001-10-28
1793888:US	50702879	R2J7XWY3WNCHHT	0471130419	693398681	Neural, Novel & Hybrid Algorithms for Time Series Prediction	Books	3	8	8	N	Y	Not for beginners	Prediction methods for time series are a multi-million dollar industry and are of upmost importance in financial engineering, weather prediction, logistics, network modeling, and myriads of other fields. This book gives an overview of various methodologies for time series prediction, and is written for readers with substantial experience in this area. The author emphasizes that time series prediction is more of an art rather than a science, with the practitioner usually employing hybrids of established techniques, only some of which have a rigorous mathematical foundation. In fact, despite the subject matter, this book is very lean on mathematics, and the reader will have to consult other books for a more detailed mathematical treatment. The NPredict package accompanying the book is designed to run on an NT and a DOS platform, and illustrates the main points in the book. Readers who have familiarity with the authors earlier books on neural networks will definitely find this one easier to follow. It is, again, not written for beginning students, but the author does a fairly good job of presenting the material for the advanced reader.	2001-10-27
1793970:US	50702879	R34RQXO5N34MYB	0387946098	785717689	Modular Forms and Fermat's Last Theorem	Books	5	24	34	N	N	Yet another application of elliptic curves...	The successful proof of Fermat's Last Theorem by Andrew Wiles was probably the most widely publicized mathematical result of the 20th century. And once again, among their numerous other applications, elliptic curves are employed in the proof. The book is a compilation of articles written by first-class mathematicians, the reading of which will give one a thorough understanding of the proof, along with an overview of some very interesting topics in number theory and algebraic geometry. The reader who undertakes an understanding of the proof already no doubt has a substantial amount of 'mathematical maturity', and no review, no matter how complete, would influence greatly such a reader. Suffice it to say then that this book is excellent, and even a reader interested solely in elliptic curves and modular forms could benefit greatly from the reading of this book.	2001-10-27
1794731:US	50702879	RBUT0C4B8UA56	080505880X	749684877	When Things Start to Think	Books	4	1	3	N	Y	Computers are for people...not the other way around.	The author of this book is clearly of the opinion that the &quot;Digital Revolution&quot; is more of what he calls a 'disinformation campaign'. His arguments are to the effect that computers and gadgets need to be responsive to human needs, this not being the case to this date. Computers should be a suit of clothes a person can wear (literally!!) and not a straightjacket, the author seems to say. We should expect more from computers, and the Digital Revolution should be for people, not computers.<br />  The author is definitely correct in saying this, as computers are still difficult to use for most people. The author's book is an attempt to propose remedies for this state of affairs, and some of these are highly creative, making the book very interesting to read. Some of the more clever ideas include smart paper, wearable computers, and smart money. He also overviews more exotic notions of computation, such as DNA and quantum computation. These ideas and developments are all very exciting, and no doubt most of them will come about....and soon.	2001-10-27
1806518:US	50702879	R16GZ6BWXJADXW	1558219013	541600025	Beyond Evolution: The Genetically Altered Future of Plants, Animals, the Earth...and Humans	Books	2	4	6	N	Y	No substantive arguments here	Any book that deals with scientific issues and its relation to morality and ethics will be controversial, and this book is no exception. It is an attempt to address the ethical issues in genetic engineering, but it does not do so in a way that is really convincing. Those against genetic engineering in any form will probably like the book, and those for genetic engineering will no doubt not like it. But for those who are genuinely attempting to answer the enormous legal and ethical complexities of genetic engineering, this book fails. The author does not substantiate his arguments with experimental data or references to such data, one example being the claim that 60% of processed foods now contain genetically engineered ingredients. What are some examples of these products? Where does the author get his estimates? The author also makes sneering and sarcastic remarks regarding the profession of genetic engineering, referring to them as a 'scientific priesthood', or as 'genetic sorcerers'.<br /> The author blames the Enlightenment period for fostering an attitude of recklessness and disrespect for animal life, the philosophers Descartes and Bacon being blamed primarily for fostering attitudes that encourage animal cruelty and disrespect for animal life in general. But Descartes and Bacon are not the only representatives of the Enlightenment period, and moreover the period encouraged optimism and respect for all life, contrary to the author's claims. The attitudes of legal reasoning of that period have continued to this day in animal rights movements, something the author, as a vetenarian, no doubt supports. The critical thinking and openness to new ideas were encouraged by the thinkers of the Enlightenment, and such thinking will allow those in the present day to use genetic engineering in a socially responsible manner.<br /> In addition, the author should remember that humans are indeed part of nature; they evolved right along with other life forms. As such, it is a valid argument to say that genetic engineering of life forms is part of the evolutionary process. The time scales involved are much faster than for 'ordinary' evolution without human intervention. This of course does not make genetic engineering a 'legitimate' activity, but it does refute objections to it on the lines that it is 'unnatural' or 'inorganic'. One cannot object to genetic engineering solely on the basis that genetic changes through its use take place much faster than evolution without human intervention.<br /> The author is clearly against the big-business aspects of genetic engineering, referring to it as 'genetic imperialism'. He is reluctant to call those who develop genetically engineered crops 'farmers', but instead calls them 'peons' who are bankrolled by the evil behemoth of agribusiness. But why should not the the organic food market, which is a multi-billion dollar business, be characterized in the same way? Clearly from reading the book, the author is a proponent of organic agriculture, a sector that stands to lose its position in the market if genetically engineered food is accepted by the majority of the public. Both the organic foods industry and the genetically-modified food industry have both been very aggressive in their advertising, each claiming to offer food products that are more 'wholesome' for the consumer. Only rigorous testing and an understanding of human nutritional needs can determine in fact whether genetically modified foods are superior to foods that are not. No amount of advertising, nor unsubstantiated claims by the author that the adoption of organic methods is optimal for food production and human health, will change the actual facts about organic or genetically modified foodstuffs. In addition, it does not matter whether the U.S. Dept. of Agriculture is in fact undermining the proposed National Organic Standards. Government departments have made blunders before, the mere fact that they are doing so again does not by itself imply that genetically modified foods are dangerous, or incompatible with organic agriculture, as the author contends. It merely means that the USDA is engaging in favoritism.<br /> The author is also way out of line in his claims that the practice and philosophy of organic agriculture is commendable because of its satisfaction of some key bioethical principles, one of these being that organic farming seeks to minimize harm to natural ecosystems. He does not provide any evidence that genetic engineering is more malicious or lacks regard for the environment. Secondly, he claims that organic farming enhances biodiversity, a claim that is totally unsubstantiated and in fact counterintuitive. Genetic engineering allows, through transgenic strategies, a wider variety of organisms and at a shorter time scale.<br /> The author also claims that those who advocate the changing of distinct and unique species for purely human ends have no reverence for life. Again, the author should not make this claim without first-hand knowledge of the people involved in genetic engineering. There are no doubt genetic engineers along with organic farmers who fit this description, along with many in both camps who do not.<br /><br /> Also, the author claims that there is no scientific evidence the genetically engineered crops are the answer to world hunger and then asserts that there is 'clear evidence' that organic agriculture does. This evidence though is not expounded upon in this book.<br /> In addition, genetically modified foods are not 'infected', and biotechnology is not 'genetic pollution', as the author charges. Such vituperation has no place in scientific debate, and serves only to raise the level of truculence on both sides of the issue.<br /> The most interesting part of the book is that the author inadvertently introduces the reader to some of the more fascinating research that is currently conducted in genetic engineering, such as genetically modified insects.<br /> One of course should admire the high degree of compassion the author shows towards animal life. It should be taken as an axiom that all forms of life deserve respect and should be treated with kindness...and this goes for genetically engineered lifeforms, whenever and wherever they are produced.itself imply that genetically modified foods are dangerous, or incompatible with organic agriculture, as the author contends. It merely means that the USDA is engaging in favoritism. <br /> The author is also way out of line in his claims that the practice and philosophy of organic agriculture is commendable because of its satisfaction of some key bioethical principles, one of these being that organic farming seeks to minimize harm to natural ecosystems. He does not provide any evidence that genetic engineering is more malicious or lacks regard for the environment. Secondly, he claims that organic farming enhances biodiversity, a claim that is totally unsubstantiated and in fact counterintuitive. Genetic engineering allows, through transgenic strategies, a wider variety of organisms and at a shorter time scale. <br /> The author also claims that those who advocate the changing of distinct and unique species for purely human ends have no reverence for life. Again, the author should not make this claim without first-hand knowledge of the people involved in genetic engineering. There are no doubt genetic engineers along with organic farmers who fit this description, along with many in both camps who do not. <br /> <BR> Also, the author claims that there is no scientific evidence the genetically engineered crops are the answer to world hunger and then asserts that there is 'clear evidence' that organic agriculture does. This evidence though is not expounded upon in this book. <br /> In addition, genetically modified foods are not 'infected', and biotechnology is not 'genetic pollution', as the author charges. Such vituperation has no place in scientific debate, and serves only to raise the level of truculence on both sides of the issue. <br /> The most interesting part of the book is that the author inadvertently introduces the reader to some of the more fascinating research that is currently conducted in genetic engineering, such as genetically modified insects. <br />One of course should admire the high degree of compassion the author shows towards animal life. It should be taken as an axiom that all forms of life deserve respect and should be treated with kindness...and this goes for genetically engineered lifeforms, whenever and wherever they are produced.	2001-10-17
1811296:US	50702879	R3TCQKX2C1PE65	1558602763	800435267	Principles of Digital Image Synthesis (The Morgan Kaufmann Series in Computer Graphics) 2 Volume Set	Books	5	9	9	N	N	Excellent	Volume 1:<br />This book is comprehensive in scope and one of the most well-written technical books in existence. In the preface the author states 'I love to write', and considering the exceptional quality of this book, this indeed shows through.<br /> The first part of the book covers the human visual system, the understanding of which is fundamental to designing effective computer graphics. Several interesting topics are discussed, including Mach bands, color opponency, perceptual color matching, MacAdam ellipses, RGB color space, and gamut mapping.<br /> The second part covers more technical matters, namely that of signal processing. The mathematical background assumed of the reader increases dramatically in this part; some exposure to elementary calculus and differential equations would suffice. The author does a good job of explaining such concepts as linear operators and the Dirac bracket notation. The pictorial representation he gives of the convolution operation is very helpful. In addition, Fourier analysis is presented at a level that makes it very clear exactly what is happening to signals, both discrete and continuous, when taking the Fourier transform. The Fast Fourier transform is not discussed however, dissapointingly. Suprisingly, a whole chapter is devoted to wavelet transforms, a topic usually not included at this level. Wavelets are used as a tool to deal with nonstationary signals. Usually discussed at a very abstract level, the presentation here is crystal clear and vey intutive, and the reader will take away a deeper appreciation of these objects than what could have been obtained from the usual presentations.<br /> Chapter 7 is one of the most important in the book for it covers Monte Carlo techniques for evaluating the integrals that arise in image processing. The speed of convergance of Monte Carlo is addressed, along with how to estimate confidence levels when the parent distribution is normal. The author presents five different ways of doing 'blind' Monte Carlo, including rejection, blind stratified, weighted, and quasi Monte Carlo. Quasi Monte Carlo has taken on particular importance in recent years wherever Monte Carlo techniques are used. The author also presents four different ways of doing 'informed' Monte Carlo, i.e. when some information about the signal is known.<br /> Uniform sampling of continuous signals is done in the next chapter. After discussing an example of sampling and reconstruction, the author outlines in detail the mathematical theory behind the uniform sampling and reconstruction of one-and two-dimensional signals. The chapter ends with a discussion of a technique to reduce aliasing artifacts called supersampling.<br /> The next chapter covers nonuniform sampling and reconstruction. Naturally this is more complicated from a mathematical standpoint, due to the role of stochastic processes, but the author does a good job of discussing the relevant concepts. Most interesting is his treatment of the duality between aliasing and noise.<br /> Chapter 10 surveys some of the more modern and practical techniques used for sampling and reconstruction of two-dimensional signals. Uniform sampling is discussed in terms of rectangular and hexagonal lattices; nonuniform sampling in terms of Poisson sampling and N-books sampling. Pseudocode is given for the decreasing radius algorithm. The concept of a refinement test is introduced and broken down into five categories, each of which is discussed in detail. The refinement test allows one to decide when more samples are needed in a neighborhood, and refinement geometry indicates where the samples are to be placed. Refinement geometry is discussed in this chapter also, with linear and area bisection techniques outlined, along with multiple-level and tree-based sampling. Techniques for interpolation and reconstruction, such as warping are also treated, and the author gives brief overviews of one-dimensional and two-dimensional sampling theorems. Numerous other methods, going by several different names are also discussed.<br /> A very large set of references is given at the end of the book, covering a wide variety of topics in computer graphics and mathematical formalism. I have not read the second volume, but I am sure it respects the high quality of the first.Numerous other methods, going by several different names are also discussed. <br /> A very large set of references is given at the end of the book, covering a wide variety of topics in computer graphics and mathematical formalism. I have not read the second volume, but I am sure it respects the high quality of the first.	2001-10-14
1813338:US	50702879	R1NPDF4194JZZA	158705020X	434677947	Advanced MPLS Design and Implementation (CCIE Professional Development)	Books	4	6	7	N	Y	Very helpful	For those familiar with the basic rudiments of MPLS this book gives an excellent overview of the more advanced aspects of the subject. It is strictly a monograph, as there are no exercises in the book, but it could be used as a classroom textbook if it were supplemented with problem sets. The book is aimed at network engineers and managers, but those interested in the performance modeling of MPLS networks will find the book very useful.<br /><br />  The author begins the book with an elementary overview of MPLS, and why it was invented, namely to allow routers and ATM switches to do forwarding based on the contents of a label, and not route lookup.<br /><br /> In the next chapter, the role of MPLS in cloud technologies like TDM, Frame Relay, and ATM is discussed. The reader is expected to know about these technologies in detail, for only short reviews of each is given. The concept of a forward equivalence class (FEC) is introduced, and conventional layer 3 routing versus MPLS is discussed. The author does not discuss the performance issues involved with using MPLS routing versus ordinary layer 3 routing.<br /><br /> The advantages of using labels to do the forwarding instead of network layer forwarding are addressed in the next chapter on MPLS architecture. The author's treatment is very detailed and readers can expect a deeper understanding of the MPLS node architecture and control plane after finishing this chapter. The author emphasizes the unsuitability of OSPF, IS-IS, IGRP, RIP, and RIPv2 for label-binding information distribution. In addition, the ability of MPLS to detect and prevent routing loops is discussed.<br /><br /> Chapter 4 discusses the use of MPLS to construct VPNs. The author emphasizes the advantages of MPLS VPNs and gives a case study in the next chapter which discusses packet-based MPLS VPNs in more detail. The actual steps one would use to configure router-based MPLS VPNs are given. The most interesting section to me was the one on Internet access over MPLS VPNs.<br /><br /> ATM-based MPLS VPNs are discussed in chapter 6, with the author emphasizing the capability of MPLS of eliminating complexity in IP transport across ATM networks by mapping IP addressing and routing information directly into ATM switching tables. QoS guarantees can still be obtained in deploying MPLS IP VPNs over MPLS-aware ATM backbones. A case study is given of a packet-based MPLS over ATM VPN.<br /><br /> The most important chapter of the book for me was chapter 7, which discusses MPLS traffic engineering. Emphasizing the need for doing traffic engineering on the Internet, the author views it as a collection of autonomous systems communicating with each other via EGP. Emphasis is placed on the use of traffic engineering to optimize the traffic flow across the service-providers backbone using techniques such as OSPF and EIGRP unequal-cost load balancing. Noting that these metric manipulation techniques do not provide dynamic redundancy, and do not consider network capacity constraints, the author then discusses the advantages of doing MPLS traffic engineering. And again, the author shows explicitly how to configure devices to support MPLS traffic engineering. Configuration case studies are given for an MPLS traffic-engineered IS-IS network and an OSPF network. The chapter was somewhat disappointing in that there was no discussion on the performance issues involved with employing MPLS traffic engineering.<br /><br /> MPLS QoS is discussed in the next chapter, with emphasis on MPLS implementation of DiffServ and the MPLS VPN QoS pipe and hose models. In the pipe model, the service provider gives the customer a QoS guarantee for traffic flows between two CE routers in the same VPN; in the hose model, the provider gives the customer guarantees for the traffic that a CE router would send/receive from other CE routers in the same VPN. An MPLS QoS case study is given.<br /><br /> Chapter 9 addresses the design issues in implementing and migrating to MPLS, including VPN design and topologies, and ATM networks. The author briefly discusses how to estimate the unidirectional and bi-directional traffic matrices, how to calculate estimated link bandwidths, and how to do MPLS LVC sizing. A lot more however needs to be done from a modeling standpoint in the design phase, so as to raise the level of confidence in the design engineers' mind as to the resilience and performance of the MPLS design.<br /><br /> The last chapter covers the more exotic architectures that are currently being considered for MPLS implementation. These include Dense Division Wavelength Multiplexing (DWDM), which is a process of multiplexing signals of different wavelengths onto a single fiber, and Multiprotocol Lamda Switching, which is the optical analogue of MPLS. In addition, the capability of extending the control plane to the optical layer using the Unified Control Plane (UCP) is discussed. The UCP is a kind of distributed intelligence that includes the optical network elements.  The UCP overlay model, which uses two distinct control planes, and the UCP peer model , which only has one, are briefly discussed.<br /><br /> One can thus gain a lot from the reading of this book, but because MPLS is relatively new in the networking world, it is imperative for network designers to be able to experiment with different MPLS configurations in a laboratory and simulation setting. These issues are not addressed in this book, but one can use the information in the book as an adequate guide to assist in these important design activities.The author briefly discusses how to estimate the unidirectional and bi-directional traffic matrices, how to calculate estimated link bandwidths, and how to do MPLS LVC sizing. A lot more however needs to be done from a modeling standpoint in the design phase, so as to raise the level of confidence in the design engineers' mind as to the resilience and performance of the MPLS design.    The last chapter covers the more exotic architectures that are currently being considered for MPLS implementation. These include Dense Division Wavelength Multiplexing (DWDM), which is a process of multiplexing signals of different wavelengths onto a single fiber, and Multiprotocol Lamda Switching, which is the optical analogue of MPLS. In addition, the capability of extending the control plane to the optical layer using the Unified Control Plane (UCP) is discussed. The UCP is a kind of distributed intelligence that includes the optical network elements.  The UCP overlay model, which uses two distinct control planes, and the UCP peer model , which only has one, are briefly discussed.    One can thus gain a lot from the reading of this book, but because MPLS is relatively new in the networking world, it is imperative for network designers to be able to experiment with different MPLS configurations in a laboratory and simulation setting. These issues are not addressed in this book, but one can use the information in the book as an adequate guide to assist in these important design activities.	2001-10-11
1813927:US	50702879	R6ZKIIVLCV857	0201483408	653507021	Out of Control: The New Biology of Machines, Social Systems, & the Economic World	Books	4	21	25	N	Y	Interesting and provocative	The ideas in this book may be thought by some to be radical or far-fetched, but to those readers familiar with the behavior of complex dynamical systems, they seem quite natural. The book emphasizes the theoretical aspects of complex systems, but some natural examples of them are discussed. The author, in spite of his choice of title for the book,  is not threatened by the consequences of artifically creating these systems. After all, we live and have evolved in a universe that is even more complex than the author describes. The fact that we humans can now speed up the process of creation of these systems should be a source of wonder instead of fear.<br />What makes this book valuable reading is that the author emphasizes the collective behavior of dynamical systems. Too often the reductionist trend in Western science obscures how the system works together, how its many parts collectively induce an emergent behavior not at all apparent in the systems &quot;equations of motion&quot;.<br />Since the book is written for a popular audience, the approach is  qualitative and allegorical. This purely descriptive approach does however allow a more general overview of complex dynamical systems im many different areas. The author gives a fascinating discussion of swarm systems and their advantages and disadvantages. One of the disadvantages according to the author is that they are &quot;nonunderstandable&quot;; but here he is mistaken, for complex systems can be understood, although such an understanding takes some effort anc computational horsepower. Also, in his discussion of network behavior the author asserts that it is &quot;counterintuitive&quot; and quotes &quot;Braess's paradox&quot; as proof of this. Dietrich Braess discovered that adding routes to an already congested network will slow it down. There are examples of this, but it is not a hard-and-fast rule, as network engineers who employ load balancing can attest to. Adding time-dependent paths can work to reduce congestion, this time-dependence not addressed in Braess's formulation of the paradox.<br />Some more interesting discussions in the book are allegorical, but they serve to encourage &quot;thinking out of the box&quot;:1. The effects of isolation and boredom on the human mind: the need for the physical body to temper unruly constructions of the mind. 2. The chameleon riddle: what color will a chameleon take on if put in front of a mirror? 3.The Prisoner's dilemna. This has got to be the most widely used tool for encouraging cooperation, in spite of its simplicity and impracticality. Computer simulation of the Prisoner's dilemna with 1000 players has revealed phenomena familiar in evolutionary studies, such as parasitism, spontaneously emerging symbiosis, and long-term stable coexistence between species. 4. Physical systems as computational processes; this is the most radical of the ideas in the book, but the author does not expound upon it in any great detail though. 5. The Biosphere experiment; I only read brief news reports of this while it was going on, so it was interesting to read here a detailed account of it. 6. The need for industry to adopt &quot;biological&quot; methodologies: complexity is more efficient, less wasteful, and more robust. 7. Network economics: The &quot;network company&quot; of the 21st century will be distributed (no single location), decentralized, collaborative (outsourcing to competitors!), and adaptive. This chapter is the most practical of all those in the book. 8. The role of encryption in a digital economy, particularly &quot;encryption-metering&quot; and digital cash. 9. The importance of simulation in defense and industry in the 21st century: simulate before you build, simulate before you buy, and simulate before you fight. 10. The evolution machine and its resultant creation of sex; the consequent discussion of genetic/evolutionary programming. The differences between 'Lamarckian' and 'Darwinian&quot; evolutionary programs. 11. Postdarwinism: why have no new species been detected naturally or even in computer simulations? The central thesis of Neodarwinism is that only the environment can select mutations, but not induce or direct them.<br />Since this book was published in 1994, there have been many advances in the areas that the author discusses. Evolutionary programming has taken off, with many applications in finance, biology, network engineering, and large-scale circuit design. Swarm robots are currently under development, with deployment just years away. Computational/intelligent agents are now managing networks, with autonomous agents just around the corner.Encryption and smart-card technologies have mushroomed along with intelligent computer virus detection. Simulation is now thought of as a &quot;must-do&quot; in every phase of business and industry, and simulations are now thought of as sophisticated enough to model real-world situations without any experimental &quot;validation&quot;. Indeed, technological advancement and its application is moving forward at a dizzying rate, and seemingly...out of control?. Postdarwinism: why have no new species been detected naturally or even in computer simulations? The central thesis of Neodarwinism is that only the environment can select mutations, but not induce or direct them.<br />Since this book was published in 1994, there have been many advances in the areas that the author discusses. Evolutionary programming has taken off, with many applications in finance, biology, network engineering, and large-scale circuit design. Swarm robots are currently under development, with deployment just years away. Computational/intelligent agents are now managing networks, with autonomous agents just around the corner.Encryption and smart-card technologies have mushroomed along with intelligent computer virus detection. Simulation is now thought of as a &quot;must-do&quot; in every phase of business and industry, and simulations are now thought of as sophisticated enough to model real-world situations without any experimental &quot;validation&quot;. Indeed, technological advancement and its application is moving forward at a dizzying rate, and seemingly...out of control?	2001-10-10
1815540:US	50702879	R30A2VFNKWH32N	0817638407	330651452	A First Course in Geometric Topology and Differential Geometry (Modern Birkhuser Classics)	Books	4	9	10	N	N	Good introduction	This book is suitable for reading at an advanced undergraduate or beginning graduate level. The author is careful to present the subject from both a rigorous point of view and one that emphasizes the geometric intuition behind the subject. These two approaches to teaching topology are not mutually exclusive, with this book giving a good example of this.<br />After a brief overview of the elementary topology of subsets of Euclidean space in chapter 1, topological surfaces are discussed in chapter 2. Surfaces are built up from arcs, disks, and one-spheres. Unfortunately, the proofs of the theorem of invariance of domain and the Schonflies Theorem are not included, but references are given. Gluing techniques though are effectively discussed, and the author does not hesitate to use diagrams to explain the relevant concepts. The more popular constructions in surface topology, namely the Mobius strip and the Klein bottle are given as examples of the cutting and pasting techniques. The amusing fact that the Klein bottle can be obtained from gluing two Mobius strips along their boundaries is proven.<br />The theory of simplicial surfaces is discussed in the next chapter. Simplicial surfaces are much easier to deal with for beginning students of topology. Simplicial complexes are introduced first, and the author then studies which simplicial complexes have underlying spaces that are topological surfaces. He proves that this is the case when each one-dimensional simplex of the complex is the face of precisely two two-dimensional simplices, and the underlying space of each link of each zero-dimensional simplex of the complex is a one-dimensional sphere. Unfortunately, the author does not prove that any compact topological surface in n-dimensional Euclidean space can be triangulated. The Euler characteristic is defined first for 2-complexes and it is shown that it is the same for two simplicial surfaces that triangulate a compact topological surface. The author does prove in detail the classification of compact connected surfaces. Interestingly, the author also proves a simplicial analogue of the Gauss-Bonnet theorem, and gives a proof of the Brouwer fixed point theorem.<br />The author turns to smooth surfaces in the next few chapters, wherein curves are defined along with the relevant differential-geometric notions such as curvature and torsion. The fundamental theorem of curves is proven. The reader is first introduced to the concept of what in more advanced treatments is called a differentiable manifold, and several concrete examples are given of smooth surfaces. The differential geometry of smooth surfaces is outlined, with the first fundamental form and directional derivatives discussed in great detail. The reader should be familiar with the inverse function theorem to appreciate the discussion of regular values.<br />Even more interesting differential geometry is discussed in chapter 6, which covers the curvature of smooth surfaces. The important Gauss map is defined, along with the Weingarten map and the second fundamental form. This allows an intrinsic notion of curvature, but the author does perform explicit computations of curvature using various choices of coordinates. The proof that Gaussian curvature is intrinsic (Theorema Egregium) is proven, along with the fundamental theorem of surfaces. Geodesics, so important in physical applications, are discussed in the next chapter. The reader gets a first look at the &quot;Christoffel symbols&quot;, even though they are not designated as such in the book.<br />The book ends with a thorough treatment of the Gauss-Bonnet theorem for smooth surfaces. The smooth case is much more difficult to prove than the simplicial case, as the reader will find out when studying this chapter. The author also gives a very brief introduction to non-Euclidean geometry.detail the classification of compact connected surfaces. Interestingly, the author also proves a simplicial analogue of the Gauss-Bonnet theorem, and gives a proof of the Brouwer fixed point theorem. <br />The author turns to smooth surfaces in the next few chapters, wherein curves are defined along with the relevant differential-geometric notions such as curvature and torsion. The fundamental theorem of curves is proven. The reader is first introduced to the concept of what in more advanced treatments is called a differentiable manifold, and several concrete examples are given of smooth surfaces. The differential geometry of smooth surfaces is outlined, with the first fundamental form and directional derivatives discussed in great detail. The reader should be familiar with the inverse function theorem to appreciate the discussion of regular values. <br />Even more interesting differential geometry is discussed in chapter 6, which covers the curvature of smooth surfaces. The important Gauss map is defined, along with the Weingarten map and the second fundamental form. This allows an intrinsic notion of curvature, but the author does perform explicit computations of curvature using various choices of coordinates. The proof that Gaussian curvature is intrinsic (Theorema Egregium) is proven, along with the fundamental theorem of surfaces. Geodesics, so important in physical applications, are discussed in the next chapter. The reader gets a first look at the &quot;Christoffel symbols&quot;, even though they are not designated as such in the book. <br />The book ends with a thorough treatment of the Gauss-Bonnet theorem for smooth surfaces. The smooth case is much more difficult to prove than the simplicial case, as the reader will find out when studying this chapter. The author also gives a very brief introduction to non-Euclidean geometry.	2001-10-10
1824211:US	50702879	R1CHJOB7V9YSYL	0132126052	700995777	Differential Topology	Books	4	11	16	N	N	A good start....	Differential topology has influenced many areas of mathematics, and also has many applications in physics, engineering, comptuer graphics, network engineering, and economics. The authors, well-known contributors to the field, have written a nice introduction in this book, which is suitable for readers having a background in linear algebra and advanced calculus.<br />  The authors begin the book with a general overview of manifolds and smooth maps between them. The local behavior of smooth maps is studied first, such behavior determined by the derivative (modulo a diffeomorphism). The inverse function theorem is stated but not proved, the authors encouraging the reader to do the proof using local parametrizations. Generalizations of local diffeomorphisms, the immersions, are discussed, and the local immersion theorem proved. Immersions that are injective and proper, the embeddings, are then discussed. When the dimension of the target manifold is less than or equal to the domain manifold, the surjectivity of the derivative of the map at every point leads to the map being what is called a submersion. Submersions can be viewed as generalizations of projection maps of standard Euclidean space to one of equal or lower dimension. The authors prove this as the local submersion theorem. Regular values of smooth maps are defined and the authors show that the premiage of regular values are submanifolds. A brief discussion of Lie groups is given as an application of the preimage theorem.<br />  The main theme of the book, a generalization of the notion of regularity, called transversality, is also introduced in this chapter. The concept of transversality is fully elaborated on in chapter 2, in the context of manifolds with boundary. Sard's theorem is proved for manifolds with and without boundary. The Transversality Theorem for families of smooth maps is proven in detail, showing that transversal maps are generic when the target manifold is Euclidean space. The authors give an excellent discussion of intersection theory modulo two, along with the famous Jordan-Brouwer separation theorem and Borsuk-Ulam theorem.<br />  In order to make intersection numbers an invariant of homotopy, intersection theory for oriented manifolds is considered in chapter 3. It is shown that homotopic maps always have the same intersection numbers. This brings up naturally the subject of Lefschetz fixed-point theory and the authors give a very clear overview of this. Index theory and the famous Poincare-Hopf index theorem are discussed in this chapter also, along with the Hopf degree theorem. And, thankfully, the authors do not hesitate to employ a myriad of diagrams to illustrate the main points and develop intuition.<br />  The last chapter of the book is more formal than the rest of the book, and covers integration on manifolds. A familiar subject in courses on advanced calculus, the authors do a good job of discussing exterior algebra, differential forms, how to integrate these on manifolds via suitable partitions of unity, and how to differentiate these on manifolds. A very brief introduction to de Rham cohomology is given. The famous Gauss-Bonnet theorem is shown to follow from the Poincare-Hopf theorem.ve an excellent discussion of intersection theory modulo two, along with the famous Jordan-Brouwer separation theorem and Borsuk-Ulam theorem. <br />     In order to make intersection numbers an invariant of homotopy, intersection theory for oriented manifolds is considered in chapter 3. It is shown that homotopic maps always have the same intersection numbers. This brings up naturally the subject of Lefschetz fixed-point theory and the authors give a very clear overview of this. Index theory and the famous Poincare-Hopf index theorem are discussed in this chapter also, along with the Hopf degree theorem. And, thankfully, the authors do not hesitate to employ a myriad of diagrams to illustrate the main points and develop intuition. <br />    The last chapter of the book is more formal than the rest of the book, and covers integration on manifolds. A familiar subject in courses on advanced calculus, the authors do a good job of discussing exterior algebra, differential forms, how to integrate these on manifolds via suitable partitions of unity, and how to differentiate these on manifolds. A very brief introduction to de Rham cohomology is given. The famous Gauss-Bonnet theorem is shown to follow from the Poincare-Hopf theorem.	2001-09-30
1830889:US	50702879	R1S1VME3AB34PG	0131038052	252861181	Artificial Intelligence: A Modern Approach	Books	5	78	97	N	Y	The optimal learning algorithm for learning A.I.	Progress in the field of artificial intelligence has executed a random walk after establishing itself with a bang in the 1950s. Optimistic predictions of the future of A.I. in that decade only partially came true in the decades after that. Currently, the field is divided up into subfields going by the names data mining, computational intelligence, intelligent agent theory, expert systems, etc. This book is the best book available for learning about this fascinating and important subject. The applications of A.I. are enormous, and will increase dramatically in the decades ahead. Indeed the prospects are very exciting, and the authors themselves have been involved heavily in extending the frontiers of the subject. Some of the main points of the book that really stand out include:<br />1. The useful exercises at the end of each chapter. 2. The discussion of simple reflex and goal-based agents. 3. The treatment of constraint satisfaction problems and heuristics for these kinds of problems. 4. The overview of iterative improvement algorithms, particularly the discussion of simulated annealing. 5. The discussion of propositional logic and its limitations as an effective A.I. paradigm. 6. The treatment of first-order logic and its use in modeling simple reflex agents, change, and its use in situation calculus. There is a good overview of inference in first-order logic in chapter 9 of the book, including completeness and resolution. 7. The treatment of logic programming systems; the Prolog language is discussed as a logical programming language. Noting that Prolog cannot specify constraints on values, the authors discuss constraint logic programming (CLP) as an alternative logic programming language that allows constraints. 8. The discussion of semantic networks and description logics. 9. The treatment of conditional programming via the conditional partial-order planner (CPOP). 10. Representing knowledge in an uncertain domain and the semantics and inference in belief networks. 11. The brief discussions on stochastic simulation methods and fuzzy logic. 12. The discussion on computational learning theory 13. The treatment of neural networks, especially the discussion of multilayer feed-forward networks and the comparison between belief networks and neural networks. 14. The brief discussion on genetic algorithms and evolutionary programming. 15. The discussion on explanation-based learning and the technique of memoization. 16. The (excellent) overview of inductive logic programming. This relatively recent area was new to me at the time of reading so I appreciated the discussion. The authors briefly mention the approach of discovery systems and the Automated Mathematician (AM). 17. The interesting discussion of telepathic communication between robots via the exchange of internal representations. 18. The discussion on a formal grammar for a subset of English and the extensive treatment of natural language processing. 19. The discussion of speech recognition and the use of hidden Markov models and the Viterbi algorithm. 20. The fascinating discussion on robotics, particularly the treatment of configuration spaces, which brings in some techniques from computational geometry and topology. 21. The discussion on the philosophical ramifications of A.I. Future developments in A.I. will provide a unique testing ground for philosophy, in a way that will be unparalleled in the history of philosophy. Philosophers critical of A.I. will have the opportunity to check whether their arguments against the possibility of &quot;strong A.I.&quot;, are in fact true.s. 11. The brief discussions on stochastic simulation methods and fuzzy logic. 12. The discussion on computational learning theory 13. The treatment of neural networks, especially the discussion of multilayer feed-forward networks and the comparison between belief networks and neural networks. 14. The brief discussion on genetic algorithms and evolutionary programming. 15. The discussion on explanation-based learning and the technique of memoization. 16. The (excellent) overview of inductive logic programming. This relatively recent area was new to me at the time of reading so I appreciated the discussion. The authors briefly mention the approach of discovery systems and the Automated Mathematician (AM). 17. The interesting discussion of telepathic communication between robots via the exchange of internal representations. 18. The discussion on a formal grammar for a subset of English and the extensive treatment of natural language processing. 19. The discussion of speech recognition and the use of hidden Markov models and the Viterbi algorithm. 20. The fascinating discussion on robotics, particularly the treatment of configuration spaces, which brings in some techniques from computational geometry and topology. 21. The discussion on the philosophical ramifications of A.I. Future developments in A.I. will provide a unique testing ground for philosophy, in a way that will be unparalleled in the history of philosophy. Philosophers critical of A.I. will have the opportunity to check whether their arguments against the possibility of &quot;strong A.I.&quot;, are in fact true.	2001-09-24
1831234:US	50702879	R2MWR1ARU5H88I	0805394850	833245912	Differential Topology; First Steps (Mathematics Monograph Series)	Books	4	26	27	N	N	A quickie on differential topology	In this book, the author has given a quick taste of a very important subject, both in mathematics and in applications. Differential topology has found a niche in economics, physics, financial engineering, computer graphics, and computational biology, and it will no doubt find many more in years to come. It is also an area of mathematics that is still advancing, and there are many unsolved problems that can lead to interesting research programs. The author reviews elementary topology in the first chapter and then immediately introduces differentiable manifolds in the next. The presentation is very clear, and the author does not hesitate to use pictures to motivate and illustrate the main points. All of the discussion in these two chapters can be read easily by someone with a background in undergraduate calculus and some linear algebra. Special subsets of differentiable manifolds, the submanifolds, are considered in chapter 3, with the important embedding theorem proved. The theory of critical points follows in the next chapter. Although Morse theory is not mentioned, the author does define nondegenerate critical points, and shows, via a collection of exercises, the well-known result that a differentiable function in a neighborhood of such a point can be written as a quadratic form. A stronger embedding theorem is proven, namely one that allows an embedding of a compact manifold in such a way that the critical points are all nondegenerate. This discussion is generalized in the next chapter to critical and noncritical levels. The author motivates well the study of the neighborhood of a critical level by first discussing the properties of critical levels in the torus. The changing of the topology as one sweeps through the critical levels in this chapter is viewed as the process of spherical modification in the next one. The author does define what is meant by spherical modification, but does not use the usual terminology to discuss it, such as &quot;cobordism&quot; etc. he does however discuss the process of isotopy, and illustrates general position by means of intersections of curves. He illustrates these results in chapter 7 in the classification of two-dimensional manifolds. The usual proof is done in terms of simplicial complexes, but here the author proves it for differentiable 2-manifolds using critical point theory. The author ends the book by discussing how the subject could be pursued if the tools of algebraic topology were brought in. He discusses the killing of homotopy groups and motivates the theorem that an orientable compact 3-dimensional manifold can be obtained from a 3-sphere by cutting out a finite number of disjoint solid tori and filling the holes again with solid tori, with suitable identification of boundaries. He does not however prove when such constructions lead to the same 3-manifold, for this would lead to a resolution of the three-dimensional Poincare conjecture.....he does however discuss the process of isotopy, and illustrates general position by means of intersections of curves. He illustrates these results in chapter 7 in the classification of two-dimensional manifolds. The usual proof is done in terms of simplicial complexes, but here the author proves it for differentiable 2-manifolds using critical point theory. The author ends the book by discussing how the subject could be pursued if the tools of algebraic topology were brought in. He discusses the killing of homotopy groups and motivates the theorem that an orientable compact 3-dimensional manifold can be obtained from a 3-sphere by cutting out a finite number of disjoint solid tori and filling the holes again with solid tori, with suitable identification of boundaries. He does not however prove when such constructions lead to the same 3-manifold, for this would lead to a resolution of the three-dimensional Poincare conjecture.....	2001-09-23
1831310:US	50702879	R1LV96QUW2EDRF	0387948686	488154134	An Introduction to Kolmogorov Complexity and Its Applications (Texts in Computer Science)	Books	5	25	27	N	N	The only one of its kind....	The theory of Kolmogorov complexity  attempts to define randomness in terms of the complexity of the program used to compute it. The authors give an excellent overview of this theory, and even discuss some of its philosophical ramifications, but they are always careful to distinguish between mathematical rigor and philosophical speculation. And, interestingly, the authors choose to discuss information theory in physics and the somewhat radical idea of reversible computation. The theory of Kolmogorov complexity is slowly making its way into applications, these being coding theory and computational intelligence, and network performance optimization, and this book serves as a fine reference for those readers interested in these applications. Some of the main points of the book I found interesting include: 1. A very condensed but effective discussion of Turing machines and effective computability. 2. The historical motivation for defining randomness and its defintiion using Kolmogorov complexity. 3. The discussion of coding theory and its relation to information theory. The Shannon-Fano code is discussed, along with prefix codes, Kraft's inequality, the noiseless coding theorem, and universal codes for infinite source word sets. 4. The treatment of algorithmic complexity. The authors stress that the information content of an object must be intrinsic and independent of the means of description. 5. The discussion of the explicit universal randomness test. 6. The discussion  (in an exercise) of whether a probabilistic machine can perform a task that is impossible on a deterministic machine. 7. The notion of incompressibility of strings. 8. The discussion of randomness in the Diophantine equations; it is shown that the set of indices of the Diophantine equations with infinitely many different solutions is not recursively enumerable; with the initial segment of length n in the characteristic sequence having Kolmogorov complexity n. 9. The discussion on algorithmic probability, especially the test for randomness by martingales. 10. The Solomonoff theory of prediction and its ability to solve the problem of induction. 11. The treatment of Pac-learning and the resultant formalization of Occam's razor. 12. The discussion of compact routing; the optimal space to represent routing schemes in communication networks on the average for all static networks. 13. Computational complexity and its connection to resource-bounded complexity. 14. The notion of logical depth, i.e. the time required by a universal computer to compute the object from its compressed original description. 15. The connection between algorithmic complexity and Shannon's entropy. 16. The discussion on reversible computation, i.e. logically reversible computers that do not dissipate heat. 17. The treatment of information distance, i.e. for two strings, the minimal quantity of information sufficient to translate from one to the other.y, especially the test for randomness by martingales. 10. The Solomonoff theory of prediction and its ability to solve the problem of induction. 11. The treatment of Pac-learning and the resultant formalization of Occam's razor. 12. The discussion of compact routing; the optimal space to represent routing schemes in communication networks on the average for all static networks. 13. Computational complexity and its connection to resource-bounded complexity. 14. The notion of logical depth, i.e. the time required by a universal computer to compute the object from its compressed original description. 15. The connection between algorithmic complexity and Shannon's entropy. 16. The discussion on reversible computation, i.e. logically reversible computers that do not dissipate heat. 17. The treatment of information distance, i.e. for two strings, the minimal quantity of information sufficient to translate from one to the other.	2001-09-23
1842590:US	50702879	ROIAGC77PTAIH	0471113530	791177593	Writing Compilers and Interpreters	Books	4	11	13	N	N	Takes some effort	The author has written a fine book for the experienced C++ programmer who wants to write a compiler or an interpreter. A lot of time will be needed to get through the book, and some knowledge of Pascal. The author takes great care in introducing the elementary concepts of compilers and code is immediately introduced to implement them. Each chapter then builds on the preceding one, and the author attempts to follow the object-oriented paradigm as much as possible. He uses class diagrams to show how a program's classes are defined and related to one another, and uses object diagrams to show how they behave at runtime. His approach here is a simplified version of the one developed by G. Booch, which is used extensively in modern object-oriented design. The reader interested in the theory of compilers should probably read another book alongside this one. Given the time and effort, a very determined reader could sort through all the source code and gain a thorough practical understanding of how to write a compiler or interpreter.	2001-09-11
1842668:US	50702879	RMEON6A2EP4VX	3540672974	440611488	Theory of Evolution Strategies	Books	5	9	10	N	N	The first of its kind	This is the first book that I am aware of that addresses the foundations of evolutionary and genetic algorithms, evolution strategies, and evolutionary programming from a rigorous mathematical point of view. The book is designed for an audience of mathematicians and computer scientists who are curious about evolutionary strategies and need a formal treatment of its foundations. Readers currently involved in designing and writing genetic programs will find this book helpful in the optimizing of their algorithms, even though at times they might find the presentation a little heavy-handed.<br /> Evolutionary strategies are thought of as dynamical systems in the book, but these are not in general deterministic, but probabilistic in nature. The state space of the dynamical system consists of the direct product of an object parameter space, an endogenous strategy parameter set, and a collection of fitness functions. Evolution takes place in this state space via the &quot;genetic operators&quot;, i.e. the selection, mutation, reproduction, and recombination operators. The goal of course is to find an optimum solution to the problem, and so a consideration of the convergence of the evolution strategy to this optimum must be addressed.<br /> These issues and others, such as the differentiation between evolutionary strategies and ordinary Monte Carlo methods, are discussed in great detail in the book. The author emphasizes that the mechanism of evolutionary strategies lies in the local properties of state space, the evolutionary process being obtained by small steps in this space. He also suggests three prerequisites for the working of evolutionary algorithms, namely the evolutionary progress principle, the genetic repair hypothesis, and mutation-induced operation by recombination. The first is the statement that each change of the individuals in the state space can result in fitness gain as well as fitness loss. The second is a device employed for statistical estimation, and attempts to answer why recombinant evolution strategies are better than nonrecombinant strategies. The third is the statement that dominant recombination causes cohesion of a population and is represented by a local operator which transforms the mutations by a random sampling process.<br /> The author makes use of differential geometry in the book to establish a theoretical framework to predict the local performance of evolution strategies. The hypersurface model is constructed as a fitness model for the calculation of progress measures, and for an elementary model of evolution dynamics. Tensor calculus is employed to study deformations of the sphere model, with the goal of obtaining useful formulae for the progress rate. A mean radius of this deformation is calculated, to serve as a substitute radius in the progress rate formulae for the sphere model.<br /> For the case of (1+1)-selection, i.e. one parent and one offspring, where both parents and offspring are contained in the selection pool, the author derives exact integral representations for the progress rate. The quality gain for one parent and any member of offspring is also considered, and the author derives an integral expression for it using an approximation of the distribution function of the mutation-induced fitness distribution. He argues that the progress rate and the quality gain are progress measures that describe totally different aspects of the performance of evolution strategies.<br /> The general problem of an evolution strategy with arbitrary numbers of parents and offspring is also considered. Since the distribution of parents in the parameter space is unknow, and since it changes in successive generations, this makes the analysis of the progress rate extremely difficult. The author does however derive the relations for this model in terms of a formal expression for the progress rate which is given as an integral over the distribution of a single descendant, which is generation-dependent and unknown. This distribution is approximated using Hermite polynomials and the determination of this function is then reduced to the finding of a collection of coefficients. These coefficients are functions of moments of the offspring and are estimated by the random selection process of the evolution strategy.<br /> Recombinative evolution strategies are also studied by the author, and two special recombination types considered, namely the intermediate and dominant cases. Intermediate recombination is shown to lead to higher performance compared to nonrecombinativie strategies. The dominant case is shown to lead to mutation-induced speciation by recombination.<br /> The author also analyzes the dynamic adaptation of the mutation strength to the local topology of the fitness landscape. Self-adaptation, which is the method for applying evolution to the adjustment of optimal strategy parameter values, is given detailed treatment for the case of one parent in terms of mean value dynamics.and unknown. This distribution is approximated using Hermite polynomials and the determination of this function is then reduced to the finding of a collection of coefficients. These coefficients are functions of moments of the offspring and are estimated by the random selection process of the evolution strategy. <br /> Recombinative evolution strategies are also studied by the author, and two special recombination types considered, namely the intermediate and dominant cases. Intermediate recombination is shown to lead to higher performance compared to nonrecombinativie strategies. The dominant case is shown to lead to mutation-induced speciation by recombination. <br /> The author also analyzes the dynamic adaptation of the mutation strength to the local topology of the fitness landscape. Self-adaptation, which is the method for applying evolution to the adjustment of optimal strategy parameter values, is given detailed treatment for the case of one parent in terms of mean value dynamics.	2001-09-11
1842685:US	50702879	R7HAHFMV1P5VX	0201100886	252944232	Compilers: Principles, Techniques, and Tools	Books	4	20	21	N	N	Has done its job well	For those interested in the more general and theoretical principles behind compilers, this book can still serve as a good introduction in that regard. More modern treatments are available to those who need more information on modern developments in compilers, such as optimization, partial evaluation, etc. The book covers lexical analysis, parsing techniques, syntax-directed translation, static semantic checking, type checking, unification, target code generation, and compiler code optimization. All of these are discussed in great detail, the C language is chosen to write the compiler coding, and numerous exercises are put at the end of the each chapter. The reader can also gain an insight into the historical origins of the subject.	2001-09-11
1848114:US	50702879	RC2MRMSE5WRHK	0138456038	299298933	Statistical Thermophysics	Books	4	11	11	N	N	Good book from the standpoint of information theory	Statistical physics, mostly from the viewpoint of information theory, is the subject of this book, with the author freely admitting his intent to follow the work of Gibbs, Callen, Jaynes, and others in laying the foundations of the subject, and not that of Boltzmann. Without space to debate this approach here, what will be done is to emphasize the unique features of the book that have proven interesting or useful for study.<br /> Appropriately, the book begins with a discussion of probability theory and its connection with information theory. The assignment of probabilities to a set of events is taken to represent information. The Shannon information entropy is derived and its role as a measure of uncertainty discussed. By maximizing the uncertainty subject to the usual constraints that the probabilities add to one and the equation for the mean value, the partition function is derived. Several examples are given to illustrate the time evolution of the probabilities and the approach to equilibrium. The examples also illustrate the evolution of the probabilities to a time-independent set that maximizes the uncertainty. An example of coupled harmonic oscillators is given to illustrate the approach to equilibrium, the equipartition of energy, and the evolution of the uncertainty to a value determined by the heat bath. The author is very detailed in this example, and he does not hestitate to use advanced mathematics when necessary. A highly interesting commentary on statistical physics is given at the end of the chapter.<br /> A statistical models for thermostatics is developed in chapter 2 using the Shannon information entropy. The usual thermophysical relations are derived, and a thorough treatment of equilibrium thermodynamics is given, including the Maxwell relations. Most importantly, the author discusses the stability of equilibrium. Nonideal gases, such as van der Waals, and more practical topics such as chemical equilibrium, are discussed briefly.<br /> The derivation of the fundamental relations of macroscopic thermodynamics from microphysical principles, or equilibrium statistical thermodynamics, is the subject of chapter 3. The treatment is pretty standard, with microcanonical, canonical, and grand canonical systems all discussed, via the calculating of the partition function. The calculation of the partition function for the general ideal gas is done nicely, and the author again returns to chemical equilibria but here in the context of the chapter.<br /> Fermi-Dirac and Bose-Einstein statistics are given an elegant presentation in chapter 4, with a discussion of white dwarfs and neutron stars included. The treatment of Bose-Einstein condensation is somewhat dated, given the current experimental results.<br /> The thermodynamics of dielectric and magnetic systems is discussed in the next chapter. The author is careful to include only those terms in the Hamiltonian for these systems that are due to local fields. This is helpful since most treatments on this topic in the literature are a little confusing.<br /> Chapter 6 gives a detailed overview of phase transtions. The author distinguishes between first and second order phase transitions and the Landau theory and critical exponents are discussed.<br /> Interactions between particles are considered in chapter 7, with the Ising model leading off the discussion, and its solution tackled first using the mean-field approximation. The exact solution of the one-dimensional Ising model is given, showing its analyticity. The transfer-matrix method is discussed, which is nice considering its importance in the area of exactly solved models in statistical physics. Raising the dimension by one causes more difficulties mathematically, but the Ising model in two dimensions is treated nicely using combinatorial and dimer-pfaffian methods.<br /> Of upmost importance in fundamental theories of physics, such as quantum field theory, renormalization is treated in chapter 8, beginning with spin systems and via the Wilson approach.<br /> The theory of irreversible processes is the subject of chapter 9, with the Onsager theory given initial consideration. The author does not neglect the Boltzmann equation, and the use of the relaxation-time approximation in its study. The hydrodynamic equations are derived using the zeroth-order approximation. The Pauli master equation is discussed as an equation for the time evolution of probabilities from the Markov process point of view. Quantum statistical physics is introduced via the statistical operator. The approach is the same as that taken in quantum field theory. Information-theoretic approaches are brought in, one being time-dependent maximum entropy formalism.<br /> The book ends with a study of fluctuations, such as the Brownian motion of a particle on a lattice and the Langevin equation. The discussion of spectral density and autocorrelation functions reads like one straight out of a book on signal processing. The author again discusses response theory, introduces superoperator techniques, and proves the Kramers-Kronig relations.g with spin systems and via the Wilson approach. <br /> The theory of irreversible processes is the subject of chapter 9, with the Onsager theory given initial consideration. The author does not neglect the Boltzmann equation, and the use of the relaxation-time approximation in its study. The hydrodynamic equations are derived using the zeroth-order approximation. The Pauli master equation is discussed as an equation for the time evolution of probabilities from the Markov process point of view. Quantum statistical physics is introduced via the statistical operator. The approach is the same as that taken in quantum field theory. Information-theoretic approaches are brought in, one being time-dependent maximum entropy formalism. <br /> The book ends with a study of fluctuations, such as the Brownian motion of a particle on a lattice and the Langevin equation. The discussion of spectral density and autocorrelation functions reads like one straight out of a book on signal processing. The author again discusses response theory, introduces superoperator techniques, and proves the Kramers-Kronig relations.	2001-09-06
1851791:US	50702879	R1203LF3RK4QEV	0387942696	830218774	Commutative Algebra: with a View Toward Algebraic Geometry (Graduate Texts in Mathematics)	Books	5	47	52	N	N	Superb	If one is interested in taking on a thorough study of algebraic geometry, this book is a perfect starting point. The writing is excellent, and the student will find many exercises that illustrate and extend the results in each chapter. Readers are expected to have an undergraduate background in algebra, and maybe some analysis and elementary notions from differential geometry. Space does not permit a thorough review here, so just a brief summary of the places where the author has done an exceptional job of explaining or motivating a particular concept:<br />(1) The history of commutative algebra and its connection with algebraic geometry, for example the origin of the concept of an &quot;ideal&quot; of a ring as generalizing unique factorization.<br />(2) The discussion of the concept of localization, especially its origins in geometry. A zero dimensional ring (collection of &quot;points&quot;) is a ring whose primes are all maximal, as expected.<br />(3) The theory of prime decomposition as a generalization of unique prime factorization. Primary decomposition is given a nice geometric interpretation in the book.<br />(4) Five different proofs of the Nullstellensatz discussed, giving the reader good insight on this important result.<br />(5) The geometric interpretation of an associated graded ring corresponding to the exceptional set in the blowup algebra.<br />(6) The notion of flatness of a module as a continuity of fibers and a test for this using the Tor functor.<br />(7) The characterization of Hensel's lemma as a version of Newton's method for solving equations. The geometric interpretation of the completion as representing the properties of a variety in neighborhoods smaller than Zariski open neighborhoods.<br />(8) The characterization of dimension using the Hilbert polynomial.<br />(9) The fiber dimension and the proof of its upper semicontinuity.<br />(10) The discussion of Grobner bases and flat families. Nice examples are given of a flat family connecting a finite set of ideals to their initial ideals.<br />(11) Computer algebra projects for the reader using the software packages CoCoA and Macaulay.<br />(12) The theory of differentials in algebraic geometry as a generalization of what is done in differential geometry.<br />(13) The discussion of how to construct complexes using tensor products and mapping cones in order to study the Koszul complex.<br />(14) The connection of the Koszul complex to the cotangent bundle of projective space.<br />(15) The geometric interpretation of the Cohen-Macauley property as a map to a regular variety.cting a finite set of ideals to their initial ideals.<br />(11) Computer algebra projects for the reader using the software packages CoCoA and Macaulay. <br />(12) The theory of differentials in algebraic geometry as a generalization of what is done in differential geometry.<br />(13) The discussion of how to construct complexes using tensor products and mapping cones in order to study the Koszul complex.<br />(14) The connection of the Koszul complex to the cotangent bundle of projective space. <br />(15) The geometric interpretation of the Cohen-Macauley property as a map to a regular variety.	2001-09-03
1851977:US	50702879	R1BDQZDT7YCFFY	0387943706	712354458	Quantum Groups (Graduate Texts in Mathematics)	Books	5	7	10	N	N	For quantum mathematicians	This book is further evidence of the tremendous influence that quantum physics, especially quantum field theory and superstring theory, has had on modern mathematics. Very rich mathematical structures and simplified methods of proof have resulted from looking at mathematics from a quantum point of view. Because of the enormous success of viewpoint, examples being proofs of the Atiyah-Singer index theorem, the Jones polynomial, and the Seiberg-Witten equations, one could justify a rephrasing of the remark by Eugene Wigner and now speak of &quot;the reasonable effectiveness of physics in mathematics&quot;.<br /> The book gives a fine overview of a field that has only been around for a few decades, and is manifested by brilliant developments. Those who have worked with the Yang-Baxter equations from the theory of exactly solved models in statistical mechanics will see these equations come alive here in a much more general form. In addition, knot theorists and geometric topologists will appreciate the discussion of how their constructions can be cast in the tensor and tangle categories that are explained in detail in this book. The title of the book is a little strange, given that the structures treated are more specific than groups, but the author has explained well the theory of quantum groups, as is it is now referrred to in journal classification schemes.<br /> An in-depth reading of the book is time-consuming, and no doubt the average reader will not read it from cover to cover but instead will peruse only the areas of immediate interest. Part One of the book is an overview of what the author calls quantum SL(2), which is an example of a Hopf algebra. The first two chapters are purely a review of algebra, with the third being an introduction to coalgebras, which the author, in a categorical sense, identifies as being dual to an algebra. The notion of a bialgebra is also discussed, which is essentially a vector space equipped with both an algebra structure and a coalgebra structure. Taking a tensor product of this vector space with itself and examining certain morphisms between these structures gives a set of compatibility conditions that define the bialgebra structure. A Hopf algebra is then a bialgebra that has a special endomorphism of the underlying vector space. The algebraic topologist reader will be familiar with Hopf algebras via studies of product manifolds such as Lie groups. Quantum groups have given many examples of non-commutative non-cocommutative bialgebras than were known before this research area had taken off. The author also discusses the quantum plane as an object that generalizes the affine plane, namely the two variables x, y generating the plane no longer commute but instead satisfy yx = q xy. The author investigates in detail the quantum group SLq(n), which is based on the classical Lie group. References are given for quantum groups based on the other Lie groups, such as the orthogonal and symplectic groups. The Lie algebra Uq(sl(2)) is given a detailed treatment by the author when q is not a root of unity. This Hopf algebra is a 1-parameter deformation of the enveloping algebra of the Lie algebra sl(2) considered in earlier chapters. The reader interested in the renormalization is strongly urged to read this first part, as recently it has been shown that for any quantum field theory, the combinatorics of Feynman diagrams gives rise to a Hopf algebra which is commutative as an algebra, and is the dual Hopf algebra of the enveloping algebra of a Lie algebra whose basis is labelled by one particle irreducible Feynman diagrams. The Lie bracket of two diagrams is computed from insertions of one graph in the other and vice versa, and the Lie group G is the group of characters of the Hopf algebra. This structure is used to go on and formulate the renormalization problem rigorously.<br /> Part two is an overview of the famous Yang-Baxter equation whose exact solutions in terms of R-matrices have generated a vast amount of research. The author introduces the concept of a braided bialgebra, which contain a &quot;universal&quot; R-matrix which induces a solution of the Yang-Baxter equation on all of their modules, and thus giving a systematic method for constructing solutions of the Yang-Baxter equation. The duals of these bialgebras give a cobraided bialgebra, and the author shows how to construct a cobraided bialgebra out of any solution of the Yang-Baxter equation. It is also shown how the quantum groups GLq(2) and SLq(2) can be obtained by this method, and it is proven that they are cobraided. The famous Drinfeld quantum double, yielding a braided Hopf algebra out of any finite-dimensional Hopf algebra with invertible antipode, is discussed in great detail.<br /> The next part is basically low-dimensional topology in the form of knots, links, and braids, wherein the author discusses the relationship between the Jones polynomial and R-matrices. The connection between knot theory and quantum groups is given by the representation theory of Hopf algebras, this connection taking place in the tensor category. A certain strict tensor category is built out of tangles, and shown to give isotopy invariants of links. Braiding in the tensor category is used to formalize the notion of crossing in link and tangle diagrams. Tensor categories modeled on framed tangles or &quot;ribbons&quot; are introduced to illustrate duality. The concept of a quasi-bialgebra is introduced and braid group representations of these are constructed. When quasi-bialgebras are equivalent under a &quot;gauge transformation&quot; introduced here, they have the same braid group representation.<br /> The last part considers the role of monodromy in the theory of quantum groups. The quantum enveloping algebras due to Drinfeld and Jimbo are discussed and shown to provide isotopy invariants of links. The monodromy of the Knizhnik-Zamolodchikov system is shown to be equivalent to the braid group representation of this system. Knot invariants of finite type are shown to be universal invariants for quantum groups.vast amount of research. The author introduces the concept of a braided bialgebra, which contain a &quot;universal&quot; R-matrix which induces a solution of the Yang-Baxter equation on all of their modules, and thus giving a systematic method for constructing solutions of the Yang-Baxter equation. The duals of these bialgebras give a cobraided bialgebra, and the author shows how to construct a cobraided bialgebra out of any solution of the Yang-Baxter equation. It is also shown how the quantum groups GLq(2) and SLq(2) can be obtained by this method, and it is proven that they are cobraided. The famous Drinfeld quantum double, yielding a braided Hopf algebra out of any finite-dimensional Hopf algebra with invertible antipode, is discussed in great detail. <br /> The next part is basically low-dimensional topology in the form of knots, links, and braids, wherein the author discusses the relationship between the Jones polynomial and R-matrices. The connection between knot theory and quantum groups is given by the representation theory of Hopf algebras, this connection taking place in the tensor category. A certain strict tensor category is built out of tangles, and shown to give isotopy invariants of links. Braiding in the tensor category is used to formalize the notion of crossing in link and tangle diagrams. Tensor categories modeled on framed tangles or &quot;ribbons&quot; are introduced to illustrate duality. The concept of a quasi-bialgebra is introduced and braid group representations of these are constructed. When quasi-bialgebras are equivalent under a &quot;gauge transformation&quot; introduced here, they have the same braid group representation. <br /> The last part considers the role of monodromy in the theory of quantum groups. The quantum enveloping algebras due to Drinfeld and Jimbo are discussed and shown to provide isotopy invariants of links. The monodromy of the Knizhnik-Zamolodchikov system is shown to be equivalent to the braid group representationof this system. Knot invariants of finite type are shown to be universal invariants for quantum groups.	2001-09-03
1852891:US	50702879	R2RYS6YT3BZX9D	0387984380	250381866	Moduli of Curves (Graduate Texts in Mathematics)	Books	5	20	21	N	N	Superb	The canonical strategy of modern mathematics when studying an object is to put this object into a collection, and see what properties they have in common. Most commonly, the objects depend on some parameter(s), and the goal is to find out how the objects vary with these parameters. The authors of this book take this approach to studying algebraic curves, with the parametrization being called the moduli space, and it enables one to gain information about the geometry of a family of objects from the moduli space and vice versa. The objects are typically schemes, sheaves, or morphisms parametrized by a scheme called the base. Putting an equivalence relation on the families gives a functor, called the moduli functor, which acts on the category of schemes to the category of sets. The functor is representable in the category of schemes if there is an isomorphism between the functor and the functor of points of a scheme. This particular scheme is called the fine moduli space for the functor, as distinguished from the coarse moduli space, where the functor is not representable, i.e. only a natural transformation, and not an isomorphism exists.<br /> The authors clarify the distinction between a moduli space and a parameter space, the former used for problems that involve intrinsic data, the latter for problems involving extrinsic data. An example of the latter, the Hilbert scheme, is discussed in detail in the first chapter, and an example due to Mumford of a component of a Hilbert scheme of space curves that is everywhere nonreduced is given to illustrate the pathologies that can arise in the extrinsic case, and to motivate the use of intrinsic moduli spaces to eliminate these difficulties. Severi varieties are discussed as objects that are more well-behaved than Hilbert schemes but still do not permit a scheme structure to be defined on them so that they represent the functor of families of plane curves with the correct geometric properties.<br /> The second chapter gives a general overview of the approaches taken in the construction of moduli spaces of curves. The authors first study the case of genus 1 (elliptic) curves to illustrate the difficulties involved in constructing fine moduli spaces. The role of automorphisms on the curves as an obstruction to the existence of fine moduli spaces is outlined, as well as approaches to deal with these automorphims, particularly the role of marked points. The authors briefly discuss the role of algebraic spaces and algebraic stacks in the moduli problem. They explain also the various approaches to the construction of the moduli space of smooth curves of genus g, namely the Teichmuller, Hodge-theoretic, and geometric invariant theoretic approaches. The local properties of the moduli space are outlined, along with a discussion of to what extent the moduli space deviates from being a projective or affine variety. The rational cohomology ring of the moduli space is also treated, in low dimensions via the Harer stability theorem, and for high dimensions via the Mumford conjecture. Most interestingly, Witten's conjectures and the Kontsevich formulas are introduced, as a theory of moduli spaces of stable maps. The famous Gromov-Witten invariants of a projective scheme and the quantum cohomology ring are briefly discussed. These have generated an enormous amount of research, the results of which show the power of viewing mathematical constructions from a &quot;quantum&quot; point of view.<br /> The next chapter gives a very specialized overview of the techniques used to study moduli spaces. The authors are very meticulous in their explanations of where the names of the concepts come from, and this is an enormous help to those seeking an in-depth understanding of the topics. One of the first is the dualizing sheaf of a nodal curve, which is the analogue of the canonical bundle of a smooth curve. The authors then describe, by taking a point as the base, the scheme-theoretic automorphism group of a stable curve, and show that it is finite and reduced. Deformation theory is introduced first as over smooth varieties. Readers will appreciate the discussion more if they have a background in the deformation theory of compact, complex manifolds. The authors then tackle the stable reduction problem, and give several beautiful examples, with lots of diagrams, to illustrate the concepts. This is one of the best discussions I have seen in print on these topics. After a brief interlude on the properties of the moduli stack, the authors treat the generalization of the Riemann-Roch formula due to Grothendieck. This section is very important to physicists working in superstring theory. The Porteous formula is also stated and applied to the determination of the class in the rational Picard group of hyperelliptic curves. The determination of the class of the locus of hyperelliptic stable curves of genus 3 is continued in two more sections using the method of test curves and admissible covers.<br /> The actual construction of the moduli space is the subject of chapter 4, from the viewpoint of geometric invariant theory. A nice example of this approach is given for the case of the set of smooth curves of genus 1. The numerical criterion for stability is discussed in detail, with Giesecker's criterion given the main focus. The case of the moduli space of curves with genus greater than two is tackled via the potential stability theorem.<br /> The authors show indeed in the next chapter that the moduli space can be used to prove results about a single curve. As one would expect intuitively, the taking of limits must be justified, and indeed this is the case here, where limits of line bundles and linear series are considered.<br />Then in the last chapter they show the reverse, that the properties of various moduli spaces can be proven using the techniques introduced in the book, such as the irreducibility of the moduli space, the Diaz result that complete subvarieties of the moduli space have dimension at most genus - 2, and moduli of hyperelliptic curves and Severi varieties.stable curve, and show that it is finite and reduced. Deformation theory is introduced first as over smooth varieties. Readers will appreciate the discussion more if they have a background in the deformation theory of compact, complex manifolds. The authors then tackle the stable reduction problem, and give several beautiful examples, with lots of diagrams, to illustrate the concepts. This is one of the best discussions I have seen in print on these topics. After a brief interlude on the properties of the moduli stack, the authors treat the generalization of the Riemann-Roch formula due to Grothendieck. This section is very important to physicists working in superstring theory. The Porteous formula is also stated and applied to the determination of the class in the rational Picard group of hyperelliptic curves. The determination of the class of the locus of hyperelliptic stable curves of genus 3 is continued in two more sections using the method of test curves and admissible covers. <br /> The actual construction of the moduli space is the subject of chapter 4, from the viewpoint of geometric invariant theory. A nice example of this approach is given for the case of the set of smooth curves of genus 1. The numerical criterion for stability is discussed in detail, with Giesecker's criterion given the main focus. The case of the moduli space of curves with genus greater than two is tackled via the potential stability theorem.<br /> The authors show indeed in the next chapter that the moduli space can be used to prove results about a single curve. As one would expect intuitively, the taking of limits must be justified, and indeed this is the case here, where limits of line bundles and linear series are considered. <BR>Then in the last chapter they show the reverse, that the properties of various moduli spaces can be proven using the techniques introduced in the book, such as the irreducibility of the moduli space, the Diaz result that complete subvarieties of the moduli space have dimension at most genus - 2, and moduli of hyperelliptic curves and Severi varieties.	2001-09-02
1854096:US	50702879	RP5TBDQRVRAU3	9810240252	213976646	The Nonlinear Workbook: Chaos, Fractals, Cellular Automata, Neural Networks, Genetic Algorithms, Fuzzy Logic with C++, Java, Symbolic C++, and Reduce Program	Books	3	35	36	N	N	Helpful in some sections	The topics covered in this book are all important from the standpoint of applications in physics, engineering, computer science, financial engineering, and computational biology. It is written for the person just getting started in these topics, and the author does a fairly good job of discussing them. Readers should not expect, and they will not get, in-depth discussions on these topics, as this would swell the book to 10 times the size. They will however get preparation for moving on to more advanced and complete treatments.<br /> Nonlinear and chaotic maps are considered in chapter 1, with elementary definitions given and six different examples of maps discussed. In discussing the calculation of numerical trajectories of maps, the author deals with the problem of large initial values for the maps and how to implement these in SymbolicC++ and Java. He also shows how to write/read data to a file using C, C++, and JAVA. The exception handling capability of JAVA comes out nicely, but no performance comparison between the three languages for simulating the maps is given by the author. The language REDUCE is used to discuss the stability of the fixed points of the logistic equation, but the code would be useless to the reader who did not have REDUCE since some of the function calls are hidden from the reader. Useful programs are given for calculating the Lyapunov and autocorrelation functions. In addition, C++ programs are given for evaluating the correlation integral for the Henon map. The programs he develops in this chapter can serve as a quick benchmark for one's own programs that calculate the same quantities.<br /> In chapter 2, the author discusses methods for studying time series, including the Lyapunov and Hurst exponents. These two quantities are of enormous importance in the study of dynamical systems, financial data, and network performance. The C++ program that the author gives for calculating the Hurst exponent will not work for arbitrary time intervals. This is followed in the next chapter by a consideration of autonomous systems of ordinary differential equations. The classification of fixed points is considered, and the important concept of a homoclinic orbit. The author gives a nice JAVA program that finds the homoclinic orbit of an anharmonic differential equation using the Lie series technique. The phase portrait of the Van der Pol oscillator is calculated using the Runge-Kutta technique in a C++ program, along with the Lotka-Volterra system from mathematical biology.<br /> Hamiltonian mechanics is discussed in chapter 4, with the important Henon-Heiles model from astrophysics is discussed and JAVA programs given for studying its behavior using the Poincare section technique. Newcomers to this technique will appreciate seeing it done here explicitly.  Integrability of Hamiltonian systems using the Lax representation and Floquet theory are also treated, but only at a very rudimentary level. Dissipation is included in the next chapter, and the author discusses the classification of fixed points according to their stability. Lyapunov exponents are again brought into the picture, and the phenomenon of hyperchaos is discussed. Some bifurcation theory is introduced with an example of the Hopf bifurcation. Chapter 6 studies nonlinear driven systems, with the Duffing oscillator treated, and the author gives a useful program for calculating the autocorrelation function of this system. The controlling of chaos with feedback and non-feedback controls is the subject of the next chapter, mostly in the context of difference maps. Fractals finally get introduced in chapter 8, with iterated function systems defined but proofs of their properties omitted. The author gives programs for calculating various popular fractals, such as the dragon, Sierpinski gasket, Koch curve, the Mandelbrot set, and the Julia set. The main disappointment in this chapter is that the author does not give programs for calculating the Hausdorff dimension or capacity, quantities that are notoriously difficult to get a meaningful computational handle on.<br /> The author switches gears in the next chapter and discusses cellular automata, which have recently made a comeback, especially in research on quantum computation. The discussion is too brief however, and does not allow the reader to gain an appreciation of the properties of these important objects. Chapter 10 gives a brief overview of some techniques for solving differential equations, such as the Euler method and the Lie series technique. The latter is not commonly treated in beginning books so its inclusion here is helpful. Symplectic integration is also discussed briefly, but the author does not discuss how to check the integrators using backward integration, which is commonly used in conservative systems modeled by symplectic maps.<br /> Chapter 11, covering neural networks, is the most well-written in the book, and the newcomer to the field will get a fairly decent introduction to the subject. The supplied programs serve to illustrate some of the important concepts in neural networks, such as the Hopfield model, the Kohonen network, the perceptron learning algorithm, and the back-propagation algorithm.<br /> Chapter 12 is an introduction to genetic algorithms, and I find this one particularly nice also, as it does give a rudimentary introduction to what evolutionary algorithms are all about, and gives some elementary genetic programs that find the maximum of one- and two-dimensional maps. He also discusses simulated annealing, and gives a useful program that allows the reader to see clearly how this technique works.<br /> The last chapter covers fuzzy sets and fuzzy logic, which has also taken on importance in recent years, especially in data mining and financial engineering. The programs given to illustrate the concepts are particularly interesting from the standpoint of coding in C++, as the author uses friend functions and operating overloading in some of them. The reader gets a good overview of fuzzy reasoning and fuzzy rule-based systems.mension or capacity, quantities that are notoriously difficult to get a meaningful computational handle on. <br /> The author switches gears in the next chapter and discusses cellular automata, which have recently made a comeback, especially in research on quantum computation. The discussion is too brief however, and does not allow the reader to gain an appreciation of the properties of these important objects. Chapter 10 gives a brief overview of some techniques for solving differential equations, such as the Euler method and the Lie series technique. The latter is not commonly treated in beginning books so its inclusion here is helpful. Symplectic integration is also discussed briefly, but the author does not discuss how to check the integrators using backward integration, which is commonly used in conservative systems modeled by symplectic maps. <br /> Chapter 11, covering neural networks, is the most well-written in the book, and the newcomer to the field will get a fairly decent introduction to the subject. The supplied programs serve to illustrate some of the important concepts in neural networks, such as the Hopfield model, the Kohonen network, the perceptron learning algorithm, and the back-propagation algorithm. <br /> Chapter 12 is an introduction to genetic algorithms, and I find this one particularly nice also, as it does give a rudimentary introduction to what evolutionary algorithms are all about, and gives some elementary genetic programs that find the maximum of one- and two-dimensional maps. He also discusses simulated annealing, and gives a useful program that allows the reader to see clearly how this technique works. <br /> The last chapter covers fuzzy sets and fuzzy logic, which has also taken on importance in recent years, especially in data mining and financial engineering. The programs given to illustrate the concepts are particularly interesting from the standpoint of coding in C++, as the author uses friend functions and operating overloading in some of them. The reader gets a good overview of fuzzy reasoning and fuzzy rule-based systems.	2001-09-01
1859769:US	50702879	R1SQK26Y5P9XC	0387943285	243370993	Advanced Topics in the Arithmetic of Elliptic Curves (Graduate Texts in Mathematics)	Books	5	15	20	N	N	The most fascinating objects in all of mathematics	This book is a continuation of the authors earlier book on elliptic curves, which was also an excellent book, and treats the more specialized topics in elliptic curves. I cannot think of a branch of physics or engineering that has not made use of some facet of the theory of elliptic curves, and they have myriads of applications in other fields also, such as cryptography and financial engineering. The book is very organized, straightforward to read, the author summarizes well his intentions at the beginning of each chapter, and recommends several references for topics left out of the main discussion. Space does not allow a detailed chapter by chapter review, so I will confine my review to the first two chapters, which were of main interest to me. In summary, Chapter 1 discusses how to study elliptic curves by taking a collection of them, each member being isomorphic, and studying the properties of modular functions and differential forms on this collection, now thought of as an algebraic curve, called the moduli space. The famous linear operators, called the Hecke operators, act on the the space of modular forms, and they and their eigenfunctions satisfy the same set of relations. One then attaches the well-known L-series to the modular forms that has very interesting algebraic and analytic properties. In more detail, the author does the following in the chapter. The set of lattices in the complex plane modulo non-zero multiplication L/C* is considered, along with the set of elliptic curves over the complex plane modulo complex isomorphism. These collections are proven to be bijective by showing that L/C* is isomorphic to C by first putting a complex structure on it. This leads to a surjective map from the upper-half plane H to L/C*. Proving this to be injective leads to a bijection from SL2(Z)\H to L/C*. Since the matrix -1 acts trivially on H, one can quotient out +1 and -1 and obtain the modular group. The quotient space modular group\H is a 2-sphere minus a point, but can be made into a Riemann surface by extending the upper half-plane (called H*). The modular curve X(1) = modular group\H* results and is compact and Hausdorff. A complex structure is put on it, making it into a a Riemann surface of genus 0. Meromorphic functions on X(1) are rational functions of the j function, but more interesting functions are defined on X(1), namely the modular functions, such as the Eisenstein series. These considerations lead to a proof of the uniformization theorem for elliptic curves over C. For a given elliptic curve E, a study of the set of all isogenies to E of degree n is the same as that of studying degree n maps from E to other elliptic curves, which is called the dual isogeny, and leads to the Hecke operator. The Hecke operator and the homothety operator both map the divisor group of the lattice to itself, and generate a commutative algebra, called the Hecke algebra. Hecke operators can act on modular forms of weight 2k, and modular forms exist which are simultaneous eigenfunctions for the Hecke operator of weight 2k. It can be proven, but the author does not do so, that the normalized eigenfunctions form a basis for the space of cusp forms of weight 2k. The Fourier coefficients of the eigenfunction have an Euler product decomposition of a Dirichlet series attached to f, called the L-series. In the next chapter, the author considers elliptic curves that have extra endomorphisms, called complex multiplication. The collection of endomorphisms is usually taken to be the real numbers R, or R(K), which is the ring of integers of R tensored with the rational numbers. And, just as in chapter 1, he studies collections of elliptic curves, but here ones with the same endomorphism ring., called ELL(R) in the book. Asking the question of how to construct an elliptic curve with complex multiplication by a particular R(K) leads him to studying the ideal class group of R(K), and this group is shown to act transitively on ELL(R(K)). The authoralso shows that every elliptic curve with complex multiplication is defined over an algebraic extension of Q. Several interesting examples of ellipti curves with complex multiplication are given. After a brief review of class field theory, the author proves that K(j(E)) is the Hilbert class field H and shows how the Galois group of H/K acts on j(E). The torsion points of E are then used to generate abelian extensions of K, using the Weber function for E/H, thus generalizing the usual cyclotomic extensions of number theory. Very interesting examples are given of these constructions and it is also shown that j(E) is an algebraic integer. Then after a brief review of cyclotomic class field theory, the author proves what he calls the main theorem of complex multiplication, which says that an automorphism of the torsion subgroup is essentially analytic multiplication by an idele of K. This theorem allows one to define a Grossencharacter associated to an elliptic curve with complex multiplication. For such a curve one can then define an L-series and show that it can be expressed as a Hecke L-series with Grossencharacter.also shows that every elliptic curve with complex multiplication is defined over an algebraic extension of Q. Several interesting examples of ellipti curves with complex multiplication are given. After a brief review of class field theory, the author proves that K(j(E)) is the Hilbert class field H and shows how the Galois group of H/K acts on j(E). The torsion points of E are then used to generate abelian extensions of K, using the Weber function for E/H, thus generalizing the usual cyclotomic extensions of number theory. Very interesting examples are given of these constructions and it is also shown that j(E) is an algebraic integer. Then after a brief review of cyclotomic class field theory, the author proves what he calls the main theorem of complex multiplication, which says that an automorphism of the torsion subgroup is essentially analytic multiplication by an idele of K. This theorem allows one to define a Grossencharacter associated to an elliptic curve with complex multiplication. For such a curve one can then define an L-series and show that it can be expressed as a Hecke L-series with Grossencharacter.	2001-08-28
1862715:US	50702879	R2PJ1VTEZXN6CA	038794348X	951429445	Foundations of Hyperbolic Manifolds (Graduate Texts in Mathematics)	Books	5	17	18	N	N	An excellent overview for mathematicians and physicists	The advent of non-Euclidean geometry resulted in many different areas of mathematics, some being specifically related to geometry, others being more general, such as proof theory and model theory. This book is an excellent overview of a particular branch of non-Euclidean geometry called hyperbolic geometry. There are good exercises in the book, and the author gives a detailed history of the subjects after the end of each chapter. After a brief review of Euclidean geometry in chapter 1, emphasizing the metric properties of Euclidean space, orthogonal transformations, and isometries, the author discusses spherical geometry in chapter 2. Spherical and hyperbolic geometries are dual to each other, in the sense that in spherical geometry, a line through a point outside a given line is never parallel to the given line; but in hyperbolic geometry there are infinitely many such lines. Also, the sum of the angles of a spherical triangle is always greater than 180 degrees ; but in hyperbolic geometry less than 180 degrees. Hyperbolic geometry is of crucial importance in physics, particularly in the theory of relativity, and the author begins a discussion of this kind of geometry in chapter 3. Hyperbolic n-space is viewed more as dual to elliptic geometry in the sense that it is modeled as a unit sphere of imaginary radius with only the positive sheet of this (disconnected) set retained. The author outlines in detail the important properties of hyperbolic geometry along with its trigonometry. This is followed in the next chapters by a model of hyperbolic n-space as a conformal ball and an upper half-space, and a consideration of the isometries of hyperbolic space. The Mobius transformations are given detailed treatment. The famous classical discrete groups are introduced, along with the crystallographic groups. The discussion gets more abstract in some parts here, for the author introduces some algebraic notions such as valuation rings, in order to prove Selberg's lemma. The author finally lays the groundwork for a theory of hyperbolic manifolds in chapter 8, by first introducing geometric spaces. These are defined by four axioms, which are generalizations of Euclid's first four axioms, and two of these axioms imply that any geometric manifold is an n-manifold. The discussion is specialized in the next chapter to geometric surfaces, where the famous Gauss-Bonnet theorem, relating the area of a surface to its Euler characteristic, is proved for spherical, Euclidean, or hyperbolic surfaces. The author studies the collection of similarity equivalence classes of complete structures for a geometric surface, namely the moduli space of such structures. Physicists, particularly string theorists, will appreciate the resulting discussion on Teichmuller space and the Dehn-Nielsen theorem. Considerations of a nature more familiar to geometric topologists follows in the next chapter, where it is shown how to explicitly construct hyperbolic 3-manifolds. Dehn surgery is employed to study the complement of the figure 8 knot. The discussion is very interesting, for it employs explicit detailed constructions that would take many hours to dig out of the literature. The general case of n-dimensional hyperbolic manifolds is the subject of chapter 11, with the constructions in chapter 10 generalized to deal with high dimensions. The author considers also the two closed, orientable, hyperbolic manifolds of the same homotopy type have the same volume by using the Gromov invariant, a quantity defined in terms of the singular homology on the manifold. The reader will get a taste of the Haar measure in the proof of the result, and later an overview of measure homology. The later is very interesting, as it brings in techniques from differential topology and the de Rham complex, and it also defines a notion of a &quot;straightening&quot; and smearing of a singular complex. Mostow rigidity, which says that for any two closed, connected, orientable, hyperbolic n-manifolds, with n greater than 2, a homotopy between these will also be an isometry, is also proven here. The next chapter is more involved than the rest, and deals with the case of geometrically finite n-manifolds. Dealing with cusps and &quot;sharp corners&quot; from the actions of discrete groups is given detailed and rigorous discussion here. The discussion leads naturally to a treatment of orbifolds in the next chapter. These objects have been extremely important in string theories in high energy physics, and the author does an excellent job of detailing their properties.olds, with n greater than 2, a homotopy between these will also be an isometry, is also proven here. The next chapter is more involved than the rest, and deals with the case of geometrically finite n-manifolds. Dealing with cusps and &quot;sharp corners&quot; from the actions of discrete groups is given detailed and rigorous discussion here. The discussion leads naturally to a treatment of orbifolds in the next chapter. These objects have been extremely important in string theories in high energy physics, and the author does an excellent job of detailing their properties.	2001-08-26
1862890:US	50702879	R2OARBAQXO2Q6N	0387987274	329255936	Advanced Topics in Computational Number Theory (Graduate Texts in Mathematics)	Books	5	3	4	N	N	A first class job, just as in the first volume	The author continues his excellent overview of computational number theory in this book. And, as in the first volume, the writing is first-rate and gives the reader a comprehensive overview of the more advanced algorithms in the subject. Contrary to the first volume, I have not used many of the algorithms in this book and cannot attest to their quality, but the author gives the detailed background on each of them, enhancing their credibility. I read this book mostly to gain more insight into algebraic geometry and its connection with coding theory and cryptography. The following algorithms were ones that I found helpful and interesting but only a few of which I coded myself: (1) The algorithm for generating a random element from an ideal. (2) The compositum of two number fields (3) Valuation of a prime ideal. (4)Ideal factorization. (5)Smith normal form for finite groups. (6) Quotient of groups. (7) Group extensions. (8) Right four-term exact sequences. (9) Image and inverse image of a subgroup. (10)Subgroups with prime index. (11) Solving linear systems in integers. (12) Algorithms involving p-adic logarithms. (13) Computation of the Dedekind eta-function. (14) Unramified Abelian extensions using complex multiplication. (15) Computation of quasi-periods for elliptic functions. (16) Computation of the sigma-function for an elliptic curve.	2001-08-25
1863411:US	50702879	R2SDEI1JS321LQ	0684870045	872816049	Quest for the Quantum Computer	Books	4	24	35	N	N	Nice job	One of the hottest topics in foundational research in quantum physics at the present time, and of overriding importance technologically, quantum computation will no doubt remain as a tour de force in years to come. The author does a fairly good job of summarizing the history and background of the theory and experimental situation in quantum computation. It is written for the layman but the author does not hestitate to interject some elementary mathematics. The author does a good job of overviewing the relevant physics, but exaggerates sometimes certain experimental results, in particular, the experimental verification of entanglement. David Deutsch, well-known in the theory of quantum computation and foundations of physics, gives a superb forward to the book. He deplores the situation of not encouraging criticism of accepted truths that he sees occuring in most universities. I think he is correct in most respcts, as such an attitude is very manifested in the current attitude on quantum entanglement: it is taken to be axiomatic that such a concept has been experimentally verified by most in the field. The first chapter gives a brief overview of what is ahead in the book, and what a quantum computer could do if constructed, and a little history behind the research on quantum computing. A discussion of Shannon information theory and Landauer's principle is given in the next chapter. The later is supposed to allow one to get away from the kT minimum energy requirement for each unit of computation, using a concept of logical irreversibility. The double-well scenario he describes though is a little suspect, since if viewed from the standpoint of quantum field theory the barrier will effectively disappear because of quantum interference. DNA computers, the Fredkin gate and the the billiard computer follow as examples of reversible computers. The billiard computer should be definitely classified as a thought experiment, for one can show that such a system is chaotic, nullifying its utility for computation (at least in the ordinary sense of computation). A more promising approach, via cellular automata, is discussed. It was refreshing to see that Paul Benioff's theories were discussed in this book, as his results were the first meaningful attempt to model classical computation by using quantum physics. I read Benioff's papers in 1990, eleven years after they were first published, my interest being somewhat different, namely that of studying the suppression of classical chaos by quantum fluctuations. Benioff was concerned with the effect of quantum fluctuations on classical computation, i.e. would the efficacy of a classical computer be reduced at the quantum level? In attempting to explain the construction of a quantum computer, the author does a good job of describing some of the important operations that act on quantum states, such as quantum rotations and Hadamard transformations. The work of Peter Shor, who received a Fields Medal for his &quot;quantum&quot; algorithm that factors numbers efficiently, is described in the book, and the author in this discussion introduces the reader to some elementary ideas in cryptography. This is followed by an excellent overview of the field quantum cryptography. Unfortunately, the discussion is limited to quantum encryption schemes that are based on quantum entanglement, the latter of which has no sound experimental foundation. The author also does a fine job of discussing the role of decoherence in &quot;messing-up&quot; the operation of a quantum computer. The time scales involved in decoherence are something that has been the subject of much interest, and will no doubt be of the deciding factor in making quantum computation a workable idea. Ion trap, cavity quantum electrodynamics, and nuclear magnetic resonance have been studied intensively as candidates for quantum computers, and the author details nicely the current experimental situation in these approaches. The role of quantum error correction is also detailed in the book, and the author introduces the reader to what can be done with to do fault-tolerant computation. The Greenberger-Horne-Zeilinger experiment is presented in the context of NMR, but the author remarks that the nonlocal features of the GHZ experiment cannot be tested using NMR techniques, and so other approaches must be used. The Grover algorithm, and its power in database searching, is discussed also. The author ends the book appropriately with speculations and best-guess predictions on the future of quantum computing. One can only hope that quantum computers will be normal parts of the computing scenery in this century, and this book does show effectively the intensity in the research efforts to bring it about. With some justification though one could wonder why the adjective &quot;quantum&quot; is used to describe this form of computing at all. It is one thing to describe a concept using the formalism of Hilbert spaces, it is quite another thing to justify that this concept is actually physical. The geometry of Hilbert space does result in peculiar predictions for physical phenomena, but there are many other constructions, in mathematics for example, that are based on Hilbert spaces but have no physical analog. Perhaps, we should all refer to the theory of computation expounded in this book as &quot;Hilbert space computation&quot;, rather than quantum computation. Such a description would free those interested to not think of physics as computation, but instead to construct a computer that is far better in performance than the ordinary &quot;classical&quot; one, but whose theory of computation and logic is based on Hilbert spaces, and not ordinary logic. The goal then would be to construct a real working example of such a computer....it might not be one that has anything to do with (traditional) quantum physics.ection is also detailed in the book, and the author introduces the reader to what can be done with to do fault-tolerant computation. The Greenberger-Horne-Zeilinger experiment is presented in the context of NMR, but the author remarks that the nonlocal features of the GHZ experiment cannot be tested using NMR techniques, and so other approaches must be used. The Grover algorithm, and its power in database searching, is discussed also. The author ends the book appropriately with speculations and best-guess predictions on the future of quantum computing. One can only hope that quantum computers will be normal parts of the computing scenery in this century, and this book does show effectively the intensity in the research efforts to bring it about. With some justification though one could wonder why the adjective &quot;quantum&quot; is used to describe this form of computing at all. It is one thing to describe a concept using the formalism of Hilbert spaces, it is quite another thing to justify that this concept is actually physical. The geometry of Hilbert space does result in peculiar predictions for physical phenomena, but there are many other constructions, in mathematics for example, that are based on Hilbert spaces but have no physical analog. Perhaps, we should all refer to the theory of computation expounded in this book as &quot;Hilbert space computation&quot;, rather than quantum computation. Such a description would free those interested to not think of physics as computation, but instead to construct a computer that is far better in performance than the ordinary &quot;classical&quot; one, but whose theory of computation and logic is based on Hilbert spaces, and not ordinary logic. The goal then would be to construct a real working example of such a computer....it might not be one that has anything to do with (traditional) quantum physics.	2001-08-25
1866491:US	50702879	R2RC0LIGRFQ3AR	0387556400	67610350	A Course in Computational Algebraic Number Theory (Graduate Texts in Mathematics)	Books	5	5	5	N	N	Definitely belongs on the shelf of all number theory lovers	This book is an excellent compilation of both the theory and pseudo-code for number theoretic algorithms. The author also takes the time to prove some of the major results as background to the algorithms, in addition to sets of exercises at the end of the book. The book is too large to do a chapter by chapter review, so instead I will list the algorithms in the book that I thought were particularly useful:<br /> 1. Most of the algorithms on elliptic curves. The author reminds the reader that number-theoretical experiments resulted in the famous Swinnerton-Dyer Conjecture and the Birch Conjecture. (a) the reduction algorithm, which for a given point in the upper half plane, gives the unique point in the half plane equivalent to this point under the action of the special linear group along with the matrix that maps these two points to each other. (b) The computation of the coefficient g2 and g3 of the Weierstrass equation of an elliptic curve. (c) The computation of the Weierstrass function and its derivative. (d) Determination of the periods of an elliptic curve over the real numbers. (e) The determination of the elliptic logarithm. (f) The reduction of a general cubic (f) The Shanks-Mestre algorithm for computing the order of an elliptic curve over a finite field F(p), where p is prime and greater than 457. (g) The reduction of an elliptic curve modulo p for p &gt; 3. (h) The reduction of an elliptic curve modulo 2 or 3. (i) Reduction of an elliptic curve over the rational numbers. (j) Determination of the rational torsion points of an elliptic curve. (k) Computation of the Hilbert class polynomials and thus a determination of the j-function of an elliptic curve.<br /> 2. A few of the algorithms on factoring. (a) The Pollard algorithm for finding non-trivial factors of composites. (The author does not give the improved algorithm due to P. Montgomery, but does give references) (b) Shanks Square Form Factorization algorithm for finding a non-trivial factor of an odd integer. (c) Lenstra's Elliptic Curve test for compositeness.<br /> 3. Primality tests (a) The Jacobi Sum Primality Test for a positive integer. (b) Goldwasser-Killian elliptic curve test for a positive integer not equal to 1 and coprime to 6.<br /> The author gives an overview of the computer packages used for number theory, including Pari, which was written by him and his collaborators. I have not used this package, but instead use Lydia and Mathematica for most of the number theoretic computations I need to do.integer. (c) Lenstra's Elliptic Curve test for compositeness. <br /> 3. Primality tests (a) The Jacobi Sum Primality Test for a positive integer. (b) Goldwasser-Killian elliptic curve test for a positive integer not equal to 1 and coprime to 6. <br /> The author gives an overview of the computer packages used for number theory, including Pari, which was written by him and his collaborators. I have not used this package, but instead use Lydia and Mathematica for most of the number theoretic computations I need to do.	2001-08-23
1871048:US	50702879	R1D0LTZU0YVK8F	0387977163	281554603	Algebraic Geometry: A First Course (Graduate Texts in Mathematics) (v. 133)	Books	5	38	42	N	N	Definitely a good start in algebraic geometry	If one is planning to do work in coding theory, cryptography, computer graphics, digitial watermarking, or are hoping to become a mathematician specializing in algebraic geometry, this book will be of an enormous help. The author does a first class job in introducing the reader to the field of algebraic geometry, using a wealth of examples and with the goal of building intuition and understanding. It is great that a mathematician of the author's caliber would take the time to write these lectures here put into book form. It is rare to find a book on algebraic geometry that attempts to make the subject concrete and understandable, and yet points the way to more modern &quot;scheme-theoretic&quot; formulations.<br /> In lecture 1, the author introduces affine and projective varieties over algebraically closed fields. Linear subspaces of n-dimensional projective space P(n) are shown to be varieties, along with any finite subset of P(n). He delays giving rigorous definitions of degree and dimension, emphasizing instead concrete examples of varieties. The twisted cubic is given as the first example of a concrete variety that is not a hypersurface, along with their generalizations, the rational normal curves.<br /> The Zariski topology, considered by the newcomer to the subject as being a rather &quot;strange&quot; topology, is introduced in lecture 2. The author does a great job though explaining its properties, and introduces the regular functions on affine and projective varieties. The Nullstellensatz theorem, needed to prove that the ring of regular functions is the coordinate ring, is deferred to a later lecture. Rational normal curves are further generalized to Veronese maps in this lecture, and the properties of the corresponding Veronese varieties discussed in some detail. Also, the very interesting Segre varieties are discussed here. With these two examples of varieties, the reader already can develop a good geometric intution of the behavior of typical varieties. The Veronese and Segre maps are then combined to give another example of a variety: the rational normal scroll. More concrete examples of varieties are given in the next two lectures, including cones, quadrics, and projections. A &quot;fiber bundle&quot; approach to forming families of varieties parametrized by a given variety is outlined here also.<br /> The author finally gets down to more algebraic matters in lecture 5, with the Nullstellensatz proven in great detail. He also discusses the origins of schemes in algebraic geometry, giving the reader a better appreciation of just where these objects arise, namely the association to an arbitrary ideal, instead of merely a radical ideal.<br /> Grassmannian varieties are then introduced in lecture 6, along with some of its subvarieties, such as the Fano varieties. The join operation, widely used in geometric topology, is here defined for two varieties.<br /> More connections with the modern viewpoint are made in lecture 7, where rational functions and rational maps are discussed. The author takes great care in explaining in what sense rational maps can be thought of as maps in the &quot;ordinary&quot; sense, namely they must be thought of as equivalence classes of pairs, instead of acting on points. The very important concept of a birational isomorphism is discussed also, along with blow-ups and blow-downs of varieties.<br /> Many more concrete examples of varieties are given in lectures 8 and 9, such as secant varieties, flag manifolds, and determinantal varieties. In addition, algebraic groups on varieties are discussed in lecture 10, allowing one to discuss a kind of glueing operation on varieties, just as in geometric topology, namely by taking the quotient of varieties via finite groups.<br /> The author then moves on to giving a more rigorous formulation of dimension, giving several different definitions, all of these conforming to intuitive ideas on what the dimension of an algebraic variety should be, and also one compatible with a purely algebraic context. Again, several concrete examples are given to illustrate the actual calculation of the dimension of a variety, both in this lecture and the next one.<br /> The next lecture is very interesting and discusses an important problem in algebraic geometry, namely the determination of how many hypersurfaces of each degree contain a projective variety in P(n). The solution is given in terms of the famous Hilbert polynomial, which is determined for rational normal curves, Veronese varieties, and plane curves in this lecture. The author also explains the utility of using graded modules in the determination of the Hilbert polynomial, something that is usually glossed over in most books on this topic. This discussion leads to the Hilbert syzygy theorem.<br /> Some analogs of basic contructions in differential geometry are defined for varieties in the next four lectures, based on an appropriate notion of smoothness. The tangent spaces, the Gauss map, and duals discussed here.<br /> Then in lecture 18 the author makes good on his promise in earlier lectures of making the notion of the degree of a projective variety more rigorous. The well-known Bezout's theorem is proven, after introducting a notion of transversal intersection for varieties. As usual in the book, several examples are given for the calculation of the degree, including Veronese and Segre varieties, in this lecture and the next.<br /> The behavior of a variety at a singular point is studied in lecture 20 using tangent cones. The author proves the resolution of singularities for curves here also.<br /> Lecture 21 is very important, especially for the physicist reader working in string and M-theories, as the author introduces the concept of a moduli space. Most results are left unproven, but the intuition gained from reading this lecture is invaluable. The all-important Chow and Hilbert varieties are discussed here. The book the ends with a fairly lengthy overview of quadric hypersurfaces.and also one compatible with a purely algebraic context. Again, several concrete examples are given to illustrate the actual calculation of the dimension of a variety, both in this lecture and the next one. <br /> The next lecture is very interesting and discusses an important problem in algebraic geometry, namely the determination of how many hypersurfaces of each degree contain a projective variety in P(n). The solution is given in terms of the famous Hilbert polynomial, which is determined for rational normal curves, Veronese varieties, and plane curves in this lecture. The author also explains the utility of using graded modules in the determination of the Hilbert polynomial, something that is usually glossed over in most books on this topic. This discussion leads to the Hilbert syzygy theorem. <br /> Some analogs of basic contructions in differential geometry are defined for varieties in the next four lectures, based on an appropriate notion of smoothness. The tangent spaces, the Gauss map, and duals discussed here. <br /> Then in lecture 18 the author makes good on his promise in earlier lectures of making the notion of the degree of a projective variety more rigorous. The well-known Bezout's theorem is proven, after introducting a notion of transversal intersection for varieties. As usual in the book, several examples are given for the calculation of the degree, including Veronese and Segre varieties, in this lecture and the next. <br /> The behavior of a variety at a singular point is studied in lecture 20 using tangent cones. The author proves the resolution of singularities for curves here also. <br /> Lecture 21 is very important, especially for the physicist reader working in string and M-theories, as the author introduces the concept of a moduli space. Most results are left unproven, but the intuition gained from reading this lecture is invaluable. The all-important Chow and Hilbert varieties are discussed here. The book the ends with a fairly lengthyoverview of quadric hypersurfaces.	2001-08-19
1872483:US	50702879	R20QZ1LDP7KN1O	0387906134	927015935	Differential Forms in Algebraic Topology (Graduate Texts in Mathematics)	Books	5	25	25	N	N	A first class job	The authors of this book, through clever examples and in-depth discussion, give the reader a rare accounting of some of the important concepts of algebraic topology. The introduction motivates the subject nicely, and the authors succeed in giving the reader an appreciation of where the concepts of algebraic topology come from, how they do their jobs, and their limitations. The de Rham cohomology, which is the main subject of the book, is explained in here in a way that gives the reader an intuitive and geometric understanding, which is sorely needed, especially for physicists who are interested in applications. As an example, they give a neat argument as to why de Rham cohomology cannot detect torsion.<br /> In chapter 1, the authors get down to the task of constructing de Rham cohomology, starting with the de Rham complex on R(n). The de Rham complex is then specialized to the case where only C-infinity functions with compact support are used, giving the de Rham complex with compact supports on R(n). The de Rham complex is then generalized to any differentiable manifold and the de Rham cohomology computed using the Mayer-Vietoris sequence.<br /> The discussion gets a little more involved when the authors characterize the cohomology of a fiber bundle. The all-important Thom isomorphism for vector bundles, is treated in detail. The authors give several good examples of the Poincare duals of submanifolds. The connection to ideas in differential topology is readily apparent in this chapter, namely transversality and the degree of a map. In addition, the first construction of a characteristic class, the Euler class, is done in this chapter.<br /> The Mayer-Vietoris sequence is generalized to the case of countably many open sets in chapter 2, and shown to be isomorphic to the Cech cohomology for a &quot;good&quot; cover of a manifold. Good examples are given for computing the de Rham cohomology from the combinatorics of a good cover. The authors then characterize Cech cohomology groups in more detail, introducing the important concept of a presheaf. Presheaves are usually introduced abstractly in most books, so it is a real treat to see them described here in such an understandable way. Computations of the case of a sphere bundle are given, and the role of orientability and the Euler class in giving the existence of a global form on the total space is detailed. The Thom isomorphism theorem and Poincare duality are generalized to the cases where the manifold does not have a finite good cover and the vector bundle is not orientable. A very concrete introduction to monodromy is given and nice examples of presheaves that are not constant are given.<br /> The authors treat spectral sequences in chapter 4, and as usual with this topic, the level of abstraction can be a stumbling block for the newcomer. The authors though explain that the spectral sequence is nothing other than a generalization of the double complex of differential forms that was considered in chapter 2. The crucial step in the chapter is the transition to cohomology with integer coefficients, which is necessary if one is to study torsion phenomena. The De Rham theory is then extended to singular cohomology and the Mayer-Vietoris sequence studied for singular cochains. The authors show that the singular cohomology of a triangularizable space is isomorphic to its Cech cohomology with the constant presheaf the integers. After a fairly detailed review of homotopy theory (including a discussion of Morse theory) the authors compute the fourth and fifth homotopy groups of S(3). The last section of the chapter discusses the rational homotopy theory of Sullivan as applied to differentiable manifolds. The authors discussion is illuminating, and shows how eliminating any torsion information allows one to prove some interesting results on the homotopy groups of spheres. One such result is Serre's theorem, the other being the computation of some low-dimensional homotopy groups of thewedge product of S(2) with itself.<br /> The last chapter of the book considers the theory of characteristic classes, with Chern classes of complex vector bundles being treated first. The theory of characteristic classes is usually treated formally, and this book is no exception, wherein the authors formulate it using ideas of Grothendieck. They do however give one nice example of the computation of the first Chern class of a tautological bundle over a projective space. The Pontryagin class is defined in terms of a complexification of a real vector bundle and computed for spheres and complex manifolds. A superb discussion is given of the construction of the universal bundle and the representation of any bundle as the pullback map over this bundle.the wedge product of S(2) with itself. <br /> The last chapter of the book considers the theory of characteristic classes, with Chern classes of complex vector bundles being treated first. The theory of characteristic classes is usually treated formally, and this book is no exception, wherein the authors formulate it using ideas of Grothendieck. They do however give one nice example of the computation of the first Chern class of a tautological bundle over a projective space. The Pontryagin class is defined in terms of a complexification of a real vector bundle and computed for spheres and complex manifolds. A superb discussion is given of the construction of the universal bundle and the representation of any bundle as the pullback map over this bundle.	2001-08-18
1872932:US	50702879	RAGK0XNDZSCJO	0387961623	409438191	Modern Geometry Methods and Applications: Part II: The Geometry and Topology of Manifolds (Graduate Texts in Mathematics) (Part 2)	Books	4	14	14	N	N	Written for the physicist in mind	This book, written by some of the master expositors of modern mathematics, is an introduction to modern differential geometry with emphasis on concrete examples and concepts, and it is also targeted to a physics audience. Each topic is motivated with examples that help the reader appreciate the essentials of the subject, but rigor is not sacrificed in the book.<br /> In the first chapter the reader gets a taste of differentiable manifolds and Lie groups, the later gving rise to a discussion of Lie algebras by considering, as usual, the tangent space at the identity of the Lie group. Projective space is shown to be a manifold and the transition functions explicitly written down. The authors give a neat example of a Lie group that is not a matrix group. A rather quick introduction to complex manifolds and Riemann surfaces is given, perhaps too quick for the reader requiring more details. Homogeneous and symmetric spaces are also discussed, and the authors plunge right into the theory of vector bundles on manifolds. Thus there is a lot packed into this chapter, and the authors should have considered spreading out the discussion more, as it leaves the reader wanting for more detail.<br /> The authors consider more fundamental questions in smooth manifolds in chapter 3, with partitions of unity used to prove the existence of Riemannian metrics and connections on manifolds. They also prove Stokes formula, and prove the existence of a smooth embedding of any compact manifold into Euclidean space of dimension 2n + 1. Properties of smooth maps, such as the ability to approximate a continuous mapping by a smooth mapping, are also discussed. A proof of Sard's theorem is given, thus enabling the study of singularities of a mapping. The reader does get a taste of Morse theory here also, along with transversality, and thus a look at some elementary notions of differential topology. An interesting discussion is given on how to obtain Morse functions on smooth manifolds by using focal points.<br /> Notions of homotopy are introduced in chapter 3, along with more concepts from differential topology, such as the degree of a map. A very interesting discussion is given on the relation between the Whitney number of a plane closed curve and the degree of the Gauss map. This leads to a proof of the important Gauss-Bonnet theorem. Degree theory is also applied to vector fields and then to an application for differential equations, namely the Poincare-Bendixson theorem. The index theory of vector fields is also shown to lead to the Hopf result on the Euler characteristic of a closed orientable surface and to the Brouwer fixed-point theorem.<br /> Chapter 4 considers the orientability of manifolds, with the authors showing how orientation can be transported along a path, thus giving a non-traditional characterization as to when a connected manifold is orientable, namely if this transport around any closed path preserves the orientation class. More homotopy theory, via the fundamental group, is also discussed, with a few examples being computed and the connection of the fundamental group with orientability. It is shown that the fundamental group of a non-orientable manifold is homomorphic onto the cyclic group of order 2. Fiber bundles with discrete fiber, also known as covering spaces, are also discussed, along with their connections to the theory of Riemann surfaces via branched coverings. The authors show the utility of covering maps in the calculation of the fundamental group, and use this connection to introduce homology groups. A very detailed discussion of the action of the discrete group on the Lobachevskian plane is given.<br />  Absolute and relative homotopy groups are introduced in chapter 5,  and many examples are given of their calculation. The idea of a covering homotopy leads to a discussion of fiber spaces. The most interesting discussion in this chapter is the one on Whitehead multiplication, as this is usually not covered in introductory books such as this one, and since it has become important in physics applications. The authors do take a stab at the problem of computing homotopy groups of spheres, and the discussion is a bit unorthodox since it depends on using framed normal bundles.<br /> The theory of smooth fiber bundles is considered in the next chapter. The physicist reader should pay close attention to this chapter is it gives many insights into the homotopy theory of fiber bundles that cannot be found in the usual books on the subject. The discussion of the classification theory of fiber bundles is very dense but worth the time reading. Interestingly, the authors include a discussion of the Picard-Lefschetz formula, as an example of a class of &quot;fiber bundles with singularities&quot;. Those interested in the geometry of gauge field theories will appreciate the discussion on the differential geometry of fiber bundles.<br /> Dynamical systems are introduced in chapter 7, first as defined over manifolds, and then in the context of symplectic manifolds via Hamaltonian mechanics. Liouville's theorem is proven, and a few examples are given from relativistic point mechanics. The theory of foliations is also discussed, although the discussion is too brief to be of much use. The authors also consider variational problems, and given its importance in physics, they continue the treatment in the last chapter of the book, giving several examples in general relativity, and in gauge theory via a consideration of the vacuum solutions of the Yang-Mills equation. The physicist reader will appreciate this discussion of the classical theory of gauge fields, as it is good preparation for further reading on instantons and the eventual quantization of gauge fields.oductory books such as this one, and since it has become important in physics applications. The authors do take a stab at the problem of computing homotopy groups of spheres, and the discussion is a bit unorthodox since it depends on using framed normal bundles. <br /> The theory of smooth fiber bundles is considered in the next chapter. The physicist reader should pay close attention to this chapter is it gives many insights into the homotopy theory of fiber bundles that cannot be found in the usual books on the subject. The discussion of the classification theory of fiber bundles is very dense but worth the time reading. Interestingly, the authors include a discussion of the Picard-Lefschetz formula, as an example of a class of &quot;fiber bundles with singularities&quot;. Those interested in the geometry of gauge field theories will appreciate the discussion on the differential geometry of fiber bundles. <br /> Dynamical systems are introduced in chapter 7, first as defined over manifolds, and then in the context of symplectic manifolds via Hamaltonian mechanics. Liouville's theorem is proven, and a few examples are given from relativistic point mechanics. The theory of foliations is also discussed, although the discussion is too brief to be of much use. The authors also consider variational problems, and given its importance in physics, they continue the treatment in the last chapter of the book, giving several examples in general relativity, and in gauge theory via a consideration of the vacuum solutions of the Yang-Mills equation. The physicist reader will appreciate this discussion of the classical theory of gauge fields, as it is good preparation for further reading on instantons and the eventual quantization of gauge fields.	2001-08-18
1875586:US	50702879	R3ELJFLP8V7U44	0387905189	461579260	Algebra (Graduate Texts in Mathematics) (v. 73)	Books	3	14	22	N	N	Comprehensive...but &quot;Bourbaki&quot; in its style	Algebra is a subject that must be mastered by anyone these days, although at varying levels. The applications of algebra permeate all fields of human endeavor, and for students, both at the elementary level and advanced graduate level, it can be a subject that is esoteric and on the surface removed from real world applications. This book, although comprehensive in its treatment of graduate level algebra, does not motivate the subject well, but instead treats it from an encyclopaedic, formal point of view. There are some exceptions to this, particularly in the chapter on Galois theory, as the author does a fine job of detailing this subject. If he would have approached the other chapters like he did in this one, this would be an excellent book. Unfortunately though too much of the book is without in-depth explanation, and it leaves the reader wanting.	2001-08-16
1876683:US	50702879	R21AAB0ZBGPX0	0387979700	46738048	Classical Topology and Combinatorial Group Theory (Graduate Texts in Mathematics) (v. 72)	Books	4	24	24	N	N	An introduction well worth reading	Ideas from topology are now manifested everywhere in physics, engineering, computer graphics, and many, many other applications. Consequently, a thorough understanding of topology has become necessary for those who are involved in these applications. This book gives an introduction to &quot;classical&quot; topology that emphasizes the geometric intuition behind the subject, and is thus very suitable for those who need such an understanding. That is not to say that aspiring mathematicians will not gain from the reading of the book. It still maintains a standard of rigor that graduate students in mathematics need to advance in more in-depth courses in topology. The author does not hesitate to use diagrams in the book, which makes it an even better one for those interested in applications. Most of the results he discusses were known in the late 1800's and early 1900's, but they are still important today, especially in physics.<br /> In chapter 0, the author introduces the fundamental concepts in topology with a discussion of the homoemorphism problem. Confining attention to three dimensions and less, the author does mention the impossibility of solving the problem in dimensions greater than or equal to four. He then gives an overview of open and closed sets, continuous functions, identification spaces, and elementary homotopy theory. The building blocks of the main objects he considers in the book, namely simplicial complexes, are discussed in detail. The Haupvermutung is briefly discussed, and a full proof, due to E.E. Moise, of the Jordan curve theorem is given. The proof is the first example of the general approach that the author takes in the book, namely of reducing general topology to combinatorial topology. A brief introduction to algorithms is given, and the author introduces the group theory needed for the rest of the book.<br /> Since he is taking an historical approach in this book, the author begins the study of surfaces with the study of Riemann surfaces. He motivates the ideas of Riemann surfaces, such as branched coverings of the 2-sphere, very nicely, and gives a very understandable theorem for surfaces is proved in detail. In addition, the concept of a universal covering space is described beautifully, and the author shows how to obtain it for orientable surfaces of genus greater than one. The author also gives a brief taste of Fuchsian groups.<br /> Chapter 2 is devoted completely to the group theory of graphs, as a warm up to the study of the fundamental group in the next chapter. The fundamental group is defined to be an equivalence class of maps, and with the exception of the circle, it is calculated using deformation retraction and the Seifert-Van Kampen theorem. The fundamental group of complexes are then calculated in chapter 4, using first a method due to Poincare, and then directly. Some knot theory is introduced, and the Wirtinger presentation of knot groups is discussed.<br /> Homology theory is presented in chapter 5 as an abelianization of the fundamental group, and the abelianization is shown to be independent of the presentation of the fundamental group. The author does not spend much time in homology, arguing (correctly) that in dimensions less than or equal to three the fundemental group contains all the information obtained from homology.<br /> The study of curves on surfaces is the subject of chapter 6, with the contractibility problem studied first using Dehn's algorithm. Some methods for &quot;simplifying&quot; simple curves on closed orientable surfaces by homeomorphisms are also discussed. These techniques could be considered an elementary warm-up to the handle calculus procedures done in higher-dimensional topology. The physicist-string-theorist reader will appreciate the discussion of the mapping class group of the torus.<br /> All of chapter 7 is devoted to knot theory, and this subject, now of enormous importance in physics and computational biology, is treated in great detail here. Thebraid group is defined, and Artin's solution of the word problem is given.<br /> A very short overview of 3-dimensional manifolds is given in chapter 8, wherein the important concept of a Heegaard splitting is discussed, along with other methods for constructing 3-manifolds. The recognition problem for the 3-sphere, and the famous Poincare conjecture, are mentioned, and the author outlines one method, called shelling a simplicial decomposition, for recoginizing a 3-sphere. He shows however the existence of an unshellable triangulation of the 3-ball (Bing's cube). The author is incorrect though when he states that an algorithm for disproving the conjecture, i.e. an algorithm for enumerating all the 3-manifolds not homeomorphic to the 3-sphere, does not exist. Since the date of publication of this book, such an algorithm has been constructed by Rourke and Sanderson.<br /> The book ends with a discussion of unsolvable problems in combinatorial topology. This is an unusual topic in a book on topology, but given the importance currently of computer algorithms in the growing field of &quot;computational topology&quot; such an inclusion is appropriate and useful. The author discusses Turing machines, Church's thesis, and the Halting problem. The author discusses the unsolvable problems in group theory, and shows how the halting problem can be reduced to the word problem in groups. He leaves as an exercise, using the formalism developed in the chapter on presentations of groups, the problem of showing the homeomorphism problem is unsolvable for closed 4-manifolds.e. The braid group is defined, and Artin's solution of the word problem is given. <br /> A very short overview of 3-dimensional manifolds is given in chapter 8, wherein the important concept of a Heegaard splitting is discussed, along with other methods for constructing 3-manifolds. The recognition problem for the 3-sphere, and the famous Poincare conjecture, are mentioned, and the author outlines one method, called shelling a simplicial decomposition, for recoginizing a 3-sphere. He shows however the existence of an unshellable triangulation of the 3-ball (Bing's cube). The author is incorrect though when he states that an algorithm for disproving the conjecture, i.e. an algorithm for enumerating all the 3-manifolds not homeomorphic to the 3-sphere, does not exist. Since the date of publication of this book, such an algorithm has been constructed by Rourke and Sanderson. <br /> The book ends with a discussion of unsolvable problems in combinatorial topology. This is an unusual topic in a book on topology, but given the importance currently of computer algorithms in the growing field of &quot;computational topology&quot; such an inclusion is appropriate and useful. The author discusses Turing machines, Church's thesis, and the Halting problem. The author discusses the unsolvable problems in group theory, and shows how the halting problem can be reduced to the word problem in groups. He leaves as an exercise, using the formalism developed in the chapter on presentations of groups, the problem of showing the homeomorphism problem is unsolvable for closed 4-manifolds.	2001-08-15
1877854:US	50702879	R1NKVOE5PFFAYM	0387902449	207047398	Algebraic Geometry (Graduate Texts in Mathematics)	Books	4	60	65	N	N	Be prepared...	This book is one of the most used in graduate courses in algebraic geometry and one that causes most beginning students the most trouble. But it is a subject that is now a &quot;must-learn&quot; for those interested in its many applications, such as cryptography, coding theory, physics, computer graphics, and engineering. That algebraic geometry has so many applications is quite amazing, since it was not too long ago that it was thought of as a highly abstract, esoteric topic. That being said, most of the books on the subject, including this one, are written from a very formal point of view. Those interested in applications will have to face up to this when attempting to learn the subject. To read this book productively one should gain a thorough knowledge of commutative algebra, a good start being Eisenbud's book on this subject. Also, it is important to dig into the original literature on algebraic geometry, with the goal of gaining insight into the constructions and problems involved. The author of this book does not make an attempt to motivate the subject with historical examples, and so such a perusal of the literature is mandatory for a deeper appreciation of algebraic geometry. The study of algebraic geometry is well worth the time however, since it is one that is marked by brilliant developments, and one that will no doubt find even more applications in this century.<br /> Varieties, both affine and projective, are introduced in chapter 1. The discussion is purely formal, with the examples given unfortunately in the exercises. The Zariski topology is introduced by first defining algebraic sets, which are zero sets of collections of polynomials. The algebraic sets are closed under intersection and under finite unions. Therefore their complements form a topology which is the Zariski topology. The properties of varieties are discussed, along with morphisms between them. &quot;Functionals&quot; on varieties, called regular functions in algebraic geometry, are introduced to define these morphisms. Rational and birational maps, so important in &quot;classical&quot; algebraic geometry are introduced here also. Blowing up is discussed as an example of a birational map. A very interesting way, due to Zariski, of defining a nonsingular variety intrinsically in terms of local rings is given. The more specialized case of nonsingular curves is treated, and the reader gets a small taste of elliptic curves in the exercises. A very condensed treatment of intersection theory in projective space is given. The discussion is primarily from an algebraic point of view. It would have been nice if the author would have given more motivation of why graded modules are necessary in the definition of intersection multiplicity.<br /> The theory of schemes follows in chapter 2, and to that end sheaf theory is developed very quickly and with no motivation (such as could be obtained from a discussion of analytic continuation in complex analysis). Needless to say scheme theory is very abstract and requires much dedication on the reader's part to gain an in-depth understanding. I have found the best way to learn this material is via many examples: try to experiment and invent some of your own. The author's discussion on divisors in this chapter is fairly concrete however.<br /> The reader is introduced to the cohomology of sheaves in chapter 3, and the reader should review a book on homological algebra before taking on this chapter. Derived functors are used to construct sheaf cohomology which is then applied to a Noetherian affine scheme, and shown to be the same as the Cech cohomology for Noetherian separated schemes. A very detailed discussion is given of the Serre duality theorem.<br /> Things get much more concrete in the next chapter on curves. After a short proof o the Riemann-Roch theorem, the author studies morphisms of curves via Hurwitz's theorem. The author then treats embeddings in projective space, and shows that any curve can be embeddedin P(3), and that any curve can be mapped birationally into P(2) if one allows nodes as singularities in the image. And then the author treats the most fascinating objects in all of mathematics: elliptic curves. Although short, the author does a fine job of introducing most important results.<br /> This is followed in the next chapter by a discussion of algebraic surfaces in the last chapter of the book. The treatment is again much more concrete than the earlier chapters of the book, and the author details modern formulations of classical constructions in algebraic geometry. Ruled surfaces, and nonsingular cubic surfaces in P(3) are discussed, as well as intersection theory. A short overview of the classification of surfaces is given. The reader interested in more of the details of algebraic surfaces should consult some of the early works on the subject, particularly ones dealing with Riemann surfaces. It was the study of algebraic functions of one variable that led to the introduction of Riemann surfaces, and the later to a consideration of algebraic functions of two variables. A perusal of the works of some of the Italian geometers could also be of benefit as it will give a greater appreciation of the methods of modern algebraic geometry to put their results on a rigorous foundation.edded in P(3), and that any curve can be mapped birationally into P(2) if one allows nodes as singularities in the image. And then the author treats the most fascinating objects in all of mathematics: elliptic curves. Although short, the author does a fine job of introducing most important results. <br /> This is followed in the next chapter by a discussion of algebraic surfaces in the last chapter of the book. The treatment is again much more concrete than the earlier chapters of the book, and the author details modern formulations of classical constructions in algebraic geometry. Ruled surfaces, and nonsingular cubic surfaces in P(3) are discussed, as well as intersection theory. A short overview of the classification of surfaces is given. The reader interested in more of the details of algebraic surfaces should consult some of the early works on the subject, particularly ones dealing with Riemann surfaces. It was the study of algebraic functions of one variable that led to the introduction of Riemann surfaces, and the later to a consideration of algebraic functions of two variables. A perusal of the works of some of the Italian geometers could also be of benefit as it will give a greater appreciation of the methods of modern algebraic geometry to put their results on a rigorous foundation.	2001-08-14
1882215:US	50702879	R1TIY7B32WUQ40	0201130467	739306491	An Introduction To Chaotic Dynamical Systems, Second Edition (Addison-Wesley Studies in Nonlinearity)	Books	4	26	27	N	N	Good introduction to the beginning student	This book gives a quick and elementary introduction to the field of chaotic dynamical systems that could be read by anyone with a background in calculus and linear algebra. The approach taken by the author is very intuitive, lots of diagrams are used to illustrate the major points, and there are many useful exercises throughout the book. It could serve well in an undergraduate mathematics course in dynamical systems, and in a physics undergraduate course in advanced mechanics. The author emphasizes the mathematical aspects of dynamical systems, and readers will be well prepared after finishing it to read more advanced books on dynamical systems.<br />Chapter 1 introduces one-dimensional dynamics, with the analysis of the quadratic map given particular attention. Called the logistic map in some circles, this very important dynamical system has been the subject of much study, and exhibits generically the properties of chaotic dynamical systems. The author also gives a brief review of some elementary notions in calculus needed for the chapter, making the book even more accessible to a wider readership. The important concept of hyperbolicity is discussed in the context of one-dimensional maps and a good discussion is given on symbolic dynamics. Structural stability, which is really useful only in dynamical systems in higher dimensions, is treated here. The intuition gained in one-dimension is invaluable though before moving on to higher-dimensional examples. Sarkovskii's theorem, which states that a one-dimensional dynamical system with a period three periodic orbit has periodic orbits for all other periods, is proved in detail. In addition, the Schwarzian derivative, so important in complex dynamics, is defined here. The author also gives an introduction to bifurcation theory, which again, is most interesting in high dimensions, and introduces the concept of homoclinicity in this discussion. Maps of the circle and the all-important Morse-Smale diffeomorphisms, are treated in this chapter also. The author introduces the reader briefly to the idea of genericity when discussing Morse-Smale diffeomorphisms. Kneading theory, so important in the mathematical theory of dynamical systems, is introduced here also.<br />In chapter 2, the author generalizes the results to higher dimensions, and begins with a review of linear algebra and some results from multivariable calculus, such as the implicit function theorem and the contraction mapping theorem. This is followed by a treatment of the dynamics of linear maps in two and three dimensions. Whereas the canonical example of one-dimensional dynamics is represented by the logistic map, in higher-dimensional dynamics this is represented by the Smale horseshoe map. The author carefully constructs this map and details its properties. Then he takes up the hyperbolic toral automorphisms (or Anosov systems as they are called in some books). Both the Smale horseshoe map and the toral automorphisms are excellent, easily understandable examples of higher dimensional dynamics and the associated symbolic dynamics.<br />The concept of an attractor is also treated in chapter 2 in the context of the solenoid and the Plykin attractor. Both of these are of purely mathematical interest, but by studying them the physicist reader can get a better understanding of what to look for in actual physical examples of attractors (or the more exotic concept of a strange attractor). The author also gives a proof of the stable manifold theorem in dimension two. This is the best part of the book, for this theorem is rarely proved in textbooks on chaotic dynamics, the proof being delegated to the original papers. However, the proof in these papers is extremely difficult to get through, and so the author has given the reader a nice introduction to this important result, even though it is done only in two dimensions. This is followed by a very understandable discussion of Morse-Smale diffeomorphisms. In addition, the author introduces the Hopf bifurcation, of upmost importance in applications, and introduces the Henon map as an application of the results obtained so far.<br />The last chapter of the book is a brief overview of complex analytic dynamics. Complex dynamical systems are very important from a mathematical point of view, and they have fascinating connections with number theory, cryptography, algebraic geometry, and coding theory. The author reviews some elementary complex analysis and then reintroduces the quadratic maps but this time over the complex plane instead of the real line. The Julia set is introduced, and the reader who has not seen the computer graphical images of this set should peruse the Web for these images, due to their beauty. The geometry of the Julia set and the associated complex polynomial maps are given a fairly detailed treatment by the author in the space provided.r introduces the Hopf bifurcation, of upmost importance in applications, and introduces the Henon map as an application of the results obtained so far. <br />The last chapter of the book is a brief overview of complex analytic dynamics. Complex dynamical systems are very important from a mathematical point of view, and they have fascinating connections with number theory, cryptography, algebraic geometry, and coding theory. The author reviews some elementary complex analysis and then reintroduces the quadratic maps but this time over the complex plane instead of the real line. The Julia set is introduced, and the reader who has not seen the computer graphical images of this set should peruse the Web for these images, due to their beauty. The geometry of the Julia set and the associated complex polynomial maps are given a fairly detailed treatment by the author in the space provided.	2001-08-11
1883515:US	50702879	R167UETF9G95J9	0387900888	713430618	Measure Theory (Graduate Texts in Mathematics) (v. 18)	Books	4	58	60	N	N	A classic in the field	This book is an overview of measure theory that is somewhat dated in terms of the presentation, but could still be read profitably by someone interested in studying the subject with greater generality than more modern texts. Measure theory has abundant applications, and has even gained importance in recent years in such areas as financial engineering. Those interested in the applications of measure theory to financial engineering should choose another book however, since this one does not even mention the word martingale.  After a review of elementary topology and set theory in chapter 1, the author begins to define the elementary notions of measure theory in chapter 2. His approach is more general than other texts, since he works over a ring instead of an algebra. Measures on intervals of real numbers is given as an example.  Measures and outer measures are defined, and it is shown how a measure induces an outer measure and how an outer measure induces a measure.<br /> The next chapter explores more carefully the relation between measures and outer measures. It is also shown in this chapter to what extent a measure on a ring can be extended to the generated sigma-ring. The all-important Lebesgue measure is developed here also, and the author exhibits an example of a non-measurable set.<br /> In order to develop an integration theory, one must first characterize the collection of measurable functions, and the author does this in chapter 4. The convergence properties of measurable functions are carefully outlined by the author.<br /> The theory of integration begins in chapter 5, wherein the author follows the standard construction of an integral by first defining integrals over simple functions. Then in chapter 6, signed measures are defined, and the Lebesgue bounded convergence theorem is proven and the Hahn and Jordan decompositions of these measures are discussed. The all-important Radon-Nikodym theorem, which gives an integral representation of an absolutely continuous sigma-finite signed measure, is proven in detail.<br /> One can of course take the Cartesian product of two measurable spaces, and the author shows how to define measures on these products in chapter 7, including infinite products. The physicist reader may want to pay attention to the section on infinite dimensional product measures, as it does have applications to functional integration in quantum field theory (although somewhat weakly).<br /> The author treats measurable transformations in chapter 8, but interestingly, the word &quot;ergodic&quot; is never mentioned. He also introduces briefly the L-p spaces, so very important in many areas of mathematics, and proves the Holder and Minkowski inequalities.<br /> The next chapter is the most important in the book, for it covers the notion of probability on measure spaces. After an brief motivation in the first section of the chapter, probability spaces are defined, and Bayes' theorem is discussed as an exercise. Both the weak and strong law of large numbers is proven in detail.<br /> Things get more abstract in chapter 10, which discusses measure theory on locally compact spaces. Borel and Baire sets on these kinds of spaces are defined, and the author gives detailed arguments on what must be changed when doing measure theory in this more general kind of space.<br /> The book ends with a discussion of measure theory on topological groups via the Haar measure. This chapter also has connections to physics, such as in the Faddeev-Popov volume measure over gauge equivalent classes in quantum field theory. The author does a fine job of characterizing the important properties of the Haar measure.continuous sigma-finite signed measure, is proven in detail. <br /> One can of course take the Cartesian product of two measurable spaces, and the author shows how to define measures on these products in chapter 7, including infinite products. The physicist reader may want to pay attention to the section on infinite dimensional product measures, as it does have applications to functional integration in quantum field theory (although somewhat weakly). <br /> The author treats measurable transformations in chapter 8, but interestingly, the word &quot;ergodic&quot; is never mentioned. He also introduces briefly the L-p spaces, so very important in many areas of mathematics, and proves the Holder and Minkowski inequalities. <br /> The next chapter is the most important in the book, for it covers the notion of probability on measure spaces. After an brief motivation in the first section of the chapter, probability spaces are defined, and Bayes' theorem is discussed as an exercise. Both the weak and strong law of large numbers is proven in detail. <br /> Things get more abstract in chapter 10, which discusses measure theory on locally compact spaces. Borel and Baire sets on these kinds of spaces are defined, and the author gives detailed arguments on what must be changed when doing measure theory in this more general kind of space. <br /> The book ends with a discussion of measure theory on topological groups via the Haar measure. This chapter also has connections to physics, such as in the Faddeev-Popov volume measure over gauge equivalent classes in quantum field theory. The author does a fine job of characterizing the important properties of the Haar measure.	2001-08-10
1885461:US	50702879	R2WCHDIR4JRCID	0387900535	978584250	Introduction to Lie Algebras and Representation Theory (Graduate Texts in Mathematics) (v. 9)	Books	4	39	40	N	N	There is a lot here for such a short book	This book is a pretty good introduction to the theory of Lie algebras and their representations, and its importance cannot be overstated, due to the myriads of applications of Lie algebras to physics, engineering, and computer graphics. The subject can be abstract, and may at first seem to have minimal applicability to beginners, but after one gets accustomed to thinking in terms of the representations of Lie algebras, the resulting matrix operations seem perfectly natural (and this is usually the approach taken by physicists). The book is aimed at an audience of mathematicians, and there is a lot of material covered, in spite of the size of the book. Readers who desire an historical approach should probably supplement their reading with other sources. Readers are expected to have a strong background in linear and abstract algebra, and the book as a textbook is geared toward graduate students in mathematics. Only semisimple Lie algebras over algebraically closed fields are considered, so readers interested in Lie algebras over prime characteristic or infinite-dimensional Lie algebras (such as arise in high energy physics), will have to look elsewhere. Physicists can profit from the reading of this book but close attention to detail will be required.<br /> The first chapter covers the basic definitions of Lie algebras and the algebraic properties of Lie algebras. No historical motivation is given, such as the connection of the theory with Lie groups, and Lie algebras are defined as vector spaces over fields, and not in the general setting of modules over a commutative ring. The four classical Lie algebras are defined, namely the special linear, symplectic, and orthogonal algebras. The physicist reader should pay attention to the (short) discussion on Lie algebras of derivations, given its connection to the adjoint representation and its importance in applications. The important notions of solvability and nilpotency are covered in fairly good detail. Engel's theorem, which essentially says that if all elements of a Lie algebra are nilpotent under the 'bracket&quot;, then the Lie algebra itself is nilpotent, is proven.<br /> The second chapter gives more into the structure of semisimple Lie algebras with the first result being the solution of the &quot;eigenvalue&quot; problem for solvable subalgebras of gl(V), where V is finite-dimensional. Cartan's criterion, giving conditions for the solvability of a Lie algebra, is proven, along with the criterion of semisimplicity using the Killing form. The representation theory of Lie algebras is begun in this chapter, with proof of Weyl's theorem. This theorem is essentially a generalization to Lie algebras of a similar result from elementary linear algebra, namely the Jordan decomposition of matrices. Again, physicist readers should pay close attention to the details of the discussion on root space decompositions.<br /> This is followed in chapter 3 by an in-depth treatment of root systems, wherein a positive-definite symmetric bilinear form is chosen on a fixed Euclidean space. These root systems enable a more transparent approach to the representation theory of Lie algebras. The theory of weights along with the Weyl group, allow a description of the representation theory that depends only on the root system. In addition, one can prove that two semisimple Lie algebras with the same root system are isomorphic, as is done in the next chapter. More precisely, it is shown that a semisimple Lie algebra and a maximal toral subalgebra is determined up to isomorphism by its root system. These maximal toral subalgebras are conjugate under the automorphisms of the Lie algebra. The author further shows that for an arbitary Lie algebra that is true, if one replaces the maximal toral subalgebra by a Cartan subalgebra. The proofs given do not use algebraic geometry, and so they are more accessible to beginning students.<br /> In chapter 5, the author introduces the universal enveloping algebra, and proves the Poincare-Birkhoff-Witt theorem. The goal of the author is to find a presentation of a semisimple Lie algebra over a field of characteristic 0 by generators and relations which depend only on the root system. This will show that a semisimple Lie algebra is completely determined by its root system (even if it is infinite dimensional).<br /> Chapter 6 is very demanding, and will require a lot of time to get through for the newcomer to the representation theory of Lie algebras. Weight spaces and maximal vectors are introduced in the context of modules over semisimple Lie algebras L. Finite dimensional irreducible L-modules are studied by first considering L-modules generated by a maximal vector. It is shown that if two standard cyclic modules of highest weight are irreducible, then they are isomorphic. The existence of a finite dimensional irreducible standard cyclic module is shown. Freudenthal's formula, which gives a formula for the multiplicity of an element of an irreducible L-module of heighest weight, is proven. A consideration of characters on infinite-dimensional modules leads to a proof of Weyl's formulas on characters of finite dimensional modules.<br /> The last chapter of the book considers Chevelley algebras and groups. Their introduction is done in the context of constructing irreducible integral representations of semisimple Lie algebras.nd proves the Poincare-Birkhoff-Witt theorem. The goal of the author is to find a presentation of a semisimple Lie algebra over a field of characteristic 0 by generators and relations which depend only on the root system. This will show that a semisimple Lie algebra is completely determined by its root system (even if it is infinite dimensional). <br /> Chapter 6 is very demanding, and will require a lot of time to get through for the newcomer to the representation theory of Lie algebras. Weight spaces and maximal vectors are introduced in the context of modules over semisimple Lie algebras L. Finite dimensional irreducible L-modules are studied by first considering L-modules generated by a maximal vector. It is shown that if two standard cyclic modules of highest weight are irreducible, then they are isomorphic. The existence of a finite dimensional irreducible standard cyclic module is shown. Freudenthal's formula, which gives a formula for the multiplicity of an element of an irreducible L-module of heighest weight, is proven. A consideration of characters on infinite-dimensional modules leads to a proof of Weyl's formulas on characters of finite dimensional modules. <br /> The last chapter of the book considers Chevelley algebras and groups. Their introduction is done in the context of constructing irreducible integral representations of semisimple Lie algebras.	2001-08-09
1885742:US	50702879	R21ZFOWURZKN3X	1856498352	702229056	Redesigning Life?: The Worldwide Challenge to Genetic Engineering	Books	2	8	16	N	N	No substantive arguments here	This book, a collection of articles pretty much against biotechnology, is a mixture of rationality and hype. There are some good arguments in some of the articles, and the book inadvertently introduces the reader to a lot of the activity and research currently being done in biotechnology and genetic engineering. In that respect the book was extremely helpful, but in terms of rational argumentation against genetic engineering, the book is lacking in general. There is a lot of anger and fear in the articles, and so it is difficult sometimes to sift through this to get at the essential points the authors are attempting to make. The authors speak of the threat of &quot;corporate globalism&quot; and &quot;horrific&quot; designs for our future. Genetic engineering, says one author, threatens to perpetuate a never-ending cycle of famine and hopelessness. No evidence, either empirical or from a modeling perspective, is given for this claim though. It is also asserted that organic agriculture has proved (&quot;time and time again&quot;) to be the better technique for growing more food, but again, no evidence is cited for this belief. In addition, the authors always emphasize the negative &quot;inadvertent&quot; consequences of genetic engineering, and do not mention any positive &quot;inadvertent&quot; ones. Can they not think of one instance where genetic engineering will have positive unintended consequences?<br /> In arguing that the Monsanto Roundup Ready soybeans will not do completely away with other herbicides or with ploughing, one of the authors emphasizes that nature is adaptable, and will find a way to circumvent a system based on a single strategy. Could it not be argued then that nature would find a way then of circumventing any negative consequences of genetic engineering? Is it purely an argument of time scales that the author is making, i.e. that a sudden introduction in nature of genetically engineered crops makes nature go wild and immediately fight this invasion? What makes nature so predisposed to treat genetically modified crops differently than those that are not?<br /> The reader is warned in the book that genetic engineering often has unexpected results, and that introducing bioengineered plants into the food supply could cause any number of possible health and environmental consequences. But is this not true of anything in the real world?  Does not the introduction of &quot;pure&quot; organic foods have unseen consequences for health?<br /> In addition, the authors in the book are fond of pointing out the fact that biotechnology companies have invested hundreds of billions of dollars into genetically modified plants and foods. The use of the word &quot;billions&quot; is supposedly meant to frighten the reader into believing that biotech has evolved into a business scale of gargantuan proportions. But does not the organic food industry invest billions of dollars into the development and marketing of organic foods? Should we be threatened by their attempts to &quot;control&quot; the food supply?<br /> University researchers have also taken on a bad name in this book, due to the millions of dollars that are now invested by biotech firms in various universities around the United States. But researchers have worked on projects financed by other corporations as well, and will continue to do so. There have been conflicts of interest in these collaborations and there no doubt will be some with biotech companies. This by itself does not justify the book's anti-biotech stance. It merely says that researchers have funding sources outside the government sector, and this, in my view, is something to be applauded and not condemned. University researchers should be proud of their work and accomplishments, and even more so if a useful product is a result of their endeavors.<br /> Human cloning is condemned in the book as being irresponsible and threatening, with the &quot;designer babies&quot; scenario created to mesh with thedistorted view propagated by science fiction. The novel &quot;Brave New World&quot; is the canonical reference in the book. Parents, it is argued, should not want to have the choice of reproductive freedom, especially cloning, since this route is beset with enormous difficulties. This is an odd argument, since if cloning does turn into a viable technique for asexual reproduction, genetic risks would stand more of a chance of being alleviated, rather than aggravated, as claimed in the book. (The authors do have reason to rejoice however, since last week (July 31, 2001), the US House of Representatives voted to ban human cloning, unfortunately. ). Worries about selling clones are misplaced; human clones should have the same rights as any other human being when it comes to what is to be done with their internal organs. The authors in the book should spend more time on focusing their energies on securing these rights legally, rather than engaging in irrational and irresponsible scare tactics. The same could be said of their discussion on eugenics.<br /> The right to secure a patent on an invention is thought of as more of a crime in this book rather than a way of securing a right to one's creativity and labor. But owning a patent on a gene is no different than owning one on any other object of discovery; if the authors feel threatened by this, a rational suggestion would be to enter the arena of discovery, come up with new ideas and innovations, and secure these patents for themselves.<br /> The authors do correctly argue against genetic determinism and against irresponsible behavior towards the environment. But never do they suggest positive solutions to environmental problems, but instead rely on vituperative dialog to get their point across.<br /> The last part of the book ends with a summary of the &quot;world-wide&quot; resistance to genetic engineering. One could argue that the authors are right: there seems to be a great reluctance on the part of many people to accept genetically modified foods and human cloning. But this will pass; people in this century are educated and smart enough to make decisions for themselves once the evidence is forthcoming on the enormous benefits of genetic engineering. The ramifications are awesome.the distorted view propagated by science fiction. The novel &quot;Brave New World&quot; is the canonical reference in the book. Parents, it is argued, should not want to have the choice of reproductive freedom, especially cloning, since this route is beset with enormous difficulties. This is an odd argument, since if cloning does turn into a viable technique for asexual reproduction, genetic risks would stand more of a chance of being alleviated, rather than aggravated, as claimed in the book. (The authors do have reason to rejoice however, since last week (July 31, 2001), the US House of Representatives voted to ban human cloning, unfortunately. ). Worries about selling clones are misplaced; human clones should have the same rights as any other human being when it comes to what is to be done with their internal organs. The authors in the book should spend more time on focusing their energies on securing these rights legally, rather than engaging in irrational and irresponsible scare tactics. The same could be said of their discussion on eugenics. <br /> The right to secure a patent on an invention is thought of as more of a crime in this book rather than a way of securing a right to one's creativity and labor. But owning a patent on a gene is no different than owning one on any other object of discovery; if the authors feel threatened by this, a rational suggestion would be to enter the arena of discovery, come up with new ideas and innovations, and secure these patents for themselves. <br /> The authors do correctly argue against genetic determinism and against irresponsible behavior towards the environment. But never do they suggest positive solutions to environmental problems, but instead rely on vituperative dialog to get their point across. <br /> The last part of the book ends with a summary of the &quot;world-wide&quot; resistance to genetic engineering. One could argue that the authors are right: there seems to be a great reluctance on the part of many people to accept genetically modified foods and human cloning. But this will pass; people in this century are educated and smart enough to make decisions for themselves once the evidence is forthcoming on the enormous benefits of genetic engineering. The ramifications are awesome.	2001-08-08
1889244:US	50702879	R3OKWVPTDUFDNA	1575862174	859027902	Time Warps, String Edits, and Macromolecules: The Theory and Practice of Sequence Comparison	Books	4	23	23	N	Y	Still a useful source of information	This book, originally published in 1983, was reissued in 1999, no doubt because of the importance of genetic sequencing in recent years. What is neat about the book is it shows how algorithms from one field can be applied to solve problems in another, possibly totally disparate field, one example being computational linguistics and sequence algorithms in computational biology.<br /> A general overview of sequence comparison is given in chapter 1 with applications to molecular biology, human speech, computer science, coding theory, gas chromotography, and bird songs discussed. The author discusses how deletion-insertion, compression-expansion, and substitution are employed in sequence comparison. Different metrics are introduced, such as the Levenshtein distance. Dynamic programming, which pretty much dominates the book, is introduced here also.<br /> Part 1 of the book discusses sequence comparison in molecular biology. The use of dynamic programming is emphasized and its importance continues to this day. The advantages of using the dynamic programming method are outlined, and it is shown how to find the substring in a longer sequence with most optimum agreement to a shorter sequence. In addition, given an RNA molecule with a known nucleotide sequence, methods are discussed for predicting the way different parts of the molecule will bond to each other. These methods are based on dynamic programming. Mathematicians considering doing research on or about entering the field will profit from the section on the biological background. The treatment of RNA secondary structures is excellent.<br /> In part 2, the emphasis is on speech processing and what is called &quot;time-warping&quot;, which is a technique for comparing functions by altering the time axis. An interesting application is given to the comparison of bird songs. An algorithm is given for adjusting the time scales for two songs to arrange them in the most optimal alignment. In addition, the differences between compression and expansion and deletion and insertion are discussed in this part.<br /> In part 3, a modified Smith-Waterman algorithm is employed to find similar portions in two sequences. Called local alignment in computational biology, it is shown in detail how to define the recurrences for the alignment and how to keep track of the pointers for backtracking. This part also generalizes the operations of substitution and Levenshtein distance. In addition, the strategy of doing sequence comparison by allowing transpositions is discussed. Such a strategy entails a generalized concept of trace, wherein trace lines can intersect each other, leading to entangling of the traces into knots or plaids. The usual dynamic programming techniques must then be extended to deal with these complications. One particular algorithm for this is discussed, called CELLAR, which involves the construction of a directed graph whose paths correspond to admissible sequences of generalizations of traces, called cuts. The computational complexity of this algorithm is discussed. In addition, an O(n^2/logn) algorithm is given for computing string-edit distances.<br /> The last part of the book deals with studying comparisons between random sequences. Combinatorial arguments are used to derive upper bounds on the expected length of the longest common subsequences of two random sequences. Other miscellaneous results dealing with comparing common subsequences of two random sequences are given.een compression and expansion and deletion and insertion are discussed in this part. <br /> In part 3, a modified Smith-Waterman algorithm is employed to find similar portions in two sequences. Called local alignment in computational biology, it is shown in detail how to define the recurrences for the alignment and how to keep track of the pointers for backtracking. This part also generalizes the operations of substitution and Levenshtein distance. In addition, the strategy of doing sequence comparison by allowing transpositions is discussed. Such a strategy entails a generalized concept of trace, wherein trace lines can intersect each other, leading to entangling of the traces into knots or plaids. The usual dynamic programming techniques must then be extended to deal with these complications. One particular algorithm for this is discussed, called CELLAR, which involves the construction of a directed graph whose paths correspond to admissible sequences of generalizations of traces, called cuts. The computational complexity of this algorithm is discussed. In addition, an O(n^2/logn) algorithm is given for computing string-edit distances. <br /> The last part of the book deals with studying comparisons between random sequences. Combinatorial arguments are used to derive upper bounds on the expected length of the longest common subsequences of two random sequences. Other miscellaneous results dealing with comparing common subsequences of two random sequences are given.	2001-08-06
1890734:US	50702879	R1SK8D4TWYSTXO	0847687821	855431489	Who's Afraid of Human Cloning?	Books	5	11	12	N	N	Brilliant	In view of the...decision made by the House of Representatives this week on banning human cloning, this book is a breath of fresh air. It is the only book I have found that addresses the issue of human cloning with a calmness of spirit and rational argumentation. The author's arguments in favor of human cloning are concise yet powerful, and everyone interested in the bioethics of human cloning will gain a lot from the reading of this book. I only wish every member of the House would have read, studied, and thought about this book before making their awful decision. One of the House members comments were to the effect that no \\"mad scientist\\" is going to be allowed to proceed with the cloning of human beings.<br /> Such commentary by the House member is rooted in popular culture according to the author.  Movies, literature, and to a large degree educational institutions have painted a picture of human cloning that has no basis in science or reality. And from my own personal confrontations with people against human cloning, his assertions are correct; most people, even highly educuated ones, have a completely distorted view about what is actually possible in today's technology.<br /> The author refutes successfully the arguments against human cloning, but also gives positive arguments for proceeding with it. I don't think the people steadfastly against human cloning will be swayed by this book, but one must remain optimistic. At any rate, the author shows convincingly that human cloning (or nuclear somatic transfer as he likes to call it) is an option that should be pursued, although with care. After reading it, one could say that a positive decision for human cloning by the citizens of our world will not lead to a \\"slippery slope\\"....but instead to a \\"thoughtful ascent\\".	2001-08-05
1891493:US	50702879	RR4DL5HA7M6HM	0132908425	425312131	Computational Geometry and Computer Graphics in C++	Books	4	13	13	N	N	A good start	This book is a short introduction of how the programming language C++ can be used to solve various problems in computational geometry. It is modest in its goals, and concentrates mostly on typical &quot;bread-and-butter&quot; topics that would be encountered by someone first encountering the field of computational and discrete geometry. Specialized topics in computational geometry and more modern techniques can then be found in the literature for interested readers who need a more comprehensive treatment.<br /> The first three chapters introduce the reader to the notion of algorithms and data structures. The author uses the boundary-intersection problem to illustrate the main points of the chapter, such as algorithmic paradigms and abstract data types. Complexity measures for algorithms are discussed briefly, along with mathematical induction. The linked list data structures he discusses are very important in computational geometry, especially the pointer-based implementation.<br /> In chapter 4, the author discusses the data structures that are needed for dealing with geometric structures in dimension 2 and 3. After a review of vector algebra he defines the point class and then the vertex class. The latter, along with the polygon class, is used to define polygons as a cycle of vertices which are stored in a circular doubly linked list. These are generalized to 3 dimensions where classes are given for points, triangles, and edges. The author then gives an algorithm for finding the intersection of a line and a triangle, which uses projection, and tests for degeneracy before projecting.<br /> The next part of the book deals with applications of the algorithms, such as finding a star-shaped polygon in a finite set of points, finding the convex hull of a set of points, the decision problem for points inside polygons, the Cyrus-Beck and Sutherland-Hodgman algorithms for clipping geometric objects to convex polygons, and an O(nlogn) algorithm for triangulating a monotone polygon. The treatment is very understandable and should prepare the reader for more advanced reading  (especially in computer graphics). The famous gift wrapping algorithm for finding the convex hull is given, along with the Graham scan algorithm. Issues more pertinent to computer graphics, such as rendering are discussed also. The hidden surface removal problem is solved via depth sorting. An algorithm is also given for finding the Delaunay triangulation. In addition, the author does a nice job of showing how to use plane-sweep algorithms for computational geometry problems in the plane. An interesting O((r + n)logn) time algorithm for finding the number r of pairs of n line segments in the plane that intersect. Voronoi diagrams are discussed also, which are extensively used in applications. The latter few chapters are more specialized than the rest of the book, and concentrate on divide and conquer algorithms and binary search trees.ne polygon. The treatment is very understandable and should prepare the reader for more advanced reading  (especially in computer graphics). The famous gift wrapping algorithm for finding the convex hull is given, along with the Graham scan algorithm. Issues more pertinent to computer graphics, such as rendering are discussed also. The hidden surface removal problem is solved via depth sorting. An algorithm is also given for finding the Delaunay triangulation. In addition, the author does a nice job of showing how to use plane-sweep algorithms for computational geometry problems in the plane. An interesting O((r + n)logn) time algorithm for finding the number r of pairs of n line segments in the plane that intersect. Voronoi diagrams are discussed also, which are extensively used in applications. The latter few chapters are more specialized than the rest of the book, and concentrate on divide and conquer algorithms and binary search trees.	2001-08-04
1895769:US	50702879	RN00E6AOCBFR7	0697113922	712176969	Discovering Jazz Dance: America's Energy and Soul (Championship Series)	Books	4	5	6	N	N	Good overview of jazz technique	This book is a good introduction to jazz dance and emphasizes the building of technique not only via the steps and movements themselves but with also from an appreciation of the cultural origins of the dance. It could be read by dancers or teachers needing an organized set of exercises, or by those who want a deeper appreciation of this form of dance. There are many good photographs in the book, and many illustrations of human anatomy to assist in the discovery of the muscles involved in dance. The opposition of forces and movements, and the many isolations in the body, give jazz its unique characteristics. This interesting and fun art form is nicely summarized in this book.	2001-08-01
1896464:US	50702879	RJW7H9XZC8JX	0916622878	217950345	The Art of Pas De Deux (English and Russian Edition)	Books	4	4	4	N	N	If you can find a used copy, buy it.	This book is a short overview of ballet technique that was translated from the Russian by Joan Lawson. It addresses strictly the techniques behind partnering in ballet, the famous pas de deux, and is a good source of information for the dancers who need hints and sound suggestions on executing some of these difficult movements. It could also be read profitably by biomechanicians studying the physics of ballet, and by anyone who wants to appreciate more what is involved in the actual execution of pas de deux. It has many illustrations that are quite good actually (and are not stick figures).<br />  Part 1 covers the basic holds in supported adage, holds with two hands on the waist, turns (including promenade, revolve, and pirouettes), falling poses and positions using two hands, hand holds, supported adage using falls into poses and positions, holds with one hand, supported adage into and falling positions and pose.<br />  Part 2 covers the more difficult area of lifts in the air, and discusses little jumps and small lifts to the level of the chest or shoulder, jumps holding the girl with both hands on her waist, jumps with a lift from two hands using various holds, jumps with one-hand holds, small lifts, half turns with a throw into the air, jumps into the boy's arms, grand elevation with lifts on to the chest and shoulders, jumps on to the chest and shoulder, lifts and holds in grand elevation, lifts in a fixed position, lifts with fixed poses on the fullest stretch of the boy's arms, and throwing the girl into the air with and without a change of pose.	2001-08-01
1899453:US	50702879	R2Z3OMWAU0J8DU	0871271923	844696108	Ear Training for the Body: A Dancer's Guide to Music	Books	4	25	25	N	N	Very helpful	This book, written for the aspiring professional dancer and choreographer, can also be read profitably by anyone interested in dance. The goal of the book is to get dancers to improve their listening skills and gain a broader understanding of musical concepts and notation. Most importantly, it encourages the dancer to explore new ideas connecting movement with sound. The author recognizes however that dance need not always been done to music, citing the great Doris Humphrey's &quot;Water Study&quot; as an example.<br /> The book is very insightful and has much to say about the relation between dance and music. In attempting to define &quot;musicality&quot; the author emphasizes the enumerable different ways that music and movement can be related. Movement need not be done &quot;with the music&quot;, it may be contrary to the music, and act &quot;against&quot; it. She details how choreographers view music and its use in dance and in dance class. Assignments are given at the end of each chapter to illustrate and extend the main points.<br /> Body percussion is introduced as a tool to understand musical percussion patterns as actually done via instruments. The author emphasizes that dancers can improvise on the spot just like most drummers do.<br />  The difference between dancer's counts and musician's counts are discussed, and dancers must learn to do both, according to the author. She draws on the knowledge and experience of some of the eminent choreographerrs on notions of musicality, counting, and how the dancer should relate to music. Choreographers are encouraged to collaborate with musicians and the author details the methods of collaboration. Interestingly, one of these is for the choreographer to put together the movement and videotape it, letting the composer have complete freedom to choose the music. The collaboration between Martha Graham, Louis Horst, and Erick Hawkins is discussed in detail as an example of a very successful collaboration.<br /> The chapter entitled &quot;Sounds and Silences&quot; emphasizes the importance of silent breaks in music. Balanchine's use of Stravinsky is quoted as an example of the unique use of silence in dance. A very brief discussion of the physics of sound is given.<br /> Good technical overviews of music dynamics and timing are given in the book, and the author is very aware of the physical effects of sound that must be dealt with in giving a performance in a large auditorium. The terminology of music dynamics is defined in detail, as well as the notion of attack and decay, with the latter being described in physics terms. A very good overview is given of string articulations and dynamic accents. The use of the metronome to keep time is discussed and the author details time signatures, bar lines, and measures. By far the most important discussion of this part is the one on syncopation, for this can be exploited very imaginatively by the dancer.<br /> Rhythmic patterns are discussed using graphical methods, and the notion of polyrhythm, where more than one rhythmic pattern is occurring at the same time, is discussed. A lengthy list is given of the more popular social dance rhythms.<br /> The notion of pitch is also related to the physics of sound along with consonance and dissonance. The different types of scales, namely diatonic, pentatonic, and whole-tone, are discussed briefly with short musical scores given as examples.<br /> Harmony is defined as a &quot;vertical dimension&quot; in music, i.e. the use of simultaneous basic scale pitches. The circle of fifths is discussed also in a section on tonality. Such technical considerations in music are geared primarily to the choreographer reader, particularly the discussions on timbre and score reading. The author also is careful to discuss non-Western musical constructions, all in relation to dance forms. One good example of this is the discussion on the Raga and Tala classical Indian procedures. There is also a brief discussion of more &quot;exotic&quot; phrasing structures such as 7/8 and 18/8 meters. In addition, the author gives a thorough treatment of sectional forms in dance, the AABB, ABA, AABBCCAB, etc. A list of &quot;10 commandments&quot; for communicating with musicians in class and rehearsal is given.on of more &quot;exotic&quot; phrasing structures such as 7/8 and 18/8 meters. In addition, the author gives a thorough treatment of sectional forms in dance, the AABB, ABA, AABBCCAB, etc. A list of &quot;10 commandments&quot; for communicating with musicians in class and rehearsal is given.	2001-07-30
1901316:US	50702879	RAFF7DMLNPZQD	1558605436	911691077	Genetic Programming III: Darwinian Invention and Problem Solving (Vol 3)	Books	5	27	29	N	N	A hint of the future.....	The authors have written a fine book here and it has and will continue to be a source of good information on the subject. What is most interesting about the approach of genetic programming is that it does not make use of the inference methods of formal logic in the search for the correct program. Correctly observing that logical thinking is insufficient for invention and creativity, the authors follow the &quot;logic considered harmful&quot; philosophy in their attempts to get a computer to find a creative/original solution to a problem. And most importantly, they discuss fourteen examples where genetic programming has produced results that are competitive with human-produced results. The book is almost 1200 pages long, but without reading all the examples one could cover the main points in a reasonable time frame. The reader knowing the LISP language will appreciate the discussion more.<br /> After a brief introduction to the book in chapter 1, the authors move on to a detailed discussion of the philosophy and approaches used in genetic programming. They list the five steps that must be done before applying a genetic algorithm to a problem and give an overview of the LISP background needed to understand genetic programming. The authors emphasize that the genetic algorithm is probabilistic in nature, with the initial populations, individual selection, and genetic operation chosen at random. They give flowcharts illustrating a typical genetic algorithm and program, and then show executable programs can be automatically created. A very extensive list of references on genetic programming is given at the end of the chapter.<br /> In the next part, the authors discuss how to eliminate the requirement that the programmer specify the architecture in advance to the program to be created. After reviewing some methods that were previously used to make the choice of architecture, the authors move on to describing a set of architecture-altering operations that give an automated method for determining the architectures of evolving programs. The discussion on automatically defined recursion is particularly interesting.<br /> The book then shows how to use the results so far to allow problem-solving to be done using genetic programming, the first one being the rotation of automobile tires and the second being evolving a computer program with the behavior of Boolean even-parity functions. This is followed by a discussion of how to use architecture-altering operations to solve a time-optimal control problem. The most interesting part of this discussion is that it illustrates the important point that disadvantageous actions should be taken in the short term so that the long-term objective can be achieved.<br /> In chapter 14, the ant foraging problem is used to illustrate a form of the (Minsky) multiagent problem and architecture-altering operations. This is followed by discussions on the digit recognition problem and the transmembrane segment identification problem. The authors choose the Fibonacci sequence to illustrate how recursion can be used in solving problems with genetic programming. The necessity of using internal storage is illustrated using the cart centering problem.<br /> The authors then overview the use of the Genetic Programming Problem Solver (GPPS) for automatically creating a computer program to solve a problem. Several problems are examined using this Solver, such as symbolic regression, sorting networks, and the intertwined spirals problem.<br /> The next part then considers the application of genetic programming to the automated synthesis of analog electrical circuits. The authors judge, rightfully, that the design process is one that will be a good judge of automated technique versus one that was done by humans, especially considering the fact that analog design is considered by many to be an &quot;art&quot; rather than a &quot;science&quot;. The authors show how to import the SPICE simulation system into the genetic programming system, and discuss how validation of circuit design using this simulator would be done by the genetic programming system. After showing how a low-pass filter may be successfully designed using the genetic programming system, the authors show how with a few changes it can be used to design many different types of circuits. Interestingly, the authors cite the rediscovery by genetic programming of the elliptic filter topology of W. Cauer. Cauer arrived at his discovery via the use of elliptic functions, but the genetic program did not make use of these, but relied solely on the problem's fitness measure and natural selection!<br /> An interesting discussion is also given of the role of crossover in genetic programming by comparing the problem of synthesizing a lowpass filter with and without using crossover. The authors conclude that the crossover operation plays a large contribution to the actual solution of the problem.<br /> Then later, the authors show how genetic programming actually evolved a cellular automata that performs better than a succession of algorithms written by humans in the last two decades. Specifically, they show how genetic programming evolved a rule for the majority classification problem for one-dimensional two-state cellular automata that exceeds the accuracy of all known rules.<br /> Most interestingly, the authors show how genetic programming evolved motifs for detecting the D-E-A-D box family of proteins and for detecting the manganese superoxide dismutase family.<br /> The actual performance and implementation issues involved in genetic programming are discussed in the last two parts of the book. They discuss the computer time needed to yield the 14 instances where they claim that genetic programming has produced results that are competitive with human-produced results.<br /> The authors wrap things up in the last chapter of the book and discuss other instances where genetic programming has succeeded in automatically producing computer programs that are competitive with human-produced results. The evidence they have in the book is impressive but there are a few areas that will be ultimate tests of this approach, the most important being the discovery of new mathematical results or algorithms. It is this area that requires the most creativity on the part of the inventor.ic programming system, and discuss how validation of circuit design using this simulator would be done by the genetic programming system. After showing how a low-pass filter may be successfully designed using the genetic programming system, the authors show how with a few changes it can be used to design many different types of circuits. Interestingly, the authors cite the rediscovery by genetic programming of the elliptic filter topology of W. Cauer. Cauer arrived at his discovery via the use of elliptic functions, but the genetic program did not make use of these, but relied solely on the problem's fitness measure and natural selection!<br /> An interesting discussion is also given of the role of crossover in genetic programming by comparing the problem of synthesizing a lowpass filter with and without using crossover. The authors conclude that the crossover operation plays a large contribution to the actual solution of the problem. <br /> Then later, the authors show how genetic programming actually evolved a cellular automata that performs better than a succession of algorithms written by humans in the last two decades. Specifically, they show how genetic programming evolved a rule for the majority classification problem for one-dimensional two-state cellular automata that exceeds the accuracy of all known rules. <br /> Most interestingly, the authors show how genetic programming evolved motifs for detecting the D-E-A-D box family of proteins and for detecting the manganese superoxide dismutase family. <br /> The actual performance and implementation issues involved in genetic programming are discussed in the last two parts of the book. They discuss the computer time needed to yield the 14 instances where they claim that genetic programming has produced results that are competitive with human-produced results. <br /> The authors wrap things up in the last chapter of the book and discuss other instances where genetic programming has succeeded in automatically producing computer programs that are competitive with human-produced results. The evidence they have in the book is impressive but there are a few areas that will be ultimate tests of this approach, the most important being the discovery of new mathematical results or algorithms. It is this area that requires the most creativity on the part of the inventor.	2001-07-28
1901414:US	50702879	R1GRPO8KZZTQY	0241898986	327103453	How to Read Music	Books	4	9	10	N	N	For the absolute beginner...buy a used copy	This book is written for the person just beginning to learn the essentials of music notation and is short, concise, and well organized. Dancers who need a knowledge of how to read music could benefit from the book, along with parents who need to teach their children how to read music. Definitely a bargain price also. There are myriads of other books on reading music and advanced treatises on music theory for those who want to go on.	2001-07-28
1901526:US	50702879	R2YJDJN4O92YST	0201503972	441092729	An Introduction To Quantum Field Theory (Frontiers in Physics)	Books	5	55	62	N	N	Promotes physical insight and understanding...not formalism	The authors give an excellent overview of the physical concepts and computational aspects of quantum field theory. They stress the situation behind the subject, and endeavor to remain as concrete as possible. Abstract mathematical constructions are left to more advanced texts in quantum field theory. The authors characterize their book as an updating of the two volume set of Bjorken and Drell.<br /> The main emphasis of the book is on quantum electrodynamics (QED), the most successful of quantum field theories. The representation and analysis of the physical processes of QED is done via Feynman diagrams, with electron-positron annihilation leading off the discussion. Recognizing that the exact expression for the amplitude of this process is not known, perturbation theory is used to give an approximate representation for it via an infinite series with each term involving successively higher powers of the strength of the coupling between the electrons and photons (i.e. the charge). Each term is represented as a Feynman diagram. This is followed by a discussion of the quantum field theory of the Klein-Gordon field. The authors give one of the best explanations in the literature of why one must deal with the quantization of fields and not particles, the most important one being causality. Canoncial quantization is employed and the Feynman propagator for the Klein-Gordon field is derived. The Dirac field is also quantized using the canonical formalism. The authors show that Klein-Gordon fields obey Bose-Einstein statistics and Dirac fields obey Fermi-Dirac statistics.  The all-important Wick's theorem is proven and higher-order Feynman diagrams are discussed. Most importantly, the authors show how to connect these results to experiment via the calculation of cross sections and decay rates. This entails the computation of the S-matrix elements from Feynman diagrams. The authors are very detailed in their elucication of the discussion, and those who have done these calculations know that it is great fun to do so. In addition, these &quot;bread-and-butter&quot; calculations give quantum field theory its ultimate justification in the modern particle accelerator. The discussion on radiative corrections is especially well-written, particularly the section on infrared divergences.<br /> The authors do not entirely neglect the more formal aspects behind quantum field theory, and spend some time discussion renormalization and the amazing Ward-Takahashi identity. This important identity gives one further confidence in the consistency of QED in that is shows that timelike and longitudinal photons can be neglected in the actual calculations. The process of renormalization has been viewed with suspicion by mathematicians, but it has been given a firmer foundation recently using, interestingly, mostly 19th century mathematics.  The authors discuss functional methods, and give an example of its use by calculating the photon propagotor. Viewing this as a constrained problem because of gauge invariance they use the Faddeev-Popov gauge fixing condition to obtain the correct results. In addition, they derive the important Schwinger-Dyson equations for QED using functional methods.<br /> Effective field theories are also introduced in the book, with an explicit calculation of the effective action. The authors show the important connection between continuous symmetries and the existence of massless particles (Goldstone's theorem). Their discussion of the renormalization group is very understandable, and they motivate the subject well, by asking why the loop integrals over virtual-particle momenta are always dominated by values on the order of the finite external momenta.<br /> Non-Abelian gauge theories are given a thorough treatment and Wilson loops are introduced as a comparator between gauge transformations at different spacetime points. The quantization of these theories is again done by viewing the quantization problem as a constrained problem, and the famous &quot;Lagrange multlipiers&quot;, the Faddeev-Popov ghosts, are introduced. The authors show in detail how their introduction allows the correct Feynman rules to be produced, by showing that the unphysical timelike and longitudinal polarization states of the gauge bosons are cancelled by these fields. The BRST symmetry is discussed as a formal device to to this cancellation. The omit though how the Ward identities are derived from BRST symmetry.<br /> The authors give the best explanation in the literature of asymptotic freedom by showing the effect of vacuum fluctuations on the Coulomb field of a SU(2) gauge theory.<br /> The important operator product expansion is treated in the context of the Callan-Symanzik equation in quantum chromodynamics. It is applied to the deep inelastic scattering and electron-positron annihilation. Dispersion relations make their appearance here.<br /> The authors also discuss anomalies and motivate the subject by analyzing the axial current in two-dimensional massless QED. The axial current is shown not to be conserved in the presence of an electromagnetic field, and they conclude that gauge invariance and conservation of axial currents in this theory cannot both be simultaneously satisfied. This is generalized to axial currents in four dimensions and the authors derive the famous Adler-Bell-Jackiw anomalies. The implications of anomalies for gauge theories are discussed along with observable consequencies.<br /> The (mysterious) Higgs mechanism is also discussed and compared to the situation in superconductivity. To view it in terms of superconductivity I think gives it the most plausible and intuitive justification. Understanding the Higgs mechanism is a usual stumbling-block for newcomers to gauge theories, and the authors do a fair job here. The quantization of spontaneously broken gauge theories is then carried out, with emphasis on the Goldstone boson equivalence theorem. A brief discussion of the future of quantum field theory ends the book.<br /> When reading this book, and others on quantum field theory, I am always amazed at the degree to which it works, and its elegance, despite the fact that it really is a collection of ad hoc strategies and sophisticated guesswork. One gets the impression that there is something profound behind the scenes, still waiting to be discovered, and which will be able to shed light on the major unsolved problem of quantum field theory: the existence of a bound state.em, and the famous &quot;Lagrange multlipiers&quot;, the Faddeev-Popov ghosts, are introduced. The authors show in detail how their introduction allows the correct Feynman rules to be produced, by showing that the unphysical timelike and longitudinal polarization states of the gauge bosons are cancelled by these fields. The BRST symmetry is discussed as a formal device to to this cancellation. The omit though how the Ward identities are derived from BRST symmetry. <br /> The authors give the best explanation in the literature of asymptotic freedom by showing the effect of vacuum fluctuations on the Coulomb field of a SU(2) gauge theory. <br /> The important operator product expansion is treated in the context of the Callan-Symanzik equation in quantum chromodynamics. It is applied to the deep inelastic scattering and electron-positron annihilation. Dispersion relations make their appearance here. <br /> The authors also discuss anomalies and motivate the subject by analyzing the axial current in two-dimensional massless QED. The axial current is shown not to be conserved in the presence of an electromagnetic field, and they conclude that gauge invariance and conservation of axial currents in this theory cannot both be simultaneously satisfied. This is generalized to axial currents in four dimensions and the authors derive the famous Adler-Bell-Jackiw anomalies. The implications of anomalies for gauge theories are discussed along with observable consequencies. <br /> The (mysterious) Higgs mechanism is also discussed and compared to the situation in superconductivity. To view it in terms of superconductivity I think gives it the most plausible and intuitive justification. Understanding the Higgs mechanism is a usual stumbling-block for newcomers to gauge theories, and the authors do a fair job here. The quantization of spontaneously broken gauge theories is then carried out, with emphasis on the Goldstone boson equivalence theorem. A brief discussion of the future ofquantum field theory ends the book. <br /> When reading this book, and others on quantum field theory, I am always amazed at the degree to which it works, and its elegance, despite the fact that it really is a collection of ad hoc strategies and sophisticated guesswork. One gets the impression that there is something profound behind the scenes, still waiting to be discovered, and which will be able to shed light on the major unsolved problem of quantum field theory: the existence of a bound state.	2001-07-28
1904074:US	50702879	R13X8FFQF279K9	0866226346	568178213	Giant Lizards	Books	5	5	5	N	N	Excellent	This book is an excellent overview of the &quot;giant&quot; lizards and touches on their biology and husbandry. It is packed full of beautiful photographs, and all the main families are covered: the Varanidae, Helodermatidae, Teiidae, Agamidae, Scincidae, and Iguanidae.  I am always amazed by the variability in skin patterns exhibited by lizards, espeically in the Varanus tristis orientalis.  You can feel the author's fascination with these marvels of the animal kingdom and he also gives a brief discussion on their vetinary care. I would have hoped he would have had more to say on the &quot;black spot&quot; problem in green iguanas  but does not mention it.<br />  Lizard lovers and all those interested in the keeping them as pets will enjoy the book, as well as those who intend to make herpetology their chosen profession.	2001-07-26
1904914:US	50702879	R14SEE320RWA4X	0817638652	179202784	The Heat Kernel Lefschetz Fixed Point Formula for the Spin-c Dirac Operator (Progress in Nonlinear Differential Equations and Their Applications)	Books	3	0	0	N	N	Short but pretty good	This book, of great interest to both mathematicians and physicists, is a good overview of the analysis and topology of the spin-c Dirac operator and how it is connected with the Lefschetz fixed point formula. Readers familiar with algebraic topology will see the similarities between the case discussed in this book and the one there where the formula involves computing the alternating sum of cohomology groups of a mapping acting on a compact manifold. If the number computed by this sum is non-zero, the mapping has a fixed point.<br /> After a brief overview of what is ahead in the book the author introduces the formalism behind the Dolbeault-Dirac operator. The object of interest is the Dolbeault complex and the existence of Hermitian structures on the tangent bundle and in fibers of holomorphic vector bundles over a given complex analytic manifold. The Dolbeault-Dirac operator is elliptic and has finite-dimensional kernel if the manifold is compact. The goal is to get explicit formulas for the Riemann-Roch number and its generalization, the holomorphic Lefschetz number. When the manifold is not Kahler, the author shows that it is more straightforward to calculate these numbers using the spin-c Dirac operator. This is because the Levi-Civita connection on the tangent bundle does not leave the almost complex structure invariant. The difference of the diagonal heat kernels converges as time approaches 0 from above, and the limit can be calculated. The price one pays for using the spin-c Dirac operator is that its kernel does not have holomorphic sections, and its square only preserves the degrees of the differential forms modulo two.<br /> The main goal of chapter 3 is to introduce the Clifford bundle, with its main properties sketched by the author. Then after a discussion of the spin and spin-c groups, the spin-c Dirac operator is defined in Chapter 6. The author proves that the spin-c Dirac operator is self-adjoint, and its principal symbol equal to the principal symbol of the Dolbeault-Dirac operator.<br /> The author then proves in chapter 6 that the square of the spin-c Dirac operator is equal to the Laplace operator with a zero order term involving curvature expressions. When a spin structure is present, it is also shown that the formulas for the square of the spin-c Dirac operator are equal. When the manifold is Kahler, the square satisfies the Bochner-Kodaira formula. This result can be used to prove the Kodaira vanishing theorem, and the author gives a reference for this.<br /> Taking the square of the spin-c Dirac operator gives the heat diffusion operator, and the author shows how to get the formula for the index using heat kernel methods in the next chapter, and discusses the heat kernel expansion in the chapter after that. These results should be very familiar to physicists working in quantum field theory.<br /> In chapter 9, it is assumed that the heat diffusion operator acts on sections of a vector bundle associated to a principal spin bundle. The &quot;zeroth-order&quot; term which is added to the Laplacian is characterized explicitly. The heat kernel expansion is give and then generalized in chapter 10 to the case where an automorphism acts on the manifold. The Hirzebruch-Riemann-Roch integrand, which is the constant term in the expansion, is calculated in chapter 11, and then generalized to the case where an automorphism is present in chapter 12, via the local Lefschetz fixed point formula.<br /> Finally, in chapter 13, the results are connected to the theory of characteristic classes, and then the (orbifold) spin-c Dirac operator and the corresponding heat kernel studied on orbifolds in chapter 14. The virtual character is computed via the heat kernel method and the Lefschetz formula is proven.<br /> The next chapter is the most interesting in the book and discusses how one can apply these results over a symplectic manifold. The symplectic form has to satisfy an integrality condition that allows it to be a Chern form of a connection of a complex line bundle over the manifold. The author briefly reviews the theory of symplectic geometry, including Hamiltonian group actions and reduction and discusses geometric quantization. If the de Rham cohomology class of the symplectic form is integral, then one can put an almost complex structure on the symplectic manifold, and using the action of a compact and connected Lie group, one can obtain the necessary structures for the definition of the spin-c Dirac operator. The author gives an explicit example using toric varieties. If the almost complex structure is integrable, then the symplectic manifold can be viewed as a projective complex algebraic variety, and studied via algebraic geometry.e a Chern form of a connection of a complex line bundle over the manifold. The author briefly reviews the theory of symplectic geometry, including Hamiltonian group actions and reduction and discusses geometric quantization. If the de Rham cohomology class of the symplectic form is integral, then one can put an almost complex structure on the symplectic manifold, and using the action of a compact and connected Lie group, one can obtain the necessary structures for the definition of the spin-c Dirac operator. The author gives an explicit example using toric varieties. If the almost complex structure is integrable, then the symplectic manifold can be viewed as a projective complex algebraic variety, and studied via algebraic geometry.	2001-07-25
1906162:US	50702879	R31QFNHR0XYL37	0671887637	391975377	Betty Crocker's New International Cookbook	Books	5	11	11	N	N	Buy a used copy!!	This cookbook is packed full of exotic but simple recipes and is a continuing source of culinary delight. The ingredients are readily available and the writing is very clear, with photographs for some of the dishes. Some of my favorite recipes are: - Sopa de Tortilla - Gazpacho (decrease the red wine vinegar to 1/4 cup) - Paella (open the clams and drain before cooking)  - Coulibiac (use fresh dill weed only!) - Vatapa  - Linguine con Vongole Bianco (al dente for linguine!!) - Chicken Curry  - Coucous with Chicken - Gai Ding (the cashews should be raw) - Moui Nagden (steam green peppers and add them when the rest of the dish has cooked) - Carne Rellena - Feijoada  - Cassoulet - Moussaka (use young eggplants) - Spanokopita - Irish Soda Bread	2001-07-24
1908437:US	50702879	RH8YMFWWNR4K6	157718064X	191518556	Options	Books	4	7	7	N	N	Excellent book for the newcomer to options pricing/analysis	This book is a good general overview of options pricing for those who do not have a strong mathematical background. It emphasizes the practical aspects of the subject and the author endeavors to be as concrete as possible. There is accompanying software with the book, but since I have written my own software for options pricing I did not use it and cannot attest to its utility or reliability.<br /> The first chapter defines the call and put option, and gives a short history of the options markets. The author discusses taxation of option transactions briefly, which is not usually found in books on options.<br /> In chapter 2, the author discusses options payoffs from using various options strategies. The important principle of arbitrage is discussed, and the assumption of no transaction costs is made throughout the chapter.  The author gives a good example of how small differences in price can persist in actual markets, thus showing how transaction costs can effect option pricing. Option combinations, such as straddles, strangles, bull, bear, box, butterfly, spreads, and condors. All of these are summarized nicely in table form. The important area of portfolio insurance is treated with brief discussions on mimicking portfolios and synthetic instruments. Helpful references are given that study the cost of portfolio insurance.<br /> In chapter 3, the author considers the factors that contribute to the pricing of an option using the principle of arbitrage. Complete financial markets are assumed, and the goal is to find how these assumptions can be used to put bounds on option prices. The chapter could be viewed as an elementary exercise in the mathematical formalism of optimization with constraints, but the arguments are mostly qualitative. The effect of interest rates on option prices is also considered in this chapter. Here, the principle of arbitrage is employed to show the price of a put must fall as interest rates rise, while call option prices increase with higher interest rates. Also, the author begins an attempt to show how stock prices influence option prices, and he shows that the riskier the underlying stock, the greater the value of an option.<br /> Then in chapter 4, the author takes up issues of a more mathematical nature, wherein he uses the single-period and multi-period binomial models to price European options. These are used to derive the famous Black-Scholes option pricing model. The author's approach is very practical as he discusses various methods of using historical data to estimate the stock's standard deviation. He cites the Crash of 1987 as an example of why one should use current data to estimate the volatility. This motivates the development of other techniques, such as implied volatility, for estimating the standard deviation.<br /> The 'Greeks', called option sensitivity measures by the author, are discussed in chapter 5. He does use partial differential calculus, but motivates it well, so readers without the mathematical preparation can follow the presentation. It is shown how to combine options with the underlying stock or into portfolios, one can construct positions with the desired risk exposure.<br /> The more difficult job of pricing American options is dealt with in chapter 6, the Black pseudo-American call option pricing model being treated first. The binomial model is applied to American options with various kinds of dividends.<br /> In chapter 7, the author considers options on stock indices, foreign currency, and futures. The Merton model leads off the discussion, and both European and American options are treated in the chapter.<br /> Then in chapter 8, the techniques developed in the book are applied to corporate securities. It is an interesting discussion, and the author gives straightforward examples to illustrate various corporate financing strategies. It should prepare the reader for more advanced reading on the subject.<br /> The last chapter is the most interesting of all as it deals with exotic options. The author considers nine types of exotic options, namely forward-start, compound, chooser, barrier, binary, loopback, average price, exchange, and rainbow options, all of these studied as European options. Closed-form solutions for these types of options are given and numerical examples are given. Several helpful references are given at the end of the chapter. The author gives an interesting real-world example of the use of chooser options, namely the case of hedging with a chooser option on the Mexican peso before the NAFTA agreement in 1993.ls with exotic options. The author considers nine types of exotic options, namely forward-start, compound, chooser, barrier, binary, loopback, average price, exchange, and rainbow options, all of these studied as European options. Closed-form solutions for these types of options are given and numerical examples are given. Several helpful references are given at the end of the chapter. The author gives an interesting real-world example of the use of chooser options, namely the case of hedging with a chooser option on the Mexican peso before the NAFTA agreement in 1993.	2001-07-23
1910324:US	50702879	RW2K90LJX1RB1	0387915621	364317748	Instant Notes in Genetics	Books	4	1	1	N	Y	Good summary and very helpful	This book is a good summary of genetics but one will need to read another book in conjunction with this one. It is great for quick reference and will suit students well as a study aid, as the authors give a set of key notes at the beginning of each chapter. The authors avoid any discussion of highly advanced topics, but instead emphasize the raw basics. However, they don't leave out some of the more exciting topics, such as population genetics, cloning, gene therapies, and the human genome project. The order of presentation is logical, with the properties of DNA beginning the book, with Mendel's laws explained based on the genetic code. In addition, this reductionist approach to explaining the biology of organisms is one that is most compatible with the requirements of sequence analysis and algorithms in computational biology. As such, this is a good set of notes for mathematicians who are moving into the area of sequence analysis and need a background in genetics.	2001-07-21
1910377:US	50702879	R1RH3PX2AI73M9	0521633044	672185611	2: String Theory (Cambridge Monographs on Mathematical Physics) (Volume 2)	Books	3	12	21	N	N	Fair exposition	In the second volume of the series the author generalizes the results of the first to string theories where supersymmetry is present. The mathematics introduced is non-rigorous, and the strategy is to see how much of the formalism for the bosonic case can be carried over to the case where fermions are present. The book is purely an exposition on the subject of string theory, and so no attempt is made to give the reader an in-depth explanation of the ideas and concepts in this area. This is particularly noticeable in the chapter on Calabi-Yau compactification and in the discussion on mirror symmetry in the last chapter.  Here is a brief outline of the contents of the book:<br />- Generalize the mass-shell condition (Klein-Gordon equation in momentum space) by using the Dirac equation.<br />- The gamma matrices will serve as CM modes of an anticommuting world sheet field.<br />- The resulting world-sheet supercurrents generate the superconformal transformations of the superconformal algebra.<br />- Counting the number of (3/2, 0) currents classifies the different superconformal field theories.<br />- Standard quantization techniques for constrained systems are applied.<br />- Free SCFTs can be obtained with the vanishing of the central charge giving 10 as the critical dimension.<br />- SCFT on a circle gives two periodicity conditions for the matter fermions (Ramond and Neveu-Schwarz sectors).<br />- Ramond and Neveu-Schwarz algberas result. -  Holomorphicity constraints give bosonization via the relation between the R sector vertex operators and bosonic winding state vertex operators.<br />- In 10 flat dimensions, 16 sectors result from the R and NS sectors, 6 of which are empty.<br />- Consistency conditions yield type IIA and IIB superstring theories.<br />- The vacuum amplitude for a closed superstring can be found by imposing modular invariance.<br />- Divergences cancell in the cylinder, Mobius strip, and Klein bottle graphs.<br />- Generalize preceding constructions by looking for sets of holomorphic and antiholomorphic currents whose Laurent coefficients form a closed algebra.<br />- Consider algebras that are different on the left- and right-moving sides of the closed string, obtaining the heterotic string.<br />- Setting the dimensions to be the same at each side and 32 left-moving spin-1/2 fields gives the SO(32) string.<br />- Split these fields into sets of 16 with independent boundary conditions to get the E8 X E8 heterotic string.<br />- Use supersymmetry constraints to study interactions of massless degrees of freedom.<br />- Tree-level interactions can be studied within low-energy supergravity; one-loop gives rise to anomalies.<br />- Anomalies cancell in type IIA, IIB, type I, and heterotic string theories.<br />- Use string perturbation theory to calculate amplitudes and interactions.<br />- Introduce supersymmetry in toroidally compactified string theory, to obtain D-branes which are BPS states and carry R-R charges.<br />- Type I, IIA, IIB string theories become states in a single theory.<br />- Study strongly coupled strings using D-brane states.<br />- The five string theories are limits of a single theory in 11-dimensional spacetime.<br />- Study conformal field theories as a prolegomena to analyzing string compactification.<br />- Study string compactification via free world-sheet conformal field theories or interacting exactly solvable conformal field theories.<br />- Connect the compactified string theory to the Standard Model.<br />- Start with orbifolds and then the more general Calabi-Yau manifolds.<br />- Techniques from algebraic geometry are brought in to study the properties of Calabi-Yau manifolds.<br />- Deduce an effective (low-energy) four-dimensional action using the topology of Calabi-Yau manifolds.<br />- Elaborate on the physics of four-dimensional string theory.<br />- Try to deal with the strong CP problem using Peccei-Quinn symmetry and the resulting axion field.<br />- Try to understand how gauge symmetries arise in the different string theories and how they are related to the ones in the Standard Model.<br />- Try to connect the different mass scales in string theory.<br />- Study more advanced topics in string theory, such as N = 2 superconformal algebras, type II superstrings on Calabi-Yau manifolds, string theories on the 4-dimensional Calabi-Yau manifold K3, minimal models, and mirror symmetry.<br />- Mirror manifolds can be constructed explicitly using Gepner models.<br />- Use mirror symmetry to obtain the full low energy field theory at the string tree level.<br />- Flop transitions can occur in string theory, giving dynamical changes in topology./>- Try to understand how gauge symmetries arise in the different string theories and how they are related to the ones in the Standard Model. <br />- Try to connect the different mass scales in string theory.<br />- Study more advanced topics in string theory, such as N = 2 superconformal algebras, type II superstrings on Calabi-Yau manifolds, string theories on the 4-dimensional Calabi-Yau manifold K3, minimal models, and mirror symmetry. <br />- Mirror manifolds can be constructed explicitly using Gepner models.<br />- Use mirror symmetry to obtain the full low energy field theory at the string tree level. <br />- Flop transitions can occur in string theory, giving dynamical changes in topology.	2001-07-21
1910406:US	50702879	R2AOCJ4LWSWSNT	1882114809	678903161	GNU Make, Version 3.77	Books	4	12	13	N	N	Good reference	This book, which was made available on the Web for free, is here published in book form for those who prefer it that way. It is a great introduction to GNU Make for beginners who need to learn it, and a good reference for those more experienced.<br /> After a brief overview of make in chapter 1, the authors move on to introduce makefiles in chapter 2 and 3. A general makefile consists of rules, with a target, dependencies, and commands. The authors do a great job of explaining makefiles and give a sample makefile explaining how an executable depends on object files, those depending themselves on C source files and header files. The use of  'make clean' is discussed also, along with the use of variables to simplify makefiles.<br /> A more detailed discussion of rule writing is given in chapter 4, with the rule syntax outlined, and how to use wildcard characters in file names. The 'vpath' directive is discussed also. The authors show how to construct rules with multiple targets, and how to use dependencies that are not necessarily identical using static pattern rules. The chapter ends with a discussion of how to generate dependencies automatically.<br /> The use of command echoing is explained in the next chapter on writing commands in rules, with the recursive use of 'make' as itself a command in a makefile. This is followed in chapter 6 by more details on the use of variables in makefiles. Readers knowing the shell very well will find this easy reading, but beginners will have to pay attention to the subtle uses of variable references and the difference between recursively expanded and simply expanded variables. The authors include an advanced section on variable reference for the more experienced reader. A detailed discussion on using conditional statements in makefiles is given.<br /> The use of functions to do text processing is the subject of chapter 8 with the general syntax for function calls given. This is followed in chapter 9 by a discussion on how to actually execute a makefile.<br /> The use of implicit rules to perform compilation in the usual way is discussed in chapter 10. This is my preference on how to use make and it is given a nice treatment here, with discussions on how to use implicit rules and introduces pattern rules.<br /> Make can also update archive files, and this is discussed in chapter 11. The last chapters of the book give a list of features of GNU make as compared with other versions of make, and a list of incompatibilities of make with other versions. The conventions that must be respected in writing GNU make programs are discussed also.ctually execute a makefile. <br /> The use of implicit rules to perform compilation in the usual way is discussed in chapter 10. This is my preference on how to use make and it is given a nice treatment here, with discussions on how to use implicit rules and introduces pattern rules. <br /> Make can also update archive files, and this is discussed in chapter 11. The last chapters of the book give a list of features of GNU make as compared with other versions of make, and a list of incompatibilities of make with other versions. The conventions that must be respected in writing GNU make programs are discussed also.	2001-07-21
1912798:US	50702879	RM8JL2RXRNLIL	067248448X	478115091	UNIX Shell Programming, Revised Edition	Books	3	30	35	N	N	Somewhat dated....	Although published in 1990, this book could still function well as an introduction to UNIX and (Bourne) shell programming, provided one is aware of some changes to the shell in most implementations of UNIX since that date. Also, the Perl language has come on strong in recent years, and depending on your tastes (and time), that language can be used with great efficiency to do the tasks that are traditionally done in the shell.<br /> After a quick review of the basics of UNIX, the authors give a purely descriptive explanation of the UNIX shell in chapter 3. Emphasizing that it is an interpretive language, the most commonly used shell commands are discussed in chapter 4, starting with a discussion of regular expressions. The cut, paste, sed, tr, grep, uniq, and sort commands are treated in detail.<br /> In chapter 5, one begins the actual task of creating shell programs using shell variables. There is no data typing in the shell, so values can be assigned to variables without noting their type as integer, float, etc. The authors only briefly discuss the  mechanism in shell programming. The method by which the shell interprets quotation characters is covered in the next chapter. The single, double, backslash, and back quote characters are discussed in detail. Noting that arithmetic operations are done on values stored in variables in the shell, the authors show to proceed with these operations using the expr program.<br /> The mechanisms for passing arguments to shell programs is treated in chapter 7, the authors showing how to write shell programs that take arguments typed on the command line. The role of positional variables for delaying assignment after normal command line processing is discussed. The $#, and $* variables are discussed briefly, with $# getting set to the number of arguments typed on the command line and $* used for programs taking a variable number of arguments. The shift command is explained well as a method to allow one to use more than nine arguments to a program.<br /> The ability of shell programs to execute decision blocks is treated in chapter 8, via the if statement. The role of the test and exit commands are in if blocks are discussed in good detail. In addition, the case command, familiar to C programmers is introduced as a technique to allow a single value to be compared against other values. The &amp;&amp; and || constructs are used to show the reader how to execute commands that are contingent on the success or failure of the preceding command.<br /> Program loops, via the for, while, and until commands are discussed in chapter 9, followed in the next chapter by a discussion of how to read data from the terminal or from a file using the read command. The ability to perform I/O redirection is discussed also.<br /> Local and export variables are discussed in the next chapter on the user environment, and the authors give a good summary of how these work in shell programming. More discussion on parameter passing is done in chapter 12, with the different methods of parameter substitution given detailed treatment. The authors show how to use the $0 variable to check whether two or more programs have been executed, and how to use the set command to set shell options and to reassign positional parameters. This is followed in the next chapter by a discussion of the eval command, which makes the shell scan the command line twice before executing it, and the wait command, which will allow serialization in program execution. The trap and type commands are discussed also.<br /> The Korn shell is discussed in chapter 15, with emphasis on the features added to Korn shell that cannot be found in the Bourne shell. The vi and emacs capability of this shell is briefly discussed in this chapter. The differences between Korn shell functions and Bourne shell functions are discussed in detail by the authors. Most importantly, the ability of the Korn shell to do integer arithmetic without using the expr command is discussed via the let command, which is built-in to the Korn shell. Also, the capability of the Korn shell to support data typing is discussed, along with its pattern matching capabilities. Pattern matching is done most efficiently now using Perl however.discussed via the let command, which is built-in to the Korn shell. Also, the capability of the Korn shell to support data typing is discussed, along with its pattern matching capabilities. Pattern matching is done most efficiently now using Perl however.	2001-07-19
1914348:US	50702879	R12QP1JNIS0PBZ	0300036299	557817767	Kant's Transcendental Idealism: An Interpretation and Defense	Books	5	60	61	N	N	A revisionist reading of Kant	The author gives a sensitive, detailed, and very understandable overview of Kant's construction of transcendental idealism. He clearly is supportive of Kant's ideas, but he does approach them also with a critical analysis. Readers who disagree with Kant are encouraged to read this book, as it offers a fresh perspective on his ideas. Kant's philosophy has pervaded many fields, such as psychology, physics, logic, and ethics, and therefore an understanding of these fields and modern philosophy will need as prerequisite a study of Kant.<br />  Allison attempts to set straight the &quot;standard picture&quot; of Kant, which he argues does not fairly represent the Kantian view. The philosophers P.F. Strawson and H.A. Prichard are to be held mostly responsible for this mistaken picture argues the author. Allison's position is that the standard picture fails to distinguish between &quot;ideality&quot; and &quot;reality&quot; and between appearances and things in themselves. He attempts to defend Kant's thinking in terms of these distinctions. A reader really interested in an in-depth analysis of his arguments will need to have a thorough knowledge of the German language.<br /> Allison argues that there is a definite distinction between an empirical and transcendental sense of 'ideality' and 'reality'. Empirically, 'ideality' characterizes the private data of an individual mind, but at the transcendental level, it characterizes the universal, necessary, and a priori conditions of human knowledge. This is an interesting reading of Kant, for it refutes the main objection to his philosophy, namely that the structure of the mind precludes any real knowledge of things. A transcendentally real object is then a nonsensible object (noumenon). The (actual) existence of these objects need not be postulated at all when reading Kant. Calling an object 'ideal' is not making a statement about its existence; empirical objects are ideal only because they cannot be described independently of the &quot;forms of sensibility&quot;. Again, one can see in this reading of Kant a definite refutation of skepticism, for at the empirical level, the appearances are mental and the things in themselves are physical; at the transcendental level, appearance means relative to the subjective conditions, while things in themselves are independent of these conditions. The conditions do not determine how things appear in the empirical realm, they give universal and necessary conditions for the capability of the mind to recognize an object. One can argue here that it is these very conditions that set the foundation for genuine knowledge of objects; or an even more minimal view that they serve as precursors to genuine knowledge.<br /> To elaborate on Kant in a more organized and rigorous manner, Allison introduces the concept of an &quot;epistemic condition&quot;. These are conditions that establish the pure concepts of the understanding and also the forms of human sensibility. They are different form psychological conditions, which are unique to the human cognitive apparatus, and from ontological conditions, which are conditions of the being of things. According to the author Kant refutes Hume by showing that Hume confuses psychological and epistemic conditions, and also refutes Newton by showing that Newton confused epistemic with ontological conditions.<br /> The author also clears up the misreading of Kant that characterizes appearances as &quot;mere representations&quot;. Kant's claim is not, according to Allison, that objects have no independent existence but rather that such existence cannot be attributed to them in the manner in which they are represented. It is here though that Allison slips a little and weakens his case against Kantian skepticism when he summarizes the Kantian position as stating that whatever is necessary for the representation of something as an object must reflect the cognitive structure of the mind rather than the nature of the object as it isin itself. He seems to be saying that the very structure of the human mind, and its required use in the attempts to gain knowledge, precludes such knowledge.<br /> The author also clears up the Kantian position versus phenomenalism. Whatever is actual must be an object of possible perception, but this is a consequence of actuality and not a cognition. Whatever can be connected with a given perception in accordance with the &quot;analogies of experience&quot; is to be deemed actual. This move by Kant removes the element of subjectivity in claims on actuality, distancing himself from Berkeley's purely psychological account of perception, defining the possibility of perception in terms of conformity to a priori principles.  In addition, the Kantian position on conceptual knowledge is clarified by Allison. Kant contrasts the human capacity for conceptual knowledge versus the notion of an intuitive intellect, the later which is purely creative and requires no cognitive effort. Further, and central to the human capability for abstraction, is the Kantian notion that a concept is an organizing principle for consciousness. Sensible intuition provides the mind with only the raw data for conceptualization, not with the determinate knowledge of objects.in itself. He seems to be saying that the very structure of the human mind, and its required use in the attempts to gain knowledge, precludes such knowledge.<br /> The author also clears up the Kantian position versus phenomenalism. Whatever is actual must be an object of possible perception, but this is a consequence of actuality and not a cognition. Whatever can be connected with a given perception in accordance with the &quot;analogies of experience&quot; is to be deemed actual. This move by Kant removes the element of subjectivity in claims on actuality, distancing himself from Berkeley's purely psychological account of perception, defining the possibility of perception in terms of conformity to a priori principles.  In addition, the Kantian position on conceptual knowledge is clarified by Allison. Kant contrasts the human capacity for conceptual knowledge versus the notion of an intuitive intellect, the later which is purely creative and requires no cognitive effort. Further, and central to the human capability for abstraction, is the Kantian notion that a concept is an organizing principle for consciousness. Sensible intuition provides the mind with only the raw data for conceptualization, not with the determinate knowledge of objects.	2001-07-18
1914854:US	50702879	RW0YCQZ44LG2U	1578700094	977119716	The Handbook of Programming Languages (HPL): Imperative Programming Languages	Books	3	3	3	N	N	Fair	This book is the second of the series on programming languages and gives an overview of some representative languages that follow the imperative programming paradigm. Specifically, the languages Fortran, C, Pascal, and Icon are discussed in the book, with the largest coverage given to C. There is also a very short part of the book devoted to &quot;intermediate languages&quot;, which are essentially used as intermediaries between high- and low-level languages.<br />  The book starts with a discussion of Fortran, and gives a short history of it development. The chapter emphasizes Fortran 95, and the comparisons between it and Fortran 90. Fortran 95 is presented as having an object-oriented flavor, due to its ability to provide derived data types, procedure overloading, and operator definition. It however cannot support operator inheritance. The author of the article lists the Fortran 90 features that were omitted in Fortran 95, and discusses portability issues. The features to be incorporated in Fortran 2000 and the high performance extension, called High Performance Fortran, are discussed, the later emphasizing ease in parallelization of code. A fairly comprehensive summary of the features and syntax of Fortran 95 is given. The author goes over in detail an interesting example of constructing a new data type in Fortran, namely a type definition for big integers.<br />In part 2 of the book the history of the C language is discussed, and is written by D. M. Ritchie, one of the developers of the language. It is interesting reading for those curious about how C originated and the developed. This is followed by a rather lengthy overview of the language itself, almost 150 pages long. The author gives good advice on how to deal with the potential complexity of C expressions, namely to think of them recursively. His discussion of how to do this, by first using what he calls primary expressions, is the first I have seen in an introductory exposition on C. Since C does support them, &quot;goto&quot; statements are discussed, but thankfully the author admonishes against their use. A good discussion of function calling in C is given, via its &quot;pass by value&quot; function semantics. The author emphasizes that there is only one exception in C to the requirement that a function not alter the values of variables passed to it as arguments, namely the case of arrays, which are called by reference. For those doing programming for embedded systems, there is a fairly decent discussion of low-level addressing.<br />After a brief discussion of intermediate languages, the rest of the book covers Pascal and Icon. Except for some experience programming in SNOBOL, I do not know these languages and so I cannot comment on the quality of the presentation.rt them, &quot;goto&quot; statements are discussed, but thankfully the author admonishes against their use. A good discussion of function calling in C is given, via its &quot;pass by value&quot; function semantics. The author emphasizes that there is only one exception in C to the requirement that a function not alter the values of variables passed to it as arguments, namely the case of arrays, which are called by reference. For those doing programming for embedded systems, there is a fairly decent discussion of low-level addressing. <br />After a brief discussion of intermediate languages, the rest of the book covers Pascal and Icon. Except for some experience programming in SNOBOL, I do not know these languages and so I cannot comment on the quality of the presentation.	2001-07-18
1915905:US	50702879	RIJCW4KUA0VLS	3540660151	741654495	Foundations of Computational Linguistics: Human-Computer Communication in Natural Language	Books	4	19	21	N	Y	Organized and well-written	This book is an essentially non-mathematical descriptive overview of computational linguistics that emphasizes an historical viewpoint. It is very understandable, even for someone approaching the subject for the first time. In addition, it could be used as a textbook as there are a large set of exercises at the end of each chapter. Computational linguistics has been applied to biological sequence analysis, which was my primary reason for reading the book.<br /> The author begins with the concept of a language, which is defined as a set of word sequences with a formal language being a subset of the free monoid over a finite lexicon. The reasons for using generator grammars are discussed but these need to be replaced by a special type called categorial (C-) grammar, invented in the 1930's and applied to natural languages in the 1950's. The disadvantages of C-grammar are outlined by the author.<br /> A second generative grammar, called phase structure (PS) grammar is discussed, and restrictions on the rule schema give four different types of PS-grammars. These different types give four different classes of complexity, with this complexity measured by an algorithm with the number of primitive operations required to analyze an input expression counted in relation to length of the input. Context-free PS-grammar is applied to natural language via phrase structures. The author distinguishes carefully the differences between C- and PS-grammars. In particular, the goal of PS-grammar is to represent what is called the constituent structure of natural language, which is defined by the author as a formal property of phase structures. He makes it very clear that there is as of yet no complete PS-grammars for natural languages. He also discusses in detail the constituent structure paradox with examples of discontinuous elements in natural language. The solution of Chomsky to this problem via transformation rules is outlined. This transformational grammar is equivalent to a Turing machine generating recursively enumerable languages and so is undecidable. To resolve this, Chomsky introduced formal restrictions on the transformations called &quot;recoverability of deletions&quot;. The author shows however via Bach-Peters sentences, that this method does not always work. The discussion of parsing distinguishes between morphology parsers, syntax parsers, and semantic parsers. This exemplifies how the declarative-procedural distinction applies to the relation between generative grammars and parsers. These distinctions are important, the author argues, when modeling natural languages on a computer.<br /> That natural languages are not context-free motivates the author to search for other formalisms. A successful formalism must be computationally tractable, and this is reflected in its grammar type. The &quot;type transparency&quot; between the parser and the grammar enables the analysis of the complexity to be done at the parser, since for any language, they will have the same formal grammar. The weaknesses of this approach for PS-grammar is discussed in detail by the author, and he gives other algorithms that restructure the PS-grammar rules in order to obtain parsing of context-free languages. These concerns also exist when the requirement that the grammar formalism &quot;input-output&quot; be equivalent to what is spoken and heard. PS-grammar is shown to be incompatible with this.<br /> The more recent notion of left-associative (LA) grammar is discussed as an alternative to C-and PS-grammars. The irregular bracketing of these grammars is handled by using the principle of possible continuations in LA-grammars. The author shows, interestingly, that the distinction between context-free and context-sensitive languages disappears in LA-grammar. The principle of possible continuations allows close relation between parsing and generation. Discontinuous elements are dealt with by coding filler positions into a functor category and then cancelled later.<br /> There are different types of LA-grammars which are characterized in terms of their generative capacity and computational complexity. Recursion theory plays a role, and the complexity is measured in terms of the operations required to process an input in the worst case. The author discusses in detail the different types of LA grammars and their subhierarchies, and compares the LA-and PS-hierarchies.<br /> The morphological analysis of natural language can be studied in terms of combination principles, with words being defined in terms of word forms, and a clear distinction is made between the two notions. Word forms in turn are composed of elementary parts called morphemes, and morphemes are associated analyzed allomorphs. The author explains the steps needed to morphologically analyze an unknown word.<br /> Even more interesting, and more important from a practical point of view, the author discusses methods for automatic word form recognition, including methodologies for investigating the frequency distribution of words. The grammar system of LA-morphology is used for word form recognition of English, German, Italian, French, Japanese, and Polish. The empirical testing of a grammar system via the building of a corpora is discussed with an illustration of Zipf's law. Unfortunately, the author does not discuss in detail the use of hidden Markov models in statistical tagging.<br /> Syntax deals with the composition of word forms and uses the combination rules of valency, agreement, and word order. German and English are analyzed in terms of their word order. The ability of LA-grammar to map variable-based rule patterns onto categorially analyzed input expressions using a strictly time-linear order makes it efficient and flexible, argues the author. The LA-syntax for English and German is discussed in detail by the author. The discussion makes heavy use of finite state machines.<br /> There are three different semantic systems, namely the logical, programming, and natural languages, and the author shows how these are related via replication, reconstruction, transfer, and composition. The problems in viewing natural languages as logical semantics is discussed in the context of Tarski's work. The author argues that the insistence of using logical semantics for analyzing natural language is incorrect since natural languages work differently from metalanguage-dependent logical languages.  Truth, meaning, and ontology are taken out of the philosophical realm and applied to the logical semantics of natural language.ter. <br /> There are different types of LA-grammars which are characterized in terms of their generative capacity and computational complexity. Recursion theory plays a role, and the complexity is measured in terms of the operations required to process an input in the worst case. The author discusses in detail the different types of LA grammars and their subhierarchies, and compares the LA-and PS-hierarchies. <br /> The morphological analysis of natural language can be studied in terms of combination principles, with words being defined in terms of word forms, and a clear distinction is made between the two notions. Word forms in turn are composed of elementary parts called morphemes, and morphemes are associated analyzed allomorphs. The author explains the steps needed to morphologically analyze an unknown word. <br /> Even more interesting, and more important from a practical point of view, the author discusses methods for automatic word form recognition, including methodologies for investigating the frequency distribution of words. The grammar system of LA-morphology is used for word form recognition of English, German, Italian, French, Japanese, and Polish. The empirical testing of a grammar system via the building of a corpora is discussed with an illustration of Zipf's law. Unfortunately, the author does not discuss in detail the use of hidden Markov models in statistical tagging. <br /> Syntax deals with the composition of word forms and uses the combination rules of valency, agreement, and word order. German and English are analyzed in terms of their word order. The ability of LA-grammar to map variable-based rule patterns onto categorially analyzed input expressions using a strictly time-linear order makes it efficient and flexible, argues the author. The LA-syntax for English and German is discussed in detail by the author. The discussion makes heavy use of finite state machines. <br /> There are three different semantic systems, namely the logical, programming, and natural languages, and the author shows how these are related via replication, reconstruction, transfer, and composition. The problems in viewing natural languages as logical semantics is discussed in the context of Tarski's work. The author argues that the insistence of using logical semantics for analyzing natural language is incorrect since natural languages work differently from metalanguage-dependent logical languages.  Truth, meaning, and ontology are taken out of the philosophical realm and applied to the logical semantics of natural language.	2001-07-17
1916456:US	50702879	R2CCAQM3Y1WI0E	1571691618	489397066	The Waite Group's C Primer Plus	Books	4	22	22	N	N	Good for the beginner to C programming	This book gives a fairly comprehensive overview of the most popular programming language ever employed. The C language still dominates the programming scene, even though at times it appears to be dying out. Compilers, embedded systems, scientific programming, and myriads of other applications use C extensively.<br /> After a brief historical background and a discussion on how to compile programs in C, the author discusses the basic data types and character strings in C. The author emphasizes the lean nature of the C language, and gives an elementary discussion on debugging in C. A good discussion is given on integer and floating-point underflow and overflow and also the mechanics of argument passing via the stack.<br /> The author then discusses the operators and control statements in C. He includes a discussion of Lvalues and Rvalues, and this is helpful since many books on C gloss over this. Good examples of the ability of C to do multiple assignment are given. Side effects, which are modifications of data objects, and sequence points, which are points in program execution at which side effects are evaluated before proceeding to the next step in the program, are briefly discussed. An understanding of side effects is crucial to programming effectively in C. Type conversion, forbidden in some other languages, can be done in C, and the author gives a fairly good discussion of type conversion and the cast operator. Nine examples are given that effectively illustrate the different uses of  &quot;for&quot; loops. Unfortunately, the author includes a discussion of the &quot;goto&quot; statement, but does admonish against its use.<br /><br />  The author then moves into more about input and output and how to use buffered versus unbuffered input. Some of the discussion on how to create user interfaces is antiquated given the current state of graphical tools to do this.<br />  C functions are defined and their use encouraged as building blocks. A program ideally should be written as a collection of function calls, and the author is sympathetic with this approach. The importance of function prototyping is discussed, along with a detailed discussion of recursion. The &amp;operator is covered in the context of function calls the modify a value in the calling function without using a return value. This peculiarity of C is a sticking point to mathematicians when they attempt to program in C. The author explains fairly effectively the reasons for doing this in C, giving examples of what can happen when one adheres to a practice of never producing side effects in function calls.<br />  The most difficult feature of C for newcomers is the existence of pointer variables. These are first discussed in the context of function calls and then in terms of the creation and initialization of arrays. Pointer arithmetic, an anathema to some programmers is given a fine treatment, along with how pointers are used to manipulate character strings and string functions.<br />The file communication capability of C is given a lengthy treatment in the book via standard I/O functions. The ability of C to support both global and local variables is discussed, with the important concepts of file, block, and function prototype given detailed treatment. The volatile, const, and restrict keywords are discussed also.<br />  Data structures, the tour de force of C programming, is discussed in great detail by the author. He shows how to create nested structures, and most importantly how to define and use pointers to structures. This is one of the most powerful features of C, and is responsible for its continued use in performance-intensive applications.<br />  Readers interested in the more &quot;low-level&quot; features of C will appreciate the discussion on bit fiddling. Indeed in embedded systems and cryptography an understanding of this is crucial for designing effective programs.<br />  The important technique of conditional compilation, using the ifdef, else, endif,and ifndef directives are discussed with many helpful examples. Memory allocation, with malloc(), free(), and calloc() functions is given ample treatment. Anyone who has done any type of debugging of C applications will realize the importance of a complete understanding of this topic. Memory leaks and dangling pointers can cause great distress in applications written in C. The author should have spent more time here on dynamic memory allocation in C.<br />  Some discussion is given on the more advanced data structures in C, such as linked lists, abstract data types, and binary trees.sing the ifdef, else, endif, and ifndef directives are discussed with many helpful examples. Memory allocation, with malloc(), free(), and calloc() functions is given ample treatment. Anyone who has done any type of debugging of C applications will realize the importance of a complete understanding of this topic. Memory leaks and dangling pointers can cause great distress in applications written in C. The author should have spent more time here on dynamic memory allocation in C. <br />   Some discussion is given on the more advanced data structures in C, such as linked lists, abstract data types, and binary trees.	2001-07-17
1918459:US	50702879	R13KWQ4D287YD7	0671021273	926743636	The Eugenics Wars Vol I:  The Rise and Fall of Khan Noonien Singh (Star Trek)	Books	4	18	23	N	N	Pure fun	This book starts where the series episode &quot;Space Seed&quot; and movie &quot;The Wrath of Khan&quot; only briefly referenced, namely the origins of the figure Khan Noonien Singh and the historical context in which he rose to power. The book is fun to read, and the author brings in some characters from the series and movies, and also real characters from history. Tainting a Star Trek episode, movie, or novel with real history can cause problems with accuracy issues, but the author does it only sparingly and so the story is believable.<br /> The presence of Gary Seven in the story was a surprising move, and one which I found a little troubling. One would like to believe the future was brought about solely by human action, with no assistance from extra-terrestrial agents who take it upon themselves to guide humanity to the &quot;correct&quot; destination. Much time is spent in the book on how Seven and his delightful female assistant are working to prevent a certain high-tech eugenics project from carrying out its plans.<br /> As with most Star Trek stories, this one has a strange admixture of optimism and cynicism. And, despite the enormous statistical evidence to the contrary, the Star Trek view of history paints the human being as a brutal, inconsiderate savage, who only occasionally exhibits compassion and reason. Indeed, this is exemplified by the character Seven, who has no confidence in the efficacy of the human mind to be able to resolve social, economic, and political problems. In addition, the view of intelligence in the Star Trek series is quite narrow. The reader is supposed to believe that Khan has superior intelligence, in spite of his zeal to use violence to achieve his ends. But the initiation of force by any individual is never a sign of intelligence, but rather of stupidity. The character of Spock, who is quoted in the book as saying that &quot;superior intelligence breeds superior ambition&quot;, to warn against the use of genetic engineering to create Khan-like monsters, is also another example of the restricted view of human intelligence in the Star Trek series. Emotions are thought of as having a disruptive, irrational effect on the human ability to reason effectively, instead of a set of natural processes that assist in the estimation and mental concentration of the human mind.<br />  The book also reflects some of the current anxiety about genetics as a science and its application in genetic engineering.  There is valid reasons for concern about the use of genetic engineering, but like all human problems, we can solve them by employing more science and technology, not less. Minds capable of creating a human clone can indeed find solutions to the concerns thus generated.<br /> The optimistic view of the future though is one that makes the Star Trek series such a pleasure to participate in. It uses the medium of art and fantasy very effectively, and allows one to take part in an era, not very far distant, that is populated by beings (human and otherwise) who hold as an axiom that reason and mutual respect are the keys to a successful life. The characters of Star Trek have their faults and personal conflicts, but with their optimisim and their sense of adventure, they are worthy of contemplation.o create Khan-like monsters, is also another example of the restricted view of human intelligence in the Star Trek series. Emotions are thought of as having a disruptive, irrational effect on the human ability to reason effectively, instead of a set of natural processes that assist in the estimation and mental concentration of the human mind. <br />  The book also reflects some of the current anxiety about genetics as a science and its application in genetic engineering.  There is valid reasons for concern about the use of genetic engineering, but like all human problems, we can solve them by employing more science and technology, not less. Minds capable of creating a human clone can indeed find solutions to the concerns thus generated. <br /> The optimistic view of the future though is one that makes the Star Trek series such a pleasure to participate in. It uses the medium of art and fantasy very effectively, and allows one to take part in an era, not very far distant, that is populated by beings (human and otherwise) who hold as an axiom that reason and mutual respect are the keys to a successful life. The characters of Star Trek have their faults and personal conflicts, but with their optimisim and their sense of adventure, they are worthy of contemplation.	2001-07-15
1920233:US	50702879	RF4ASIDUZC9WC	0132733501	51860099	Neural Networks: A Comprehensive Foundation (2nd Edition)	Books	5	64	68	N	N	Good detail with rigorous mathematics	This book, excellent for self-study and for use as a textbook, covers a subject that has had enormous impact in science and technology. One can say with confidence that neural networks will increase in importance in the decades ahead, especially in the field of artificial intelligence. The book is a comprehensive overview, and does take some time to read and digest, but it is worth the effort, as there are many applications of neural networks and the author is detailed in his discussion.<br />In the first part of the book, the author introduces neural networks and modeling brain functions. A good overview of the modeling of neural networks and knowledge representation is given, along with a discussion of how they are used in artificial intelligence. Ideas from computational learning are introduced, as well as the important concept of the Vapnik-Chervonenkis (VC) dimension. The VC dimension is defined in this book in terms of the maximum number of training examples that a machine can learn without errors. The author shows it to be a useful parameter, and allows one to avoid the difficult  problem of finding an exact formula for the growth function of a hypothesis space.<br />In the next part of the book, the author discusses learning machines that have a teacher. The single-layer perceptron is introduced and shown to have an error-correction learning algorithm that is convergent. There is a fine discussion of optimization techniques and Bayes classifiers in this part. The least-mean-square algorithm is generalized to the back-propagation algorithm in order to train multi-layer perceptrons along with a discussion on how to optimize its performance using heuristics. The author gives a detailed discussion of the limitations of back-propagation learning. In addition, the radial-basis function networks are introduced. Supervised learning is viewed as an ill-posed hypersurface reconstruction problem, which is then solved using regularization methods. Support vector machines are introduced as neural networks that arise from statistical learning theory considerations via the VC dimension. A summary is given of the differences between the different approaches in neural network learning machines. Committee machines, based on the divide and conquer algorithm, are also treated. Here the strategy is to divide the learning process into a number of experts, with the expectation that the collective efforts of these experts will more efficiently arrive at the solution.<br />The next part of the book introduces unsupervised learning machines. The ability of machines to discover useful information, such as patterns or features, in the input data is taken as an acid test for real intelligence. Hebbian learning via principal components analysis is discussed, along with competitive learning via self-organizing maps. The author uses computer simulations to illustrate the behavior of systems of neurons. Vector quantization is brought in as another supervised learning technique to fine tune the quality of the classifiers. Most interestingly, information-theoretic models are discussed with mutual information techniques used effectively as unsupervised learning algorithms. Some elementary but interesting examples of single neurons under the influence of noise are discussed in detail. The topic of Boltzmann machines is discussed also, and the physicists will find the treatment particularly fascinating, as it takes ideas from statistical mechanics and applies them to solve combinatorial optimization problems. Other more general statistical machines, such as Helmholtz machines, and mean-field theoretic approaches are discussed also. Reinforcement learning, using dynamic programming techniques is treated in detail.<br />The book ends with a treatment of nonlinear dynamical techniques to study the behavior of neural networks. The discussion makes use of many examples and computer experiments, and there are some good exercises at the end of the chapters for further analysis. Dynamical systems employing short-term memory and feedforward are discussed along with a treatment of stability in nonlinear dynamical systems. Feedback mechanisms are used to obtain input-output mapping. The definition of chaos is very weak, as it only employs the positivity of a Lyapunov exponent, but this is suitable for the purposes in the book.<br />The applications of neural networks are vast and space prevents here a comprehensive list. I have found them an excellent tool to study load balancing algorithms in distributed computing and networks, modeling of mobile communications, options pricing, and computational biology. There are also dozens of companies that specialize solely in neural network algorithms. No doubt as new learning algorithms are discovered and computers become faster, neural networks will play a major role in creating independent, autonomous, intelligent machines. This book will give the reader a solid understanding of how neural networks fit into the computational learning paradigm.r further analysis. Dynamical systems employing short-term memory and feedforward are discussed along with a treatment of stability in nonlinear dynamical systems. Feedback mechanisms are used to obtain input-output mapping. The definition of chaos is very weak, as it only employs the positivity of a Lyapunov exponent, but this is suitable for the purposes in the book. <br />The applications of neural networks are vast and space prevents here a comprehensive list. I have found them an excellent tool to study load balancing algorithms in distributed computing and networks, modeling of mobile communications, options pricing, and computational biology. There are also dozens of companies that specialize solely in neural network algorithms. No doubt as new learning algorithms are discovered and computers become faster, neural networks will play a major role in creating independent, autonomous, intelligent machines. This book will give the reader a solid understanding of how neural networks fit into the computational learning paradigm.	2001-07-13
1920775:US	50702879	R3C5GKORXBJC1A	0262061414	386841794	Game Theory (MIT Press)	Books	5	36	48	N	N	Comprehensive and very well written	The theory of games is now pervasive in the fields of economics, financial modeling, logistics, operations research, network engineering, and population biology. As such a background in game theory is an absolute necessity if one is to deal with problems in these areas. This book is an advanced treatment of game theory, and presupposes the reader already has had some exposure to the subject. There is an excellent set of exercises at the end of each chapter, and so the book can be used as a textbook or for self-study.<br />After an elementary example of a game in the introduction to motivate the subject, the authors begin in Part I of the book with the subject of static games with complete information. Strategic-form games are defined, along with dominated strategies, and the important concept of Nash equilibrium, the latter being introduced to deal with games that are not solvable by iterated strict dominance. For those with a background in elementary functional analysis, the authors prove that finite strategic-form game has a mixed-strategy equilibrium and prove that the Nash-Equilibrium has a closed graph. The concept of Nash equilibrium is extended to the concept of a correlated equilibrium, wherein each player can send another a private signal before they choose their strategy.<br />In Part II, the authors discuss dynamic games with complete information. Examples of these kinds of games include a sequential version of the battle of the sexes game, and a sequential version of matching pennies. The authors discuss subgame-perfect equilibria, wherein an n-tuple of strategies constitute Nash equilibria in every subgame. The Stackelberg model of duopoly is discussed along with the repeated Prisoner&quot;s dilemna, the latter being an example of backward induction in finitely repeated games. A kind of generalization of the principle of optimality in dynamic programming is used to analyze perfect public equilibria via a tool called self-generation.<br />In Part III of the book, the authors discuss static games of incomplete information. Examples are discussed including Bayesian games, where at least one player is uncertain about another player&quot;s payoff function, and first-price and second-price auctions. In first-price auctions, each player submits a sealed bid and the one with the highest bid obtains the item; in second-price auctions each player submits a sealed bid but the player submitting the highest bid gets to purchase the item for a cost given by the player with the second highest bid. The authors explain in detail the dominant strategies for these types of auctions. Bargaining with two-sided incomplete information is discussed and the optimal amount of trade is found from the linear equilibrium of the Chatterjee-Samuelson double action.<br />In Part IV, dynamic games of incomplete information are discussed by the authors. Examples that they discuss include signaling games such as the two-period reputation game, and Spence&quot;s education game. Signaling is widely used by firms and organizations in spite of it being somewhat costly to do so. For example a public company may be trying to convince investors that it represents high returns. The authors show how to obtain sequential perfect Bayes equilibrium in these and other scenarios. The authors also discuss reputation effects in games, with an example being the chain-store game. The general case of single long-run players with reputation effects is treated in detail. Bargaining with sequential buyers is also discussed with examples given for one-sided asymmetric information and mechanism design.<br />The last part of the book discussed miscellaneous topics in game theory, including strategic stability, more discussion on signaling, finite strategic-form games, and supermodular games. The treatment is more complicated mathematically with emphasis on proving existence theorems for Nash equilibria and pure-strategy equilibria. The notion of a Markov perfect equilibrium is employed to discuss situations where the past has a direct influence on current opportunities. This brings in the fascinating subject of stochastic games, wherein current payoffs depend on the state of the game and on current actions, with the state evolving according to a Markov process. These are generalized to continuous time, leading to the famous differential games. Game theory under &quot;common knowledge&quot; is also discussed, with examples given of the &quot;dirty face&quot; games.<br />Some omissions in the book, which would have of course increased the size of the book substantially, include mathematical modeling of poker and other card games. These are complicated games in which to analyze, but they have taken on considerable importance in the casino industry in recent years.ibrium is employed to discuss situations where the past has a direct influence on current opportunities. This brings in the fascinating subject of stochastic games, wherein current payoffs depend on the state of the game and on current actions, with the state evolving according to a Markov process. These are generalized to continuous time, leading to the famous differential games. Game theory under &quot;common knowledge&quot; is also discussed, with examples given of the &quot;dirty face&quot; games. <br />Some omissions in the book, which would have of course increased the size of the book substantially, include mathematical modeling of poker and other card games. These are complicated games in which to analyze, but they have taken on considerable importance in the casino industry in recent years.	2001-07-13
1922914:US	50702879	R2ZWTPJUQSP042	0670882178	132792490	The Age of Spiritual Machines: When Computers Exceed Human Intelligence	Books	5	4	5	N	Y	Sheer optimism at its very best...	That the future of thinking, self-aware machines is closer in the future than one realizes is the main point of this book, which is written primarily for the curious and the optimistic, but also those interested in developments in artificial intelligence from a commercial point of view. In the book, the author unashamedly embraces a future inhabited by beings whose intelligence is much greater than what humans now possess. But also, in his future humans are not left behind, but instead stand chin-to-chin with the robust, brilliant machines that have created. Not content with being mere passive spectators whose needs are being serviced by these silicon geniuses, they become hybrids of the organic and inorganic, a combination which makes the human mind even more efficacious and powerful.<br /> The author attempts to justify his predictions starting in the first part of the book. In chapter one, called &quot;The Law of Time and Chaos&quot;, the author attempts to show that time is changing its &quot;speed&quot;. The examples he gives are not really convincing from a scientific point of view, and he does not give any recommendations for any empirical tests of his assertions. And even though his arguments are plausible, one could deny them and still believe in the predictions he makes later in the book.<br /> His view of artificial intelligence is in terms of neural networks and genetic algorithms, with the former being around for some time now, and the later making its presence known rapidly. There is no doubt, and the author addresses this many times, that any type of machine intelligence will have to be able to mimic the creativity of the human mind and its ability to make unexpected connections with concepts that can appear at first glance to be completely unrelated. The author gives though convincing arguments as to the ability of even current computers to perform acts of creativity and automatic knowledge acquisition and discrimination, such as in the arts.<br /> The author discusses many strategies for building this new form of intelligence, including optical technology, nanotubes, and DNA computing. The later however will probably not be the way to go, as astronomical quantities are needed to perform some of the feats of calculation, such as the traveling salesman problem, which is mentioned by the author in the book as one that can be tackled using DNA computing.<br /> Quantum computing however is also mentioned in the book, and this approach holds much promise, and will be extremely powerful if realized. Current strategies in quantum computing are usually based on the experimentally unjustified notion of entanglement, but it looks hopeful that other ones will be developed that will bring out this quantum coup de etat in programming power.<br /> The social ramifications of the new age of intelligent machines is not ignored however in the book. He predicts, with ample justification I think, a growing &quot;Luddite&quot; challenge to the explosion of technology. Thankfully though, the author remains optimistic, and predicts events and technologies that would make today's computer scientists drool with anticipation.<br /> All of this is going to happen according to the author, within the next 30 years, and he gives a dramatic overview of the hypothetical decades ahead. Those readers basking in the current optimism, which can with confidence be called a technological Enlightment, will read these pages with great excitement and a longing to be part of what is ahead. Sure, the book is only a prediction, but lets keep our fingers crossed.........> The author discusses many strategies for building this new form of intelligence, including optical technology, nanotubes, and DNA computing. The later however will probably not be the way to go, as astronomical quantities are needed to perform some of the feats of calculation, such as the traveling salesman problem, which is mentioned by the author in the book as one that can be tackled using DNA computing. <br /> Quantum computing however is also mentioned in the book, and this approach holds much promise, and will be extremely powerful if realized. Current strategies in quantum computing are usually based on the experimentally unjustified notion of entanglement, but it looks hopeful that other ones will be developed that will bring out this quantum coup de etat in programming power. <br /> The social ramifications of the new age of intelligent machines is not ignored however in the book. He predicts, with ample justification I think, a growing &quot;Luddite&quot; challenge to the explosion of technology. Thankfully though, the author remains optimistic, and predicts events and technologies that would make today's computer scientists drool with anticipation. <br /> All of this is going to happen according to the author, within the next 30 years, and he gives a dramatic overview of the hypothetical decades ahead. Those readers basking in the current optimism, which can with confidence be called a technological Enlightment, will read these pages with great excitement and a longing to be part of what is ahead. Sure, the book is only a prediction, but lets keep our fingers crossed.........	2001-07-12
1923992:US	50702879	R2HAB8OE6SO4UO	0122063821	333653527	Computability, Complexity, and Languages, Second Edition: Fundamentals of Theoretical Computer Science (Computer Science and Scientific Computing)	Books	4	44	44	N	N	Beautiful overview	The authors of this book define theoretical computer science as the mathematical study of models of computation, and they do an excellent job of detailing the major results in the theory of computation as related to mathematical logic. Mathematicians, programmers, and philosophers will find the book an effective one in which to learn computability theory, and it serves well as a textbook for courses in the subject.<br /> After a brief review of elementary mathematics and mathematical logic in chapter 1, the authors move right into the consideration of computable functions in chapter 2. They choose a particular abstract programming language in which to study the computability theory, which is built from variables, and programs that can be built from lists of instructions. Examples of programs are given, which have a Fortran flavor, with examples of computing partial functions. Unfortunately, a plethora of GOTO statements appear in the programs, and throughout the rest of the book, which is surprising given the publishing date. The use of these GOTO statements in the book is a major annoyance.<br /> Then in chapter 3, the authors discuss primitive recursive functions, beginning with a treatment of composition, followed by the all-important concept of recursion. The class (PRC) of primitive recursive functions is introduced, and shown to be computable. The primitive recursive predicates are introduced, followed by a proof that the existential and universal quantifiers over an element of a PRC class are also PRC. This is followed by a discussion of minimalization and Godel numbers.<br /> The next chapter is very interesting, wherein the famous halting problem is discussed and related to Church's thesis. The authors stress, most importantly, that an algorithm cannot be defined outside of the choice of a language, and therefore Church's thesis cannot be proved as a theorem. The authors also introduce recursively enumerable sets and show, via diagonalization, that non-recursively enumerable sets exist. They give an interesting example of a function that is computable but not primitive recursive.<br /> The next chapter extends the results to strings of symbols instead of just numbers, and the authors introduce programming languages for doing string computations. One of these is the famous Post-Turing language, which they use to discuss the halting problem, with a variant used in the next chapter on Turing machines. The authors discuss the famous halting problem for Turing machines in this chapter. This is followed in chapter 7 by a discussion of productions and simulation of nondeterministic Turing machines. A very lucid treatment of Post's correspondence problem is given.<br /> Things get somewhat more complicated in chapter 8, where the authors attempt to classify unsolvable problems. It contains one of the best discussions I have seen in the literature on oracles, and the authors give a very clear treatment of arithmetic hierarchies.<br /> The second part of the book reads more like a book on compilers, as the authors delve into the area of grammars and automata. Regular languages, deterministic and non-deterministic finite automata are discussed, and Kleene's theorem, which states that regular languages and finite automata define the same languages, is proven. The context-free languages, so familiar from the study of compilers, are discussed also, along with a proof that a context-free grammar can be reduced to a Chomsky normal form grammar. Pushdown automata, needed for accepting context-free languages, are treated in detail. The authors give a good explanation here as to the additional facilities needed for a finite automaton to decide if a word belongs to a &quot;bracket&quot; language. Chomsky hierarchies are also discussed, and the authors motivate nicely the need for a linear bounded automaton to accept context sensitive languages.<br /> Part three of the book is an overview of mathematical logic, and begins with a treatmentof the propositional calculus. The satisfiability problem is discussed for this system, along with how to reduce formulas to normal form. The important compactness theorem is given a very detailed proof. Predicate calculus is then discussed, and Herbrand's theorem, which effectively reduces logical inference in predicate calculus to a problem of satisfiability of universal sentences, is proven. This theorem is fascinating and has important applications to automated theorem proving, as it ties together semantic and syntactical properties of a formal system. The Godel incompleteness theorem and the unsolvability of the satisfiability problem in predicate logic is proven.<br /> In part 4, issues in computational complexity are addressed, the measure of complexity given in terms of the Blum axioms. This is a very abstract way of introducing complexity theory, as it introduces measures of complexity that more general than time and space complexity.  The fascinating gap theorem, comparing program performance on two computing machines via complexity measures, is proven. This is followed by a detailed discussion of the speedup theorem, which essentially states that there is a wildly complicated recursive function such that for any program computing this function, there exists another program computing the function that works a lot faster for almost every input. The polynomial-time computability is discussed along with the famous P vs NP problem, with the discussion given in terms of Turing machines. Examples of NP-complete problems are given.<br /> The last part of the book covers semantics, with operational and denotational semantics defined and compared. The emphasis in this part is on programming languages and constructions that one would actually find in practice, and so the preceding chapters on computable functions must be extended. The concept of an approximate ordering is introduced to allow for the instantaneous of a computation at some point before its completion. The denotational semantics of recursion equations and infinitary data structures are discussed, with the latter put it in to deal with the sophisticated systems that are constructed here. The discussion here is very involved, but the authors do a fair job of explaining the need for these types of data structures. The same is done for operational semantics, and the authors finally show that the computable numerical functions are actually partially computable. They then show the existence of computable irrational numbers.eatment of the propositional calculus. The satisfiability problem is discussed for this system, along with how to reduce formulas to normal form. The important compactness theorem is given a very detailed proof. Predicate calculus is then discussed, and Herbrand's theorem, which effectively reduces logical inference in predicate calculus to a problem of satisfiability of universal sentences, is proven. This theorem is fascinating and has important applications to automated theorem proving, as it ties together semantic and syntactical properties of a formal system. The Godel incompleteness theorem and the unsolvability of the satisfiability problem in predicate logic is proven. <br /> In part 4, issues in computational complexity are addressed, the measure of complexity given in terms of the Blum axioms. This is a very abstract way of introducing complexity theory, as it introduces measures of complexity that more general than time and space complexity.  The fascinating gap theorem, comparing program performance on two computing machines via complexity measures, is proven. This is followed by a detailed discussion of the speedup theorem, which essentially states that there is a wildly complicated recursive function such that for any program computing this function, there exists another program computing the function that works a lot faster for almost every input. The polynomial-time computability is discussed along with the famous P vs NP problem, with the discussion given in terms of Turing machines. Examples of NP-complete problems are given. <br /> The last part of the book covers semantics, with operational and denotational semantics defined and compared. The emphasis in this part is on programming languages and constructions that one would actually find in practice, and so the preceding chapters on computable functions must be extended. The concept of an approximate ordering is introduced to allow for the instantaneous of a computation at some point before its completion. The denotational semantics of recursion equations and infinitary data structures are discussed, with the latter put it in to deal with the sophisticated systems that are constructed here. The discussion here is very involved, but the authors do a fair job of explaining the need for these types of data structures. The same is done for operational semantics, and the authors finally show that the computable numerical functions are actually partially computable. They then show the existence of computable irrational numbers.	2001-07-11
1924913:US	50702879	RQCNCI2725UCS	0486634620	396563506	Foundations of Mathematical Logic (Dover Books on Mathematics)	Books	4	51	53	N	N	Still an interesting read....	Those interested in mathematical logic will appreciate this book written by one of the main contributors to the field in the twentieth century. The technique of &quot;currying&quot; in higher order logic is named after the author, wherein unary functions can be used to emulate functions with many parameters. The book was first published in 1963, reprinted in 1977, and so is not a up-to-date treatment of mathematical logic, but it could still be used as an historical supplement to a course in this subject. The reader should be aware though the terminology employed by the author is very idiosyncratic and therefore it may not reflect what is currently used in the literature.<br /> The first chapter of the book could be considered an introduction to the philosophy of logic and mathematics. The author though views &quot;philosophical logic&quot; as the study of the principles of valid reasoning, and this is to be distinguished from &quot;mathematical logic&quot;, wherein mathematical systems are constructed to study (formally) the principles of valid reasoning. One can also according to the author view logic as a theory in itself, and many &quot;models&quot; of it can be studied, in much the same way as many different models of geometry can be considered. The author also discusses very succinctly the logical paradoxes, and the different schools of thought in mathematics, such as Platonism, intuitionism, and formalism. The author clearly advocates the formalist school of thought in this book.<br /> In chapter 2, the author gets more into the details of formal reasoning, the field of semiotics is outlined, and the author first begins defining the grammar and symbols for the upcoming discussion. A theory is defined as a class of statements, and consistency and decidability of theories is defined. The idea of a deductive theory is also defined, and the author defines the notion of such a theory being complete. The notions of consistency, decidability, and completeness are the familiar ones now entrenched in current textbooks on mathematical logic. A formal system, according to the author, is a theory in which the parameters of the statements of the theory are introduced as unspecified objects, and the statements of the theory make assertions on the properties of the parameters and their relations. The author considers syntactical systems, wherein the formal objects are taken from some object language, and what he calls Ob systems, which are essentially the systems considered in modern mathematical logic.The author employs the familiar Godel numbering scheme to numerically represent formal objects. The notion of algorithm is brought in here as an effective procedure to manipulate the formal objects of a system.<br /> The next chapter is basically an introduction to the analysis of what would now be called the metalanguage of a formal system. This analysis is done in terms of what the author calls epistatements and epitheorems. Examples of these epitheorems include the Godel incompleteness theorem and the Skolem-Lowenheim theorem. The author introduces and classifies variables, and defines free and bound variables. A brief introduction to the lambda calculus and combinatory logic is given.<br /> Then in chapter 4, the author discusses logical systems which are relational but with no bound variables. These are called logical algebras by the author, and the reader will encounter the famous truth tables and lattices in this chapter. A discussion of the Heyting algebra is given in the notes to the chapter. The reader interested in the more exotic types of algebraic logic, such as quantum logic, could benefit greatly from the reading of this chapter.<br /> The logic of propositional calculus in terms of algebraic logic is discussed in chapter 5. Called propositional algebras by the author, the author proves the deduction theorem for such systems in this chapter. Interestingly, the L systems introduced by Gentzen are also discussed in this chapter. Although there are much better overviews of Gentzen's work in the current literature, a reader may still profit from a perusing of this chapter. L-systems where negation is added is then the subject of the next chapter.<br /> Quantification in formal systems is taken up in chapter 7, considered both in the usual predicate calculus and in L systems. Prenex normal forms, the Herbrand-Gentzen theorem, and the completeness theorem are discussed in fairly good detail, albeit with old-fashioned notation.<br /> The last chapter covers the interesting concept of modal logic. First considered by Aristotle, the author discusses it in the context of L systems, with the presentation being the shortest in the book.s chapter. Although there are much better overviews of Gentzen's work in the current literature, a reader may still profit from a perusing of this chapter. L-systems where negation is added is then the subject of the next chapter. <br /> Quantification in formal systems is taken up in chapter 7, considered both in the usual predicate calculus and in L systems. Prenex normal forms, the Herbrand-Gentzen theorem, and the completeness theorem are discussed in fairly good detail, albeit with old-fashioned notation. <br /> The last chapter covers the interesting concept of modal logic. First considered by Aristotle, the author discusses it in the context of L systems, with the presentation being the shortest in the book.	2001-07-10
1928257:US	50702879	R30J3B8P6XAG8R	0691081220	584593399	Characteristic Classes. (AM-76)	Books	2	20	54	N	N	No in-depth discussion here of a very important subject	The learning of an area of mathematics especially at the level of this book can be a time-consuming affair depending on the depth in which one wants to understand the results. A formal and computational understanding of mathematics takes considerably less time than a thorough in-depth understanding, which requires careful thought and minute attention to detail. Very rarely do modern textbooks and monographs in mathematics attempt to convey to the reader this type of understanding, and this book is no exception. It emphasizes the axiomatic and formal machinery behind the theory of characteristic classes, but does not attempt to show the underlying motivation and intuition behind these very important objects. I took a course in advanced algebraic topology which used this book as a text, have read and studied the book many times, and worked out every problem in the book, but it took a very time-consuming literature search to reach a level of understanding that I thought acceptable. The theory of characteristic classes permeates many different areas of mathematics, and has found its way into physical applications in quantum field theory and string theory. Most of the physicists I have talked to who work in these areas are able to compute effectively physical results that involve the use of characteristic classes, but all of them voiced the opinion that they did not really understand exactly what was going on behind the scenes.<br /> It would have been very helpful if the authors of this book, prominent mathematicians in their own right, would have given an historical motivation for this subject, and one that emphasizes the need for characteristic classes in the study of non-trivial vector bundles. In the chapter on Stiefel-Whitney classes in particular, a set of four axioms that must be satisfied by these classes is given, and only later do the authors show that objects can be defined that will satisfy the axioms. It is not helpful to merely delineate the algebraic relations that these classes satisfy as a consequence of the axioms. What is needed is a series of explanations, starting from the simplest and proceeding to the more complex, that will give the reader an appreciation of just how these objects were discovered and later formalized mathematically. Physicists in particular must have this kind of appreciation in order to better use these concepts in developing new physical theories.<br /> Such a criticism can be leveled against the rest of the book also, for the chapters on Chern classes, Pontryagin classes, and Euler classes are purely formal and not written for the person desiring a complete understanding. The only chapter that most closely approximates one that gives a fairly good intuitive, geometric understanding is the one on combinatorial Pontryagin classes. The authors work with cohomology over the rational numbers and over geometric complexes. They don't however show how topological invariants can be captured by this approach, but instead give a reference, disappointingly.<br /> Unfortunately I do not know of a book that will assist the person genuinely interested in understanding in-depth the theory of characteristic classes. To gain such an understanding will involve a time-consuming review of the literature on the subject, this literature beginning essentially in the 1930's. Such an undertaking is worth it however, for the theory of characteristic classes is fascinating, and its application to physics even more so.ations that these classes satisfy as a consequence of the axioms. What is needed is a series of explanations, starting from the simplest and proceeding to the more complex, that will give the reader an appreciation of just how these objects were discovered and later formalized mathematically. Physicists in particular must have this kind of appreciation in order to better use these concepts in developing new physical theories. <br /> Such a criticism can be leveled against the rest of the book also, for the chapters on Chern classes, Pontryagin classes, and Euler classes are purely formal and not written for the person desiring a complete understanding. The only chapter that most closely approximates one that gives a fairly good intuitive, geometric understanding is the one on combinatorial Pontryagin classes. The authors work with cohomology over the rational numbers and over geometric complexes. They don't however show how topological invariants can be captured by this approach, but instead give a reference, disappointingly. <br /> Unfortunately I do not know of a book that will assist the person genuinely interested in understanding in-depth the theory of characteristic classes. To gain such an understanding will involve a time-consuming review of the literature on the subject, this literature beginning essentially in the 1930's. Such an undertaking is worth it however, for the theory of characteristic classes is fascinating, and its application to physics even more so.	2001-07-08
1930556:US	50702879	R1GCH1XCB2TTQ4	0817636447	821057885	Loop Spaces, Characteristic Classes and Geometric Quantization (Progress in Mathematics)	Books	4	7	7	N	N	Pretty good overview	Characteristic classes, one of the most abstract and most difficult subjects to teach, are treated in this book at a level that is fairly understandable. The author endeavors to explain how characteristic classes &quot;do their jobs&quot; in the areas in which they are employed, and, even though he does not give an understanding of the foundations of the subject, a reading of the book will give one some helpful guidance in the gaining of such an understanding. In the introduction in particular, the author gives an excellent overview of the history of characteristic classes and explains how the arise in different areas of mathematics. The book is written for the mathematician in mind, but readers interested in applying the theory of characteristic classes, such as high energy physicists, could gain a great deal from the reading of this book.<br /> In chapter 1, the author overviews the language of sheaf theory and how to construct complexes of sheaves. Although the presentation is somewhat abstract, the author does give some examples of the constructions, such as the exponential exact sequence of sheaves. Using an injective resolution of a sheaf, the sheaf cohomology groups are defined and then shown to be independent of the injective resolution. Using the idea of a double complex, spectral sequences are introduced, along with the concept of sheaf hypercohomology.  The later is constructed using an injective resolution corresponding to a sheaf complex. Most interestingly, the author shows how the hypercohomology of sheaves is related to the Cech cohomology. The later is more concrete from an applications point of view, and is one that can be more readily understood by physicists, as well as de Rham cohomology that is introduced later, and is shown to be a resolution of the constant sheaf of a smooth manifold. The Cech cohomology groups are shown to be canonically isomorphic to the de Rham cohomology groups.<br /> A cohomology theory not so familiar to most is the Deligne cohomology, which is also introduced in chapter 1. This is also called Cheeger-Simons cohomology by some, and has applications in conformal field theory. The presentation here is actually quite good, as the author shows how Deligne cohomology is related to ordinary cohomology via a few examples, and how Deligne cohomology can be used to compare Cech cohomology classes with de Rham cohomology classes. The chapter ends with an overview of the famous Leray spectral sequence.<br /> In chapter 2, the author goes into the classification of line bundles, basically using the Weil-Kostant theory. When the line bundle has a connection, the author shows that the isomorphism classes of line bundles with connections is related to the second Deligne cohomology group. The Kostant central extensions of the group of symplectic diffeomorphims is also considered, and the author shows how this acts on sections of line bundles.  In chapter 3, the author considers first the topology on the space of singular knots in a smooth three-dimensional manifold, which is shown to great surprise to be a Kahler manifold. Not only that, the author further shows it to have a symplectic, complex, and a Riemannian structure.<br /> The discussion gets considerably more interesting in chapter 4, wherein the author discusses how to generalize the classical result that the second integral cohomology group of a manifold is the group of isomorphism classes of line bundles over the manifold. The goal is to characterize the third integral cohomology group, and the author does this by using the theory of C*-algebras. The result of Dixmier-Douady relating the algebra of compact operators on a separable Hilbert space is shown to give the geometric description of the third integral cohomology group. The section on connections and curvature in this chapter is especially well written because the author explains and motivates well the eventual identification of the Hilbert space as the space of infinitely differentiable functions on the unit circle.<br /> In chapter 5, things get more complicated, where the Dixmier-Douady theory of sheaves of groupoids is related to the third integral cohomology group. Torsors are introduced as a generalization of principal bundles. Algebraic geometers frequently refer to sheaves of groupoids as &quot;stacks&quot; and the author discusses these and the idea of a gerbe from the standpoint of category theory. The sheaf of groupoids is shown to represent the third integral cohomology group and the author constructs a cohomology class of the sheaf of groupoids using differential-geometric constructions.<br /> Chapter 6 considers line bundles over loop spaces, with the holonomy of line bundles initiating the discussion. Interestingly, the author shows that Deligne cohomology again plays a role here, in that the holonomy of a line bundle with a connection can be expressed in terms of a transgression map in Deligne cohomology. The line bundle over the loop space of a smooth manifold is constructed using the sheaf of groupoids over the manifold, and is called the anomaly line bundle associated to the sheaf of groupoids. When the (free) loop space is generalized to the space of oriented singular knots, and the manifold is 3-dimensional, the author shows how to obtain a bundle over this space, and shows the relation to geometric quantization. The central extension of the loop group is considered, interestingly, in terms of action functionals, an approach which has its origins in physics.<br /> The author ends the book with a discussion of the Dirac monopole. This object has been studied in great detail in the literature, but here the author gives an interesting twist wherein he relates the monopole to the Dixmier-Douady sheaf of groupoids over the three-dimensional sphere, and gives an explicit generator of the third integral cohomology group of this sphere. The classical quantization condition then follows naturally.fferentiable functions on the unit circle. <br /> In chapter 5, things get more complicated, where the Dixmier-Douady theory of sheaves of groupoids is related to the third integral cohomology group. Torsors are introduced as a generalization of principal bundles. Algebraic geometers frequently refer to sheaves of groupoids as &quot;stacks&quot; and the author discusses these and the idea of a gerbe from the standpoint of category theory. The sheaf of groupoids is shown to represent the third integral cohomology group and the author constructs a cohomology class of the sheaf of groupoids using differential-geometric constructions. <br /> Chapter 6 considers line bundles over loop spaces, with the holonomy of line bundles initiating the discussion. Interestingly, the author shows that Deligne cohomology again plays a role here, in that the holonomy of a line bundle with a connection can be expressed in terms of a transgression map in Deligne cohomology. The line bundle over the loop space of a smooth manifold is constructed using the sheaf of groupoids over the manifold, and is called the anomaly line bundle associated to the sheaf of groupoids. When the (free) loop space is generalized to the space of oriented singular knots, and the manifold is 3-dimensional, the author shows how to obtain a bundle over this space, and shows the relation to geometric quantization. The central extension of the loop group is considered, interestingly, in terms of action functionals, an approach which has its origins in physics. <br /> The author ends the book with a discussion of the Dirac monopole. This object has been studied in great detail in the literature, but here the author gives an interesting twist wherein he relates the monopole to the Dixmier-Douady sheaf of groupoids over the three-dimensional sphere, and gives an explicit generator of the third integral cohomology group of this sphere. The classical quantization condition then follows naturally.	2001-07-06
1931603:US	50702879	R272OVHX2H3LQX	0671657135	660942558	The Society of Mind	Books	4	114	121	N	N	Highly original...will make you &quot;think out of the box&quot;.	In this book the author attempts to explain the workings of the human mind as a collection of a large number of autonomous mindless connected agents. The approach is metaphorical/philosophical, and no empirical evidence is given for the ideas expounded. The &quot;society of mind&quot;, composed as it is of a collection of simple objects, is purely reductionist in its strategy and philosophy. It is though a highly original and thought provoking introduction to the major questions involving mental states, concept formation in the brain, learning theory, and artificial intelligence. The author gives many interesting examples that entice the reader to &quot;think out of the box&quot;.<br /> The book itself is written as though each chapter were itself one of these agents. Typically a chapter poses a question or a particular phenomenon, and the author then addresses how the mind would implement of resolve this question or deal with this phenomenon.  Some interesting chapters in the book include:<br />1. Self-Knowledge is Dangerous: The author argues that mental constraints are needed to prevent the individual from artificially creating emotional states that would prevent deliberate action on our part. An intelligent machine will then need to have such constraints in order to prevent it from repeating endlessly the same activity.<br />2. Learning from Failure: Minsky argues that confining oneself to positive learning experiences will not be as robust or effective as one that will involve some kind of discomfort or pain. Such discomfort will enable more radical changes in conceptual structure.<br />3. Power of Negative Thinking: The author argues that an optimistic problem-solving strategy is contingent on the ability to recognize several paths to the solution, with the best path then selected. When such knowledge is not available, a &quot;pessimistic&quot; strategy is more optimal. The solution in this case is one that at first glance seems the worst possible avenue of approach.<br />4. Emotion: The question is posed as to whether machines can be intelligent without any emotions. The author seems to be arguing, and plausibly I think, that emotions serve as a defense against competing interests when a goal is set. Emotional responses occur when the most important goal(s) are disrupted by other influences. Intelligent machines then will need to have the many complex checks and balances.<br />5. Must Machines be Logical: It is argued correctly that intelligent machines must employ reasoning tools other then ones that are strictly logical. Logic is strictly a side constraint, a test that prevents invalid conclusions. It cannot by itself lead to genuine knowledge.<br />6. Mathematics Made Hard: Minsky argues that the strategy behind the construction of mathematical systems, via strict definitions and categorization, results in systems that have very small &quot;meaning&quot; content. More robust systems must be developed and integrated into the educational process and into any design for intelligent machines.<br />7. Weighing Evidence: There is an interesting example of a collection of four index cards on two of which are connected line patterns, and on the other two disconnected line patterns. When the cards are cut into many pieces, and put into separate piles, then a machine with a feature weighing capability would be unable to distinguish between the piles.<br />8. The Mind and the World: The author's thinking on the mind-body problem is a very sensible one, namely that &quot;minds are simply what brains do&quot;. It matters not, according to the author, what the substance of mind (brain) is, only what it (the agents) do.<br /> A few omissions in the book include the discussion on intelligence: the author never really gives his outlook or &quot;definition&quot; of intelligence, but merely comments on a few other opinions on this concept. If one is to make &quot;intelligent&quot; machines, it is important that intelligence be characterized explicitly so that one will know when and if the goal of artificial intelligence has been reached. The author correctly argues however that expert systems can and have been successfully constructed, and that the most formidable obstacle to constructing an &quot;intelligent&quot; machine is in implementing the ability of humans to exercise &quot;common sense&quot;.characterized explicitly so that one will know when and if the goal of artificial intelligence has been reached. The author correctly argues however that expert systems can and have been successfully constructed, and that the most formidable obstacle to constructing an &quot;intelligent&quot; machine is in implementing the ability of humans to exercise &quot;common sense&quot;.	2001-07-05
1932950:US	50702879	R9SSWWK8ZKUYB	0821821393	620345913	Geometry of Characteristic Classes (Translations of Mathematical Monographs)	Books	3	13	18	N	Y	Fairly good reading	The theory of characteristic classes goes back to the 1930's, and is a subject that is one of the most poorly motivated from a didactic point of view. The literature on the subject is vast, but there are few works that explain the theory in a way that is transparent and helpful to those who need to apply it, such as physicists in the areas of high energy physics and quantum field theory. Individuals who really desire an in-depth real understanding of characteristic classes, rather than a purely formal one, will find the road difficult. There does not seem to be anywhere in the literature a treatment of characteristic classes that gives genuine insight on why these objects work as well as they do for the jobs they are supposed to do.  This book is no exception to this, but it does serve to introduce the reader to the theory of characteristic classes as it has been developed in the last few decades. The first chapter is an introduction to de Rham homotopy theory, and its purpose is to outline the approach of using differential forms rather than cohomology groups to study the homotopy type of a smooth manifold. After a brief overview of Postnikov decompositions, the author discusses the rational homotopy type of a topological space. This is a strategy that is based on ignoring torsion and viewing the homotopy group as being over the rational numbers. This makes computation of the homotopy type much easier. The rational spaces have fundamental groups that are Lie groups over the rationals and each higher homotopy group is a vector space over the rationals. This theory is basically due to D. Sullivan and his main results are proved in this chapter. The interesting part of this discussion is the construction of de Rham complexes over simplicial complexes instead of smooth manifolds. The author shows in detail how the rational cohomology can be computed for these types of objects. He then discusses the cohomology of groups in terms of Eilenberg-Maclane spaces, and defines what is called the Malcev completion of a finitely generated group. This is basically a rational nilpotent completion of the group, and is used in the chapter to give the connection between fundamental groups and differential forms.<br /> In chapter 2, the author discusses characteristic classes over flat bundles. The author shows very effectively how the fundamental group of the base space of a flat bundle can introduce twist in the flat bundle. The Chern-Weil theory, which allows one to study the global structure of principal bundles with a given Lie group as a structure group, is reviewed in the first part of the chapter. The author also gives a very interesting characterization of flatness in terms of holonomy homomorphisms. Then after a brief overview of the cohomology of Lie algebras, he defines characteristic classes of flat product bundles. Since a given principal bundle may not be trivial, defining characteristic classes for a general flat principal bundle takes more work, which the author does nicely in what follows. The Chern-Simons theory, so important in physical applications, is then discussed as a specialization of the Chern-Weil theory. The author then returns to the consideration of characteristic classes of flat bundles via Gelfand-Fuks cohomology. This is the cohomology of the subcomplex of the continuous cochains of the smooth vector fields of a smooth manifold, and the author shows how it acts as a characteristic class for flat product bundles.<br /> The author moves on to the characteristic classes of foliations in chapter 3. This is a topic very important to those who study dynamical systems, and the author gives a pretty good overview of how characteristic classes can measure the global properties of foliations. He reviews briefly what foliations are, and then defines the Godbillon-Vey characteristic class for a foliation of a smooth manifold. The author gives an example of foliation for the Lie group PSL(2, R), and shows the existence of a non-trivial Godbillon-Vey class for a collection of torsion-free discrete subgroups of this group. The Bott vanishing theorem is proved, and then the author shows how to relate the Gelfand-Fuks cohomology to the characteristic classes of foliations via the Weil algebra. Then the author gives a fascinating discussion on how to find &quot;discontinuous invariants&quot; induced by a real cohomology class. The discussion is very interesting given the disparity between real and integer cohomology classes. He then returns to the consideration of the characteristic classes of flat bundles where now the Lie group is replaced by a given closed smooth manifold.<br /> In the last chapter of the book, the author discusses the characteristic classes of surface bundles, where the genus of the surface is greater than or equal to 2. String theorists will appreciate the discussion, as it goes into the mapping class group of surfaces, the Teichmuller modular group, and how they act on the homology group of surfaces. The author shows explicitly how to construct surface bundles with non-trivial characteristic classes, and gives a brief outline of the proof that these characteristic classes are algebraically independent.<br />  The author ends the book with a discussion of future research problems for the interested reader, along with a short list of references.existence of a non-trivial Godbillon-Vey class for a collection of torsion-free discrete subgroups of this group. The Bott vanishing theorem is proved, and then the author shows how to relate the Gelfand-Fuks cohomology to the characteristic classes of foliations via the Weil algebra. Then the author gives a fascinating discussion on how to find &quot;discontinuous invariants&quot; induced by a real cohomology class. The discussion is very interesting given the disparity between real and integer cohomology classes. He then returns to the consideration of the characteristic classes of flat bundles where now the Lie group is replaced by a given closed smooth manifold. <br /> In the last chapter of the book, the author discusses the characteristic classes of surface bundles, where the genus of the surface is greater than or equal to 2. String theorists will appreciate the discussion, as it goes into the mapping class group of surfaces, the Teichmuller modular group, and how they act on the homology group of surfaces. The author shows explicitly how to construct surface bundles with non-trivial characteristic classes, and gives a brief outline of the proof that these characteristic classes are algebraically independent. <br />    The author ends the book with a discussion of future research problems for the interested reader, along with a short list of references.	2001-07-05
1935509:US	50702879	R1IXWD6UDM46H1	0262133415	829239639	Programming with Constraints: An Introduction	Books	4	26	27	N	N	Very good introduction	This book is one of the few devoted to constraint programming, and does a good job of introducing the field to those interested. Optimization problems are finding use of constraint programming and there are a few commercial packages available that implement constraint programming technique in optimization. The book can be used as a textbook of an actual course, since there are many exercises included in it. The authors encourage the reader to use the CLP(R) package, which is freely available, to solve some of the practical exercises.<br /><br /> After a brief introduction to constraint programming, the authors introduce three types of constraints that exist in constraint programming, namely arithmetic, tree, and finite domain. They also introduce three operations involving constraints: satisfiability, simplification, and optimization. The authors spend most of the chapter on the question of satisfiability. Constraints are defined from the standpoint of mathematical logic, along with what it means for them to be satisfiable, and a discussion on modeling with arithmetic constraints and constraint satisfaction is given with an example from electric circuits. Tree constraints are then discussed with an example of a C-language binary tree used to motivate the discussion. Boolean constraints are then discussed, along with sequence constraints, which are shown to have an interesting application to DNA mapping and decoding. An application to artificial intelligence is given, and this one involves constraints that are not taken from mathematics. The authors finish the chapter with a discussion of constraint solving using local propagation, a technique used in graph theory.<br /><br /> The authors discuss the simplification and optimization of constraints in the next chapter. They show when constraints are redundant, give rules for deciding when one constraint is equivalent to another, and show how using projection can allow the simplifying of a constraint with respect to the variables of interest. When projection cannot be done, they then show how to add variables to a constraint in order to achieve simplification. The (polynomial-time) Dantzig simplex algorithm is discussed for problems with linear real arithmetic constraints. Algorithms are discussed for deciding when two constraints are equivalent or when one implies the other.<br /><br /> In chapter 3, the authors discuss constraint problems for the case where the constraint domain is a finite set. The arc and node consistency, bounds propagation, and integer programming techniques, familiar from AI and operations research, are discussed in detail. The famous N-queens problem is introduced as motivation for the constraint satisfaction problem. The free-ware Prolog package ECLiPSe is introduced in the practical exercises. The authors give references to an interesting application of constraint satisfaction problems to planning gene-splicing experiments (the MOLGEN system).<br /><br /> The next part of the book concerns the constraint logic programming (CLP) paradigm wherein the authors define constraint logic programs and programming techniques. The reader familiar with logic programming (Prolog for example), will clearly see the influence of ideas from that area, such as rules, goals, rewriting, and derivations. An interesting and useful example of applying CLP to the modeling of options trading is given. Also, the authors show how to employ some of the more common data structures, such as lists and binary trees into CLP. In addition, they show how one can measure the efficiency of a CLP program, and how to improve it using various programming techniques to reduce the search space. The authors show how CLP can be implemented for both cases of infinite and finite domain constraints.<br /><br /> In the last part of the book the authors discuss other ways of viewing constraint logic programs, such as thinking it in terms of a database, called a constraint database. The discussion is very interesting, for the authors show how they are generalizations of the standard databases, and they show how the usual evaluation techniques in CLP, such as backtracking, must be generalized if one is to efficiently implement constraint databases. This \\"bottom-up\\" evaluation is compared with the \\"top-down\\"; approach usually employed. They show in great detail how constraint databases are a natural generalization of relational databases. They also show how CLP can be generalized to the case of concurrent constraint programming, where agents can execute concurrently and communicate via some global constraint in memory. In addition, they give a brief overview of how CLP can be implemented into the functional and imperative programming paradigms. They mention the use of various commercial packages for doing constraint programming, such as Mathematica, Maple, Macsyma, and ILOG SOLVER. Since the time of publication a very powerful commercial package, called ILOG OPL has appeared.<br /><br /> The applications of constraint programming are mushrooming, and I have found it to be a very powerful tool for example in network modeling and simulation, and in mathematical portfolio analysis, although sometimes one must be patient because of performance.  The programming methodologies used are different than the usual ones, but I find them to be very effective for program transparency and economy of thought. Others have also apparently found constraint programming to be useful, for example the problem of protein structure prediction has recently made heavy use of constraint programming techniques. Other recent uses of CLP include a system for transport planning and scheduling for a large food industry, a system for a TV/radio company to plan and control the assignment of journalists and technicians to different emissions, and a system to develop work plans and schedules for train drivers and conductors, optimal planning of digital cordless communication systems, and nuclear fuel transportation and scheduling.ry interesting, for the authors show how they are generalizations of the standard databases, and they show how the usual evaluation techniques in CLP, such as backtracking, must be generalized if one is to efficiently implement constraint databases. This \\"bottom-up\\" evaluation is compared with the \\"top-down\\"; approach usually employed. They show in great detail how constraint databases are a natural generalization of relational databases. They also show how CLP can be generalized to the case of concurrent constraint programming, where agents can execute concurrently and communicate via some global constraint in memory. In addition, they give a brief overview of how CLP can be implemented into the functional and imperative programming paradigms. They mention the use of various commercial packages for doing constraint programming, such as Mathematica, Maple, Macsyma, and ILOG SOLVER. Since the time of publication a very powerful commercial package, called ILOG OPL has appeared.<br /><br /> The applications of constraint programming are mushrooming, and I have found it to be a very powerful tool for example in network modeling and simulation, and in mathematical portfolio analysis, although sometimes one must be patient because of performance.  The programming methodologies used are different than the usual ones, but I find them to be very effective for program transparency and economy of thought. Others have also apparently found constraint programming to be useful, for example the problem of protein structure prediction has recently made heavy use of constraint programming techniques. Other recent uses of CLP include a system for transport planning and scheduling for a large food industry, a system for a TV/radio company to plan and control the assignment of journalists and technicians to different emissions, and a system to develop work plans and schedules for train drivers and conductors, optimal planning of digital cordless communication systems, and nuclear fueltransportation and scheduling.	2001-07-03
1935898:US	50702879	R2RLOW0FLX6MIW	0691029067	263267851	Introduction to Mathematical Logic	Books	4	41	42	N	N	One of the classics	This book, which first appeared in print as an issue in Annals of Mathematics in 1944, is now a classic in mathematical logic, and is still worth perusing in spite of the out-dated notation. The author outlines comprehensively the propositional calculus and predicate calculus. Although the book is mostly formal in its style, the author does introduce the reader to some elementary notions in logic, and some brief commentary on what would now be classified as philosophical logic. He defines logic as the analysis of propositions and their proof according to their form and not their content. He notes also that inductive logic and the theory of partial confirmation should also be included as part of mathematical logic. There are exercises throughout the book, and so it could conceivably be used as a textbook, in spite of its publication date. The book could better be used as a historical supplement to a course in mathematical logic or one in the philosophy of logic.<br /> In the introduction to the book the author defines the terms and concepts he will use in the book, with a discussion of proper names, constants and variables, functions, and sentences. He adopts the Fregian point of view that sentences are names of a particular kind. His discussion of this is rather vague however, for he does not give enough clarification of the difference between an &quot;assertive&quot; use of a sentence and its &quot;non-assertive&quot; use. Readers will have to do further reading on Frege in order to understand this distinction more clearly, but essentially what Church is saying here is that sentences are names with truth values. The existential and universal quantifiers are introduced as well. And here the author also introduces the concepts of object language and metalanguage, along with a discussion of the axiomatic method. The author distinguishes between informal and formal axiomatic methods. The modern notions of syntax and semantics are given a nice treatment here, and the di<br />scussion is more in-depth than one might get in more modern texts on mathematical logic.<br /> Chapter 1 is a detailed overview of propositional logic, being the usual formal system with three symbols, one constant, an infinite number of variables, rules on how to form well-formed formulas, and the rules of inference. The deduction theorem is proved in detail along with a discussion of the decision problem for propositional logic, with the famous truth tables due to W. Quine introduced here. The notions of consistency and completeness are briefly discussed.<br /> The discussion of the propositional calculus is continued in the next chapter where a new system of propositional calculus is obtained by dropping the constants from the first one and adding another symbol (negation). The two systems are shown to be equivalent to each other using a particular well-formed formula in the second one to replace the constant in the first. Other systems of propositional calculus are also introduced here, using the idea of primitive connectives such as disjunction, along with various rules of inference. Church also outlines an interesting propositional calculus due to J.G.P.Nicod, which assumes only one primitive connective, one axiom, and only one rule of inference (besides substitution). The author also introduces partial systems of propositional calculus, with the goal of showing just what must be added to these systems to obtain the full propositional calculus. He discusses the highly interesting and thought-provoking intuitionistic propositional calculus, due to A. Heyting, which is a formalization of the famous mathematical intuitionism of L.E.J. Brouwer. The system he discusses is a variant of Heyting's and he gives references to the positive solution of the decision problem for this system. The author ends the chapter with a brief discussion of how to construct a propositional calculus by employing axiom schemata.<br /> The author then moves on to what he has termedfunctional calculi of first order beginning in the next chapter. Called predicate calculi in today's parlance, the author first defines the pure functional calculus of first order, and shows that the theorems of the propositional calculus also follow when considered as part of this system. Free and bound variables are defined, and Church proves explicitly the consistency of this system, and the deduction theorem. The important construction of a prenex normal form of a well-formed formula is discussed, and the author shows that every well-formed formula of the functional calculus is equivalent to some well-formed formula in prenex normal form.<br /> In chapter 4, the author gives an alternative formulation of pure functional calculus of first order, wherein rules of substitution are used and axiom schemata are replaced by instances, making the number of axioms finite. The Skolem normal form of a well-formed formula is defined, which sets up a discussion of satisfiability and validity. The author then proves the Godel completeness theorem, which states that every valid well-formed formula is a theorem. This is followed by a very well written discussion of the Skolem-Lowenheim theorem, and an overview of the decision problem in functional (predicate) calculus.<br /> In the last chapter of the book the author considers functional (predicate) calculi of second order, which is distinguished from the first order case by allowing the variables to range over what its predicates and subjects represent. In second-order functional calculus, propositional and predicate variables can have bound occurrences. The author discusses the elimination problem and consistency for second-order predicate calculus, and gives a proof of the (Henkin) completeness theorem. A fairly detailed discussion of a logical system for elementary number theory is given, but the treatment involves notation that is somewhat clumsy and the discussion is difficult to follow.med functional calculi of first order beginning in the next chapter. Called predicate calculi in today's parlance, the author first defines the pure functional calculus of first order, and shows that the theorems of the propositional calculus also follow when considered as part of this system. Free and bound variables are defined, and Church proves explicitly the consistency of this system, and the deduction theorem. The important construction of a prenex normal form of a well-formed formula is discussed, and the author shows that every well-formed formula of the functional calculus is equivalent to some well-formed formula in prenex normal form. <br /> In chapter 4, the author gives an alternative formulation of pure functional calculus of first order, wherein rules of substitution are used and axiom schemata are replaced by instances, making the number of axioms finite. The Skolem normal form of a well-formed formula is defined, which sets up a discussion of satisfiability and validity. The author then proves the Godel completeness theorem, which states that every valid well-formed formula is a theorem. This is followed by a very well written discussion of the Skolem-Lowenheim theorem, and an overview of the decision problem in functional (predicate) calculus. <br /> In the last chapter of the book the author considers functional (predicate) calculi of second order, which is distinguished from the first order case by allowing the variables to range over what its predicates and subjects represent. In second-order functional calculus, propositional and predicate variables can have bound occurrences. The author discusses the elimination problem and consistency for second-order predicate calculus, and gives a proof of the (Henkin) completeness theorem. A fairly detailed discussion of a logical system for elementary number theory is given, but the treatment involves notation that is somewhat clumsy and the discussion is difficult to follow.	2001-07-03
1939229:US	50702879	R32O34IJUAS6MJ	0387948392	848589545	Methods of Mathematical Finance (Stochastic Modelling and Applied Probability)	Books	5	43	49	N	N	One of the best	The application of highly sophisticated mathematical techniques to finance is now commonplace and is considered also of great practical importance. Mathematical modeling in finance is now very entrenched in investment houses and trading firms and this will only increase in years to come. This book is an excellent overview of mathematical finance and is written for mathematicians who have no background in finance. The book could be read easily by anyone with background in stochastic processes at the level of the author's earlier book \\"Brownian Motion and Stochastic Calculus\\". Since it is written for mathematicians, it follows a \\"definition-theorem-proof\\" format. However the authors do interject a lot of explanation into the dialog, especially that concerning finance.<br /><br />Chapter 1 is an overview of a Brownian motion model of financial markets. Financial assets are considered to have prices evolving continuously in time and driven by Brownian motion. They do however g!ive references for models that assume discontinuous asset prices. The authors define a financial market rigorously in terms of (progressively) measurable processes for the risk-free rate, mean rate of return, dividend rate, and volatility. The after a discussion of portfolio, gains, income, and wealth processes, the authors define a notion of a viable market, namely one where there are no arbitrage opportunities. They then define standard and complete financial model and characterize  their properties in terms of martingales.<br /><br /> Chapter 2 is a treatment of options pricing theory, with the assumption of a complete standard, financial market. These contingent claims are given a brief historical introduction at the beginning of the chapter. European contigent claims are treated first, followed by a discussion of forward and futures contracts. The Black-Scholes option pricing formula is then derived. American contingent claims are then discussed and defined as an income proc!ess and a settlement process. With the assumption that the discount payoff process is bounded from below and continuous, the value of the American contingent claim is given in terms of the Snell envelope of the payoff process. The discussion illustrates the difficulties in valuing American claims, based as they are on an arbitrary exercise time.<br /><br /> Chapter 3 is a study of a \\"small\\" single investor who begins with an initial endowment and invests in a standard complete market. The discussion reads more like one from a book on utility theory and portfolio analysis. Indeed, the Legendre transform of the utility function appears when attempting to mazimize utility from consumption plus expected utility from terminal wealth. The (nonlinear) Hamilton-Jacobi-Bellman equation appears in thes considerations as expected.<br /><br /> In chapter 4, the equilibrium problem is considered. In such a model, security prices are determined by the law of supply and demand. There are a finite !number of agents with utility functions and there are endowment processes. The endowments can be traded via a financial market of stocks and money market funds. The goal of the chapter is to find the equilibrium condition where endowments are consumed and the net supply of securities is zero. The authors give a rigorous proof of the existence and uniqueness of equilibrium. In addition, they give interesting examples of equilibrium markets that can be computed explicitly.<br /><br /> The next chapter is much more involved and studies how to do arbitrage pricing in incomplete markets. Portfolio constraints force the market to be incomplete, and the authors show how buyers and sellers in such a market can calculate the hedging price of a claim in terms of \\"dual\\" processes in a family of auxiliary markets. Since this is a constrained optimization problem, one would naturally think Lagrange multipliers would appear, and this is indeed the case, with the dual processes being the analog!ue of Lagrange multipliers. The usual unconstrained problem then is the result of this. Their approach here is extended in the last chapter of the book where the problem of optimal consumption and investment in a constrained financial market is considered. This is specialized to a deterministic case and the dual to the constrained problem satisfies a linear Hamilton-Jacobi-Bellman equation. This duality between the Lagrangian and Hamiltonian points of view is not surprising to the astute reader (and particularly the physicist reader).nconstrained problem then is the result of this. Their approach here is extended in the last chapter of the book where the problem of optimal consumption and investment in a constrained financial market is considered. This is specialized to a deterministic case and the dual to the constrained problem satisfies a linear Hamilton-Jacobi-Bellman equation. This duality between the Lagrangian and Hamiltonian points of view is not surprising to the astute reader (and particularly the physicist reader).	2001-06-30
1939479:US	50702879	R2LGP1O0SE0PJU	3540620583	839050056	Numerical Computation 1: Methods, Software, and Analysis (Numerical Computation 1 Vol. XVI)	Books	4	3	3	N	N	Good for reference and self-study	This book gives an excellent overview of numerical analysis from both the theoretical and practical points of view. The in-depth discussion given by the author makes this book a welcome addition to the literature on numerical analysis and scientific computation. Fortran 90 is the language of choice for the author in discussing programming implementations of the examples and concepts. There are no exercises in the book, so it would be difficult to use as a textbook or a course in numerical analysis, but it does serve as a useful reference and supplement to such a course.<br /> In chapter 1, the author briefly overviews the strategies and techniques behind scientific modeling and gives many historical examples. A rather short discussion however is given on the testing and validation of models. More should have been said here about this very important phase of the modeling process.<br /> The author introduces the principles behind numerical analysis in chapter 2. He uses the problem of the plane pendulum from elementary physics to motivate the issues involved, such as the accuracy of the mathematical model. The author then classifies numerical problems into four categories, and gives a rigorous discussion of the accuracy of numerical results. This is followed by a discussion of the types of error one would encounter when doing numerics, these being model errors, data errors, algorithm errors, and rounding errors. Data error analysis, which studies the impact on the solution by altering the data on which it is based, is given a fine treatment by the author in terms of functional analysis. He defines the important concepts of absolute and relative condition numbers, and then discusses ill-conditioned problems. The author emphasizes that characterizing a problem as being ill-conditioned depends on the desired level of accuracy. He then gives a fairly complete overview of the validation of numerical computations and numerical software. The author emphasizes the extreme difficulties involved in the accessing of software quality statistically.<br /> Chapter 3 gives an overview of computer hardware and architecture used to perform numerical computations. The author discusses the use of parallelization, pipelining, vector processors, memory hierarchies, caching (the discussion of this is excellent), virtual memory, and interleaving. He also gives a useful discussion of how to quantify numerical software performance, and how to perform an analytical and empirical assessment of hardware performance.<br /> The actual implementation of numerical algorithms is discussed in the next chapter, wherein the author discusses just how numerical data is represented in digital circuits, and how such data is operated on arithmetically. The implementation of floating-point arithmetic, via the IEC/IEEE floating-point standard is discussed. The author addresses well the accuracy issues that arise for problems (such as partial differential equations for example), involving an extremely large number of floating-point operations. In addition, he discusses the use and implementation of multiple-precision arithmetic, with examples given of the ISML, MP, FM, and MPFUN packages for doing this. I have found though that, in addition to some of these packages, high-level symbolic programming languages, such as Mathematica, can be very suitable for heavy-duty number crunching. The discussion of number systems and rounding in this chapter is excellent and well suited for the beginning student in numerical analysis.<br /> Chapter 5 gives begins a discussion of numerical algorithms, and the author discusses the basic notions of algorithms and their complexity characterization via the O-notation. Case studies in matrix multiplication and summation are given to illustrate the contributions of rounding errors and error propagation. This is followed in chapter 6 by a discussion of numerical programs, wherein the author discusses the quality, efficiency, and computational overhead of programs. Performance optimization, via such techniques as loop optimization and blocked memory access, is given a fairly thorough treatment. Again, matrix multiplication is given as a case study for the concepts and techniques discussed by the author.<br /> The software currently available for numerical algorithms is discussed in chapter 7. The IMSL and NAG packages are emphasized, but the author gives a very long list of the packages that are available, both commercially and as freeware.<br /> In chapter 8, the author returns to a discussion of mathematical modeling, wherein approximation techniques are emphasized. After a brief discussion of analytic models, the author moves right into the techniques used to approximate these models, such as discrete and function approximation. More functional analytic techniques are brought in to discuss how to quantify the distance from a model function to the function actually being modeled.<br /> The important technique of interpolation is discussed in chapter 9, and very thoroughly. Polynomial interpolation via Bernstein and Chebyshev polynomials is included, as well as the Horner, Clenshaw, Casteljau algorithms for finding the values of polynomials. Piecewise polynomial interpolation is also treated, as well as spline functions, the latter of which in particular is given a thorough treatment. Multivariate interpolation, along with tensor product interpolation is also discussed at the end of the chapter.al overhead of programs. Performance optimization, via such techniques as loop optimization and blocked memory access, is given a fairly thorough treatment. Again, matrix multiplication is given as a case study for the concepts and techniques discussed by the author. <br /> The software currently available for numerical algorithms is discussed in chapter 7. The IMSL and NAG packages are emphasized, but the author gives a very long list of the packages that are available, both commercially and as freeware. <br /> In chapter 8, the author returns to a discussion of mathematical modeling, wherein approximation techniques are emphasized. After a brief discussion of analytic models, the author moves right into the techniques used to approximate these models, such as discrete and function approximation. More functional analytic techniques are brought in to discuss how to quantify the distance from a model function to the function actually being modeled. <br /> The important technique of interpolation is discussed in chapter 9, and very thoroughly. Polynomial interpolation via Bernstein and Chebyshev polynomials is included, as well as the Horner, Clenshaw, Casteljau algorithms for finding the values of polynomials. Piecewise polynomial interpolation is also treated, as well as spline functions, the latter of which in particular is given a thorough treatment. Multivariate interpolation, along with tensor product interpolation is also discussed at the end of the chapter.	2001-06-29
1942704:US	50702879	R3L5H94E5YC33F	1578700116	717950322	The Handbook of Programming Languages (HPL): Functional, Concurrent and Logic Programming Languages	Books	4	9	9	N	N	Fairly good overview	This book is the last of the HPL series and covers some of the more  popular logic and functional programming languages. It is however somewhat outdated, since some up-and-coming functional programming languages, such as Haskell, are only mentioned and not treated in detail.<br /> The first chapter is a quick introduction to Lisp (2 pages) and is put into to set up the next chapter on Emacs Lisp. This chapter is written by R.J. Chassell, and gives a general overview of the main features of Emacs Lisp. The author does a good job of explaining the language, and how it fits into the functional programming paradigm. He uses an interesting diagrammatic representation, which he calls &quot;chest of drawers&quot; to explain how printed representations of Emacs Lisp are different from the internal representation in the computer. One can also see very clearly the lambda calculus origins of Lisp in this chapter. The definition of a function in Lisp clearly illustrates the effectiveness of functional programming in emulating the concept from mathematics. A function is thought of as a rule for computation that takes several arguments and returns a value. It can however have a &quot;side effect&quot; of changing the values of variables or the contents of data structures. It is this later pr<br />operty of a function in programming languages that can cause confusion to a mathematician-turned-programmer. Mathematicians are not accustomed to worrying about these side effects, only concerning themselves with the result of the function.  But the author does give a good explanation as to the importance of side effects in building programs. He is also careful to explain the different types of functions in Lisp, namely defined, anonymous, and primitive ones. The later are built-in ones that are written in C and provide performance enhancement. In addition, macros are distinguished from functions in that they merely serve as translators from user expressions to expressions to be evaluated by the Lisp interpreter. The &quot;fundamental&quot; functions &quot;car&quot;, &quot;cdr&quot;, and &quot;cons&quot; are also explained in detail, as functions that create and operate on lists.<br /> In chapter 3, the author Brian Harvey discusses the language Scheme, and he endeavors to illustrate the simplicity of Scheme as a programming language. Because of its simplicity, Scheme has been used as a teaching tool in courses on computer languages and general programming. The author shows how Scheme is related to Lisp, and most importantly, he emphasizes the composition of functions (recursion) as being the primary control mechanism in Scheme. He makes a good case for the use of functional programming as a methodology for obtaining clarity and economy of thought in writing programs. The ability of Scheme to perform garbage collection contributes greatly to Scheme's ease of use. For example, Scheme employs lists in preference to arrays, with lists being dynamically allocated data structures, and the elements of the list can themselves be lists. In addition, and also very important, is the capability of Scheme to implement untyped variables. Mixing data types is a very powerful capability when attempting to write programs that are written to study complicated ideas and constructions from pure mathematics. The author also outlines the ability of Scheme to do tail call elimination, emphasizing that Scheme is the first language in which to guarantee this as part of its language specification. Recursive calls can be expensive for performance, but this capability allows conventional &quot;for&quot; and &quot;while&quot; processing to take place. For the beginner to Scheme, or functional programming, the author gives a useful discussion on common programming problems at the end of the chapter.<br /> In the next chapter, the author Jim Blandy gives an overview of Guile. I did not read this chapter so I will omit its review.<br /> In chapter 5, Jim Vietch discusses CommonLisp Object System (CLOS), which is an attempt to make Common Lisp an object-oriented programming language. The author gives a good historical introduction to CLOS and outlines its main features. The author compares CLOS with C++ and Smalltalk at various places in the chapter, which is helpful to programmers who are familiar with these latter languages and want to learn about how to do OO-programming in a functional programming language. The author does a good job of explaining the metaobject protocol (MOP), which allows overriding of the standard CLOS semantics. The author is convincing in his arguments of how MOP can add clarity and efficiency in OO-programmming. In addition, an effective discussion, using various code examples, is given of the power of dependency tracking and lazy evaluation. For me personally, lazy evaluation has been the tour-de-force behind functional programming and one of its most powerful features. Towards the end of the chapter, the author gives a good overview of performance issues with CLOS and a few hints on how to improve it.<br /> The last chapter of the book covers Prolog, and is written by James Andrews. From the standpoint of mathematical logic, Prolog is based on the theory of Horn clauses, instead of the lambda calculus. Thus it could be described as a logic programming language, and this is the characterization given by the author in this book. Commercial Prolog compilers are now available, but the use of Prolog has executed a sort of random walk since its invention in the early 1970s. The author discusses, objectively I think, the misconceptions and problems with the use of Prolog. The main properties of Prolog are summarized very well in the article, with rules and recursion being the main expressive and computational strategies employed in Prolog. A program in Prolog is a sequence of (Horn) clauses, and the author shows how a Prolog program is able to arrive at a conclusion (or output) based on the rules and facts given in the program, which is effectively a depth-first search algorithm. The author also gives a nice discussion on the advanced features of Prolog, including negation, cuts, and predicates.mmon Lisp Object System (CLOS), which is an attempt to make Common Lisp an object-oriented programming language. The author gives a good historical introduction to CLOS and outlines its main features. The author compares CLOS with C++ and Smalltalk at various places in the chapter, which is helpful to programmers who are familiar with these latter languages and want to learn about how to do OO-programming in a functional programming language. The author does a good job of explaining the metaobject protocol (MOP), which allows overriding of the standard CLOS semantics. The author is convincing in his arguments of how MOP can add clarity and efficiency in OO-programmming. In addition, an effective discussion, using various code examples, is given of the power of dependency tracking and lazy evaluation. For me personally, lazy evaluation has been the tour-de-force behind functional programming and one of its most powerful features. Towards the end of the chapter, the author gives a good overview of performance issues with CLOS and a few hints on how to improve it. <br /> The last chapter of the book covers Prolog, and is written by James Andrews. From the standpoint of mathematical logic, Prolog is based on the theory of Horn clauses, instead of the lambda calculus. Thus it could be described as a logic programming language, and this is the characterization given by the author in this book. Commercial Prolog compilers are now available, but the use of Prolog has executed a sort of random walk since its invention in the early 1970s. The author discusses, objectively I think, the misconceptions and problems with the use of Prolog. The main properties of Prolog are summarized very well in the article, with rules and recursion being the main expressive and computational strategies employed in Prolog. A program in Prolog is a sequence of (Horn) clauses, and the author shows how a Prolog program is able to arrive at a conclusion (or output) based on the rules and facts givenin the program, which is effectively a depth-first search algorithm. The author also gives a nice discussion on the advanced features of Prolog, including negation, cuts, and predicates.	2001-06-27
1943369:US	50702879	R3HQQRRSLQYOA3	0201309564	76819262	Generic Programming and the STL: Using and Extending the C++ Standard Template Library	Books	4	12	13	N	N	Pretty good job	The language C++ cannot be thought of as a mere extension to the C language. It supports object-oriented programming, and even more importantly, the generic programming paradigm. This book gives an overview of how C++ fits into the generic programming paradigm, and the author does a decent job of explaining how this is done. Anyone familiar with C++ and the Standard Template Library should have no problem following the dialog in the book. The approach taken by generic programming can be very abstract, but it is extremely powerful, and one that allows generality and economy of thought in programming.<br /> After a brief summary of the STL in chapter 1, the author moves on to studying linear search and iterators in chapter 2. The author stresses the need to design algorithms that are independent of the data structures they operate on. The discussion sets up the terminology and concepts for later chapters on function objects and containers in later chapters. The author introduces the idea of a concept, which is essentially a collection of type requirements, types, and valid programs. Readers with a background in mathematical logic are referred to the references for a discussion of the connection between concepts and the theory of many-sorted algebras. Iterators are introduced as five different types of concepts, these all serving as a generalization of pointers. The five kinds of iterator concepts are discussed in detail in the chapter. These concepts do have properties in common, and this leads the author to consider refinements of concepts. In addition, the different iterator concepts allow the author to classify generic algorithms according to the iterator concepts it uses.<br /> The discussion of iterators is continued in the next chapter, where iterator traits and associated types are discussed. The idea of an iterator value type is introduced as the object type the iterator points to. The author introduces, interestingly, a generalization of the type overloading capability of C++ to concept overloading, and he shows in detail how to emulate concept overloading in C++ .<br /> Function objects, which I consider one of the most powerful and useful concepts in generic programming, are discussed in chapter 4. Function objects are introduced as entities that can parameterize any kind of operation, and the author gives good arguments to show that every algorithm can be generalized by abstracting some part of its behavior as a function object. The associated types of a function object are the types of its arguments and return values. The composition of functions, so familiar in elementary mathematics, is here generalized to function objects via function object adaptors. Thus one can view function objects as entities behaving as expected in a mathematical sense.<br /> Containers are then introduced in chapter 5, essentially as generalizations of arrays, and the author stresses that the elements of a container are actual objects and not addresses. This &quot;value semantics&quot; of containers is shown to be a useful strategy by the author.<br /> The next part of the book begins an overview of generic programming concepts that are applicable in general, and not just the STL. STL though is given as an example in the discussion, and this is somewhat disappointing given the emphasis on generality. But the author does outline with clarity the important constructions in generic programming, such as iterators, function objects, and containers. Therefore this part of the book does serve as a good reference manual.<br /> The next part is a reference manual on the algorithms and classes available in the STL. The discussion on memory management primitives is useful for it gives information on the algorithms used to manipulate uninitialized storage in order to implement containers. Nonmutating algorithms, which are used for operating on a range of iterators without changing the elements they point to, are given a good overview, as are mutatingalgorithms, which modify the values pointed to by a range of iterators. The discussion of the predefined function objects is also useful, as they implement most of the standard arithmetic operations, such as multiplication and addition, and the logical operations, such as AND and OR. In addition, the discussion of member function adaptors is useful since it shows the reader how to call member functions as function objects. A polymorphic function call will result if the member function is virtual, and this, the author states, is a link between generic programming and OO-programming in C++<br /> The very important Vector class is discussed also, stressing its ability for automatic memory management. In my experience, the Vector class has been one of the most useful features of the STL.ating algorithms, which modify the values pointed to by a range of iterators. The discussion of the predefined function objects is also useful, as they implement most of the standard arithmetic operations, such as multiplication and addition, and the logical operations, such as AND and OR. In addition, the discussion of member function adaptors is useful since it shows the reader how to call member functions as function objects. A polymorphic function call will result if the member function is virtual, and this, the author states, is a link between generic programming and OO-programming in C++<br /> The very important Vector class is discussed also, stressing its ability for automatic memory management. In my experience, the Vector class has been one of the most useful features of the STL.	2001-06-26
1943656:US	50702879	R120QL6V4E4CTD	0130166294	219873582	Introduction to MFC Programming with Visual C++	Books	4	53	58	N	N	Good introduction with many code examples	For reader who has a fairly good background in C++, this book is a good introduction to MFC programming/Visual C++. It is written for individuals who want an in-depth practical understanding of MFC programming, and who are willing to put the time and effort into the learning of it. The book includes a CD which includes the 90 different sample programs in the book.<br /> In chapter 1, the author introduces MFC utility objects in console applications. The three utility classes CString, CPoint, and CRect are used to create a simple Windows application. The author is careful to distinguish between a console application, which has the main() function, and a windows program, which does not. The CString class is used, instead of the standard C++ library class, and this is standard in MFC programming. The author advises the reader to think of CString objects as an actual object, and not as a pointer to a string.  This is an example of value (or &quot;copy&quot;) semantics, wherein the value is copied, and not just the pointer. Programmers concerned about performance issues commonly use this feature of C++. The author gives an interesting method to extract a string from a stream into a CString object, and how to use the Format() function to convert a value to a string for eventual display in a window.<br /> A review of classes in C++ is given in Chapter 2, with emphasis on how virtual functions get executed in windows applications. The author shows explicitly how to use Visual Studio to add a class and member functions, and a good discussion is given on the difference between passing parameters by value, by reference, and by pointer. The role of the member function \\"this\\" is discussed also.<br /> Chapter 3 could be skipped by the reader interested only in MFC windows applications, according to the author, where he discusses collections and class templates. Object and pointer array collections are treated via the code examples. The author discusses the three different ways of performing tasks on collections, and discusses how to use pointers to objects, which is very advantageous from a memory management point of view. He is also gives an interesting discussion on serialization.<br /> The actual building of MFC Windows programs begins in Chapter 4, without using the AppWizard. The event handling via keyboard and mouse input is given the main emphasis, and the author gives a detailed discussion on the steps taken by a window event. The different types of member functions in the CMainFrame class are given a thorough treatment. The reader is first asked to use an MFC virtual function in this chapter.<br /> In the next chapter, the author shows how to get graphics shapes in the windows, via device context attributes. This is followed in Chapter 6 by a discussion on how to use the mouse and keyboard to make changes to text and graphics.<br /> The window controls are then discussed in Chapter 7, and the author gives a very detailed discussion on how controls fit in to CMainFrame. The process by which event and notification messages are handled is summarized in a diagram. List boxes, combo boxes, and scroll bars are all treated in detail using the example programs. This is followed naturally in Chapter 8 by a discussion of menus and dialog boxes in the context of resource editors.<br /> Finally in Chapter 9, the author uses the AppWizard to generate an application. A simple program example begins the discussion, followed by a non-document application. The author carefully explains the steps used in the AppWizard to give the reader more insight on just how it is able to do its job. Then in Chapter 10, the AppWizard and the ClassWizard are used to refine and extend the discussion on menus, toolbars, and dialogs. A good program example is given for a dialog-based application.<br /> Time-dependent messaging and XOR drawing mode are the subjects of the next chapter. The three functions for timer control are discussed, along with a discussion of animation. This is followed in Chapter 12 by a treatment of bitmap graphics, with bitmap editors via MS Paint discussed.<br /> Messaging via the MFC functions SendMessage() and PostMessage() is discussed in Chapter 13. These functions are discussed in a setting more general than modeless dialogs. Modeless dialogs are however discussed in detail in the chapter, and the difference between modal and modeless dialogs clearly explained.<br /> The next chapter of the book discusses how to use the document view architecture and the author shows in detail the major classes involved in its use. The reader can see the CMainFrame object as a container object, which will adjust the sizes of the windows it contains if the mainframe window is resized. The document and view classes are derived from the CDocument and CView classes. The discussion is helpful in that it shows how to use the member functions in these classes to propagate information to all views. The author also shows how to serialize the document objects.<br /> In the last chapter the author shows the reader how to use Visual C++ to manipulate an existing ODBC database. The discussion is very brief, but it does the reader with database knowledge of how to generate code to interact with these databases.ion of animation. This is followed in Chapter 12 by a treatment of bitmap graphics, with bitmap editors via MS Paint discussed.<br /> Messaging via the MFC functions SendMessage() and PostMessage() is discussed in Chapter 13. These functions are discussed in a setting more general than modeless dialogs. Modeless dialogs are however discussed in detail in the chapter, and the difference between modal and modeless dialogs clearly explained. <br /> The next chapter of the book discusses how to use the document view architecture and the author shows in detail the major classes involved in its use. The reader can see the CMainFrame object as a container object, which will adjust the sizes of the windows it contains if the mainframe window is resized. The document and view classes are derived from the CDocument and CView classes. The discussion is helpful in that it shows how to use the member functions in these classes to propagate information to all views. The author also shows how to serialize the document objects. <br /> In the last chapter the author shows the reader how to use Visual C++ to manipulate an existing ODBC database. The discussion is very brief, but it does the reader with database knowledge of how to generate code to interact with these databases.	2001-06-26
1947437:US	50702879	R1BXFRICB04XR4	1884133258	278865393	Jamsa's C/C++ Programmer's Bible	Books	3	3	3	N	N	Fairly good reference	This book, one of many written on C and C++ gives a summary of the structure and syntax of these two languages, and gives an introduction to the Standard Template Library and Windows programming. It is best used as a reference and not as a textbook, since there are no exercises or coding problems in the book. Some of it is out-dated, particularly the section on Windows programming, and an overview of that topic is best done with a book on the latest version of Visual C++. The authors do attempt to be comprehensive, and treat most of the main features of C and C++, but some important topics, such as performance issues with C++ versus C, are not discussed. It is a suitable reference for those who have considerable expertise in these two languages.<br />The first 800 paragraphs cover the C programming language, and the authors do a pretty good job of summarizing the main properties of the language. Some of the strong points in the discussion include: type modifiers, compiler pragmas, preprocessor condition testing, the functions atof, atoi, and atoll, formal versus actual parameters, function overhead, call by value and (pointer) reference, recursion, calling assembly language functions, the va_arg, va_start, and va_end macros, tradeoff between arrays and dynamic memory, quick sort, pointer arithmetic, DOS and BIOS services, memory management, memory models, the tzset function, the MAKE utility, linked lists, child processes, interrupts, invariant code, inlining, fast function calls, and code compaction. The authors give a large amount of sample code to illustrate these concepts.<br />The next 450 paragraphs give an overview of the C++ programming language, emphasizing it as an extension of C, and not as an independent object-oriented language. There are very effective discussions on: anonymous unions, the global resolution operator, lazy evaluation (this was particularly helpful), the 3 different ways to pass parameters in C++, the inline keyword, operator overloading, the scope resolution operator, when to use inline and out-of-line functions, friend classes, constructor functions, overloading with friend functions, multiple inheritance, mutual friend classes, inline assembly language statements in method functions (particularly useful discussion), the THIS pointer, implementing polymorphism, generic functions, exception handling, namespaces, the doubly linked list class, containers, iterators, and the vector class (very well written!).<br />I will omit reviewing the last part of the book on Windows programming since it is out of date and is treated more effectively elsewhere.ng, the scope resolution operator, when to use inline and out-of-line functions, friend classes, constructor functions, overloading with friend functions, multiple inheritance, mutual friend classes, inline assembly language statements in method functions (particularly useful discussion), the THIS pointer, implementing polymorphism, generic functions, exception handling, namespaces, the doubly linked list class, containers, iterators, and the vector class (very well written!).<br />I will omit reviewing the last part of the book on Windows programming since it is out of date and is treated more effectively elsewhere.	2001-06-23
1948128:US	50702879	R3KN05930US1GN	0387989811	770323770	Diophantine Geometry: An Introduction (Graduate Texts in Mathematics)	Books	5	21	27	N	N	Fascinating subject	The subject of this book is now over 1900 years old, and it grows more fascinating year after year. The study of solutions of polynomial equations over the integers is now called Diophantine geometry, and is brilliantly outlined by the authors in this book. Avoiding the use of schemes, the author's goal in the book is to prove the Mordell-Weil theorem, Roth's theorem, Siegel's theorem, and Falting's theorem.<br /> The first part of the book gives a review of the geometry of curves and Abelian varieties for the reader who has only an elementary knowledge of algebraic geometry. But the authors emphatically recommend that the first part NOT be read, as this will prevent the reader from reaching the important ideas in the later parts. But all the standard results from algebraic geometry, such as local rings, heights, divisors, intersection numbers, ampleness, sheaves, Riemann surfaces, and a brief discussion of schemes is given.<br /> This is followed by a very well-written presentation of the theory of height functions. The concept of a height function is explained very carefully, as well as its role in translating geometric information about a variety into arithmetic information about the rational points on the variety. A brief but introduction to Arakelov theory is given in this part also.  The Mordell-Weil theorem, which states that the group of rational points on an Abelian variety is finitely generated, is proven in the next part of the book. This theorem, the generalization of the famous tangent and chord construction for elliptic curves, is proven using the theory of heights and Fermat descent, via the weak Mordell-Weil theorem. This theorem treats the case where the group of rational points has been factored out by dividing its points by an integer greater than or equal to 2. The resulting quotient group is shown to be finite and this then implies the stronger version of the theorem. In an appendix, they give a very interesting analysis of the proof in terms of Galois cohomology and the Selmer and Tate-Shaferevich groups.<br /> In the next part of the book, the authors take a look at Diophantine approximation and give a proof of Roth's theorem, namely that an algebraic number has finitely many approximations or order 2 + epsilon. What is unique about the discussion is the clarity of the author's presentation, I have not seen it done as clearly as is done in this book. They summarize the main points behind the proof of the theorem before getting into the details. This makes it much easier for the reader to appreciate the constructions involved in the proof. Then, using the techniques of this part and the theory of heights, also prove in this part the theorem of Siegel, that every curve of genus greater than or equal to one has only finitely many rational points.<br /> The next part is dedicated to proving Falting's theorem, which states that every curve of genus greater than or equal to 2 has finitely  many rational points. The proof the authors discuss though is not based on Faltings original proof, which used highly sophisticated techniques from scheme and stack theory, but the proof of E. Bombieri, which uses classical Diophantine approximation theory, height theory, and concepts from the classical theory of surfaces. The discussion is fascinating and very clearly presented.<br /> The authors close the book with a discussion on generalizations and open problems in the field of Diophantine geometry. The interesting abc-conjecture is discussed and shown to imply Falting's theorem and an asymptotic version of Fermat's last theorem. Most interestingly though, and one of the major reasons why I purchased this book, is the discussion on the effective computation of the relevant finite groups, such as the Mordell-Weil group. The four main theorems in the book are qualitative statements about the finiteness of the groups, they do not attempt to give an algorithm to compute the elements of the finite set. The case of elliptic curves and their torsion subgroups is presented as a theorem, but the proof is not given unfortunately. The authors do discuss the case for the rank of the Mordell-Weil group in terms of an algorithm given by Y. Manin, which is dependent on the resolution of a number of unproven conjectures which they discuss in this part. The authors also discuss the effective computation of rational points on curves in terms of moduli spaces, Arakelov theory, Mordell-Weil groups, and the abc conjecture/uniformization. Although brief, they do give many references for further reading. In addition, a short discussion on finding quantitative bounds on the number of elements in the groups is given. The authors then wrap up with a brief discussion of the Bombieri-Lang and Vojta conjectures. It is intriguing in all of this discussion on the role elliptic curves have furnished as a testing ground for most of the conjectures and results.liptic curves and their torsion subgroups is presented as a theorem, but the proof is not given unfortunately. The authors do discuss the case for the rank of the Mordell-Weil group in terms of an algorithm given by Y. Manin, which is dependent on the resolution of a number of unproven conjectures which they discuss in this part. The authors also discuss the effective computation of rational points on curves in terms of moduli spaces, Arakelov theory, Mordell-Weil groups, and the abc conjecture/uniformization. Although brief, they do give many references for further reading. In addition, a short discussion on finding quantitative bounds on the number of elements in the groups is given. The authors then wrap up with a brief discussion of the Bombieri-Lang and Vojta conjectures. It is intriguing in all of this discussion on the role elliptic curves have furnished as a testing ground for most of the conjectures and results.	2001-06-23
1948337:US	50702879	R3ENDROPVWPR8V	1850328803	687054361	Software Testing Techniques, 2nd Edition	Books	4	21	23	N	N	Useful summary of software testing strategies	Every professional and commercial software development organization spends a great deal of time in the testing and validation of their software. The testing process, driven either by legal or financial requirements, can be expensive and may thwart the planned deployment of the application. Many studies indicate that the testing process can even take three times as long as the actual coding itself. Indeed, software development done under the ISO 9000 or FDA auspices can be extremely time intensive.<br /> This book gives a lengthy and fairly comprehensive overview of software testing that emphasizes formal models for testing. In the introduction, the author gives a general overview of the testing process and the reasons and goals for testing. He carefully distinguishes between testing and debugging, and advocates these as separate activities. Testing according to the author is done to find bugs; whereas debugging is done to find the origin of the bugs and fix them. The author characterizes testing as either functional or structural. Functional testing treats the program from the user's point of view, with inputs given to the program, and then the outputs are checked for conformance to a specified reference. Structural testing examines how the program is implemented, in terms of programming style, design, etc. The notion of an oracle is defined as any program or process that specifies the expected outcome of a collection of tests. The author clearly identifies and characterizes the different types of tests that arise in development organizations, such as unit testing, regression testing, stress testing, and integration testing.<br /> In chapter 2, the author classifies the different types of bugs that could arise in program development. Bugs are classified according to functional, structural, data, coding, system, and design and test bugs. He stresses the need to not have a religious attitude about bugs, namely that all software will have them to some degree, and therefore it is the quality measure of the software that is important in deploying the application. If a minor bug requires a major software rewrite for example, it would not be advantageous to fix this bug.<br /> Chapter 3 takes up the notion of path testing, which, according to the author, is based on the use of the program's flow control. The tester selects a set of test paths through the program with the goal of executing every statement and branch of the program at least once. The author summarizes well the flowgraph and process block techniques used to implement path testing.<br /> In chapter 4, the author introduces the concept of a transaction flow as a representation of a system's processing. The flowgraphs developed in chapter 3 are used here to create a transaction flowgraph for functional testing. The transaction flow representation gives a way to model the system's behavior. The author's treatment here is very detailed, and he gives several useful tips on how to conduct this kind of testing.<br /> The next chapter covers the topic of data-flow testing, where again flowgraphs are used, but this time the focus is on exploring the things that can happen to data. Data objects should be initialized prior to program execution, and selecting paths to insure this is the goal of data testing. The author does a good job of defining and characterizing data anomalies, and the strategies employed in static and dynamic anomaly detection. This is followed by a good overview of domain testing in chapter 6. This kind of testing, more mathematical in nature than others, attempts to test whether the inputs to programs are fulfilling some prior classification or specification. The author uses concepts from vector spaces and convex geometry to describe domain testing.<br /> In chapter 7, several attempts are discussed to quantify program complexity, such as Halstead's metrics and token counts. This chapter is somewhat more theoretical at first glance, but a lot of these ideas have found practical application in development, particularly the measures for subroutine nesting. This is followed in the next two chapters by more abstract discussion involving paths, regular expression, and syntax testing. The discussion however is useful, for it trains the reader about how to think about a program in more general, linguistic terms. Such thinking is always useful when attempting to show a particular program is acting in ways other than that which it was designed for.<br /> Logic-based testing, via Boolean algebra, is the topic of chapter 10. The author uses Karnaugh-Veitch charts to reduce the algebraic manipulations to a useful graphical representation. Finite-state machines, so useful in all areas of software engineering, are the topic of chapter 11. The concepts are presented very effectively by the author, and the reader should take away an appreciation of how these constructions are employed in software testing.<br /> The next chapter reads like one straight out of a book on discrete geometry, wherein graph matrices are employed to give matrix representations in software. Linked lists are used to represent the graphs in a computer, and it is shown how testing problems can be represented as a graph problem.<br /> The last chapter discusses how to implement software testing based on the strategies discussed in the book. The three-phase test scenario is described, namely unit, integration, and system testing. An overview of commercial testing tools is also given, with CASE mentioned, but the author chooses not to review the actual packages, citing the dynamic nature of the commercial situation. However he does give a useful discussion of the different characteristics of current testing tools.eas have found practical application in development, particularly the measures for subroutine nesting. This is followed in the next two chapters by more abstract discussion involving paths, regular expression, and syntax testing. The discussion however is useful, for it trains the reader about how to think about a program in more general, linguistic terms. Such thinking is always useful when attempting to show a particular program is acting in ways other than that which it was designed for. <br /> Logic-based testing, via Boolean algebra, is the topic of chapter 10. The author uses Karnaugh-Veitch charts to reduce the algebraic manipulations to a useful graphical representation. Finite-state machines, so useful in all areas of software engineering, are the topic of chapter 11. The concepts are presented very effectively by the author, and the reader should take away an appreciation of how these constructions are employed in software testing. <br /> The next chapter reads like one straight out of a book on discrete geometry, wherein graph matrices are employed to give matrix representations in software. Linked lists are used to represent the graphs in a computer, and it is shown how testing problems can be represented as a graph problem. <br /> The last chapter discusses how to implement software testing based on the strategies discussed in the book. The three-phase test scenario is described, namely unit, integration, and system testing. An overview of commercial testing tools is also given, with CASE mentioned, but the author chooses not to review the actual packages, citing the dynamic nature of the commercial situation. However he does give a useful discussion of the different characteristics of current testing tools.	2001-06-22
1949356:US	50702879	R1P2WHFQJZIMAC	0262031418	608833205	Introduction to Algorithms (MIT Electrical Engineering and Computer Science)	Books	5	12	16	N	N	Useful overview	This book has served well the needs of many researchers, scientists, and software developers since it was first printed in 1990. The authors have done a first-class job, and no-doubt the book will continue to be a good source of information in the next decade. Pseudocode is used to illustrate how to eventually code the algorithms, and exercises abound throughout the book. It has been, and will continue to be used as an effective textbook.<br /> After a comprehensive overview of the mathematical foundations, the authors treat sorting algorithms, with heapsort, quicksort, and order statistics treated in great detail. They give an asymptotic analysis of the algorithms, and give an introduction to randomized algorithms in the discussion of quicksort. I found the discussion on order statistics very helpful for studying data polling algorithms in networks.<br /> The authors then discuss data structures and how they can be used to construct algorithms for different problems. Queues, stacks, linked lists, and trees are discussed in detail, and the authors give asymptotic analyses for hashing and searching algorithms. The very important area of dynamic programming is also discussed at length. From the standpoint of someone interested in network modeling, I found the discussion of Dijkstra's algorithm especially well written. Unfortunately, the authors do not discuss in detail the Ajtai-Komlos-Szemeredi sorting algorithm. The treatment of this algorithm in the original paper is difficult reading so a better presentation would have been nice here. Parallel algorithms are given a nice treatment. The Fast Fourier Transform is given an interesting application to O(n lgn) multiplication of polynomials.<br /> For readers interested in cryptography, the authors discuss the algorithm for the RSA cryptosystem. Primality testing is also treated, with the Miller-Rabin probabilistic algorithm given a nice treatment. The Pollard rho method for integer factorization is also discussed.<br /> I found the discussion of string matching also very useful from the standpoint of computational biology. The Rabin-Karp and Knuth-Morris-Pratt algorithms are both treated in great detail.<br />A short but good introduction to algorithms in computational geometry, such as the gift-wrapping algorithm in convex geometry, is given.<br />  The authors thus cover a large amount of material here, and each chapter could itself be a 1000-page book. But their selection of algorithms in each of the areas covered serves well to introduce the reader to the more popular ones available. A large list of references is given for further reading on revisions and extensions to these algorithms.br /> I found the discussion of string matching also very useful from the standpoint of computational biology. The Rabin-Karp and Knuth-Morris-Pratt algorithms are both treated in great detail. <br />A short but good introduction to algorithms in computational geometry, such as the gift-wrapping algorithm in convex geometry, is given. <br />    The authors thus cover a large amount of material here, and each chapter could itself be a 1000-page book. But their selection of algorithms in each of the areas covered serves well to introduce the reader to the more popular ones available. A large list of references is given for further reading on revisions and extensions to these algorithms.	2001-06-22
1951943:US	50702879	RN4FPNP3LF4O7	3540629718	546651934	Clause and Effect: Prolog Programming for the Working Programmer	Books	4	24	24	N	N	Serves its purpose well	For those who have experience in logic programming, either with Prolog or some other language, such as Lisp, or even a high-level symbolic programming language like Mathematica or Maple, this book could serve as a first course or a summary of Prolog programming. Research in logic programming is still an active area, and the approach taken in logic programming languages seems more natural from the standpoint of mathematical (predicate) logic. The author, in this short book, gives the reader an appreciation of Prolog and the philosophy and constructions behind logic programming. Many examples are employed that illustrate how to code in Prolog and how useful it can be in real-world applications.<br /> In the first chapter, the author gives some justification for programming in Prolog, such as its symbol manipulation capability, automatic backtracking, the view that data structures and programs are of the same form, and the relational form of clauses. The syntax of Prolog is then discussed, and examples given of the three kinds of terms in Prolog. Readers with some background in category theory will appreciate the discussion more, as the author does employ some of this in the discussion, for example the view of addition as being a functor of a term. Terms are drawn in tree form in this chapter and throughout the book. The author then characterizes a Prolog program as a set of procedures, with each defining a predicate, and consisting of one or more (Horn) clauses. Unification of terms is discussed as a basic operation that determines when two clauses can be made equivalent by a substitution of variables. The execution of a program is viewed as a querying of the clauses, and the goal or e nd of the program is a proof that the goal is true.<br /> Data structures in Prolog are discussed in chapter 2 as generalizations of programs using compound terms instead of just constants and variables. Lists are defined and their syntax discussed, along with dot and bracket notation. The implementation of simple arithmetic in Prolog is discussed. Several effective examples are given to illustrate arithmetic and list manipulation in Prolog.<br /> Mappings, which are relations between two data structures, are the topic of chapter 3, and the author gives many examples illustrating how it is used to compose Prolog programs and how they act an both lists and more general trees.<br /> The built-in predicate &quot;cut&quot; is discussed in the next chapter as a predicate to allow backtracking control of the program. The author gives many examples illustrating the problems involved with the use of &quot;cut&quot;.<br /> Difference structures are discussed in chapter 5 as a tool to simplify and increase program efficiency. A generalization of the idea of an accumulator, they allow one to work with &quot;holes&quot; in data structures during actual program execution. A list for example, can be viewed as &quot;open&quot; with its elements known only up to a point. It can then be filled in with an empty or a proper list. A difference list, discussed in the chapter, is then a list represented as a pair of &quot;front&quot; and &quot;back&quot;, with the back being variable.<br /> Applications of term rewriting are given in chapter 6, with symbolic differentiation launching the discussion. This is the more popular example of what Prolog-type languages can do, and is usually the reason given for beginning the use of symbolic programming languages. The author also discussed matrix multiplication in this chapter.<br /> The next two chapters discuss the representation and manipulation of logical circuits using Prolog, including shift registers and coding circuits. This is followed in chapter 9 by an interesting discussion on how to write a compiler in Prolog, with the author discussing compilation for a single-accumulator computer, a RISC machine, and a stack machine. This is followed in chapter 10 by an even more interesting discussion on how to write a Fast Fourier transform in Prolog.<br /> The last chapter of the book discusses how to use higher-order functional programming techniques in Prolog. For individuals, like myself, who are convinced that functional and logic programming are the most effective programming paradigms, this chapter is very interesting reading. The author defines an evaluator written in Prolog for these higher-order functional programs. Functional programming views computation as a collection of function applications on an expression representing a particular problem, and these functions can then be viewed as arguments to other functions. The lambda calculus from mathematical logic serves as the foundation for functional programming, and the author reviews this quickly, along with the technique of currying, in order to obtain facilities for functional programming in Prolog. Although short, this chapter introduces the reader to a fascinating area, and helpful references are given at the end of the chapter.ast Fourier transform in Prolog. <br /> The last chapter of the book discusses how to use higher-order functional programming techniques in Prolog. For individuals, like myself, who are convinced that functional and logic programming are the most effective programming paradigms, this chapter is very interesting reading. The author defines an evaluator written in Prolog for these higher-order functional programs. Functional programming views computation as a collection of function applications on an expression representing a particular problem, and these functions can then be viewed as arguments to other functions. The lambda calculus from mathematical logic serves as the foundation for functional programming, and the author reviews this quickly, along with the technique of currying, in order to obtain facilities for functional programming in Prolog. Although short, this chapter introduces the reader to a fascinating area, and helpful references are given at the end of the chapter.	2001-06-20
1954391:US	50702879	R3SMPX7XIY8E4K	189311595X	575919020	Cryptography in C and C++	Books	4	69	71	N	N	Helpful	This book is an introduction to cryptography from a practical perspective and emphasizes how to write the code to implement it in real-world applications. The author has chosen the languages C and C++ to write the code, and this is acceptable since current cryptographic algorithms are usually written in these languages. The RSA and the new Rijndael algorithms are treated in detail, but unfortunately, the author has chosen not to discuss elliptic curve cryptography. The level of the book is suitable for the newcomer to cryptography, and assumes a strong knowledge of C and C++. Some background in number theory and algebra is also assumed.<br /> In chapter 1, the author discusses briefly how the natural numbers are constructed via the Peano axioms. This discussion could have been omitted easily, for not enough detail is given, and one only needs to assume the natural numbers for the purpose of a book such as this. A full treatment of the construction of the natural numbers can be found elsewhere. The software used in the book is summarized in this chapter.<br /> In chapter 2, the author begins to discuss the most important initial task for any implementation of cryptography, namely the problem of representing large numbers in  computer memory. For performance reasons, the author chooses not to use dynamic memory management for large numbers, but instead uses a definition of static length. Large integers are represented by means of &quot;unsigned short int&quot;. The software in the book makes use of assembler functions for high performance arithmetic. Chapter 3 then discusses briefly the semantics of the function interface, with the usual discussion about output versus return values.<br /> Chapter 4 discusses C functions for arithmetic; there are some sentences that have unclear meaning possibly because of the translation. Karatsuba multiplication is treated and its performance compared with the usual multiplication, but is not used in the book. The division algorithm receives a very detailed treatment. This is followed in the next two chapters by a discussion of modular arithmetic. The important Montgomery algorithm is treated, and its importance in cryptography is discussed in great detail. This is followed in the next chapter by the functions used for implementing bitwise operations.<br /> After a treatment of assignment and I/O in chapter 8, the author shows how to create functions for manipulating registers. This is a very helpful discussion, and implements ideas from the literature that are not usually found in books. Then in chapter 9, the author constructs C functions to do more high-level number-theoretic arithmetic, such as finding the multiplicative inverse and square roots in residue class rings. In addition, the author discusses in detail the Rabin, Fiat, and Shamir encryption schemes that use quadratic residues and their roots. A very nice discussion is then given on primality testing, including the Solvay-Strassen probabilistic primality test.<br /> In chapter 11, a very short overview of random number generation is given. The Brent algorithm for determining periodicity is discussed, along with the chi-square test. The Blum-Blum-Shub algorithm for generating pseudorandom numbers is implemented in C.<br />  The importance of testing algorithms is treated in chapter 12, the author being aware of the ISO 9000 standard. It is very helpful that a discussion of testing be included in a book on cryptography, given the importance of security in modern business and military applications. Although this chapter is merely a short overview of software testing, the author does give many references and has included many test functions in C for the software developed in the book. The author returns to the topic of software testing in C++ in chapter 17 of the book.<br />  The author switches gears in the next chapter, which begins the second half of the book, where he begins to use C++ to develop the cryptographic code. In this chapter and the next, the constructors used for generating the large-integer objects are given, along with the operator overloading needed for processing these objects and the built-in C++ integer types simultaneously. Stream classes are used to define the functions for the formatted input of the large-integer objects. In this public interface, the author distinguishes between arithmetic and number theoretic functions. The latter do not overwrite the implicit first argument with the result, as do arithmetic functions, and so return values instead of pointers. Manipulators are used to control the output format for large-integer objects. This is followed in the next chapter by a short treatment of exception handling for the software developed in the book.<br />  Finally in Chapter 16, the author discusses the RSA cryptosystem, and in great detail. The idea of an asymmetric cryptosystem is discussed, and the RSA algorithm is implemented using C. The author discusses the strengths and weaknesses of the RSA algorithm, along with a discussion of digital RSA signatures. The algorithm is then implemented in C++ at the end of the chapter in great detail. Readers who have not seen the coding involved with the implementation of the RSA algorithm will definitely appreciate the treatment here.<br />  The last chapter of the book covers the new Rijndael algorithm and the Advanced Encryption Standard is discussed. This is the first time I have seen a discussion of the algorithm in a book, and the author does a good job. After a review of polynomial arithmetic over finite fields, the author outlines in detail the constructions employed in the algorithm. The reader is expected to know what a Feistel algorithm is though, since the author only devotes one sentence of explanation as to what it is. Although Feistel networks have long been employed in cryptography, newcomers to the field need a little more discussion here. On the enclosed CD-ROM, the author gives three implementations of the Rijndael algorithm.ode. In this chapter and the next, the constructors used for generating the large-integer objects are given, along with the operator overloading needed for processing these objects and the built-in C++ integer types simultaneously. Stream classes are used to define the functions for the formatted input of the large-integer objects. In this public interface, the author distinguishes between arithmetic and number theoretic functions. The latter do not overwrite the implicit first argument with the result, as do arithmetic functions, and so return values instead of pointers. Manipulators are used to control the output format for large-integer objects. This is followed in the next chapter by a short treatment of exception handling for the software developed in the book. <br />      Finally in Chapter 16, the author discusses the RSA cryptosystem, and in great detail. The idea of an asymmetric cryptosystem is discussed, and the RSA algorithm is implemented using C. The author discusses the strengths and weaknesses of the RSA algorithm, along with a discussion of digital RSA signatures. The algorithm is then implemented in C++ at the end of the chapter in great detail. Readers who have not seen the coding involved with the implementation of the RSA algorithm will definitely appreciate the treatment here.<br />       The last chapter of the book covers the new Rijndael algorithm and the Advanced Encryption Standard is discussed. This is the first time I have seen a discussion of the algorithm in a book, and the author does a good job. After a review of polynomial arithmetic over finite fields, the author outlines in detail the constructions employed in the algorithm. The reader is expected to know what a Feistel algorithm is though, since the author only devotes one sentence of explanation as to what it is. Although Feistel networks have long been employed in cryptography, newcomers to the field need a little more discussion here. On the enclosed CD-ROM, the author gives three implementations of the Rijndael algorithm.	2001-06-18
1956057:US	50702879	R1W0J0X3VQLVIR	0387949216	95702919	The Logic of Logistics: Theory, Algorithms, and Applications for Logistics Management (Springer Series in Operations Research and Financial Engineering)	Books	4	18	19	N	N	Rigorous overview of logistic modeling	Logistics has always been an integral part of industry and the military, and with the advent of the Internet, it has taken on major importance. This book gives a rigorous introduction to the formalism of logistics, and as such is fascinating reading for anyone interested in this area. Even individuals not into supply chain management and logistics engineering, and interested merely in the mathematics, will find this book interesting.  After a short overview of logistics in the introduction, the authors discuss worst-case analysis of various algorithms for the bin-packing and traveling salesman problems. They define two performance metrics to measure the worst-case effectiveness: the absolute and asymptotic performance ratios. The First-Fit, Best-Fit, First-Fit Decreasing, and Best-Fit Decreasing heuristics are discussed in detail for the bin-packing problem. The authors show that a polynomial time heuristic cannot have an absolute performance ratio less than 3/2. They also show that finding a heuristic for the traveling salesman problem with a constant worst-case bound is as difficult as solving any NP-complete problem. The minimum spanning tree based, nearest insertion, Christofides', and local search heuristics are all discussed in great detail.<br />  The next chapter considers the probabilistic analysis of algorithms via the characterization of the average performance of a given heuristic. The analysis is asymptotic with large problem sizes needed. Again, the bin-packing and traveling salesman problems are considered for studying this approach. This is followed by an approach to studying the efficacy of a particular heuristic by using mathematical programming in the next chapter. The strategy here is to cast the (NP-complete) problem as an integer problem, and then relax the constraint of integrality and solve the linear program. The authors showthat tight lower bounds can be found for these integer programs.  The authors switch gears somewhat in the next two chapters, where vehicle routing problems are studied. In particular, the single-depot capacitated vehicle routing problem with equal and unequal demands is analyzed via worst-case and probabilistic analysis. The analysis is generalized in chapter 7 for the case where time constraints are present. An analytical solution of this problem, called the vehicle routing problem with time windows, is considered in detail by the authors. They back up their analysis with computational results at the end of the chapter. In chapter 8, a column generation approach is employed to solve the vehicle routing problem. No time constraints are put in, and the authors give in detail the steps behind this technique.<br />  The study of inventory models is begun in chapter 9, with the economic lot size model leading off the discussion. This model illustrates effectively the tradeoffs between ordering and storage costs, and the optimal ordering policy is found. This model is generalized to the case where finite time horizons are included and the optimal policing found. Multi-item inventory models are then studied via worst-case analysis.  The Wagner-Whitin model, which is an inventory model with varying demands, is formulated and solved in the next chapter. The techniques used, interestingly, involve dynamic programming. This model is generalized to the case where there is an upper bound on the amount that can be ordered or produced, and then the optimal solution found.<br />  The case where the demand is a random variable is considered in the next chapter on stochastic inventory models. Single period and finite horizon models are considered using a dynamic programming algorithm to determine the optimal policy. The analysis makes heavy use of the properties of convex and quasiconvex functions.<br />  Facility location models are the subject of the next chapter. The p-Median, single-source capacitated facility location (CFLP), and distribution system design problems are analyzed as warehouse location problems, with Lagrangian relaxation techniques used to find the solutions to these problems.<br />  Logistics models that integrate inventory and routing strategies are considered in chapter 13, with the success of Wal-Mart given as an example of a firm whose success was generated by a reliance on  an efficient logistical design and planning model called cross docking. Along with analyses of zero inventory ordering policies, the authors give an asymptotic analysis of cross-docking strategies.<br />  The last two chapter of the book consider the implementation of logistic algorithms in practice. Although short, the chapters do give a fairly good overview of how these algorithms are used in the real world. The authors consider the routing and scheduling of New York City school buses and a decision support system for network configuration. Only one exercise is found in these chapters though unfortunately.analyzed as warehouse location problems, with Lagrangian relaxation techniques used to find the solutions to these problems. <br />    Logistics models that integrate inventory and routing strategies are considered in chapter 13, with the success of Wal-Mart given as an example of a firm whose success was generated by a reliance on  an efficient logistical design and planning model called cross docking. Along with analyses of zero inventory ordering policies, the authors give an asymptotic analysis of cross-docking strategies. <br />    The last two chapter of the book consider the implementation of logistic algorithms in practice. Although short, the chapters do give a fairly good overview of how these algorithms are used in the real world. The authors consider the routing and scheduling of New York City school buses and a decision support system for network configuration. Only one exercise is found in these chapters though unfortunately.	2001-06-17
1956225:US	50702879	RE0YJXA2LS0KT	0387976558	232369706	Brownian Motion and Stochastic Calculus (Graduate Texts in Mathematics) (Volume 113)	Books	5	55	69	N	N	The best introduction	The theory of Brownian motion is ubiquitous in physics and mathematics, and has recently become very important in mathematical finance and network modeling. The observation of the irregular movement of pollen suspended in water by Robert Brown in 1828 led Albert Einstein to formulate a theory for Brownian motion. In this book the authors outline rigorously the theory of Browian motion. Their logic is impeccable, and the content is fascinating reading, even to those very experienced in the subject.<br /> The authors begin in chapter 1 with the task of defining martingales and filtrations, with the notion of a stochastic process being adapted to a filtration taking on particular importance. They omit the proof that a process is progressively measurable if and only if it is measurable and adapted, because of the difficulty of the proof, but give a reference where the proof can be found. Continuous-time martingales are defined, with (compensated) Poisson processes given as an example. The Doob-Meyer decomposition and square-integrable martingales are discussed, and the chapter if full of exercises, with solutions provided to some of these at the end of the chapter.  Brownian motion is formally defined in the next chapter, with its existence proven using Wiener measure on the space of continuous functions on the positive half line. The discussion in this chapter has to rank as one of the best in print, due to the meticulous and precise manner in which the material is presented. The Markov property of Brownian motion is proven, along with a good presentation of the Levi modulus of continuity. Readers working in constructive quantum field theory will see their usual construction of Wiener measure in the second exercise of the chapter. Those working in that area are used to seeing (conditional) Wiener measure defined on a collection of cylinder sets, which is then extended to the Borel subsets . Such a construction is done in this book, but the approach is somewhat different than what physicists normally see in quantum field theory.<br /> The theory of stochastic integration is presented in Chapter 3, and it is superbly written. The authors are careful to distinguish the theory of integration for stochastic processes from the ordinary one with emphasis on the actual computation of stochastic integrals. The reader is first asked to explore the Stratonovitch and Ito integrals in an exercise., and then a thorough treatment is given by the authors later in the chapter. The authors point out the differences between the Ito and Stratonovich integrals, with the latter being defined for a smaller class of functions than the former. The important Ito rule for changing variables is discussed, and then used to give the Kunita-Watanabe martingale characterization of Brownian motion. Physicists involved in constructive quantum field theory will appreciate the discussion of the Trotter existence theorem in this chapter.<br /> The connection of Brownian motion with partial differential equations, so familiar to physicists via the heat equation, is the subject of the next chapter. These equations give the transition probabilities of the stochastic process, and are studied here first in the context of harmonic analysis, namely the classical Dirichlet problem. This is followed by a beautiful treatment of the one-dimensional heat equation and the Feynman-Kac formulas. Those readers working in constructive quantum field theory will see the Green's function lurking in the background.<br /> The very important topic of stochastic differential equations is outlined in chapter 5, with emphasis placed on the study of diffusive processes. The solutions of these equations have an immense literature, and the authors do not of course overview all of it, but do give a useful introduction. Both strong and weak solutions are discussed, with the Girsanov and Yamada-Watanabe techniques used throughout. Explicit solutions are given for linear stochastic differential equations, such as the Ornstein-Uhlenbeck process governing the Brownian motion of a particle with friction. Financial engineers will appreciate the discussion of the applications of this formalism to option pricing and the Merton consumption theory in this chapter. Options pricing is cast in martingale terms, and then the usual Black-Scholes equation is derived from this. The notorious Hamilton-Jacobi-Bellman equation is discussed in the consumption/investment problem, and the authors show how to employ techniques for solving this problem instead of solving this difficult nonlinear equation. The authors give a hint of the important Malliavin calculus in the Appendix and give references for the reader.<br /> The last chapter of the book is more specialized than the rest and deals with the Levy theory of Brownian local time. This theory does have a connection with the theory of jump processes, which are currently very important in financial and network modeling. The authors do a fine job of explaining how Poisson random measures permit the event bookkeeping in these jump processes. Their discussion is applied to the computing of the transition probabilities for a Brownian motion with two-valued drift.tial equations, such as the Ornstein-Uhlenbeck process governing the Brownian motion of a particle with friction. Financial engineers will appreciate the discussion of the applications of this formalism to option pricing and the Merton consumption theory in this chapter. Options pricing is cast in martingale terms, and then the usual Black-Scholes equation is derived from this. The notorious Hamilton-Jacobi-Bellman equation is discussed in the consumption/investment problem, and the authors show how to employ techniques for solving this problem instead of solving this difficult nonlinear equation. The authors give a hint of the important Malliavin calculus in the Appendix and give references for the reader. <br /> The last chapter of the book is more specialized than the rest and deals with the Levy theory of Brownian local time. This theory does have a connection with the theory of jump processes, which are currently very important in financial and network modeling. The authors do a fine job of explaining how Poisson random measures permit the event bookkeeping in these jump processes. Their discussion is applied to the computing of the transition probabilities for a Brownian motion with two-valued drift.	2001-06-17
1956666:US	50702879	R10P6H6T4HGQBC	0471180122	481644492	Object-Oriented Multithreading Using C++	Books	3	6	9	N	N	Fair overview	The subject of concurrency in software development has taken on particular importance these days due to the emphasis on multitasking in application environments. Users are expecting to be able to perform many tasks at once, and therefore applications must be written that will allow these tasks to be initiated and managed. The strategy for delivering this multitasking is called multithreading and is the topic of this book, and the authors use C++ to implement the needed multithreading. In the book, they discuss mutex objects, anonymous and named pipe objects, thread objects, and container components. They define a concept called incremental multithreading to allow the construction of multithreaded components. The authors do not assume the reader to have any experience in multithreading, but a good background in C++ is assumed. The authors implement the code using POSIX pthreads, and there is an enclosed disk on the book jacket that contains the source code discussed in the book, although only snippets of code are inserted in the book. It is an overview only, and not a textbook, since no problem sets or coding assignments are given in the book. Thus it is not really suitable as a textbook for classroom use, but serves well as a reference.<br /> After a brief review of C++ and OO programming in chapter 1, the authors introduce the concept of a thread and a process in chapter 2.  Defining a process as a program in execution, and the environment of a process as a collection of pointers defined by the system, the list the information different types of operating systems give about a process. Processes can be in nine different states with several possible transitions possible between the process states. The authors effectively employ state transition diagrams to illustrate the possibilities. They also discuss in detail the creation of child processes in various operating systems, the differences between synchronous and asynchronous processes, and how processes use available resources.<br /> In chapter 3, a thread is defined as a lightweight process, meaning that the OS does not have quite the burden to manage a thread versus a general process. A multithreaded process then has more than one thread, and the authors give a useful list of the differences between processes and threads. The advantages and disadvantages of threads are the discussed in detail and they classify threads as being sleepers, one shots, anticipating work, and deferring work. Thread control is detailed, along with a discussion of how to prioritize threads. And again, state transition diagrams are used to discuss the dynamics of the changes between different thread states, which are classified as ready, running, and blocked.<br /> Multitasking, which allows more than one process to execute at the same time, and multithreading, which allows a single process to perform many tasks at the same time, are discussed in the next chapter. The advantages of each are discussed, along with scheduling strategies.<br /> The most useful part of the book is the next chapter on interprocess and interthread communication, which are very important in designing concurrent applications. Piping is discussed in detail, along with shared memory and dynamic data exchange. They contrast, effectively using diagrams, the differences between types of communications used by threads, to the types used by processes.<br /> The intricacies and pitfalls behind writing multithreaded applications are discussed in chapter 6 which overviews the cooperation and synchronization of threads. This is where mutexes come in, and the authors do a good job of explaining how they are used.<br /> Interface classes are discussed in more detail in the next chapter, where they are implemented for interprocess communication. The authors could have skipped the generalities on these classes, and instead spend more time on how they assist in multithreading implementations. This chapter finally gets down to a OO approach to programming, and this is followed to a large extent in the next chapter on synchronization objects, where mutex classes are introduced.<br /> Object-oriented multithreaded architectures are discussed in chapter 9, where some multitier approaches are outlined, and a logical PRAM model is discussed. This is followed in the next chapter by how inheritance is used in class hierarchies to implement multithreading. The most useful part of this chapter is the discussion on casting the this pointer, to allow the passing of anything to the thread's main function.<br /> Chapter 11 discusses how C++ objects behave in a multithreaded environment. After a  brief review of scoping in C++ and an example, the authors discuss in detail just how objects are created and destroyed in a multithreaded environment. This is followed by a discussion of thread-safe and unsafe functions, and how to use the Standard Template Library in a multithreaded architecture.<br /> In chapter 12, the authors discuss how to test multithreaded applications. The discussion is very general in the first half of the chapter, and not new to anyone who has done software development in a team environment. They do specialize the discussion somewhat to test cases for objects, and discuss the different thread models used when attempting to test multithreaded applications. The discussion however could really be expanded upon, due to its importance. The last chapter of the book is short and merely a wrap-up. The POSIX thread management specifications are given in an appendix to the book.<br /> The authors have done a fairly decent job, but some more advanced examples could have been included along with exercises and projects for the reader to test their understanding. Programming, using multithreading or not, cannot be learned unless code is written and executed by the learner.oach to programming, and this is followed to a large extent in the next chapter on synchronization objects, where mutex classes are introduced. <br /> Object-oriented multithreaded architectures are discussed in chapter 9, where some multitier approaches are outlined, and a logical PRAM model is discussed. This is followed in the next chapter by how inheritance is used in class hierarchies to implement multithreading. The most useful part of this chapter is the discussion on casting the this pointer, to allow the passing of anything to the thread's main function. <br /> Chapter 11 discusses how C++ objects behave in a multithreaded environment. After a  brief review of scoping in C++ and an example, the authors discuss in detail just how objects are created and destroyed in a multithreaded environment. This is followed by a discussion of thread-safe and unsafe functions, and how to use the Standard Template Library in a multithreaded architecture. <br /> In chapter 12, the authors discuss how to test multithreaded applications. The discussion is very general in the first half of the chapter, and not new to anyone who has done software development in a team environment. They do specialize the discussion somewhat to test cases for objects, and discuss the different thread models used when attempting to test multithreaded applications. The discussion however could really be expanded upon, due to its importance. The last chapter of the book is short and merely a wrap-up. The POSIX thread management specifications are given in an appendix to the book. <br /> The authors have done a fairly decent job, but some more advanced examples could have been included along with exercises and projects for the reader to test their understanding. Programming, using multithreading or not, cannot be learned unless code is written and executed by the learner.	2001-06-16
1956667:US	50702879	RKYG4JIRU7ECP	0201633469	326443823	001: TCP/IP Illustrated, Vol. 1: The Protocols (Addison-Wesley Professional Computing Series)	Books	5	97	101	N	N	Somewhat out of date...but excellent	Even though this book was published in 1994, it still serves as a useful reference and learning tool for the TCP/IP protocol. There are of course changes and additions that have been made to TCP/IP over the last 7 years such as IPv6, but one can still refer to this book as a good source of information about the dynamics of TCP/IP. There are exercises at the end of each chapter, so it can, and has been used as an effective textbook.<br /> In chapter 1, the author gives a brief overview of protocol layering, Internet addressing, and the domain name system. The encapsulation mechanisms for TCP and UDP are outlined as well as a discussion of the different implementations of TCP/IP. The Vegas implementation is not discussed since it was invented long after the date of publication of this book. Ethernet and the encapsulation provided by IEEE, SLIP, and PPP is discussed in the next chapter on the link layer, along with the loopback interface and MTU. Estimates are given of serial line throughput, setting the stage for later timing calculations.<br /> The IP protocol is the subject of chapter 3, the author stressing first the connectionless and unreliable nature of IP packet transfer. The IP datagram format is given in discussed, along with a detailed discussion of subnet addressing and subnet masks. The discussion of IP given here is of course very out of date with the advent of IPv6.<br /> Chapter 4 is an overview of ARP, and the author illustrates it effectively using an example of an FTP transfer and Telnet. This is followed by a treatment of RARP in the next chapter, with the limitations of this protocol briefly discussed. Although ARP is incorporated in all current implementations of TCP/IP (with the exception of IPv6), not all of these include RARP.<br /> The ICMP error handling protocol is discussed in the next chapter, with all the message types listed, and brief discussions given of timestamp and address mask requests. This is followed naturally by a discussion of the Ping program in chapter 7, which uses ICMP echo request and reply messages.<br /> The traceroute program, which finds which path IP packets follow from one to the other, is discussed in Chapter 8. An explicit example is given of how to use traceroute. Then in the next chapter, IP routing is discussed, along with an explicit example of a routing table. Again, the discussion is out-of-date, since in IPv6, the router discovery is replaced by a mandatory router solicitation and advertisement mechanism.<br /> Dynamic routing protocols are the subject of the next chapter, wherein the author discusses RIP, OSPF, BGP, and CIDR. The newer ones, such as IGRP, EIGRP, and MPLS, are of course not treated.<br /> UDP is then discussed in the next chapter, with examples given and IP fragmentation discussed, along with a brief overview of how UDP and ARP interact. This is followed in Chapter 12 by a discussion of broadcasting and multicasting, and the author outlines briefly the problems that rise when attempting to broadcast through routers. Then in the next chapter, the ICMP mechanism for multicasting is discussed. Here again the treatment is dated, since in IPv6 IGMP is replaced by multicast listener discovery messages and there are no broadcast addressing in IPv6.<br /> The DNS database is discussed in the next chapter, with emphasis on how resolvers communicate with name servers using TCP/IP. The discussion is limited to A resource records, which is replaced in IPv6 with AAAA or A6 resource records. I did not read the next two chapters on TFTP and  BOOTP so I will omit any commentary.<br /> It is in the next chapter that the basics of TCP begin to be discussed, with the details of the TCP header given. The dynamics of the TCP connection is then treated in chapter 18, with a complete TCP state transition diagram given. The discussion is very helpful to those who need a thorough understanding of the connection steps in TCP. This is followed by a treatment of the Nagle algorithm and delayed ACKs in chapter 19. The exercises in this chapter need to be worked to appreciate the discussion.<br /> The following chapter overviews how TCP sliding windows work, and how window sizing is done. Slow start, the bandwidth-delay product, and the urgent mode are all treated in great detail. The mathematical considerations behind TCP timeout and retransmission are given in chapter 21, along with a discussion of the congestion avoidance algorithm and the fast retransmit and fast recovery algorithms. Then in chapter 22, the TCP persist timer, used to prevent transmission deadlock and the silly window syndrome, is discussed in detail. The ability of TCP to implement a keepalive timer is discussed in the next chapter. Since it is out of date, I did not read the next chapter on the future of TCP.<br /> The SNMP network management protocol is outlined in Chapter 25, with definitions of MIB and an overview of SNMP traps. These are very important concepts given the enormous importance of network management currently. There are currently several vendors that supply packages for polling, reporting, and forecasting network behavior that are based partially on SNMP and MIBs.<br /> Telnet and Rlogin, which are still used extensively in modern networks, are discussed in the next chapter. After reading this chapter, the reader will have a thorough understanding of how these protocols work, which is also true of the next chapter that covers the FTP protocol, and the SMTP protocol, which is covered in chapter 28. I did not read the last two chapters of the book so I will omit any commentary.<br /> The author has done a good job here of relating to the reader the structure and dynamics of TCP/IP based on what was known at the time. In view of the fact that IPv4 is still alive and well, and given that TCP implementations have only been slightly modified since 1994, one can still read this book profitably.le algorithm and delayed ACKs in chapter 19. The exercises in this chapter need to be worked to appreciate the discussion. <br /> The following chapter overviews how TCP sliding windows work, and how window sizing is done. Slow start, the bandwidth-delay product, and the urgent mode are all treated in great detail. The mathematical considerations behind TCP timeout and retransmission are given in chapter 21, along with a discussion of the congestion avoidance algorithm and the fast retransmit and fast recovery algorithms. Then in chapter 22, the TCP persist timer, used to prevent transmission deadlock and the silly window syndrome, is discussed in detail. The ability of TCP to implement a keepalive timer is discussed in the next chapter. Since it is out of date, I did not read the next chapter on the future of TCP. <br /> The SNMP network management protocol is outlined in Chapter 25, with definitions of MIB and an overview of SNMP traps. These are very important concepts given the enormous importance of network management currently. There are currently several vendors that supply packages for polling, reporting, and forecasting network behavior that are based partially on SNMP and MIBs. <br /> Telnet and Rlogin, which are still used extensively in modern networks, are discussed in the next chapter. After reading this chapter, the reader will have a thorough understanding of how these protocols work, which is also true of the next chapter that covers the FTP protocol, and the SMTP protocol, which is covered in chapter 28. I did not read the last two chapters of the book so I will omit any commentary. <br /> The author has done a good job here of relating to the reader the structure and dynamics of TCP/IP based on what was known at the time. In view of the fact that IPv4 is still alive and well, and given that TCP implementations have only been slightly modified since 1994, one can still read this book profitably.	2001-06-16
1960732:US	50702879	R3C1WYPS39RKGO	1861003110	489887920	Professional XML	Books	4	10	13	N	N	Useful introduction	The XML declarative language, with its adaptability and expressive power, is continuing to become the language of choice for reporting and classifying information. XML is a formal grammar that captures the syntactic features of a document type definition, and its properties, syntax, and applications are discussed effectively in this book. It covers XML as formalized by the W3C and the authors show how to use XML in Web-based and database applications. Readers who have developed applications in HTML will probably view XML as somewhat more abstract, since the visual representation of the content of a document is not emphasized in XML. Readers are expected to have a background in HTML, JavaScript, Java, and ASP in order to read the book. Although XML can be learned by reading the W3C specifications, these documents are frequently difficult reading, and this book makes the learning of XML much easier than reading these specifications. They include the W3C specifications for XML 1.0 in an appendix to the book for the interested reader.  The book is a little dated, since the W3C has been updating XML specs since the time of publication (especially with regard to schemas), but there is a 2nd edition coming out soon.<br /> In Chapter 1, XML is introduced as a mark-up language and its inherent extensibility emphasized. This is followed by a detailed treatment of XML syntax in the next chapter, with emphasis placed on the hierarchical nature of XML. The authors do include a discussion of Processing Instructions (PIs) for users who want to use XML in this fashion.<br /> Document Type Definitions (DTD) are the subject of Chapter 3, where the authors communicate effectively how DTDs formal grammar is used to specify the structure and permissible values of XML documents. The formal DTD structure is discussed, and the principles behind writing DTDs are effectively outlined. They also discuss the problems with using DTDs.<br /> Data modeling with XML is discussed in the next chapter, with information modeling via static and dynamic models treated in detail, and the authors carefully distinguish these two approaches. The actual designing of XML documents is given a nice overview as well as the role of schemas in XML. This is followed in Chapter 6 by a discussion of the (tree-based) Document Object Model, which overviews how XML documents can be accessed by various programs. Some helpful examples are given on how the DOM can be used to create an XML document programmatically. An alternative way of processing an XML document is discussed in the next chapter on the (event-based) SAX interface. The authors outline in detail the benefits of using SAX rather than DOM. In Appendix B the reader will find the Internet Explorer 5.0 XML DOM 1.0 W3C specifications. In addition, in Appendix C, the specification for the SAX 1.0 interface is given.<br /> The shortcomings of DTD are addressed in terms of XML Schemas and namespaces in chapter 7. Since this book was published, XML Schemas have reached W3C recommendation status as of Nov 2000. The authors give a good overview of namespaces and schemas, with helpful examples. This is followed in chapter 8 by a discussion of how to link and query into XML documents using the XML information set, XLink, XPath, XPointer, XML Fragment Interchange, with XLST covered in the next chapter. For database applications, the authors outline the differences between relational databases and XML documents. A very detailed treatment of how XLST transforms the source document is given, and the authors compare XLS and DOM transformations. An Internet Explorer XSL reference is included in one of the appendices of the book.<br /> More details on the relationship between databases and XML is the subject of chapter 10, wherein the authors show how to store XML and how data can be communicated between different servers using XML. The issues involved when moving data from RDBMS to OODBMS or from Oracle to Sybase, are discussed by the authors. This is followed by an interesting discussion on how to use XML as a distributed component model for server-to-server communications via XML-Remote Procedure Call and Simple Object Access Protocol.<br /> E-commerce applications are discussed in the next chapter, with EDI and its improvement via XML. The business markup language cXML , which allows business to business electronic commerce transactions across the Internet, is also treated in detail.<br /> The authors then finally discuss how to render XML documents more readable and pleasing for the viewer in the next chapter using the style languages CSS and XSL. The discussion is really interesting, for the authors dig a little deeper into the foundations of style languages. The discussion of style languages as rule-based languages is particularly illuminating.<br /> The next chapter is very interesting and its inclusion is actually very surprising, namely a discussion of the Wireless Application Protocol. The authors give an introduction to the Wireless Markup Language and WMLScript. The book ends with four useful chapters on case studies for data duality, distributed applications, a book catalog information service, and SOAP.<br /> There are many applications of XML in many different areas, such as CellML (proprietary) used in cell biology, CML (Chemical Markup Language) for molecular chemistry, IML (Instrument Markup Language) for control of laboratory equipment, BSML (Bioinformatic Sequence Markup Language) for gene sequencing, and MathML for formatting of mathematical equations. I find XML an extremely powerful approach to information reporting and I am currently developing a package called NMML (Network Modeling Markup Language) for use in reporting results in simulation and mathematical modeling of networks, and FMML (Financial Modeling Markup Language) for use in reporting results in the modeling of financial instruments. This book, along with the W3C specifications, has been a tremendous help in the development of these applications.the authors. This is followed by an interesting discussion on how to use XML as a distributed component model for server-to-server communications via XML-Remote Procedure Call and Simple Object Access Protocol. <br /> E-commerce applications are discussed in the next chapter, with EDI and its improvement via XML. The business markup language cXML , which allows business to business electronic commerce transactions across the Internet, is also treated in detail. <br /> The authors then finally discuss how to render XML documents more readable and pleasing for the viewer in the next chapter using the style languages CSS and XSL. The discussion is really interesting, for the authors dig a little deeper into the foundations of style languages. The discussion of style languages as rule-based languages is particularly illuminating. <br /> The next chapter is very interesting and its inclusion is actually very surprising, namely a discussion of the Wireless Application Protocol. The authors give an introduction to the Wireless Markup Language and WMLScript. The book ends with four useful chapters on case studies for data duality, distributed applications, a book catalog information service, and SOAP.  <br /> There are many applications of XML in many different areas, such as CellML (proprietary) used in cell biology, CML (Chemical Markup Language) for molecular chemistry, IML (Instrument Markup Language) for control of laboratory equipment, BSML (Bioinformatic Sequence Markup Language) for gene sequencing, and MathML for formatting of mathematical equations. I find XML an extremely powerful approach to information reporting and I am currently developing a package called NMML (Network Modeling Markup Language) for use in reporting results in simulation and mathematical modeling of networks, and FMML (Financial Modeling Markup Language) for use in reporting results in the modeling of financial instruments. This book, along with the W3C specifications, has been a tremendous help in the development of these applications.	2001-06-13
1960878:US	50702879	R30H2L33I7CCA3	0387986375	325272743	The Geometry of Schemes (Graduate Texts in Mathematics)	Books	5	41	41	N	N	Crystal clear overview of a traditionally abstract subject	The theory of schemes is usually thought to be highly abstract and esoteric, and one that makes the study of algebraic geometry even more difficult. The authors definitely dispel this notion in this book, which could have been called &quot;A Concrete Introduction to Schemes&quot;, because of the clarity with which the concepts are introduced and explained. After studying this book, one will understand and appreciate the power of schemes in algebraic geometry. The authors do an even better job  than they did in their earlier and short work &quot;Schemes: The Language of Modern Algebraic Geometry&quot;, which is now out of print.<br />  In chapter 1, the main definitions are given and the basic concepts behind schemes outlined. That schemes are more complicated than varieties is readily apparent even in this beginning chapter, where they are thought of as corresponding to the spectrum of a commutative ring with identity. Very elementary exercises are given to help the reader gain confidence in the constructions involved. They authors do have to discuss some sheaf theory, but they show its relevance nicely in this chapter. They also discuss the notion of a fibered product as a generalization of the idea of a preimage of a set under the application of a function and relate it to the construction of the functor of points. The role of the functor of points as reducing schemes to a kind of set theory is brought out beautifully here.<br />  The next chapter gives many examples of schemes, with the first examples being reduced schemes over algebraically closed fields, these being essentially the ordinary varieties of classical algebraic geometry. The authors then give examples of schemes, the local schemes, which are more general than varieties. When departing from the assumption of a field that is not finitely generated, extra points will have to be added to classical varieties. The fact that only one closed point appears is compared to the case of complex manifolds, via the concept of a germ. This is a very helpful comparison, and one that further solidifies the understanding of a scheme in the mind of the reader. The authors give the reader a short peek at the etale topology in one of the examples. Examples are then given where the field is not algebraically closed, generalizing classical number theory, and non-reduced schemes, where nilpotents are present. The chapter ends with examples of arithmetic schemes where the spectra of rings are finitely generated over the integers.<br /> Projective schemes are the subject of Chapter 3, and are defined in terms of graded algebras and invariants of projective schemes embedded in projective space are discussed. The Grasmannian scheme is discussed in detail as an example of a projective scheme. Interestingly, Bezout's theorem, very familiar from elementary algebraic geometry, is generalized here to projective schemes.<br /> Constructions from classical algebraic geometry are generalized to schemes in Chapter 4. The first one discussed is the notion of a flex, which deals (classically) with the locus of tangent lines to a variety. The flexes are defined in terms of the Hessian of the variety, the latter being generalized by the authors to define a scheme of flexes. The notion of blowing up is also generalized to the scheme setting, with the authors motivating the discussion by blowing up the plane. The discussion of blow-ups along non-reduced subschemes of a scheme and blow-ups of arithmetic schemes is fascinating and the presentation is crystal clear. Fano varieties are also generalized to Fano schemes in the chapter. Most of the information about these schemes are contained in the exercises, and some of these need to be worked out for a thorough understanding.<br /> The next chapter is more categorical in nature, and deals with generalizations of the classical Sylvester construction of resultants and discriminants to the scheme setting.<br /> In the last chapter the authors return to the functor of points, and motivate the discussion by asking for a parametrization of families of schemes. The authors show, interestingly, that using the functor of points one can more easily compute geometric information about a scheme than using its equations. They illustrate this for the Zariski tangent space. Then after an overview of Hilbert schemes they close the book by introducing the reader to moduli spaces and a hint of algebraic stacks. No end in sight for this beautiful subject..........to the functor of points, and motivate the discussion by asking for a parametrization of families of schemes. The authors show, interestingly, that using the functor of points one can more easily compute geometric information about a scheme than using its equations. They illustrate this for the Zariski tangent space. Then after an overview of Hilbert schemes they close the book by introducing the reader to moduli spaces and a hint of algebraic stacks. No end in sight for this beautiful subject..........	2001-06-13
1961409:US	50702879	R2BNN66CCE5BXI	1555580416	821114573	Common LISP. The Language. Second Edition	Books	4	13	15	N	N	Good reference	This book is an excellent reference book on Common Lisp and will serve the experienced Lisp programmer well in that regard. The author has meticulously documented the features of Common Lisp and its relation with other Lisp dialects, such as MacLisp. Readers who know Lisp only marginally can also benefit from the book, for example computer scientists or logicians with a background in lambda calculus, or programmers with a background in functional or logical programming. Users of Mathematica, Reduce, or Maple could also use the book profitably, as it gives insight on the origin of some of the function calls and syntax in these high-level symbolic programming languages. The size of the book prohibits a per-chapter review, but some highlights of the book include the discussion on data types and scoping in the first two chapters. The author summarizes effectively the kinds of scope in Common Lisp. The program structure in Lisp, namely the organization of a program as a function call or a form is outlined in detail. It is this program structure I believe that gives Lisp its power and makes it a more natural language in which to program, at least from a purely mathematical standpoint. The author stresses that function application is the primary method for generating Lisp programs. In addition, the author shows in detail how a function in Lisp can compute several objects and return them; and here again, the approach taken by Lisp is much cleaner from a mathematical perspective than the one taken by other programming languages.<br /> A very good overview of how Common Lisp represents numbers is also given in the book. The discussion is supplemented with a treatment of complex functions and many graphs are given illustrating their behavior, the graphs being generated by PostScript code by Common Lisp code. Also, there is a useful discussion of hashing in and how to implement user-defined structures in Common Lisp.<br /> Also quite interesting is the discussion on the object-oriented extension to Common Lisp called the Common Lisp Object System (CLOS), which is based on generic functions, multiple inheritance, declarative method combination, and a meta-object protocol. The fundamental objects of CLOS are classes, instances, generic functions, and methods, and the author discusses each of these in detail. The use of CLOS has become important recently in the area of constraint programming and its applications.t-oriented extension to Common Lisp called the Common Lisp Object System (CLOS), which is based on generic functions, multiple inheritance, declarative method combination, and a meta-object protocol. The fundamental objects of CLOS are classes, instances, generic functions, and methods, and the author discusses each of these in detail. The use of CLOS has become important recently in the area of constraint programming and its applications.	2001-06-13
1964616:US	50702879	R230OOHATA19VX	0136938221	785258102	Capacity Planning for Web Performance: Metrics, Models, and Methods	Books	4	16	16	N	N	Good introduction for the beginner	The modeling of the Internet has become extremely important in recent years as it continues to grow in leaps and bounds. Network architects have to become very aware of the performance issues when they design networks that will be integrated into this elaborate spider of clients, servers, routers, and switches. The issues in the modeling of global networks are extremely complex and involve very advanced mathematical techniques in order to do the job effectively. The authors of this book however have written an introduction to Web modeling that is written at a level appropriate for network designers and the beginning modeling engineer. They employ Excel spreadsheets and C code to assist in the modeling efforts, and these packages are available on an accompanying CD.<br /> After a brief discussion of the issues concerning capacity planning, Web server, Intranet, and ISP performance in Chapter 1, the authors move on to defining and characterizing client/server systems in the next chapter. After a brief overview of the history of the Internet, they discuss LANs and WANs, and a quick treatment of protocols. The TCP protocol is considered in somewhat more detail because of its importance in network performance.<br /> The quantitative analysis of performance in client/server environments is begun in chapter 3, wherein the authors begin with communication-processing delay diagrams to illustrate how requests spend time at each resource. This is done for both a 2-tier and a 3-tier C/S architecture, and the authors detail how disk subsystems contribute to the service time at a disk.  An elementary iteration technique is used to compute the disk utilization. A very interesting and detailed discussion of the RAID-5 disk array is given. Some elementary queuing theory is discussed, using the assumption of flow equilibrium. A simplified summary of the utilization, forced flow, service demand, and Little's laws is also given without resorting to complicated mathematics.<br /> Performance issues in Intranets and Web servers are the topic of the next chapter, and most importantly, the authors outline the differences between HTTP 1.0 and HTTP 1.1. The role of the proxy server and its contribution to performance is also discussed, along with Web cluster architectures. The authors first mention the role of burstiness in this chapter, but do not give an in-depth mathematical discussion.<br /> In chapter 5, the authors give a step-by-step methodology for capacity planning for C/S systems. Workload characterization, data collection issues, model validation, and forecasting are all discussed quantitatively with more details in later chapters.<br /> How to characterize the workload quantitatively is the subject of the next chapter, in terms of a business, functional, and resource-oriented methodology. The authors discuss briefly workload models from a non-mathematical point of view, with parametrized models given the emphasis. The calculation of the parameters is given a more detailed and mathematical treatment, with distance measures and clustering algorithms outlined. Self-similarity in network traffic is first mentioned here, but not discussed from a rigorous mathematical perspective. The authors do however give a rudimentary method for calculating the burstiness.<br /> Benchmarking is discussed in Chapter 7, with the authors detailing the most common approaches to this activity, and mention the most cited benchmark sources, including SPEC, TPC, AIM, and NNBB. The authors divide benchmarks into two categories, component-level and system-level, and discuss CPU performance benchmarking, file server performance, and transaction processing systems as examples of these two categories. Web server benchmarking is also discussed in the context of the two most popular benchmarks: Webstone and SPECweb. Webstone uses Little&#8217;s Law to derive a metric called Little&#8217;s Load Factor, which gives the average number of connections open at the Web server at aparticular time during a network test. Their discussion is very helpful for network modelers who need an introduction to the current benchmarks used in network testing and planning.<br /> The authors fortunately get even more mathematical in the next two chapters on system-level and component-level performance models. Various queuing models are analyzed assuming operational equilibrium, which the authors assume for all models in the book, and which means that the number of requests initially is equal to the number at the end of the observation interval. State transition diagrams are introduced, but the mathematical formalism used is not based on one from stochastic processes, but instead is more phenomenological. The authors employ mean value analysis to solve closed queuing networks with the EXCEL spreadsheets nicely illustrating the results.....<br /> The last chapter of the book discusses how to obtain network performance data experimentally. This can be a difficult task, but the authors do a good job of discussing the possible strategies one can use to collect this data, and give a brief overview of the commercially available network monitors available for this purpose. The difficult job of parameter estimation using measurement data is also discussed in some detail. The authors refer to their other book however for a more thorough treatment of validation and calibration techniques.<br /> The authors have written a fine book here, and will serve well the person first beginning in network modeling and the network designer who needs to understand performance issues. After reading this book, and with some more mathematical preparation, readers can then move on to more sophisticated treatments of the mathematical and simulation modeling of networks.r at a particular time during a network test. Their discussion is very helpful for network modelers who need an introduction to the current benchmarks used in network testing and planning. <br /> The authors fortunately get even more mathematical in the next two chapters on system-level and component-level performance models. Various queuing models are analyzed assuming operational equilibrium, which the authors assume for all models in the book, and which means that the number of requests initially is equal to the number at the end of the observation interval. State transition diagrams are introduced, but the mathematical formalism used is not based on one from stochastic processes, but instead is more phenomenological. The authors employ mean value analysis to solve closed queuing networks with the EXCEL spreadsheets nicely illustrating the results..... <br /> The last chapter of the book discusses how to obtain network performance data experimentally. This can be a difficult task, but the authors do a good job of discussing the possible strategies one can use to collect this data, and give a brief overview of the commercially available network monitors available for this purpose. The difficult job of parameter estimation using measurement data is also discussed in some detail. The authors refer to their other book however for a more thorough treatment of validation and calibration techniques. <br /> The authors have written a fine book here, and will serve well the person first beginning in network modeling and the network designer who needs to understand performance issues. After reading this book, and with some more mathematical preparation, readers can then move on to more sophisticated treatments of the mathematical and simulation modeling of networks.	2001-06-11
1965931:US	50702879	R2APX9WMNZ2CTQ	0691042896	893787168	Time Series Analysis	Books	4	107	116	N	N	Extremely Useful	This book is a comprehensive overview of the theory and techniques for analyzing time series. The author has done a fine job, and the book will no doubt continue to be a good source of information for researchers and statisticians, and also to students, since exercises appear at the end of some of chapters. Proofs of the important mathematical results are put in the appendices to each chapter.<br /> Chapter 1 introduces both first order and pth order difference equations and outlines some methods of solution, such as recursive substitution. Dynamic multipliers are discussed, along with long-run and present-value calculations. Readers familiar with linear ordinary differential equations will see the similarity in solution techniques.<br /> The next chapter introduces time series for the first time, and gives examples, both deterministic and probabilistic. Time series operators are discussed, with specific emphasis on the lag operator. The role of initial conditions for solving difference equations is outlined in detail.<br /> After discussing the concepts of stochastic processes, stationarity, ergodicity, and white noise, in Chapter 3 the author discusses moving average processes and autoregressive processes, along with the invertibility of these processes. A few realizations of AR(1) processes are plotted explicitly.<br /> The forecasting of time series is the topic of Chapter 4, with techniques based on conditional expectation, triangular and Cholesky factorization, and the Box and Jenkins method. An elementary example of sample and sample partial autocorrelations for US quarterly GNP growth is plotted.<br /> The technique of  maximum likelihood estimation is discussed in the next chapter, wherein the author shows how to calculate the likelihood function for various Gaussian ARMAs, along with optimization techniques. The discussion on grid searching is one of the best I have seen in the literature.<br /> The all-important spectral analysis techniques are covered in Chapter 6 and the author does an excellent job of explaining how taking the spectrum will illustrate the contributions of periodic cycles to the variance of the data. An example of spectral analysis dealing with manufacturing data is given.<br /> The next chapter on asymptotic distribution theory is a little bit more demanding mathematically, but the author does manage to explain the details of this theory very well. The reader can see explicitly how the central limit theorem comes into play in time series analysis.<br /> After a review of ordinary least squares, the author gives a very rigorous discussion of linear regression models in Chapter 8. The author shows the role that heteroskedasticity plays in these techniques.<br /> Departures from the ideal regression model are discussed further in Chapter 9, wherein the author illustrates the impact of simultaneous equations bias in contributing to the correlation of the error term with the explanatory variables. A supply and demand model from econometrics is used effectively to illustrate this contribution.<br /> Chapters 10 and 11 discuss vector time series, with multivariate dynamical systems and vector autoregressions both treated in detail. The population coherence between two vector processes is given, along with the Newey-West, the Granger-Causality tests, and spectral-based estimators.  \\"Green's function\\" techniques, via the impulse-response function , are also discussed.<br /> Bayesian techniques, which take advantage of prior information on the sample, are discussed in Chapter 12 from both an analytical and numerical point of view. The role of  Monte Carlo techniques in estimating posterior moments is unfortunately only discussed briefly.<br /> The representation of a dynamical system in terms of state-space via the Kalman filter is treated in the next chapter. The author discusses the use of the Kalman filter in forecasting , maximum likelihood estimation, smoothing, and statistical inference. All of thesetools are important in applications, and the author does a fine job of explaining them in this chapter.<br /> The Hansen technique of generalized moments is considered in Chapter 14, with the most interesting discussion being the one on the estimation of rational expectation models. The author also shows how to use the method when nonstationary data is present.<br /> Chapter 15 begins the study of nonstationary time series, with trend-stationary and unit root processes compared and analyzed throughout the chapter in terms of their forecast errors and their dynamic multipliers. Two other approaches to the study of nonstationary time series are also discussed in the chapter, namely, the fractionally integrated process and processes with discrete shifts in the time trend.<br /> Processes with deterministic time trends are the subject of Chapter 16, wherein the author outlines the methods for calculating the asymptotic distributions of the coefficient estimates.<br />The most interesting discussion in the next chapter on univariate processes is on the Brownian walk, for it permits a more general formulation of the central limit theorem. A very detailed discussion of the Dickey-Fuller tests is given with an example of quarterly real US GNP. The Dickey-Fuller test has been widely accepted as a standard test for nonstationarity in time series.  Other approaches to finding the unit roots, such as the Phillips-Perron tests are also given.  The results here are generalized to the multivariate case in the next chapter.<br />Vector unit root processes called cointegrated processes are the subject of Chapters 19 and 20. These special time series, with each component series being I(1), are treated with respect to the implications they have on moving average, Philips triangular, common trends, and error-correction representations. An interesting application is given to exchange rate data.<br />Time series with variances that change over time, or heteroskedastic processes, are discussed in Chapter 21. The infamous ARCH models are fully detailed, along with their generalizations, the GARCH models.<br />Drastic changes in the behavior of time series is the subject of the last chapter of the book, wherein Markov chains are employed to model these kinds of time series. An application of the these models to  U.S real GNP is given.<br />Some omissions in the book include approaches for testing covariance stationarity, such as the postsample prediction test, the CUSUM test, and the modified scaled range test.All of these tools are important in applications, and the author does a fine job of explaining them in this chapter. <br /> The Hansen technique of generalized moments is considered in Chapter 14, with the most interesting discussion being the one on the estimation of rational expectation models. The author also shows how to use the method when nonstationary data is present. <br /> Chapter 15 begins the study of nonstationary time series, with trend-stationary and unit root processes compared and analyzed throughout the chapter in terms of their forecast errors and their dynamic multipliers. Two other approaches to the study of nonstationary time series are also discussed in the chapter, namely, the fractionally integrated process and processes with discrete shifts in the time trend. <br /> Processes with deterministic time trends are the subject of Chapter 16, wherein the author outlines the methods for calculating the asymptotic distributions of the coefficient estimates. <br />The most interesting discussion in the next chapter on univariate processes is on the Brownian walk, for it permits a more general formulation of the central limit theorem. A very detailed discussion of the Dickey-Fuller tests is given with an example of quarterly real US GNP. The Dickey-Fuller test has been widely accepted as a standard test for nonstationarity in time series.  Other approaches to finding the unit roots, such as the Phillips-Perron tests are also given.  The results here are generalized to the multivariate case in the next chapter. <br />Vector unit root processes called cointegrated processes are the subject of Chapters 19 and 20. These special time series, with each component series being I(1), are treated with respect to the implications they have on moving average, Philips triangular, common trends, and error-correction representations. An interesting application is given to exchange rate data. <br />Time series with variances that change over time, or heteroskedasticprocesses, are discussed in Chapter 21. The infamous ARCH models are fully detailed, along with their generalizations, the GARCH models. <br />Drastic changes in the behavior of time series is the subject of the last chapter of the book, wherein Markov chains are employed to model these kinds of time series. An application of the these models to  U.S real GNP is given. <br />Some omissions in the book include approaches for testing covariance stationarity, such as the postsample prediction test, the CUSUM test, and the modified scaled range test.	2001-06-09
1966610:US	50702879	R2ZPVF0Z1NPSTR	0387970037	636138868	Introduction to Applied Nonlinear Dynamical Systems and Chaos (Texts in Applied Mathematics) (v. 2)	Books	4	30	31	N	N	Effective overview of a useful subject	The subject of dynamical systems has been around for over a century now, having been defined by Henri Poincare in the early 1900s, but having its roots in Hamiltonian and Lagrangian mechanics in the 19th century. In this book ths author has done a fine job of overviewing the subject of dynamical systems, particularly with regards to systems that exhibit chaotic behavior. There are 292 illustrations given in the book, and they effectively assist in the understanding of a sometimes abstract subject.<br /> After a brief introduction to the terminology of dynamical systems in Section 1.1, the author moves on to as study of the Poincare map in the next section. Recognizing that the construction of the Poincare map is really an art rather than a science, the author gives several examples of the Poincare map and discusses in detail the properties of each. Structural stability, genericity, transversality are defined, and, as preparation for the material later on, the Poincare map of the damped, forced Duffing oscillator is constructed. The later system serves as the standard example for dynamical systems exhibiting chaotic behavior.<br /> The simplification of dynamical systems by means of normal forms is the subject of the next part, which gives a thorough discussion of center manifolds. Unfortunately, the center manifold theorem is not proved, but references to the proof are given.<br /> Local bifurcation theory is studied in the next part, with bifurcations of fixed points of vector fields and maps given equal emphasis. The author defines rigorously what it means to bifurcate from a fixed point, and gives a classification scheme in terms of eigenvalues of the linearized map about the fixed point. Most importantly, the author cautions the reader in that dynamical systems having time-dependent parameters and passing through bifurcation values can exhibit behavior that is dramatically different from systems with constant parameters. He does give an interesting example that illustrates this, but does not go into the singular perturbation theory needed for an effective analysis of such systems.<br /> An introduction to global bifurcations and chaos is given in the next part, which starts off with a detailed construction of the Smale horseshoe map. Symbolic dynamics, so important in the construction of the actual proof of chaotic behavior is only outlined though, with proofs of the important results delegated to the references. The Conley-Moser conditions are discussed also, with the treatment of sector bundles being the best one I have seen in the literature. The theory is illustrated nicely for the case of two-dimensional maps with homoclinic points. The all-important Melnikov method for proving the existence of transverse homoclinic orbits to hyperbolic periodic orbits is discussed and is by far one of the most detailed I have seen in the literature. The author employs many useful diagrams to give the reader a better intuition behind what is going on. He employs also the pips and lobes terminology of Easton to study the geometry of the homoclinic tangles. Homoclinic bifurcation theory is also treated in great detail. This is followed by an overview of the properties of orbits homoclinic to hyperbolic fixed points. A brief introduction to Lyapunov exponents and strange attractors is also given.<br /> This book has served well as a reference book and should be useful to students and other individuals who are interested in going into this area. It is a subject that has found innumerable applications, and it will continue to grow as more tools and better computational facilities are developed to study the properties of dynamical systems.at illustrates this, but does not go into the singular perturbation theory needed for an effective analysis of such systems. <br /> An introduction to global bifurcations and chaos is given in the next part, which starts off with a detailed construction of the Smale horseshoe map. Symbolic dynamics, so important in the construction of the actual proof of chaotic behavior is only outlined though, with proofs of the important results delegated to the references. The Conley-Moser conditions are discussed also, with the treatment of sector bundles being the best one I have seen in the literature. The theory is illustrated nicely for the case of two-dimensional maps with homoclinic points. The all-important Melnikov method for proving the existence of transverse homoclinic orbits to hyperbolic periodic orbits is discussed and is by far one of the most detailed I have seen in the literature. The author employs many useful diagrams to give the reader a better intuition behind what is going on. He employs also the pips and lobes terminology of Easton to study the geometry of the homoclinic tangles. Homoclinic bifurcation theory is also treated in great detail. This is followed by an overview of the properties of orbits homoclinic to hyperbolic fixed points. A brief introduction to Lyapunov exponents and strange attractors is also given. <br /> This book has served well as a reference book and should be useful to students and other individuals who are interested in going into this area. It is a subject that has found innumerable applications, and it will continue to grow as more tools and better computational facilities are developed to study the properties of dynamical systems.	2001-06-09
1967186:US	50702879	R28E7MCG6RLPT3	0691057745	226393114	A Non-Random Walk Down Wall Street	Books	5	133	140	N	N	A non-random challenge to the random walk hypothesis	The random walk hypothesis, considered the bedrock of financial theory and modeling, is challenged in this collection of eleven papers by the authors. They attempt in these papers to show that the financial markets do contain a certain degree of predictability, and they illustrate this by both analyzing empirical data and with the development of various mathematical formalisms. It is always interesting when a given paradigm which is entrenched in the minds of a field's practicioners, is challenged and shown to be either inconsistent or not supporting the real facts. The authors make a strong case in this book against the inherent randomness of the financial markets, and they do so in a way that is very understandable. Also, after a consideration of their results, one can construct practical trading software packages that are based on financial models not using the random walk hypothesis. Thus their study is very useful from a practical, everyday trading point of view.<br />  After a brief overview of the efficient markets hypothesis, in the next chapter the authors go right into the analysis of the efficient markets hypothesis by using a specification test based on variance estimators. They conclude from their results that the random walk model is not consistent with the behavior of weekly returns. Interestingly, they find large (negative) autocorrelations in security prices. They do not conclude though that all financial models based on the random walk hypothesis are invalid, but rather they use the specification test to study various stochastic price processes. Since volatilities do change over time, the authors are careful not to reject the random walk hypothesis because of heteroskedasticity; the test they do employ takes into account changing variances. They also discuss the possible role that non-trading practices may have on their conclusions. For the purely mathematical reader, they include in an Appendix to the chapter proofs of the theorems they used in the chapter.<br />  In Chapter 3, the authors employ Monte Carlo simulations to study the variance ratio, Dickey-Fuller, and Box-Pierce tests under  Gaussian null and heteroskedastic null hypotheses. They also consider the power of the variance ratio test against an AR(1) process, AR(1) + random walk, and an integrated AR(1) process models of asset price behavior. The discussion is very thorough, and they conclude that the variance ratio test is a viable tool to use for inference in financial modeling. Since they do inform the reader the particular packages they use to perform the Monte Carlo simulations, their results, which they report in tables in the chapter, can be straightforwardly checked.<br />  A somewhat esoteric but very readable account of what has been called nonsynchronous trading is given in the next chapter. They begin the discussion by employing an interesting and elementary argument that explains very well the consequences of ignoring nonsynchronicity in the sampling of multiple time series. The authors list  ten consequences of the presence of nonsynchronous trading and then study the empirical evidence for nontrading effects. Also, they give a brief summary of the implications of employing Markov chains to build dependence into the nontrading process, motivating readers to perform the necessary calculations on their own.<br />  The next chapter focuses on contrarian investment strategies; namely one that takes advantage of negative serial dependence in asset returns. The authors summarize the data on autocorrelation properties and also present a formal model of a particular contrarian strategy. They conclude, interestingly, that a large portion of contrarian profits cannot be attributed to overreaction.<br />  The most interesting chapter in the book is the next one on long-range dependence in stock market prices, for it is here that many alternative statistical techniques have been devised to study this dependence. The R/S statistic is modified and then used by the authors to test for long-range dependence in daily and monthly stock return indices. Surprisingly, they find that after correcting for short-range dependencies, there is no evidence of long-range dependence in this data.<br />  The authors switch gears somewhat in Chapter 7, where they discuss deviations from the capital asset pricing model. They discuss effectively the two models which attempt to explain these differences, based on risk-based and nonrisk-based alternatives. These two models are proposed as alternatives to the multifactor asset pricing models that have been employed to explain deviations from CAPM.<br />  In chapter 8, data-snooping biases are investigated using the theory of induced order statistics and tested with Monte Carlo simulations. The authors effectively convince the reader of the impact of data-snooping biases in asset pricing models, and how these biases arise from tendencies to focus on anomalous data.<br />  Even more practical considerations are considered in Chapter 9, where the authors show how to maximize predictability in asset returns. They use a model of time-varying premiums to estimate what they call the maximally predictable portfolio, with this model using an out-of-sample rolling estimation technique to avoid data snooping problems. Monte Carlo simulations are again used to validate the results of the models.  They emphasize in their conclusions that predictability does not imply market inefficiency.<br />  Emphasizing the discreteness of real price data, the irregular timing of transaction prices, and the conditional nature of price changes, the authors develop in Chapter 10 a model that addresses these issues using what they call an ordered probit model. They conclude, using some interesting technical analysis with their model and its comparison with empirical data, that discreteness is important in financial modeling.<br />  Chapter 11 is very empirical, wherein the authors study transaction data on the S&amp;P 500 futures contracts with the goal of studying price behavior in relation to arbitrageur strategies. They conclude that on the average, mispricing increases with time to maturity and is path-dependent.<br />  The last chapter of the book discusses the October 1987 stock market crash, with the goal of analyzing order imbalances and stock returns. They conclude that there are notable differences in the returns realized by stocks in the S&amp;P index and those that are not, interestingly.istic is modified and then used by the authors to test for long-range dependence in daily and monthly stock return indices. Surprisingly, they find that after correcting for short-range dependencies, there is no evidence of long-range dependence in this data. <br />   The authors switch gears somewhat in Chapter 7, where they discuss deviations from the capital asset pricing model. They discuss effectively the two models which attempt to explain these differences, based on risk-based and nonrisk-based alternatives. These two models are proposed as alternatives to the multifactor asset pricing models that have been employed to explain deviations from CAPM. <br />    In chapter 8, data-snooping biases are investigated using the theory of induced order statistics and tested with Monte Carlo simulations. The authors effectively convince the reader of the impact of data-snooping biases in asset pricing models, and how these biases arise from tendencies to focus on anomalous data. <br />       Even more practical considerations are considered in Chapter 9, where the authors show how to maximize predictability in asset returns. They use a model of time-varying premiums to estimate what they call the maximally predictable portfolio, with this model using an out-of-sample rolling estimation technique to avoid data snooping problems. Monte Carlo simulations are again used to validate the results of the models.  They emphasize in their conclusions that predictability does not imply market inefficiency. <br />    Emphasizing the discreteness of real price data, the irregular timing of transaction prices, and the conditional nature of price changes, the authors develop in Chapter 10 a model that addresses these issues using what they call an ordered probit model. They conclude, using some interesting technical analysis with their model and its comparison with empirical data, that discreteness is important in financial modeling. <br />     Chapter 11 is very empirical, wherein the authors study transaction data on the S&amp;P 500 futures contracts with the goal of studying price behavior in relation to arbitrageur strategies. They conclude that on the average, mispricing increases with time to maturity and is path-dependent. <br />   The last chapter of the book discusses the October 1987 stock market crash, with the goal of analyzing order imbalances and stock returns. They conclude that there are notable differences in the returns realized by stocks in the S&amp;P index and those that are not, interestingly.	2001-06-08
1967678:US	50702879	R33LXG13IYFV12	0387944265	161297150	Algebraic Topology	Books	3	10	14	N	N	For reference ONLY	This book is a highly advanced and very formal treatment of algebraic topology and meant for researchers who already have considerable background in the subject. A category-theoretic functorial point of view is stressed throughout the book, and the author himself states that the title of the book could have been &quot;Functorial Topology&quot;. It serves best as a reference book, although there are problem sets at the end of each chapter.<br /> After a brief introduction to set theory, general topology, and algebra, homotopy and the fundamental group are covered in Chapter 1. Categories and functors are defined, and some examples are given, but the reader will have to consult the literature for an in-depth discussion. Homotopy is introduced as an equivalence class of maps between topological pairs. Fixing a base point allows the author to define H-spaces, but he does not motivate the real need for using pointed spaces, namely as a way of obtaining the composition law for the loops in the fundamental group. By suitable use of the reduced join, reduced product, and reduced suspension, the author shows how to obtain H-groups and H co-groups. The fundamental group is defined in the last section of the chapter, and the author does clarify the non-uniqueness of the fundamental group based at different points of a path-connected space.<br /> Covering spaces and fibrations are discussed in the next chapter. The author does a fairly good job of discussing these, and does a very good job of motivating the definition of a fiber bundle as a generalized covering space where the &quot;fiber&quot; is not discrete. The fundamental group is used to classify covering spaces.<br /> In chapter 3 the author gets down to the task of computing the fundamental group of a space using polyhedra. Although this subject is intensely geometrical. only six diagrams are included in the discussion.<br /> Homology is introduced via a categorical approach in the next chapter. Singular homology on the category of topological pairs and simplicial homology on the category of simplicial pairs. The author begins the chapter with a nice intuitive discussion, but then quickly runs off to an extremely abstract definition-theorem-proof treatment of homology theory. The discussion reads like one straight out of a book on homological algebra.<br /> This approach is even more apparent in the next chapter, where homology theory is extended to general coefficient groups. The Steenrod squaring operations, which have a beautiful geometric interpretation, are instead treated in this chapter as cohomology operations. The logic used is impeccable but the real understanding gained is severely lacking.<br /> General cohomology theory is treated in the next chapter with the duality between homology and cohomology investigated via the slant product. Characteristic classes, so important in applications, are discussed using algebraic constructions via the cup product and Steenrod squares. Characteristic classes do have a nice geometric interpretation, but this is totally masked in the discussion here.<br /> The higher homotopy groups and CW complexes  are discussed in Chapter 7, but again, the functorial approach used here totally obscures the underlying geometrical constructions.<br /> Obstruction theory is the subject of Chapter8, with Eilenberg-Maclane spaces leading off the discussion. The author does give some motivation in the first few paragraphs on how obstructions arise as an impediment to a lifting of a map, but an explicit, concrete example is what is needed here.<br /> The last chapter covers spectral sequences as applied to homotopy groups of spheres. More homological algebra again, and the same material could be obtained (and in more detail) in a book on that subject.the category of topological pairs and simplicial homology on the category of simplicial pairs. The author begins the chapter with a nice intuitive discussion, but then quickly runs off to an extremely abstract definition-theorem-proof treatment of homology theory. The discussion reads like one straight out of a book on homological algebra. <br /> This approach is even more apparent in the next chapter, where homology theory is extended to general coefficient groups. The Steenrod squaring operations, which have a beautiful geometric interpretation, are instead treated in this chapter as cohomology operations. The logic used is impeccable but the real understanding gained is severely lacking. <br /> General cohomology theory is treated in the next chapter with the duality between homology and cohomology investigated via the slant product. Characteristic classes, so important in applications, are discussed using algebraic constructions via the cup product and Steenrod squares. Characteristic classes do have a nice geometric interpretation, but this is totally masked in the discussion here.<br /> The higher homotopy groups and CW complexes  are discussed in Chapter 7, but again, the functorial approach used here totally obscures the underlying geometrical constructions. <br /> Obstruction theory is the subject of Chapter8, with Eilenberg-Maclane spaces leading off the discussion. The author does give some motivation in the first few paragraphs on how obstructions arise as an impediment to a lifting of a map, but an explicit, concrete example is what is needed here. <br /> The last chapter covers spectral sequences as applied to homotopy groups of spheres. More homological algebra again, and the same material could be obtained (and in more detail) in a book on that subject.	2001-06-08
1970550:US	50702879	RO06ARV9YLPGK	1565928695	474216311	Enterprise JavaBeans (Java Series)	Books	4	17	19	N	N	Recommended	This book gives an excellent overview of Enterprise JavaBeans and their applications. At all times the author does an effective job of relating to the reader the concepts behind this new methodology. Even performance issues involved with the utilization of Enterprise JavaBeans is discussed briefly in the book and both versions 1.0 and 1.1 are covered. The reader is expected to be an expert in the Java programming language, and have familiarity with the JDBC API or SQL.<br />  The author begins Chapter 1 with an introduction to distributed objects, server-side components, and component transaction monitors (application servers).  Enterprise JavaBeans is defined as a server-side component model for component transaction monitors. The standard 3-tier architecture is illustrated, along with definitions of stub and skeleton, and the RMI protocol. Effective diagrams and Java source code are used to describe the distributed object model. The chapter ends with a defense of using server-side components and the author employs an imaginary business application as an illustration of the concepts. This example is expanded upon throughout the rest of the book.<br />  The architecture of EJB is covered in Chapter 2, with entity beans and session beans the two main components. The author carefully distinguishes between these two bean types. The remote interface, the home interface, the bean class, and the primary key are all described in detail and the author shows how to build a bean with relevant Java code. Deployment descriptors, which enable customization of software behavior at runtime, and JAR files, used for packaging Java classes, are both treated in detail. The author is careful also to distinguish the differences between 1.0 and 1.1.<br />  The resource management capability of component transaction monitors are discussed in the next chapter. Application performance is critically dependent on this capability, and the author stresses the benefits of using EJB servers to meet the heavy load requirements while still maintaining optimum performance. State transition diagrams are effectively employed to explain instance swapping, the activation mechanism, concurrency, and persistence of beans. Security of EJB is also discussed with authentication, access control, and secure communication being supported.<br /> In the next chapter the example business application is used to guide the reader through the actual development of an entity bean and a session bean. Again, two different versions of the beans are developed, depending on whether 1.0 or 1.1 is used.<br /> JNDI is used in the next chapter to give an overview of beans from the clients perspective, and allows the application to view the EJB server as a collection of directories. After locating and obtaining the remote reference to the EJB home using JDNI,  a remote reference to the bean can then be obtained. State transition diagrams are again employed to illustrate the Java RMI serialization and remote reference.<br />  The author returns to a more detailed discussion of entity beans in Chapter 6. He outlines the advantages of using entity beans instead of accessing the database directly. Container-managed and bean-managed persistence are thoroughly treated, and the author shows how Create methods come into play for both of these beans. A nice state transition diagram is given for the life cycle of an entity bean along with a detailed description on what causes transitions among the different states.<br /> Session beans are then the topic of Chapter 7, and the author discusses when to use session beans versus entity beans. In addition, the other properties of session beans are discussed and the lifecycles of both a stateless session bean and a stateful session are given in terms of state transition diagrams.<br /> Transactions are discussed in the next chapter, with the concept of declarative transaction management discussed, which allows the transactional behavior to be controlled using the deployment descriptor. The author details the advantages of employing declarative transaction management. Effective diagrams are employed to illustrate transaction attributes. In addition, isolation and database locking is discussed in detail along with explicit transaction management. The later is used with the Java Transaction API used by EJB to deal explicitly with transactions. A very useful state transition diagram is given for the transactional stateful session bean.<br />  The next two chapters are written from a design perspective, and discuss how to solve particular design problems, working with specific databases, and XML deployment descriptors. These chapters are specialized discussions and are geared toward those who are actually involved in the designing and coding of EJB applications. The author does address how to improve performance with session beans, treating in particular the network traffic and latency issues, and resource consumption. Method calls on a remote reference will initiate a remote method invocation loop, which will send streamed data from the stub to the server and then back to the stub, and thus consume bandwidth. Network traffic will mushroom as more clients create more beans, update their states, and request information. Reducing the EJB network traffic is a challenge to the application developer and many proposals have been given on the Web and in the literature for how to best do this. Network modelers have to pay particular attention to these issues when EJB is being deployed in an application to be run over a network.<br />  The last chapter covers the J2EE with discussions of servlets, application client components, and connectivity.<br />  There are very useful appendices inserted at the end, especially Appendix B, which gives the state and sequence UML diagrams for all of the bean types discussed in the book. Appendix D is also useful since it discusses the new features available in EJB 1.1.ntrolled using the deployment descriptor. The author details the advantages of employing declarative transaction management. Effective diagrams are employed to illustrate transaction attributes. In addition, isolation and database locking is discussed in detail along with explicit transaction management. The later is used with the Java Transaction API used by EJB to deal explicitly with transactions. A very useful state transition diagram is given for the transactional stateful session bean. <br />    The next two chapters are written from a design perspective, and discuss how to solve particular design problems, working with specific databases, and XML deployment descriptors. These chapters are specialized discussions and are geared toward those who are actually involved in the designing and coding of EJB applications. The author does address how to improve performance with session beans, treating in particular the network traffic and latency issues, and resource consumption. Method calls on a remote reference will initiate a remote method invocation loop, which will send streamed data from the stub to the server and then back to the stub, and thus consume bandwidth. Network traffic will mushroom as more clients create more beans, update their states, and request information. Reducing the EJB network traffic is a challenge to the application developer and many proposals have been given on the Web and in the literature for how to best do this. Network modelers have to pay particular attention to these issues when EJB is being deployed in an application to be run over a network. <br />   The last chapter covers the J2EE with discussions of servlets, application client components, and connectivity. <br />   There are very useful appendices inserted at the end, especially Appendix B, which gives the state and sequence UML diagrams for all of the bean types discussed in the book. Appendix D is also useful since it discusses the new features available in EJB 1.1.	2001-06-06
1971037:US	50702879	R3V9OU4M339JV	020163354X	174323817	TCP/IP Illustrated: The Implementation, Vol. 2	Books	4	61	62	N	N	Dated but still good....	Even though this book was first published in 1995, it still serves as a useful research and reference guide to those involved in changing the TCP/IP protocol or the mathematical and simulation modeling of it. Most of the source code is included for the protocol and UDP is treated also, with Berkeley TCP/IP used as the protocol implementation. A brief introduction to descriptors and memory buffers is given in Chapter 1, along with a discussion of input processing. The authors treat memory buffers (Mbufs) in detail in Chapter 2. Four different types of Mbufs are used in the protocol, depending on the flag setting in the m_flags member of the header. The source code clearly illustrates the data structures used for the Mbufs. This is followed by a detailed discussion of the Mbuf macros and functions.  This is followed in the next chapter with a discussion of the interface layer and the all-important sockaddr data structure. In addition, the system initialization procedures are treated very nicely. This is followed by a very informative overview of the Ethernet interface, with most of the source code omitted since it is hardware specific. The LANCE driver is discussed thoroughly in this chapter. Then, in the next chapter, the SLIP and loopback interfaces are discussed with a very effective diagram used to illustrate the device drivers. The authors do manage to spend a few helpful paragraphs on SLIP performance considerations.<br />  Chapter 6 is a very detailed treatment of IP addressing, the most useful discussion being the one on the in_ifinit function. This is followed by a discussion of the data structures used in domains and group protocols, with the IP initialization and transport multiplexing discussion being of particular interest to me.<br /> The next 3 chapters give an overview of the IP layer, with IP packet structures and processing, option processing, and fragmentation and assembly all given detailed treatments. The performance issues involved in computing checksums and data copying are discussed also. The treatment of  timeout processing by the function ip_slowtimo, which is very important from a modeling perspective, was given a thorough treatment.<br /> ICMP is discussed in Chapter 11, with an extensive table included of the ICMP message types and codes. The discussion on error processing was particularly useful. This is followed in Chapter 12 by a survey on how IP multicasting is implemented along with Ethernet multicast addresses. A brief discussion of performance issues involved with Ethernet cards not supporting perfect filtering is given.<br /> IGMP is then taken up in the next chapter, with a good discussion given of the virtual interface table in IP multicasting given in the next chapter. The authors carefully discuss the difference between physical interfaces and tunnels.<br /> The most useful discussion in the book for me was the one on sockets in chapters 15, 16, and 17. The code for the socket data structure is given and a very detailed overview of socket system calls is given. The discussion of the listen and accept system calls is very helpful in understanding the process by which TCP sets up a connection. A full description is given of each macro and function involved in socket buffer allocation and manipulation.<br /> Tree routing tables are discussed in chapters 18, 19, and 20, with emphasis on the structure of the radix tree routing tables used by packets, the interface functions between the kernel and the radix tree functions, and the routing sockets used to exchange routing messages. The discussion is extremely detailed, and the authors take great care in explaining the relevant data structures and function calls used.<br /> ARP is discussed in Chapter 21, with a useful diagram given illustrating the relationship between ARP and routing tables and interface data structures. The structure of the ARP packet when transmitted on an Ethernet channel is shown in detail. Most interesting was the discussion on the algorithm used to avoid ARP flooding.<br /> Protocol control blocks are discussed in the next chapter, with detailed treatments of binding, connecting, and demultiplexing. The handling of ICMP errors with the in_pcbnotify function is surveyed, with a detailed diagram summarizing how ICMP errors are processed.<br /> The actual UDP implementation is discussed in Chapter 23, and the authors show how checksumming is done in this protocol. This is followed naturally by a discussion of the TCP implementation in the next 6 chapters. The reader can clearly see the difference in complexity between UDP and TCP in terms of the number of function calls and lines of code. A complete listing of  the statistics used in the  tcpstat data structure is given along with a listing of the SNMP variables used in tcp group. The TCP state transition diagram, familiar from Volume 1 by Stevens is given here also. The discussion of the seven TCP timers is very detailed and very helpful to those involved in the modeling of  TCP performance. In particular the discussion of the tcp_xmit_timer function, which updates the smoothed RTT estimator and the smoothed mean deviation estimator, is very well written. Retransmission timeouts, the occurrence of which is so important in performance analysis and network troubleshooting, is given ample treatment also. Most interesting was the discussion on determining when a segment should be sent, via the tcp_output function. Also, the reassembly mechanism with the tcp_reass function is discussed in great detail. The reader who needs to be a TCP expert should take away a thorough understanding of it when completing these chapters.<br />  The book ends with a fairly detailed treatment of the BSD Packet Filter and raw IP.<br />  Noticeably missing of course, because of its age, is a discussion of the different versions of TCP/IP currently implemented in Windows 2000, Sun Solaris etc, which are slightly different. The reader will have to consult the Web or modern books to get an understanding of these implementations.the discussion on the algorithm used to avoid ARP flooding. <br /> Protocol control blocks are discussed in the next chapter, with detailed treatments of binding, connecting, and demultiplexing. The handling of ICMP errors with the in_pcbnotify function is surveyed, with a detailed diagram summarizing how ICMP errors are processed. <br /> The actual UDP implementation is discussed in Chapter 23, and the authors show how checksumming is done in this protocol. This is followed naturally by a discussion of the TCP implementation in the next 6 chapters. The reader can clearly see the difference in complexity between UDP and TCP in terms of the number of function calls and lines of code. A complete listing of  the statistics used in the  tcpstat data structure is given along with a listing of the SNMP variables used in tcp group. The TCP state transition diagram, familiar from Volume 1 by Stevens is given here also. The discussion of the seven TCP timers is very detailed and very helpful to those involved in the modeling of  TCP performance. In particular the discussion of the tcp_xmit_timer function, which updates the smoothed RTT estimator and the smoothed mean deviation estimator, is very well written. Retransmission timeouts, the occurrence of which is so important in performance analysis and network troubleshooting, is given ample treatment also. Most interesting was the discussion on determining when a segment should be sent, via the tcp_output function. Also, the reassembly mechanism with the tcp_reass function is discussed in great detail. The reader who needs to be a TCP expert should take away a thorough understanding of it when completing these chapters. <br />  The book ends with a fairly detailed treatment of the BSD Packet Filter and raw IP. <br />   Noticeably missing of course, because of its age, is a discussion of the different versions of TCP/IP currently implemented in Windows 2000, Sun Solaris etc, which are slightly different. The reader will haveto consult the Web or modern books to get an understanding of these implementations.	2001-06-05
1971067:US	50702879	R3IFMSR9FJQUG6	0072121157	641023638	CISCO: A Beginner's Guide	Books	4	36	36	N	N	Very elementary introduction to Cisco	This book is an introduction to Cisco technology and Cisco's IOS operating system. It also instructs the reader on how to deal with Cisco routers, switches, hubs, and access servers. The first chapter starts with an overview of the Internet and how Cisco technology has positioned itself in the Internet explosion. The discussion is very general, and defines the terminology and basic network configurations currently of use in the Internet and networks in general. A listing of the SOHO, midrange, and backbone routers is given along with brief descriptions of each.  Access switches and Catalyst switches are also discussed, and the authors are careful to distinguish between access switches and LAN switches.<br /> This is followed in Chapter 2 by a very elementary overview of networking and is written for the absolute beginner. The OSI reference model is discussed in detail, along with an overview of Ethernet, Token Ring, and ATM network technologies. WAN trunk technologies are also covered very quickly, with T1, T3, Frame Relay, and VPN discussed. The discussion of TCP/IP is fairly detailed and a should be very informative for those exposed to this protocol for the first time. The chapter ends with an overview of IP addressing, and again, at a very understandable level. Both of the first two chapters could be skipped by a reader with more preparation.<br />  My interest in this book was from a network modeling perspective, so I did not read Chapter 3 since I was not interested in Cisco certification.<br />  Chapter 4 gives a good overview of Cisco routers, and shows how to log on to Cisco routers directly. A quick discussion of router security is given in this chapter along with an overview of hardware. The later half of this chapter, and the next chapter on configuring routers, are written more for the network administrator, with a thorough treatment given. Chapter 6 covers switches and hubs, and the treatment is fairly general, with a detailed introduction to firewalls. How to configure firewalls to deal with intrusion and denial-of-service attacks is treated very well. Particularly helpful was the discussion of the Cisco PIX firewall and the Adaptive Security Algorithm. The chapter ends with a quick overview of VPNs.<br />  Chapter 7 begins the discussion on network design, and the authors do a good job of explaining how routing protocols succeed in delivering packets to the correct destination. Although non-mathematical, the discussion on insuring loop-free routing is a fairly good one, and introduces the reader to hold-downs, split horizons, and Poisson reverse.The discussion on routing protocol architectures is fairly helpful, for it discusses distance-vector routing and link-state routing. A fairly good overview of the Cisco routing protocols is given, wherein IGRP and EIGRP are discussed, along with OSPF and BGP. Performance issues with these routing protocols are not discussed however, unfortunately.<br />  The next chapter on network management is very helpful for those who need to understand how networks are monitored for performance. The SMNP protocol is discussed along with how MIBS collect, poll, and aggregate network information. A detailed diagram of the Cisco private MIB hierarchy is given, showing how it is broken into four subgroups. In addition, the authors show how SNMP commands can be used to set thresholds for a particular SMNP variable. The use of traps to report alarms is discussed nicely also. The authors then move on to a discussion of RMON probes in switched networks. They explain effectively why the incorporation of the RMON probe directly into the switch's hardware can insure visibility across switched networks. The chapter ends with a detailed discussion of Ciscoworks2000, CWSI, and NetSys Baseliner. The later is a modeling tool used for baselining by the use of RMON probes and IOS device accounting.<br />  Chapter 10 is a detailed discussion of how Cisco implements security into their devices. The authors outline access list and firewall security strategies, along with the AAA security framework. The two security protocols in AAA, TACACS and RADIUS, are treated in great detail.Unfortunately, the security protocol Kerberos is only given scant discussion, even though IOS includes Kerberos commands in its AAA framework.The CiscoSecure ACS package is also discussed thoroughly. The chapter ends with a short overview of dynamic access lists.<br />  The next chapter covers how to design networks using Cisco hardware.The three-layer hierarchical design model and the consequent deployment of hierarchical topologies is discussed as a superior design strategy over flat network topologies. The authors give a good discussion on the access, distribution, and core layers. Design methodologies, such as redundancy,load balancing, topology meshing, and backdoor and chain configurations are discussed in detail. There is also a short discussion on QoS. The chapter ends with an overview of logical network design, including IP addressing strategies, and DNS.<br />  The last chapter of the book considers network troubleshooting, with the discussion geared toward the actual steps taken to pinpoint network problems, such as host IP configuration and connectivity problems. A detailed treatment of the most common Ethernet statistics is given and a good discussion of troubleshooting WAN links.<br />  The book serves well as an elementary introduction to networking via Cisco hardware products and should server well those who are approaching this subject for the first time. As someone interested in network modeling,I found the book helpful mostly in the discussions on network management and network security. The book will pave the way for more advanced reading on the subject.y into their devices. The authors outline access list and firewall security strategies, along with the AAA security framework. The two security protocols in AAA, TACACS and RADIUS, are treated in great detail.Unfortunately, the security protocol Kerberos is only given scant discussion, even though IOS includes Kerberos commands in its AAA framework.The CiscoSecure ACS package is also discussed thoroughly. The chapter ends with a short overview of dynamic access lists. <br />      The next chapter covers how to design networks using Cisco hardware.The three-layer hierarchical design model and the consequent deployment of hierarchical topologies is discussed as a superior design strategy over flat network topologies. The authors give a good discussion on the access, distribution, and core layers. Design methodologies, such as redundancy,load balancing, topology meshing, and backdoor and chain configurations are discussed in detail. There is also a short discussion on QoS. The chapter ends with an overview of logical network design, including IP addressing strategies, and DNS. <br />     The last chapter of the book considers network troubleshooting, with the discussion geared toward the actual steps taken to pinpoint network problems, such as host IP configuration and connectivity problems. A detailed treatment of the most common Ethernet statistics is given and a good discussion of troubleshooting WAN links. <br />    The book serves well as an elementary introduction to networking via Cisco hardware products and should server well those who are approaching this subject for the first time. As someone interested in network modeling,I found the book helpful mostly in the discussions on network management and network security. The book will pave the way for more advanced reading on the subject.	2001-06-05
1971409:US	50702879	R2TZV8U8J0X8JD	013617549X	969598800	Network Flows: Theory, Algorithms, and Applications	Books	4	25	29	N	N	Very complete	This book is a comprehensive overview of network flow algorithms with emphasis on cost constraint algorithms. In chapter 1 the authors introduce the network flow problems that will be studied in the book along with a discussion of the applications of these problems.<br />  The terminology needed for network flow problems  is introduced in Chapter 2, with rigorous definitions given for graphs, trees, and network representations. Most interesting is the discussion on network transformations, for here the authors discuss how to simplify networks to make their study more tractable.<br />  An overview of complexity concepts in algorithms is given in the next chapter. A good discussion is given on parameter balancing. Pseudocode is given at various places to illustrate the algorithms.<br />  Chapter 4 discusses shortest-path algorithms, with emphasis on label-setting algorithms. For network modelers and designers involved in routing algorithms, there is a nice discussion of Dijkstra's algorithm in this chapter, along with a treatment of how to improve on  that algorithm by using Dial's, heap, and radix heap implementations.<br />  A more general discussion of shortest path algorithms follows in Chapter 5, with details on label-correcting algorithms. The reader is asked to investigate the Bellman's equations in the exercises.<br /> The maximum flow algorithm is treated in Chapter 6, and the reader with a background in linear programming will see ideas from that area applied nicely here. An application to parallel programming is given also. The maximum flow problem is treated using algorithms that improve worst-case complexity in Chapter 7, by employing the preflow-push algorithms. Even more approaches to the maximum flow problem are considered in Chapter 8, where the reader can find a good presentation of dynamic tree implementations.<br /> All of the algorithms up to this point are put into the context of the minimum cost flow problem in Chapter 9. It is here that optimality conditions become very transparent in the implementation of the algorithms. A very quick but helpful discussion is given on sensitivity analysis of the minimum cost flow problem. An interesting application of the results is given to the problem of reconstructing the left ventricle in the heart from X-ray projections. Polynomial time algorithms for minimum cost flows are discussed effectively in Chapter 10, which is followed by a discussion of using linear programming methods in the minimum cost flow problem in Chapter 11.<br /> The application of combinatorial optimization techniques is the subject of Chapter 12, where matching problems are discussed. The authors give a thorough treatment, along with many examples.<br /> Spanning trees again make their appearance in Chapter 13, via the minimum spanning tree problem. The all-important Kruskal algorithm is given a detailed treatment, along with a very interesting discussion of matroids.<br /> Nonlinear optimization via convex cost flows is the subject of Chapter 14, wherein the authors show how to transform a convex cost flow problem into a minimum cost flow problem.<br />  Flow problems that are not conservative at the nodes are the subject of the next chapter on generalized flow problems. The solutions of these problems are discussed within the context of augmented forest structures, and many applications are given.<br />  Lagrangian methods are the subject of Chapter 16, where the authors show how to solve constrained shortest path algorithms using Lagrangian relaxation. It is here that one can see the interplay between all of the techniques introduced so far. Particularly interesting is the discussion on applications to the traveling salesman problem, vehicle routing, and network design.<br />Flow problems where more than one entity are transferred across the network are the subject of Chapter 17, and logistic planners and engineers will find the treatment very helpful.<br />  Most helpful to those using network flow algorithms in their everyday work is the discussion in Chapter 18 on the computational testing of algorithms. The authors give a fine discussion on how to identify bottlenecks, compare performance differences between two algorithms, and how to use virtual running times instead of CPU times to test algorithms.<br />  The book ends with a chapter on more applications of network flow problems. Twenty-four applications are discussed, the most interesting ones to me being the optimal destruction of military targets, data scaling, DNA sequence alignment, automatic karyotyping of chromosomes, minimum project duration, just-in-time scheduling, warehouse layout, and inventory planning.l to those using network flow algorithms in their everyday work is the discussion in Chapter 18 on the computational testing of algorithms. The authors give a fine discussion on how to identify bottlenecks, compare performance differences between two algorithms, and how to use virtual running times instead of CPU times to test algorithms. <br />    The book ends with a chapter on more applications of network flow problems. Twenty-four applications are discussed, the most interesting ones to me being the optimal destruction of military targets, data scaling, DNA sequence alignment, automatic karyotyping of chromosomes, minimum project duration, just-in-time scheduling, warehouse layout, and inventory planning.	2001-06-05
1971866:US	50702879	R3SJVL68Q9S3BJ	0387968709	295177628	An Introduction to Hilbert Space and Quantum Logic (Problem Books in Mathematics)	Books	4	20	20	N	N	Effective introduction	This book gives a nice introduction to the mathematical formalism behind quantum physics and the logic of measurement.  The first chapter gives an introduction to measure theory with emphasis on probabilities of measurement outcomes. The author is careful to point out that the calculation of the Lebesgue integral presents more difficulties than in the Riemann integral case, since the fundamental theorem of calculus does not apply to Lebesgue integrals.<br /> This is followed by an elementary introduction to Hilbert space in Chapter 2. This is standard material and most of the proofs of the main results are omitted and left to the reader as projects.<br /> Chapter 3 is more controversial, and attempts to formulate a logic of experimentation for &quot;non-classical&quot; systems. This is done by use of what the author calls a &quot;manual&quot;, which is viewed as an abstraction of the experimenters knowledge about a physical system. A manual is a collection of experiments, and an &quot;event&quot; is a subset of an experiment. Orthogonality of events is defined, along with the notion of a collection of events being &quot;compatible&quot;, meaning that there is an experiment that contains all of these events. A manual is called &quot;classical&quot; if every pair of events is compatible. The author then exhibits systems that are not classical via the double-slit and Stern-Gerlach experiments. A logic of events is then developed in the next section, where quantum logic is defined explicitly. The author defines a pure state that is not dispersion-free as a state of ontological uncertainty as opposed to &quot;epistemic&quot; uncertainty. Quantum systems have states that are ontologically uncertain according to the author. The author chooses not to engage in the debate about the actual existence of these states and, accordingly, no real-world experiments are given to illustrate the relevance of the concepts and definitions.<br /> The next chapter covers the geometry of infinite-dimensional Hilbert spaces. The structure of the collection of these subspaces is defined in terms of the quantum logic defined earlier. This is followed by a discussion of maps on Hilbert spaces, as preparation for defining observables in quantum systems. The important Riesz representation theorem is stated but the proof left to the reader. Projection operators are defined also with the eventual goal of relating them to the compatibility of two propositions.<br /> Gleason's theorem is discussed in Chapter 6, along with a discussion of the geometry of state space. The proof of Gleason's theorem is omitted, the author emphasizing its difficulty. The proof in the literature is non-constructive and thus the theorem is suspect according to some schools of thought.<br /> The spectral theorem, so important in quantum physics, is discussed in the next chapter. Once again the proofs are left to the reader for most of the results. The spectral theorem allows the author to define another notion of compatibility in terms of the commutativity of two Hermitian operators.<br /> The books ends with a overview of the EPR dilemna and is naturally more controversial than the rest of the book. This topic has provoked much philosophical debate, and the author gives the reader a small taste of this in this chapter.<br />  The book does serve its purpose well, and regardless of one's philosophical position on quantum physics, the mathematical formulations of quantum physics and measurement theory are nicely expounded in this book.infinite-dimensional Hilbert spaces. The structure of the collection of these subspaces is defined in terms of the quantum logic defined earlier. This is followed by a discussion of maps on Hilbert spaces, as preparation for defining observables in quantum systems. The important Riesz representation theorem is stated but the proof left to the reader. Projection operators are defined also with the eventual goal of relating them to the compatibility of two propositions. <br /> Gleason's theorem is discussed in Chapter 6, along with a discussion of the geometry of state space. The proof of Gleason's theorem is omitted, the author emphasizing its difficulty. The proof in the literature is non-constructive and thus the theorem is suspect according to some schools of thought. <br /> The spectral theorem, so important in quantum physics, is discussed in the next chapter. Once again the proofs are left to the reader for most of the results. The spectral theorem allows the author to define another notion of compatibility in terms of the commutativity of two Hermitian operators. <br /> The books ends with a overview of the EPR dilemna and is naturally more controversial than the rest of the book. This topic has provoked much philosophical debate, and the author gives the reader a small taste of this in this chapter. <br />    The book does serve its purpose well, and regardless of one's philosophical position on quantum physics, the mathematical formulations of quantum physics and measurement theory are nicely expounded in this book.	2001-06-05
1973834:US	50702879	R1V4TUSWPFLY4Y	0387908196	673745456	Nonlinear Oscillations, Dynamical Systems, and Bifurcations of Vector Fields (Applied Mathematical Sciences)	Books	4	39	41	N	N	Will never collect dust....	This book has been a continuing source of information and guidance for 18 years now. Students and researchers in many different fields have used this book due to its breadth and detail of coverage. The book does require a fairly advanced mathematical background, but the authors do include a glossary for the reader lacking this.<br />  Chapter one is an overview of differential equations and dynamical systems. All the concepts needed for a study of such systems are discussed in great detail and also very informally, stressing instead the understanding of the concepts, and not merely their definition. Some of the proofs of the main results, such as the Hartman-Grobman and the stable manifold theorems, are omitted however.<br />  This is followed in Chapter 2 by a very intuitive discussion of the van der Pols equation, Duffings equation, the Lorenz equations, and the bouncing ball. Numerical calculations are effectively employed to illustrate some of the main properties of the systems modeled by these equations.<br />  A taste of bifurcation theory follows in Chapter 3. Center manifolds are defined and many examples are given, but the proof of the center manifold theorem is omitted unfortunately. Normal forms and Hopf bifurcations are treated in detail.<br />  Averaging methods are discussed in Chapter 4, with part of the averaging theorem proved using a version of Gronwall's lemma. Several interesting examples of averaging are given, along with a discussion of to what extent the bifurcation properties of the averaged equations carry over to the original equations. Most importantly, this chapter discusses the Melnikov function, so very important in the study of small perturbations of dynamical systems with a hyperbolic fixed point. A full proof that simple zeros of the Melnikov function imply the transversal intersection of the stable and unstable manifolds is given.<br />  Chapter 5 moves on to results of a more purely mathematical nature, where symbolic dynamics and the Smale horseshoe map are discussed. The proofs of the stable manifold theorem and the Palis lambda lemma are, however, omitted. Markov partitions and the shadowing lemma are discussed also but the latter is not proven. The authors do however give a proof of the Smale-Birkhoff homoclinic theorem. A purely mathematical overview of attractors is given along with measure-theoretic (ergodic) properties of dynamical systems.<br />  The (local) bifurcation theory of Chapter 3 is extended to global bifurcations in the next chapter. A very detailed discussion of rotation numbers is given but the KAM theory is only briefly mentioned. The main emphasis is on 1-dimensional maps, the Lorentz system, and Silnikov theory. The authors give a very detailed treatment of wild hyperbolic sets.<br />  The book ends with a discussion of bifurcations from equilibrium points that have multiple degeneracies. The discussion is more motivated from a physical standpont than the last few chapters. But some interesting mathematical constructions are employed, namely the role of k-jets, which have  fascinating connections with algebraic goemetry, via the &quot;blowing-up&quot; techniques.<br />  The concepts in the book have proven to have enduring value in the study of dynamical systems, and this book will no doubt continue to serve students and researchers in the years to come.where symbolic dynamics and the Smale horseshoe map are discussed. The proofs of the stable manifold theorem and the Palis lambda lemma are, however, omitted. Markov partitions and the shadowing lemma are discussed also but the latter is not proven. The authors do however give a proof of the Smale-Birkhoff homoclinic theorem. A purely mathematical overview of attractors is given along with measure-theoretic (ergodic) properties of dynamical systems. <br />   The (local) bifurcation theory of Chapter 3 is extended to global bifurcations in the next chapter. A very detailed discussion of rotation numbers is given but the KAM theory is only briefly mentioned. The main emphasis is on 1-dimensional maps, the Lorentz system, and Silnikov theory. The authors give a very detailed treatment of wild hyperbolic sets. <br />   The book ends with a discussion of bifurcations from equilibrium points that have multiple degeneracies. The discussion is more motivated from a physical standpont than the last few chapters. But some interesting mathematical constructions are employed, namely the role of k-jets, which have  fascinating connections with algebraic goemetry, via the &quot;blowing-up&quot; techniques. <br />    The concepts in the book have proven to have enduring value in the study of dynamical systems, and this book will no doubt continue to serve students and researchers in the years to come.	2001-06-03
1974131:US	50702879	R26PLYF31PD3TX	0262011972	17969396	The Handbook of Brain Theory and Neural Networks: Second Edition	Books	5	1	1	N	Y	An excellent reference	Review of Second Edition (January 2008):<br /><br />This sizable collection of articles updates the first volume with many discoveries and conceptual developments that were unknown at the time. Meant of course for reference, a typical reader, such as this reviewer, would probably not read every article in the collection but would instead concentrate on the ones of primary interest. The editor however does offer advice on \\"how to use this book\\" at the beginning of the book, for those readers who intend to use it as their primary source of information, or for instructors who will use it as a supplement to such classes as brain theory, artificial intelligence, computational neuroscience, and cognitive neuroscience. All of these topics are represented, with emphasis of course on those that the editor finds important. Time constraints will of course play in role in any sampling algorithm for the articles, but every article that was studied by this reviewer was well worth the time spent.<br /><br />One of these articles, written by the editor, gave an overview of his work on the `mirror system hypothesis' (MSH). This work has been widely discussed in the literature on evolutionary linguistics since the first edition of this book, and when confronting it for the first time may seem like a radical hypothesis.  Such skepticism is aggravated by the lack of any historical record for the structure of the brain, and so any theories on language evolution will remain more tentative as compared to other scientific theories. The editor though wants the reader to consider evidence for the mirror system hypothesis that is drawn from existing life forms. Thus he proposes that we examine the \\"mirror system\\" for grasping in monkeys, which he asserts contains `mirror neurons\\" that are activated when the monkey performs a specific hand action and when it only observes a human or other monkey performing a similar action. The MSH is the assertion that the matching in the neural code between observation and execution occurs in the common ancestor of monkey and human. Further, this matching explains the notion of language `parity', which asserts that a spoken utterance has essentially identical semantics between speaker and listener. The editor reviews his ideas on what brain mechanisms are responsible for language and grasping, and whether a mirror system is indeed present in humans. Experiments using proton emission topography support his thesis to some extent, but he cautions that the a lot more work needs to be done before one can make definitive conclusions. His thesis though is a plausible one on the surface, and interesting in that it proposes that language originally evolved not from a need for communication but from a need to recognize a set of actions. \\"Language readiness\\" then, resulted from an extension of the mirror system from being able to recognize single actions to being able to imitate compound actions. A natural question to ask here is why sophisticated grammatical constructions, some of them semantically awkward and of no practical value, would evolve from the mere need to imitate, which itself is not really complex from any reasonable measure of complexity. The editor is aware of these kinds of objections, for in the article he addresses them under the guise of `protospeech', wherein he postulates two evolutionary stages for its development. His assertions in this regard are interesting for they involve the need for cooperation between two or more areas of the brain. Along these same lines, and even more fascinating, is the editor's discussion on neuronal models for the mirror system, for when he proposes a canonical structuring for sentences he is actually asserting a kind of \\"entanglement\\" (he does not use this terminology in the article) between the F5 area and its mirror.<br /><br />Review of First Edition:<br />This complilation of articles by leading experts in the field gives an excellent overview of studies in cognitive theory and the theory and applications of neural networks. The first two parts of the book give an overview and background of the properties of neurons and gives guidance to the reader on what sequence the articles are to be read. This reviewer did not read all of the articles, but only those that piqued his interest. such as the following articles which are particularly well-written and informative: 1. \\"Applications of Neural Networks\\": Outlines the diverse applications of neural networks to signal processing, time series, imaging, etc. 2. \\"Astronomy\\": Neural network applications in astronomy, such as adaptive optics and telescope guidance. 3. \\"Chains of Coupled Oscillators\\": Their connection with the lamprey central pattern generator.  4. \\"Chaos in Axons\\": An excellent review of chaos experimentally in squid axons and numerically with nerve equations.  5. \\"Collective Behavior of Coupled Oscillators\\": A study of the phase and complex Ginzburg-Landau model.  6. \\"Computer Modeling Methods for Neurons\\": Good overview of numerical modeling of neurons.  7. \\"Computing with Attractors\\": Overview of omputing and feedback networks with attractors and a fascinating discussion of the possible existence of attractors in the brain.  8. \\"Constrained Optimization and the Elastic Net\\": Useful discussion of application of neural networks to optimization problems.  9. \\"Data Clustering and Learning\\": Good discussion of parameter estimation of mixture models by parametric statistics and vector quantization of a data set by combinatorial optimization.  10. \\"Diffusion Models of Neuron Activity\\": Discusses 1-dimensional stochastic diffusion models for the neuron membrane potential.  11. \\"Disease: Neural Network Models\\": Interesting overview of neural net computational models of various mental illnesses.  12. \\"Dynamics and Bifurcation of Neural Networks\\": Discussion of neural nets and their behavior as dynamical systems.  13. \\"Emotion and Computational Neuroscience\\": Fascinating discussion of computational models of emotion.  14. \\"Investment Management\\": A discussion of tactical asset allocation neural network methods in asset management.  15. \\"Learning and Centralization: Theoretical Bounds\\": Overview of computational learning theory.  16. \\"Locust Flight\\": Interesting neural network study of the locust flight system. 17. \\"Neural Optimization\\": Discussion of combinatorial optimization using Ising and Potts neural networks.  18. \\"PAC Learning and Neural Networks\\": Overview of the Valiant \\"probabilistically correct learning paradigm in neural networks.  19. \\"Protein Structure Prediction\\": Neural network applications to prediction of protein secondary structure.  20. \\"Schema Theory\\": Extremely interesting overview of schemas.  21. \\"Speech Recognition: Pattern Matching\\": Excellent discussion of the applications of hidden Markov models to speech recognition.  22. \\"Statistical Mechanics of Neural Networks\\": Discussion of the use of the Hopfield model in neural networks.  23. Vapnik-Chervonenkis Dimension of Neural Networks\\": Very interesting discussion of the VC-dimension of neural networks.cations of neural networks. The first two parts of the book give an overview and background of the properties of neurons and gives guidance to the reader on what sequence the articles are to be read. This reviewer did not read all of the articles, but only those that piqued his interest. such as the following articles which are particularly well-written and informative: 1. \\"Applications of Neural Networks\\": Outlines the diverse applications of neural networks to signal processing, time series, imaging, etc. 2. \\"Astronomy\\": Neural network applications in astronomy, such as adaptive optics and telescope guidance. 3. \\"Chains of Coupled Oscillators\\": Their connection with the lamprey central pattern generator.  4. \\"Chaos in Axons\\": An excellent review of chaos experimentally in squid axons and numerically with nerve equations.  5. \\"Collective Behavior of Coupled Oscillators\\": A study of the phase and complex Ginzburg-Landau model.  6. \\"Computer Modeling Methods for Neurons\\": Good overview of numerical modeling of neurons.  7. \\"Computing with Attractors\\": Overview of omputing and feedback networks with attractors and a fascinating discussion of the possible existence of attractors in the brain.  8. \\"Constrained Optimization and the Elastic Net\\": Useful discussion of application of neural networks to optimization problems.  9. \\"Data Clustering and Learning\\": Good discussion of parameter estimation of mixture models by parametric statistics and vector quantization of a data set by combinatorial optimization.  10. \\"Diffusion Models of Neuron Activity\\": Discusses 1-dimensional stochastic diffusion models for the neuron membrane potential.  11. \\"Disease: Neural Network Models\\": Interesting overview of neural net computational models of various mental illnesses.  12. \\"Dynamics and Bifurcation of Neural Networks\\": Discussion of neural nets and their behavior as dynamical systems.  13. \\"Emotion and Computational Neuroscience\\": Fascinating discussion of computational models of emotion.  14. \\"Investment Management\\": A discussion of tactical asset allocation neural network methods in asset management.  15. \\"Learning and Centralization: Theoretical Bounds\\": Overview of computational learning theory.  16. \\"Locust Flight\\": Interesting neural network study of the locust flight system. 17. \\"Neural Optimization\\": Discussion of combinatorial optimization using Ising and Potts neural networks.  18. \\"PAC Learning and Neural Networks\\": Overview of the Valiant \\"probabilistically correct learning paradigm in neural networks.  19. \\"Protein Structure Prediction\\": Neural network applications to prediction of protein secondary structure.  20. \\"Schema Theory\\": Extremely interesting overview of schemas.  21. \\"Speech Recognition: Pattern Matching\\": Excellent discussion of the applications of hidden Markov models to speech recognition.  22. \\"Statistical Mechanics of Neural Networks\\": Discussion of the use of the Hopfield model in neural networks.  23. Vapnik-Chervonenkis Dimension of Neural Networks\\": Very interesting discussion of the VC-dimension of neural networks.	2001-06-03
1974468:US	50702879	R216502WZJVESL	0691027307	799183167	The Classical and Quantum 6j-symbols. (MN-43)	Books	4	1	1	N	N	Good introduction to topological quantum field theory	This book is an excellent introduction to the concepts and techniques used to define invariants of closed 3-dimensional manifolds using the representation theory of U(sl(2)). Starting with the well-known results in the finite-dimensional irreducible representations of SL(2) via the Clebsch-Gordan theory, one can decompose the tensor product of these representations in two ways. The two decompositions can be compared using recoupling theory, with the coefficients being the ubiquitous 6j-symbols, so familiar to physicists in the theory of angular momentum. The orthogonality and Elliott-Biedenharn identities of the 6j-symbols have a geometric interpretation as the union of two tetrahedra. The quantum analog of these results for sl(2) leads to the Turaev-Vivo invariants of 3-manifolds, with the Elliott-Biedenharn identity corresponding to an Alexander move on a triangulation of a 3-manifold and the orthogonality condition corresponding to a Matveev move on the dual 2-skeleton of a triangulation.<br />  The book could thus be considered an introduction to the theory of &quot;quantum topology&quot;. The authors employ many diagrams to illustrate the beautiful connections between topology and algebra using the reprensentations of U(sl(2)) and the &quot;quantized&quot; version where the representation spaces are homogeneous polynomials in two variables that commute modulo a parameter. These constructions are generalizations of the ones that are employed  in studying exactly solved models in statistical mechanics using the Yang-Baxter equation. This theory is now called quantum groups, even though strictly speaking, the objects dealt with are more general than groups and the adjective &quot;quantum&quot; means only a lack of commutation up to a parameter (usually called q). Very interesting is the way in which braid groups appear as realizations of quantum representation spaces. Quotient representations have to be considered since in general the representations of the braid group are not semi-simple.<br />  For a representation of Uq(sl(2)) the authors define trace, called the &quot;quantum trace&quot;, in this representation which gives the required invariants. These invariants however are not finer than other 3-manifold invariants unfortunately. The authors do show to what extent two 3-manifolds with the same Turaev-Viro invariants are similar, and show the equivalence between the Turaev-Viro and Kauffman-Lins invariants. These invariants are examples of topological quantum field theories, which have grown out of considerations from high energy physics, and which will no doubt continue to be of considerable interest in the future.raid group are not semi-simple. <br />  For a representation of Uq(sl(2)) the authors define trace, called the &quot;quantum trace&quot;, in this representation which gives the required invariants. These invariants however are not finer than other 3-manifold invariants unfortunately. The authors do show to what extent two 3-manifolds with the same Turaev-Viro invariants are similar, and show the equivalence between the Turaev-Viro and Kauffman-Lins invariants. These invariants are examples of topological quantum field theories, which have grown out of considerations from high energy physics, and which will no doubt continue to be of considerable interest in the future.	2001-06-03
1978742:US	50702879	R15P1BMDVK8B5C	0716724154	103030383	Ornithology	Books	5	64	66	N	N	Could not put it down....	This superb book was such fun to read and it is packed full of interesting and thought-provoking information. Space prohibits a chapter-by-chapter review so I will list the things in the book that I found very interesting: 1. The plumage color patterns of dawny young shorebirds. 2. DNA hybridization experiments and evolutionary tree of herons. 3. Geese flying in formation to save energy. 4. The use of thermals by a gliding vulture to counteract sinking. 5. The unique landing abilities of birds: rotation of center of mass upward to stall directly over the landing site. 6. Vortex creation by beating wings of pigeons and kestrels. 7. Respiratory abilities of birds. 8. High metabolic rates of frizzled chickens. 9. Discussion on avian intelligence. 10. The detection of natural magnetic fields using rhodopsin. 11. Use of echolocation for navigation; asymmetry of ear placement in the owl to pinpoint sound source. 12. The avian taste for chili peppers. 13. Birds having two independent voices. 14. Individual spacing behavior while perching. 15. The nests of swallows reflecting their evolutionary history. 16. Insurance egg laying by penguins and boobies.17. The restoration of the peregrines. 18. The illustrations of the birds of the world in the appendix. 19. The enormous bibliography.  This is definitely a book to be read by students and those interested in ornithology. An incredible book.......	2001-05-30
1981631:US	50702879	R1R0WKTTYSHC13	0806905492	876450095	Cacti & Succulents	Books	5	10	10	N	N	Beautiful job	This book gives a comprehensive overview of the more important species of cacti and succulents. The photographs are beautiful and the information content is superb. For cacti and succulent lovers/keepers, the author gives very helpful advice on their care and maintenance. In addition, he gives a short discussion at the beginning on the evolution of cacti and succulents. The myriads of different shapes taken on by these plants are a constant source of amazement, for they can be highly symmetric as well as twisted and deformed. The photographs in the book are a marvelous example of this variety.<br />  A short dictionary of terms is inserted at the beginning of the book for the beginner who is approaching cacti for the first time. The botanical names are given for each entry and the author gives recommendations on the cacti that bloom the easiest. A section on propagation and grafting is also included in the book.<br />  A very delightful book on a class of plants that are intriguing in every way.	2001-05-28
1982072:US	50702879	R3TJN9BWY3ECJX	0387903577	970327656	Elementary Topics in Differential Geometry (Undergraduate Texts in Mathematics)	Books	4	11	12	N	N	A good start	This book could be considered as the second semester of an advanced calculus course and serves as an excellent introduction to differential geometry. The approach is rigorous, but the author does employ a great deal of illustrations to explain the relevant concepts. The first five chapters cover vector fields on curves and surfaces. The many concrete examples given by the author illustrate effectively the normal and tangent vector fields. The Gauss map is then appropriately introduced in Chapter 6 and shown to be onto for compact, connnected, oriented n-dimensional surfaces in n+1-dimensional Euclidean space.<br />  This is followed by a discussion of geodesics and parallel transport in the next two chapters. The important concept of holonomy is introduced in the exercises along with the Fermi derivative. These ideas are extremely important in physical applications and must be understood in depth if the reader is to go into areas such as general relativity and high energy physics.<br />The next chapter considers the local behavior of curvature on an n-surface via the Weingarten map. The important concept of the covariant derivative is introduced. The concept of a geodesic spray, so important in the theory of differential equations, is introduced in the exercises.  The curvature of plane curves is treated in Chapter 10 with the circle of curvature introduced. The Frenet formulas, which relate the tangent and normal vectors to the curvature and torsion, are discussed in the exercises. The curvature of surfaces is discussed later in Chapter 12 with the first and second fundamental form introduced, along with the very important Gauss-Kronecker curvature. And in this chapter the author introduces the idea of local and global properties of an n-surface. Although not rigorous, the discussion is helpful for students first introduced to these concepts.<br />  After a nice overview of convex surfaces, the parametrization of surfaces is discussed in the next two chapters, where the inverse function theorem for n-surfaces is proved. This is followed by a consideration of focal points with Jacobi fields discussed in the exercises.<br />  More measure-theoretic concepts are discussed in the next chapter on surface area and volume. Partitions of unity are brought in so as to define the integral of an n-form over a compact oreinted n-surface. Exterior products of forms are introduced in the exercises.<br />  Soap bubble enthusiasts will appreciate the discussion on minimial surfaces in Chapter 18. Although very short, the author's treatment does bring out the important ideas. Minimal surfaces have taken on particular important in the new membrane theories in high energy physics recently. This is followed by a detailed treatment of the exponential map in Chapter 19. Once again, techniques with a variational calculus flavor are used to characterize geodesics as shortest paths.<br />  After a discussion of surfaces with boundary in Chapter 20 the Gauss-Bonnet theorem is proved in Chapter 21 using Stoke's theorem. The discussion of this important result is crystal clear and should prepare the reader for more advanced statements of it in the general context of differentiable manifolds. This is followed by a brief discussion of rigid motions and isometries in the next two chapters. The book ends with ta discussion of Riemannian geometry, a topic of upmost importance in physics and discussed here with care.<br />  A very good book and one that will be useful to beginning students of differential geometry, and also physics students going into the areas of gravitational physics or high energy physics.o chapters, where the inverse function theorem for n-surfaces is proved. This is followed by a consideration of focal points with Jacobi fields discussed in the exercises.<br />   More measure-theoretic concepts are discussed in the next chapter on surface area and volume. Partitions of unity are brought in so as to define the integral of an n-form over a compact oreinted n-surface. Exterior products of forms are introduced in the exercises. <br />    Soap bubble enthusiasts will appreciate the discussion on minimial surfaces in Chapter 18. Although very short, the author's treatment does bring out the important ideas. Minimal surfaces have taken on particular important in the new membrane theories in high energy physics recently. This is followed by a detailed treatment of the exponential map in Chapter 19. Once again, techniques with a variational calculus flavor are used to characterize geodesics as shortest paths. <br />      After a discussion of surfaces with boundary in Chapter 20 the Gauss-Bonnet theorem is proved in Chapter 21 using Stoke's theorem. The discussion of this important result is crystal clear and should prepare the reader for more advanced statements of it in the general context of differentiable manifolds. This is followed by a brief discussion of rigid motions and isometries in the next two chapters. The book ends with ta discussion of Riemannian geometry, a topic of upmost importance in physics and discussed here with care.   <br />  A very good book and one that will be useful to beginning students of differential geometry, and also physics students going into the areas of gravitational physics or high energy physics.	2001-05-28
1982346:US	50702879	R2D3FHOSVRJSGV	0963288539	981525502	Application of Chaos Theory to Psychological Models	Books	2	12	14	N	N	Marginal	This book is a general, essentially non-mathematical overview of the author's work and speculations in applying the theory of chaotic dynamics to psychological modeling. After a brief introduction, which mainly focusses on the author's belief that psychological modeling needs new paradigms and must move away from reductionism, she moves on to a literature review in the next chapter. The author argues that a new theoretical framework is needed, which is not shy of metaphysical considerations, and one one that employs a &quot;systems approach&quot; to theory and model building. A few mathematical considerations are employed in the discussion, mainly to set up the discussion of chaos later. The author is not convincing in her arguments against reductionism, for no examples are given as to why this approach is weak. Her discussion of Jungian psychodynamics though is interesting, and motivates the reader to consult the literature for additional insight. And, even though I agree with her stance against operationalism, she does not substantiate her position with any sound arguments. The author spends chapter four on chaotic dynamics in physical systems, but the treatment is purely qualitative, and there are a few instances of undefined terms, for example &quot;chaotic phase&quot;. The definition of chaos given in the glossary is not the standard one as it omits any reference to sensitive dependence on initial conditions. Also, in the definition of equilibrium the author refers to the state as one where molecules are &quot;paralyzed&quot;, but does not elaborate on this strange terminology.<br />  In chapter 5, the author discusses the application of chaos to  psychological modeling. The approach of Jennings/Ward is advocated as the appropriate methodology for psychological modeling. A model of moral behavior is given in terms of the logistic map, with the parameter in that map taken to be a measure of personal self-centeredness. This is modified later to include a contribution of a person's family  measuring that self-centeredness. The new difference equation models how the person's family measure of self-centeredness affects the rate of change in the person's moral behavior. These models are then solved numerically with the &quot;erratic&quot; behavior of the solution interpreted as moral behavior in highly volatile situations. Unfortunately, the author does not give any empirical justification or attempt at validation for these models.  More detailed in-depth research needs to be done when applying dynamical systems to psychological modeling, and such a goal is worthwhile and very important if successful.bution of a person's family  measuring that self-centeredness. The new difference equation models how the person's family measure of self-centeredness affects the rate of change in the person's moral behavior. These models are then solved numerically with the &quot;erratic&quot; behavior of the solution interpreted as moral behavior in highly volatile situations. Unfortunately, the author does not give any empirical justification or attempt at validation for these models.     More detailed in-depth research needs to be done when applying dynamical systems to psychological modeling, and such a goal is worthwhile and very important if successful.	2001-05-28
1982526:US	50702879	R21DT1U0GO5WZS	0521395542	721191740	The Geometry and Physics of Knots (Lezioni Lincee)	Books	3	4	4	N	N	Quick overview of TQFT and knot invariants	This book is a very quick overview of what was known at the time (1989) about the connection between quantum field theory and knot theory. The subject of topological quantum field theories and their connection with knot invariants was at that time just beginning thanks to the work of Edward Witten on the Jones polynomial.<br />  The approach that the author takes in the book is very formal and not for the beginner who is looking to learn about these results. Readers with enough background to read it will no doubt want to read more up-to-date treatments of the subject. The book however does give an indication of how Feynman path integrals are used to define the invariants. The use of these is not rigorous mathematics and this has not changed at the present day.	2001-05-28
1982791:US	50702879	RD5HJB8BJ42SK	0671244175	976655099	Simon & Schuster's Guide to Rocks & Minerals	Books	4	51	53	N	N	Very useful field guide	For rockhounds and beginning geologists, this book is a good overview. It not only gives a very long listing of the more popular rocks and minerals, but a thorough discussion of each along with beautiful photographs. In addition, the author does give a brief overview of crystallography that will serve well the beginner and motivates further reading on the subject. This part of geology and mineralogy is fascinating but can be time-consuming to get through. Even when not out in the field I have found this book fun to read in leisure time. It is packed full of interesting information and for the price cannot be beat.	2001-05-27
1982894:US	50702879	RXTGEJ97Z95A6	0903505355	219737402	The House Plant Expert	Books	5	0	0	N	N	VERY useful	This book is an excellent overview of plant care and I have referred to it many times when encountering plant problems of my own. The author also gives advice on what plants are more suitable for different rooms of the house. A detailed description of the more popular houseplants is given, with their lighting, temperature, water, and humidity requirements, along with repotting requirements and tips on propagation. He also gives a very useful &quot;Special Problems&quot; discussion on each plant group to assist the reader in diagnosing plant maladies and how to remedy them. Definitely a very good book for both beginners and seasoned plant lovers.	2001-05-27
1983417:US	50702879	R2299HHQSXIRHN	185273051X	834705953	The Dance Workshop	Books	4	5	5	N	N	Nicely illustrated and useful	This book is an introduction to basic patterns and exercises in modern and jazz dance. It serves its purpose well, and the illustrations are effective in conveying to the reader the sequence of steps needed to do the exercises. The photographs also serve to inspire the beginning student of dance into what is possible in this art form. The author also gives the rthythmic timing in all the exercises, making it easier to pick music to accompany. Teachers will find it useful in lesson planning and as a reference.	2001-05-27
1983477:US	50702879	R3VXVJ47DXJ4F1	0903505355	219737402	The House Plant Expert	Books	5	26	28	N	N	VERY useful	This book is an excellent overview of plant care and I have referred to it many times when encountering plant problems of my own. The author also gives advice on what plants are more suitable for different rooms of the house. A detailed description of the more popular houseplants is given, with their lighting, temperature, water, and humidity requirements, along with repotting requirements and tips on propagation. He also gives a very useful &quot;Special Problems&quot; discussion on each plant group to assist the reader in diagnosing plant maladies and how to remedy them. Definitely a very good book for both beginners and seasoned plant lovers.	2001-05-27
1983615:US	50702879	R2ZLH6Z3EDHFRX	0387176004	461095931	Convex Bodies and Algebraic Geometry: An Introduction to the Theory of Toric Varieties (ERGEBNISSE DER MATHEMATIK UND IHRER GRENZGEBIETE 3 FOLGE)	Books	4	6	6	N	N	Advanced but readable	This book is an advanced overview of the theory of toric varieties written for individuals with a strong background in algebraic geometry, topology, and algebra. It is very formal and not for a beginning course.<br />  The author moves right into the necessary convex geometry in the first section of Chapter 1 and then defines a toric variety in the next section. He does not hesitate to use diagrams to illustrate the examples, which is good given the level of abstraction he employs in the book. The fundamental group of a toric variety is given an explicit characterization, but the proof is omitted unfortunately. This is followed by a discussion of when a toric variety is compact and nonsingular, with detailed proofs given. The Hironaka resolution of singularities theorem is discussed for toric varieties, the proof being a lot simpler of course in this case. A concrete realization of singularity resolution using continued fractions is given in the next section. The chapter ends with a very detailed and superb discussion of the birational geometry of toric varieties.<br />  The next chapter is very involved and deals with Cartier divisors on toric varieties and toric projective varieties. The latter are related to convex polytopes by means of moment maps. In particular, integral convex polytopes have many connections with toric projective varieties, and these are outlined in detail in this chapter. A toric version of Mori's theorem is also outlined. Toric varieties offer a nice, intuitive picture of Mori's program for rational curves on projective varieties.<br />  Chapter 3 deals with differential forms on toric varieties. The author employs the sheaf of germs of holomorphic vector fields with logarithmic zeroes and the sheaf of germs of p-forms with logarithmic poles to study holomorphic differential forms over toric varieties. In addition, Ishida complexes are used to study complexes of coherent sheaves on toric varieties. A very interesting discussion on the automorphism groups of toric varieties is given in terms of Cremona groups.<br />  The last chapter discusses applications, such as Mumford toroidal embeddings, quotients of toric varieties, semisimple algebraic groups, and Newton polyhedra. Unfortunately, the author does not expound on these, but refers the reader to the literature. Instead, the author explains how to construct complex manifolds in dimension two by taking the quotient of an open set of a toric variety with respect to an action of a discrete map. Some interesting examples of compact quotientsof toric varieties are given, including complex tori, Hopf surfaces, and Inoue surfaces. The latter, for the case of parabolic Inoue surfaces, use elliptic curves in their constructions, interestingly.<br />  The book does contain a review of convex geometry for a reader not well-versed in this area. There is a lot in this book, even though it is short. The price is very high so only for individuals seriously interested in this topic.e automorphism groups of toric varieties is given in terms of Cremona groups. <br />    The last chapter discusses applications, such as Mumford toroidal embeddings, quotients of toric varieties, semisimple algebraic groups, and Newton polyhedra. Unfortunately, the author does not expound on these, but refers the reader to the literature. Instead, the author explains how to construct complex manifolds in dimension two by taking the quotient of an open set of a toric variety with respect to an action of a discrete map. Some interesting examples of compact quotientsof toric varieties are given, including complex tori, Hopf surfaces, and Inoue surfaces. The latter, for the case of parabolic Inoue surfaces, use elliptic curves in their constructions, interestingly.<br />    The book does contain a review of convex geometry for a reader not well-versed in this area. There is a lot in this book, even though it is short. The price is very high so only for individuals seriously interested in this topic.	2001-05-26
1983639:US	50702879	RE5HVO4E7L4WL	0387946802	288295820	Ideals, Varieties, and Algorithms: An Introduction to Computational Algebraic Geometry and Commutative Algebra (Undergraduate Texts in Mathematics)	Books	4	10	10	N	N	Good book	I don't have the second edition of this book but did read the first, and the authors do a fine job of introducing the reader to the computational side of algebraic geometry. I will forego a chapter by chapter review therefore, but no doubt the second edition (which I do not own) is as well-written as the first. I would recommend it to anyone interested in the many applications of algebraic geometry and to those who need to understand how to compute things in algebraic geometry. The good thing about this book is that it gives a concrete flavor to a highly abstract subject. Algebraic geometry, through its applications to coding theory, cryptography, and computer graphics, is fast becoming the subject to learn. It is no longer just an esoteric, high-brow subject but one that is taking on major importance in the information age. Even without applications though it is a fascinating subject, and readers will get a taste of this in this book.	2001-05-26
1983890:US	50702879	RQ4M2DKXANFG4	0811802329	930125611	Breaking Bounds: The Dance Photography of Lois Greenfield	Books	5	2	2	N	N	Visually stunning....	This book's photography are excellent and exemplify the beauty, symmetry (asymmetry) of modern dance. All those interested in celebrating the human form will find this book fascinating, even if modern dance is not in their background. My favorite photograph is on p. 73, as it brings out the dancers in mid-flight, totally out of equilibrium, as though Doris Humphrey herself was arranging the scene.......	2001-05-26
1984077:US	50702879	R3AFR8Z4FB7G4A	038530840X	857875594	The Doors: The Complete Lyrics	Books	5	15	16	N	N	Excellent for Doors lovers	This book is a complete compilation of the Doors lyrics as written by themseleves. One of my favorites, &quot;Back Door Man&quot;, of course is missing, as it was not written by them. Some historical summaries are put in, as well as a fine set of photographs. The music and lyrics of the Doors is both simple and unique, malevolent at times, but always tantalizing and dramatic. One can only wonder what they would sound like today if Morrison would have not passed on...	2001-05-26
1984575:US	50702879	R21EFN3NFY4CZ7	1560252162	736344123	Ladies: Retold Tales of Goddesses and Heroines	Books	5	6	8	N	N	Delightful	This book has magnificent drawings and paintings and the stories are well-written. Definitely a choice for Vallejo fans as it is a good sampling of his ability. &quot;Deianira&quot; is my favorite for sure, and the reader will find Persephone, Gorgon, Ariadne, Coronis, Medea, Circe, Eurydice, Arachne, and Pandora. Some consider Vallejo's drawings sexist, but I consider them to be symbolic of the beauty and complexity of women, and that is true in the fantasy world as well as reality.	2001-05-26
1987009:US	50702879	R1F8AO1SF55MIP	0387943277	421570283	Algebraic Topology: A First Course (Graduate Texts in Mathematics)	Books	4	22	25	N	N	A book of ideas	This book is an introduction to algebraic topology that is written by a master expositor. Many books on algebraic topology are written much too formally, and this makes the subject difficult to learn for students or maybe physicists who need insight, and not just functorial constructions, in order to learn or apply the subject. Anyone learning mathematics, and especially algebraic topology, must of course be expected to put careful thought into the task of learning. However, it does help to have diagrams, pictures, and a certain degree of handwaving to more greatly appreciate this subject.<br />  As a warm-up in Part 1, the author gives an overview of calculus in the plane, with the intent of eventually defining the local degree of a mapping from an open set in the plane to another. This is done in the second part of the book, where winding numbers are defined, and the important concept of homotopy is introduced. These concepts are shown to give the fundamental theorem of algebra and invariance of dimension for open sets in the plane. The delightful Ham-Sandwich theorem is discussed along with a proof of the Lusternik-Schnirelman-Borsuk theorem. I would like to see a constructive proof of this theorem, but I do not know of one.<br />  Part 3 is the tour de force of algebraic topology, for it covers the concepts of cohomology and homology. The author pursues a non-traditional approach to these ideas, since he introduces cohomology first, via the De Rham cohomology groups, and these are used to proved the Jordan curve theorem. Homology is then effectively introduced via chains, which is a much better approach than to hit the reader with a HOM functor.  Part 4 discusses vector fields and the discussion reads more like a textbook in differential topology with the emphasis on critical points, Hessians, and vector fields on spheres. This leads naturally to a proof of the Euler characteristic.<br />  The Mayer-Vietoris theory follows in Part 5, for homology first and then for cohomology.<br />  The fundamental group finally makes its appearance in Part 6 and 7, and related to the first homology group and covering spaces. The author motivates nicely the Van Kampen theorem. A most interesting discussion is in part 8, which introduces Cech cohomology. The author's treatment is the best I have seen in the literature at this level. This is followed by an elementary overview of orientation using Cech cocycles.<br />  All of the constructions done so far in the plane are generalized to surfaces in Part 9. Compact oriented surfaces are classified and the second de Rham cohomology is defined, which allows the proof of the full Mayer-Vietoris theorem.<br />  The most important part of the book is Part 10, which deals with Riemann surfaces. The author's treatment here is more advanced than the rest of the book, but it is still a very readable discussion. Algebraic curves are introduced as well as a short discussion of elliptic and hyperelliptic curves.<br />  The level of abstraction increases greatly in the last part of the book, where the results are extended to higher dimensions. Homological algebra and its ubiquitous diagram chasing are finally brought in, but the treatment is still at a very understandable level.<br />  For examples of the author's pedagogical ability, I recommend his book Toric Varieties, and his masterpiece Intersection Theory.irst and then for cohomology. <br />     The fundamental group finally makes its appearance in Part 6 and 7, and related to the first homology group and covering spaces. The author motivates nicely the Van Kampen theorem. A most interesting discussion is in part 8, which introduces Cech cohomology. The author's treatment is the best I have seen in the literature at this level. This is followed by an elementary overview of orientation using Cech cocycles. <br />    All of the constructions done so far in the plane are generalized to surfaces in Part 9. Compact oriented surfaces are classified and the second de Rham cohomology is defined, which allows the proof of the full Mayer-Vietoris theorem.<br />   The most important part of the book is Part 10, which deals with Riemann surfaces. The author's treatment here is more advanced than the rest of the book, but it is still a very readable discussion. Algebraic curves are introduced as well as a short discussion of elliptic and hyperelliptic curves.<br />   The level of abstraction increases greatly in the last part of the book, where the results are extended to higher dimensions. Homological algebra and its ubiquitous diagram chasing are finally brought in, but the treatment is still at a very understandable level.<br />    For examples of the author's pedagogical ability, I recommend his book Toric Varieties, and his masterpiece Intersection Theory.	2001-05-24
1988115:US	50702879	R3ES5EAAN0CZPQ	0387983813	952289976	Mathematical Physiology (Interdisciplinary Applied Mathematics)	Books	5	23	24	N	N	All of it fascinating....	This book is an excellent overview of the major research into the mathematics of physiological processes. The first part of the book covers cellular physiology beginning with a discussion of biochemical reactions in the first chapter. Some of the applications of dynamical systems are nicely illustrated here, especially bifurcation theory.<br />  Applications of the diffusion equation follow in the next chapter on cellular homeostasis. The Nernst-Planck electrodiffusion equation is discussed but not derived, and is solved in the constant field approximation.<br />  This is complicated somewthat in the next chapter on membrane ion channels, where the potential across the membrane is not assumed to have a constant gradient. There is a discussion of channel blocking drugs in the last section, but unfortunately it is too short. This is an important area of application, with the experimental validation of the mathematical results of upmost importance.<br />  The Hodgkin-Huxley and the FitzHugh-Nagumo equations dominate the next chapter on electrical signaling in cells. The phase space analysis of these models is discussed, along with an interesting treatment of the excitability of cardiac cells in the Appendix of the chapter.<br />  A very well-written treatment, along with helpful diagrams, of calcium dynamics is given in Chapter 5. The authors show how ignoring the fast variables and transients lead one to a solution of they dynamical problem of the receptor model.<br />  Phase space analysis is used extensively in the next chapter on electrical bursting, with emphasis on bursting in pancreatic beta-cells. An interesting discussion on the classification of bursting oscillations is given purely in terms of bifurcation theory.<br />  That synaptic transimission is quantal in nature is one of the topics of the next chapter on intercellular communication. This is the first time in the book that probabilistic methods are introduced into the modeling. The authors quote some very old references on the experimental verification of the quantal model, leaving the reader wondering if more modern experiments have been done. In calculating the effective diffusion coefficients, the authors introduce the technique of homogenization, and give a explanation of the rationale behind the technique. The strategy of determining the behavior at a particular scale without solving completely the details at a finer scale is one that has proven to be quite productive, especially in physics.<br />  The use of partial differential equations is increased in the next chapter on electrical flow in neurons, with the linear cable equation playing the dominant role. The authors use transform methods to obtain the solutions in the main text and exercises, giving references for the reader not familiar with these techniques.<br />  The nonlinear cable equation is the subject of the next chapter, with traveling waves solutions of the bistable equation given the main emphasis. Shooting methods are employed in the solution of this equation, and the authors also treat the more difficult case of the discrete bistable equation.<br />  Wave propagation in higher dimensions is the subject of the next chapter, with spiral waves discussed along with a brief discussion of scroll waves.<br />  The fascinating subject of cardiac propagation is the subject of Chapter 11. The mathematical techniques are not much more complicated, but mathematicians coming to cardiac biology for the first time will need to pay attention to the details.  One of the most interesting subjects of the book is treated in Chapter 13 on cell function regulation. Mathematical models of the G1 and G2 checkpoint processes are given.<br />  Part two of the book emphasizes the mathematical modeling of the biological systems, rather than at the cellular level. This part begins with a consideration of how cellular activity can be coordinated to produce a regular heartbeat and how failure can occur. Interestingly, aSchrodinger-like equation appears when linearizing the FitzHugh-Nagumo equations for oscillating cells. And, interestingly, dynamical systems via circle maps appear in the model of the AV modal signal. This is followed by a lengthy and fascinating discussion of the mathematics of the circulatory system. Unfortunately, the discussion on the dangers of high blood pressure is not justified by any mathematical models in the book. It would have been very interesting to see a model developed that would predict the effects of hypertension on the heart, kidneys, etc and one that would be compared with historical and clinical data.<br />  The next chapters discuss physiology of the blood, respiration, and muscles. A very interesting discussion of hormone physiology and mammal ovulation is given. The mathematical models of the kidneys and gastrointestinal systems are very detailed and very enlightening for individuals not in these fields.<br />  The book ends with chapters on the physiology of sight and hearing. The discussion of the light reflex mechanism is very interesting as the authors use linear stability analysis. The oscillations of the basilar membrane in the inner ear are good reading for the physicist.<br />  This book would be of great interest to mathematicians who are entering the field of computational physiology or computational biologists who need an understanding of the modeling required. Very captivating reading........oduce a regular heartbeat and how failure can occur. Interestingly, a Schrodinger-like equation appears when linearizing the FitzHugh-Nagumo equations for oscillating cells. And, interestingly, dynamical systems via circle maps appear in the model of the AV modal signal. This is followed by a lengthy and fascinating discussion of the mathematics of the circulatory system. Unfortunately, the discussion on the dangers of high blood pressure is not justified by any mathematical models in the book. It would have been very interesting to see a model developed that would predict the effects of hypertension on the heart, kidneys, etc and one that would be compared with historical and clinical data. <br />    The next chapters discuss physiology of the blood, respiration, and muscles. A very interesting discussion of hormone physiology and mammal ovulation is given. The mathematical models of the kidneys and gastrointestinal systems are very detailed and very enlightening for individuals not in these fields. <br />   The book ends with chapters on the physiology of sight and hearing. The discussion of the light reflex mechanism is very interesting as the authors use linear stability analysis. The oscillations of the basilar membrane in the inner ear are good reading for the physicist. <br />    This book would be of great interest to mathematicians who are entering the field of computational physiology or computational biologists who need an understanding of the modeling required. Very captivating reading........	2001-05-23
1992714:US	50702879	R3W44LILXUL525	0387984925	121552243	Using Algebraic Geometry (Graduate Texts in Mathematics)	Books	4	19	21	N	N	Good introduction	Once thought to be high-brow estoeric mathematics, algebraic geometry is now finding applications in a myriad of different areas, such as cryptography, coding algorithms, and computer graphics. This book gives an overview of some of the techniques involved when applying algebraic geometry. The authors gear the discussion to those who are attempting to write computer code to solve polynomial equations and thus the first few chapters cover the algebraic structure of ideals in polynomial rings and Grobner basis algorithms. The reader is expected to have a fairly good background in undergraduate algebra in order to read this book, but the authors do give an introduction to algebra in the first chapter. Many exercises permeate the text, some of which are quite useful in testing the reader's understanding. The Maple symbolic programming language is used to illustrate the main algorithms, and I think effectively so. The authors do mention other packages such as Axiom, Mathematica, Macauley, and REDUCE to do the calculations.  The chapter on local rings is the most well-written in the book, as the idea of a local ring is made very concrete in their discussion and in the examples. The strategy of studying properties of a variety via the study of functions on the variety is illustrated nicely with an example of a circle of radius one.  Later, in a chapter on free resolutions, the authors discuss the Hilbert function and give a very instructive example of its calculation, that of a twisted cubic in three-dimensional space. They mention the conjecture on graded resolutions of ideals of canonical curves and refer the reader to the literature for more information.  Particularly interesting is the chapter on polytopes, where toric varieties are introduced. The authors motivate nicely how some of the more abstract constructions in this subject, such as the Chow ring and the Veronese map, arise. The important subject of homotopy continuation methods is discussed, and this is helpful since these methods have taken on major applications in recent years. In optimization theory, they serve as a kind of generalization of the gradient methods, but do not have the convergence to local minima problems so characteristic of these methods. In addition, one can use homotopy continuation methods to get a computational handle on the Schubert calculus, namely, the problem of finding explicity the number of m-planes that meet a set of linear subspaces in general position. There are some software packages developed in the academic environment that deal with homotopy continuation, such as &quot;Continuum&quot;, which is a projective approach based on Bezout's theorem; and &quot;PHC&quot;, which is based on Bernstein's theorem, the latter of which the authors treat in detail in the book.  My primary reason for purchasing the book was mainly the last chapter on algebraic coding theory. The authors do give an effective presentation of the concepts, including error-correcting codes, but I was disappointed in not finding a treatment of the soft-decision problem in Reed-Solomon codes.<br />  In general this is a good book and worth reading, if one needs an introduction to the areas covered. Students could definitely benefit from its perusal.d this is helpful since these methods have taken on major applications in recent years. In optimization theory, they serve as a kind of generalization of the gradient methods, but do not have the convergence to local minima problems so characteristic of these methods. In addition, one can use homotopy continuation methods to get a computational handle on the Schubert calculus, namely, the problem of finding explicity the number of m-planes that meet a set of linear subspaces in general position. There are some software packages developed in the academic environment that deal with homotopy continuation, such as &quot;Continuum&quot;, which is a projective approach based on Bezout's theorem; and &quot;PHC&quot;, which is based on Bernstein's theorem, the latter of which the authors treat in detail in the book.           My primary reason for purchasing the book was mainly the last chapter on algebraic coding theory. The authors do give an effective presentation of the concepts, including error-correcting codes, but I was disappointed in not finding a treatment of the soft-decision problem in Reed-Solomon codes. <br />        In general this is a good book and worth reading, if one needs an introduction to the areas covered. Students could definitely benefit from its perusal.	2001-05-20
1996135:US	50702879	R248UTDVQUNVUJ	0521575575	340593565	Introduction to the Modern Theory of Dynamical Systems (Encyclopedia of Mathematics and its Applications)	Books	4	14	15	N	N	Great book with lots of detail	This book is a comprehensive overview of modern dynamical systems that covers the major areas. The authors begin with an overview of the main areas of dynamics: ergodic theory, where the emphasis is on measure and information theory; topological dynamics, where the phase space is a topological space and the &quot;flows&quot; are continuous transformations on these spaces; differentiable dynamics where the phase space is a smooth manifold and the flows are one-parameter groups of diffeomorphisms; and Hamiltonian dynamics, which is the most physical and generalizes classical mechanics. Noticeably missing in the list of references for individuals contributing to these areas are Churchill, Pecelli, and Rod, who have done interesting work in the area of both topological and Hamiltonian mechanics. No doubt size and time constraints forced the authors to make major omissions in an already sizable book.<br />  Some elementary examples of dynamical systems are given in the first chapter, including definitions of the more important concepts such as topological transitivity and gradient flows. The authors are careful to distinguish between topologically mixing and topological transitivity. This (subtle) difference is sometimes not clear in other books. Symbolic dynamics, so important in the study of dynamical systems, is also treated in detail.<br />  The classification of dynamical systems is begun in Chapter 2, with equivalence under conjugacy and semi-conjugacy defined and characterized. The very important Smale horseshoe map and the construction of Markov partitions are discussed. The authors are careful to distinguish the orbit structure of flows from the case in discrete-time systems.<br />  Chapter 3 moves on to the characterization of the asymptotic behavior of smooth dynamical systems. This is done with a detailed introduction to the zeta-function and topological entropy. In symbolic dynamics, the topological entropy is known to be uncomputable for some dynamical systems (such as cellular automata), but this is not discussed here. The discussion of the algebraic entropy of the fundamental group is particularly illuminating.<br />  Measure and ergodic theory are introduced in the following chapter. Detailed proofs are given of most of the results, and it is good to see that the authors have chosen to include a discussion of Hamiltonian systems, so important to physical applications.<br />  The existence of invariant measures for smooth dynamical systems follows in the next chapter with a good introduction to Lagrangian mechanics.<br />  Part 2 of the book is a rigorous overview of hyperbolicity with a very insightful discussion of stable and unstable manifolds. Homoclinicity and the horseshoe map are also discussed, and even though these constructions are not useful in practical applications, an in-depth understanding of them is important for gaining insight as to the behavior of chaotic dynamical systems. Also, a very good discussion of Morse theory is given in this part in the context of the variational theory of dynamics.<br />  The third part of the book covers the important area of low dimensional dynamics. The authors motivate the subject well, explaining the need for using low dimensional dynamics to gain an intuition in higher dimensions. The examples given are helpful to those who might be interested in the quantization of dynamical systems, as the number-theoretic constructions employed by the author are similar to those used in &quot;quantum chaos&quot; studies. Knot theorists will appreciate the discussion on kneading theory.<br />  The authors return to the subject of hyperbolic dynamical systems in the last part of the book. The discussion is very rigorous and very well-written, especially the sections on shadowing and equilibrium states. The shadowing results have been misused in the literature, with many false statements about their applicability. The shadowing theorem is proved along with the structural stabilitytheorem.<br />  The authors give a supplement to the book on Pesin theory. The details of Pesin theory are usually time-consuming to get through, but the authors do a good job of explaining the main ideas. The multiplicative ergodic theorem is proved, and this is nice since the proof in the literature is difficult.theorem.<br />  The authors give a supplement to the book on Pesin theory. The details of Pesin theory are usually time-consuming to get through, but the authors do a good job of explaining the main ideas. The multiplicative ergodic theorem is proved, and this is nice since the proof in the literature is difficult.	2001-05-17
1996897:US	50702879	R1UD8P0KP4I62G	0471330612	822984779	Human Molecular Genetics 2	Books	5	39	42	N	N	The book to read for an in-depth background	This book is a very complete overview of molecular biology as applied to human genetics. As someone interested in bioinformatics and computational biology, I read it to get a background in the biology/genetics behind these fields. That being said, I was glad I made the choice of this book as the authors do a fine job of explaining the relevant concepts and biological processes in genetics. In the light of the recent draft of the human genome, this edition of the book is especially timely. That being said, there is a lot of material covered, and to digest all of the terms and processes outlined takes a fair amount of time. The discussion on functional genomics and the post-genome sequencing era was particularly interesting. More could be said on gene sequencing validation as it applies to gene therapies and drug discovery. The most fascinating chapter was the one on genetic manipulation of animals as this is where genetic engineering has had its successful proving ground. Even though this is a science text, a discussion on the ethics of human genetic engineering would be appropriate, given some of the current attitudes about it. My opinion is that these technologies should move ahead with diligence; humankind cannot afford not to do so.<br />  I would highly recommend this book to those who have the time to read through it, as it offers the necessary concepts needed to understand this fascinating area.	2001-05-16
2002341:US	50702879	RYB3SZU6SPXO9	1565926641	706647888	Developing Bioinformatics Computer Skills: An Introduction to Software Tools for Biological Applications	Books	5	30	36	N	Y	HIGHLY recommended for those entering bioinformatics	This book is an excellent introduction to bioinformatics for a person entering the field or deciding to enter. The author's introduction to UNIX in the second part of the book is better written than most books devoted completely to UNIX. The discussion would be even better if some words were said about the new MAC OS X operating system. With its UNIX flavor, and the ease of use of a MAC, it will no doubt make its presence known in bioinformatics. Publication timing may have prevented a discussion of it however since OS X has just been released in the last few months.<br />  A non-mathematical but very informative overview of sequence analysis is given in part three of the book. A mathematician who might be deciding to enter this exciting field will the discussion good preparation for further technical reading in computational biology and sequence algorithms. The authors even include a discussion of mathematical physiology and give URLs and  a list of companies attempting to create user applications in this area of computational biology. This is a further example of the book's merits, as it shows what areas in bioinformatics need more application tools to be developed.<br />  Even the rather short chapter on PERL programming still suffices to create an appreciation of the power of PERL in bioinformatics. What takes sometimes many weeks of development time and many lines of code can frequently be done in a matter of hours and a few lines of code in PERL.<br />  The book ends with an introduction to databases and data mining, and, even though the discussion is short, the authors explain the concepts well. Data mining in this field, as in others, is a subject that will take on further importance in the near future.<br />  In addition, the book is just plain fun to read. A large set of references is given along with many URLs throughout the book. I visited all of these Websites and with their content and the book at hand....I had a BLAST.	2001-05-12
2003843:US	50702879	R2S8987ZGD0IE4	1565923987	934048322	Mastering Algorithms with Perl: Practical Programming Through Computer Science	Books	4	20	21	N	N	Nice introduction	This book ia fairly good introduction to the use of PERL in developing and implementing various algorithms, including scientific and cryptographic ones. Fortunately, source is included, setting the book apart from the usual books on computer algorithms.<br />  The first few chapters outline PERL data structures, with the built-in data structures discussed, along with a discussion of how to create new ones. The dynamic nature of arrays in PERL is emphasized, and this is a feature that sets PERL way above other languages, such as C and C++. Linked lists are given a detailed treatment along with garbage collection in PERL. The authors are careful to point out that reference counting in PERL will fail when one is dealing with a circle of reference values.<br />  A discussion of sorting follows, with radix and hybrid sorts being the most useful of the algorithms discussed. The authors give a useful comparison study of the running time of the sorting algorithms.  This is followed by a discussion of searching algorithms, which unfortunately omits any details of dynamic programming, which is useful in applying PERL to areas such as computational biology.<br />  The authors give a very interesting treatment of how to do set operations using PERL in the next chapter. They did not treat the case of fuzzy sets in detail though, unfortunately.<br />  Matrix algorithms are discussed next, with the PERL modules MatrixRead and PDL integrated into the discussion. I have only  used PDL and its graphic library PGPLOT and have had varying degress of success with it. PERL still has a long way to go before it is accepted as a language suitable for numerical computations.<br />  Graph algorithms are the subject of the next chapter. The most useful section is the one on minimum spanning trees, so useful in network routing algorithms.<br />  This is followed by a thorough discussion of string algorithms in Chapter 9. These algorithms are extremely important in current applications, such as string matching and alignment in computational biology. That the authors give the source code for the algorithms is extremely helpful to those who need to apply these algorithms.<br />  The authors return to geometric algorithms in the next chapter, with only elementary ones being discussed, with brief overviews of PERL graphics modules available.<br />  Number systems and numerical precision are taken up in the next chapter, with 32 bit precision implemented in the discussion. The authors do however discuss how large number arithmetic can be implemented in PERL via the BigFloat and BigInt modules. This is followed by modular arithmetic and number theory ,  with PERL code given for the Miller-Rabin primality test. This chapter is very short, but it sets up the next chapter on cryptography, which begins with a discussion of passwords, with a PERL program given that checks valid passwords. Then, interestingly, a PERL 1-liner is given for cracking a password list. The discussion on passwords should be of interest to individuals first entering the field of computer security. This is followed by a fairly complete elaboration on authentication and checksums. Encryption of data is discussed in the next section, along with a brief mention of the AES, which at the time of publication of this book, was not settled. The RSA algorithm is discussed also, with a 3-line PERL code given for it, along with a more instructive version later. Only one section on steganography is included, and since this is a subject of intense research with useful applications, this is somewhat disappointing.<br />  The last three chapters covers probability and statistics and numerical analysis, and given the growing use of PDL in astrophysics and other areas of science, this is a fitting way to end the book. PERL code is given for the most popular probability distributions, and also for some of the standard statistical tests. Only some rudimentary algorithms are given for calculus and data interpolation, but the discussion should prepare the reader for more advanced reading in numerical algorithms using PERL and the use of PDL.thms are given for calculus and data interpolation, but the discussion should prepare the reader for more advanced reading in numerical algorithms using PERL and the use of PDL.	2001-05-10
2008550:US	50702879	R3KN4B5QA3JRSX	0125140762	457594740	Differential Topology and Quantum Field Theory	Books	3	16	19	N	N	Fair treatment	This book is written for the theoretical physicist in mind. It is somewhat out-of-date, as there have been many developments in differential topology, such as the Seiberg-Witten theory, since this book was published. However, it might still serve the reader with an introduction to these latter developments. Being just a summary there are no proofs given, and this might annoy the mathematician, but it still could be read profitably by a mathematician if they need a quick introduction to the interplay between physics and differential topology. Indeed, some of the results outlined in the book have been dubbed &quot;physical mathematics&quot; by mathematicians because of the lack of rigour involved in some of the constructions. Quantum field theory is not a subject at all to look for mathematical rigour. Several attempts have been made to put it on a sound mathematical foundation, by these attempts all result in a weakening of its physical predictive power.<br />  The author introduces some basic topological notions in the first chapter, such as homotopy and homology/cohomology groups. He does give a good explanation via the smash product, of how to get a base point in a product space when each factor has a base point. Also, his discussion of H-and coH-spaces is very intuitive and serves the physicist-reader well in developing a functorial mind set. Freedman's and Donaldson's work in 4-dimensional topology is discussed only very briefly however. The existence of exotic structures on 4-dimensional topology is discussed only very briefly however. The existence of exotic structures on 4-dimensional Euclidean space has recently been shown to have interesting physical consequences, but the author only devotes a few sentences to exotica. The explicit construction of an exotic structure is of great importance to physical applications, but as of yet only existence results are known.<br />  Physicists are used to dealing with elliptic partial differential equations, and the next chapter discusses these in a more abstract guise: the theory of elliptic operators. These are introduced in the context of vector bundles, as preparation for the Atiyah-Singer index theorem. The locality of pseudo-differential operators sets up the need for Sobolev spaces, and the author does a fairly good job of overviewing the main results.<br />  The concept of a sheaf is introduced in the next chapter, but I think physicists would understand sheaves better if they were introduced via analytic continuation, a procedure that physicists are very well acquainted with. K-theory is also discussed in this chapter and the corresponding stable theory. Physicists have to understand the Bott periodicity theorems when doing functional integration in quantum field theory. Characteristic classes are only briefly treated, and, like all the treatments of this subject, the discussion gives no insight as to why these objects work as well as they do.<br />  The author returns to elliptic operators in the next chapter, where their index theory is discussed. The treatment is too formal. and the reader will have to search the literature for  more in-depth discussion.<br />  Algebraic geometry, which has taken on immense importance in string theories and M-theory, is introduced in the next chapter. This chapter might be too quick for the physicist needing an understanding for applicaations in these areas. More concrete examples of varieties and explicit calculations of moduli spaces would have been helpful.<br />  Physicists who have done current algebra will appreciate the next chapter on infinite dimensional groups. The loop group, gauge group, Virasoro group, and the Kac-Moody algebra, of use in conformal field theories and gauge field theories, are given fairly good treatment.<br />  Morse theory, so indispensable in both mechanics and quantum field theory, is discussed in the next chapter. This is probably the best written of the chapters in the book, especially the sections onequivariance and supersymmetry.<br />  Instantons, so important in guage theories and the subsequent quantization via functional integration, are treated in Chapter 8. It is a fairly good discussion, with infinite dimensional critical point theory given emphasis.<br />  Applications to string theory is the subject of the next chapter, but the chapter is far too short to be of much use to someone first entering the field.<br />  The treatment of anomalies in the next chapter is quite good though; the section on Fock space and Gauss's law is one of the best I have seen in the literature. The author explains carefully the origin of the Schwinger term.<br />  Conformal field theories follow in Chapter 9, and the Virasoro algebra again makes its appearance. This is an area that employs more of the &quot;hard&quot; analysis in obtaining results rather than &quot;soft&quot; techniques, so physicists should be fairly comfortable with the discussion.<br />  The last chapter introduces a topic that could fairly be classified as a &quot;quantization of mathematics&quot;. The author discusses topological quantum field theories, and it is in this area that I believe the most fascinating constructions in all of mathematical physics take place. These theories have spurred a tremendous amount of research, and the author gives a fairly good overview.  The book is a little too overpriced considering the content and the fact that it is a paperback. Such expense is worth it for a self-contained book, but this is not one of these, and must be supplemented by a great deal of outside reading.especially the sections on equivariance and supersymmetry. <br />      Instantons, so important in guage theories and the subsequent quantization via functional integration, are treated in Chapter 8. It is a fairly good discussion, with infinite dimensional critical point theory given emphasis. <br />      Applications to string theory is the subject of the next chapter, but the chapter is far too short to be of much use to someone first entering the field. <br />      The treatment of anomalies in the next chapter is quite good though; the section on Fock space and Gauss's law is one of the best I have seen in the literature. The author explains carefully the origin of the Schwinger term. <br />      Conformal field theories follow in Chapter 9, and the Virasoro algebra again makes its appearance. This is an area that employs more of the &quot;hard&quot; analysis in obtaining results rather than &quot;soft&quot; techniques, so physicists should be fairly comfortable with the discussion. <br />      The last chapter introduces a topic that could fairly be classified as a &quot;quantization of mathematics&quot;. The author discusses topological quantum field theories, and it is in this area that I believe the most fascinating constructions in all of mathematical physics take place. These theories have spurred a tremendous amount of research, and the author gives a fairly good overview.         The book is a little too overpriced considering the content and the fact that it is a paperback. Such expense is worth it for a self-contained book, but this is not one of these, and must be supplemented by a great deal of outside reading.	2001-05-06
2009626:US	50702879	RMTC4WHNDB7WT	0691082383	296892784	Etale Cohomology. (PMS-33)	Books	5	15	23	N	N	Well worth the time	This book is a rigorous overview of an approach to the study of schemes that uses a generalization of the complex topology called the etale topology. For the case of of ordinary complex algebraic varieties, the etale topology is simply the complex topology, which gives more information about the variety than the Zariski topology. The etale topology gives rise to sheaf and cohomology theories for schemes that parallels that of the cohomology of complex manifolds. These concepts are discussed in great detail in this book, and the reader is expected to have a substantial background in algebra, algebraic geometry, and topology. With this background, the reader will encounter an exceptionally well-written book full of fascinating ideas and constructions. There is also a set of notes on etale cohomology written by the author that he has posted on the Web. The notes compliment this book and treat the case of varieties rather than schemes.<br /><br />  When one is dealing with a complex algebraic variety, most of the usual concepts from algebraic topology carry over. For example, the dimensions of the rational cohomology groups of the variety, namely the Betti numbers, can be defined. For a variety over a general algebraically closed field, one has to deal with the Zariski topology, which is not fine enough for the usual techniques of algebraic topology. One example of this are the integer cohomology groups, which for an irreducible variety are all zero except in dimension zero. When one uses the etale topology though, the corresponding cohomology groups give the correct Betti numbers and the standard results of algebraic topology carry over. That the etale topology is a generalization of the complex topology is easier to see in the context of varieties rather than schemes as is done in this book. An etale covering of a nonsingular complex algebraic variety can be refined by a covering for the complex topology. The reader familiar with Riemann surfaces should keep in mind the concept of an unramified covering when studying this chapter.  The first chapter emphasizes the role of etale morphisms and their role in defining the etale topology. To reinforce this connection even further, the author asks the reader to show that a morphism between two smooth varieties over a field is etale if and only if the morphism induces an isomorphism on the tangent spaces. When going over to a general scheme, this geometric picture is lost, and one must rely completely on algebraic constructions. But the author does show effectively that etale morphisms for schemes are essentially local isomorphisms in a sense. He also discusses the fundamental group of a scheme in this chapter. When reading this section, it is best to think of the fundamental group from ordinary topology in terms of the universal covering space instead of simple connectedness as it is the former concept that is employed to define the fundamental group of a scheme.<br /><br />  The author turns to sheaf theory in the next chapter and shows how etale topology does give exactness for sequences of sheaves that are not exact in the Zariski topology. The notion of a flat topology, even finer than the etale topology, is integrated into the discussion. The author gives a nice example of a sequence involving a scheme of characteristic p that is exact relative to the flat topology, but not the etale or Zariski topologies.<br /><br />  The next chapter moves on to the cohomology of sheaves on flat and etale sites. He convinces the reader right away that the sheaf category is more general than the abelian category by showing that the former does not have enough projectives. Cech cohomology is introduced mostly as a device to compute the cohomology groups, which is difficult to do directly when expressed in terms of derived functors. The author takes greatcare in explaining the connection between these different approaches, for example showing that for a separated scheme over a quasi-coherent sheaf, they coincide. Also, several very insightful examples of the actual calculation of the cohomology groups relative to the etale topology are given. In addition, the author compares flat vs. Zariski, flat vs etale, and etale vs complex cohomologies.<br /><br />  The next chapter covers the Brauer group, which was introduced by Grothendieck as a generalization of central simple algebras over fields. The Brauer group is defined in terms of equivalence classes of Azumaya algebras, with the cohomological Brauer group defined as the torsion part of the second etale cohomology group. There is an injection of the Brauer group into the cohomological Brauer group, and this chapter outlines what was known at the time of publication when this is a bijection. It is now known that for schemes of dimension less than or equal to 1, regular surfaces, Abelian varieties, unions of affine schemes with affine intersection, smooth toric varieties, and separated geometrically normal algebraic surfaces that such a bijection exists.<br /><br />  Starting with the construction of a Lefschetz pnecil, so powerful in symplectic geometry, the calculation of the cohomology curves and surfaces is taken up in the next chapter. The author's proofs are very concise but understandable and he explains the need for using constructible sheaves in obtaining the usual Euler characteristic and Poincare duality results from algebraic topology.The situation in characteristic p is treated in detail.<br /><br />  This sets the stage for the last chapter which proves the Kunneth formula and the Lefschetz fixed point formula. The all-important L-series is proved to be rational when it arises from representations of Galois groups. This chapter should satisfy algebraic topologists who are curious as to what extent the usual results in their area carry over to schemes.very insightful examples of the actual calculation of the cohomology groups relative to the etale topology are given. In addition, the author compares flat vs. Zariski, flat vs etale, and etale vs complex cohomologies.    The next chapter covers the Brauer group, which was introduced by Grothendieck as a generalization of central simple algebras over fields. The Brauer group is defined in terms of equivalence classes of Azumaya algebras, with the cohomological Brauer group defined as the torsion part of the second etale cohomology group. There is an injection of the Brauer group into the cohomological Brauer group, and this chapter outlines what was known at the time of publication when this is a bijection. It is now known that for schemes of dimension less than or equal to 1, regular surfaces, Abelian varieties, unions of affine schemes with affine intersection, smooth toric varieties, and separated geometrically normal algebraic surfaces that such a bijection exists.    Starting with the construction of a Lefschetz pnecil, so powerful in symplectic geometry, the calculation of the cohomology curves and surfaces is taken up in the next chapter. The author's proofs are very concise but understandable and he explains the need for using constructible sheaves in obtaining the usual Euler characteristic and Poincare duality results from algebraic topology.The situation in characteristic p is treated in detail.    This sets the stage for the last chapter which proves the Kunneth formula and the Lefschetz fixed point formula. The all-important L-series is proved to be rational when it arises from representations of Galois groups. This chapter should satisfy algebraic topologists who are curious as to what extent the usual results in their area carry over to schemes.	2001-05-05
2009915:US	50702879	R1NU77ZKWC37TV	0387947558	945543147	Combinatorial Convexity and Algebraic Geometry (Graduate Texts in Mathematics)	Books	5	6	9	N	N	An excellent way to begin a study of algebraic geometry	This book is a very organized introduction to the study of constructions that really go back to Isaac Newton, one of these now being called a Newton polygon. In the context of modern algebraic geometry, the constructions take place when dealing with the resolution of singularities of varieties. Given a variety X, this procedure asks for a map from a nonsingular variety Y to X, such that the map is an isomorphism over the nonsingular locus of X. It was the case of a plane curve singularity that was essentially solved by Newton. His techniques were generalized considerably beginning in the 1970's, and resulted in the theory of toric varieties, which is the main subject of this book.<br />  Loosely speaking, a toric variety is a complex algebraic variety which is the partial compactification of an algebraic torus. The algebraic torus acts on a point in the toric variety such that the orbit of the point is an embedded copy of the algebraic torus. Toric varieties are excellent concrete examples of algebraic varieties since they are characterized entirely by a combinatorial object called its fan, which is a collection of convex cones.<br />  This book is an fine introduction to toric varieties. The author does a thorough job of detailing the relevant background in the first half of the book, which deals mostly with convexity and the geometry of lattice polytopes. A very interesting discussion of the Picard group is given in the last few sections of this part. This is one of the best discussions I have seen in the literature on this subject as it gives the reader a very intuitive and concrete view of this group.<br />  The second half covers toric varieties in detail with systems of rational functions on a toric variety studied via sheaf theory. The reader familiar with sheaf theory from general algebraic geometry will see it take on a beautifully concrete form in this book. Readers new to algebraic geometry will appreciate the more abstract approach to sheaf theory if they move on to these more advanced treatments. The author gives many examples of the constructions involved with toric varieties. The cohomology of toric varieties is also treated very nicely, and here again, a reader with a modest background in combinatorial topology will follow the presentation. The physicist reader doing research into mirror symmetry will appreciate this book, as toric varieties serve as a good starting point for the constructions in that area.ry if they move on to these more advanced treatments. The author gives many examples of the constructions involved with toric varieties. The cohomology of toric varieties is also treated very nicely, and here again, a reader with a modest background in combinatorial topology will follow the presentation. The physicist reader doing research into mirror symmetry will appreciate this book, as toric varieties serve as a good starting point for the constructions in that area.	2001-05-05
2014301:US	50702879	R3LAV5WH5BZ7D6	038794527X	559606993	Monte Carlo: Concepts, Algorithms, and Applications (Springer Series in Operations Research and Financial Engineering)	Books	5	35	35	N	N	HIGHLY recommended!!	This book gives a rigorous introduction to the main ideas behind the Monte Carlo technique and also gives many concrete examples to illustrate the important concepts. The applications of Monte Carlo are immense, and cover a wide range of fields, including finance, physics, chemistry, computational biology, geology, computational radiology, and network engineering.<br />  The author begins, naturally, with a discussion of how to compute the volume of a high-dimensional body using standard (deterministic) methods and then shows the advantages of using Monte Carlo to find the volume. He does a fine job of assessing the errors in the volume calculation, being careful to distinguish between convergence with probability one and convergence in probability. He also explains the need for specifying confidence levels, and not just the epsilon error term, to determine the smallest sample size that guarantees an error no larger than the specified epsilon. He also gives an interesting application to network reliability in this chapter. The probability that two network nodes are connected is reduced to a volume computation which is then estimated using Monte Carlo sampling. This is an excellent example of how Monte Carlo can be used to arrive at an accurate estimate of an intractable problem. The author gives another example of this later in the chapter wherein he uses Monte Carlo methods in combinatorial probability. Also included in the chapter are some useful hands-on exercises for the reader.<br />  The sometimes tricky procedure of generating samples from a variety of distributions is the subject of the next chapter. The author is careful throughout the chapter to distinguish between results that are exact from a formal standpoint and those that are implementable in practice. In addition, a thorough discussion of the error introduced by using pseudorandom numbers in place of sequences of uniform deviates is given. This is the only book I know of that discusses this issue with the clarity it does. The author treats the inverse transform, composition, acceptance-rejection, ratio-of-uniforms, and exact-approximation in great detail. Here again a very useful set of hands-on exercises is given at the end of the chapter.<br />  Increasing the efficiency of Monte Carlo sampling is the subject of the next chapter, wherein importance sampling, control variates, stratified sampling, correlated sampling, and conditional Monte Carlo are discussed in detail. These methods are usually called variance reduction techniques, but the author gives an interesting argument about why this characterization is not really accurate.<br />  The author brings in conditional sampling, or Markov chain sampling, in the next chapter. It is this approach that has made Monte Carlo such a widely used techniques in science, finance, and network queueing problems. He gives a rather quick overview of the necessary background in Markov chains, and then moves on to discuss neutron transport. It was the intractable nature of the Boltzmann transport equation that gave Monte Carlo its first real application back in the 1940's. The much-used Metropolis<br />method is discussed later, with close attention paid to the details. This is a section that should be read by anyone interested in Monte Carlo techniques. This is followed by a detailed discussion of Markov random fields, Gibbs sampling, and simulated annealing, all of these being heavily used in applications. And also, no book on Monte Carlo could be complete without a discussion of the three-dimensional Ising model, which is in here.  The next chapter concentrates on sampling design and statistical inference, wherein the author discusses how choices of the initial (nonequilibrium) distribution, the number of steps, the number of replications, and the simulation time affect the computational and statistical efficiency of the Monte Carlo simulation. He explains very effectively these issues and also the difficulties involvedwith path-dependence. Network modelers will appreciate his example of routing algorithm performance.  The last chapter treats in great detail procedures for generating pseudorandom numbers. The standard methods for doing this are covered, along with spectral tests and performance issues. More exotic pseudorandom generators using nonlinear recursion are also discussed, but the proofs for these are omittted.  This excellent book belongs on the shelves of anyone interested in Monte Carlo techniques. The price is reasonable considering how much time it would take to collect all the results in the book from the literature. It deserves a highest recommendation.ties involved with path-dependence. Network modelers will appreciate his example of routing algorithm performance.       The last chapter treats in great detail procedures for generating pseudorandom numbers. The standard methods for doing this are covered, along with spectral tests and performance issues. More exotic pseudorandom generators using nonlinear recursion are also discussed, but the proofs for these are omittted.     This excellent book belongs on the shelves of anyone interested in Monte Carlo techniques. The price is reasonable considering how much time it would take to collect all the results in the book from the literature. It deserves a highest recommendation.	2001-05-01
2018019:US	50702879	R1FZ4KQUA9PY65	0691025320	717440668	An Extension of Casson's Invariant. (AM-126)	Books	4	1	1	N	N	Good place to start for recent results	This book is an overview of work done by the author in extending the Casson invariant of integer homology 3-spheres to the rational homology case. The proofs given are very detailed and they bring out how difficult it is to show isotopy invariance via an example of a Heegard splitting of genus 2. The author does a good job of detailing the background needed in the chapter on representation spaces, and discusses effectively the properties of the invariant, such as its invariance under a reversal of orientation, and how it transforms under a Dehn surgery.<br />  The Casson-Walker invariant was generalized to all 3-manifolds by Christine Lescop and is now called the Casson-Walker-Lescop invariant. In addition, a modified version of the Seiberg-Witten invariant and the Casson-Walker invariant for rational homology 3-spheres have been shown to be related, and there are also interesting connections of the invariant to formulas in topological quantum field theory and knot theory.<br />  The book serves well as introduction to these results and should be of interest to students or mathematicians who desire to  know more about this exciting field.	2001-04-28
2018288:US	50702879	R22305ZA7XF8QK	0471193666	181311849	Queueing Networks and Markov Chains: Modeling and Performance Evaluation with Computer Science Applications	Books	4	12	12	N	N	Fine addition to the literature	The authors give a nice overview of computer performance evaluation using queueing theory and continuous and discrete-time Markov chains. After a short review of the relevant probability and statistics, the authors discuss Markov chains in the second chapter, pointing out that Markov processes can be used to model queueing systems even when these systems have behavior governed by non-exponential distributions. They characterize these as Markovizing methods. Their treatment of both discrete and continuous time Markov models is short but adequate, covering all the necessary concepts such as ergodicity and irreducibility. They then give a thorough discussion of the modeling process as actually done in practice. Their discussion of model sizing sets up their methodologies for dealing with large models later in the book. Performance measures for system requirements are discussed in terms of Markov reward models. Their treatment here is very detailed and they also give a large collection of helpful references on the subject.Petri nets are also discussed in the context of model generation. The authors state, correctly I think, that more time should be spent of developing models rather than the underlying mathematics. In their treatment of networks with non-exponential service time and interarrival time distributions, the authors employ the diffusion approximation via the solution of the Fokker-Planck equation. The don't discuss this in detail but give references for those who can read German. This would have been a place for a detailed analysis and derivation, given the surprising introduction of the Fokker-Planck equation in queueing theory. They also use, interestingly, maximum entropy methods to get approximate solutions of open and closed queueing networks. A very short chapter on optimization is given in the next chapter, which could stand to be more lengthy given the importance of this in implementing networks commercially. The next chapter covers some of the performance tools that are available for studying networks. The Performance Evaluation and Prediction System (PEPSY), stochastic Petri net package (SPNP), the CSPL language, the Model Description Language (MOSEL), the symbolic hierarchical automated reliability performance evaluator (SHARPE) are discussed with examples of each. Readers not having these tools will of course will not benefit too much from reading this chapter, except for maybe to get an idea of what is available. The OPNET and Ns-simulator packages,which are very nice modeling tools are not treated at all for some reason.<br />  The last chapter covers applications, with case studies of queueing networks, Markov chains, stochastic Petri nets, and hierarchical models. Although of somewhat limited value in practice, the examples given do give the reader an idea of how the material in the book can be applied. And here again, the authors stress the use of modeling packages such as SHARPE and PEPSY, to verify the calculations in the case studies. They consider a closed non-product form queueing model of a medium-sized LAN in some detail with Ethernet links and a FDDI ring, solving it using Marie's method. Also interesting is their model of the UNIX operating system, which is also represented by a closed non-product queueing network. They compare the computation time needed to solve the model using CTMC, shadow, and DES techniques. Although the discussion is rather hurried, their model of an ATM network is also interesting, in that they use Markov reward models, obtaining both the state and transient solutions.<br />  The book is one that will be of great assistance to those doing network modeling, performance analysis, and other time-scheduling modeling activiites. It is somewhat expensive, but worth the price I think considering the care which the authors take in their exposition.ance tools that are available for studying networks. The Performance Evaluation and Prediction System (PEPSY), stochastic Petri net package (SPNP), the CSPL language, the Model Description Language (MOSEL), the symbolic hierarchical automated reliability performance evaluator (SHARPE) are discussed with examples of each. Readers not having these tools will of course will not benefit too much from reading this chapter, except for maybe to get an idea of what is available. The OPNET and Ns-simulator packages,which are very nice modeling tools are not treated at all for some reason. <br />      The last chapter covers applications, with case studies of queueing networks, Markov chains, stochastic Petri nets, and hierarchical models. Although of somewhat limited value in practice, the examples given do give the reader an idea of how the material in the book can be applied. And here again, the authors stress the use of modeling packages such as SHARPE and PEPSY, to verify the calculations in the case studies. They consider a closed non-product form queueing model of a medium-sized LAN in some detail with Ethernet links and a FDDI ring, solving it using Marie's method. Also interesting is their model of the UNIX operating system, which is also represented by a closed non-product queueing network. They compare the computation time needed to solve the model using CTMC, shadow, and DES techniques. Although the discussion is rather hurried, their model of an ATM network is also interesting, in that they use Markov reward models, obtaining both the state and transient solutions. <br />    The book is one that will be of great assistance to those doing network modeling, performance analysis, and other time-scheduling modeling activiites. It is somewhat expensive, but worth the price I think considering the care which the authors take in their exposition.	2001-04-28
2019807:US	50702879	R2KDSHXMBNEH1H	0387949054	224815373	Sheaf Theory (Graduate Texts in Mathematics)	Books	5	23	24	N	N	Excellent job	This is a very rigorous and detailed account of a very esoteric subject that historically began with the concept of analytic continuation in complex analysis. The author begins with the concept of a presheaf which he defines categorically and then gives a few examples. My preference would be for the author to motivate the subject from a historical perspective, give several concrete examples of presheaves, along with an indepth discussion of why presheaves were invented, and then move on to the abstract definitions. It would be very helpful to the newcomer to sheaf theory if the author could explain why the functor from open sets to abelian groups is a contravariant functor, instead of a covariant one.<br /> Sheaves are defined next, along with several examples of sheaves that illustrate the sometimes non-Hausdorff topology of sheaves. The cohomology of sheaves is discussed in the next chapter, and many examples are given illustrating the main points, along with relative cohomology. Most of the usual constructions from algebraic topology that carry through to sheaf cohomology, such as the Kunneth and universal coefficient theorems, the Mayer-Vietoris sequence, and Steenrod squares.<br /> Sheaf cohomology is compared with other cohomology theories in the next chapter. Although short, the author's discussion is effective in that he clarifies the need for a paracompactifying family of supports, generalizing the paracompactness hypothesis needed in the usual cohomology theories.<br /> Spectral sequences follow in chapter four, and, as is usual with discussions of these, the treatment is very abstract. There are however many examples, and the section on fiber bundles makes even clearer the constructions employed. The Thom class, the Thom isomorphism, the Euler class, and the Gysin sequence all make their appearances.<br /> The most well-written chapter is the next one on Borel-Moore homology. The author does an excellent job of explaining why this homology theory was invented, namely to fix the some of the pathologies of ordinary homology theories. But he also explains effectively that this new homology theory does have some peculiarities of its own. It is a very lengthy chapter however, and very detailed, taking much effort to read and digest.<br /> The book has solutions to most of the exercises in one of the appendices, and these serve to enhance even further the didactic quality of the book. It can serve well for students entering the field, and also to physicists who need an introduction to sheaf theory, as these ideas on now permeating high energy physics via superstring and M-theories.invented, namely to fix the some of the pathologies of ordinary homology theories. But he also explains effectively that this new homology theory does have some peculiarities of its own. It is a very lengthy chapter however, and very detailed, taking much effort to read and digest. <br /> The book has solutions to most of the exercises in one of the appendices, and these serve to enhance even further the didactic quality of the book. It can serve well for students entering the field, and also to physicists who need an introduction to sheaf theory, as these ideas on now permeating high energy physics via superstring and M-theories.	2001-04-26
2026386:US	50702879	R25X6YNV6L0NWP	0262140519	367583799	Using Hard Problems to Create Pseudorandom Generators (ACM Distinguished Dissertation)	Books	4	1	1	N	N	Good overview..... although dated	This book is an elaboration of the results of the author's Phd thesis on the connnection between pseudorandom generators and computational hardness. As such it requires the reader to have a background in this area. The author does not attempt to define the notation and concepts needed for the results outlined.<br />  Randomization can of course be very useful in the design of efficient algorithms, and are often simpler for a given problem. Monte Carlo simulation is an example of this, and is used extensively in physics, chemistry, biology, and finance. In primality testing and some counting problems, the only algorithms known are randomized ones. Some problems, like the approximate computation of the volume of a convex body, can only be solved by a randomized algorithm. In addition, the simulation of a randomized algorithm can be a powerful tool: the computing of the convex hull of n-points in d-dimensional space is obtained by simulating a randomized algorithm. In linear programming, randomized algorithms overtake the best deterministic algorithms by a factor exponential in the dimension d.<br />  In spite of the fact that there are no explicit concrete examples in the book, it is interesting reading, and the author outlines some ideas on how to efficiently simulate (deterministically) random algorithms using assumptions that are not as strong as ones known at that time. The book could be viewed as an attempt to answer whether or not randomization is really of any assistance in making computations efficient, i.e. whether P = BPP. There has been a considerable amount of work done on resolving this question since this thesis was written. It has been shown that if there exists a sparse &quot;efficiently enumerable&quot; language of sufficiently high circuit complexity, then P = BPP. In addition, it has been shown that either all the decision problems solvable in time 2^O(n) are solvable by circuits of size 2^O(n) or B = BPP.  The author also resolves the open question as to whether NP with a random oracle is identical to the class of Arthur-Merlin (AM) languages accepted by some AM machine that runs in polynommial time. In addition, he also describes the construction of a pseudorandom generator for Logspace using multiparty communication games.  Although the book is somewhat dated, it still serves as a good introduction to an important area, and is worth perusing as preparation for further research.tion as to whether NP with a random oracle is identical to the class of Arthur-Merlin (AM) languages accepted by some AM machine that runs in polynommial time. In addition, he also describes the construction of a pseudorandom generator for Logspace using multiparty communication games.         Although the book is somewhat dated, it still serves as a good introduction to an important area, and is worth perusing as preparation for further research.	2001-04-21
2028204:US	50702879	R1EGCJ0L80K5B4	0471874388	745224932	Paul Wilmott on Quantitative Finance, 2 Volume Set	Books	4	41	48	N	N	Good set of books...but needs exercises	This book is a lengthy overview of some modern techniques in financial engineering. If viewed from the standpoint of applications of partial differential equations to finance, then this book is a reasonably complete treatment. The author does spend a great deal of time on the more bread-and-butter topics of financial modeling and less on more specialized topics, as for example weather and energy derivatives, where the use of partial differential equations is of upmost importance. There are of course alternative approaches to financial modeling from the mathematical perspective, such as techniques from the theory of stochastic processes and martingales, but a consideration of such techniques would swell the book to over twice the size, and there are other good books that cover thses approaches in detail.<br /> The author uses Visual Basic and Excel spreadsheets to compute the relevant financial quantities, and given the popularity of spreadsheets in finance, this is appropriate. The numerical solution of partial differential equations is most efficiently done using C (or Fortran) and no doubt the author does recognize this, for he does mention translating existing code in C to Visual Basic.<br /> My only major objection to the book is the lack of exercises, which were a major selling point to me in the author's earlier book on derivatives. Having such exercises is indispensable in understanding results of this nature.<br /> The first few chapters of Volume 1 give an elementary introduction to the theory of derivatives and stochastic calculus. The author does remain concrete in his explanations, and he gives a fairly straightforward derivation of the Black-Scholes equation. This is followed by a very quick discussion of Green's function solutions of the equation and introduction to the Greeks. Generalizations of the Black-Scholes model are discussed later, in the context of dividends, foreign currency, and time-dependent parameters. The author does not give a critical analysis of the Black-Scholes equation in these chapters. This would have been useful to both the practitioner and a newcomer to the field. Also, the Black-Scholes can be derived in many different ways, and it would have been instructive to see some of these alternative derivations. There are derivations of the Black-Scholes equations based on concepts from information theory, and these shed light on the limitations of this equation. All of the concepts in these chapters can be found in the author's earlier book on derivatives.  The second half of the first volume is an overview of the mathematical techniques used to deal with path-dependent and &quot;exotic&quot; options. Consultation of the references is mandatory for a complete understanding of the ideas in these chapters, for the author is a little lacking on details. In addition, more discussion is needed on case history validation of the many formulas given in these chapters: are these formulas useful in practice? The author also introduces some new concepts in this volume that are not in the derivatives book, one being stochastic control. Also, the author introduces a similarity reduction technique for partial differential equations that is very much like the techniques used in neutron reactor physics. Physicists-turned-financial-engineers will see the similarity between these two approaches.<br /> The last part of the first volume deals with extending Black-Scholes. The author discusses the problems with Black-Scholes but his treatment is too hurried. A better approach might have been to give (historical) examples of what might happen, from an investment/risk management perspective, if the assumptions of Black-Scholes are followed to the letter. He does give references though for a more in-depth discussion. Volatility surfaces, viz a viz the Fokker-Planck equation, are discussed here, and effectively. Again, the physicist reader will pick up on the dialog immediately. Information-theoretic techniques, via entropy minimization, are used, interestingly. It is refreshing to see in this part that the author gets down to an empirical analysis of some important issues (volatility for example).<br /> The second volume is somewhat more specialized that the first and outlines in the first chapters fixed income products, swaps, and interest rate derivatives. Phase plane analysis is employed in the discussion on multi-factor interest rate modeling. The treatment here is too curt and needs considerable expansion. The theory of stability of fixed points under the influence of noise is non-trivial and requires careful consideration. A departure from the framework of partial differential equations occurs in the discussion of the Heath, Jarrow, and Morton model. Noting that this model is non-Markovian, he introduces Monte Carlo simulation as a technique to calculate the expected present values. He remarks that the simulation time to carry this out is very long. The sluggishness of Monte Carlo simulations in this model and others in financial engineering has motivated many researchers and start-up firms to devise techniques to speed up the simulations. Indeed, a whole industry has grown in recent years offering packages and algorithms to speed up Monte Carlo.<br />  Risk and portfolio management are also discussed in this volume, beginning with modern portfolio theory. The most interesting and well-written part is on asset allocation in continuous time. Energy derivatives, an up-and-coming field are also discussed. The author is un-sure of himself in this chapter, but he does give a general but elementary introduction to the subject. This is an area that needs a lot more investigation and research given its importance.<br /> The last part of the book addresses numerical methods, and there is some source code in Visual Basic. Monte Carlo simulation is discussed again, along with an introduction to low-discrepancy sequences. These sequences have been used extensively in recent years to improve the efficacy of Monte Carlo simulations. The author's treatment is very terse but he does give many references.<br /> The author has done a fine job in these two volumes, and he spices up the reading with a litte humour, which does not detract at all from the seriousness of the topics, but instead makes for more enjoyable reading., via entropy minimization, are used, interestingly. It is refreshing to see in this part that the author gets down to an empirical analysis of some important issues (volatility for example). <br /> The second volume is somewhat more specialized that the first and outlines in the first chapters fixed income products, swaps, and interest rate derivatives. Phase plane analysis is employed in the discussion on multi-factor interest rate modeling. The treatment here is too curt and needs considerable expansion. The theory of stability of fixed points under the influence of noise is non-trivial and requires careful consideration. A departure from the framework of partial differential equations occurs in the discussion of the Heath, Jarrow, and Morton model. Noting that this model is non-Markovian, he introduces Monte Carlo simulation as a technique to calculate the expected present values. He remarks that the simulation time to carry this out is very long. The sluggishness of Monte Carlo simulations in this model and others in financial engineering has motivated many researchers and start-up firms to devise techniques to speed up the simulations. Indeed, a whole industry has grown in recent years offering packages and algorithms to speed up Monte Carlo. <br />  Risk and portfolio management are also discussed in this volume, beginning with modern portfolio theory. The most interesting and well-written part is on asset allocation in continuous time. Energy derivatives, an up-and-coming field are also discussed. The author is un-sure of himself in this chapter, but he does give a general but elementary introduction to the subject. This is an area that needs a lot more investigation and research given its importance. <br /> The last part of the book addresses numerical methods, and there is some source code in Visual Basic. Monte Carlo simulation is discussed again, along with an introduction to low-discrepancy sequences. These sequences have been used extensively in recentyears to improve the efficacy of Monte Carlo simulations. The author's treatment is very terse but he does give many references. <br /> The author has done a fine job in these two volumes, and he spices up the reading with a litte humour, which does not detract at all from the seriousness of the topics, but instead makes for more enjoyable reading.	2001-04-19
2041287:US	50702879	RD6FU5LM8Z5X0	0198504187	717531192	Virus dynamics: Mathematical principles of immunology and virology	Books	4	39	40	N	Y	A good introduction	This book is best described as the application of nonlinear ordinary differential equations to immunology and virology. It's primary emphasis is on understanding the time development of viral infections, drug treatments, and viral resistance of the HIV and hepatitis-B viruses.<br />  The authors do a good job of describing the relevant equations needed to model virus dynamics. The book would be a good beginning for mathematicians interested in going into the field of mathematical immunology. And, even though it should be classified as a monograph, rather than a textbook, since there are no problem sets, students of mathematical immunology should find this book a useful introduction to the subject. In addition, the authors give a large list of references at the end of each chapter for further reading.<br /> Mathematicians who need a background in the biology of the HIV virus will find a good discussion in Chapter 2 of the book. The authors give an historical summary of the origins and treatment of the virus in this chapter. This sets the stage for the mathematical modeling of virus dynamics in Chapter 3, where the authors define the basic reproductive ratio and write down a system of three coupled nonlinear ordinary differential equations as the basic equations of virus dynamics. They remark, though without justification, that an analytical solution of the time development is not possible, and so they use approximation schemes to solve the equations. The equations are a phenomenological representation of virus dynamics, and no attempt is made to relate the rate constants to the underlying microscopic properties/structures/processes of viruses. They do however discuss the empirical data associated with studies of SIV infections, and show convincingly there is a correlation between the initial growth of the virus and its value at equilibrium. They caution the reader that the basic model does not give the true reproductive ratio, and show how to correct for this by introducing time delays.<br /> The efficacy of drug therapy is treated from both a mathematical and experimental viewpoint in the next chapter. This is a very enlightening discussion from the standpoint of the validation of the virus models.<br /> The authors switch gears in the next chapter and talk about the dynamics of the Hepatitus B virus. Again, they do a good job of introducing the reader to the experimental evidence for the models of this virus.<br /> In chapter 6, they bring in the contribution of the immune system to the basic equations. They assume that the reader is familiar with the concept of CTL responsiveness. The resulting equations are somewhat more complicated, and the authors show how the ubiquitous Lotka-Volterra equations arise with the virus being the prey, and the immune system the predator. No detailed phase space analysis is done however to study any of the equations in this chapter, which would have been useful to the reader.<br /> The chapter on quasispecies is the most interesting one in the book, as the authors not only give a rudimentary definition of quasispecies, but they also give an indication of their complexity. Disappointingly, they mention the idea of mutation rates and their connection with chaos and self-organized criticality, but do not elaborate on this at all.<br /> The Bonhoeffer's laws of anti-viral treatment are discussed in the next chapter and the authors show how to derive them using the basic  model. The emergence of resistance during drug treatment is modeled by parameters which reflect the replication rates of the virus, but these parameters are again not connected with any underlying microscopic properties of the virus.<br /> Some interesting dynamical behavior occurs for the case of multiple epitopes where the existence of quasiperiodic oscillations is shown to occur. They authors refer to this as &quot;unpredictable&quot; but they do not define this term in the book. The existence of quasiperiodic orbits in a dynamical system does not by itself make the system &quot;unpredictable&quot; or random of some sort.<br /> This book is a very addition to the literature, and most importantly, it emphasizes the role of validating mathematical models experimentally, which takes on even greater importance given the medical ramifications of the topics in this book.a dynamical system does not by itself make the system &quot;unpredictable&quot; or random of some sort. <br /> This book is a very addition to the literature, and most importantly, it emphasizes the role of validating mathematical models experimentally, which takes on even greater importance given the medical ramifications of the topics in this book.	2001-04-08
2044351:US	50702879	R11A9377U1AVGH	0521585198	615208293	Algorithms on Strings, Trees, and Sequences: Computer Science and Computational Biology	Books	5	67	69	N	N	Excellent...but dense	This textbook gives a rigorous introduction to the algorithms of computational biology from the standpoint of theoretical computer science. It does however give the reader an overview of the practical application of these algorithms to the subject. The author gives a very detailed discussion of the most important results in the field, but the book is very dense: there are 228 definitions, 127 theorems, 490 references, and over 400 exercises that both illustrate the topics in the book and extend them. The author omits any real source code, but does give a URL where code for many of the algorithms can be found.<br />  The author restricts his attention to deterministic approaches to string matching and comparison, and thus there is no treatment of hidden Markov models or Monte Carlo methods. The major algorithms such as the Aho-Corasick, Boyer-Moore, Knuth-Morris-Pratt, Needleman-Winsch, and Smith-Waterman are discussed and brilliantly motivated in the book. The author employs very effective diagrams to illustrate the matching concepts that are detailed in the book.<br />  The book does require some time to read but it is worth the effort. Also, the exercises can be challenging but some should he done in order to understand the concepts in the book. The empirical results of the algorithms as sequence databases are also included, with FASTA, BLAST, BLOCKS, BLOSUM, and PROSITE are discussed in detail. The chapter that discusses these is the least mathematical of all the ones in the book and was no doubt included to connect the reader with real-world applications of the techniques in the book.<br />  The last quarter of the book is a lot more trendy than the rest, with emphasis placed on algorithms for physical mapping, fragment assembly, and phylogenetic trees. These algorithms of course take on particular importance today given the Human Genome and other gene sequencing projects.  Radiation-hybrid mappings, direct sequencing, and shotgun DNA sequencing are discussed in one of the chapters in this section, and the author addresses in great detail some approaches to speeding up sequence assembly. In the discussion on shotgun DNA sequencing the author refrains from any  probabilistic analysis, instead referring the reader to the references. This omission goes along with the rest of the book, where probabilistic methods are not used, which is a little disappointing since these have shown great promise in computational biology. The exercises at the end of the chpater are very interesting and it is worth spending time working some of them through.<br />  In a later chapter, the solution of the satisfiability problem in mathematical logic is discussed and shown to be solved (at least theoretically) by DNA-based computing. The quantities of DNA needed to carry out the computation are shown to be infeasible by the author.<br />  This book will no doubt be of great assistance to those interested in the more rigorous approaches to computational biology. But the best attribute of the book is that one gets the impression that the author had a good time writing it, and that shows through in this very important book.ed in one of the chapters in this section, and the author addresses in great detail some approaches to speeding up sequence assembly. In the discussion on shotgun DNA sequencing the author refrains from any  probabilistic analysis, instead referring the reader to the references. This omission goes along with the rest of the book, where probabilistic methods are not used, which is a little disappointing since these have shown great promise in computational biology. The exercises at the end of the chpater are very interesting and it is worth spending time working some of them through. <br />   In a later chapter, the solution of the satisfiability problem in mathematical logic is discussed and shown to be solved (at least theoretically) by DNA-based computing. The quantities of DNA needed to carry out the computation are shown to be infeasible by the author. <br />    This book will no doubt be of great assistance to those interested in the more rigorous approaches to computational biology. But the best attribute of the book is that one gets the impression that the author had a good time writing it, and that shows through in this very important book.	2001-04-05
2048413:US	50702879	R13VVKHD10AW16	0521629713	810685756	Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids	Books	5	43	46	N	N	Excellent overview of probabilistic computational biology	This book is a very well written overview to hidden Markov models and context-free grammar methods in computational biology. The authors have written a book that is useful to both biologists and mathematicians. Biologists with a background in probability theory equivalent to a senior-level course should be able to follow along without any trouble. The approach the author's take in the book is very intuitive and they motivate the concepts with elementary examples before moving on to the more abstract definitions. Exercises also abound in the book, and they are straightforward enough to work out, and should be if one desires an in-depth understanding of the main text. In addition, there is a software package called HMMER, developed by one of the authors (Eddy) that is in the public domain and can be downloaded from the Internet. The package specifically uses hidden Markov models to perform sequence analysis using the methods outlined in the book.<br /> Probabilistic modeling has been applied to many different areas, including speech recognition, network performance analysis, and computational radiology. An overview of probabilistic modeling is given in the first chapter, and the authors effectively introduce the concepts without heavy abstract formalism, which for completeness they delegate to the last chapter of the book. Bayesian parameter estimation is introduced as well as maximum likelihood estimation. The authors take a pragmatic attitude in the utility of these different approaches, with both being developed in the book.<br /> This is followed by a treatment of pairwise alignment in Chapter Two, which begins with substitution matrices. They point out, via some exercises, the role of physics in influencing particular alignments (hydrophobicity for example). Global alignment via the Gotoh algorithm and local alignment via the Smith-Waterman algorithm, are both discussed very effectively. Finite state machines with accompanying diagrams are used to discuss dynamic programming approaches to sequence alignment. The BLAST and FASTA packages are briefly discussed, along with the PAM and BLOSUM matrices.<br /> Hidden Markov models are treated thoroughly in the next chapter with the Viterbi and Baum-Welch algorithms playing the central role. HIdden Markov models are then used in Chapter 4 for pairwise alignment. State diagrams are again used very effectively to illustrate the relevant ideas. Profile hidden Markov models which, according to the authors are the most popular application of hidden Markov models, are treated in detail in the next chapter. A very surprising application of Voronoi diagrams from computational geometry to weighting training sequences is given.<br /> Several different approaches, such as Barton-Sternberg, CLUSTALW, Feng-Doolittle, MSA, simulated annealing, and Gibbs sampling are applied to multiple sequence alignment methods in Chapter 6. It is very well written, with the only disappointment being that only one exercise is given in the entire chapter. Phylogenetic trees are covered in Chapter 7, with emphasis placed on tree building algorithms using parsimony. The next chapter discusses the same topic from a probabilistic perspective. This to me was the most interesting part of the book as it connects the sequence alignment algorithms with evolutionary models.<br /> The authors switch gears starting with the next chapter on transformational grammars. It is intriguing to see how concepts used in compiler construction can be generalized to the probabilistic case and then applied to computational biology. The PROSITE database is given as an example of the application of regular grammars to sequence matching. This chapter is fascinating reading, and there are some straightforward exercises illustrating the main points.<br /> The last chapter covers RNA structure analysis, which introduces the concept of a pseudoknot. These are not to be confused with the usual knot constructions that can be applied to the topology of DNA, but instead result from the existence of non-nested base pairs in RNA sequences. The authors discuss many other techniques used in RNA sequence analysis and take care to point out which ones are more practical from a computational point of view. Surprisingly, genetic algorithms and algorithms based on Monte Carlo sampling are not discussed in the book, but the authors do give references for the interested reader.<br /> The best attribute of this book is that the authors take a pragmatic point of view of how mathematics can be applied to problems in computational biology. They are not dogmatic about any particular approach, but instead fit the algorithm to the problem at hand.the topology of DNA, but instead result from the existence of non-nested base pairs in RNA sequences. The authors discuss many other techniques used in RNA sequence analysis and take care to point out which ones are more practical from a computational point of view. Surprisingly, genetic algorithms and algorithms based on Monte Carlo sampling are not discussed in the book, but the authors do give references for the interested reader. <br /> The best attribute of this book is that the authors take a pragmatic point of view of how mathematics can be applied to problems in computational biology. They are not dogmatic about any particular approach, but instead fit the algorithm to the problem at hand.	2001-04-01
2048788:US	50702879	R19HB1BCP0Y3EG	0521407001	122823773	Gene Cloning and Manipulation	Books	5	7	8	N	N	Excellent overview of techniques in genetic engineering	This book is a &quot;wet&quot; approach to genetic engineering and outlines for the reader modern laboratory techniques in cloning and gene sequencing. It is well suited for a mathematician or an aspiring bioinformatics specialist who needs an overview of the experimental side of genetic engineering. The treatment is very detailed and a lot is covered given the size of the book, but it is well written and an interesting read. It does require a fair amount of background in biochemistry but even readers without such a background can follow the dialog if close attention is paid to the definitions. A little elementary physics background is required in the discussion on gel electrophoresis, and in the discussion on biolistic transformations with a particle gun. For the mathematician/bioinformaticist the most useful chapters will be the chapters on the making and screening libraries. The validation of gene sequence data is an important but tedious exercise and these chapters introduce the reader to what must lie ahead if such activities are pursued. Even if read leisurely the book is fascinating and one takes away a deeper appreciation of the tools and techniques used in this new century of biology.	2001-04-01
2056012:US	50702879	R34SYQ4SKYIC17	0849385245	384502541	Handbook of Discrete and Computational Geometry	Books	4	14	14	N	N	Very comprehensive overview of computational geometry	This book, written by many well-known experts in the field, is a fine compendium of articles on the most active areas of computational geometry. Each article is supplemented with a glossary of terms needed for understanding the relevant concepts and frequently contains a list of open problems.  An overview of the convex hull of a collection of random points in Euclidean n-space is given in one of the articles on discrete aspects of stochastic geometry, where also a very interesting discussion of generalizations of the Buffon needle problem is given.<br />  There are a few articles overviewing Voronoi diagrams, such as the one on Voronoi diagrams and triangulations. The applications of Voronoi diagrams are many, and include tumour cell diagnosis, biometry, galaxy distributions, and pattern recognition. This article is a little short considering the importance of the subject.<br />The article on shortest paths and networks is somewhat disappointing since there is no in-depth discussion on network routing algorithms.<br />  The article on computational topology highlights some of the results in this very important area. Many problems in topology have been tackled recently using computers, particularly the work of the mathematician A.T. Fomenko. Computational topology is a relatively young field, having been in existence only since the early 1990's. The applications are enormous, ranging from meshing, morphing, feature extraction, data compression, and in many scientific areas such as computational medicine, chemistry, and astrophysics. It can also be used in computer security via graphical passwords. It is an immense help in visualizing complicated topological objects, such as Lens spaces, horned spheres, and thickened knots. The article does not touch on the use of Mayer-Vietoris sequences to design efficient divide-and-conquer schemes for computing the homology of higher-dimensional complexes. The interplay between topology and finding better algorithms in computational geometry is one that will flourish no doubt in years to come.<br />The last section of the book covers applications with the most interesting article being the one on sphere packing and coding theory. The algorithms in sphere packing have direct applicability to error correctiong codes over the field GF(q). The author of this article does touch briefly on general algebraic-geometric codes, which is good considering their importance in applications.<br />The last article appropriately discusses available software for computational geometry. Although the list of Web sites is quite extensive, there are many more available since this book was first printed.<br />  A very fine addition to the literature on computational geometry and should be on everyone's shelf who is interested in this important area.putational geometry is one that will flourish no doubt in years to come. <br />The last section of the book covers applications with the most interesting article being the one on sphere packing and coding theory. The algorithms in sphere packing have direct applicability to error correctiong codes over the field GF(q). The author of this article does touch briefly on general algebraic-geometric codes, which is good considering their importance in applications.<br />The last article appropriately discusses available software for computational geometry. Although the list of Web sites is quite extensive, there are many more available since this book was first printed. <br />  A very fine addition to the literature on computational geometry and should be on everyone's shelf who is interested in this important area.	2001-03-25
2056209:US	50702879	R15GPAAO4PWZ01	0691025460	477760322	Pseudorandomness and Cryptographic Applications (Princeton Computer Science Notes)	Books	4	9	9	N	N	Definitely worth studying	Walking into a colleague's office and noticing papers scattered all over her desk and shelves, I remarked on the apparent disorganization. She explained that from her standpoint everything was organized and easy to find. Randomness, she said, is observer dependent.<br />  This is the theme taken in this book, namely tha a proper concept of randomness is not an intrinsic property of a collection or a distribution, but rather is dependent of the tools and computing capabilities of the observer. The concept of a pseudorandom distribution is introduced as a distribution where no efficient procedure or program can distinguish it from a uniform distribution. Pseudorandom generators are polynomial-time deterministic programs that take a randomly selected seed and expand it into a pseudorandom bit sequence.<br />  The preliminaries/introduction gives an overview of sets, set functions, big-O, little-o notation, and most importantly from the author's standpoint, function and probability ensembles. He defines what it means to have a source of random bits, but does not give algorithms on how to produce them. Complexity classes are also discussed for both the deterministic and probabilistic cases, along with a very brief review of probability.<br />  Private key cryptosystems begin the next chapter with an example of a one-time-pad private key cryptosystems. Pseudorandom generators are introduced as a solution to the problem of sending secure messages that are longer than the private key.<br />  The author does a good job of defining computational and statistical indistinguishability, and the connection between 1-way functions and pseudorandom generators. What is interesting about all of these constructions is that they are based on sequences of probability distributions (called ensembles in the book) instead of a single probability distribution. The author defines ensembles as being different and close in the statistical sense and then uniform and pseudorandom.<br />  The approach he takes is helpful because he gives informal definitions to develop the reader's intuition and then moves on to the formal definitions. After reading the book, one takes away an appreciation of what pseudorandomness is all about and how it applies to cryptography.approach he takes is helpful because he gives informal definitions to develop the reader's intuition and then moves on to the formal definitions. After reading the book, one takes away an appreciation of what pseudorandomness is all about and how it applies to cryptography.	2001-03-25
2056835:US	50702879	R2XGJRDFT4HANK	0691000492	452719222	Introduction to Toric Varieties. (AM-131)	Books	4	11	12	N	N	Good introduction to the subject	Anyone who needs a concrete set of examples from the set of general algebraic varieites will find them in toric varieties. The definitions and resulting constructions of toric varieties satisfy the need for an intuitive understanding of varieties. In addition, toric varieties are the easiest collection of varieties to manipulate from the standpoint of computational-geometric algorithms. Toric varieties also have applications to various areas of mathematical physics, such as in mirror symmetry. Indeed, the case of toric varieties is one of the few examples where an explicit mirror can be found.<br />Fulton gives an excellent overview of toric varieties in this short book, and the reading is fairly easy going. He introduces toric varieties in the first chapter as objects originating from compactification studies, with projective n-space the natural example as a compactification of complex n-space. It is their definition in terms of fans in lattices however that permeates chapter one. The author's treatment is very understandable, and he does not hesitate to use many diagrams and figures to illustrate the concepts. This is followed by a consideration of compactness and resolution of singularities. The example given of the resolution of a two-dimensional toric singularity is done, interestingly, via Hirzebruch-Jung continued fractions. A taste of the algebraic topology of toric varieties is given in the next chapter, where the fundamental groups and Euler characteristics are calculated, along with the cohomology of line bundles over toric varieties. More of this follows in the next chapter, where a statement and proof of Serre duality is given, along with a calculation of Bott numbers. The most interesting results are in the last chapter of the book on intersection theory. Because of the intuitive nature of toric varieties, one can see the very abstract constructions of algebraic geometry take on a concrete form. I think one can appreciate the more abstract constructions in algebraic geometry if the more concrete examples are studied first. This is especially true for those seeking to apply these ideas, for example physicists, who must grasp them quickly and efficiently.<br />This book should give readers sufficient insight into the subject to move on to applications or to more advanced treatments of toric varieties or algebraic geometry.ns in algebraic geometry if the more concrete examples are studied first. This is especially true for those seeking to apply these ideas, for example physicists, who must grasp them quickly and efficiently. <br />This book should give readers sufficient insight into the subject to move on to applications or to more advanced treatments of toric varieties or algebraic geometry.	2001-03-25
2061011:US	50702879	R3FC2GG3W75QNU	0521497701	641895548	A First Course in Optimization Theory	Books	4	36	39	N	N	Good introduction to the field of optimization	This book gives a nice introduction to the theory of optimization from a purely mathematical standpoint. The computational and algorithmic aspects of the subject are not treated, with emphasis instead placed on existencetheorems for various optimization problems. The author does an effective job of detailing the mathematical formalism needed in optimization theory. After a brief review of background mathematics in the first chapter, the author outlines the objectives of optimization theory in Chapter Two. He also gives some examples of optimization problems, such as utility maximization, expenditure minimization, profit maximization, cost minimization, and portfolio choice. All of these examples are extremely important in industrial, logistical, and financial applications. The author is also careful in this chapter to outline his intentions in later chapters, namely, that of finding the existence of solutions to optimization problems, and also in the characterization of the set of optimal points. The existence question is outlined in Chapter Three using only elementary calculus, and the Weierstrass theorem is proved. Necessary conditions for unconstrained optima are examined in the next chapter, again using only elementary calculus and linear algebra. Lagrange multipliers and how they are used in constrained optimization problems are effectively discussed in Chapter 5. To discuss how optimization problems vary with a set of parameters, in particular if they vary continuously with the set of parameters, the author introduces the concept of a corespondence. This is essentially a map that assigns sets to points. His discussion of upper and lower-semicontinuity is very clear and I think one of the best presentations given at this level. He then proves a maximum theorem, showing that parametrized optimization problems can have continuous solutions under certain conditions. A game-theoretic application follows along with statements, but not proofs, of the Kakutani and Brouwer Fixed Point theorems. The author introduces an order relation on the parameter space and discusses parametric monotonicity in the next chapter. Again a game theory application is given along with a statement (but not a proof) of the Tarski Fixed Point theorem. The last two chapters cover dynamic programming and these are the most interesting chapters of the book. It is here that the author makes the connection with more advanced treatments of optimization theory, via Banach spaces and nonlinear functional analysis. With further reading in real analysis and topology, readers will be well on their way to understanding more advanced treatments of optimization theory that use nonlinear functional analysis and differential topology.uwer Fixed Point theorems. The author introduces an order relation on the parameter space and discusses parametric monotonicity in the next chapter. Again a game theory application is given along with a statement (but not a proof) of the Tarski Fixed Point theorem. The last two chapters cover dynamic programming and these are the most interesting chapters of the book. It is here that the author makes the connection with more advanced treatments of optimization theory, via Banach spaces and nonlinear functional analysis. With further reading in real analysis and topology, readers will be well on their way to understanding more advanced treatments of optimization theory that use nonlinear functional analysis and differential topology.	2001-03-21
2061483:US	50702879	RTVRNJW1UJIPF	0817650660	421700421	Symplectic Invariants and Hamiltonian Dynamics (Birkhauser Advanced Texts)	Books	5	8	9	N	N	Very well written	This monograph gives a good overview of a very important subject in both mathematics and physics. The phase space formulation of classical mechanics via the Hamiltonian formalism is represented throughout this book in the language of symplectic manifolds. The geometry of symplectic manifolds has many surprises considering the very simple definition of a symplectic form. One would not have suspected that they would imply the Gromov squeezing theorem and other interesting results. The authors do an excellent job of explaining this theorem and other intricacies of symplectic geometry, in particular the idea of symplectic capacities, Floer-Morse theory, and the Arnold conjecture. The Gromov squeezing theorem has an analogue in quantum physics. Jokingly called &quot;quantum claustrophobia&quot; by physicists, this represents the idea that particles in the quantum realm tend to avoid small regions of phase space. The book should be of great assistance to the mathematically-inclined physicist interested in the properties of nonlinear dynamical systems in phase space. Even though the KAM theory is only briefly discussed in the book, the presentation should prepare the physicist reader for additional reading on the subject. The most interesting and important part of the book is the discussion on how symplectic capacities are related to volumes and Lebesgue measures in ordinary Euclidean space. The capacity and volume agree as invariants only for two-dimensional symplectic manifolds. In addition, in four dimensions and higher, open sets can be very different in terms of shape, size, measure, and topology, and still have the same capacity. The author's presentation of these facts is very well-written and thought provoking. Probably the most difficult part of the book is the justification of the squeezing theorem using variational principles. The technical details of the proof are very intricate and take lots of time to digest. Everything about the symplectic category is interesting and this book is a fine compendium of modern results in the field.sting and this book is a fine compendium of modern results in the field.	2001-03-21
2064701:US	50702879	R3IT01UH2B96MF	082182127X	34384883	Mirror Symmetry and Algebraic Geometry (Mathematical Surveys and Monographs)	Books	5	14	15	N	N	Excellent overview of mirror symmetry	This book is one of the few monographs on mirror symmetry that is not a collection of articles written by specialists. It attempts to put mirror symmetry on a mathematically rigorous foundation and does so to a large degree. The book opens with a review of the motivations for mirror symmetry in quantum field theory and superstring theory. The content of this chapter is straightforward reading for physicists/string theorists but mathematicians may have trouble with the physical reasoning employed. The chapter explains the motivation for the mathematical constructions performed in the rest of the book. The author does a good job of presenting the mathematics in a form that is as rigorous as possible. The predictions made by physicists to quantities in in algebraic geometry are too interesting from a mathematical standpoint to let lay couched in the formalism of path integrals. The book gives many examples of mirror symmetry constructions that are rigorous mathematically, most of these involving toric varieties. A general methodology for finding the mirror of a given Calabi-Yau manifold is still unknown according to the author. By far the best chapter in the book is the one on quantum cohomology, as this tool has so many applications in algebraic and symplectic geometry. One is always impressed on the originality and breadth of ideas that have been employed in this subject. There are several topics in mirror symmetry that are not discussed in the book, but even with these omissions, this is a fine addition to the literature on the subject. One question that immediately arises when thinking about mirror symmetry is there is anything that is interesting in the case of Calabi-Yau manifolds over finite fields. The special case that comes to mind is for elliptic curves. Are mirrors of Calabi-Yau manifolds easier to find in the finite field case and does the mirror have a group operation related to the one on the original manifold (elliptic curve)? These questions are not addressed in this book, but answering them may have important ramifications for applications of mirror symmetry to the field of cryptography for example.dressed in this book, but answering them may have important ramifications for applications of mirror symmetry to the field of cryptography for example.	2001-03-18
2065696:US	50702879	R1G1KNED0Y85HV	0821806343	168614903	Mirror Symmetry II (Ams/Ip Studies in Advanced Mathematics, No. 1)	Books	5	3	3	N	N	Excellent	This book is somewhat dated since Mirror Symmetry III has recently appeared. However, this volume is now being reprinted and so a review is appropriate.  The topic of mirror symmetry has to rank as the most fascinating one in all of modern mathematics. It has its origins in high energy physics, and as such to understand it fully, one must have a background in both quantum field theory and in some fairly esoteric mathematics, such as algebraic geometry, algebraic topology, and complex manifolds. A mathematician familiar with these areas will also have to get used to the sometimes hand-waving arguments used by physicists to discuss some of the concepts in mirror symmetry.  The book is a collection of articles written by well-known experts in the field, and each article has varying degrees of physics/mathematics interplay. The literature on mirror symmetry has been dubbed &quot;physical mathematics&quot; by some mathematicians because of the physical constructions employed that are not based on rigorous mathematics.  The powerful connections between quantum field theory and algebraic geometry are brought out in the first article of the book by B.R. Greene and H.Oogurt. Correlation functions in quantum field theory are related to the collection of holomorphic maps to rational curves on a complex compact 3-dimensional Kahler manifold. This theme of relating correlation functions in quantum field theory and superstring theory to various structures in algebraic geometry and complex manifolds is played out in the rest of the book.  Most fascinating is the construction of the mirror manifolds themselves, for these look the same from a physical string-theory standpoint but are different as complex manifolds. The properties needed by physics imply the relevant manifolds are Calabi-Yau, many having been found by computer. The challenge of defining mirror symmetry rigorously is brought out in many articles in the book, with toric varieties showing the most promise: the enlarged Kahler moduli space of a given manifold is isomorphic to the complex structure moduli space of its mirror. Interestingly, some of the authors show that topology change can occur intrinsically in string theories; this is to be contrasted with &quot;effective&quot; changes in topology that occur in quantum field theory (and even in quantum mechanics). Again, toric varieties play the predominant role in showing this behavior.  Some of the authors discuss the connection between mirror symmetry and enumerative geometry. This connection has stimulated much research, and the book serves as an introduction to the fascinating area of quantum cohomology.  I think it would be fair to classify the results in this book as a kind of &quot;quantization of mathematics&quot;. The reasonable effectiveness of physics in mathematics, to rephrase the statement by Eugene Wigner, is brought out brilliantly by the authors in this book.larged Kahler moduli space of a given manifold is isomorphic to the complex structure moduli space of its mirror. Interestingly, some of the authors show that topology change can occur intrinsically in string theories; this is to be contrasted with &quot;effective&quot; changes in topology that occur in quantum field theory (and even in quantum mechanics). Again, toric varieties play the predominant role in showing this behavior.   Some of the authors discuss the connection between mirror symmetry and enumerative geometry. This connection has stimulated much research, and the book serves as an introduction to the fascinating area of quantum cohomology.    I think it would be fair to classify the results in this book as a kind of &quot;quantization of mathematics&quot;. The reasonable effectiveness of physics in mathematics, to rephrase the statement by Eugene Wigner, is brought out brilliantly by the authors in this book.	2001-03-17
2066025:US	50702879	RCH5TKTEEZQGB	0817634967	209009677	Elements of KK-Theory (Mathematics: Theory & Applications)	Books	4	3	3	N	N	Be prepared	This monograph gives an excellent introduction to a very abtruse and difficult subject. Readers familiar with the K-theory of operators due to Brown-Douglas-Fillmore and the Kadison-Ringrose theory of operator algebras should have ample background to read this book. These background works are very advanced mathematical subjects and so this book should be viewed as one written for specialists only.  KK-theory can be thought of in some sense as a unification of K-homology and K-cohomology. This takes place via the KK bivariant groups of the mathematician G.G. Kasparov. Ordinary K-theory has its origins of course in the theory of elliptic operators via the work of M.Atiyah and I.Singer on index theory. The authors of this book however do not motivate their book at all with any history or with any discussion of elliptic operators but instead proceed from a purely algebraic/axiomatic point of view. This approach is well suited to mathematicians coming to the subject for the first time since no doubt they are familiar with the BDF theory if they are choosing to learn KK-theory. However, KK-theory is now finding applications in physics, such as superstring and dual theories, and physicists would not in general be familiar with the BDF/Kadison-Ringrose works. For physicists then this book might be very difficult to follow.  That being said this is an interesting subject, and the authors do a good job for those who are prepared. The product on KK groups that Kasparov constructed can be used to obtain all the usual products in topological K-theory, such as the cap, cup, and slant products. Reading the book will also prepare one for the fascinating area of non-commutative geometry ala Alain Connes.	2001-03-17
2066137:US	50702879	RPUM1E21IMNBA	3540669132	491167918	Mathematics Unlimited	Books	5	17	20	N	N	An awesome look at the future of mathematics	This book is a look to the future of mathematics based on the trends in mathematical thinking at the present time.  I did not read all the articles in the book, so my review will be limited to those I did.  The article &quot;Experimental Mathematics&quot; by D. Bailey and J. Borwein is an overview of a somewhat controversial activity in mathematics.  This activity, characterized as &quot;experimental&quot; mathematics, has, the authors argue, enabled very interesting mathematical problems to be eventually solved. They outline in the article the recent discovery of how to calculate the the nth digit of Pi without computing any of the first n-1 digits without multiple-precision arithmetic and needing only low memory. The calculation scheme was based on a formula that was discovered by a computer, the first time this has happened.according to the authors. Experimental mathematics can be viewed as &quot;real-time&quot; discovery of mathematics, as well as letting us visualize the mathematical structures involved using computer graphics. Mathematicians interested in network modeling will appreciate the article by F. Kelly entitled  &quot;Mathematical Modeling of the Internet&quot;. Interestingly, his approach makes use of dynamical systems, with the goal of studying the behavior and stability of the TCP/IP protocol.  The most interesting section of the article is the section on packet marking strategies. One can find surprising connections between strategies for packet marking, packet shaping, and network QoS, with techniques in option pricing from financial engineering. This is particularly true for frame relay networks. This connection was not discussed in Kelly's article, but I have found these connections in developing my own network models. Kelly  gives good insight on how to apply techniques from optimization theory and dynamical systems to study the behavior of modern networks. The network modeling of the 21st century will have to contend with wireless, DWDM, and other more exotic technologies.  By far the most interesting articles in the book were the two articles &quot;Geometric Aspects of Mirror Symmetry&quot; by D. Morrison and &quot;A Chapter in Physical Mathematics&quot; by K. Marathe. The constructions that take place in the areas discussed in these two articles have to rank as the most fascinating in all of mathematics. And most interestingly, the ideas had a powerful influence from theoretical physics. One can say without question that physical ideas coming from quantum field theory/high energy physics justify a rephrasing of the words of the famous physicist Eugene Wigner. One could now speak of &quot;the reasonable influence of physics in mathematics&quot;. Physical ideas have permeated many different areas of mathematics and will continue to do so. Some mathematicians have classified this influence as &quot;physical mathematics&quot; because some of the mathematical constructions have not been justified rigorously. Several brilliant mathematical developments have occurred in the last two decades resulting from ideas from high energy physics, such as quantum invariants of knots and three-dimensional manifolds, Seiberg-Witten theory, mirror symmetry in algebraic geometry, and supersymmetry and index theorems. These exciting results could be described best as kind of a &quot;quantization of mathematics&quot;, and the future will hold more of the this line of thinking. Every construction in mathematics will have a quantum analog, with a correspondence between mappings/structures in &quot;ordinary&quot; or &quot;classical&quot; mathematics and unitary transformations/noncommutative structures in the &quot;quantized&quot; version. An example of this kind of development is occurring today in the field of non-commutative geometry.  &quot;Mathematics Unlimited-2001 And Beyond&quot; is a brief glimpse of what will be an exciting century for mathematics. Quantum computation will no doubt become a  reality soon, and its computational power, coupled with the needs of the information age, will push mathematics to new dizzying heights. What was called experimental and physical mathematics in the book will continue to have their niches; but &quot;pure&quot; mathematics will also hold its ground and continue to solidify and advance. The mathematical adventure is just beginning......computational power, coupled with the needs of the information age, will push mathematics to new dizzying heights. What was called experimental and physical mathematics in the book will continue to have their niches; but &quot;pure&quot; mathematics will also hold its ground and continue to solidify and advance. The mathematical adventure is just beginning......	2001-03-17
2069206:US	50702879	R2DY7OYATDPM7I	0521423538	951743674	Complex Algebraic Curves (London Mathematical Society Student Texts)	Books	4	10	11	N	N	Well suited as an introduction to algebraic curves	The book gives a good general overview of algebraic curves using only elementary algebra, topology, and complex analysis. There are lots of diagrams of elliptic curves in the historical introduction in the first chapter and the subject is well motivated. Hilbert's Nullstellensatz is introduced in the context of real algebraic curves as an answer to the question of when the polynomials definte the same curve. The visualization approach taken by the author in the first chapter has taken on dramatic proportions do to the computer graphics packages currently available.  The author introduces complex algebraic curves in complex 2-dimensional space in the next chapter. Recognizing that such curves are not compact, he compactifies them by adding suitable points at infinity, giving complex projective curves. The algebraic properties of these curves are studied in the next chapter. He does a good job of motivating the group law on elliptic curves on the last theorem of the chapter, leaving the proof of associativity to the reader in the exercises. The topology of complex projective curves is taken up in Chapter 4. The author gives two proofs of the degree-genus formula, one geometric and the other from a holomorphic point of view. This leads to a consideration of branch points and ramified covers. The author's outline of the proofs is very detailed and therefore very helpful to one encountering the proof for the first time. The statement of the formula via the Riemann-Roch theorem in more formal treatments (and later in the book) can then be appreciated more.  The subject of non-singular complex projective curves, namely Riemann surfaces, is effectively discussed in Chapter 5, with holomorphic differentials outlined in Chapter 6. The Riemann-Roch theorem makes its appearance here, and the author is careful to point out its use as an alternative characterization of the genus given earlier by topological arguments. Divisors are introduced as formal sums, but their understanding is straightforward here because the author has motivated them with a discussion of the properties of holomorphic and meromorphic functions earlier in the chapter. The proof of the Riemann-Roch theorem is very detailed and understandable. The book ends with a discussion of singular curves via resolution of singularities. Newton polygons and Puiseux expansions are used to investigate the behavior of degree d projective curves near a singular point. The geometrical constructions used here by the author are of great help in understanding the behavior of these curves.  A very well-written book for students and new-comers to the area of algebraic curves. It will pave the way for more advanced reading on the subject.g is straightforward here because the author has motivated them with a discussion of the properties of holomorphic and meromorphic functions earlier in the chapter. The proof of the Riemann-Roch theorem is very detailed and understandable. The book ends with a discussion of singular curves via resolution of singularities. Newton polygons and Puiseux expansions are used to investigate the behavior of degree d projective curves near a singular point. The geometrical constructions used here by the author are of great help in understanding the behavior of these curves.    A very well-written book for students and new-comers to the area of algebraic curves. It will pave the way for more advanced reading on the subject.	2001-03-14
2073654:US	50702879	R119HER5WR2BGU	0521552893	73591865	Financial Calculus: An Introduction to Derivative Pricing	Books	4	69	70	N	N	Nice, compact book on financial engineering	This book is an introduction to financial engineering from the standpoint of martingales, and assumes the reader knows only elementary calculus and probability theory. After giving a motivating example entitled &quot;the parable of the bookmaker&quot; the authors clarify in the introduction the difference between pricing derivatives by expected value versus using the concept of arbitrage. Vowing then never to use the strong law of large numbers to price derivatives, discrete processes are take up in the next chapter. The authors do an excellent job of discussing the binomial tree model using only elementary mathematics. Interestingly, they introduce the concept of a filtration in constructing the binomial tree model for pricing. Filtrations are usually introduced formally in other books as a measure theory concept. They then define a martingale using a filtration and a choice of measure. The use of martingales pretty much dominates the rest of the book. They emphasize that a martingale can be a martingale with respect to one measure but not to another. Continuous models are the subject of the next chapter, where the ubiquitous Brownian motion is introduced. The discussion is very lucid and easy to understand, and they explain why the conditions in the definition of Brownian motion make its use nontrivial; namely, one must pay attention to all the marginals conditioned on all the filtrations (or histories). The Ito calculus is then appropriately introduced along with stochastic differential equations. The authors do a good job of discussing the difference between stochastic calculus and Newtonian calculus. Recognizing that the Brownian motion they have defined is with respect to a given measure, they then ask the reader to consider the effect of changing the measure, thus motivating the idea of a Radon-Nikodym derivative. Their discussion is very intuitive and promotes a clear understanding rather than giving a mere formal measure-theoretic definition. Many interesting examples of changes are given. Portfolio construction and the Black-Scholes model follows. Basing their treatment of the Black-Scholes model of martingales gives an interesting and enlightening alternative to the usual ones based on partial differential equations (they do however later show how to obtain the usual equations). The next chapter discusses how to use the Black-Scholes equations to price market securities and how to assess the market price of risk. The discussion is very understandable but not enough exercises are given. Modeling interest rates is the subject of the next chapter. The mathematical treatiment is somewhat more involved than the rest of the the book. Several models of interest rate dynamics are discussed here very clearly, including the Ho/Lee, Vasicek, Cox-Ingersoll-Ross, Black-Karasinski, and Brace-Gatarek-Musiela models. A few of these models were unfamliar to me so I appreciated the author's detailed discussion. The book ends with a discussion of extensions to the Black-Scholes model. The emphasis is on multiple stock and foreign currency interest-rate models. A brief discussion  of the Harrison/Pliska theorem is given with references indicated for the proof. An excellent book and recommended for beginning students or mathematicians interested in entering the field. My sole objection is the paucity of exercises in the last few chapters.ng examples of changes are given. Portfolio construction and the Black-Scholes model follows. Basing their treatment of the Black-Scholes model of martingales gives an interesting and enlightening alternative to the usual ones based on partial differential equations (they do however later show how to obtain the usual equations). The next chapter discusses how to use the Black-Scholes equations to price market securities and how to assess the market price of risk. The discussion is very understandable but not enough exercises are given. Modeling interest rates is the subject of the next chapter. The mathematical treatiment is somewhat more involved than the rest of the the book. Several models of interest rate dynamics are discussed here very clearly, including the Ho/Lee, Vasicek, Cox-Ingersoll-Ross, Black-Karasinski, and Brace-Gatarek-Musiela models. A few of these models were unfamliar to me so I appreciated the author's detailed discussion. The book ends with a discussion of extensions to the Black-Scholes model. The emphasis is on multiple stock and foreign currency interest-rate models. A brief discussion  of the Harrison/Pliska theorem is given with references indicated for the proof. An excellent book and recommended for beginning students or mathematicians interested in entering the field. My sole objection is the paucity of exercises in the last few chapters.	2001-03-10
2084201:US	50702879	R21FORRNGHLQ6S	1565924533	257363874	Mastering Algorithms with C: Useful Techniques from Sorting to Encryption	Books	4	54	60	N	N	Helpful book on algorithms using C	C programming is still with us because of its high performance ability and this book outlines several algorithms using the language. It begins with a classification of algorithms as randomized, divide-and-conquer, dynamic programming, greedy and approximation. Some algorithms the author states defy classiification but he does not give examples. Pointers are discussed in the next chapter, and covers how to avoid dangling pointers, memory allocation, pointers to data structures, function parameters, double pointers, and generic and function pointers. The chapter is clearly written and diagrams are used frequently to illustrate the uses and properties of pointers. The author in particular gives an excellent explanation of how C can simulate call-by-reference parameter passing. This capability in C can be a source of trouble to the newcomer to C. The author does not however discuss triple pointers in this chapter, in spite of their great utility in computational geometry and computational radiology. Void pointers and casting are discussed in detail though, and the author does a good job. Only a cursory discussion of function pointers is given; I would have preferred many more examples to be given. Recursion and tail-recursion are discussed in Chapter 3, with the factorial function used to illustrate the differences. Computational complexity and the O-notation are covered in the next chapter, with the treatment pretty sparse but clear. Linked lists, extremely useful in all areas of engineering and science, are discussed effectively in Chapter 5. Eleven linked list macross, thirteen doubly linked list macros, and eight circular list macros are discussed and the complexity of each given. Virtual memory and paging are given as examples of applications of linked lists. The author moves on to stacks in the next chapter with several stack macros outlined. FIFO queues are discussed but in view of their importance in network modeling not enough examples are given. A very interesting overview of how to implement sets as a data type in C is given in Chapter 7. I was not aware that such a construction could be done effectively in C so this chapter was of particular interest to me. All of the usual set operations are implemented using a number of diffrent macros. A clever set covering algorithm is given at the end of the chapter. Hashing and chain hash tables as arrays of linked lists are outlined in the next chapter. Hash functions are used heavily in such areas as cryptography and the author does a fine job of outlining their implementation. After a good discussion of trees, heaps, priority queues, and graphs, the author begins in the third part of the book with the actual implementationof many useful algorithms. The chapter on numerical methods could be more in depth because of its immmense importance and because C has been one of the best performers for the the time intensive calculations in this area. Huffman encoding and other compression algorithms are also treated with some detail. Several macros for bit operations are given and the ones discussed are helpful for the next chapter on encryption algorithms. The DES and RSA algorithms are treated in this chapter, but unfortunately elliptic curve encryption algorithms are not. The book ends with a fairly good overview of graph algorithms and algorithms in computatational geometry. This is really a pretty good book and gives a good overview of some very important algorithms, and all within a little over 500 pages. The only major omission was the lack of exercises/problems at the end of each chapter.ting overview of how to implement sets as a data type in C is given in Chapter 7. I was not aware that such a construction could be done effectively in C so this chapter was of particular interest to me. All of the usual set operations are implemented using a number of diffrent macros. A clever set covering algorithm is given at the end of the chapter. Hashing and chain hash tables as arrays of linked lists are outlined in the next chapter. Hash functions are used heavily in such areas as cryptography and the author does a fine job of outlining their implementation. After a good discussion of trees, heaps, priority queues, and graphs, the author begins in the third part of the book with the actual implementationof many useful algorithms. The chapter on numerical methods could be more in depth because of its immmense importance and because C has been one of the best performers for the the time intensive calculations in this area. Huffman encoding and other compression algorithms are also treated with some detail. Several macros for bit operations are given and the ones discussed are helpful for the next chapter on encryption algorithms. The DES and RSA algorithms are treated in this chapter, but unfortunately elliptic curve encryption algorithms are not. The book ends with a fairly good overview of graph algorithms and algorithms in computatational geometry. This is really a pretty good book and gives a good overview of some very important algorithms, and all within a little over 500 pages. The only major omission was the lack of exercises/problems at the end of each chapter.	2001-03-02
2086287:US	50702879	R10UG988LJIJ88	0691025975	147568347	The Seiberg-Witten Equations and Applications to the Topology of Smooth Four-Manifolds (Mathematical Notes, Vol. 44)	Books	3	4	5	N	N	Fairly good book on the subject	This book is a pretty good introduction to the main results that caused a flurry of excitement in the mathematical community in the mid 1990's. The mathematical constructions involved here are interesting mostly to those in the area of the differential topology of 4-manifolds. The Seiberg-Witten invariants as they are now called, have been widely discussed since then, but mostly now in the context of symplectic geometry. After a brief overview of spin geometry and Clifford algebras, the author discusses the complex spin representation. This sets up the discussion of spin bundles in the next chapter, and, even though it is really not the place for it, the author does not prove that a principal SO(V) bundle lifts to a principal Spin(V) if and only if the second Stiefel-Whitney class is equal to zero. There are many different proofs of this in the literature, but I have not discovered in any of these proofs any real, sound insight as to why this result is true. The chapter continues its very formal treatment with an overview of spin bundles and the Dirac operator. The next chapter then moves immediately to the Seiberg-Witten equations and they are viewed as nonlinear generalizations of elliptic partial differential equations in the sense that the linearization of both the Seiberg-Witten equations and the gauge group action is shown to be an ellipic complex. The next chapter shows that the moduli space of solutions to the Seiberg-Witten equations is compact. This is the most technical of the chapters and requires attentive reading. The Seiberg-Witten invariant for complex spin structures is discussed in the next chapter. Again one must pay close attention to the details of the arguments. The actual calculation of a Seiberg-Witten invariant is performed in the context of Kahler manifolds in the last chapter of the book. This sets up the reader nicely for the current work on symplectic manifolds. The book will be of interest to mathematicians wanting an understanding of this area of four-dimensional topology and to high-energy physicists who are interested in the low energy behavior and duality in SU(2) supersymmetric gauge theories. The constructions of Seiberg and Witten in quantum field theory are what led to the invariants outlined in this book. All in all a fascinating area of mathematics and its consequences are sill being worked out with diligence.his area of four-dimensional topology and to high-energy physicists who are interested in the low energy behavior and duality in SU(2) supersymmetric gauge theories. The constructions of Seiberg and Witten in quantum field theory are what led to the invariants outlined in this book. All in all a fascinating area of mathematics and its consequences are sill being worked out with diligence.	2001-02-28
2091603:US	50702879	R3U716X2SLA8MS	0387983775	805994762	Banach Algebra Techniques in Operator Theory (Graduate Texts in Mathematics)	Books	5	9	11	N	N	Disappointing	If this book is disappointing why did I rate it 5 stars? Well, it is because having studied the first edition I was expecting more updates in the second. It really is an excellent book, but I wanted the author to discuss the Brown-Douglas-Fillmore K-theory of operator algebras and give an in-depth discussion of the invariant subspace conjecture. I used this book for a two semester course in functional analysis and operator theory while a sophomore in undergraduate and found it very challenging. The presentation of the topics is very quick and the problems are pretty difficult, but you take away an appreciation of this important area of mathematics. Indeed, the theory of Hp-spaces and Toeplitz operators, which are covered in the last two chapters, have many applications in engineering and physics. The author does give an update on the problems he marked with two stars (indicating an unsolved problem) in the first edition, and references that discuss their solution. When studying the book, I am always amazed about how rich linear transformations become when they operate on infinite-dimensional Hilbert spaces; but also how much the finite-dimensional results have generalizations in infinite dimensions. The theory of C* and W*-algebras is discussed in the book, and the presentation should be helpful to physicists who use these techniques, even though the presentation is much more general than one would find in physical theories. The explanation of the W*-algebra as arising from the enlargement of the functional calculus to an algebra of functions generated by characteristic functions; where the Gelfand transform is taken on a larger commutative self-adjoint subalgebra of the space of linear operators is one that is easier to remember and seems more natural than merely giving a set of axioms that a W*-algebra is supposed to satisfy. A very abstract discussion of index theory is given, and one that is pretty distant from the theory of integral equations, but with some work one can see the connection to these equations. Who knows, maybe a third edition with more of the author's insights?k one can see the connection to these equations. Who knows, maybe a third edition with more of the author's insights?	2001-02-23
2092199:US	50702879	R3G1JUYONFZH98	1884777694	884156780	Implementing Elliptic Curve Cryptography	Books	4	7	12	N	N	Full of good, helpful information	This book is the first I have read on elliptic curves that actually attempts to explain just how they are used in cryptography from a practical standpoint. It does not attempt to prove the many interesting properties of elliptic curves but instead concentrates on the computer code that one might use to put in place an elliptic curve cryptosystem. The code the author admits could be done in many other ways, but the one he chose I think does its job in instructing the reader just how to implement elliptic curves in cryptography. Indeed, his implementation of large integer math routines is very clear and points out the difference in using a (high level) language like C versus doing the same in Assembly. The only minus to the book from a didactic standpoint are the subroutine schematics that permeate the book. These could have been omitted without any serious damage to understanding what is going on.  Readers who need a more rigorous introduction to the mathematics can go to the (immense) literature on elliptic curves. A fine book, and definitely worth reading to gain a practial understanding of elliptic curve cryptosystems.	2001-02-23
2093642:US	50702879	R1YB9VPD7H12G5	0262720205	596261525	Handbook of Theoretical Computer Science - 2 Vol Set	Books	5	9	9	N	N	Massive collection on computer science	This collection of articles on the foundations of computer science is a nice addition addition to the literature and guides the reader to further reading on the subject. I did not read all of the chapters so I will concentrate my remarks on the ones that I did:  Chapter 4 on Kolmogorov complexity puts emphasis on the applications and the authors endeavor to bring the reader quickly to the level of understanding needed for applications. The ones discussed are primarily in the area of parallel computation and branching programs. The chapter on algorithms for finding patterns in strings is nicely written and the authors do a good job of summarizing the main results. Computational biologists dealing with string matching algorithms may find the presentation very helpful. The author uses pseudocode to illustrate the main algorithms, such as Knuth-Morriss-Platt, Boyer-Moore, Aho-Corasick, and Commentx-Walter. Concrete examples are given for each of these algorithms. The chapter on computational geometry discusses the main algorithms for finding convex hulls and Voronoi diagrams are discussed in fairly good detail. Linear programming, triangulation, and point locating are given a fast treatment. The author does make use of pictures to illustrate the the algorithms. The only disappointment was that combinatorial geometry was given only a very cursory treatment. Of particular importance to me was the chapter on algorithms in number theory. Interestingly, the authors jump right into a discussion of elliptic curves and actually do a fairly good job (within 4 pages) of summarizing this massive area of mathematics. The authors return to elliptic curves in a later section on factoring integers, after discussing algorithms for finite abelian groups. The Shanks baby-step-giant-step, Pollard's rho method, the Chinese Remainder theorem, and the index calculus algorithm are discussed concisely. Elliptic curves are again used in the section on primality testing. There is a good summary of cryptography in Chapter 13, with the most interesting discussions on probabilistic encryption, &quot;over-the-phone&quot; poker, and zero-knowledge interactive proofs. In Volume B, those interested in the foundations of logic and functional programming, Chapter 6 on rewrite systems covers the main points. The chapter is fairly long an detailed. Functional programming and lambda calculus are contained in the next chapter with proofs given of the main results. The most interesting section is on denotational semantics. LISP is discussed a little at the end of the chapter. Chapter 10 also discusses logic programming in a fairly detailed manner. The most interesting sections are the ones on the completion of programs and deductive databases. The author ends the chapter with a brief history of logic programming. In reading this I found out that there has been work done on developing a theory of logic programming based on 3-valued logic and useful references were given. The theory of relational databases in covered in Chapter 17. This is of overwhelming importance today and the author does a decent job of outlining what relational databases are all about. The section on query optimization is particularly illuminating. Although the text is very formal and very far away from the everday practice of database management, reading it does give a deeper appreciation of the foundations of the subject.  Overall, a very fine addition to the literature...I hope the publishers decide to move ahead with an updated edition.of cryptography in Chapter 13, with the most interesting discussions on probabilistic encryption, &quot;over-the-phone&quot; poker, and zero-knowledge interactive proofs. In Volume B, those interested in the foundations of logic and functional programming, Chapter 6 on rewrite systems covers the main points. The chapter is fairly long an detailed. Functional programming and lambda calculus are contained in the next chapter with proofs given of the main results. The most interesting section is on denotational semantics. LISP is discussed a little at the end of the chapter. Chapter 10 also discusses logic programming in a fairly detailed manner. The most interesting sections are the ones on the completion of programs and deductive databases. The author ends the chapter with a brief history of logic programming. In reading this I found out that there has been work done on developing a theory of logic programming based on 3-valued logic and useful references were given. The theory of relational databases in covered in Chapter 17. This is of overwhelming importance today and the author does a decent job of outlining what relational databases are all about. The section on query optimization is particularly illuminating. Although the text is very formal and very far away from the everday practice of database management, reading it does give a deeper appreciation of the foundations of the subject.  Overall, a very fine addition to the literature...I hope the publishers decide to move ahead with an updated edition.	2001-02-22
2098164:US	50702879	R3F7HLYVD1BASM	038757204X	677359261	Mathematical Biology (Biomathematics, Vol 19)	Books	5	27	28	N	N	Excellent book on the subject	A few decades ago mathematical biology consisted mostly of evolutionary and predator-prey models. This has changed dramatically in recent years with the advent of computational biology and gene sequencing projects. The applications of mathematics to biology are now exploding and this book is an excellent example of that. The book could best be described as the application of nonlinear dynamical systems and reaction-diffusion partial differential equations to biology structures and processes. Readers with background in these areas of mathematics will find their ideas applied beautifully in this book. The best sections of the book for me were the discussions of synchronized insect emergence, models of testosterone secretion control, insect dispersal models, calcium waves on amphibian eggs, mammalian coat patterns, models of hallucination patterns in the brain, and modeling the transmission dynamics of HIV. Numerous exercises end each chapter, and the mathematical algorithms can easily be coded in Mathematica or some other high level language. This is a fine addition to the literature on mathematical biology and for the price it is a real bargain.	2001-02-19
2100750:US	50702879	R1J6MEN9GZ1SHA	1850154325	31746018	Dance Quotations	Books	5	4	4	N	N	A collection of dancer's scriptures, to be read and danced..	Lots of nice reading here...a celebration of dance by those and for those who love to dance. Some of my favorites from the book: &quot; If we think, feel, and move, we can dance. &quot; - Margaret N. H'Doubler &quot;It is what I've always wanted to do - to show the laughing, the fun, the appetite, all through dance.&quot; -Martha Graham &quot; I don't want people who want to dance, I want people who have to dance.&quot; -George Balanchine	2001-02-16
2101075:US	50702879	RAE7XKRWDEDXS	9810230435	552808595	Computational Methods In Physics And Engineering (2Nd Edition)	Books	3	6	6	N	N	Fairly good book on computational physics	This book is a fairly decent overview of computational physics. The author covers most of the topics that one would obtain in taking a senior level or first year graduate course in this subject. It could be used successfully in such a course as there are problem sets at the end of each chapter that can be solved most efficiently by writing programs. In addition, the author gives pseudocode throughout the book for the main algorithms. The most useful chapter to me was Chapter 7, which covered Monte Carlo techniques. The author is pretty thorough in his treatment of this subject, and does discuss how to apply this technique in calculating path integrals in quantum mechanics. Unfortunately, he limits his discussion to the harmonic oscillator and does not give any problem sets at the end of the chapter that will allow the reader to apply the techniques to other potentials in quantum mechanics (such as maybe the anharmonic oscillator or the double well potentials). The author also discusses finite difference methods and finite element methods in the last two chapters. The author unfortunately does not discuss the numerical solution of the Boltzmann transport equation, which is of interest to me.  Overall though a pretty nice job, and will introduce the new comer to the field.	2001-02-16
2110482:US	50702879	R1AQ152903PCZ9	0471319740	397397612	Self-Similar Network Traffic and Performance Evaluation	Books	4	15	15	N	N	Good compilation of recent results in the field	This book is a compilation of articles written for the performance analyst and network modeler who is needing an overview of the recent results in this area. The book does include articles on both the theoretical and experimental results in self-similar network traffic and this makes it useful from a model validation viewpoint. Each article also has numerous up-to-date references for the reader who needs more in-depth information.  The first article gives a general overview of the subject along with relevant definitions for those who may be approaching it for the first time. Theorems are stated but not proved but references are given for the proofs. Wavelets are discussed in Chapter 2; the most useful part of this chapter is the discussion on how to generate fractional Brownian motion time series using wavelet expansions. Chapter 3 gives a very quick overview of network simulations with heavy-tailed distributions. This chapter is a little disappointing in that the authors do not discuss how to deal with heavy-tailed distributions (with their large moments) computationally. This is important for developing network simulations and models using these distributions.A discussion of approximations of heavy-tailed distributions by other more manageable distributions would have been helpful here.  The next chapter talks about fractional Brownian motion and could be viewed as a first glance at the theory of large deviations. The author does a good job of showing that analytical results are available in these kinds of processes. More general results in Gaussian input processes are discussed in Chapter 5, with asymptotics of queue length distributions characterized in some detail. The M/G/1 model is discussed in Chapter 6, where it is assumed that the service time is heavy-tailed. The most interesting part of this chapter is the discussion of the limit theorems. Chapter 7 gives a good overview of performance degradation under heavy-tail sources; the authors show, interestingly, that the expected time for overflow is polynomially fast. The authors in Chapter 8, give asymptotic bounds for the buffer overflow probability given a self-similar source They do take the time to prove many of their results. M/G/Infinity input processes are discussed in Chapter 9 and the authors do a good job of using large deviations to give asymptotic bounds on these kinds of queuing models. In Chapter 10, the author discusses subexponential distributions. These results were very new to me but the author did I think do a good job of explaining them. Queuing with on/off sources is discussed in Chapter 11, and the author derives many of the results using the Mellin transform. Most importantly he does compare his results with simulation experiments. I did not read the next chapter on VBR so I will omit its review. Just perusing though it seems as though the author holds that long-range dependence is irrelevant for VBR. Chapter 13 discusses transient losses and the impact on performance. The authors do a great job of comparing the difference in performance between Markov and long-range dependent processes. Actually the most interesting part of this chapter is the use of integral equations to prove some of the results. The results in Chapter 14 are more practical, where the authors use network simulations to study the problem of file size distributions drawn from heavy-tailed distributions in client-server models. The most useful part of this chapter is the comparison between the UDP and TCP as a moderator of the degradation experienced when self-similarity is increased. The best chapter for me was Chapter 15, which discusses TCP connection arrivals and their self-similar nature. The author does show how to model empirical distributions, particularly the Weibull distribution. I did not read the rest of the chapters so I will omit their review.  This book is recommended for those involved in network modeling and performance. It is somewhat expensive, but worth it bothas an introduction and as a reference source.both as an introduction and as a reference source.	2001-02-08
2314997:US	50702879	RRUZJOR833ZPU	0387900403	68725003	A Course in Arithmetic (Graduate Texts in Mathematics, Vol. 7)	Books	5	16	18	N	N	A sheer delight	This short book on number theory by one of the giants of 20th century  mathematics is delightful to read. Its length motivates one to finish the  book, and it is packed full of interesting results. Most of the theory  discussed in the book has wide-ranging applications, such as cryptography  and dynamical systems. The last chapter of the book is the best and covers  the subject of modular forms, including theta functions, Hecke operators,  and general modular functions. If you want to understand the Wiles proof of  Fermat's last theorem, start with this book.	2000-08-20
2315146:US	50702879	R3CF60T4WB3LTE	0691037698	793748846	Quantization of Gauge Systems	Books	5	16	16	N	N	Excellent overview of quantum gauge theory	Anyone interested in how to quantize gauge theories and BRST cohomology  will want to read this book. The authors do a fine job of motivating the  problem and discussing in depth where the essential problems arise. The  book starts naturally with a discussion of constrained Hamiltonian systems,  and this chapter is especially well written as it sets up the geometry for  later discussions on quantization. Most of the discussion in the next few  chapters is on geometrical constructions in classical gauge field theory.  The authors do a fine job of explaining how Grassman  algebra constructions  come into play in classical field theory. To a beginner in the subject the  appearance of &quot;spin&quot; degrees of freedom in classical field theory  may be strange at first, but the chapter on Fermi degrees of freedom  alleviates any skepticism on why one should proceed this way. BRST  constructions occupy the next few chapters, and here one sees the role of  ghosts as being a sort of &quot;Lagrange multiplier&quot; in the  quantization of constrained systems. The authors discuss path integral  quantization in the last chapters of the book, and do so in a way that is  mostly formal, given that path integrals are not well defined from a  mathematical standpoint. By far the best part of this discussion is on the  Koszul-Tate complex and how it is related to the Schwinger-Dyson equations.  It would take a lot of searching in the journal literature to obtain the  knowledge gained from the reading of this book. Definitely a fine addition  to the literature on this very difficult topic.	2000-08-20
2315396:US	50702879	R19INV39FRVU33	0387965084	657204697	Elliptic Functions (Graduate Texts in Mathematics, Vol. 112)	Books	4	8	9	N	N	Nice job on the theory of elliptic curves	This book gives an overview of the theory of elliptic curves rom a more  number-theoretic viewpoint. As such, it is good reading for anyone  interesting in applications of elliptic curves to physics, such as  integrable models in statistical mechanics and superstring theory.  Readers  interested in learning the theory in order to apply it to cryptography may  be disappointed as the theory of elliptic curves in characteristic p is put  in two appendices. The author is well known for his expertise in algebra  and number theory and this is brought out nicely in part two of the book,  which deals with complex multipication. The most useful part of the book  for those interested in physics applications is part four, dealing with the  theory of theta functions, even though they are not discussed in the  context of being solutions of the heat equation. String theorists will  however have to supplement the reading with other sources in order to gain  more familiarity with theta functions. There are no exercises in the book,  since it qualifies as being more of a monograph, but there are numerous  places where one has to fill in the details of the arguments in the proofs.	2000-08-20
2315504:US	50702879	R2NOQEJQTHX3HJ	0387962034	529986892	The Arithmetic of Elliptic Curves (Graduate Texts in Mathematics) (v. 106)	Books	5	20	24	N	Y	Who could ask for more?	The theory of elliptic curves has to rank as one of the most fascinating  fields in all of mathematics. Being around for almost two centuries,  elliptic curves are finding myriads of applications, including  cryptography, superstring theory, and computer imaging. The author does a  brilliant job of organizing and explaining the theory in this book.  Although the book requires a thorough understanding of algebraic geometry  and modern algebra, the book is packed full of insights without sacrificing  mathematical rigor. This is rare in most textbooks on modern mathematics.  Numerous exercises exist at the end of each chapter, which allow readers to  test their understanding of the subject as well as giving extensions to the  main results in the text. The author reserves the cases of elliptic curves  in characteristics 2 and 3 to the appendix. This may be disappointing for  those reading the book for cryptographic applications of elliptic curves,  but it does prepare one for further reading on the subject. By far the best  chapter in the book is Chapter 10 on computing the Mordell-Weil group as  the author does a nice job of detailing the relevant constructions.  This  book is well worth the time and effort required to study, and could serve  well in an actual class on the subject. The author does have a follow-up  book called \\"Advanced Topics in the Theory of Elliptic Curves\\"  for those who need further stimulation in this intriguing and important  field of mathematics.<br /><br />Addendum to review, Dec 12, 2009:<br />The second edition of this book respects the same quality as the first.The new chapter on the algorithmic aspects of elliptic curves reflects the importance of elliptic curve cryptography since the appearance of the first edition and can be viewed as a warm-up for the study of cryptography over general Abelian varieties and for a study of group schemes. The author mentions group schemes when he discusses Lenstra's algorithm for elliptic curve factorization: the need for elliptic curves over rings Z/NZ when N is composite, and in the case of the elliptic curve discrete logarithm problem where there is a need for an \\"elliptic scheme\\", i.e. an elliptic curve over Z/p^2Z, where p is prime and greater than or equal to 3.  The reader will get a taste of one of the algorithms for computing the Weil pairing and its generalization the Tate-Lichtenbaum pairing. By some specialists in cryptography, the latter is considered to be a pairing that makes up for the deficiencies in the Weil pairing, namely that the Weil pairing is skew-symmetric. The author proves the nondegeneracy of the Tate-Litchtenbaum pairing in this chapter. Both the Weyl and Tate-Litchtenbaum pairings can be viewed in the more abstract, general framework of arithmetic duality theory and arithmetic geometry if one is willing to learn the appropriate techniques from Galois cohomology. In this framework the Tate-Litchtenbaum pairing for a (principally polarized) Abelian variety relates its Mordell-Weil group, its first cohomology group, and its Brauer group. For the author the value of the Tate-Litchtenbaum pairing over the Weil pairing is that the Miller algorithm for the Tate-Litchtenbaum pairing is twice as efficient as the Weil pairing. Included also in this chapter is a brief discussion of elliptic divisibility sequences (but delegated to the exercises), and references are given for their generalization in what are now called \\"elliptic nets\\", the latter of which is a recent development, and so it remains to be seen how much impact it will have on the computation of pairings.d for elliptic curves over rings Z/NZ when N is composite, and in the case of the elliptic curve discrete logarithm problem where there is a need for an \\"elliptic scheme\\", i.e. an elliptic curve over Z/p^2Z, where p is prime and greater than or equal to 3.  The reader will get a taste of one of the algorithms for computing the Weil pairing and its generalization the Tate-Lichtenbaum pairing. By some specialists in cryptography, the latter is considered to be a pairing that makes up for the deficiencies in the Weil pairing, namely that the Weil pairing is skew-symmetric. The author proves the nondegeneracy of the Tate-Litchtenbaum pairing in this chapter. Both the Weyl and Tate-Litchtenbaum pairings can be viewed in the more abstract, general framework of arithmetic duality theory and arithmetic geometry if one is willing to learn the appropriate techniques from Galois cohomology. In this framework the Tate-Litchtenbaum pairing for a (principally polarized) Abelian variety relates its Mordell-Weil group, its first cohomology group, and its Brauer group. For the author the value of the Tate-Litchtenbaum pairing over the Weil pairing is that the Miller algorithm for the Tate-Litchtenbaum pairing is twice as efficient as the Weil pairing. Included also in this chapter is a brief discussion of elliptic divisibility sequences (but delegated to the exercises), and references are given for their generalization in what are now called \\"elliptic nets\\", the latter of which is a recent development, and so it remains to be seen how much impact it will have on the computation of pairings.	2000-08-20
2315550:US	50702879	R2YP7Y82K6Z7JQ	0387905081	595181606	002: Measure and Category: A Survey of the Analogies between Topological and Measure Spaces (Graduate Texts in Mathematics)	Books	4	11	11	N	N	Interesting monograph on measure theory	This short book is an interesting account of measure theory and how it  relates to topology. The topics are the standard ones that one would find  in a book on the subject, and the book is a real pleasure to read. Its  length motivates one to finish the book and the book is very applicable to  the theory of dynamical systems and the theory of large deviations. It  could be used as a textbook on measure theory or foundations of analysis if  one supplemented it with problem sets and some outside reading. A good  book.	2000-08-20
2315653:US	50702879	RN65NM5Y3EMNI	007057717X	671760622	Hurst's the Heart, Arteries and Veins (Single Volume)	Books	5	6	6	N	N	A true gem of a book	This book is an exhaustive compilation of articles written by leading cardiologists and medical researchers who study the diseases and  functioning of the heart. The sheer size of the book (over 2600 pages) make  it a challenge to read entirely, but the articles that can be read are  worthwhile spending time on. The only minus to the book is that there are  no articles on the mathematical or computational modeling of the heart. But  for studies in anatomy and physiology of the heart, and treatment of heart  disease, this book is excellent. One would expect a higher price for the  book considering its size and the color plates it has enclosed, so even at  $150.00 it is still really a bargain.	2000-08-20
2315803:US	50702879	RQPQ3MPPIZE2P	0387948236	687045319	A Course in Homological Algebra (Graduate Texts in Mathematics)	Books	4	7	9	N	N	Good overview of the subject	This book, written by two of the leading experts in the area, is a sound  exposition of a very abstract/abtruse subject. The logic is impeccable and  the organization nicely done. Algebraic topology is given a rigorous  foundation in this book and readers with a background in that subject will  appreciate the discussion more. By far the best chapter in the book is the  one on exact couples and spectral sequences as it gives proofs that would  take a lot of time to find in the original literature. At the time of publication, spectral sequences were viewed as a relatively new tool in homological algebra and readers who are introduced to them might at first find them somewhat esoteric and difficult to master. The authors make their understanding much more palatable as soon as one gets used to the overabundance of diagram chasing.<br /><br />Another chapter that is of great help and receives excellent motivation from the authors is the one on derived functors. Introduced by the authors as the \\"heart of homological algebra\\", it is viewed as a generalization of the extension of modules and the Tor (or \\"flatness detecting\\") functor, which are discussed in detail in chapter 3 of the book. The view of homological algebra in terms of derived functors is extremely important and must be mastered if for example readers are to understand how algebraic topology can be applied to the etale cohomology of algebraic varieties and schemes.	2000-08-20
2316354:US	50702879	R6LFKMZLLY3ZY	0821820141	454892085	Quantum Fields and Strings: A Course for Mathematicians (2 Volume Set) (v. 1 & 2)	Books	4	33	34	N	N	Definitely for mathematicians only	This book is an excellent compliation of articles written for  mathematicians who want to understand quantum field theory. It is not  surprising then that the articles are very formal and there is no attempt  to give any physical intuition to the subject of quantum field theory. This  does not mean however that aspiring physicists who want to specialize in  quantum field theory should ont take a look at the contents. The two  volumes are worth reading, even if every article cannot be read because of  time constraints. All of the articles are written by the some of the major  players in the mathematics of quantum field theory.  Volume 1 starts off  with a glossary of the terms used by physicists in quantum field theory and  is nicely written. The next few hundred pages are devoted to supersymmetry  and supermanifolds. A very abstract approach is given to these areas, with  the emphasis not on computation but on the structure of supermanifolds as  they would be studied mathematically. There is an article on classical  field theory put in these pages, which is written by Pierre Deligne and  Daniel Freed, and discussed in the framework of fiber bundles. The  discussion of topological terms in the classical Lagrangian is especially  well written. There is an introduction to smooth Deligne cohomology in this  article, and this is nice because of the difficulty in finding  understandable literature on this subject.  Part Two of Volume 1 is  devoted to the formal mathematical aspects of quantum field theory. After a  short introduction to canonical quantization, the Wightman approach is  discussed in an article by David Kazhdan. Most refreshing is that statement  of Kazhdan that the Wightman approach does not work for gauge field  theories. This article is packed with interesting insights, especially the  section on scattering theory, wherein Kazdan explains how the constructions  in scattering theory have no finite dimensional analogs. The article by  Witten on the Dirac operator in finite dimensions is fascinating and a good  introduction to how powerful concepts from quantum field theory can be used  to prove important results in mathematics. A fairly large collection of  problems (with solutions) ends Volume 1.  The first part of Volume 2 is  devoted entirely to the mathematics of string theory and conformal field  theory. The article by D'Hoker stands out as one that is especially  readable and informative. D. Gaitsgory has a well written article on vertex  algebras and defines in a very rigorous manner the constructions that occur  in the subject.  The last part of Volume 2 discusses the dynamics of  quantum field theory and uses as much mathematical rigor as possible. One  gets the impression that it this is the area where it is most difficult to  proceed in an entirely rigorous way. Path integrals, not yet defined  mathematically and used throughout the discussion. The best article in  Volume 2, indeed of the entire two volumes is the one on N = 2 Yang-Mills  theory in four dimensions. It is here that the most fascinating  constructions in all of mathematics find their place.  These two volumes  are definitely worth having on one's shelf, and the price is very  reasonable considering the expertise of the authors and considering what  one will take away after reading them.ac operator in finite dimensions is fascinating and a good  introduction to how powerful concepts from quantum field theory can be used  to prove important results in mathematics. A fairly large collection of  problems (with solutions) ends Volume 1.    The first part of Volume 2 is  devoted entirely to the mathematics of string theory and conformal field  theory. The article by D'Hoker stands out as one that is especially  readable and informative. D. Gaitsgory has a well written article on vertex  algebras and defines in a very rigorous manner the constructions that occur  in the subject.     The last part of Volume 2 discusses the dynamics of  quantum field theory and uses as much mathematical rigor as possible. One  gets the impression that it this is the area where it is most difficult to  proceed in an entirely rigorous way. Path integrals, not yet defined  mathematically and used throughout the discussion. The best article in  Volume 2, indeed of the entire two volumes is the one on N = 2 Yang-Mills  theory in four dimensions. It is here that the most fascinating  constructions in all of mathematics find their place.    These two volumes  are definitely worth having on one's shelf, and the price is very  reasonable considering the expertise of the authors and considering what  one will take away after reading them.	2000-08-19
2321064:US	50702879	R2NZSFWO1U2J8Y	0521599229	166324625	Computational Learning Theory (Cambridge Tracts in Theoretical Computer Science)	Books	4	2	2	N	N	Very short but good introduction to the field	This book gives a good introduction to the mathematical modeling of cognition and does so with a level of mathematics that is very accessible  to a typical graduate student in computer science or psychology. The book  could have been written using tools from measure theory but luckily it was  not for a book at an introductory level. The concept of probably  approximately correct is introduced early on in the third chapter of the  book with efficient learning given later on in Chapter 5. Chapter 7, the  best chapter of the book, discusses the idea of VC dimension, which has had  many applications, such as network stability and optimization. VC dimension  plays the pre-dominant theme in the rest of the book, with the book ending  with an application to neural networks.  There are short problem sets at  the end of the chapters, and these are useful for more understanding of the  concepts in the book.  A very interesting book and worth the price.	2000-08-16
2324840:US	50702879	R1NUBG0XZAS5AD	0871272016	686519285	Doris Humphrey: An Artist First	Books	4	6	6	N	N	Good book on the life of Doris Humphrey	Those interested in and learning the infamous Humphrey-Weidman technique  in modern dance get a good overview of the life of Doris Humphrey. The book  also has many photos of this incredibly beautiful woman, who not only  originated one of the most original techniques of modern dance in the 20th  century, but also was a dance theoreticain/philosopher. The only  disappointing aspect of the book was that one interested in the influence  of the philosopher Friedrich Neitzsche on her dance technique will find  only a brief discussion. But the book is fascinating reading, and after  reading it one feels even more admiration for this remarkable woman and  dancer.	2000-08-13
2324948:US	50702879	R6GK61TJ7TXRK	0822956667	638398249	Prodigal Son	Books	4	4	4	N	N	Captivating reading	This autobiography gives a very interesting account of the authors life in  dance under the direction of George Balanchine. The reading is very fast,  as it keeps your attention, and there are photos inserted in the book that  give more insight on the authors life and family. One gains an appreciation  of the difficulties and joys of being a professional dancer while reading  the book, and also insight on what it was like to work under Balanchine. A  fine book for everyone interested in the personal lives of those who dance  professionally.	2000-08-13
2324978:US	50702879	RDIBYWTLTDJ1A	0871271931	706849260	Modern Dance Fundamentals	Books	5	3	3	N	N	Great technical overview of modern dance	This book details the exercises and styling of modern dance using Laban  notation. Laban notation is introduced in part 1 and is used throughout the  book to detail the positioning and placement of the body in various  exercises and movements. Stick figures are used to supplement  the notation  in the beginning chapters of the book, but are later omitted as the reader  gains more experience in Laban notation. For those learning Laban notation,  and for those interested in the more technical/mathematical aspects of  modern dance, this book makes for sound reading. So much can be obtained  from reading this book, and for so little cost in purchasing.	2000-08-13
2325066:US	50702879	R391909AWDQK8	0813016177	183398360	The Classic Ballet: Basic Technique and Terminology	Books	5	17	17	N	N	Fantastic book!!!	I have the hard bound edition of this book, published some time ago by  Alfred Knopf, and I never tire of looking at the drawings and appreciating  the mathematical precision of classical ballet. The reading of this book  will be of an enormous assistance to studying ballet, and it is also  invaluable if one wants to study the more technical facets of the subject.  Ballet is one form of dance that can be mathematically systemaitized and  characterized, and this book is a great reference for such an undertaking.  Definitely worth having and the paperback edition with its low price makes  it completely accessible to all.	2000-08-13
2325486:US	50702879	R26UK609O1024Q	0674571762	53158553	Methods of Logic	Books	4	14	15	N	N	Good textbook on logic	This book is a nice overview of the foundations of modern logic with some  additional non-traditional topics, such as modal logic included. Quine is  necessary reading for all those interested in mathematical logic,  philosophical logic, and theoretical foundations of computer science. By  far the best chapter of the book is Chapter 33 which deals with the  Skolem-Lowenheim theorem. Even though it is very short, Quine does a good  job of explaining what this result is all about, and does so with upmost  clarity. Another nice feature of the book is the inclusion of historical  notes at the end of each chapter. This gives the reader a general view of  just where the results came from, and encourages further reading on the  subject. Anyone interested in functional and logical programming will gain  a lot in the reading of this book, as it introduces the proper tools and  methodologies used in these important programming paradigms.	2000-08-13
2325555:US	50702879	R2DHZGF39LMFZN	0671657151	12401298	The Closing of the American Mind	Books	4	3	16	N	N	Good book for the time, but now outdated	Thankfully the attitudes and philosophies that Bloom outlined in this book are no longer of predominant concern in the beginning of the 21st century,  full as it is with optimism and exuberance. The philosophical relativism  and aversion for analytical thinking of the 20th century has give way to  the enlightened pragmatism of the 21st. This book should be viewed now as  more of a history book. It gives great insight into what it was like to  work and teach in the universities in the later half of the 20th century.  But now the marketplace, with its entrepunerial spirit and its need for  highly technical innovation, have replaced the university as an educational  arena; as one where individuals must not only be receptive or  &quot;open&quot; to new ideas, but where such ideas take a concrete form in  new products and technologies. The methodologies and discipline needed to  make ideas work in today's marketplace are a complete antithesis to the  moods and despair that Bloom outlines in his book.	2000-08-13
2325618:US	50702879	R3LEN8SOH62HYF	0028713265	153356240	Physics, Dance, and the Pas De Deux	Books	4	14	14	N	N	Good follow-up to &quot;The Physics of Dance&quot;	The author does a fine job of adding to his earlier book &quot;The Physics  of Dance&quot; in this book. It is very uncommon to find a physicist  interested in dance, but the author definitely will keep the attention of a  professional physicist. The book is more qualitative in nature than the  first one, but physicists interested in kinesiology will gain something by  reading this book. As in all of physics, one can disagree on the analysis  of the movements, but the book does give a good overview of the  difficutlies that arise when dancers attempt to perform the pas da deux.  Dancers also could gain something by reading this book, as it will make  them more aware of how exactly they should place their bodies to make  movements in the pas da deux more effective.  A fine addition to the  technical literature on dance, and hopefully the author will find the time  to write a third one on the more quantitative/mathematical issues that  arise in analyzing the physics of dance.	2000-08-13
2326713:US	50702879	R1FDRN2U083LNZ	0412993910	817870014	Introduction to Computational Biology: Maps, Sequences and Genomes (Chapman & Hall/CRC Interdisciplinary Statistics)	Books	4	57	58	N	N	Packed full of good information	This book gives a good survey of the different techniques employed by computational biologists. After a brief review of molecular biology in  Chapter 1, the author treats the mathematical modeling of restriction maps  in Chapter 2 using graph theory. His presentation is somewhat hurried, but  he does give references and gives the reader three exercises at the end of  the chapter. Multiple maps are treated in Chapter 3, wherein the author  first makes use of probability theory, via the Kingman subadditive ergodic  theorem. The proof is omitted but the author does a good job of explaining  its use in studying the double digest problem (DDP). The best part of this  chapter is the author's explanation of the difficulties of using Kingman's  results for solving the DDP, and goes on to discuss multiple solutions of  the DDP. Graph theory is again used in the discussion. This sets up the  discussion in Chapter 4, which outlines algorithms for the DDP. The author  gives a very compact introduction to P- and NP-complete problems in the  theory of computation, then proves that DDP is NP-complete. The author does  a good job of discussing subsequent approximate methods used for the DDP,  such as simulated annealing. Markov chains are introduced in the book here  for the first time, but due to the shortness of the presentation, the  reader should do outside reading as a back-up. The author does a great job  of explaining the difficulties if measurement error is introduced in the  DDP at the end of the chapter. Cloning is discussed in Chapter 5, with  tools from probability theory used to deal with partial digest libraries.  The chapter is really short though, and the working the problems at the end  of the chapter is essential for the understanding the results of this  chapter. The author switches gears in the next chapter, wherein physical  maps are discussed. The discussion is fairly detailed and interesting.  Sequencing is discussed in the next two chapters, and the treatment is very  good. Hashing is introduced here, and psedocode is given throughout. The  very important method of dynamic programming is outlined in Chapter 9,  which is beautifully written, and again pseudocode abounds throughout.  Genetic mapping is left out though, but the this, the longest chapter of  the book, is a detailed introduction to this area. The results in this  chapter are used to study multiple sequence alignment in Chapter 10,  wherein hidden Markov models are introduced for the first time. The  discussion of these models is very curt, but there are other books and  notes available if the reader needs further guidance. The best chapter of  the book follows, which discusses probability and statistics for sequence  alignment. The theory of large deviations is brought in, and the author  does an excellent job of discussing this important, and powerful theory.  The reader's level of mathematical sophistication is assumed to be a lot  greater than the rest of the book in this chapter. Knowledge of measure  theory and martingales are assumed here. The author uses the very powerful  tool of relative entropy, so indispensable in other applications of  probability. The problem set at the end of the chapter is challenging but  working them through is definitely worth the time involved. The next  chapter also uses some heavy guns from probability theory to study sequence  patterns. The author returns to matter of a more empirical nature in  Chapter 13, which deals with RNA secondary structures. The reader with a  background in simple combinatorial theory should find the reading  straightforward and informative. Continuous-time Markov chains are  introduced in the next chapter to study trees and sequences. The treatment  here is rather hurried, so again the reader should work the exercises at  the end of the chapter. The book ends with a discussion of the literature  and references.  All in all a very nice book, worth the price, and worth  spending time reading. The only minus might be the total omission of actual  source code, but that really was not the intent of the book. Readers with a  strong mathematical background will like the book, as well as anyone  interested in going into the area of computational biology.The only minus might be the total omission of actual  source code, but that really was not the intent of the book. Readers with a  strong mathematical background will like the book, as well as anyone  interested in going into the area of computational biology.	2000-08-12
2333111:US	50702879	R2IRX919WG0LTD	0387940871	124623437	Fibre Bundles (Graduate Texts in Mathematics) (v. 20)	Books	3	13	16	N	N	OK book on Fiber bundles	Modern mathematics books are usually written in a formal style that makes  for impeccable logic but poor didactic quality.  Husemoller in this book  gives a good summary of the main results in the theory of fiber bundles but  leaves the reader wanting as to just why the techniques used to study  bundles work as well as they do. One needs insight and intuition into a  subject if one is to apply it or extend its frontiers. The techniques from  K-theory and the idea of characteristic classes needs to be explained in  detail. It would be have been nice if the author could have explained, and  not just expounded, why these techniques are so powerful in the study of  fiber bundles. I have read both the 2nd and 3rd edition of this book, went  through all of the calculations and proofs, and still was left with a  hunger for more understanding of the relevant concepts. For such an  understanding I read the original papers in the early part of the 20th  century, and read Norman Steenrod's book on fiber bundles. No doubt that  understanding of such an abstract formalism does require careful thought,  but a good book should be a guide in that effort. Husemoller's book cannot  be read as a standalone book in that regard. One must supplement it with a  tremendous amount of outside reading.  The merits of the book, at least  in the 3rd edition, are the discussion of the guage group of the principal  bundle, and the inclusion of a chapter on characteristic classes and  connections. The physicist reader who is interested in how fiber bundles  enter into quantum field theory or superstring theory will welcome this.  A good book for reference and worth purchasing, but if you want an  in-depth understanding of the theory of fiber bundles, be prepared to read  a lot more other than this book....definitely much too formal.	2000-08-07
2334015:US	50702879	R377O4QS2NY0PQ	0387901485	397871544	Differential Topology (Graduate Texts in Mathematics)	Books	4	20	24	N	N	Nice introduction to differential topology	This book introduces the basic concepts in differential topology, a field  that has taken on particular importance in medical imaging, game theory,  and network optimization. Although written for mathematicians, and  therefore somewhat formal, a good course in multivariable calculus should  prepare the reader for this book. The most difficult chapter is probably  Chapter 2, where Hirsch studies manifolds by means of function spaces and  jets. He does do a good job in this chapter though  of explaining the  origin and need for partitions of unity and gives examples. He also gives  the reader good insight into why analytic maps are more difficult to handle  than the C-r case, and wets the readers appetite for further reading on the  analytic case. The important notion of transversality is discussed in  Chapter 3, which would be good reading for one interested in applications  of differential topology to dynamical systems. A more detailed discussion  of vector bundles would have been helpful in Chapter 4, which discusses  these important objects and the idea of a tubular neighborhood. Sring  theorists or those learning the mathematics should get a lot out of Chapter  5, wherein intersection theory in differential topology is discussed. The  most important chapter of the book is Chapter 6, which discusses Morse  theory. The applications of Morse theory are immense, and cover not only  mathematics, but physics via quantum field theory and string theory,  economics, and even computer graphics. A short chapter on cobordism  follows, which is very nicely written, but a few more words would have been  nice on this topic. After discussing isotopy in Chapter 8, Hirsch gives a  good proof of the classification for surfaces in the last chapter of the  book.  A nice book to have for reference if one is interested in the  subject for its own sake or for its many applications. It should prepare  one for further advanced reading in differential topology, such as the work  of Freedman and Smale on the Poincare conjecture in dimesions 4 and above.  Those interested in applications of differential topology will be amply  prepared to apply these results to the relevant areas, which are many.dman and Smale on the Poincare conjecture in dimesions 4 and above.  Those interested in applications of differential topology will be amply  prepared to apply these results to the relevant areas, which are many.	2000-08-07
2340671:US	50702879	R2D3Y6VC07BN6H	0387985093	240302448	Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues (Texts in Applied Mathematics)	Books	4	40	43	N	N	Good introduction to queuing theory	This book gives a general overview of the more classical results and tools  in queuing theory and Monte Carlo simulation. The author gives a review of  probability theory in Chapter 1. Measure theory and real analysis are not  used here nor in the rest of the book so it should be accessible to  advanced undergraduates and graduate students. Random walks and stochastic  automata are used as examples of discrete-time Markov chains, the topic of  Chapter 2. The author's discussion is very clear and concise and easy to  follow. The important topics of ergodicity and recurrence are discussed in  Chapter 3, in which the author gives a nice definition of the invariant  measure, a concept which is usually presented much too abstractly in modern  texts. He gives a very nice elementary example of an irreducible,  homogeneous Markov chain that has an invariant measure, but that is not  recurrent.Network engineers will appreciate the example of instability in  the slotted ALOHA protocol in this section.  Physicists will like his  discussion of the ergodic theorem in the last section of the chapter. The  next chapter discusses the important topic of convergence to equilibrium,  and he does a good job of doing this without using real analysis or measure  theory. The definition of convergence relies on a concept of distance in  variation between two probability distributions. A brief discussion of  thermodynamic irreversibility is given in this chapter, and illustrated  nicely with Newton's law of cooling. The concepts of absorption and renewal  are treated in this chapter in a way that is very intutive and  understandable. A cute example of absorption is given in terms of  sister-brother mating in genetics. Chapter 5 covers martingales and  Lyapunov functions, of current interest to financial engineers and network  engineers. The author returns to the slotted ALOHA example of Chapter 3 and  shows that altering the retransmission probability will give stability to  the protocol. He discusses the practical limitations of this solution to  instability by an analysis of collision-resolution protocols subsequently.  Potential theory is introduced in this chapter and the author again manages  to do it without real or complex analysis. The important Perron-Frobenius  theorem is discussed in the next chapter on nonhomogeneous Markov chains.  The genetics example introduced earlier is given as one where the  eigenvalues of the transition matrix are computed. The author shows that  the eigenvalue problem for transition matrices is tractable for the  reversible case. Chapter 7 deals with Monte Carlo simulation and the author  does a fine job of introducing the concept of a random fields. He does get  into some topological notions here, by defining neighborhood systems on the  elements of a set. This might have been a problem for the reader not versed  in point set topology, but the author gives the reader good insight by  relating these notions to vertices and edges of a graph. Gibbs  distributions are introduced in a manner similar to what would find in an  undergraduate book on statistical physics. The Ising model and neural  networks are used to illustrate Gibbs models. The author discusses the  Gibbs-Markov equivalence in a nice, detailed manner.Those interested in  computer graphics will enjoy his discussion of image models and textures in  the third section of this chapter, and again in the next section on  Bayesian restoration of images. Section 5 is all physics, where  magnetization and the Ising model dominate the discussion. The simulation  of random fields, along with the all-important Markov chain Monte Carlo  method are the topics of the next two sections. The discussion of MCMC is  definitely the best part of the entire book. The Metropolis algorithm is  discussed in detail. The last section of the chapter discusses simulated  annealing and the discussion is again made very intuitive and avoids the  usual multivariable calculus.  Chapter8 deals with continuous-time  Markov models and the author does a good job, via examples and proofs, of  making the relevant notions clear and understandable. Infinitesimal  generators are introduced via stochastic matrices, and jump processes, so  important to financial engineering, are discussed in this chapter. The  author does discuss the Kolmogorov equation in this chapter, giving the  reader a nice taste of stochastic differential equations. Queuing theory  dominates the last chapter of the book, via Poisson systems. Readers get  their first taste of stochastic discrete-event dynamical systems, and  network modeling engineers will definitely want to pay close attention to  this chapter. The mathematical manipulations could be viewed as a warm-up  maybe to later advanced reading on Ito/Stratonovich calculus, and so  financial engineers will be interested in this discussion. All the standard  queuing theory of networks is discussed in the last sections of the book.  Students of network engineering, physics, financial engineering, and  mathematics will want to take a look at this book. Its price is reasonable  and it is packed with information and insight. Definitely worth reading.er 8 deals with continuous-time  Markov models and the author does a good job, via examples and proofs, of  making the relevant notions clear and understandable. Infinitesimal  generators are introduced via stochastic matrices, and jump processes, so  important to financial engineering, are discussed in this chapter. The  author does discuss the Kolmogorov equation in this chapter, giving the  reader a nice taste of stochastic differential equations. Queuing theory  dominates the last chapter of the book, via Poisson systems. Readers get  their first taste of stochastic discrete-event dynamical systems, and  network modeling engineers will definitely want to pay close attention to  this chapter. The mathematical manipulations could be viewed as a warm-up  maybe to later advanced reading on Ito/Stratonovich calculus, and so  financial engineers will be interested in this discussion. All the standard  queuing theory of networks is discussed in the last sections of the book.      Students of network engineering, physics, financial engineering, and  mathematics will want to take a look at this book. Its price is reasonable  and it is packed with information and insight. Definitely worth reading.	2000-08-03
2345607:US	50702879	R1RQA59N2KFXK2	0944838758	686141926	The Physics of Radiotherapy X-Rays from Linear Accelerators	Books	4	5	8	N	N	Good introduction to radiotherapy physics	The authors give a good introduction to the physics behind radiation therapy planning in this book, from an applied, theoretical, and computational perspective. The coverage emphasizes the physics of linear  accelerators in the first chapter of the book. The discussion is a good  one, and when reading it one appreciates why medical physicists choose the  physical units they do. Treatment aids, such as wedges, multileaf  collimators, blocks, and compensators are also discussed in this chapter,  although somewhat hurriedly. The interaction of X-rays with matter is  treated in Chapter 2, from a phenomenological point of view, with the cross  sections for the physical processes  written down instead of being  calculated from quantum electrodynamics. The authors do a good job of  discussing the origins of the terms kerma and terma in this chapter. The  important topic of electron scattering powers is discussed, again with  quantum field theory left out of the picture, along with a purely  desciptive discussion of charged particle equilibrium. Dosimetry is  discussed in Chapter 3, and the authors give an overview of current  techniques. A discussion of the connection between dose measurements and  how they relate to tumour control should have been more comprehensive. The  authors do however do a good job in informing the reader of the current  techniques in dosimetry in this, the longest chapter of the book. The next  two chapters discuss the properties of X-ray beams and the actual treatment  planning process. The reader will gain an appreciation of the use of the  physical unit MU in these chapters. The authors are not democratic in their  choice of commercial treatment planning systems in this book. The major  vendors, such as Computerized Medcial Systems and ADAC, are only barely  mentioned. The authors do give a general overview of the convolution and  superposition methods in calculating dose, along with a discussion of Monte  Carlo methods. The solution of the transport problem, via the Boltzmann  transort equation, is not mentioned at all. This is not really a detriment  to the book, since this approach has not resulted in anything close to a  clinical application, but it is important to mention why the other  techniques in dose calculation were employed so as to not have to deal with  the general (and difficult) transport problem. Tumor and tissue response  issues are discussed in the last chapter, and the authors do a good job of  discussing this approach to RTP. The book should definitely be on the shelf  of those who aspire to learn this important field and make subsequent  contributions to it.sport problem, via the Boltzmann  transort equation, is not mentioned at all. This is not really a detriment  to the book, since this approach has not resulted in anything close to a  clinical application, but it is important to mention why the other  techniques in dose calculation were employed so as to not have to deal with  the general (and difficult) transport problem. Tumor and tissue response  issues are discussed in the last chapter, and the authors do a good job of  discussing this approach to RTP. The book should definitely be on the shelf  of those who aspire to learn this important field and make subsequent  contributions to it.	2000-07-31
2345872:US	50702879	R3ILP379JDPIW6	0387987991	973404178	Computational Radiology and Imaging: Therapy and Diagnostics (The IMA Volumes in Mathematics and its Applications)	Books	5	0	0	N	N	Great overview of the compuational aspects of RTP	This book is a collection of articles written by various specialists in computational radiology. The content is very mathematical and emphasizes formal aspects of radiology rather than actual program code. The most  refreshing article in the book is the one by D.S. Andronov, A.E. Kovtanyuk,  and I.V. Prokhorov on tomography using the Boltzmann transport equation.  The solution of the transport equation, numerically or otherwise, should be  the main effort of concentration today. Monte Carlo simulations have for  quite some time been used to examine transport problems with the assumption  that the solution of the transport problem is too difficult or too  computationally intensive. Christoph Borgers' article in the opening pages  of the book give credence to the view that the object of interest to  computational radiologists should be the numerical solution of the  Boltzmann transport equation.  Finite elements are one method to  approach the transport problem, and these techniques are advocated in the  field of optical tomography in the article by Arridge and Schweiger.  Pseudocode is given in this article to illustrate the solution of the  relevant problems.  In this book the reader can gain much insight into  the difficult problems facing computational radiologists. The articles are  all well written, the breadth is decent for such a short book, and the  price is reasonable.	2000-07-30
2346557:US	50702879	R241WTRXNJ7ZG5	0691085595	31133036	Elliptic Curves. (MN-40)	Books	5	21	22	N	N	So much insight for so little assumed background	Usually the Princeton Notes are written for specialists in the field. This book by Knapp is a definite exception. The didactic quality is excellent, and the background assumed of the reader is meager compared to what you can  take away by reading this book. The reader is only assumed to have an  undergraduate background in complex analysis and modern algebra...not bad  considering the frontiers that Knapp reaches in this book. The  Eichler-Shimura thoery is treated in the next to last chapter of the book,  and at a very understandable level.  After reading the book one takes  away an understanding of many deep results in the theory of elliptic  curves. The author gives the reader a rare gift for most modern  mathematical texts: insight. Proofs are given for most of the results, but  the main emphasis is on understanding how elliptic curves are studied and  why they are useful mathematical objects.  This is definitely a book to  be read by everyone interested in the theory of elliptic curves. String  theorists, cryptoanalysts, physicists, and aspiring mathematicians whose  interests and applications are in the theory of elliptic curves should  definitely read this book. A mere $50.00 will get you a copy...but it is  definitely worth four times that.  If you are coming to the theory of  elliptic curves for the first time and have a background in comnplex  analysis and modern algebra, read first Joseph Silverman's book on rational  points on elliptic curves, and then Knapp's book. Then move on to  Silverman's two books on the arithmetic of elliptic curves. For both theory  and applications, this sequence should prepare anyone for entering this  very interesting world of elliptic curves.  If only more books in modern  mathematics were written like Knapp's Elliptic Curves...............	2000-07-30
2347147:US	50702879	R14V8ZBPV15JLB	0521653746	823964291	Elliptic Curves in Cryptography (London Mathematical Society Lecture Note Series)	Books	4	26	29	N	N	Good compact book on elliptic curves in cryptography	This book gives a good summary of the current algorithms and methodologies employed in elliptic curve cryptography. The book is short (less than 200 pages), so most of the mathematical proofs of the main results are omitted.  The authors instead concentrate on the mathematics needed to implement  elliptic curve cryptography. The book is written for the reader with some  experience in cryptography and one who has some background in the theory of  elliptic curves.  A reader coming to the field for the first time might  find the reading difficult. The authors do give a brief summary in Chapter  1 on the idea of doing cryptography based on group theory. They then move  on to discuss finite field arithmetic in Chapter 2. The reader is expected  to know some of the basic notions of multiprecision arithmetic for  integers. The authors choose to work with 2^16. Psuedocode is given for  doing modular arithmetic with Montgomery arithmetic given special  attention. The last section of the chapter gives a good summary of  arithmetic in fields of characteristic 2. Chapter 3 discusses very  compactly arithmetic in elliptic curves. This is where the reader should  already have the background in the theory of elliptic curves, since the  reading is very fast and formal. The authors do a good job of summarizing  how modular polynomials come into play in elliptic curve cryptography and  give some explicit examples of these polynomials.  The most important  chapter of the book is Chapter 4, where the authors give a discussion of  how to implement elliptic curves efficiently in cryptosystems. This chapter  is nicely written and pseudocode appears many times with lots of nice  examples. This chapter serves as background for the next one on the  discrete logarithm problem using elliptic curves over finite fields. The  MOV attack, the anomalous attack, and the baby step/giant step methods are  discussed very nicely. Random methods, such as the tame and wild kangaroo  are discussed at the end of the chapter.<br />  The next three chapters  concentrate on how to actually generate elliptic curves for cryptosystems,  with particular attention payed to the Schoof Algorithm. The chapter on  Schoof's algorithm is more detailed than the rest of the chapters and this  makes for better reading. The authors do discuss how to generate curves  using complex multiplication although the discussion is somewhat hurried.  The next chapter discusses how elliptic curves have been applied to other  areas in cryptography, such as factoring, etc. A good discussion of the  ECPP algorithm on proving primality ends the chapter.  The authors end  the chapter with a discussion of hyperelliptic cryptography. Anyone  familiar with the theory of elliptic curves and how they are applied to  cryptography will naturually ask if hyperelliptic curves have any  advantages over the elliptic case. The authors never really address this  explicity but do give examples on just what is involved in implementing  hyperelliptic curves in cryptography.  Overall a fine addition to the  literature on elliptic curves in cryptography. One would hope that the  authors would write a follow-up book on hyperelliptic curves and maybe on  general algebraic curves and their possible use in this area.end of the chapter. <br />  The next three chapters  concentrate on how to actually generate elliptic curves for cryptosystems,  with particular attention payed to the Schoof Algorithm. The chapter on  Schoof's algorithm is more detailed than the rest of the chapters and this  makes for better reading. The authors do discuss how to generate curves  using complex multiplication although the discussion is somewhat hurried.     The next chapter discusses how elliptic curves have been applied to other  areas in cryptography, such as factoring, etc. A good discussion of the  ECPP algorithm on proving primality ends the chapter.    The authors end  the chapter with a discussion of hyperelliptic cryptography. Anyone  familiar with the theory of elliptic curves and how they are applied to  cryptography will naturually ask if hyperelliptic curves have any  advantages over the elliptic case. The authors never really address this  explicity but do give examples on just what is involved in implementing  hyperelliptic curves in cryptography.   Overall a fine addition to the  literature on elliptic curves in cryptography. One would hope that the  authors would write a follow-up book on hyperelliptic curves and maybe on  general algebraic curves and their possible use in this area.	2000-07-29
2347333:US	50702879	R31YLY452K0U9S	0387978259	210434268	Rational Points on Elliptic Curves (Undergraduate Texts in Mathematics)	Books	5	18	19	N	N	Full of useful information and a great guide to intuition	The authors do a fantastic job of introducing elliptic curves for  individuals and students interested in this area. Because of the importance of elliptic curves to cryptography, in integrable models in statistical  mechanics, in superstring theory in physics, in mirror symmetry in  algebraic geometry, in mechanics in the solution of the spinning top, and  even in financial engineering, this book will be useful in building  intuition about these interesting objects.  Be careful in reading this  book though...the theory of elliptic curves is beautiful and addicting, and  you will want no doubt to read more about them after finishing it. There  are two other books by Silverman that will alleviate the monkey on your  back for more knowledge about elliptic curves. Happy reading......	2000-07-29
2347676:US	50702879	R12A30U6GJQDLI	0792385896	138998233	Elliptic Curves and Their Applications to Cryptography: An Introduction	Books	4	3	3	N	N	A balanced, nice introduction to elliptic curve cryptography	This book gives a straightforward introduction to the theory of elliptic curves as applied to cryptography and is written for those individuals without a strong background in abstract mathematics. The authors summarize  the ideas behind public key cryptography in the first chapter and then move  on to the group law on elliptic curves. The best part of this chapter is  the explicit calculations the author gives for the group operations,  espeically over fields of characteristic 2. The author chooses not to prove  the associativity of the group operation geometrically bust uses the  isomorphism between the curve and the degree zero part of its Picard group.  This approach on the surface might seem abstract for those not having a  background in algebraic geometry but the author does a good job of giving  an intuition about the Picard group. A reader with a basic background in  complex variable theory should find the discussion very understandable.  Chapter 3 gives a thorough discussion of elliptic curves over finite  fields, those being relevant to cryptographic applications. Explicit  calculations are given for the Weil pairing and Hasse's theorem is proved  in detail. Dissapointingly, the author does not give explicit proofs for  the cases of supersingular curves but instead refers the reader to the  literature. More discussion on the supersingular case might be warranted  here so as to give an idea on its limitations in elliptic curve  cryptography.  The chapter on the discrete logarithm problem is nicely  written with discussions of the different attacks done in detail.Some  pseudocode inserted in the text would have been nice. The last chapter  concerns calculating the order of the group, and the author does a good job  of discussing the Baby-Step Giant-Step algorithm and Schoof's algorithm.  The important idea of isogeny is discussed briefly in this chapter but  proofs relating isogenies and modular polynomials are omitted entirely and  the reader is referred to the literature. It would have been nice if the  author could have taken this difficult theory and distilled it down to a  form that is similar to the rest of the book. Such an intuitive discussion  would have proven to be invaluable and would justify more the price of the  book.  A very expensive book but worth it for those very interested in  elliptic curve cryptography.ed to the literature. It would have been nice if the  author could have taken this difficult theory and distilled it down to a  form that is similar to the rest of the book. Such an intuitive discussion  would have proven to be invaluable and would justify more the price of the  book.    A very expensive book but worth it for those very interested in  elliptic curve cryptography.	2000-07-29
2793016:US	50702879	RYN3T9HXFU0CF	0849385237	713146115	Handbook of Applied Cryptography (Discrete Mathematics and Its Applications)	Books	4	27	47	N	N	Nice job but discussion of ECC omitted.	This book could be studied by anyone with mathematical background equivalent to what one would pick up in an average undergraduate education in mathematics: strong knowledge of group theory, elementary number theory, and some coursework in computer science such as algorithm development or theory of algorithms. Things might get a little heavy for such a reader when the authors discuss irreducible polynomials over finite fields but the authors manage to explain it in such a way as to make it palatable. The pseudocode presented after each algorithm will no doubt be extremely helpful to those readers who are responsible for implementing them in real-world applications of cryptography. Overall the book is nicely organized into theory, definitions, examples, facts, and algorithm sections that are set apart in the text for more manageable reading.<br /><br />This might be a disappointing book for those who expected a discussion of elliptic curve cryptography (ECC) as the  authors spend one paragraph on elliptic curves and state that an in-depth discussion of such is beyond the scope of the book.The book is however a very good one for discussing most of the other approaches to  cryptography. A serious student/practitioner of cryptography should have this  on his/her shelf, but supplemented by some of the other books on elliptic  curve cryptography. The authors could no doubt write a second edition  of this book which includes a discussion of elliptic curve cryptography, and then the handbook would become a \\"Bible\\" for specialists in cryptography.	1999-09-10
2797261:US	50702879	RG4YA4B7SPX11	0201563177	673455254	Advanced Programming in the UNIX(R) Environment (Addison-Wesley Professional Computing Series)	Books	5	4	6	N	N	Beautiful book!	This is a very nice book on the C programming behind the UNIX operating system. It should be of great interest to those who are working on security issues in the UNIX operating system as well as those curious about how the  UNIX shell command code is written. Chapter 4 on files and directories was  exceptionally well written. A definite buy for those who are really  embedded in the intricacies of UNIX.	1999-09-03
2799117:US	50702879	R1N8MJAA31Z4U1	0201548550	667504788	Advanced C++ Programming Styles and Idioms	Books	4	5	7	N	N	Vrey readable book on advanced C++	This book was nice reading and discussed the more abstract details of C++. Even one of the appendices, namely Appendix A on C in a C++ environment, was very helpful in my designing of interface functions to call C++  routines from legacy C code. It would have been better if Coplien had  included this discussion as an entire chapter and made the discussion more  detailed. These issues arise more and more every day as companies who have  programmed in C are moving over to C++. Chapter 8 on programming with  examplars was very interesting reading. -LC (Global Mathematics, Inc)	1999-08-31
2799432:US	50702879	R2NW22H49RTUU4	0201834545	246872019	Inside the C++ Object Model	Books	4	7	11	N	N	Helpful book on C++	I found this book helpful in explaining more of the foundational issues behind C++. Chapter 3 in particular was very helpful, in that Lippman explains in detail just how classes are compiled.  Buy this book if you  want more details on performance issues in C++.	1999-08-31
2799684:US	50702879	RUCYGXU1MH9UO	0387947752	694783395	A Theory of Objects (Monographs in Computer Science)	Books	5	16	20	N	N	Interesting methodology for modeling OOP.	This book attempts to give a kind of \\"lambda calculus\\" for objects in OOP (object-oriented programming)and does a fine job in that regard. For those interested in the foundations of programming languages, this book will be interesting reading and it no doubt will play a role in applications such as artificial intelligence and computational linguistics. The formalism is deep and highly abstract, but this should be no surprise to those readers who are familiar with the foundational essays on other programming paradigms, such as logic programming and functional programming.	1999-08-30
2799704:US	50702879	R2B9BO3NHPR9R2	0898712955	41801717	Random Number Generation and Quasi-Monte Carlo Methods (CBMS-NSF Regional Conference Series in Applied Mathematics)	Books	5	6	8	N	N	Nice book on Quasi-Monte Carlo methods.	This book is a mathematical introduction and summary of quasi-Monte Carlo methods and is geared towards mathematicians. The author does an excellent job of detailing the results in the field, with all theorems being proved  in detail. I would recommend this book to both pure mathematicians  interested in quasi-Monte Carlo and to applied mathematicians and software  developers who need to understand the theory behind these very important  methodologies. Quasi-Monte Carlo methods are &quot;beating out&quot; the  standard Monte Carlo techniques in areas of financial engineering and  transport theory. This book belongs on the shelf of those interested in  this very important topic.	1999-08-30
2800134:US	50702879	R3UHT29IZUEETM	0131037978	377783880	Object-Oriented Programming with C++ and Smalltalk	Books	5	1	3	N	N	A great book...sorry it had to end	With no doubt, this is the best book on object-oriented programming out there. The author addresses not only the theoretical concepts behind OO-programming, but he outlines how to do it using Smalltalk, one of the first OO-languages, and C++, certainly one of the most widely-used OO-languages. I do not know Smalltalk, and did not read the part on this language, so my comments will be limited to the sections on C++ and the general discussions on OO-programming.<br />  The author gives an overview of the semantics or \\"meaning\\" of a program. He is very thorough in his treatment, and some of the areas that I found particularly well-written include his discussions of:Order of evaluation and side effects; conditional, controlled, and implicit iteration; the importance of strong typing in giving more reliable code; the run-time stack; passing by name, by value, by value-result,and by reference; declarations versus definitions; the difference between static and dynamic typing; static versus dynamic scoping; object lifetime and instantiation; static, automatic, and dynamic storage; data types; pointers; constrained types; encapsulation and information hiding; abstraction mechanisms; programming paradigms, including imperative, functional, logic, and object-oriented; =class semantics; the distinction between \\"pure\\" OO-languages such as Smalltalk, Eiffel, and Java, and hybrid OO-languages such as Object Pascal, Oberon, Delphi Pascal, Ada95, C++, and Objective C; the tradeoffs between execution time and dynamic binding in C++; the justification for using in-line functions rather than macros in C++; static, file, local function, and class scope in C++; static and dynamic storage allocation of objects in C++; the distinction between a class in C++, which must be an instance, and thus not \\"first-class\\" as in Smalltalk; friend declarations in C++ and how they depart from OO-philosophy; the example of the \\"Queue\\" class; the \\"this\\" pointer in C++; \\"smart\\" pointers in C++; and class templates in C++.<br />He does not include a discussion of object-oriented design methodologies (Booch, etc), but does give references for further reading. Excellent summaries are given at the end of each chapter along with exercises.It is definitely a book that serves well also as a reference, even though it was published in 1997, and some changes to the implementation of C++ have occurred since then.ss templates in C++.    <br />He does not include a discussion of object-oriented design methodologies (Booch, etc), but does give references for further reading. Excellent summaries are given at the end of each chapter along with exercises.It is definitely a book that serves well also as a reference, even though it was published in 1997, and some changes to the implementation of C++ have occurred since then.	1999-08-30
